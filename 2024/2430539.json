{
 "awd_id": "2430539",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Foundations of Trustworthy Deep Learning: Interpretable Neural Network models with Robustness Guarantees",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2024-09-01",
 "awd_exp_date": "2027-08-31",
 "tot_intn_awd_amt": 596797.0,
 "awd_amount": 596797.0,
 "awd_min_amd_letter_date": "2024-08-22",
 "awd_max_amd_letter_date": "2024-08-22",
 "awd_abstract_narration": "Deep neural networks have achieved remarkable success in fields ranging from computer vision to healthcare and autonomous driving. However, their susceptibility to various failure modes and blindspots can pose significant risks, especially in safety-critical and high-stakes applications. Given their complex and opaque \u201cblack-box\u201d nature, understanding why and when deep neural networks fail is crucial for their safe real-world deployment. Existing mainstream interpretability methods for neural networks are limited\u2014they focus mainly on subjective explanations based on influential features, fail to scale or explain the internal network processes, and struggle with minor input changes, which can be risky in high-stakes applications. This project aims to develop an automated framework for interpreting neural networks and to design robust, neural network models based on human-understandable concepts. These advancements will promote automation and scalability, ensure transparent decision-making, facilitate efficient model debugging, and enable timely intervention, leading to safer, more reliable, and widely trusted applications of deep learning technology in critical domains. \r\n\r\nThis project will develop methods that can be used to ensure modern deep neural network models are interpretable and trustworthy. It includes methods for (1) automating interpretations that describe the internal functioning of a deep neural network via human-understandable concepts without the need to collect curated and expert annotations; (2) learning intrinsically interpretable models that contain task-relevant human-interpretable concepts by design; (3) quantifying and ensuring the robustness and reliability of the generated interpretations and the neural network models. The methods will draw on the investigator\u2019s expertise in trustworthy machine learning and neural network robustness verification techniques to develop scalable and automated methods that will promote interpretability, robustness, transparency, and reliability in deep learning. If successful, this project will guide the design of deep learning systems to guarantee transparency and robustness, and provide the tools needed to enforce these properties during model development and deployment.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tsui-Wei",
   "pi_last_name": "Weng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tsui-Wei Weng",
   "pi_email_addr": "lweng@ucsd.edu",
   "nsf_id": "000842499",
   "pi_start_date": "2024-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 GILMAN DR",
  "perf_city_name": "LA JOLLA",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 596797.0
  }
 ],
 "por": null
}