{
 "awd_id": "2339096",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Synesthetic Teaching of Dexterous Robots through Multi-Sensory Fusion of Vision, Touch, and Vibration",
 "cfda_num": "47.041, 47.070",
 "org_code": "07010000",
 "po_phone": "7032922303",
 "po_email": "eabed@nsf.gov",
 "po_sign_block_name": "Eyad Abed",
 "awd_eff_date": "2024-06-01",
 "awd_exp_date": "2029-05-31",
 "tot_intn_awd_amt": 585448.0,
 "awd_amount": 485448.0,
 "awd_min_amd_letter_date": "2024-05-28",
 "awd_max_amd_letter_date": "2024-05-28",
 "awd_abstract_narration": "Our world is messy, unpredictable, and teeming with diverse sensory stimuli. While meticulous modeling and ingenious engineering have enabled robots to revolutionize the factory floor, the ability to effectively manipulate everyday objects in common environments remains an elusive challenge. A fundamental reason for this challenge lies in their limited sensing capabilities. Consider the problem of unlocking a door lock. To accomplish this, humans utilize a range of senses including sound to locate the pocket with keys, vision to identify the correct key, tactile feedback to insert the key precisely, and proprioception to coordinate movements. These rich sensory modalities compensate for each other's deficiencies (e.g. visual occlusion), facilitate recall of past strategies (e.g. the click of unlocking) and ensure robustness against sensor failure (e.g. numb hands). Developing a robotic system that can synergistically utilize a wide range of sensors requires creating new algorithms capable of reasoning about high-dimensional, uncalibrated and noisy inputs. This Faculty Early Career Development (CAREER) project funds research that aims to develop Synesthetic Teaching, a new framework for teaching dexterous manipulation to multifingered robots using rich, multi-modal sensory observations.\r\n\r\nThis research project is divided into four broad topics to advance the state of the art in robotics by integrating new sensing modalities for multi-fingered robots: (1) combining multi-camera streams with multi-fingered proprioception; (2) incorporating uncalibrated tactile feedback for enhanced offline imitation; (3) utilizing vibration feedback for adapting to dynamic manipulation; (4) developing multi-fingered robot systems capable of contact-rich manipulation in real-world scenarios created in the PI's lab. This research will create robots that solve more difficult manipulation problems than currently possible, by developing new algorithms in self-supervised representation learning, cross-modal fusion, and online imitation. The intended applications of these robots are in assistive robotics, flexible manufacturing, household robotics, fulfillment and others that require enhanced multi-fingered dexterity.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lerrel",
   "pi_last_name": "Pinto",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Lerrel J Pinto",
   "pi_email_addr": "lp91@nyu.edu",
   "nsf_id": "000814794",
   "pi_start_date": "2024-05-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "70 WASHINGTON SQ S",
  "perf_city_name": "NEW YORK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 485448.0
  }
 ],
 "por": null
}