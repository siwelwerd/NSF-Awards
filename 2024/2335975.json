{
 "awd_id": "2335975",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RAPID DRL AI: Empowering Teachers to Collaborate with Generative AI for Developing High-Quality STEM Learning Resources",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032925126",
 "po_email": "abaylor@nsf.gov",
 "po_sign_block_name": "Amy Baylor",
 "awd_eff_date": "2023-12-01",
 "awd_exp_date": "2024-11-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2023-11-29",
 "awd_max_amd_letter_date": "2023-11-29",
 "awd_abstract_narration": "The rapid advances in large language models (LLMs) have presented tremendous opportunities to create interactive, personalized learning resources on a large scale. To fully harness the educational potential of these technologies, it is  crucial that teachers - who are at the forefront of daily student interaction and possess indispensable knowledge and expertise - serve as key contributors in the process. This time-sensitive project addresses the urgent need for viable mechanisms to empower teachers to harness the capabilities of LLMs through a teacher-AI collaboration paradigm in the context of learning through video. The research team will partner with WGBH Educational Foundation (GBH), Boston\u2019s PBS station, to support teachers in creating  and customizing an intelligent tutor that accompanies the STEM learning resources available on PBS LearningMedia, a platform already popular among teachers nationwide, with a comprehensive library of over 5,000 high quality STEM-focused videos and millions of users. This proposal was received in response to the Dear Colleague Letter (DCL): Rapidly Accelerating Research on Artificial Intelligence in K-12 Education in Formal and Informal Settings (NSF 23-097) and funded by the Innovative Technology Experiences for Students and Teachers (ITEST) program, which supports projects that build understandings of practices, program elements, contexts and processes contributing to increasing students' knowledge and interest in science, technology, engineering, and mathematics (STEM) and information and communication technology (ICT) careers.\r\n\r\nIntelligent tutors will be incorporated into videos and pose comprehension questions to students and provide personalized feedback during video viewing. The team will iteratively design and develop a teacher-AI collaborative platform that allows teachers to oversee the intelligent tutors\u2019 generation of question sequences and feedback. The platform will provide \"LLM building blocks\" for teachers to steer LLMs to generate desirable outputs. Thus, teachers maintain control over the tutors' instructional dialogue with students, ensuring such dialogue aligns with teachers\u2019 instructional objectives and the unique needs of their students. The team will then generate evidence demonstrating the feasibility and potential effectiveness of the proposed mechanism and specific design strategies that enable non-technical domain experts to have significant involvement in the development of AI-based educational resources. This project has the potential for a substantial broader impact, as it builds upon the existing PBS LearningMedia platform. This ensures the sustainability of the proposed platform and reach a large number of educators. By making the platform publicly available, this research will enable educators to continue generating interactive videos that cater to their specific educational needs. This work holds the promise of democratizing access to AI for teachers and promoting their active involvement in the production of AI-based learning resources.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xu",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xu Wang",
   "pi_email_addr": "xwanghci@umich.edu",
   "nsf_id": "000839066",
   "pi_start_date": "2023-11-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ying",
   "pi_last_name": "Xu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ying Xu",
   "pi_email_addr": "ying_xu@gse.harvard.edu",
   "nsf_id": "000845124",
   "pi_start_date": "2023-11-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "Regents of the University of Michigan - Ann Arbor",
  "perf_str_addr": "1109 GEDDES AVE, SUITE 3300",
  "perf_city_name": "ANN ARBOR",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091079",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "722700",
   "pgm_ele_name": "ITEST-Inov Tech Exp Stu & Teac"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "092Z",
   "pgm_ref_txt": "AI-Supported Learning"
  },
  {
   "pgm_ref_code": "7914",
   "pgm_ref_txt": "RAPID"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "1300PYXXDB",
   "fund_name": "H-1B FUND, EDU, NSF",
   "fund_symb_id": "045176"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p dir=\"ltr\">We introduce ScienceChat, a platform that allows high school teachers to create their own chatbots embedded into any youtube videos. We evaluated the platform with high school students and found that students learnt significantly with both AI-powered chat agents, and AI-generated quiz questions with feedback. The platform is ready for use and is compatible with any youtube videos, which is a critical source for science learning in high school classrooms.</p>\r\n<p dir=\"ltr\">The primary image is the student interface of ScienceChat. Students interact with a chatbot while watching a video. The video pauses at question markers, and the agent poses a question such as &ldquo;what is a mutation&rdquo;, the student can engage in back-and-forth conversations with the agent, and after the student demonstrates good understanding, they continue watching the video.</p>\r\n<p dir=\"ltr\">In the teacher interface of SciencChat, teachers can configure how the chatbot behaves, e.g., teachers can provide &ldquo;required components&rdquo; in a student answer. Teachers can also test the chatbot through role-playing as a student.</p>\r\n<p dir=\"ltr\">A unique design of the chatbot is that it contains multiple specialized agents communicating in the back-end. Each agent is configured with a set of different chain-of-thought prompts. This multi-agent approach allows different agents to query different contexts (i.e., different subsets of video transcript) to deliver the most accurate information. For example, there are specialized agents for evaluating student answers (which requires the agent to be retrieving information from the video transcript), and there are specialized agents for answering student questions (where the agent can be more creative). The flow diagram can be seen in the supplementary images.</p>\r\n<p dir=\"ltr\">Using the platform, we performed an evaluation study investigating the relative effectiveness of chat-based tutoring and quiz-based tutoring. In the quiz mode, the video plays on the left, and the video player pauses at question markers, and the student will answer a multiple-choice question and receive immediate feedback.</p>\r\n<p dir=\"ltr\">This project contributes the following insights:</p>\r\n<ol>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\">First, this project contributes insights on how teachers would like to collaborate with AI to create educational materials. To derive the chat tutor design requirements, we performed three rounds of a need-finding study with 20 high school science teachers. We derived several key design requirements for developing tutoring systems to teach educational videos. This includes i) teachers liked the idea of embedding back-and-forth conversations in videos; ii) teachers would like to embed questions at regular intervals to maintain engagement; iii) teachers want to make sure the questions are answerable and align with NGSS standards. Teachers want to ask questions about important vocabularies and concepts; iv) teachers want to ask questions that elicit critical thinking.&nbsp;</p>\r\n</li>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\">Second, this project contributes insights on teacher-AI collaborative techniques to configure chat-based tutoring systems. In developing ScienceChat, we show a proof of concept that with input from teachers, e.g., &ldquo;required components&rdquo; in student answers, the chatbots can accurately evaluate students&rsquo; responses and give hints and feedback. This project also contributes a multi-agent approach in reducing hallucinations and providing reliable information in a tutoring context.&nbsp;</p>\r\n</li>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\">Through comparing chat-based tutoring and quiz-based tutoring, we found that students demonstrated significant learning gains in both scenarios. On a 8-point quiz, students' average score increased from 2.9 to 6.2, an average gain of 41% of the total score. However, we did not witness a significant difference between the two conditions on learning gains. This suggests that when teachers are limited on time, a carefully designed LLM pipeline could deliver pedagogically beneficial quiz questions which are ready for immediate use, e.g., on platforms that are already popular among teachers such as EdPuzzle. Given that using AI-powered chat tutors requires more computational resources, it needs further evidence to advocate for their use.&nbsp;</p>\r\n</li>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\">We observed qualitative evidence that for students who had lower pre-test scores, they seemed to benefit more from chat-based tutoring. Since our study sample is relatively small, future work is required to investigate the interaction between tutoring methods and students' prior knowledge levels. In the experience survey, students rated the chat mode to be more thought-provoking, provided more new knowledge, and encouraged deeper reflections about the video. However, students also rated chat mode to incur higher cognitive loads.</p>\r\n</li>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\">We observed that answering questions in the chat mode could take longer. Students reviewed previous video segments more frequently and recalled more details when answering questions in chat mode, whereas many students got the multiple-choice question right on the first try. We observed qualitative evidence of learning in the chat mode, e.g., when students showed misconceptions in their answers, the AI agent guided them to correct the mistakes. We also noticed situations where the AI chat agent was annoying and distracting for the students, e.g., when it tries to elicit unnecessary details from the students. It requires future work to address the AI limitations and further investigate the learning benefits of LLM-powered chat tutoring systems.&nbsp;</p>\r\n</li>\r\n</ol><br>\n<p>\n Last Modified: 02/28/2025<br>\nModified by: Xu&nbsp;Wang</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801864925_RAPID_img5_chatexample--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801864925_RAPID_img5_chatexample--rgov-800width.png\" title=\"Good example of student chat with the agent\"><img src=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801864925_RAPID_img5_chatexample--rgov-66x44.png\" alt=\"Good example of student chat with the agent\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">In this example, the agent asks a good probing question, which reveals a student misconception. The student first listed all organisms that could have mutations, without mentioning the commonality among them. The agent followed up to elicit the desired level of understanding.</div>\n<div class=\"imageCredit\">Xu Wang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xu&nbsp;Wang\n<div class=\"imageTitle\">Good example of student chat with the agent</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801624742_RAPID_img4_multiagent--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801624742_RAPID_img4_multiagent--rgov-800width.png\" title=\"Implementation method of the chat agent. We used a multi-agent approach to reduce hallucinations.\"><img src=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801624742_RAPID_img4_multiagent--rgov-66x44.png\" alt=\"Implementation method of the chat agent. We used a multi-agent approach to reduce hallucinations.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The AI agent in the chat mode is composed of multiple specialized agents communicating with each other, each configured with a set of different chain-of-thought prompts. This multi-agent approach allows different agents to query different contexts (i.e., different subsets of video transcript).</div>\n<div class=\"imageCredit\">Xu Wang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xu&nbsp;Wang\n<div class=\"imageTitle\">Implementation method of the chat agent. We used a multi-agent approach to reduce hallucinations.</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801130416_RAPID_img1_studentinterface--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801130416_RAPID_img1_studentinterface--rgov-800width.png\" title=\"Student interface: students interact with a chatbot while watching a video\"><img src=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801130416_RAPID_img1_studentinterface--rgov-66x44.png\" alt=\"Student interface: students interact with a chatbot while watching a video\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">As shown in the above screenshot of the student interface of ScienceChat, students interact with a chatbot while watching a video. The video pauses at question markers, and the agent poses a question such as \ufffdwhat is a mutation\ufffd, the student can engage in back-and-forth conversations with the agent,</div>\n<div class=\"imageCredit\">Xu Wang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xu&nbsp;Wang\n<div class=\"imageTitle\">Student interface: students interact with a chatbot while watching a video</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801932371_RAPID_img6_chatexample--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801932371_RAPID_img6_chatexample--rgov-800width.png\" title=\"Good example of student chat with the agent\"><img src=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801932371_RAPID_img6_chatexample--rgov-66x44.png\" alt=\"Good example of student chat with the agent\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">In this example, the student missed an important piece of information in their answer. The agent asked a good follow-up question, the student rewatched the video and picked up the critical information.</div>\n<div class=\"imageCredit\">Xu Wang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xu&nbsp;Wang\n<div class=\"imageTitle\">Good example of student chat with the agent</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801167512_RAPID_img2_teacherinterface--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801167512_RAPID_img2_teacherinterface--rgov-800width.png\" title=\"Teacher interface: teachers can configure the chatbot, e.g., modifying the components\"><img src=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801167512_RAPID_img2_teacherinterface--rgov-66x44.png\" alt=\"Teacher interface: teachers can configure the chatbot, e.g., modifying the components\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">In the teacher interface of SciencChat, teachers can configure how the chatbot would behave, e.g., teachers can provide \ufffdrequired components\ufffd in a student answer. Teachers can also test the chatbot role-playing as a student.</div>\n<div class=\"imageCredit\">Xu Wang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xu&nbsp;Wang\n<div class=\"imageTitle\">Teacher interface: teachers can configure the chatbot, e.g., modifying the components</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801311375_RAPID_img3_chatvsquiz--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801311375_RAPID_img3_chatvsquiz--rgov-800width.png\" title=\"In this project, we compared chat-based tutoring with quiz-based tutoring. In the ScienceChat platform, we introduced two modes (chat on the left, and quiz on the right).\"><img src=\"/por/images/Reports/POR/2025/2335975/2335975_10903281_1740801311375_RAPID_img3_chatvsquiz--rgov-66x44.png\" alt=\"In this project, we compared chat-based tutoring with quiz-based tutoring. In the ScienceChat platform, we introduced two modes (chat on the left, and quiz on the right).\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">In this project, we investigate two methods of embedding AI-based tutoring in high school science videos, including chat-based tutoring (left) where learners have conversations with an agent, and quiz-based tutoring (right), where learners answer multiple-choice questions and receive feedback</div>\n<div class=\"imageCredit\">Xu Wang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xu&nbsp;Wang\n<div class=\"imageTitle\">In this project, we compared chat-based tutoring with quiz-based tutoring. In the ScienceChat platform, we introduced two modes (chat on the left, and quiz on the right).</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nWe introduce ScienceChat, a platform that allows high school teachers to create their own chatbots embedded into any youtube videos. We evaluated the platform with high school students and found that students learnt significantly with both AI-powered chat agents, and AI-generated quiz questions with feedback. The platform is ready for use and is compatible with any youtube videos, which is a critical source for science learning in high school classrooms.\r\n\n\nThe primary image is the student interface of ScienceChat. Students interact with a chatbot while watching a video. The video pauses at question markers, and the agent poses a question such as what is a mutation, the student can engage in back-and-forth conversations with the agent, and after the student demonstrates good understanding, they continue watching the video.\r\n\n\nIn the teacher interface of SciencChat, teachers can configure how the chatbot behaves, e.g., teachers can provide required components in a student answer. Teachers can also test the chatbot through role-playing as a student.\r\n\n\nA unique design of the chatbot is that it contains multiple specialized agents communicating in the back-end. Each agent is configured with a set of different chain-of-thought prompts. This multi-agent approach allows different agents to query different contexts (i.e., different subsets of video transcript) to deliver the most accurate information. For example, there are specialized agents for evaluating student answers (which requires the agent to be retrieving information from the video transcript), and there are specialized agents for answering student questions (where the agent can be more creative). The flow diagram can be seen in the supplementary images.\r\n\n\nUsing the platform, we performed an evaluation study investigating the relative effectiveness of chat-based tutoring and quiz-based tutoring. In the quiz mode, the video plays on the left, and the video player pauses at question markers, and the student will answer a multiple-choice question and receive immediate feedback.\r\n\n\nThis project contributes the following insights:\r\n\r\n\r\n\n\nFirst, this project contributes insights on how teachers would like to collaborate with AI to create educational materials. To derive the chat tutor design requirements, we performed three rounds of a need-finding study with 20 high school science teachers. We derived several key design requirements for developing tutoring systems to teach educational videos. This includes i) teachers liked the idea of embedding back-and-forth conversations in videos; ii) teachers would like to embed questions at regular intervals to maintain engagement; iii) teachers want to make sure the questions are answerable and align with NGSS standards. Teachers want to ask questions about important vocabularies and concepts; iv) teachers want to ask questions that elicit critical thinking.\r\n\r\n\r\n\n\nSecond, this project contributes insights on teacher-AI collaborative techniques to configure chat-based tutoring systems. In developing ScienceChat, we show a proof of concept that with input from teachers, e.g., required components in student answers, the chatbots can accurately evaluate students responses and give hints and feedback. This project also contributes a multi-agent approach in reducing hallucinations and providing reliable information in a tutoring context.\r\n\r\n\r\n\n\nThrough comparing chat-based tutoring and quiz-based tutoring, we found that students demonstrated significant learning gains in both scenarios. On a 8-point quiz, students' average score increased from 2.9 to 6.2, an average gain of 41% of the total score. However, we did not witness a significant difference between the two conditions on learning gains. This suggests that when teachers are limited on time, a carefully designed LLM pipeline could deliver pedagogically beneficial quiz questions which are ready for immediate use, e.g., on platforms that are already popular among teachers such as EdPuzzle. Given that using AI-powered chat tutors requires more computational resources, it needs further evidence to advocate for their use.\r\n\r\n\r\n\n\nWe observed qualitative evidence that for students who had lower pre-test scores, they seemed to benefit more from chat-based tutoring. Since our study sample is relatively small, future work is required to investigate the interaction between tutoring methods and students' prior knowledge levels. In the experience survey, students rated the chat mode to be more thought-provoking, provided more new knowledge, and encouraged deeper reflections about the video. However, students also rated chat mode to incur higher cognitive loads.\r\n\r\n\r\n\n\nWe observed that answering questions in the chat mode could take longer. Students reviewed previous video segments more frequently and recalled more details when answering questions in chat mode, whereas many students got the multiple-choice question right on the first try. We observed qualitative evidence of learning in the chat mode, e.g., when students showed misconceptions in their answers, the AI agent guided them to correct the mistakes. We also noticed situations where the AI chat agent was annoying and distracting for the students, e.g., when it tries to elicit unnecessary details from the students. It requires future work to address the AI limitations and further investigate the learning benefits of LLM-powered chat tutoring systems.\r\n\r\n\t\t\t\t\tLast Modified: 02/28/2025\n\n\t\t\t\t\tSubmitted by: XuWang\n"
 }
}