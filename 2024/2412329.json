{
 "awd_id": "2412329",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: OAC Core: Small: Anomaly Detection and Performance Optimization for End-to-End Data Transfers at Scale",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2023-10-01",
 "awd_exp_date": "2024-10-31",
 "tot_intn_awd_amt": 275000.0,
 "awd_amount": 72989.0,
 "awd_min_amd_letter_date": "2023-12-18",
 "awd_max_amd_letter_date": "2024-11-15",
 "awd_abstract_narration": "Despite continuous efforts and investments to upgrade the networking infrastructure of research and education institutions to meet the needs of large-scale science applications, the data transfers on these networks often perform very poorly. Understanding the underlying reasons for poor transfer performance is important yet challenging due to the sophisticated design of today's cyberinfrastructures. This project offers a set of novel models and algorithms to detect and mitigate performance issues of data transfers in research networks. The proposed suite of tools helps researchers and system administrators to pinpoint the root cause of performance problems of data transfers so that necessary actions can be taken swiftly to minimize their impact on ongoing transfers.  The project will also integrate the research into all levels of education, including science projects with K-12 students, development of new curriculum modules for graduate- and undergraduate-level courses, and summer workshops specifically for minority groups.\r\n\r\nUnderstanding the true underlying reasons for poor transfer performance is key to mitigating them and delivering the promised transfer speeds. However, the involvement of multiple end systems, dynamically changing background traffic, and the complexity of today's networking infrastructures turns it into a complicated and time-consuming process.  This project develops a novel anomaly-detection and performance-optimization framework for end-to-end data transfers at scale. The framework helps to predict, understand, diagnose, and optimize wide-area file transfers in today's extreme-scale cyberinfrastructures. To achieve this goal, it derives deep-neural-network-based predictive models that can relate transfer settings to throughput. These models are then used to estimate the optimal configuration for new transfers. The framework also gathers performance metrics for end-system and network resources periodically to keep track of system utilization. When a transfer anomaly is detected, the collected metrics are fed into anomaly-classification models to identify the root causes. Once the underlying reasons of performance problems are identified, the framework launches a real-time optimization process to reconfigure the transfer settings such that the impact of anomalies can be alleviated.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Engin",
   "pi_last_name": "Arslan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Engin Arslan",
   "pi_email_addr": "heyengin@gmail.com",
   "nsf_id": "000758403",
   "pi_start_date": "2023-12-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Arlington",
  "inst_street_address": "701 S NEDDERMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "ARLINGTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "8172722105",
  "inst_zip_code": "760199800",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT ARLINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "LMLUKUPJJ9N3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Arlington",
  "perf_str_addr": "701 S. NEDDERMAN DR",
  "perf_city_name": "ARLINGTON",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "760199800",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "090Y00",
   "pgm_ele_name": "OAC-Advanced Cyberinfrast Core"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 72989.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 0.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">This peoject aimed to address critical performance bottlenecks in high-speed research networks. Despite continuous advancements in networking infrastructure, large-scale data transfers often suffer from inefficiencies due to the complexity of cyberinfrastructures, dynamically changing traffic, and unpredictable anomalies. This project developed novel machine learning models, real-time monitoring frameworks, and optimization algorithms to diagnose and enhance data transfer performance, ensuring that research institutions can effectively utilize their high-speed networks.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">One of the key contributions of this project was the development of predictive models using deep neural networks to understand and optimize end-to-end data transfers. These models analyze transfer settings and predict achievable throughput under various conditions, enabling automatic tuning of parameters to maximize performance. Unlike conventional rule-based heuristics, which struggle to generalize across different network environments, the deep-learning-based approach dynamically adapts to changing conditions, improving transfer efficiency.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">Another major outcome was the implementation of a real-time monitoring framework capable of detecting and diagnosing anomalies in wide-area file transfers. Lightweight monitoring agents were deployed on data transfer nodes to collect real-time performance metrics, which were then analyzed using machine learning and heuristic-based models. By identifying the root causes of performance degradation&mdash;such as network congestion, hardware limitations, or suboptimal transfer configurations&mdash;the framework provided actionable insights to system administrators. The monitoring system demonstrated the ability to track over 40,000 transfers across multiple nodes, ensuring scalability and high precision.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">To mitigate performance bottlenecks, the project also introduced advanced online optimization techniques for data transfer tuning. A deep reinforcement learning-based approach utilizing Proximal Policy Optimization (PPO) was developed to optimize network bandwidth utilization. This adaptive algorithm dynamically adjusted parallel TCP streams to enhance throughput while preventing congestion and ensuring fairness among competing transfers. Compared to traditional optimization methods like gradient descent and Bayesian optimization, this approach identified near-optimal solutions 40% faster while achieving up to 15% higher throughput.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">Furthermore, the project designed&nbsp;<span class=\"s1\">Marlin</span>, a modular file transfer architecture that decouples read, transfer, and write operations, allowing independent optimization of each component. Marlin employs a game-theory-inspired utility function and online optimization algorithms to determine the best concurrency settings in real time. Evaluations showed that Marlin could match the throughput of state-of-the-art transfer solutions while significantly reducing system overhead. It also improved small file transfers by more than 2x when write I/O was the bottleneck, leveraging high-speed networks to move data into cache memory efficiently.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">Overall, the project&rsquo;s findings significantly advanced the state-of-the-art in data transfer optimization for research networks. By integrating machine learning, real-time monitoring, and adaptive optimization, the developed solutions not only improved network efficiency but also provided valuable tools for diagnosing and mitigating performance issues. The broader impact of this work extends to science and education communities by enabling faster, more reliable data transfers for large-scale scientific applications. Additionally, the project fostered educational opportunities through curriculum development, summer workshops for underrepresented groups, and hands-on research experiences for students. These contributions help bridge the gap between theoretical advancements and practical deployment, ensuring that research institutions can fully harness the potential of modern high-speed networks.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/18/2025<br>\nModified by: Engin&nbsp;Arslan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis peoject aimed to address critical performance bottlenecks in high-speed research networks. Despite continuous advancements in networking infrastructure, large-scale data transfers often suffer from inefficiencies due to the complexity of cyberinfrastructures, dynamically changing traffic, and unpredictable anomalies. This project developed novel machine learning models, real-time monitoring frameworks, and optimization algorithms to diagnose and enhance data transfer performance, ensuring that research institutions can effectively utilize their high-speed networks.\r\n\n\n\r\n\n\nOne of the key contributions of this project was the development of predictive models using deep neural networks to understand and optimize end-to-end data transfers. These models analyze transfer settings and predict achievable throughput under various conditions, enabling automatic tuning of parameters to maximize performance. Unlike conventional rule-based heuristics, which struggle to generalize across different network environments, the deep-learning-based approach dynamically adapts to changing conditions, improving transfer efficiency.\r\n\n\n\r\n\n\nAnother major outcome was the implementation of a real-time monitoring framework capable of detecting and diagnosing anomalies in wide-area file transfers. Lightweight monitoring agents were deployed on data transfer nodes to collect real-time performance metrics, which were then analyzed using machine learning and heuristic-based models. By identifying the root causes of performance degradationsuch as network congestion, hardware limitations, or suboptimal transfer configurationsthe framework provided actionable insights to system administrators. The monitoring system demonstrated the ability to track over 40,000 transfers across multiple nodes, ensuring scalability and high precision.\r\n\n\n\r\n\n\nTo mitigate performance bottlenecks, the project also introduced advanced online optimization techniques for data transfer tuning. A deep reinforcement learning-based approach utilizing Proximal Policy Optimization (PPO) was developed to optimize network bandwidth utilization. This adaptive algorithm dynamically adjusted parallel TCP streams to enhance throughput while preventing congestion and ensuring fairness among competing transfers. Compared to traditional optimization methods like gradient descent and Bayesian optimization, this approach identified near-optimal solutions 40% faster while achieving up to 15% higher throughput.\r\n\n\n\r\n\n\nFurthermore, the project designedMarlin, a modular file transfer architecture that decouples read, transfer, and write operations, allowing independent optimization of each component. Marlin employs a game-theory-inspired utility function and online optimization algorithms to determine the best concurrency settings in real time. Evaluations showed that Marlin could match the throughput of state-of-the-art transfer solutions while significantly reducing system overhead. It also improved small file transfers by more than 2x when write I/O was the bottleneck, leveraging high-speed networks to move data into cache memory efficiently.\r\n\n\n\r\n\n\nOverall, the projects findings significantly advanced the state-of-the-art in data transfer optimization for research networks. By integrating machine learning, real-time monitoring, and adaptive optimization, the developed solutions not only improved network efficiency but also provided valuable tools for diagnosing and mitigating performance issues. The broader impact of this work extends to science and education communities by enabling faster, more reliable data transfers for large-scale scientific applications. Additionally, the project fostered educational opportunities through curriculum development, summer workshops for underrepresented groups, and hands-on research experiences for students. These contributions help bridge the gap between theoretical advancements and practical deployment, ensuring that research institutions can fully harness the potential of modern high-speed networks.\r\n\n\n\t\t\t\t\tLast Modified: 03/18/2025\n\n\t\t\t\t\tSubmitted by: EnginArslan\n"
 }
}