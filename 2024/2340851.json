{
 "awd_id": "2340851",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Towards a Game Theory of Safe Human-Centered Robotics",
 "cfda_num": "47.041, 47.070",
 "org_code": "05020000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2024-08-01",
 "awd_exp_date": "2029-07-31",
 "tot_intn_awd_amt": 600000.0,
 "awd_amount": 475000.0,
 "awd_min_amd_letter_date": "2024-07-11",
 "awd_max_amd_letter_date": "2024-07-11",
 "awd_abstract_narration": "Future robotic systems promise to transform our homes, cities and roads, but they also raise critical questions about safety and reliability. What assurances should we, as a society, expect and demand from these new technologies? How can we tell an unfortunate accident from an unacceptable safety failure calling for a large-scale recall? From robotic caregivers to delivery drones and autonomous cars, robots' promise to society hinges on their ability to operate safely around people, yet current prototypes fall short of the safety assurances we all but take for granted in bridges, elevators, and airplanes. Unfortunately, traditional algorithms that once kept robots safe in factories now struggle with the complexity of the outside world, while machine learning approaches that thrive on big data are blindsided by safety-critical black swan events. This Faculty Early Career Development (CAREER) project aims to lay a new foundation for safe robot autonomy, enabling robots to continually prove that their course of action is safe with respect to any possible eventuality, however unlikely, out of a broad range of operating conditions (e.g., an autonomous car will avoid collisions even if a nearby cyclist suddenly falls into its path). These transparent, clear-cut guarantees will improve robots' reliability and facilitate regulatory oversight and public trust. To this end, the project's research activities are tightly interwoven with (i) a renewed robotics curriculum, from high school to graduate programs, preparing future generations of engineers to build safety into the core of robot autonomy, (ii) a series of workshops on Public Trust in Autonomous Systems spurring conversations about safety certification between industry and policy experts, and (iii) collaborations with key industry players equipped to mature and deploy the newly discovered techniques as well as to ensure the alignment of research progress with technological needs and regulatory standards. The project's outcomes will directly impact the domains of autonomous driving and mobile robots, and gained insights may be further extended beyond robotics to improve the safety of other AI technologies, boosting the ability of the United States and the international community to integrate intelligent systems safely and beneficially into society.\r\n\r\nThe project investigates the rapid onboard construction of safety-certified robot motion strategies in the face of complex physical dynamics, close interactions with people, extreme low-probability events, and limited sensing capabilities. The project's key technical insight is to bring these challenges under a unifying analytical framework grounded in dynamic game theory. The formalism seeks to ensure safety under all admissible realizations of the robot's uncertainty, hypothesizing a zero-sum game against the worst-case turn of events at each moment. Undue conservativeness is avoided through two mechanisms: an Operational Design Domain (ODD) that clearly delimits the conditions under which the robot must operate, as specified by designers or regulators; and a precise treatment of information structure, which captures the robot and other agents' ability to acquire and adapt to new information over time. Focusing on legged robot walking and dense urban driving, investigators will explore the use of deep adversarial reinforcement learning (compatible with raw sensory inputs, black-box perception and prediction modules, and up to hundreds of state variables) to tractably synthesize approximate solutions to safety games for ODDs allowing external forces, changing terrain and visibility conditions, and hazardous or misleading human behavior. The research team will further investigate real-time robust planning and control approaches to refine these \"untrusted\" learned solutions into verified motion strategies guaranteed to preserve safety against the space of ODD-allowed scenarios. By separating synthesis and verification, this methodology provides a scalable, systematic mechanism to construct ODD-certified safety filters that continually monitor robots' candidate actions and intervene when deemed necessary to preempt potential catastrophic failures. A crucial property of the resulting framework is that restricting the robot's computational resources would only result in a more conservative safety assessment, and therefore potentially degraded task performance, but never in a safety violation. The technical approach will be rigorously validated on legged robot hardware, autonomous driving datasets and simulators, and in-lab user studies to ensure its effectiveness and practical applicability to the deployment of safety-critical autonomous systems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jaime",
   "pi_last_name": "Fern\u00e1ndez Fisac",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jaime Fern\u00e1ndez Fisac",
   "pi_email_addr": "jfisac@princeton.edu",
   "nsf_id": "000838817",
   "pi_start_date": "2024-07-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "619 Alexander Road - Suite 102",
  "perf_city_name": "PRINCETON",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085406000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 475000.0
  }
 ],
 "por": null
}