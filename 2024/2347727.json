{
 "awd_id": "2347727",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ERI: SoundEYE: AI-Driven Sensory Augmentation System for Visually Impaired Individuals through Natural Sound",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032927328",
 "po_email": "harkim@nsf.gov",
 "po_sign_block_name": "Harrison Kim",
 "awd_eff_date": "2024-07-01",
 "awd_exp_date": "2026-06-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2024-04-30",
 "awd_max_amd_letter_date": "2024-04-30",
 "awd_abstract_narration": "The goal of this Engineering Research Initiation (ERI) project is to improve the independence, accessibility, and overall safety and well-being of visually impaired persons (VIPs) by developing an AI-based sensory augmentation system that can leverage the power of natural representative sound and technology. This research hypothesizes that using representable synchronous sound extracted from visual data will have a more significant impact on augmenting visual perception than usual auditory cues/captioning. This research will enhance spatial cognition and streamline navigation, increase personal freedom and empowerment, and ensure the well-being and health of visually impaired individuals. The project will address challenges related to analyzing complex scenes with multiple sound sources and generating representable synchronous sound through audio-visual synchronization with moving objects. This will provide content-wise relevant, augmented sound alerts of the most immediate events to users. This automatic generation of representable sound for critical situations will have a significant impact on VIPs to comprehend and deal with real-world events. Additional deliverables of this project will include engineering research experiences for students from a wide spectrum of backgrounds, including under-represented minority groups.\r\n\r\nThe research will develop a novel AI-driven sensory augmentation framework for human sensory augmentation that can leverage the potential of semantic representative sound and alleviate the limitation of considering subsequent motion changes in a visual scene. The design will incorporate visual-to-sound-synthesizing AI model design through an efficient visual action recognition approach, followed by a deep sound generative model facilitated by cloud-based continuous learning concepts. The project includes an empirical study to analyze the impact of natural sound over vocal auditory cues for the visually impaired person (VIP). This study will contribute to assessing the effect of natural auditory guidance on VIPs towards assisting them in understanding the layout of their surroundings and facilitating spatial orientation and mobility. Consequently, it will help analyze how interacting with objects/scenarios in the environment significantly enhances the independence, accessibility, and overall well-being of visually impaired people while using the aid. This research has broad societal impacts by establishing a path towards expanding multimodal AI research in multiple directions. The proposed framework can contribute to developing cyber-physical/IoT systems for human sensory augmentation using advanced AI techniques. The proposed visual-to-audio synthesis model has the potential to impact diverse applied fields, including cyber-physical system design in safety and security applications; multimodal signal processing and system integration in developing next-generation multimedia systems; and engineering AI systems development for enhanced-embedded battlefield intelligence with the necessary situational awareness.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanchita",
   "pi_last_name": "Ghose",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sanchita Ghose",
   "pi_email_addr": "sanchitaghose@sfsu.edu",
   "nsf_id": "000949116",
   "pi_start_date": "2024-04-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "San Francisco State University",
  "inst_street_address": "1600 HOLLOWAY AVE",
  "inst_street_address_2": "",
  "inst_city_name": "SAN FRANCISCO",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "4153387090",
  "inst_zip_code": "941321740",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "CA11",
  "org_lgl_bus_name": "SAN FRANCISCO STATE UNIVERSITY",
  "org_prnt_uei_num": "JW7YN4NDAHC1",
  "org_uei_num": "F4SLJ5WF59F6"
 },
 "perf_inst": {
  "perf_inst_name": "San Francisco State University",
  "perf_str_addr": "1600 HOLLOWAY AVE BUILDING NAD ROOM 358C",
  "perf_city_name": "SAN FRANCISCO",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "941321722",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "CA11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "072Y00",
   "pgm_ele_name": "EDSE-Engineering Design and Sy"
  },
  {
   "pgm_ele_code": "180Y00",
   "pgm_ele_name": "ERI-Eng. Research Initiation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "067E",
   "pgm_ref_txt": "DESIGN TOOLS"
  },
  {
   "pgm_ref_code": "068E",
   "pgm_ref_txt": "DESIGN THEORY"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9264",
   "pgm_ref_txt": "RESEARCH INITIATION AWARD"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": null
}