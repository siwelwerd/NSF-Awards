{
 "awd_id": "2344020",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps: Eye-Tracking System for Cognitive Abnormalities and Traumatic Brain Injuries",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922160",
 "po_email": "rshuman@nsf.gov",
 "po_sign_block_name": "Ruth Shuman",
 "awd_eff_date": "2023-11-15",
 "awd_exp_date": "2025-04-30",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2023-11-03",
 "awd_max_amd_letter_date": "2023-11-03",
 "awd_abstract_narration": "The broader impact/commercial potential of this I-Corps project is the development of eye tracking technology that enables remote assessment of brain injuries, cognitive and developmental conditions, and learning disabilities.  It is estimated that 50% of concussions go untreated or undiagnosed, which can have significant health consequences. The proposed technology and testing system may be utilized by patients at home on a regular basis or it may be used as a quick assessment on the sideline or in a training facility allowing the trainers or physicians to utilize data for quick decision making. For cases requiring an in-depth assessment, the proposed system also may be utilized to perform a battery of tests that capture the oculomotor eye response status of the patient. Then, a physician may analyze the data through a variety of visualizations and decide the appropriate treatment.  In addition, the system may be used for the delivery of remote therapy sessions for trauma and stress management (e.g., therapy based on bilateral stimulation), and would support delivering better care in rural and remote areas, as well as making patients more aware of conditions that can become more serious (e.g., repeat concussions).\r\n\r\nThis I-Corps project is based on the development of an application that uses webcam eye-tracking and machine learning algorithms to track facial features and the pupils more accurately for concussion and other assessments.  Initial validation tests have shown the proposed technology accurately tracks eye movements within 50 centimeters from the screen. To enhance the technology, a proprietary signal processing and optimization algorithm was developed to improve signal acquisition and enable \u201czero-shot\u201d detection of significant eye features at the point where the user is looking on the screen (gaze point). The acquisition component may be combined with a stimulation system to prompt oculomotor tasks and other tasks for the person being examined. Once data is acquired, either by the end user (e.g., patient, parent, or coach) or by a physician/technician, the information may be analyzed and visualized on the device (e.g., laptop or tablet) for immediate feedback, stored in a centralized system, or transmitted or shared with remote stakeholders (i.e., physicians or athletic trainers).  In addition, the proposed technology may be incorporated into most portable devices with built-in webcams such as laptops and tablets that users already possess or may be used alongside other concussion assessment tools and tools for online office visits performed by healthcare providers.  Data acquisition may be decoupled from data analysis, thus enabling end users (e.g., athletes or healthcare providers) to complete the assessment at home or on the sideline during a competition or practice.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nicholas",
   "pi_last_name": "Caporusso",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nicholas Caporusso",
   "pi_email_addr": "caporusson1@nku.edu",
   "nsf_id": "000943156",
   "pi_start_date": "2023-11-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gabriel",
   "pi_last_name": "Sanders",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Gabriel J Sanders",
   "pi_email_addr": "sandergj@ucmail.uc.edu",
   "nsf_id": "000943157",
   "pi_start_date": "2023-11-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northern Kentucky University",
  "inst_street_address": "NUNN DR",
  "inst_street_address_2": "",
  "inst_city_name": "NEWPORT",
  "inst_state_code": "KY",
  "inst_state_name": "Kentucky",
  "inst_phone_num": "8595725768",
  "inst_zip_code": "410990001",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "KY04",
  "org_lgl_bus_name": "NORTHERN KENTUCKY UNIV",
  "org_prnt_uei_num": "LN53C9E23GH6",
  "org_uei_num": "LN53C9E23GH6"
 },
 "perf_inst": {
  "perf_inst_name": "Northern Kentucky University",
  "perf_str_addr": "NUNN DR",
  "perf_city_name": "NEWPORT",
  "perf_st_code": "KY",
  "perf_st_name": "Kentucky",
  "perf_zip_code": "410990001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "KY04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "066E",
   "pgm_ref_txt": "INSTRUMENTATION & DIAGNOSTICS"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": null
}