{
 "awd_id": "2346790",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ERI: Exploring Visual-Haptic Synergy in Fragile Object Manipulation",
 "cfda_num": "47.041, 47.070",
 "org_code": "07030000",
 "po_phone": "7032922633",
 "po_email": "aleoness@nsf.gov",
 "po_sign_block_name": "Alex Leonessa",
 "awd_eff_date": "2024-09-01",
 "awd_exp_date": "2026-08-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2024-08-05",
 "awd_max_amd_letter_date": "2024-08-05",
 "awd_abstract_narration": "This Engineering Research Initiation (ERI) grant will support research that contributes new knowledge to robotic manipulation, addresses the current bottlenecks in manipulation reliability, improves work efficiency, enhances people's well-being, and consolidates the United States' leading position in robotics. Medical, agricultural, and household robots face a common challenge: the reliable and safe manipulation of fragile objects. Overcoming this bottleneck will enable significant advancements in the application of robotics in real-world environments. However, the variety of object properties and differences in manipulation tasks in the real world hinder the application of manipulation methods that are fully validated in laboratory environments. This award supports fundamental research to provide new knowledge for reliable object manipulation. This new knowledge will lead to the development of a technology that can automatically adapt to a variety of objects and manipulation goals by understanding the relationships between object properties, manipulation tasks, and robot operations. This technology will achieve breakthroughs in the safety, reliability, and efficiency of object manipulation in robotic surgery, agricultural robots, and household robots, directly benefiting the United States' medical, economic, and social fields. This research will also provide learning and research opportunities for students with disabilities, promoting balanced societal development and comprehensive engineering education.\r\n\r\nIntegrating vision and touch is considered the solution to the problem of manipulating deformable and fragile objects. Existing solutions directly integrate visual and tactile information to guide manipulation. Although simple in theory, these solutions tightly couple perception, modeling, and control issues, making it difficult to overcome the resolution differences of multimodal perception, solve the problem of sensor synchronization, and achieve universal applicability. This research project will work to establish an understanding of the complementary relationship between touch and vision and use novel deep causal learning techniques to decouple multimodal perception and the modeling of object properties. This approach will strive to realize a control method based on object properties that can simultaneously optimize the position, angle, speed, acceleration, and interaction force, thereby achieving reliable manipulation of deformable and fragile objects with wide applicability.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "YANGMING",
   "pi_last_name": "Lee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "YANGMING Lee",
   "pi_email_addr": "ymliee@rit.edu",
   "nsf_id": "000800270",
   "pi_start_date": "2024-08-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rochester Institute of Tech",
  "inst_street_address": "1 LOMB MEMORIAL DR",
  "inst_street_address_2": "",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5854757987",
  "inst_zip_code": "146235603",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "ROCHESTER INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "J6TWTRKC1X14"
 },
 "perf_inst": {
  "perf_inst_name": "Rochester Institute of Tech",
  "perf_str_addr": "1 LOMB MEMORIAL DR",
  "perf_city_name": "ROCHESTER",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146235603",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9264",
   "pgm_ref_txt": "RESEARCH INITIATION AWARD"
  },
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": null
}