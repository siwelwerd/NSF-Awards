{
 "awd_id": "2420352",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: TaskDCL: Collaborative Research: IMPACT: Interactive Mixed-Reality-Based Platform for AI-Driven Adaptive and Collaborative Task Training Environments",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032927557",
 "po_email": "amedinab@nsf.gov",
 "po_sign_block_name": "Alexandra Medina-Borja",
 "awd_eff_date": "2024-09-15",
 "awd_exp_date": "2026-08-31",
 "tot_intn_awd_amt": 149999.0,
 "awd_amount": 149999.0,
 "awd_min_amd_letter_date": "2024-08-07",
 "awd_max_amd_letter_date": "2024-08-07",
 "awd_abstract_narration": "Advanced AI-driven training platforms can revolutionize education, workforce development, and specialized training, such as emergency response preparation, by providing realistic, cost-effective, and interactive environments. Progress in this area has been hindered by the need for more affordable and adaptable platforms capable of creating realistic, real-time, closed-loop environments. This EArly-concept Grants for Exploratory Research (EAGER) project aims to develop research infrastructure to enhance human training through AI-driven task environments integrating humans with virtual scene simulations and multi-modal sensorimotor interactions, which holds significant societal benefits. By overcoming current technological limitations, AI-driven task environments can improve the quality and accessibility of training for various applications. The technology this award aims to develop has the potential to significantly reduce training costs, enhance learning experiences, and better prepare individuals for real-world challenges, ultimately benefiting society as a whole. Additionally, the project will introduce K-12 students to cutting-edge mixed reality and AI technologies, sparking their interest in STEM fields. \r\n\r\nThis research will first develop the platform for multi-modal sensorimotor interactions to ensure the best immersive and smooth interactions between humans and virtual scene simulations. It will then establish theoretical foundations and develop efficient algorithms for a closed-loop AI-driven scene task environment. In particular, the research will encompass three interdependent thrusts: 1)Establishing an edge-assisted mixed-reality infrastructure to provide immersive environments and enable smooth sensorimotor interactions between humans and virtual scene simulations. 2)Creating a wide range of training tasks and realistic sensorimotor interactions using flexible and composable modules. 3)Developing a multi-agent reinforcement learning engine to enable dynamic virtual scene generation and adaptation based on interactions. Collectively, this project will produce an immersive mixed-reality infrastructure that ensures smooth sensorimotor interactions, supports real-time task execution, and allows for the exploration of innovative multi-agent learning algorithms.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tian",
   "pi_last_name": "Lan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tian Lan",
   "pi_email_addr": "tlan@gwu.edu",
   "nsf_id": "000610915",
   "pi_start_date": "2024-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "George Washington University",
  "inst_street_address": "1918 F ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "WASHINGTON",
  "inst_state_code": "DC",
  "inst_state_name": "District of Columbia",
  "inst_phone_num": "2029940728",
  "inst_zip_code": "200520042",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DC00",
  "org_lgl_bus_name": "GEORGE WASHINGTON UNIVERSITY (THE)",
  "org_prnt_uei_num": "",
  "org_uei_num": "ECR5E2LU5BL6"
 },
 "perf_inst": {
  "perf_inst_name": "George Washington University",
  "perf_str_addr": "1918 F ST NW",
  "perf_city_name": "WASHINGTON",
  "perf_st_code": "DC",
  "perf_st_name": "District of Columbia",
  "perf_zip_code": "200520042",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DC00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "058Y00",
   "pgm_ele_name": "M3X - Mind, Machine, and Motor"
  },
  {
   "pgm_ele_code": "164200",
   "pgm_ele_name": "Special Initiatives"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7632",
   "pgm_ref_txt": "HUMAN-ROBOT INTERACTION"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 149999.0
  }
 ],
 "por": null
}