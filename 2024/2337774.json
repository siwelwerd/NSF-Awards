{
 "awd_id": "2337774",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER: Adaptive Multimodal Fusion for Robust Robot Perception in Underwater Environments",
 "cfda_num": "47.041, 47.070",
 "org_code": "07030000",
 "po_phone": "7032925365",
 "po_email": "jberg@nsf.gov",
 "po_sign_block_name": "Jordan Berg",
 "awd_eff_date": "2024-07-01",
 "awd_exp_date": "2029-06-30",
 "tot_intn_awd_amt": 599997.0,
 "awd_amount": 599997.0,
 "awd_min_amd_letter_date": "2024-05-08",
 "awd_max_amd_letter_date": "2024-05-08",
 "awd_abstract_narration": "This Faculty Early Career Development Program (CAREER) project will support research that attempts to provide new capabilities for marine robotic systems to map, visualize, and navigate underwater sites autonomously; that is, without the need for direct control by a human operator. This will  advance scientific knowledge, bolster maritime defense, and strengthen the economy. These new capabilities will be achieved using innovative machine learning methods to simultaneously capture the robot\u2019s surroundings and pinpoint the robot\u2019s location by combining acoustic and visual information. Project outcomes will be demonstrated for use in archaeology by mapping historically significant shipwreck sites. The results will also apply to tasks such as underwater construction, infrastructure maintenance, and emergency response. The underwater environment is a challenging workplace for robots and humans. Most electromagnetic radiation is absorbed or scattered over short distances, precluding reliance on satellite navigation signals or ambient illumination. Other effects due to water movement or variable transmission properties can further distort interpretation of sensor measurements. Because different types of signals respond differently to these effects, the fusion of diverse imaging modes such as light and sound offers the promise of improved mapping and localization error, while also reducing the amount of data required. Reducing or eliminating the need for a human pilot allows allocation of human expertise to higher-value tasks. This project will develop virtual resources for K-12 education, university curricula, and public outreach platforms, making marine robotics research and education accessible to a broader population. Software and datasets developed throughout this work will be published to foster innovation in robotics for ocean exploration.\r\n\r\nMarine environments pose unique challenges to robot perception due to the complex nature of underwater sensing across multiple modalities. Imagery collected with cameras provides high resolution observations at close range but can be highly degraded due to the effects of underwater light propagation. This results in loss of information about the scene, especially at longer ranges. Sonar can provide long-range sensing capabilities but has low resolution and viewpoint-dependent appearance. While acoustic and visual sensors appear complementary, multi-sensor fusion is non-trivial due to the differences in geometry and appearance across these modalities. This research project investigates implicit neural representations for multimodal fusion of underwater imagery and acoustic data. This project will contribute new knowledge in adaptive multimodal fusion and uncertainty estimation for deep learning to leverage the learned implicit neural representations for real-time simultaneous localization and mapping (SLAM). The developed methods will be demonstrated in real underwater environments through the task of autonomous real-time dense mapping of shipwreck sites in Thunder Bay National Marine Sanctuary. This work will be broadly applicable to survey and inspection of complex marine structures beyond shipwrecks, including offshore energy infrastructure, pipelines, and underwater caves. Knowledge developed through this project will be transferable to mobile robots operating in challenging terrestrial environments, such as in poor weather conditions or GPS-denied environments.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Katherine",
   "pi_last_name": "Skinner",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Katherine A Skinner",
   "pi_email_addr": "kskin@umich.edu",
   "nsf_id": "000709277",
   "pi_start_date": "2024-05-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "Regents of the University of Michigan - Ann Arbor",
  "perf_str_addr": "1109 GEDDES AVE, SUITE 3300",
  "perf_city_name": "ANN ARBOR",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091079",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  },
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 599997.0
  }
 ],
 "por": null
}