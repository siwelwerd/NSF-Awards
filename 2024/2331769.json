{
 "awd_id": "2331769",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: RI: Small: Shape Configuration Learning and Its Applications",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2024-09-01",
 "awd_exp_date": "2027-08-31",
 "tot_intn_awd_amt": 299964.0,
 "awd_amount": 299964.0,
 "awd_min_amd_letter_date": "2024-08-21",
 "awd_max_amd_letter_date": "2024-08-21",
 "awd_abstract_narration": "This project aims to enhance how computers understand and recognize shapes in images and 3D data. While current advanced computer systems are powerful, they struggle to perceive objects as humans do\u2014as whole shapes made up of interconnected parts. This project seeks to teach computers to focus on the critical parts of an image that constitute an object, disregarding the background and other distractions. The project is also developing methods for computers to comprehend the relationships between different parts of an object, akin to recognizing a chair by identifying its seat, legs, and back in a specific arrangement. This will be achieved within recent deep learning frameworks without explicitly referencing such parts. The improved visual perception capabilities could help computers better to perform tasks like object recognition, 3D position estimation, and understanding shapes from various viewpoints. The potential applications of this research are vast, including advancements in medical imaging, dental radiology, augmented reality, assisted driving technologies, and robotics. Additionally, the project will involve students from high school to doctoral programs in research, with a focus on including underrepresented groups.\r\n\r\nThe project creates a framework for deep learning models to learn configural (or holistic) shape representation and arrangements of object parts, demonstrating their applicability to various computer vision tasks. It will augment the learning framework of vision transformers to learn how to restrict the attention of image patches. This is achieved by adding a new branch that computes an auxiliary loss called object-focused attention, which limits the attention to patches belonging to the same object. This allows transformers to gain a better understanding of configural object shapes by largely ignoring the background and other objects. Additionally, the project will develop a novel graph-transformer-based shape configuration framework named ShapeGT for generic shape understanding tasks. ShapeGT will include several new techniques and applications, including (1) novel between-edge attention and edge-to-node attention modules, (2) joint graph learning and matching algorithms, (3) view encoding techniques for multi-view analysis, and (4) cross-modal fusion mechanisms for capturing 3D-to-2D (shape-to-image) interactions. Due to the wide range of applications of shape analysis, the project is expected to have broader impacts on fields beyond computer vision, such as dental maxillofacial radiology, augmented reality, molecular biology, assistive driving, medical image analysis, and robotics.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Haibin",
   "pi_last_name": "Ling",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Haibin Ling",
   "pi_email_addr": "hling@cs.stonybrook.edu",
   "nsf_id": "000516498",
   "pi_start_date": "2024-08-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "perf_city_name": "STONY BROOK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117940001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 299964.0
  }
 ],
 "por": null
}