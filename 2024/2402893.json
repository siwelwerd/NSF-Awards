{
 "awd_id": "2402893",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: HCC: Medium: Untethered3D: In-Air 3D Modeling Using Non-Visual Feedback",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922170",
 "po_email": "tmartin@nsf.gov",
 "po_sign_block_name": "Thomas Martin",
 "awd_eff_date": "2024-10-01",
 "awd_exp_date": "2028-09-30",
 "tot_intn_awd_amt": 719999.0,
 "awd_amount": 719999.0,
 "awd_min_amd_letter_date": "2024-08-18",
 "awd_max_amd_letter_date": "2024-08-18",
 "awd_abstract_narration": "In this context of virtual reality, creating, perceiving, and editing three-dimensional (3D) shapes are at the core of activities such as product design (creating or evaluating objects for manufacturing or personal fabrication), online shopping (experiencing furniture in a room or trying on clothing), and specialized training (gaining familiarity with a remote tool). Yet, today's approaches for interacting with virtual 3D shapes are strictly visual, requiring precise manipulation and interpretation of digital designs on a screen. This project's goal is to create algorithms and interfaces that make 3D modeling easier and more effective, even in the absence of visual cues: auto-correct for 3D drawing, the ability to hear shapes, and the ability to edit 3D shapes verbally. By using senses that do not require a screen\u2014body awareness and sound\u2014this project aims to untether people from their screens, enabling virtual 3D perception from anywhere. The outcomes of this project are expected to have far-reaching impacts, including increased accessibility for people with visual impairments, enhanced interface techniques for low-visibility scenarios, and new opportunities for underrepresented groups in research and do-it-yourself fabrication.\r\n\r\nThe research focuses on three main objectives: developing accurate \u201cin-air\u201d 3D drawing tools, designing sonification (conveying information through sound) techniques for non-visual shape perception and editing, and creating verbal 3D shape editing tools and interactions. These aims will be pursued through auto-correct algorithms that account for the limits of proprioceptive (a person\u2019s sense of their body pose and movement) accuracy, techniques to sonify shapes based on hand pose, and methods for verbal shape modification. This research sets the stage for future studies on incorporating sound and speech into 3D modeling, as well as non-visual user interfaces.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yotam",
   "pi_last_name": "Gingold",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yotam Gingold",
   "pi_email_addr": "ygingold@gmu.edu",
   "nsf_id": "000636938",
   "pi_start_date": "2024-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "George Mason University",
  "inst_street_address": "4400 UNIVERSITY DR",
  "inst_street_address_2": "",
  "inst_city_name": "FAIRFAX",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "7039932295",
  "inst_zip_code": "220304422",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "VA11",
  "org_lgl_bus_name": "GEORGE MASON UNIVERSITY",
  "org_prnt_uei_num": "H4NRWLFCDF43",
  "org_uei_num": "EADLFP7Z72E5"
 },
 "perf_inst": {
  "perf_inst_name": "George Mason University",
  "perf_str_addr": "4400 UNIVERSITY DR",
  "perf_city_name": "FAIRFAX",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "220304422",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "VA11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 719999.0
  }
 ],
 "por": null
}