{
 "awd_id": "2339071",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Career: Learning Multimodal Representations of the Physical World",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2024-03-01",
 "awd_exp_date": "2029-02-28",
 "tot_intn_awd_amt": 599778.0,
 "awd_amount": 259770.0,
 "awd_min_amd_letter_date": "2024-02-29",
 "awd_max_amd_letter_date": "2025-02-05",
 "awd_abstract_narration": "Touch and hearing convey physical properties about the world that are difficult to perceive from vision alone. The objective of this project is to give machine perception systems the ability to form cross-modal associations between these three sensory modalities, such as the ability to predict how an object will feel or sound from sight. These cross-modal associations can also be obtained directly via sensors, making them well-suited to creating autonomous systems that learn to physically interact with the world without human-provided supervision. The project's integrated education and outreach activities will also advance an understanding of multimodal machine learning for a general audience, and for students at multiple levels.\r\n\r\nThis project aims to learn material properties and microgeometry through cross-modal associations between sight, sound, and touch. It does this through four research thrusts. First, it aims to capture 3D multimodal representations by registering observations from all modalities into a unified 3D model, using estimated visual geometry to obtain dense estimates of touch and sound from sparse observations. Second, it aims to generate space-time reconstructions of objects from touch and sound during physical interaction, using cross-modal visual supervision. Third, it aims to learn material representations that capture acoustic properties, as well as methods that integrate these representations into 3D sound synthesis models. Finally, it aims to simulate and learn physical interactions within captured 3D multimodal scenes.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Andrew",
   "pi_last_name": "Owens",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Andrew H Owens",
   "pi_email_addr": "ahowens@umich.edu",
   "nsf_id": "000843360",
   "pi_start_date": "2024-02-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "Regents of the University of Michigan - Ann Arbor",
  "perf_str_addr": "1301 Beal Avenue",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092122",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002728DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002829DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 122432.0
  },
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 137338.0
  }
 ],
 "por": null
}