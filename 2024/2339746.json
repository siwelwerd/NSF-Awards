{
 "awd_id": "2339746",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Robust, Fair, and Culturally Aware Commonsense Reasoning in Natural Language",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922972",
 "po_email": "emiltsak@nsf.gov",
 "po_sign_block_name": "Eleni Miltsakaki",
 "awd_eff_date": "2024-05-01",
 "awd_exp_date": "2029-04-30",
 "tot_intn_awd_amt": 598932.0,
 "awd_amount": 120752.0,
 "awd_min_amd_letter_date": "2024-04-09",
 "awd_max_amd_letter_date": "2024-04-09",
 "awd_abstract_narration": "Recent advances in artificial intelligence have led to the proliferation of Large Language Models (LLMs). LLMs are models that cane be used for interactions with human users through written language; for example, a user inputs an instruction or question in English to the LLM-based program, and the LLM outputs a response in fluent English. With these linguistic capabilities, LLMs are being developed for use in applications that are both ubiquitous (e.g., internet search, customer support, writing tools) and high-stakes (e.g., mental health care, classroom education, assistive technology for people with disabilities). Despite their growing adoption, many fundamental properties of LLMs aren\u2019t yet well understood, and pressing questions remain about when and whether LLMs can be entrusted with such important tasks. For example, when instructed to make simple predictions about every-day situations, like cooking a meal or riding in a vehicle, LLMs can make strange and surprising errors, exhibiting concerning lapses in basic common sense judgment and reasoning abilities. Additionally, these predictions made by LLMs can reflect social stereotypes and cultural assumptions which, at best, limit the usefulness of the technology for certain populations and, at worst, cause active harm. This project seeks to address unfairness and bias due to stereotyping and cultural context by proposing a generalized framework for defeasible commonsense inference in natural language in which a system compares two similar situations with respect to their support for a given inference. The proposed work aims at developing scientific methods to measure and improve the abilities of LLMs to (1) reason correctly about every-day situations, (2) do so in a manner that is fair and unprejudiced, and (3) adapt these reasoning abilities across specific cultural contexts. By measuring these fundamental capabilities of LLMs, we can better understand and mitigate the risks of applying this technology in high-stakes settings.\r\n\r\nThe three phases of the project focus on the (1) robustness, (2) social fairness, and (3) cultural awareness dimensions of reasoning in LLMs. The project assumes a basic task formulation in which a situation description is provided to an LLM (e.g., \u201cSomeone drops a glass\u201d), and the LLM must either evaluate a possible inference, or generate an inference from scratch (\u201cThe glass breaks\u201d). In phase 1, methods will be developed to automatically manipulate situation descriptions in order to train and evaluate an LLM\u2019s ability to make nuanced inferences, with the goal of learning to distinguish which factors influence a particular inference and which ones do not (e.g., when trying to predict if a dropped glass is going to break, the thickness of the glass matters but the color of the glass does not.) In phase 2, methods will be developed to automatically test whether LLMs make socially fair inferences, for example via name substitution tests, and to intervene when a proposed output is detected as unfair. In phase 3, survey participants from the U.S. and Ghana will answer multiple stages of questions about every-day situations; the collected data will be used to develop evaluation questions for a case study on the adaptability of LLMs across these two cultural settings. For each phase of the project, the resulting datasets, methods, and scientific findings will be made available to the public.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rachel",
   "pi_last_name": "Rudinger",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rachel Rudinger",
   "pi_email_addr": "rudinger@umd.edu",
   "nsf_id": "000830991",
   "pi_start_date": "2024-04-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland, College Park",
  "perf_str_addr": "3112 LEE BLDG 7809 REGENTS DR",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425103",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002728DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002829DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 120752.0
  }
 ],
 "por": null
}