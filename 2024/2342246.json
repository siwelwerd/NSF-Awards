{
 "awd_id": "2342246",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NeRD: Neural Representations for Dexterity",
 "cfda_num": "47.041, 47.070",
 "org_code": "05020000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2024-04-15",
 "awd_exp_date": "2027-03-31",
 "tot_intn_awd_amt": 945193.0,
 "awd_amount": 945193.0,
 "awd_min_amd_letter_date": "2024-04-25",
 "awd_max_amd_letter_date": "2024-04-25",
 "awd_abstract_narration": "Grasping and using objects and tools is a remarkable skill that humans possess, but it remains a challenge to replicate this ability in robotic hands. Achieving such a capability in robots would have a profound impact on autonomous robotic manipulation, revolutionizing various fields like domestic services, manufacturing, and logistics. This project has the potential to advance national prosperity and welfare by enabling robots to perform intricate object manipulation using multi-fingered hands. To reach this objective, this project identified as a core challenge the design of an appropriate interface between robot's sight sense and control of the hand. This interface is riddled by uncertainty because information that can be extracted from cameras through which the robot observes the environment is not precise and incomplete. Most existing approaches to robot manipulation with multifingered hands oversimplify this interface, often relying on perfect simulation or demonstrating limited tasks on real robotic hardware that often appear brittle. In contrast, proposed research supported by this award will look to develop a novel concept for robot manipulation, that captures both object shape and appearance. By integrating both types of information, novel method that is intended to be developed, can be used for keeping track of objects, inferring manipulation strategies, and accounting for uncertainty - all at the same time. The project\u2019s novelties are in the algorithms for dexterous manipulation. Because it aims to enable complex manipulation skills such as tool use, assembly, object inspection or dense packing, this project\u2019s impacts are to improve domestic services, manufacturing and logistics, as well as to develop courses on robotics, and provide immersive and engaging programming activities for K-12 students. \r\n\r\n\r\nThe primary objective of this research project is to develop a novel approach for robotic dexterous manipulation that leverages the powerful new object representation of Neural Radiance Fields (NeRFs). NeRFs have recently emerged as a new representation of photorealistic 3D scenes constructed from RGB images alone. NeRFs are able to render synthetic photorealistic RGB images of the scene from camera view points not previously seen in the data. The core hypothesis is that not only appearance, but also full object shape is accurately encoded in the NeRF representation despite not being explicitly labeled in the training images. Therefore, NeRFs can provide the basis for novel grasping and manipulation algorithms that operate on unlabelled images alone, without requiring accurate object mesh models. The challenge is that this representation is nontraditional, as it represents the object as a volumetric density field without a distinct object \"surface,\" and therefore does not immediately lend itself to use with current grasping and manipulation algorithms. In this project, it is intended that fundamentally different ways of formalizing grasping and manipulation can be utilized by manipulation robots. Furthermore, it is hypothesized that the NeRF density output in fact reflects a measure of uncertainty about the location of the true object surface. A sharp density transition indicates high confidence in the surface location, while a gradual transition indicates low certainty about the surface location. Therefore, developed grasping and manipulation algorithms will aim for robustness with respect to this measure of surface uncertainty. Robustness to object shape and pose uncertainty is essential for precision robot manipulation in the wild, and is largely unsolved. Ultimately, using the NeRF as an object representation, it is intended that an algorithmic pipeline to go from pixels to grasp to manipulation trajectory will be developed and validated in the hardware.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeannette",
   "pi_last_name": "Bohg",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jeannette Bohg",
   "pi_email_addr": "bohg@stanford.edu",
   "nsf_id": "000783547",
   "pi_start_date": "2024-04-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mac",
   "pi_last_name": "Schwager",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mac Schwager",
   "pi_email_addr": "schwager@stanford.edu",
   "nsf_id": "000609509",
   "pi_start_date": "2024-04-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "353 Serra Mall",
  "perf_city_name": "STANFORD",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943052004",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 945193.0
  }
 ],
 "por": null
}