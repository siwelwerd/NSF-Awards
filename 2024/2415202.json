{
 "awd_id": "2415202",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: NSF-MeitY: CSR: Small: Eco-LLM: Energy-Efficient Computation and Communication for Large Language Models with  CXL-based Chip Architecture and Software",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2024-10-01",
 "awd_exp_date": "2027-09-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2024-08-26",
 "awd_max_amd_letter_date": "2024-08-26",
 "awd_abstract_narration": "Although crucial for advanced Artificial Intelligence (AI) applications due to their language understanding and generation capabilities, Large Language Models (LLMs) are energy intensive. This project\u2019s goals and novelty are to enhance the efficiency of training and inference associated with LLMs by leveraging emerging high-speed networks and computing architecture. The project\u2019s broader significance and importance are to (1) enable a broad range of LLMs to efficiently operate, advancing AI applications at a low energy cost; (2) strengthen international research collaboration between U.S. and India researchers; and (3) provide educational opportunities for graduate students.\r\n\r\nThis project addresses the energy efficiency challenges of LLMs by optimizing their energy consumption in heterogeneous Compute Express Link (CXL)-enabled hardware environments. By leveraging High-Performance Computing (HPC) middleware and the high-bandwidth, low-latency features of CXL, the project aims to ensure sustainable and efficient AI operations. This project seeks to find solutions to the following set of fundamental issues in training and using LLMs at scale: 1) identifying and characterizing idleness in the LLM workloads; 2) using the knowledge of long idleness to insert low-overhead Dynamic Voltage and Frequency Scaling (DVFS) control and undervolting to save static energy consumption; 3) designing CXL-aware and energy-efficient Message Passing Interface (MPI)-based communication runtime for LLM training and inferencing; and 4) studying the overall impact of the integrated systems on the energy consumption of LLM training and inference. The results are disseminated to collaborating organizations to impact their HPC/AI software applications and hardware chip designs, promoting broader societal advancement through improved technological capabilities.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Laxmi",
   "pi_last_name": "Bhuyan",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Laxmi N Bhuyan",
   "pi_email_addr": "bhuyan@cs.ucr.edu",
   "nsf_id": "000318919",
   "pi_start_date": "2024-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Riverside",
  "inst_street_address": "200 UNIVERSTY OFC BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "RIVERSIDE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9518275535",
  "inst_zip_code": "925210001",
  "inst_country_name": "United States",
  "cong_dist_code": "39",
  "st_cong_dist_code": "CA39",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA AT RIVERSIDE",
  "org_prnt_uei_num": "",
  "org_uei_num": "MR5QC5FCAVH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Riverside",
  "perf_str_addr": "200 UNIVERSTY OFC BUILDING",
  "perf_city_name": "RIVERSIDE",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "925210001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "39",
  "perf_st_cong_dist": "CA39",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "120Z",
   "pgm_ref_txt": "US-India Collaborative Research"
  },
  {
   "pgm_ref_code": "6194",
   "pgm_ref_txt": "INDIA"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": null
}