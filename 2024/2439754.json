{
 "awd_id": "2439754",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: EAGER: End-to-end Neural Training for Very Large Output Spaces",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927978",
 "po_email": "racharya@nsf.gov",
 "po_sign_block_name": "Raj Acharya",
 "awd_eff_date": "2024-08-15",
 "awd_exp_date": "2026-07-31",
 "tot_intn_awd_amt": 75000.0,
 "awd_amount": 75000.0,
 "awd_min_amd_letter_date": "2024-08-19",
 "awd_max_amd_letter_date": "2024-08-19",
 "awd_abstract_narration": "Modern machine learning models often need to make predictions with an enormous amount of choices. For example, on the internet, search engines need to predict the most relevant candidate for a given query from billions of potential candidates. There are similar prediction problems that are ubiquitous in many search, retrieval and recommendation systems in our daily lives. It is challenging for a machine learning algorithm to deal with a large output space in both the training and inference phases, as any linear scan through all candidates is computationally prohibitive.  This project aims to develop a family of scalable and reliable algorithms to tackle the problem of predicting in a large output space. To develop an end-to-end solution, we will tackle the problem of designing novel architectures, and accompanying training and inference procedures that jointly optimize inference speed and prediction accuracy. These efforts will eventually produce a comprehensive toolkit for learning with large output spaces, thus enabling its application in both practical systems and future research activities. The project will also support students and train them in conducting research activities in collaboration with application domains.\r\n\r\nExisting approaches for dealing with a large output space split the prediction task into two separate components: a neural network encoder and an approximate nearest neighbor search module. The neural network encoder encodes queries and items into a latent space, while the nearest neighbor search module finds the closest vectors in the database for a given query vector. This two-stage approach simplifies the development of each module, but this splitting of components is not focused on end-to-end prediction performance, and thus compromises accuracy and efficiency.  The core challenging technical direction of this project is to create algorithms that allow the two components to be aware of each other and thus develop an end-to-end model and training algorithm to handle very large output space.  This research direction will be addressed through the development of a novel end-to-end neural network architecture that contains both encoders and trainable search modules. The end-to-end training process will enable direct optimization for precision and efficiency in a single step, instead of requiring two separate steps.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Inderjit",
   "pi_last_name": "Dhillon",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Inderjit S Dhillon",
   "pi_email_addr": "inderjit@cs.utexas.edu",
   "nsf_id": "000200521",
   "pi_start_date": "2024-08-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "110 INNER CAMPUS DR",
  "perf_city_name": "AUSTIN",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121139",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 75000.0
  }
 ],
 "por": null
}