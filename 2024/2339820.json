{
 "awd_id": "2339820",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "HCC: CAREER: Foundational Interaction Research for Manipulating Drones",
 "cfda_num": "47.070, 47.083",
 "org_code": "05020000",
 "po_phone": "7032924420",
 "po_email": "cbethel@nsf.gov",
 "po_sign_block_name": "Cindy Bethel",
 "awd_eff_date": "2024-07-01",
 "awd_exp_date": "2029-06-30",
 "tot_intn_awd_amt": 585389.0,
 "awd_amount": 339358.0,
 "awd_min_amd_letter_date": "2024-07-11",
 "awd_max_amd_letter_date": "2024-07-11",
 "awd_abstract_narration": "Small uninhabited aerial vehicles (UAVs) have become a part of everyday human activities like farming, sports, and zoon management. These UAVs have offered new ways to see the world, but looking is not enough for people; they need to see and touch things to fully understand them. This project will explore new ways for people to work safely and effectively with small UAVs. They will work to touch or interact with objects in dynamic environments. This project will feature a novel UAV. It will adapt using diverse human viewpoints to improve the precision of human-object interaction. There are two primary challenges in doing this. First, the preferred perspective for a person may not be the best perspective for UAV performance. Second, humans need specific viewpoints to do tactile tasks . The intersection of these challenges will result in guidelines for future UAVs to work with people to let them explore new environments. The design of the educational and outreach components will inspire and cultivate a new generation of human-robot interaction experts. \r\n\r\nThis project will fix problems between humans and small uninhabited aerial vehicles (UAVs). These problems occur when small UAVs manipulate objects. The solution will include corrective approaches and interaction guidelines using visual perceptions. This work explores two main ideas. First, making the robot easier for users to understand through perceptible changes. Second, ensuring safety and efficiency. Interaction methods will adapt to fit the platform, users, and environment. The research goals of this project are: (1) to create a new computational framework. It will enable a shared visual interface between a  small UAV and a human user. This will let the human and UAV share the same knowledge for tasks. (2) to develop a computational method. It will use synthetic visual data to get knowledge from human multi-modal inputs. These inputs have the abilities needed for manipulating real objects with UAVs. (3) to integrate the first two goals. This will improve the ability of the user and UAV to work together to manipulate objects. There will be a complete evaluation plan to support the three study aims. It will include formative assessments and continuous evaluation. This research will create new human-robot data sets. It will also produce technical knowledge and educational outcomes. It will do this by advancing the manipulation of physical objects by UAVs.\r\n\r\nThis project is jointly funded by the Computer and Information Science and Engineering Directorate (CISE), Division of Information and Intelligent Systems (IIS), Human-Centered Computing cluster (CISE/IIS/HCC) and the Established Program to Stimulate Competitive Research (EPSCoR).\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Joshua",
   "pi_last_name": "Peschel",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Joshua M Peschel",
   "pi_email_addr": "peschel@iastate.edu",
   "nsf_id": "000738382",
   "pi_start_date": "2024-07-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Iowa State University",
  "inst_street_address": "1350 BEARDSHEAR HALL",
  "inst_street_address_2": "515 MORRILL ROAD",
  "inst_city_name": "AMES",
  "inst_state_code": "IA",
  "inst_state_name": "Iowa",
  "inst_phone_num": "5152945225",
  "inst_zip_code": "500112103",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IA04",
  "org_lgl_bus_name": "IOWA STATE UNIVERSITY OF SCIENCE AND TECHNOLOGY",
  "org_prnt_uei_num": "DQDBM7FGJPC5",
  "org_uei_num": "DQDBM7FGJPC5"
 },
 "perf_inst": {
  "perf_inst_name": "Iowa State University",
  "perf_str_addr": "515 MORRILL RD, 1350 BEARDSHEAR HALL",
  "perf_city_name": "AMES",
  "perf_st_code": "IA",
  "perf_st_name": "Iowa",
  "perf_zip_code": "500112105",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002728DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002829DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 339358.0
  }
 ],
 "por": null
}