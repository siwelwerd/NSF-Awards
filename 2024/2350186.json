{
 "awd_id": "2350186",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Boosting Reasoning in Boolean Networks with Attributed Graph Learning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2023-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 381707.0,
 "awd_amount": 166740.0,
 "awd_min_amd_letter_date": "2024-02-06",
 "awd_max_amd_letter_date": "2024-02-06",
 "awd_abstract_narration": "Boolean networks, mostly represented as graphs, have emerged as an effective logical representation to model not only the computational processes but also several phenomena from science and engineering, such as genetic analysis, electronic design automation, formal verification, etc. However, Boolean networks used in modern science and engineering applications can be extremely large with complex structures, which makes them less practical for real-world applications.  For example, Boolean networks for optimizing logic circuits can have billions of vertices and cannot be effectively handled using traditional algorithms. Recent years have seen a widespread application of machine-learning (ML) techniques to various problems over graphs, namely graph learning, which has been successfully applied to accelerate applications by exploiting graph features found in social-network prediction and drug analysis. This project aims to develop a systematic framework that leverages graph learning to reason about Boolean networks, including dataset design, learning-algorithm development, training models, system integration, and evaluation over various application domains. The framework will be implemented in an extensible platform that can be used for a variety of applications in science and engineering. This project will create unique education and outreach opportunities for both academic and industrial participants, which involve mentoring of graduate and undergraduate students, innovation in teaching with investigator\u2019s new courses in electronic design and deep learning, and attracting and preparing high-quality researchers with diverse backgrounds.\r\n\r\nThe team of researchers will develop a set of novel algorithms in graph fusion, graph coarsening and refinement, and graph neural networks, to achieve high-quality and scalable embeddings for reasoning about functional, high-level abstractions of billion-node Boolean networks. The methods in this project will sit between the classical symbolic techniques in formal methods and ML in order to benefit both research communities in many domains, such as verification and synthesis, bioinformatics, artificial intelligence, and security. Specifically, the investigator plans to leverage and advance ML in symbolic-reasoning tasks, such that it can perform truly scalable Boolean reasoning analogously to traditional symbolic-reasoning approaches. The developments of this project will focus on novel algorithms in graph fusion and neural network architectures, domain-specific compression algorithms, end-to-end system integration, and large-scale system-level parallelism. In addition, the framework will be evaluated in algorithmic design-space exploration, targeting Boolean satisfiability solving and Boolean optimization.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cunxi",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cunxi Yu",
   "pi_email_addr": "cunxiyu@umd.edu",
   "nsf_id": "000815565",
   "pi_start_date": "2024-02-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland, College Park",
  "perf_str_addr": "3112 LEE BLDG 7809 REGENTS DR",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 166740.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>As the complexity of modern hardware systems grows, achieving fast and effective hardware exploration has become increasingly challenging due to limitations in existing electronic design automation (EDA) toolflows. Recent years have seen a surge in the application of machine learning (ML) techniques in EDA to reduce manual effort and accelerate the design closure process. Many EDA problems, such as Boolean optimization, physical design, and high-level synthesis, are combinatorial optimization tasks represented on graph-based data structures, which are unlikely to be solvable by polynomial-time algorithms. With modern logic designs comprising millions, or even billions, of logic gates, these problems present significant challenges.</p>\n<p>In practice, these challenges are addressed using scalable optimization algorithms that rely on approximations and domain-specific heuristics, developed through extensive engineering efforts and deep domain expertise. This project explored the potential of graph learning and graph neural networks (GNNs) in representing and optimizing Boolean circuits in EDA, focusing on the functional and structural properties of these circuits. Our efforts included theoretical studies on graph embeddings concerning functional and structural information, integrated design optimization and reasoning, and the development of an open-source, generic graph learning framework for hardware design.</p>\n<p><strong>Main Outcomes:</strong></p>\n<p><strong>Enhanced Functional Awareness in Circuit Graph Learning</strong>: Reasoning about high-level abstractions in Boolean networks, such as gate-level netlists, provides substantial benefits for functional verification, logic minimization, datapath synthesis, and malicious logic identification. However, conventional reasoning approaches rely heavily on structural hashing and functional propagation, which are limited in scalability and inefficiently use modern computing power. In the era of global and democratized integrated circuit (IC) development, scalable reasoning methods offer significant benefits for hardware optimization and security.&nbsp;</p>\n<p><strong>Importance of Infrastructure and Data Preparation Support</strong>: While the proposed Boolean circuit graph learning methods have demonstrated strong capabilities in understanding complex relationships, there is a notable lack of infrastructure for preparing hardware datasets&mdash;particularly for graph representations of RTL (Register-Transfer Level) designs. Two key challenges exist: (1) the absence of a comprehensive infrastructure that connects RTL designs with graph representations to facilitate dataset construction and integration with existing frameworks, such as PyTorch Geometric (PyG), and (2) the need for more design variations to train RTL foundation models effectively. In response, this project introduced an open-source infrastructure compatible with major graph learning frameworks, increasing the number of RTL design examples through functionally equivalent RTL augmentations.</p>\n<p><strong>Hardware Design Augmentation</strong>: Circuit design representation augmentation is essential for learning-based optimization and analysis. Unlike image augmentation, where transformations preserve semantic meaning, augmenting digital hardware systems presents unique challenges to ensure that circuit functionality remains intact. We identified that the primary challenge in circuit design augmentation is maintaining logical behavior during transformations, essential for model validity. To address this, we explored and demonstrated the potential of synthesis techniques from academic and industry sources to perform effective data augmentation within the hardware domain, ensuring that augmented circuit representations are functionally equivalent to their originals.</p>\n<p>&nbsp;</p>\n<p>This project has advanced ML for EDA, particularly using graph learning techniques and hardware optimization, creating significant research and educational impacts. The development of open-source tools like Verilog-to-PyG (V2PYG) and GAMORA has drawn interest from industry leaders such as NVIDIA Research, demonstrating the project's potential to shape future EDA practices. These tools provide foundational resources for researchers studying Boolean circuit optimization, making cutting-edge methodologies more accessible. These tools provide foundational resources for researchers working on Boolean circuit optimization, making advanced methodologies more accessible. The project has supported a diverse group of students, including female PhD and undergraduate students and an LGBT PhD student, fostering an inclusive learning environment and encouraging further study. Notably, one undergraduate student published two papers in top EDA venues, was recognized as a DAC Young Fellow, and later joined MIT for PhD studies. Research outcomes have been integrated into courses, enhancing student learning through new modules on RL in optimizations and advanced EDA techniques. The project's collaborations and open-source contributions promise lasting impacts on the field, driving innovation in hardware design and optimization while preparing the next generation of leaders in computer science.</p><br>\n<p>\n Last Modified: 10/31/2024<br>\nModified by: Cunxi&nbsp;Yu</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2350186/2350186_10675067_1730401445059_Screenshot_2024_10_31_at_2.59.19__8239_PM--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2350186/2350186_10675067_1730401445059_Screenshot_2024_10_31_at_2.59.19__8239_PM--rgov-800width.png\" title=\"Verilog-to-PYG\"><img src=\"/por/images/Reports/POR/2024/2350186/2350186_10675067_1730401445059_Screenshot_2024_10_31_at_2.59.19__8239_PM--rgov-66x44.png\" alt=\"Verilog-to-PYG\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Verilog-to-PyG Website</div>\n<div class=\"imageCredit\">Cunxi Yu</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Cunxi&nbsp;Yu\n<div class=\"imageTitle\">Verilog-to-PYG</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2350186/2350186_10675067_1730401409566_Screenshot_2024_10_31_at_2.58.11__8239_PM--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2350186/2350186_10675067_1730401409566_Screenshot_2024_10_31_at_2.58.11__8239_PM--rgov-800width.png\" title=\"GAMORA_Example\"><img src=\"/por/images/Reports/POR/2024/2350186/2350186_10675067_1730401409566_Screenshot_2024_10_31_at_2.58.11__8239_PM--rgov-66x44.png\" alt=\"GAMORA_Example\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Illustrative Example of Functional Aware Learning on Boolean Networks</div>\n<div class=\"imageCredit\">Cunxi Yu</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Cunxi&nbsp;Yu\n<div class=\"imageTitle\">GAMORA_Example</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nAs the complexity of modern hardware systems grows, achieving fast and effective hardware exploration has become increasingly challenging due to limitations in existing electronic design automation (EDA) toolflows. Recent years have seen a surge in the application of machine learning (ML) techniques in EDA to reduce manual effort and accelerate the design closure process. Many EDA problems, such as Boolean optimization, physical design, and high-level synthesis, are combinatorial optimization tasks represented on graph-based data structures, which are unlikely to be solvable by polynomial-time algorithms. With modern logic designs comprising millions, or even billions, of logic gates, these problems present significant challenges.\n\n\nIn practice, these challenges are addressed using scalable optimization algorithms that rely on approximations and domain-specific heuristics, developed through extensive engineering efforts and deep domain expertise. This project explored the potential of graph learning and graph neural networks (GNNs) in representing and optimizing Boolean circuits in EDA, focusing on the functional and structural properties of these circuits. Our efforts included theoretical studies on graph embeddings concerning functional and structural information, integrated design optimization and reasoning, and the development of an open-source, generic graph learning framework for hardware design.\n\n\nMain Outcomes:\n\n\nEnhanced Functional Awareness in Circuit Graph Learning: Reasoning about high-level abstractions in Boolean networks, such as gate-level netlists, provides substantial benefits for functional verification, logic minimization, datapath synthesis, and malicious logic identification. However, conventional reasoning approaches rely heavily on structural hashing and functional propagation, which are limited in scalability and inefficiently use modern computing power. In the era of global and democratized integrated circuit (IC) development, scalable reasoning methods offer significant benefits for hardware optimization and security.\n\n\nImportance of Infrastructure and Data Preparation Support: While the proposed Boolean circuit graph learning methods have demonstrated strong capabilities in understanding complex relationships, there is a notable lack of infrastructure for preparing hardware datasetsparticularly for graph representations of RTL (Register-Transfer Level) designs. Two key challenges exist: (1) the absence of a comprehensive infrastructure that connects RTL designs with graph representations to facilitate dataset construction and integration with existing frameworks, such as PyTorch Geometric (PyG), and (2) the need for more design variations to train RTL foundation models effectively. In response, this project introduced an open-source infrastructure compatible with major graph learning frameworks, increasing the number of RTL design examples through functionally equivalent RTL augmentations.\n\n\nHardware Design Augmentation: Circuit design representation augmentation is essential for learning-based optimization and analysis. Unlike image augmentation, where transformations preserve semantic meaning, augmenting digital hardware systems presents unique challenges to ensure that circuit functionality remains intact. We identified that the primary challenge in circuit design augmentation is maintaining logical behavior during transformations, essential for model validity. To address this, we explored and demonstrated the potential of synthesis techniques from academic and industry sources to perform effective data augmentation within the hardware domain, ensuring that augmented circuit representations are functionally equivalent to their originals.\n\n\n\n\n\nThis project has advanced ML for EDA, particularly using graph learning techniques and hardware optimization, creating significant research and educational impacts. The development of open-source tools like Verilog-to-PyG (V2PYG) and GAMORA has drawn interest from industry leaders such as NVIDIA Research, demonstrating the project's potential to shape future EDA practices. These tools provide foundational resources for researchers studying Boolean circuit optimization, making cutting-edge methodologies more accessible. These tools provide foundational resources for researchers working on Boolean circuit optimization, making advanced methodologies more accessible. The project has supported a diverse group of students, including female PhD and undergraduate students and an LGBT PhD student, fostering an inclusive learning environment and encouraging further study. Notably, one undergraduate student published two papers in top EDA venues, was recognized as a DAC Young Fellow, and later joined MIT for PhD studies. Research outcomes have been integrated into courses, enhancing student learning through new modules on RL in optimizations and advanced EDA techniques. The project's collaborations and open-source contributions promise lasting impacts on the field, driving innovation in hardware design and optimization while preparing the next generation of leaders in computer science.\t\t\t\t\tLast Modified: 10/31/2024\n\n\t\t\t\t\tSubmitted by: CunxiYu\n"
 }
}