{
 "awd_id": "2335974",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Reimagining Futures of AI-Based Emotion Inference Technologies (Emotion AI) with Diverse Teens and Young Adults",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2024-07-01",
 "awd_exp_date": "2029-06-30",
 "tot_intn_awd_amt": 656402.0,
 "awd_amount": 399009.0,
 "awd_min_amd_letter_date": "2024-06-10",
 "awd_max_amd_letter_date": "2024-12-06",
 "awd_abstract_narration": "This project investigates the social and ethical impacts of Emotion Artificial Intelligence (AI), in which AI is used to try to infer people's emotions; for example, if given a picture of a smiling face, or text that contains cheerful, positive words, an Emotion AI algorithm might predict 'happy'. Systems using Emotion AI are becoming more commonly used to assess people in everyday life contexts from work and education to medicine and criminal justice. However, Emotion AI algorithms pose risks because even the best systems often make errors; algorithms may also be systematically biased if they are built using datasets that have biases in the amount or types of data they contain about different groups of people, or in the labels attached to that data. This projec's goal is to bring everyday people, particularly those who might be most vulnerable to errors and biases, into the conversation about when, and how, it is appropriate to use Emotion AI techniques. To do this the team will conduct a series of workshops and design activities with diverse teens and young adults, as well as technology workers, that will (a) inform designers of Emotion AI-based systems about what people expect and fear, and (b) increase AI literacy for both the workshop participants and their communities. This project will document the opinions, hopes, fears, and future visions that workshop participants share about Emotion AI. Through the research, the project aims to support education, diversity, and helping change the future of Emotion AI to benefit society.\r\n\r\nThis reimagining of the use of Emotion AI will be driven by two main methodological approaches: critical AI literacy and design futuring. Critical AI literacy is a set of skills that enables people to effectively use AI while also considering AI's benefits and risks. Design futuring is a method for critically considering ethics and unanticipated consequences of technology through creating alternative futures in which the technology has different, and not necessarily positive, effects on society. The project team will host workshops with culturally diverse teens and young adults in the Atlanta area to develop a library of both critical AI literacy materials and Emotion AI design futures, grounded specifically in approaches to Emotion AI based on Facial Expression Analysis, in which computer vision techniques are used to identify faces and apply the Facial Action Coding System approach that analyzes facial sub-expressions to infer emotions. These materials will then be used as prompts for discussions with developers that create Emotion AI-based systems about how they weigh benefits and risks in their work. The work will advance both the area of Emotion AI by integrating more diverse perspectives about it, as well as the underlying methods of design futuring by developing approaches to making futuring more diverse and participatory.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Noura",
   "pi_last_name": "Howell",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Noura Howell",
   "pi_email_addr": "nhowell8@gatech.edu",
   "nsf_id": "000846541",
   "pi_start_date": "2024-06-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Tech Research Corporation",
  "perf_str_addr": "926 DALNEY ST NW",
  "perf_city_name": "ATLANTA",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303186395",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 399009.0
  }
 ],
 "por": null
}