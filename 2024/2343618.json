{
 "awd_id": "2343618",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: NeTS: Small: A Privacy-Aware Human-Centered QoE Assessment Framework for Immersive Videos",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032924624",
 "po_email": "amatta@nsf.gov",
 "po_sign_block_name": "Abraham Matta",
 "awd_eff_date": "2024-05-01",
 "awd_exp_date": "2027-04-30",
 "tot_intn_awd_amt": 350000.0,
 "awd_amount": 350000.0,
 "awd_min_amd_letter_date": "2024-03-05",
 "awd_max_amd_letter_date": "2024-03-05",
 "awd_abstract_narration": "Immersive videos, also known as 360-degree videos, provide viewers with a complete visual perspective of their environment. The global market for immersive video is projected to reach 22 billion U.S. dollars by 2025. With the rising popularity of 360-degree videos, network operators and service providers are increasingly keen on gaining insights into users\u2019 Quality of Experience (QoE) perception. However, the conventional QoE models designed for two dimensional videos fall short of capturing users\u2019 unique subjective feelings in viewing this new type of video. To bridge this gap, the project focuses on constructing human-centered models that utilize \u201chuman factors\u201d via a variety of virtual reality (VR) onboard sensors. Leveraging multi-modal sensory readings, the researchers will tap into a direct representation of users\u2019 perceptual experiences. This approach captures subjective feelings often missed by the objective system parameters commonly used in existing QoE models. The success of this project will provide an in-depth understanding of users\u2019 nuanced perceptual experience while engaging with 360-degree videos. It will create opportunities for stakeholders to implement user-specific network resource optimization and video streaming strategies, ultimately enhancing customer satisfaction on an individual basis. The research outcomes will significantly contribute to the human-centered sensing and networking research communities and benefit numerous VR applications beyond 360-degree videos.\r\n\r\nThis project involves three closely related research thrusts. The first thrust investigates how to extract salient features from multi-modal sensory readings for effective QoE assessment. To combat bias arising from datasets with unevenly distributed labels, novel approaches will be developed to augment underrepresented data by exploring useful information across sensing modalities. The second thrust seeks to optimize system resource utilization for QoE assessment. Multiple personalized models will share common neural network layers at edge servers for resource-efficient model hosting. Adaptive sampling will be applied at VR terminals during sensory data acquisition to maintain data utility. The third thrust focuses on devising data privacy protection mechanisms without sacrificing QoE assessment accuracy. Under the differential privacy framework, the approach features formal quantification of data correlation of multi-modality sensory data, which has been largely overlooked by prior work. The proposed research is inter-disciplinary, which spans data-driven modeling, sensing, and privacy-preserving computing. The proposed mechanisms and designs will be thoroughly evaluated via a combination of measurement campaigns, simulations, and experimental studies.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ming",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ming Li",
   "pi_email_addr": "ming.li@uta.edu",
   "nsf_id": "000677955",
   "pi_start_date": "2024-03-05",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yingying",
   "pi_last_name": "Zhu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yingying Zhu",
   "pi_email_addr": "yingying.zhu@uta.edu",
   "nsf_id": "000857267",
   "pi_start_date": "2024-03-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Arlington",
  "inst_street_address": "701 S NEDDERMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "ARLINGTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "8172722105",
  "inst_zip_code": "760199800",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT ARLINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "LMLUKUPJJ9N3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Arlington",
  "perf_str_addr": "701 S. NEDDERMAN DR",
  "perf_city_name": "ARLINGTON",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "760199800",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 350000.0
  }
 ],
 "por": null
}