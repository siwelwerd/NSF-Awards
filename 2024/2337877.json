{
 "awd_id": "2337877",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: The Impact of Associations and Biases in Generative AI on Society",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2024-09-01",
 "awd_exp_date": "2029-08-31",
 "tot_intn_awd_amt": 603342.0,
 "awd_amount": 355237.0,
 "awd_min_amd_letter_date": "2024-02-29",
 "awd_max_amd_letter_date": "2024-02-29",
 "awd_abstract_narration": "This project aims to solidify the foundations of ethics in generative artificial intelligence (AI). Generative AI systems are built on unimodal and multimodal combinations of language, speech, and vision machine learning models. Generative AI models such as the chatbot ChatGPT and the text-to-image generator Stable Diffusion offer innovative and practical tools. However, this technology has inherent problems. Generative AI models learn implicit associations and biases documented in cognitive psychology from large-scale sociocultural data, which is a source of human biases regarding gender, race or ethnicity, social class, age, ability, sexuality, nationality, religion, concepts, and intersectional associations. Generative AI bias poses implications for performance disparities in AI, as well as AI ethics, particularly concerning the impact of generative AI on individuals and society. Outputs from easily accessible generative AI models contain biased social associations, amplifying complex biases that are challenging to mitigate for both AI developers and users. This project will develop methods for evaluating associations and biases in generative AI, assess the impact of generative AI on society, and analyze how generative AI shapes human cognition and agency. The project will advance civil rights by developing methods to address bias in machines, human-AI collaboration, and society. The open-source tools and materials presented by this award will raise awareness among a range of stakeholders, including the diverse student population, researchers, developers, industry, the open-source community, AI users, policymakers, and the public. This effort will enhance AI education at the University of Washington by introducing a generative AI ethics curriculum across disciplines and divisions. As AI regulation and legislation are being formulated, the scientific evidence produced by this award will inform policymakers on the safe, secure, and trustworthy development and use of AI. Active collaboration with policy think-tanks will aid transfer of the knowledge to policymaking.\r\n\r\nThis project will integrate computer and information science research in machine learning, natural language processing, computer vision, speech processing, and human-AI interaction with methodologies and large-scale datasets from social cognition. The project's primary objective is to empirically analyze the societal impact of generative AI, contributing to the ethical and responsible development and deployment of AI. The project seeks to evaluate and characterize associations and biases in generative AI systems by developing principled and generalizable detection and measurement methods. Leveraging the findings and developed bias evaluation methods, the research will devise approaches that automatically identify and reduce bias signals in generative AI models, taking into account the specific task, application, context, and use case. These approaches will encompass techniques such as training data augmentation, embedding space processing, fine-tuning, instruction tuning, and reinforcement learning from feedback. By examining generative AI biases in comparison to implicit and explicit biases of humans at the state and country levels and identifying emergent generative AI biases, the project will uncover the broader societal impact of generative AI. The analysis of changes in human implicit association test scores and decisions following exposure to biased generative AI outputs will assess their influence on human biases, perception, and decisions in human-AI collaboration. Accordingly, the award will develop novel approaches that align generative AI with human values by introducing new associations to mitigate the negative consequences caused by generative AI biases. The potential advancements resulting from this award extend beyond computer and information science, providing tools and insights for cognitive science, psychology, linguistics, sociology, and political science, while informing fields such as philosophy, law, and policy.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aylin",
   "pi_last_name": "Caliskan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aylin Caliskan",
   "pi_email_addr": "aylin@uw.edu",
   "nsf_id": "000802011",
   "pi_start_date": "2024-02-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "4333 Brooklyn Ave NE",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981950001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 355237.0
  }
 ],
 "por": null
}