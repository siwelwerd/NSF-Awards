{
 "awd_id": "1800947",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Medium: Collaborative Research: Augmented Reality Agents with Pervasive Awareness, Appearance, and Abilities",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 262726.0,
 "awd_amount": 262726.0,
 "awd_min_amd_letter_date": "2018-08-15",
 "awd_max_amd_letter_date": "2018-08-15",
 "awd_abstract_narration": "Voice-based assistants that respond to commands of people can be thought of as virtual companions that are always standing by to play music, tell us the weather, turn the lights off, etc. While their powers to respond and act on our behalf are increasing, unlike real companions they are largely unaware of our presence, take little initiative, look like appliances rather than interaction partners, and have limited abilities to both respond to queries and to sense and control real objects around us. This project will develop Augmented Reality Agents (ARAs) to embody these voice-based assistants, making them more are aware of our appearance, emotions, and behaviors, giving dynamic visual representations that make us aware of their state and behaviors; and leveraging the growth in \"Internet of Things\" (IoT) infrastructure and devices to increase the breadth and depth of their awareness. Together, these advances will lead to more effective and accepted voice-based assistants, both in the home and beyond. Such ARAs have a number of potential applications, including healthcare (by increasing the realism of clinical simulation and training, or providing support for caregiving through remote communication and virtual companionship) and education (by being more engaging tutors or representing historically important individuals). \r\n \r\nTo develop embodied Augmented Reality Agents (ARAs) with pervasive contextual awareness, appearance, and abilities the researchers will undertake a program of research aimed at the nexus of concepts and technologies associated with Augmented Reality (AR), Intelligent Virtual Agents (IVA), and the Internet of Things (IoT). To maximize the expected knowledge outcomes the researchers have organized their plans into three categories. First, they will develop new understanding of and priorities for ARA awareness, appearance, and abilities in a manner that does not require, nor depend on, a specific technological realization of automated behaviors. Second, they will use off-the-shelf and custom components to realize pervasive ARA functionality, to facilitate formative experiments related to basic ARA behaviors, and develop domain-specific applications and experiments. Third, the researchers will use application-specific realizations to assess the potential usefulness related to companionship and two areas of healthcare training: pediatric patient simulators and wide-area team-based medical training. The healthcare-focused work will leverage relevant courses at UF and UCF, and UCF's NSF REU center on the Internet of Things to engage students beyond their core team, in meaningful research.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Benjamin",
   "pi_last_name": "Lok",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Benjamin C Lok",
   "pi_email_addr": "lok@cise.ufl.edu",
   "nsf_id": "000364797",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326115500",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 262726.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aims to improve healthcare in the United States by helping healthcare students (such as nursing students) be exposed to and receive feedback on a variety of challenging scenarios through the use of simulation. By using simulation, healthcare students can practice skills such as communication, critical thinking, teamwork, observational skills, and decision making skills in a safe environment. Students can practice as many times as they want, can make mistakes and learn from them, and receive feedback on their performance.</p>\n<p>To support the healthcare student's skill development, we had to create new technologies and evaluate student performace to enable effective training and simulation. Specifically, this award aimed to study how to use virtual patients in both a virtual space (e.g. in a 3D hospital) and when augmenting existing training spaces (e.g. a virtual character that appeared in a real world nursing training facility).</p>\n<p>Through this award, we were able to train nursing students on how to triage mass causality events, how to catch errors made by teammates, how to communicate effectively as part of a team, develop critical thinking skills, and develop observational skills of conditions that change over time (e.g. a drug allergic reaction). These scenarios are available online and have facilitated hundreds of extra student training opportunities. Further these opportunities were critical during the Covid-19 pandemic (which occurred midway through this award) as well as post pandemic training that often leverages a hybrid model of both in-person and remote instruction.</p>\n<p>In total, this award has both advanced the fields of augmented reality, virtual reality, and simulation and training as well as improved the healthcare quality of United States through improving training of healthcare students.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/11/2022<br>\n\t\t\t\t\tModified by: Benjamin&nbsp;C&nbsp;Lok</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1800947/1800947_10571397_1660244998206_ScreenShot2022-08-11at3.07.19PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1800947/1800947_10571397_1660244998206_ScreenShot2022-08-11at3.07.19PM--rgov-800width.jpg\" title=\"Virtual agent teammates and patients\"><img src=\"/por/images/Reports/POR/2022/1800947/1800947_10571397_1660244998206_ScreenShot2022-08-11at3.07.19PM--rgov-66x44.jpg\" alt=\"Virtual agent teammates and patients\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This training simulation had students try to identify errors made by virtual teammates</div>\n<div class=\"imageCredit\">Jacob Stuart</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Benjamin&nbsp;C&nbsp;Lok</div>\n<div class=\"imageTitle\">Virtual agent teammates and patients</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1800947/1800947_10571397_1660244923494_ScreenShot2022-08-11at3.07.27PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1800947/1800947_10571397_1660244923494_ScreenShot2022-08-11at3.07.27PM--rgov-800width.jpg\" title=\"Virtual Reality Agent with drug allregy\"><img src=\"/por/images/Reports/POR/2022/1800947/1800947_10571397_1660244923494_ScreenShot2022-08-11at3.07.27PM--rgov-66x44.jpg\" alt=\"Virtual Reality Agent with drug allregy\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">students practiced observing drug reactions on virtual patients</div>\n<div class=\"imageCredit\">Jacob Stuart</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Benjamin&nbsp;C&nbsp;Lok</div>\n<div class=\"imageTitle\">Virtual Reality Agent with drug allregy</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1800947/1800947_10571397_1660245121276_ScreenShot2022-08-11at3.07.11PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1800947/1800947_10571397_1660245121276_ScreenShot2022-08-11at3.07.11PM--rgov-800width.jpg\" title=\"Augmented Reality Agent used in Triage Training for Nurses\"><img src=\"/por/images/Reports/POR/2022/1800947/1800947_10571397_1660245121276_ScreenShot2022-08-11at3.07.11PM--rgov-66x44.jpg\" alt=\"Augmented Reality Agent used in Triage Training for Nurses\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Nursing students practiced triage of a mass causality event using augmented reality that had virtual characters inhabit the physical training space of the student</div>\n<div class=\"imageCredit\">Jacob Stuart</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Benjamin&nbsp;C&nbsp;Lok</div>\n<div class=\"imageTitle\">Augmented Reality Agent used in Triage Training for Nurses</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project aims to improve healthcare in the United States by helping healthcare students (such as nursing students) be exposed to and receive feedback on a variety of challenging scenarios through the use of simulation. By using simulation, healthcare students can practice skills such as communication, critical thinking, teamwork, observational skills, and decision making skills in a safe environment. Students can practice as many times as they want, can make mistakes and learn from them, and receive feedback on their performance.\n\nTo support the healthcare student's skill development, we had to create new technologies and evaluate student performace to enable effective training and simulation. Specifically, this award aimed to study how to use virtual patients in both a virtual space (e.g. in a 3D hospital) and when augmenting existing training spaces (e.g. a virtual character that appeared in a real world nursing training facility).\n\nThrough this award, we were able to train nursing students on how to triage mass causality events, how to catch errors made by teammates, how to communicate effectively as part of a team, develop critical thinking skills, and develop observational skills of conditions that change over time (e.g. a drug allergic reaction). These scenarios are available online and have facilitated hundreds of extra student training opportunities. Further these opportunities were critical during the Covid-19 pandemic (which occurred midway through this award) as well as post pandemic training that often leverages a hybrid model of both in-person and remote instruction.\n\nIn total, this award has both advanced the fields of augmented reality, virtual reality, and simulation and training as well as improved the healthcare quality of United States through improving training of healthcare students.\n\n\t\t\t\t\tLast Modified: 08/11/2022\n\n\t\t\t\t\tSubmitted by: Benjamin C Lok"
 }
}