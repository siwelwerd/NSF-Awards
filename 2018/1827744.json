{
 "awd_id": "1827744",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RIDIR:  Collaborative Research: Enabling Access to and Analysis of Shared Daylong Child and Family Audio Data",
 "cfda_num": "47.075",
 "org_code": "04010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Patricia Van Zandt",
 "awd_eff_date": "2018-03-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 360683.0,
 "awd_amount": 360683.0,
 "awd_min_amd_letter_date": "2018-03-09",
 "awd_max_amd_letter_date": "2020-12-18",
 "awd_abstract_narration": "A child's language development in the first few years of life predicts long-term cognitive development, academic achievement, and expected income as an adult. Early language development in turn depends on linguistic interactions with adults. Increasingly, researchers are using daylong audio recordings to study child language development and child-caregiver interactions. Compared to short language samples, daylong recordings capture the full range of experiences a child has over the course of a day. Daylong audio recordings are also being used in applied settings. For example, studies show that by the time they enter First Grade, children from higher socioeconomic backgrounds hear tens of millions more words than children from lower socioeconomic backgrounds, perpetuating social inequalities. Multiple large-scale intervention projects targeting low socioeconomic households, including the Thirty Million Words Initiative in Chicago and the Providence Talks program, are using daylong audio recordings to provide automated, personalized feedback to parents on when and how often their child hears adult words and experiences conversational turns. The features of daylong recordings that are advantageous for researchers and practitioners also pose unique challenges. For one, their long durations are ideal for studying the temporal dynamics of child-adult interaction, but taking advantage of the long durations requires the enlistment of automated speech recognition technology. Current automatic speech recognition systems have difficulties with child speech and are challenged by the noisy and varied acoustic environments represented in the recordings. Another challenge is that the recordings capture private moments that require long hours of human listening to remove. This makes it difficult for researchers to share the recordings publicly, so that the potential value of the recordings collected by individual research labs is not fully realized.\r\n\r\nThis project will create a new resource, called HomeBank, that will have three key components: (1) a public dataset containing daylong audio recordings that have had private information removed by human listeners, (2) a larger dataset containing about ten to one hundred times as many hours of recording that have not had private information removed and will be free but restricted to those who have demonstrated training in human research ethics, and (3) an open-source repository of computer programs to automatically analyze the daylong audio recordings. HomeBank will take advantage of an existing cyberinfrastructure for sharing linguistic data called TalkBank. The daylong audio recordings included in the datasets will represent both typically developing and clinical groups, a range of ages from newborn infants to school age children, and a range of language and socioeconomic backgrounds. We expect the primary users to be basic and applied child development researchers as well as engineers developing automatic speech recognition technologies. The free-to-access database and the open source computer programs will ultimately improve both the data on which early interventions are based and the tools available for providing parents with feedback on the linguistic input they provide their children.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SMA",
 "org_div_long_name": "SBE Office of Multidisciplinary Activities",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anne",
   "pi_last_name": "Warlaumont",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Anne S Warlaumont",
   "pi_email_addr": "warlaumont@ucla.edu",
   "nsf_id": "000661480",
   "pi_start_date": "2018-03-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles",
  "perf_str_addr": "10889 Wilshire Boulevard",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900951406",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  },
  {
   "pgm_ele_code": "829400",
   "pgm_ele_name": "Data Infrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8004",
   "pgm_ref_txt": "Software Institutes"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 360683.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In the past decade, there has been an increase in the use of&nbsp;day-long child-centered audio recordings to study communication development. A mobile recording device is typically placed in a chest pocket in specially-constructed clothing. Sound is captured from morning through evening as the child experiences a typical day in their real-world environment. The child's vocalizations are captured as are input the child hears from adults and other sounds the child is exposed to over the day.</p>\n<p>This project created a set of tools and resources that enable researchers to share day-long child-centered audio recordings with other researchers and, when participants and institutions allow, with the general public. Specifically, the project created a new data resource, called HomeBank (https://homebank.talkbank.org). At the core of HomeBank is a database that currently contains roughly a dozen datasets (a.k.a. \"corpora\"). Each dataset consists of multiple day-long audio recordings contributed by a research group. Researchers have in most cases also provided&nbsp;demographic metadata about the children and their families. Most researchers have also provided information about the precise times during each recording&nbsp;when various sound type categories are likely to have occurred, as determined&nbsp;automatically by an algorithm included in the software used to collect the recordings.</p>\n<p>Across corpora, HomeBank currently contains thousands of daylong audio recordings. The data are available to HomeBank members, who have undergone human subjects research training and agreed to protect the data and coordinate with the contributing groups. A variety of languages, settings, and populations are represented in the datasets. A handful of the datasets have subsets that are shared publicly, in some cases together with transcripts of the child and adult speech they contain.</p>\n<p>Besides the shared data, the HomeBank website provides information and resources to help researchers obtain participant consent for data sharing, prepare and transfer data, obtain access to the password-protected sections of HomeBank, and access derivative datasets and tools for analyzing day-long child-centered audio. Many of these resources were also created or enhanced as a result of this project.</p>\n<p>These resources and associated efforts have enabled researchers and students in a range of disciplines, such as Engineering, Psychology, and Linguistics, to readily access real-world long-form audio recordings of the sounds children make and hear. This has facilitated interdisciplinary and interinstitutional collaborations. These collaboarations have in turn led to the development of new, open-source algorithms for detecting and classifying child and adult voices. The collaborations this project has fostered and supported have also led to new findings regarding children's&nbsp;language input and the types of sounds children produce at different ages and across cultures. The new database and in particular the publicly available portions also enable students and members of the public to access data on children's real-world audio experiences and vocal productions.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/30/2021<br>\n\t\t\t\t\tModified by: Anne&nbsp;S&nbsp;Warlaumont</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn the past decade, there has been an increase in the use of day-long child-centered audio recordings to study communication development. A mobile recording device is typically placed in a chest pocket in specially-constructed clothing. Sound is captured from morning through evening as the child experiences a typical day in their real-world environment. The child's vocalizations are captured as are input the child hears from adults and other sounds the child is exposed to over the day.\n\nThis project created a set of tools and resources that enable researchers to share day-long child-centered audio recordings with other researchers and, when participants and institutions allow, with the general public. Specifically, the project created a new data resource, called HomeBank (https://homebank.talkbank.org). At the core of HomeBank is a database that currently contains roughly a dozen datasets (a.k.a. \"corpora\"). Each dataset consists of multiple day-long audio recordings contributed by a research group. Researchers have in most cases also provided demographic metadata about the children and their families. Most researchers have also provided information about the precise times during each recording when various sound type categories are likely to have occurred, as determined automatically by an algorithm included in the software used to collect the recordings.\n\nAcross corpora, HomeBank currently contains thousands of daylong audio recordings. The data are available to HomeBank members, who have undergone human subjects research training and agreed to protect the data and coordinate with the contributing groups. A variety of languages, settings, and populations are represented in the datasets. A handful of the datasets have subsets that are shared publicly, in some cases together with transcripts of the child and adult speech they contain.\n\nBesides the shared data, the HomeBank website provides information and resources to help researchers obtain participant consent for data sharing, prepare and transfer data, obtain access to the password-protected sections of HomeBank, and access derivative datasets and tools for analyzing day-long child-centered audio. Many of these resources were also created or enhanced as a result of this project.\n\nThese resources and associated efforts have enabled researchers and students in a range of disciplines, such as Engineering, Psychology, and Linguistics, to readily access real-world long-form audio recordings of the sounds children make and hear. This has facilitated interdisciplinary and interinstitutional collaborations. These collaboarations have in turn led to the development of new, open-source algorithms for detecting and classifying child and adult voices. The collaborations this project has fostered and supported have also led to new findings regarding children's language input and the types of sounds children produce at different ages and across cultures. The new database and in particular the publicly available portions also enable students and members of the public to access data on children's real-world audio experiences and vocal productions.\n\n\t\t\t\t\tLast Modified: 12/30/2021\n\n\t\t\t\t\tSubmitted by: Anne S Warlaumont"
 }
}