{
 "awd_id": "1837999",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: IA: Collaborative Research: Asynchronous Distributed Machine Learning Framework for Multi-Site Collaborative Brain Big Data Mining",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-01-01",
 "awd_exp_date": "2022-12-31",
 "tot_intn_awd_amt": 119982.0,
 "awd_amount": 119982.0,
 "awd_min_amd_letter_date": "2018-09-10",
 "awd_max_amd_letter_date": "2018-09-10",
 "awd_abstract_narration": "Recent advances in multimodal brain imaging and high throughput genotyping and sequencing techniques provide exciting new opportunities to ultimately improve our understanding of brain structure and neural dynamics, their genetic architecture, and their influences on cognition and behavior. However, data privacy and security issues have inhibited data sharing across institutes. Emerging multi-site collaborative data analysis can address these issues and facilitate data and computing resource sharing. In collaborative data analysis, the participating institutes keep their own data, which are analyzed and computed locally, and only share the computed results by communicating with a server. The server communicates with all institutes and updates the local models such that the trained machine learning models indirectly use all data and are shared with all institutes. Although some distributed/parallel computation techniques were recently proposed to address big data mining problems, most of them are synchronous models. Asynchronous distributed learning methods are much more efficient, because they allow the server to update the model with information from only one worker node without waiting for slow worker nodes in each round. However, the convergence analysis for the asynchronous distributed algorithms is much more difficult due to the inconsistent variables update across nodes. Thus, it is challenging to design efficient distributed machine learning algorithms for collaborative big data analysis. The research objective of this project is to address the computational challenges in the emerging multi-site collaborative data mining for brain big data.\r\n \r\nThis project seeks to harness the opportunities of designing new efficient asynchronous distributed machine learning algorithms with rigorous theoretical foundations for multi-site collaborative brain big data mining, creating large-scale computational strategies and effective software tools to reveal sophisticated relationships among heterogeneous brain data. This project designs the asynchronous distributed machine learning and principled big data mining models to conduct the comprehensive study of brain imaging genomics and connectomics. Specifically, the principal investigators investigate: 1) collaborative genotype and phenotype association study using new asynchronous doubly stochastic proximal gradient algorithms; 2) communication-efficient multi-site collaborative data integration models to integrate imaging genomics data for predicting outcomes of interest; 3) collaborative deep learning algorithm speedup by the asynchronous distributed algorithms with applications in temporal cognitive change prediction; and 4) new graph convolutional deep learning models for brain network mining. It is innovative to integrate new distributed machine learning and data-intensive computing with brain imaging genomics and connectomics that hold great promise for a systems biology of the brain. The developed methods and tools impact other neuroimaging, genomics, and neuroscience research, and enable investigators working on brain science to effectively test their scientific hypotheses. This project will also facilitate the development of novel educational tools.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Todd",
   "pi_last_name": "Parrish",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Todd B Parrish",
   "pi_email_addr": "toddp@northwestern.edu",
   "nsf_id": "000090709",
   "pi_start_date": "2018-09-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University at Chicago",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "KG76WYENL5K1",
  "org_uei_num": "KG76WYENL5K1"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "737 N. Michigan Ave., Suite 1600",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606116652",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "IL05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 119982.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project supported my participation in the AI in Medical Imaging working group that I founded with Professor Aggelos Katsaggelos (EE, Northwestern) in 2016. Virginia Hill, Neuroradiologist, and Katie Bandt, Neurosurgeon, were key clinical collaborators. We have grown to ~60 members that come from engineering, computer science, Radiology, Psychiatry, Neurosurgery, and Neurology. The members are undergraduates, graduate students, post-docs, fellows and faculty. We cover many physiologic systems but have a brain focus, since that is my area of interest.</p>\n<p>During the period of the grant we investigated several large imaging datasets that were public (ADNI, PPMI, Oasis, UK BioBank) and some that were internally generated and curated for research projects. The data was mostly MRI-based but some projects included chest X-rays, cardiac ultrasound, and head CT scans. Furthermore, we had a project that used natural language processing applied to radiology reports to develop imaging labels for a large internal dataset.</p>\n<p>Our earliest projects involved the ADNI dataset to predict individuals with Alzheimer&rsquo;s disease using 3D structural MRI and PET imaging data by fusing 2 networks. These models maintained the spatial information by processing the entire 3D volumes instead of using patches. We found late fusion provided better results than early fusion. In subsequent work (in preparation for publication), we added additional demographic and genetic factors to improve the prediction at the current time point but was also able to predict cognitive decline rates. Such information is critical to families and physicians as it informs them how to best treat the patient.</p>\n<p>We then developed methods to use Graph Convolutional Neural Networks (gCNN) to investigate the brain. The surface of the brain and the gray/white matter interface are very complex. These surfaces reflect the structure/function relationship as well as provides information about atrophy. This is a departure from the MR signal based methods typically used since the gCNN is using shape of the cortical ribbon for prediction or regression outputs. Using more than 6,400 brains from 11 publicly available datasets from around the world, we were able to predict sex with an accuracy of 87.99% and achieved a Person&rsquo;s coefficient of 0.93 for predicting chronological brain age with an average absolute error of 4.5 years. Furthermore, using Class Activation Maps and Regression Activation Maps it was possible to identify those anatomic regions that contributed to those prediction/regression results. Using our Neuroscience knowledge of development, this information demonstrated that the algorithm was using real information compared to &ldquo;noise&rdquo; or artifacts to generate the results. These gCNN models were also trained to predict fluid intelligence in 2 different populations with higher accuracy than those that won the data challenge for the same task. Furthermore, a gCNN model was applied to the ADNI dataset we first used and it obtained an accuracy of 96.35% at identifying Alzheimer&rsquo;s disease.</p>\n<p>Our group then focused on developing our own large dataset of non-contrast head CT scans. We gathered over 50,000 individual subjects dating from 2008-2013 from the NMH/NU Enterprise Data Warehouse which contains de-identified patients records for research use. Applying NLP to 1,002 hand-curated radiology reports that were verified for accuracy, we developed a labeling model that partitioned the subjects into 12 common neurological categories. These categories could be further grouped into normal or pathology groups or into emergent or non-emergent depending on the overall project goal. This n-gram encoding model allowed us to provide diagnostic labels for the 50,000 scans that we mined. This has led to the development of a model that can predict if the input head CT scan is an emergent category so it can be read tight away or if it is non-emergent and could be read in the order that it was acquired. Furthermore, using multiple instance learning coupled with the RSNA hemorrhage dataset, we developed a hemorrhage detection model that can color code the types of hemorrhage and calculate volumes in a matter of seconds. These features are critical in assisting Radiologists follow traumatic brain injury subjects to make sure they are no longer bleeding.</p>\n<p>&nbsp;</p>\n<p>All of the models developed during this project are translational with the aim of aiding the Radiologist and/or physicians to better treat patients.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/04/2023<br>\n\t\t\t\t\tModified by: Todd&nbsp;B&nbsp;Parrish</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project supported my participation in the AI in Medical Imaging working group that I founded with Professor Aggelos Katsaggelos (EE, Northwestern) in 2016. Virginia Hill, Neuroradiologist, and Katie Bandt, Neurosurgeon, were key clinical collaborators. We have grown to ~60 members that come from engineering, computer science, Radiology, Psychiatry, Neurosurgery, and Neurology. The members are undergraduates, graduate students, post-docs, fellows and faculty. We cover many physiologic systems but have a brain focus, since that is my area of interest.\n\nDuring the period of the grant we investigated several large imaging datasets that were public (ADNI, PPMI, Oasis, UK BioBank) and some that were internally generated and curated for research projects. The data was mostly MRI-based but some projects included chest X-rays, cardiac ultrasound, and head CT scans. Furthermore, we had a project that used natural language processing applied to radiology reports to develop imaging labels for a large internal dataset.\n\nOur earliest projects involved the ADNI dataset to predict individuals with Alzheimer\u2019s disease using 3D structural MRI and PET imaging data by fusing 2 networks. These models maintained the spatial information by processing the entire 3D volumes instead of using patches. We found late fusion provided better results than early fusion. In subsequent work (in preparation for publication), we added additional demographic and genetic factors to improve the prediction at the current time point but was also able to predict cognitive decline rates. Such information is critical to families and physicians as it informs them how to best treat the patient.\n\nWe then developed methods to use Graph Convolutional Neural Networks (gCNN) to investigate the brain. The surface of the brain and the gray/white matter interface are very complex. These surfaces reflect the structure/function relationship as well as provides information about atrophy. This is a departure from the MR signal based methods typically used since the gCNN is using shape of the cortical ribbon for prediction or regression outputs. Using more than 6,400 brains from 11 publicly available datasets from around the world, we were able to predict sex with an accuracy of 87.99% and achieved a Person\u2019s coefficient of 0.93 for predicting chronological brain age with an average absolute error of 4.5 years. Furthermore, using Class Activation Maps and Regression Activation Maps it was possible to identify those anatomic regions that contributed to those prediction/regression results. Using our Neuroscience knowledge of development, this information demonstrated that the algorithm was using real information compared to \"noise\" or artifacts to generate the results. These gCNN models were also trained to predict fluid intelligence in 2 different populations with higher accuracy than those that won the data challenge for the same task. Furthermore, a gCNN model was applied to the ADNI dataset we first used and it obtained an accuracy of 96.35% at identifying Alzheimer\u2019s disease.\n\nOur group then focused on developing our own large dataset of non-contrast head CT scans. We gathered over 50,000 individual subjects dating from 2008-2013 from the NMH/NU Enterprise Data Warehouse which contains de-identified patients records for research use. Applying NLP to 1,002 hand-curated radiology reports that were verified for accuracy, we developed a labeling model that partitioned the subjects into 12 common neurological categories. These categories could be further grouped into normal or pathology groups or into emergent or non-emergent depending on the overall project goal. This n-gram encoding model allowed us to provide diagnostic labels for the 50,000 scans that we mined. This has led to the development of a model that can predict if the input head CT scan is an emergent category so it can be read tight away or if it is non-emergent and could be read in the order that it was acquired. Furthermore, using multiple instance learning coupled with the RSNA hemorrhage dataset, we developed a hemorrhage detection model that can color code the types of hemorrhage and calculate volumes in a matter of seconds. These features are critical in assisting Radiologists follow traumatic brain injury subjects to make sure they are no longer bleeding.\n\n \n\nAll of the models developed during this project are translational with the aim of aiding the Radiologist and/or physicians to better treat patients.\n\n \n\n\t\t\t\t\tLast Modified: 09/04/2023\n\n\t\t\t\t\tSubmitted by: Todd B Parrish"
 }
}