{
 "awd_id": "1814846",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: RUI: Leveraging Movement, Posture, and Anthropometric Contexts to Strengthen the Security of Mobile Biometrics",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jeremy Epstein",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2023-03-31",
 "tot_intn_awd_amt": 499758.0,
 "awd_amount": 499758.0,
 "awd_min_amd_letter_date": "2018-09-04",
 "awd_max_amd_letter_date": "2018-09-04",
 "awd_abstract_narration": "Modern smartphones regularly store and access large amounts of personal data, such as e-mails, photos, videos, and banking information. For this reason, securing them is of paramount importance. User authentication is a crucial step towards securing a smartphone. However, current user authentication mechanisms such as graphical passwords, Personal Identification Numbers (PINs), and fingerprint scans offer limited security, and are ineffective after the smartphone has been unlocked. To address these issues, this project develops continuous authentication mechanisms that rely on behavioral cues to determine whether the smartphone is being used by its owner. This project will result in (1) new foundational understanding of mobile behavioral biometrics under realistic posture, movement, and anthropometric conditions, and (2) new techniques to distinguish legitimate behavioral traits from forgeries.\r\n\r\nThe project will systematically quantify the impact of posture, movement, and anthropometric variables on behavioral biometric traits in hitherto understudied subject populations, such as older adults and people with Parkinson's disease. To this end, the project involves the analysis and dissemination of datasets collected in two settings: (1) fine-grained 3-dimensional motion capture data collected in a laboratory setting, and (2) real-world smartphone sensor data captured over a period of up to 12 months in the users' everyday environment. The project is expected to result in new behavioral authentication techniques that achieve lower error rates under realistic conditions by adapting to drifts in contexts and behaviors.  Additionally, this project seeks to quantify the susceptibility of behavioral biometric traits to forgery attacks, and introduce novel liveness detection techniques that rely on contextual information, as well as lightweight and unobtrusive user challenges, to mitigate these attacks. The investigators will evaluate these techniques on up to 150 subjects, and will share the results of this project in the form of datasets, presentations, publications, and code.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rosemary",
   "pi_last_name": "Gallagher",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rosemary Gallagher",
   "pi_email_addr": "rgalla01@nyit.edu",
   "nsf_id": "000764246",
   "pi_start_date": "2018-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kiran",
   "pi_last_name": "Balagani",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kiran Balagani",
   "pi_email_addr": "kbalagan@nyit.edu",
   "nsf_id": "000555124",
   "pi_start_date": "2018-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Paolo",
   "pi_last_name": "Gasti",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Paolo Gasti",
   "pi_email_addr": "pgasti@nyit.edu",
   "nsf_id": "000689447",
   "pi_start_date": "2018-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Isaac",
   "pi_last_name": "Kurtzer",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Isaac L Kurtzer",
   "pi_email_addr": "ikurtzer@nyit.edu",
   "nsf_id": "000737572",
   "pi_start_date": "2018-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York Institute of Technology",
  "inst_street_address": "1855 BROADWAY",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5166867737",
  "inst_zip_code": "100237606",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NY12",
  "org_lgl_bus_name": "NEW YORK INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "SVZSJHR2A4T6"
 },
 "perf_inst": {
  "perf_inst_name": "New York Institute of Technology",
  "perf_str_addr": "Northern Boulevard, PO Box 8000",
  "perf_city_name": "Old Westbury",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "115688000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "NY03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "065Z",
   "pgm_ref_txt": "Human factors for security research"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 499758.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-4f70f440-7fff-90b3-5f74-db7ac8a10c3e\"> </span></p>\n<p dir=\"ltr\"><span>The primary goal of this project was to use spatial and temporal measurements of body posture and movement when a user interacts with a smartphone to build the foundation for robust and secure behavioral authentication on mobile devices. Using these measurements, we systematically quantified the impact of posture, movement, anthropometric, and cohort-specific variables on behavioral authentication signals collected from young adults (20-40 years old), individuals of age 65 or older, and individuals with Parkinson's disease (PD).</span></p>\n<p dir=\"ltr\">This research provided a new foundational understanding of the security of mobile behavioral biometrics under realistic posture, movement, and anthropometric contexts. By involving elderly subjects and subjects with PD, the proposed research paved the way for reliable continuous authentication with these cohorts. This is in stark contrast with prior work, which based its results largely on data from young adults and student cohorts.</p>\n<p dir=\"ltr\">In the project, the major activities performed include the following (1) smartphone and 3D motion capture data collected from a total of 84 subjects (including 41 young adults, 22 older adults, and 21 people with Parkinson Disease); (2) smartphone behavioral authentication data (i.e., typing and swiping patterns) collected from a total of 29 users in their home environment without any restrictions imposed on the posture; (3) development of a smartphone biometric authentication framework to expand the behavioral biometric features by including posture contexts extracted from smartphone motion capture data; (4) using neurophysiological guiding principles to extract postural features; (5) Use of multiple body-sensor based authentication to circumvent impostor attacks as well as reduce authentication latency.</p>\n<p dir=\"ltr\">For smartphone behavioral biometric authentication, we designed feature selection methods to separate posture-related physiological features from smartphone behavioral features. We also extracted features and specific posture-related context by utilizing the joint angles and posture geometry from 3D motion capture data.</p>\n<p dir=\"ltr\">Our work quantified the influence of contexts on behavioral biometric signals and refined context extraction with the goal of reducing authentication errors. We quantified the reduction of error rates by using head and body postural contexts along with behavioral biometric signals. We developed a data collection app that we then deployed the subject&rsquo;s own environment (e.g., subject&rsquo;s home) to help determine the collectability of each postural context that can be extracted or inferred from smartphone sensors.&nbsp;</p>\n<p dir=\"ltr\"><span>We also investigated whether it is possible to reconstruct swipes from video of users performing common activities on their smartphone. Based on the resulting evidence, the possibility of recreating swipes from the external videos was low because of the low coverage obtained in the external videos recorded from above the subject, especially during walking activities.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/01/2023<br>\n\t\t\t\t\tModified by: Kiran&nbsp;Balagani</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThe primary goal of this project was to use spatial and temporal measurements of body posture and movement when a user interacts with a smartphone to build the foundation for robust and secure behavioral authentication on mobile devices. Using these measurements, we systematically quantified the impact of posture, movement, anthropometric, and cohort-specific variables on behavioral authentication signals collected from young adults (20-40 years old), individuals of age 65 or older, and individuals with Parkinson's disease (PD).\nThis research provided a new foundational understanding of the security of mobile behavioral biometrics under realistic posture, movement, and anthropometric contexts. By involving elderly subjects and subjects with PD, the proposed research paved the way for reliable continuous authentication with these cohorts. This is in stark contrast with prior work, which based its results largely on data from young adults and student cohorts.\nIn the project, the major activities performed include the following (1) smartphone and 3D motion capture data collected from a total of 84 subjects (including 41 young adults, 22 older adults, and 21 people with Parkinson Disease); (2) smartphone behavioral authentication data (i.e., typing and swiping patterns) collected from a total of 29 users in their home environment without any restrictions imposed on the posture; (3) development of a smartphone biometric authentication framework to expand the behavioral biometric features by including posture contexts extracted from smartphone motion capture data; (4) using neurophysiological guiding principles to extract postural features; (5) Use of multiple body-sensor based authentication to circumvent impostor attacks as well as reduce authentication latency.\nFor smartphone behavioral biometric authentication, we designed feature selection methods to separate posture-related physiological features from smartphone behavioral features. We also extracted features and specific posture-related context by utilizing the joint angles and posture geometry from 3D motion capture data.\nOur work quantified the influence of contexts on behavioral biometric signals and refined context extraction with the goal of reducing authentication errors. We quantified the reduction of error rates by using head and body postural contexts along with behavioral biometric signals. We developed a data collection app that we then deployed the subject\u2019s own environment (e.g., subject\u2019s home) to help determine the collectability of each postural context that can be extracted or inferred from smartphone sensors. \nWe also investigated whether it is possible to reconstruct swipes from video of users performing common activities on their smartphone. Based on the resulting evidence, the possibility of recreating swipes from the external videos was low because of the low coverage obtained in the external videos recorded from above the subject, especially during walking activities.\n\n \n\n\t\t\t\t\tLast Modified: 07/01/2023\n\n\t\t\t\t\tSubmitted by: Kiran Balagani"
 }
}