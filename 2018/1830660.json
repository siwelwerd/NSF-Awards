{
 "awd_id": "1830660",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: INT: COLLAB: Shared Autonomy for Unstructured Underwater Environments through Vision and Language",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 313303.0,
 "awd_amount": 313303.0,
 "awd_min_amd_letter_date": "2018-08-31",
 "awd_max_amd_letter_date": "2018-08-31",
 "awd_abstract_narration": "Existing underwater robotic systems typically provide one of two operating modes---full teleoperation or full autonomy. Teleoperation is by far the most common, particularly for tasks involving interaction with the environment, such as grasping and manipulation. Autonomy is restricted to non-contact survey missions and to controlled laboratory settings. The ability to operate between teleoperation and autonomy will improve the efficiency and effectiveness of tasks performed in underwater environments. This research will develop and evaluate a novel shared autonomy framework. The research leverages the different nature of humans and robots. This work will reduce the need for multiple, highly trained operators. It has the potential to drastically reduce the cost of underwater missions. The contributions of this research will impact the way in which humans work together with robots within a wide variety of applications, including space exploration, disaster relief, and assistive robotics.\r\n\r\nAs robotic systems play an ever-larger role as our surrogates for marine science and exploration, the ability to leverage the complementary nature of humans and robots becomes critical for scientific discovery. This research will develop new models and algorithms that exploit multiple non-commensurate sensing and control modalities to realize intelligent shared autonomy in complex unstructured environments. Novel to this research is the use of natural language and vision as complementary forms of weak supervision to enable robots to learn human-collaborative sensorimotor manipulation policies opportunistically from narrated human demonstrations. Fundamental to these methods is their ability to then refine these policies in situ based upon interaction with a human operator. Together, these models and algorithms will enhance the efficiency and effectiveness of underwater scientific exploration.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Walter",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew R Walter",
   "pi_email_addr": "mwalter@ttic.edu",
   "nsf_id": "000689337",
   "pi_start_date": "2018-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Toyota Technological Institute at Chicago",
  "inst_street_address": "6045 S KENWOOD AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7738340409",
  "inst_zip_code": "606372803",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "TOYOTA TECHNOLOGICAL INSTITUTE AT CHICAGO",
  "org_prnt_uei_num": "ERBJF4DMW6G4",
  "org_uei_num": "ERBJF4DMW6G4"
 },
 "perf_inst": {
  "perf_inst_name": "Toyota Technological Institute at Chicago",
  "perf_str_addr": "6045 S. Kenwood Ave.",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606372803",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 313303.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Existing underwater robotic systems typically provide one of two operating modes&mdash;full teleoperation or full autonomy. Autonomous operations are currently limited to non-contact survey work with autonomous underwater vehicles (AUVs) or simple autonomous intervention in controlled laboratory settings. In contrast, teleoperation is routinely used for direct contact (intervention) operations involving manipulation and grasping tasks. Most existing underwater systems lack the ability to operate in the continuum that exists between full teleoperation and full autonomy, because they decouple the capabilities of the operator and the machine. This problem is not limited to the subsea domain, and is true of other applications that require maneuverability and manipulation in unstructured and semi-structured environments, such as assistive technology, co-robotic industrial applications and planetary exploration. Consequently, current field robotic operational assets are used almost exclusively in a fully teleoperated mode, severely limiting the effectiveness and efficiency of the tasks that can be performed. Under this effort, we propose developed, implemented, and evaluated a shared autonomy framework suitable to unstructured environments that leverages the complementary nature of humans and robots. Integral to these models and algorithms is their exploitation of multiple non-commensurate modalities including natural language, visual imagery, proprioceptive sensors, and manual control input to better understand the space between operator and robot. These capabilities will advance the frontiers in tasks that currently require multiple highly trained operators. The results will help to further reduce the cost and increase the accessibility of underwater remotely operated and human-occupied vehicle missions, and contribute to improvements in the efficiency and effectiveness of manipulation within unstructured environments in general.</p>\n<p>The capabilities developed under this effort help to advance what is achievable in domains that currently require multiple highly trained operators, reducing the cost and increasing the accessibility of underwater remotely operated vehicle (ROV) and human-occupied vehicle (HOV) operations. This improves the efficiency and effectiveness of subsea science missions. While grounded in the underwater domain, the methods that we have developed are relevant to a variety of unstructured and semi-structured domains, including space exploration, disaster relief, and assistive robotics.&nbsp;</p>\n<p>This award has supported numerous efforts by the PIs and students to facilitate K&ndash;12, undergraduate, and graduate education in computer science, with a particular emphasis on participation by students from historically underrepresented groups. This effort has been fundamental to the theses of three PhD and one BS student. It also introduced undergraduates from diverse backgrounds to PhD-level research and supported a number of public-facing outreach efforts at Chicago public schools and science museums.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/02/2022<br>\n\t\t\t\t\tModified by: Matthew&nbsp;R&nbsp;Walter</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nExisting underwater robotic systems typically provide one of two operating modes&mdash;full teleoperation or full autonomy. Autonomous operations are currently limited to non-contact survey work with autonomous underwater vehicles (AUVs) or simple autonomous intervention in controlled laboratory settings. In contrast, teleoperation is routinely used for direct contact (intervention) operations involving manipulation and grasping tasks. Most existing underwater systems lack the ability to operate in the continuum that exists between full teleoperation and full autonomy, because they decouple the capabilities of the operator and the machine. This problem is not limited to the subsea domain, and is true of other applications that require maneuverability and manipulation in unstructured and semi-structured environments, such as assistive technology, co-robotic industrial applications and planetary exploration. Consequently, current field robotic operational assets are used almost exclusively in a fully teleoperated mode, severely limiting the effectiveness and efficiency of the tasks that can be performed. Under this effort, we propose developed, implemented, and evaluated a shared autonomy framework suitable to unstructured environments that leverages the complementary nature of humans and robots. Integral to these models and algorithms is their exploitation of multiple non-commensurate modalities including natural language, visual imagery, proprioceptive sensors, and manual control input to better understand the space between operator and robot. These capabilities will advance the frontiers in tasks that currently require multiple highly trained operators. The results will help to further reduce the cost and increase the accessibility of underwater remotely operated and human-occupied vehicle missions, and contribute to improvements in the efficiency and effectiveness of manipulation within unstructured environments in general.\n\nThe capabilities developed under this effort help to advance what is achievable in domains that currently require multiple highly trained operators, reducing the cost and increasing the accessibility of underwater remotely operated vehicle (ROV) and human-occupied vehicle (HOV) operations. This improves the efficiency and effectiveness of subsea science missions. While grounded in the underwater domain, the methods that we have developed are relevant to a variety of unstructured and semi-structured domains, including space exploration, disaster relief, and assistive robotics. \n\nThis award has supported numerous efforts by the PIs and students to facilitate K&ndash;12, undergraduate, and graduate education in computer science, with a particular emphasis on participation by students from historically underrepresented groups. This effort has been fundamental to the theses of three PhD and one BS student. It also introduced undergraduates from diverse backgrounds to PhD-level research and supported a number of public-facing outreach efforts at Chicago public schools and science museums.\n\n\t\t\t\t\tLast Modified: 08/02/2022\n\n\t\t\t\t\tSubmitted by: Matthew R Walter"
 }
}