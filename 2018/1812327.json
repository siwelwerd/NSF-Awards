{
 "awd_id": "1812327",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "NSF-BSF: RI: Small: Collaborative Research: Modeling Crosslinguistic Influences Between Language Varieties",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 166000.0,
 "awd_amount": 166000.0,
 "awd_min_amd_letter_date": "2018-07-27",
 "awd_max_amd_letter_date": "2018-09-13",
 "awd_abstract_narration": "Most people in the world today are multilingual. Though multilingualism is a gradual phenomenon, previous research has primarily examined text from second language learners who have not yet achieved fluency. This project focuses on text produced by nonnative but highly fluent speakers. Fluent but nonnative language differs subtly from native, monolingual language in the frequencies of certain concepts, constructions, and collocations. This raises the possibility that language technologies -- typically trained on \"standard\" native language -- are systematically biased in ways that render them less useful for the majority of users.  This project will develop methods to examine large datasets of fluent nonnative language to detect the subtle influences of the native language and deliver natural language processing (NLP) tools for these language varieties. Its methods will be applicable beyond the populations in this study, including NLP-based measurement for social science and research seeking to better understand cognition in the bilingual mind. Native language identification will enable potential applications in language learning, cybersecurity, geolocation, personalization, and more. The project will openly share implementations and data, and will include educational activities that bring research into education.\r\n\r\nThis project will advance natural language processing techniques to shed light on the differences in language use by fluent speakers with varying linguistic backgrounds:  native speakers, highly fluent nonnative speakers, and translators when translating from another language into English.  It is known that classifiers can be trained to discriminate with high accuracy among these populations, even though humans have difficulty telling them apart. This project will focus on semantic phenomena, which can confound even fluent nonnative speakers. If current NLP models are biased toward native language, then they may not support accurate measurement in nonnative text; the project will develop new techniques to mitigate this bias. This project will deliver a range of new models for native language identification, new measurement models and multi-variety models for language-variety-aware NLP tools, new semantic annotations in several Englishes, and a study on nonnative annotation.  These novel methods for studying variation within a language and building such variation into our NLP systems will lead to unprecedented flexibility in computational models of natural language semantics.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yulia",
   "pi_last_name": "Tsvetkov",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yulia Tsvetkov",
   "pi_email_addr": "yuliats@cs.washington.edu",
   "nsf_id": "000728441",
   "pi_start_date": "2018-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 166000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The primary goal of the 2-year project was to create Natural Language Processing (NLP) tools for non-native speakers of English&mdash;a large portion of the world's population.&nbsp;</p>\n<p>Specifically, the project developed (1) new approaches to characterize text data produced by fluent non-native speakers of English, (2) new approaches to detect and mitigate bias in current methods, particularly focusing on bias against underrepresented populations such as non-native speakers, and (3) new robust massively multilingual NLP models that can effectively and equitably process fine-grained varieties of English. These techniques are powered by machine learning and incorporate linguistics and sociolinguistic knowledge in novel ways, enabling socially inclusive NLP tools that attain good performance on low-resource language varieties and dialects spoken by underrepresented populations.</p>\n<p>Scientific publications supported by the project include 16 journal and conference publications in top NLP venues.&nbsp; The publications were accompanied with open-source implementations of all the published results and newly constructed data resources. These works have opened novel research avenues, including natural language processing for fluent non-native language varieties, language generation with continuous output spaces, interpretability and deconfounding of deep learning NLP models via influence functions, incorporating code-switching in written dialogues, and others.</p>\n<p>This project also produced publications and educational materials that have attracted the attention of the research community to the problem of bias in NLP datasets and tools. It showed that current widely-used systems suffer from lower recall and inferior performance on texts produced by underrepresented populations and proposed approaches to alleviate social disparities in NLP systems.</p>\n<p>This project supported professional development of several junior researchers, including members of underrepresented populations, thereby promoting diversity in STEM.</p>\n<p>Educational materials produced and disseminated through this funding have been publicly released, and a new graduate course developed in this project has been adopted by several institution. The course focuses on the topics of social good, teaching the student to develop NLP technologies that will serve millions of speakers of low-resource languages, and to develop socially equitable NLP technologies that perform equally well for speakers of diverse populations. These scientific and educational contributions pave the way towards combating ethical challenges in AI tools used by millions of citizens.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/15/2021<br>\n\t\t\t\t\tModified by: Yulia&nbsp;Tsvetkov</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe primary goal of the 2-year project was to create Natural Language Processing (NLP) tools for non-native speakers of English&mdash;a large portion of the world's population. \n\nSpecifically, the project developed (1) new approaches to characterize text data produced by fluent non-native speakers of English, (2) new approaches to detect and mitigate bias in current methods, particularly focusing on bias against underrepresented populations such as non-native speakers, and (3) new robust massively multilingual NLP models that can effectively and equitably process fine-grained varieties of English. These techniques are powered by machine learning and incorporate linguistics and sociolinguistic knowledge in novel ways, enabling socially inclusive NLP tools that attain good performance on low-resource language varieties and dialects spoken by underrepresented populations.\n\nScientific publications supported by the project include 16 journal and conference publications in top NLP venues.  The publications were accompanied with open-source implementations of all the published results and newly constructed data resources. These works have opened novel research avenues, including natural language processing for fluent non-native language varieties, language generation with continuous output spaces, interpretability and deconfounding of deep learning NLP models via influence functions, incorporating code-switching in written dialogues, and others.\n\nThis project also produced publications and educational materials that have attracted the attention of the research community to the problem of bias in NLP datasets and tools. It showed that current widely-used systems suffer from lower recall and inferior performance on texts produced by underrepresented populations and proposed approaches to alleviate social disparities in NLP systems.\n\nThis project supported professional development of several junior researchers, including members of underrepresented populations, thereby promoting diversity in STEM.\n\nEducational materials produced and disseminated through this funding have been publicly released, and a new graduate course developed in this project has been adopted by several institution. The course focuses on the topics of social good, teaching the student to develop NLP technologies that will serve millions of speakers of low-resource languages, and to develop socially equitable NLP technologies that perform equally well for speakers of diverse populations. These scientific and educational contributions pave the way towards combating ethical challenges in AI tools used by millions of citizens.\n\n\t\t\t\t\tLast Modified: 01/15/2021\n\n\t\t\t\t\tSubmitted by: Yulia Tsvetkov"
 }
}