{
 "awd_id": "1818726",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Stochastic Methods for Complex Systems",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leland Jameson",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 99970.0,
 "awd_amount": 99970.0,
 "awd_min_amd_letter_date": "2018-07-26",
 "awd_max_amd_letter_date": "2018-07-26",
 "awd_abstract_narration": "This project addresses computational challenges in materials science, chemistry, uncertainty quantification, and related fields.  Quantities of interest such as chemical reaction rates, strength of alloys, and more, can be estimated using a common mathematical modeling framework that computes mean values and provides quantification of the variance about the means.  Estimating these quantities by computer simulation can be particularly challenging when the property that one wishes to study is rare and many repeated computer simulations would be required to estimate the mean value and the variance.  While this challenge is somewhat alleviated by growth in computing power, some simulations, including chemical reaction rates, cannot be addressed via brute force computation.  Rather than rely on raw computing power, the investigators intend to develop novel computer algorithms and approximations that will allow for more efficient and more accurate predictions.  This includes the use of interacting copies of mathematical models, which communicate information between one another, resulting in higher quality estimates.  These algorithms and approximations will allow more faithful prediction of quantities of interest and access to bigger models (such as larger, more complicated molecules).  Mathematically the project will provide a rigorous understanding of the computer algorithms, providing confidence to scientists in a variety of fields. \r\n \r\nMultiscale distributions appear in a variety of applications, including materials science, chemistry, and uncertainty quantification.  Given efficient sampling strategies, one can compute a variety of quantities of interest, including ensemble averages, mean first passage times, and probabilities of rare events.  However, multiscale distributions in high number of dimensions are particularly challenging to sample.  One example is the Boltzmann distribution induced by an energy landscape containing superbasins.  Such a landscape features clusters of local minima that correspond to close groupings of modes in the distribution.  This project will investigate four sampling algorithms: weighted ensemble sampling, parallel replica dynamics, local entropy smoothing, and piecewise deterministic Markov processes.  Weighted ensemble sampling partitions state space into bins and then elects to sample within those bins in an optimal way.  The project will investigate the choice of the sample allocation strategy and consider both finite and infinite system size limits for the method.  Parallel replica dynamics also involves using an ensemble of samples, but, in contrast to weighted ensemble, it uses the replicas to efficiently find first exits out of one metastable region and into another.  Local entropy smoothing removes the superbasin features of the energy landscape by performing local ensemble sampling and averaging.  Finally, the investigators will use piecewise deterministic Markov processes to perform rejection free sampling without requiring estimates of gradients.  These algorithms will be rigorously analyzed, and they will be tested on a variety of realistic high-dimensional problems including chemical reaction networks and stochastic molecular dynamics.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Aristoff",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Aristoff",
   "pi_email_addr": "aristoff@rams.colostate.edu",
   "nsf_id": "000688007",
   "pi_start_date": "2018-07-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Colorado State University",
  "inst_street_address": "601 S HOWES ST",
  "inst_street_address_2": "",
  "inst_city_name": "FORT COLLINS",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "9704916355",
  "inst_zip_code": "805212807",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "COLORADO STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "LT9CXX8L19G1"
 },
 "perf_inst": {
  "perf_inst_name": "Colorado State University",
  "perf_str_addr": "200 W. Lake Street",
  "perf_city_name": "Fort Collins",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "805214593",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 99970.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project involved basic research into computational methods for simulating complex dynamics.&nbsp;<br /><br />One important application is in computer-aided drug design. The interactions of pharmaceutical drugs with molecules in the body can be explained by very complicated equations. These equations lead to ``molecular dynamics'' which may be simulated on a computer, and can, in principle, mimic what actually happens in the human body. This approach, if brought to scale, could lead to astonishing capabilities in drug design.&nbsp;<br /><br />For example, a drug works by binding with a particular protein in the body. The time it takes to eventually unbind is important for evaluating effectiveness, longevity, side effects, and so on.<br /><br />Applications extend far beyond chemistry. Difficult problems in many scientific fields lead to the same point: where it becomes necessary to simulate some very complicated dynamics. Another example comes from machine learning, where training an ``artificial intelligence'' (AI) can require simulating dynamics from equations related to the (complex) AI architecture.<br /><br />A major obstacle to the naive approach of just simulating the dynamics is that it takes far too long. For example, each discrete step of a molecular dynamics model corresponds to about one in a quadrillionth of a second of time. So, one quadrillion discrete steps are needed to simulate what happens within the human body for about one second. In real time, this can take weeks, years, or longer, depending on the complexity of the model.<br /><br />This project largely focused on ``evolutionary algorithms,'' in which many replicas are simulated, and periodically, replicas that are ``valuable'' are copied, while less valuable replicas are killed. For example, if we wish to simulate a particular biological event -- like the unbinding of a drug from a protein -- then we might say that valuable replicas are ones that get ever closer to the desired event. Replicas can be simulated in parallel, which is a big upside.<br /><br />(We also focus on a particular type of dynamics, in which whatever happens in the next discrete step depends only on the system's current state. Most molecular dynamics models have this form.)<br /><br />Such evolutionary algorithms have been widely used for the last 20 years or so. We focused on one algorithm, ``weighted ensemble,'' that so far has received little attention but has three very important features. First, it can exactly compute average dynamical quantities -- like the mean unbinding time of a drug from a protein. Second, it is the only such method that can give reliable results over long times. Third, it has no major disadvantages compared to other evolutionary algorithms.&nbsp;<br /><br />We gave the first mathematical proofs of the first two features above, and justified the third feature through an optimization analysis. This analysis also showed, for the first time, what the best measure of ``valuable'' is for any given system, as well as how best to copy and kill replicas. The ``no free lunch'' principle obviously applies: in complex systems, the optimal value metric is also very complex. It can be approximated, however, by standard techniques.<br /><br />Our ideas lead to practical techniques, guided by what the math shows is optimal. Our preliminary results show that these techniques can lead to speedups of orders of magnitude -- so, instead of simulating what happens in the body for one second, we can get to minutes or hours, without needing more (real) time to simulate the molecular dynamics model.<br /><br />Our results and techniques have now been published in several peer-reviewed articles. We also developed open-source code that implements our techniques on systems of moderate complexity. This code is more flexible than the main weighted ensemble codebase, so it can more readily handle the various optimization procedures we have proposed.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2021<br>\n\t\t\t\t\tModified by: David&nbsp;Aristoff</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project involved basic research into computational methods for simulating complex dynamics. \n\nOne important application is in computer-aided drug design. The interactions of pharmaceutical drugs with molecules in the body can be explained by very complicated equations. These equations lead to ``molecular dynamics'' which may be simulated on a computer, and can, in principle, mimic what actually happens in the human body. This approach, if brought to scale, could lead to astonishing capabilities in drug design. \n\nFor example, a drug works by binding with a particular protein in the body. The time it takes to eventually unbind is important for evaluating effectiveness, longevity, side effects, and so on.\n\nApplications extend far beyond chemistry. Difficult problems in many scientific fields lead to the same point: where it becomes necessary to simulate some very complicated dynamics. Another example comes from machine learning, where training an ``artificial intelligence'' (AI) can require simulating dynamics from equations related to the (complex) AI architecture.\n\nA major obstacle to the naive approach of just simulating the dynamics is that it takes far too long. For example, each discrete step of a molecular dynamics model corresponds to about one in a quadrillionth of a second of time. So, one quadrillion discrete steps are needed to simulate what happens within the human body for about one second. In real time, this can take weeks, years, or longer, depending on the complexity of the model.\n\nThis project largely focused on ``evolutionary algorithms,'' in which many replicas are simulated, and periodically, replicas that are ``valuable'' are copied, while less valuable replicas are killed. For example, if we wish to simulate a particular biological event -- like the unbinding of a drug from a protein -- then we might say that valuable replicas are ones that get ever closer to the desired event. Replicas can be simulated in parallel, which is a big upside.\n\n(We also focus on a particular type of dynamics, in which whatever happens in the next discrete step depends only on the system's current state. Most molecular dynamics models have this form.)\n\nSuch evolutionary algorithms have been widely used for the last 20 years or so. We focused on one algorithm, ``weighted ensemble,'' that so far has received little attention but has three very important features. First, it can exactly compute average dynamical quantities -- like the mean unbinding time of a drug from a protein. Second, it is the only such method that can give reliable results over long times. Third, it has no major disadvantages compared to other evolutionary algorithms. \n\nWe gave the first mathematical proofs of the first two features above, and justified the third feature through an optimization analysis. This analysis also showed, for the first time, what the best measure of ``valuable'' is for any given system, as well as how best to copy and kill replicas. The ``no free lunch'' principle obviously applies: in complex systems, the optimal value metric is also very complex. It can be approximated, however, by standard techniques.\n\nOur ideas lead to practical techniques, guided by what the math shows is optimal. Our preliminary results show that these techniques can lead to speedups of orders of magnitude -- so, instead of simulating what happens in the body for one second, we can get to minutes or hours, without needing more (real) time to simulate the molecular dynamics model.\n\nOur results and techniques have now been published in several peer-reviewed articles. We also developed open-source code that implements our techniques on systems of moderate complexity. This code is more flexible than the main weighted ensemble codebase, so it can more readily handle the various optimization procedures we have proposed.\n\n\t\t\t\t\tLast Modified: 11/29/2021\n\n\t\t\t\t\tSubmitted by: David Aristoff"
 }
}