{
 "awd_id": "1763540",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF: Medium: Collaborative Research: ECC: Ephemeral Coherence Cohort for I/O Containerization and Disaggregation",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2018-06-01",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2018-05-21",
 "awd_max_amd_letter_date": "2019-09-09",
 "awd_abstract_narration": "Leadership computing facilities for high-performance computing (HPC) have a huge investment in the file and storage systems. The reason is that the HPC storage system often is the Achilles Heel of HPC systems, as it is fraught with numerous scenarios for contention, congestion and performance variability. This problem is getting worse due to: (a) the increased importance of data-driven HPC and the growth in the amount of data generated by large-scale simulation; and (b) the slower growth of disk speed, as compared to CPU speed. The addition of high-bandwidth persistent memory devices as burst-buffers brings in new opportunities for fast caching of application data while still allowing data persistence. However, the conventional approach of exploiting burst-buffers as yet another caching layer cannot reduce the lengthy and costly data processing steps in the deep I/O stack or reconcile occasional contentions inside the complex storage system. This project, therefore, seeks to exploit burst-buffers as repositories of persistent application-specific parallel file systems, with a lifetime commensurate to the lifetime of an application or an application campaign on a HPC system. This is a collaborative project between University of Illinois at Urbana-Champaign and Florida State University. \r\n\r\nThis project formulates a research framework called Ephemeral Coherence Cohort (ECC) that offers an abstraction to represent the active collection of application data through containerization, insulate I/O activities across different applications, and enable storage disaggregation for ephemeral allocation and dynamic utilization of burst buffers. The proposed ECC framework aims to enhance a variety of mission-critical applications running on the Department of Energy and the National Science Foundation leadership computing facilities. The project strengthens the collaboration between University of Illinois Urbana-Champaign and the Florida State University. The project has plans to organize panels and birds-of-feather sessions on burst buffer research in the upcoming HPC conferences and collaborate with leaders of super-computing centers for wider community penetration with techniques from this research.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Marc",
   "pi_last_name": "Snir",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Marc Snir",
   "pi_email_addr": "snir@illinois.edu",
   "nsf_id": "000165753",
   "pi_start_date": "2018-05-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Franck",
   "pi_last_name": "Cappello",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Franck Cappello",
   "pi_email_addr": "cappello@uchicago.edu",
   "nsf_id": "000595076",
   "pi_start_date": "2018-05-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "201 N Goodwin",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618012302",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 328846.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 171154.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>While the performance of High-Performance Computing (HPC) platforms continues to increase, the performance of storage systems has a hard time to keep up. HPC storage traditionally consists of separate racks containing storage servers and disks. Those are configured as a Parallel File System (PFS) that is accessed by all jobs running on the machine. This is now increasingly augmented with local storage ? local Solid-State Drives (SSDs) that are directly attached to the compute nodes in the system. An increasingly common way of using such ?burst buffers? is to install on them a <em>burst buffer file system</em>. When a set of nodes is allocated to run a batch job, the attached SSDs are configured as a file system dedicated to the application that persists until the job completes. Since such file system is dedicated to one application it is possible to configure it in a way that best matches the application?s needs.</p>\n<p>One major performance bottleneck for PFSs is the <em>strong consistency</em> POSIX semantics that they usually provide: A write by any process must be visible to a read of any other process if the read succeeds the write and both access the same file location. This requires a complex and expensive coherence protocol. Typically, the writer must lock the locations it intends to write, and the reader must acquire the lock before reading these file locations. This can become a bottleneck with hundreds of storage servers. Our research started with the hypothesis that this expensive protocol is not necessary in the applications typically run on supercomputers. We tested this hypothesis by running and tracing the IO operations of 17 representative HPC codes and found only one where a process overwrites a location written by another (Write-After-Write conflict). The conflict could be removing by altering one line of code, without affecting the code behavior. As part of this study, we developed efficient tools for tracing the IO operations of applications and verifying whether confliction IO operations occur and, if so, whether the two conflicting processes properly synchronize to ensure that the conflicting accesses occur in the proper order (e.g., write before read). We next defined two weaker IO consistency models, <em>commit semantic</em>s and <em>session semantics</em>, that seem appropriate for HPC applications. In commit semantics, a writer needs to execute a commit operation after the write and before any other process read the written locations. In session semantics, the writer must close the file session after the write and the reader must open the file session after the session close and before the read. We built a <em>tunable parallel file system </em>that can be configured to support either model, or POSIX semantics. The system, named Tangram, supports lower-level IO primitives that can be combined to implement the desired model. We used Tangram to study to cost of supporting the different models, for different IO access patterns.</p>\n<p>We hope that our work will help standardizing file consistency models that are weaker than the POSIX model and will help implementing such models in burst buffer file systems.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/08/2023<br>\n\t\t\t\t\tModified by: Marc&nbsp;Snir</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhile the performance of High-Performance Computing (HPC) platforms continues to increase, the performance of storage systems has a hard time to keep up. HPC storage traditionally consists of separate racks containing storage servers and disks. Those are configured as a Parallel File System (PFS) that is accessed by all jobs running on the machine. This is now increasingly augmented with local storage ? local Solid-State Drives (SSDs) that are directly attached to the compute nodes in the system. An increasingly common way of using such ?burst buffers? is to install on them a burst buffer file system. When a set of nodes is allocated to run a batch job, the attached SSDs are configured as a file system dedicated to the application that persists until the job completes. Since such file system is dedicated to one application it is possible to configure it in a way that best matches the application?s needs.\n\nOne major performance bottleneck for PFSs is the strong consistency POSIX semantics that they usually provide: A write by any process must be visible to a read of any other process if the read succeeds the write and both access the same file location. This requires a complex and expensive coherence protocol. Typically, the writer must lock the locations it intends to write, and the reader must acquire the lock before reading these file locations. This can become a bottleneck with hundreds of storage servers. Our research started with the hypothesis that this expensive protocol is not necessary in the applications typically run on supercomputers. We tested this hypothesis by running and tracing the IO operations of 17 representative HPC codes and found only one where a process overwrites a location written by another (Write-After-Write conflict). The conflict could be removing by altering one line of code, without affecting the code behavior. As part of this study, we developed efficient tools for tracing the IO operations of applications and verifying whether confliction IO operations occur and, if so, whether the two conflicting processes properly synchronize to ensure that the conflicting accesses occur in the proper order (e.g., write before read). We next defined two weaker IO consistency models, commit semantics and session semantics, that seem appropriate for HPC applications. In commit semantics, a writer needs to execute a commit operation after the write and before any other process read the written locations. In session semantics, the writer must close the file session after the write and the reader must open the file session after the session close and before the read. We built a tunable parallel file system that can be configured to support either model, or POSIX semantics. The system, named Tangram, supports lower-level IO primitives that can be combined to implement the desired model. We used Tangram to study to cost of supporting the different models, for different IO access patterns.\n\nWe hope that our work will help standardizing file consistency models that are weaker than the POSIX model and will help implementing such models in burst buffer file systems.\n\n \n\n\t\t\t\t\tLast Modified: 10/08/2023\n\n\t\t\t\t\tSubmitted by: Marc Snir"
 }
}