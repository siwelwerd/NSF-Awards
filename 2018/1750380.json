{
 "awd_id": "1750380",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: A collaboration coach with effective intervention strategies to optimize group performance.",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922971",
 "po_email": "sroberts@nsf.gov",
 "po_sign_block_name": "Scott Robertson",
 "awd_eff_date": "2018-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 511453.0,
 "awd_amount": 623453.0,
 "awd_min_amd_letter_date": "2018-03-23",
 "awd_max_amd_letter_date": "2023-04-06",
 "awd_abstract_narration": "Many employees question the effectiveness of workplace meetings, despite their importance to collaborative decision-making.  Sometimes attendees have trouble staying focused, or else one individual dominates the conversation; in both cases, productivity is down.  The ability to conduct a meeting and foster effective participation by all is influenced by subjective and unquantifiable factors such as relationship dynamics, gender biases, and willingness to accept criticism.  This research will explore whether it may be possible to avoid these complications by using an impersonal entity - the computer - to conduct group meetings and provide both live and post-meeting feedback that enables participants to stay on topic, take part equally, and listen closely to one another, all while generating analytics about the process.  The framework that will be developed in this research may serve as a tool for improving meeting efficiency and effectiveness, while opening up the possibility of designing interventions for individuals with Asperger syndrome or social phobia who find it difficult to assert themselves in group settings.  Providing live feedback during a meeting will require real-time recognition and analysis of the sensed data, but live feedback is only valuable when its interpretation does not impose a cognitive overload on the participants. This research will make contributions on designing live feedback that is effective yet not distractive.  Project findings will also be applicable in the context of online learning, where a computer facilitator could engage every student equally.  In addition to standardized test scores, computers can also create objective analytics on, for example, students' ability to ask questions, participate effectively and maintain a positive attitude.  Recognizing students for their effort may positively impact their scores.  Project findings may help virtual assistants (such as Alexa or Google Home) mediate conversations with appropriate and respectful intervention strategies, and in addition they may yield insights into the role played by gender and racial diversity in improving team performance.  \r\n\r\nThe interplay of human behaviors (e.g., facial expression, tone of voice, language, interruptions, participation rates, and turn-taking) is considered subtle, sometimes contradictory, and often confusing.  These behaviors can be highly individual-specific, and may require temporal modeling with real-time performance if they are to be harnessed automatically for effective meeting mediation.  While the raw sensed numbers are useful when developing algorithm benchmarks, they add very little value for users.  This research will use principles of human centric computing to visualize, interpret and reveal insights from raw behavioral data.  In particular, the following research questions will be addressed using human-centric approaches in the context of online video conferencing: 1) What possible mediation strategies exist that avoid being disruptive and disrespectful to human participants; 2) Which is most helpful: live feedback, post-meeting feedback, a combination of both, or no feedback at all; 3) Can we implement an automated process to facilitate meeting productivity; and 4) Does feedback improve group performance in any measurable way?\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ehsan",
   "pi_last_name": "Hoque",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ehsan Hoque",
   "pi_email_addr": "mehoque@cs.rochester.edu",
   "nsf_id": "000654070",
   "pi_start_date": "2018-03-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146270140",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 122332.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 118068.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 134586.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 114797.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 117670.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project, funded by the National Science Foundation, explored how collaboration can be enhanced in group settings using technology, focusing on creativity and performance in social networks. The outcomes emphasize the intellectual merit of advancing human-computer interaction and understanding group dynamics, alongside broader societal impacts on teamwork and innovation.</p>\r\n<h3>Key Findings and Intellectual Merit:</h3>\r\n<ol>\r\n<li>\r\n<p><strong>Understanding Group Dynamics</strong>: We developed a unique video-conferencing platform, CoCo (Collaboration Coach), to analyze group conversations in real-time. By examining turn-taking, interruptions, gestures, and language use, we uncovered patterns in effective communication.</p>\r\n</li>\r\n<li>\r\n<p><strong>Enhancing Creativity</strong>: Through experiments in creativity-centric social networks, we demonstrated how demographic and performance cues influence idea generation. We found that balancing visibility among contributors fosters innovation by reducing redundancy without diluting idea quality.</p>\r\n</li>\r\n<li>\r\n<p><strong>Intervention Strategies</strong>: Implicit and explicit interventions were tested to guide participants in choosing inspiration sources. Implicit interventions using popularity signals elevated creativity, while explicit recommendations optimized collaboration.</p>\r\n</li>\r\n<li>\r\n<p><strong>Technological Innovations</strong>: The project integrated findings into practical tools like MeetingCoach, enhancing inclusivity and productivity in online and hybrid meetings.</p>\r\n</li>\r\n</ol>\r\n<h3>Broader Impacts:</h3>\r\n<ol>\r\n<li>\r\n<p><strong>Applications in Education and Workforce</strong>: The developed methods provide scalable solutions for improving teamwork in classrooms and workplaces, fostering skills like creativity and effective communication.</p>\r\n</li>\r\n<li>\r\n<p><strong>Inclusion and Equity</strong>: By addressing biases linked to gender and race cues in networks, this research promotes equitable collaboration.</p>\r\n</li>\r\n<li>\r\n<p><strong>Future of Work</strong>: As automation reduces manual labor demand, the project's insights help prepare individuals for creativity-driven roles, ensuring better adaptation to the evolving job market.</p>\r\n</li>\r\n</ol>\r\n<h3>Training and Dissemination:</h3>\r\n<ul>\r\n<li>Graduate and undergraduate students actively contributed, gaining skills in data analysis, experimental design, and machine learning.</li>\r\n<li>Research findings were shared through peer-reviewed journals, conferences, and public platforms, ensuring wide accessibility and impact.</li>\r\n</ul>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/01/2024<br>\nModified by: Ehsan&nbsp;Hoque</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1750380/1750380_10535875_1733045760508_2024_12_01_12_32_41--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1750380/1750380_10535875_1733045760508_2024_12_01_12_32_41--rgov-800width.png\" title=\"MIA: Motivational Interviewing Agent for Improving Conversational Skills in Remote Group Discussions\"><img src=\"/por/images/Reports/POR/2024/1750380/1750380_10535875_1733045760508_2024_12_01_12_32_41--rgov-66x44.png\" alt=\"MIA: Motivational Interviewing Agent for Improving Conversational Skills in Remote Group Discussions\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The project created chatbots with and without Motivational Interviewing strategies. \"MIA\" uses open-ended and menu-based responses to enhance user interaction, while \"Roboto\" relies solely on menu-based options, focusing on informative guidance.</div>\n<div class=\"imageCredit\">S. Samrose, E. Hoque, Suggestive Motivational Interviewing Agent for Remote Group Discussion, ACM International Conference on Supporting Group Work (Group 22), Jan 2022.</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Ehsan&nbsp;Hoque\n<div class=\"imageTitle\">MIA: Motivational Interviewing Agent for Improving Conversational Skills in Remote Group Discussions</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1750380/1750380_10535875_1733045861663_coco--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1750380/1750380_10535875_1733045861663_coco--rgov-800width.png\" title=\"Collaboration Coach (CoCo)\"><img src=\"/por/images/Reports/POR/2024/1750380/1750380_10535875_1733045861663_coco--rgov-66x44.png\" alt=\"Collaboration Coach (CoCo)\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">(Left) Video Conferencing System, (Right) Feedback Interface</div>\n<div class=\"imageCredit\">S. Samrose, R. Zhao, J. White, V. Li, L. Nova, Y. Lu, M. R. Ali, M. E. Hoque, CoCo: Collaboration Coach for Understanding Team Dynamics during Video Conferencing, PACM on Interactive, Mobile, Wearable, and Ubiquitous Computing (IMWUT)</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ehsan&nbsp;Hoque\n<div class=\"imageTitle\">Collaboration Coach (CoCo)</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project, funded by the National Science Foundation, explored how collaboration can be enhanced in group settings using technology, focusing on creativity and performance in social networks. The outcomes emphasize the intellectual merit of advancing human-computer interaction and understanding group dynamics, alongside broader societal impacts on teamwork and innovation.\r\nKey Findings and Intellectual Merit:\r\n\r\n\r\n\n\nUnderstanding Group Dynamics: We developed a unique video-conferencing platform, CoCo (Collaboration Coach), to analyze group conversations in real-time. By examining turn-taking, interruptions, gestures, and language use, we uncovered patterns in effective communication.\r\n\r\n\r\n\n\nEnhancing Creativity: Through experiments in creativity-centric social networks, we demonstrated how demographic and performance cues influence idea generation. We found that balancing visibility among contributors fosters innovation by reducing redundancy without diluting idea quality.\r\n\r\n\r\n\n\nIntervention Strategies: Implicit and explicit interventions were tested to guide participants in choosing inspiration sources. Implicit interventions using popularity signals elevated creativity, while explicit recommendations optimized collaboration.\r\n\r\n\r\n\n\nTechnological Innovations: The project integrated findings into practical tools like MeetingCoach, enhancing inclusivity and productivity in online and hybrid meetings.\r\n\r\n\r\nBroader Impacts:\r\n\r\n\r\n\n\nApplications in Education and Workforce: The developed methods provide scalable solutions for improving teamwork in classrooms and workplaces, fostering skills like creativity and effective communication.\r\n\r\n\r\n\n\nInclusion and Equity: By addressing biases linked to gender and race cues in networks, this research promotes equitable collaboration.\r\n\r\n\r\n\n\nFuture of Work: As automation reduces manual labor demand, the project's insights help prepare individuals for creativity-driven roles, ensuring better adaptation to the evolving job market.\r\n\r\n\r\nTraining and Dissemination:\r\n\r\nGraduate and undergraduate students actively contributed, gaining skills in data analysis, experimental design, and machine learning.\r\nResearch findings were shared through peer-reviewed journals, conferences, and public platforms, ensuring wide accessibility and impact.\r\n\r\n\n\n\t\t\t\t\tLast Modified: 12/01/2024\n\n\t\t\t\t\tSubmitted by: EhsanHoque\n"
 }
}