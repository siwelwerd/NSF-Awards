{
 "awd_id": "1823276",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRI: II-New: Cognitive Mechanisms and Computational Modeling of Gaze Control During Scene Free Viewing, Visual Search, and Daily Tasks",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 249277.0,
 "awd_amount": 249277.0,
 "awd_min_amd_letter_date": "2018-08-07",
 "awd_max_amd_letter_date": "2018-08-22",
 "awd_abstract_narration": "This project is to build an infrastructure to study visual attention and its applications at the University of Central Florida. The infrastructure will also enable larger-scale inquiries into high-level visual recognition problems in the vision sciences. The infrastructure of fixed and portable eye trackers will be used by several faculty and researchers across the University (e.g., Computer Science, Engineering and Computer Engineering, Psychology, Biomedical engineering and UCF Institute for Simulation and Training) to study human perception, cognition, learning, and motor control, as well as exploring applications in activity recognition, surveillance, and data summarization. \r\n\r\nThe core goal of this infrastructure is to utilize gaze and eye tracking technology to understand mechanisms of attention from behavioral, neurophysiological, and computational perspectives and explore its applications in a wide range of problems in computer vision and psychology. The team utilizing the infrastructure has complementary expertise to address research encompassing computer vision, machine learning, human vision, imaging, and psychology. In particular, this infrastructure will be used to explore in what ways current attention models fail, how to remedy them, and discover new cues that attract gaze. The approach is a combination of cognitive and computational studies utilizing machine learning and computer vision techniques. New large-scale eye movement datasets and benchmarks will be constructed as part of this proposal.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mubarak",
   "pi_last_name": "Shah",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mubarak Shah",
   "pi_email_addr": "shah@crcv.ucf.edu",
   "nsf_id": "000318379",
   "pi_start_date": "2018-08-22",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Ali",
   "pi_last_name": "Borji",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ali Borji",
   "pi_email_addr": "ali.borji@ucf.edu",
   "nsf_id": "000728033",
   "pi_start_date": "2018-08-07",
   "pi_end_date": "2018-08-22"
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Mubarak",
   "pi_last_name": "Shah",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mubarak Shah",
   "pi_email_addr": "shah@crcv.ucf.edu",
   "nsf_id": "000318379",
   "pi_start_date": "2018-08-07",
   "pi_end_date": "2018-08-22"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Neider",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Mark B Neider",
   "pi_email_addr": "Mark.Neider@ucf.edu",
   "nsf_id": "000633674",
   "pi_start_date": "2018-08-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ulas",
   "pi_last_name": "Bagci",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ulas Bagci",
   "pi_email_addr": "ulas.bagci@northwestern.edu",
   "nsf_id": "000693268",
   "pi_start_date": "2018-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "The University of Central Florida Board of Trustees",
  "inst_street_address": "4000 CENTRAL FLORIDA BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "ORLANDO",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "4078230387",
  "inst_zip_code": "328168005",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "FL10",
  "org_lgl_bus_name": "THE UNIVERSITY OF CENTRAL FLORIDA BOARD OF TRUSTEES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RD7MXJV7DKT9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Central Florida",
  "perf_str_addr": "4000 Central Florida Blvd.",
  "perf_city_name": "Orlado",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "328162365",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "FL10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 249277.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The equipment support through this award has allowed us to develop new insights regarding how oculomotor attention informs real world behavior.&nbsp; At a more basic level, we have learned that attentional control mechanisms are sensitive to information at the categorical level; if an observer is asked to search for a teddy bear, they are able to suppress objects that do not conform to a typical representation of a teddy bear.&nbsp; Form information appears to be particularly important to attentional processes in this regard.&nbsp; At a more practical level, we have begun investigating whether eye movements correlate to accurate classification of phishing emails, with the longer term goal of developing an online measure of cyber-performance that would track a user&rsquo;s eye movements in real time and inform the user if their eye movement patterns suggest potential vulnerability.</p>\n<p>In addition, we have developed new machine learning methods where we were able to include experts in the loop for semantic-decisions. We have applied our new algorithms to radiology field and showed it is possible to make the machine generated results feasible and interpretable. For basic radiology applications, such as delineation and detection of pathological regions, and their class label determination (aggressive vs benign) were possible and easier with the technology we used (eye-tracking, nearly real time use). Our research findings were presented in different venues, most recently in one of the top medical AI venue, Radiology AI (attached PDF), where we have used eye tracking to segment important organs or pathological regions with true attention mechanism, which are coming from experts&rsquo; eye movement and gaze information. Similarly, we extend this idea to other fields, where we used civil engineering applications (infrastructure damage quantification), and extended our algorithms to work on mixed reality systems (instead of eye tracking technology). Next, we will investigate other high-risk fields where we can integrate mixed reality systems (HoloLens) or eye tracking systems in the application as a part of trustable machine learning algorithms. Examples will include surgery room experience as well as real time colonoscopy and endoscopy applications.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/16/2021<br>\n\t\t\t\t\tModified by: Mubarak&nbsp;Shah</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe equipment support through this award has allowed us to develop new insights regarding how oculomotor attention informs real world behavior.  At a more basic level, we have learned that attentional control mechanisms are sensitive to information at the categorical level; if an observer is asked to search for a teddy bear, they are able to suppress objects that do not conform to a typical representation of a teddy bear.  Form information appears to be particularly important to attentional processes in this regard.  At a more practical level, we have begun investigating whether eye movements correlate to accurate classification of phishing emails, with the longer term goal of developing an online measure of cyber-performance that would track a user\u2019s eye movements in real time and inform the user if their eye movement patterns suggest potential vulnerability.\n\nIn addition, we have developed new machine learning methods where we were able to include experts in the loop for semantic-decisions. We have applied our new algorithms to radiology field and showed it is possible to make the machine generated results feasible and interpretable. For basic radiology applications, such as delineation and detection of pathological regions, and their class label determination (aggressive vs benign) were possible and easier with the technology we used (eye-tracking, nearly real time use). Our research findings were presented in different venues, most recently in one of the top medical AI venue, Radiology AI (attached PDF), where we have used eye tracking to segment important organs or pathological regions with true attention mechanism, which are coming from experts\u2019 eye movement and gaze information. Similarly, we extend this idea to other fields, where we used civil engineering applications (infrastructure damage quantification), and extended our algorithms to work on mixed reality systems (instead of eye tracking technology). Next, we will investigate other high-risk fields where we can integrate mixed reality systems (HoloLens) or eye tracking systems in the application as a part of trustable machine learning algorithms. Examples will include surgery room experience as well as real time colonoscopy and endoscopy applications. \n\n \n\n \n\n\t\t\t\t\tLast Modified: 09/16/2021\n\n\t\t\t\t\tSubmitted by: Mubarak Shah"
 }
}