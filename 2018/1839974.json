{
 "awd_id": "1839974",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FW-HTF: Collaborative Research: Enhancing Human Capabilities through Virtual Personal Embodied Assistants in Self-Contained Eyeglasses-Based Augmented Reality (AR) Systems",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032925365",
 "po_email": "jberg@nsf.gov",
 "po_sign_block_name": "Jordan Berg",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 809999.0,
 "awd_amount": 809999.0,
 "awd_min_amd_letter_date": "2018-09-13",
 "awd_max_amd_letter_date": "2018-09-13",
 "awd_abstract_narration": "The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim. \r\n\r\nThis award supports basic research underpinning development of an eyeglass-based 3D mobile telepresence system with integrated virtual personal assistant. This technology will increase worker productivity and improve skills. The system automatically adjusts visual focus and places virtual elements in the image without eye strain.  The user will be able to communicate to the system by speech.  The system also uses sensors to keep track of the user's surroundings and provide the relevant information to the user automatically.  The project will explore two of the many possible uses of the system: amplifying a workers capabilities (such as a physical therapist interacting with a remote patient), and accelerating post-injury return to work through telepresence (such as a burn victim reintegrating into his/her workplace). The project will advance the national interest by allowing the right person to be virtually in the right place at the right time. The project also includes an education and outreach component wherein undergraduate and graduate students shall receive training in engineering and research methods. Course curriculum at Stanford University and the University of North Carolina at Chapel Hill shall be updated to include project-related content and examples. \r\n\r\nThis project comprises fundamental research activities needed to develop an embodied Intelligent Cognitive Assistant (GLASS-X) that will amplify the capabilities of workers in a way that will increase productivity and improve quality of life. GLASS-X is conceived of as an eyeglass-based 3D mobile telepresence system with integrated virtual personal assistant. Methods include: body and environment reconstruction (situation awareness) from a fusion of images provided by an eyeglass frame-based camera array and limb motion data provided by inertial measurement units; fundamental research on adaptive focus displays capable to reduce eye strain when using augmented reality displays; dialog-based communication with a virtual personal assistant, including transformations from visual input to dialog and vice versa; human subject evaluations of GLASS-X technology in two workplace domains (remote interactions between a physical therapist and his/her patient; burn survivor remote return-to-work). This research promises to push the state of the art in core areas including: computer vision; augmented reality; accommodating displays; and natural language and dialogue models.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gordon",
   "pi_last_name": "Wetzstein",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gordon Wetzstein",
   "pi_email_addr": "gordon.wetzstein@stanford.edu",
   "nsf_id": "000690865",
   "pi_start_date": "2018-09-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jeremy",
   "pi_last_name": "Bailenson",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Jeremy N Bailenson",
   "pi_email_addr": "bailenso@stanford.edu",
   "nsf_id": "000158257",
   "pi_start_date": "2018-09-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "350 Serra Mall Packard Bld",
  "perf_city_name": "Palo Alto",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943054027",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "CA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "082Y00",
   "pgm_ele_name": "FW-HTF-Adv Cogn & Phys Capblty"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 809999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Augmented Reality (AR) and artificial intelligence (AI) are rapidly becoming integral parts of our society. The goal of this project was to further our understanding and knowledge of the potential of these technological revolutions by developing and evaluating core technological components needed to create GLASS-X - an eyeglasses-based 3D mobile telepresence system (3DMT) to enhance worker productivity and improve skills. To this end, we developed an immersive teleconferencing system, called Telegie, which is available for free on the Apple App Store for the iPhone. The effectiveness of this system was evaluated using extensive user studies for the purpose of physical therapy and compared with a conventional video-based system. We found that video fidelity of remote communication systems is most crucial but that the level of immersion is also important for the effectiveness of such system, determining the success of future, augmented reality-based physical therapy systems. Additionally, we have advanced several technology components of AR systems, including camera systems for scene and eye tracking, machine learning-based 3D scene representations, bandwidth-efficient rendering algorithms, and perceptually realistic and visually comfortable wearable display systems. We expect the innovations developed in this project to have a transformative impact on AR systems technologies that will form a core component of the future of work.&nbsp;</p>\n<p>In total, 33 papers were published as part of this project. These include several works published in the most prestigious journals and conferences of general science, computer graphics, compter vision, and machine learning. This project partially supported 9 PhD students, who successfully defended their dissertations and completed their PhD programs, as well as one postdoctoral researcher, who has since become an Assistant Professor at a top-tier international university. The research conducted in this program has been directly integrated into the teaching curriculum of several undergraduate and graduate-level courses at Stanford and the project has also supported continued education of industry professionals through seminar series and workshops organized as part of Stanford's Center for Image Systems Engineering, of which one of the PIs is a faculty co-director.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/02/2023<br>\n\t\t\t\t\tModified by: Gordon&nbsp;Wetzstein</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAugmented Reality (AR) and artificial intelligence (AI) are rapidly becoming integral parts of our society. The goal of this project was to further our understanding and knowledge of the potential of these technological revolutions by developing and evaluating core technological components needed to create GLASS-X - an eyeglasses-based 3D mobile telepresence system (3DMT) to enhance worker productivity and improve skills. To this end, we developed an immersive teleconferencing system, called Telegie, which is available for free on the Apple App Store for the iPhone. The effectiveness of this system was evaluated using extensive user studies for the purpose of physical therapy and compared with a conventional video-based system. We found that video fidelity of remote communication systems is most crucial but that the level of immersion is also important for the effectiveness of such system, determining the success of future, augmented reality-based physical therapy systems. Additionally, we have advanced several technology components of AR systems, including camera systems for scene and eye tracking, machine learning-based 3D scene representations, bandwidth-efficient rendering algorithms, and perceptually realistic and visually comfortable wearable display systems. We expect the innovations developed in this project to have a transformative impact on AR systems technologies that will form a core component of the future of work. \n\nIn total, 33 papers were published as part of this project. These include several works published in the most prestigious journals and conferences of general science, computer graphics, compter vision, and machine learning. This project partially supported 9 PhD students, who successfully defended their dissertations and completed their PhD programs, as well as one postdoctoral researcher, who has since become an Assistant Professor at a top-tier international university. The research conducted in this program has been directly integrated into the teaching curriculum of several undergraduate and graduate-level courses at Stanford and the project has also supported continued education of industry professionals through seminar series and workshops organized as part of Stanford's Center for Image Systems Engineering, of which one of the PIs is a faculty co-director. \n\n \n\n\t\t\t\t\tLast Modified: 01/02/2023\n\n\t\t\t\t\tSubmitted by: Gordon Wetzstein"
 }
}