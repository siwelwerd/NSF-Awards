{
 "awd_id": "1821074",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Improving Particle Filter Performance in Spatially-Extended Problems Using Generalized Random Field Likelihoods",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Pena Edsel",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 219814.0,
 "awd_amount": 219814.0,
 "awd_min_amd_letter_date": "2018-08-15",
 "awd_max_amd_letter_date": "2019-08-13",
 "awd_abstract_narration": "Ensembles of model simulations are used in a variety of fields to estimate and predict things like rain, plankton blooms, or oil well pressure. Ensembles are used to provide uncertainty quantification to the predictions: one wants to know not just the most likely estimate but also how likely this estimate is, and whether any other outcomes are likely. The main mathematical framework that underpins the rigorous use of ensembles for uncertainty quantitfication is called, for historical reasons, the 'particle filter.' Each ensemble member is a 'particle.' Unfortunately particle filters do not work well for problems in high dimensions -- a `dimension' can be loosely understood here as a location where observational data is available, not the dimensions of space and time -- since they require an astronomically large number of ensemble members. This project will develop methods to improve the performance of particle filters in problems with spatial extent, like weather forecasting. The improvement comes by reducing the effective dimensionality by smoothing the observations. For example, millions of satellite observations of the atmosphere and oceans are taken each day; the project reduces the dimensionality of this data in a manner qualitatively similar to compressing an image. Since the required ensemble size for a particle filter is exponentially sensitive to the effective dimension of the system, even a small compression of the data can lead to enormous improvements in the performance of the particle filter.\r\n\r\nThe sequential importance sampling particle filter with resampling is known to converge, in the limit of infinite ensemble size, to the Bayesian posterior of the filtering problem for dynamical systems (under mild assumptions). Unfortunately the rate of convergence is slow: the required ensemble size is exponential in the effective dimension of the system. This is prohibitive for spatially-extended problems like weather forecasting, where the effective dimension is enormous. Alternative methods like the ensemble Kalman filters are very successful in practice, but there is no rigorous analysis relating the distribution that the ensemble members represent and the true Bayesian posterior. This project aims to improve particle filter performance by reducing the effective dimensionality of the system for spatially extended problems. The true likelihood representing the relationship between the observational data and the system state is altered by smoothing the observations. This reduces the effective dimensionality of the system and is equivalent to modeling the observation error as a generalized random field. Although the particle filter converges more rapidly, it converges to a distribution that is not the true Bayesian posterior. However, the character of the error between the true and approximate posteriors is known and can be controlled to balance accuracy and cost, unlike the ensemble Kalman filters where the difference between the ensemble distribution and the true posterior is unknown and uncontrolled. The main technical goal of the project is to develop smoothing operators that can be applied to scattered spatial data in Cartesian coordinates or on the sphere. These operators need to be computationally efficient, and to allow the degree of smoothing to be tunable. Fast methods will be developed based on radial basis function interpolation of the data, followed by the fast application of a smoothing integral operator, approximated using multi-resolution Gaussian atoms. The method will be applied to meteorological data to build intuition on how the degree of smoothing impacts the posterior. If necessary, the method will be combined with other methods for improving particle filter performance, like implicit sampling or optimal transport.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ian",
   "pi_last_name": "Grooms",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Ian G Grooms",
   "pi_email_addr": "ian.grooms@colorado.edu",
   "nsf_id": "000718167",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gregory",
   "pi_last_name": "Beylkin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gregory Beylkin",
   "pi_email_addr": "gregory.beylkin@colorado.edu",
   "nsf_id": "000123460",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Kleiber",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "William P Kleiber",
   "pi_email_addr": "william.kleiber@colorado.edu",
   "nsf_id": "000627415",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Colorado at Boulder",
  "inst_street_address": "3100 MARINE ST",
  "inst_street_address_2": "STE 481 572 UCB",
  "inst_city_name": "Boulder",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "3034926221",
  "inst_zip_code": "803090001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "THE REGENTS OF THE UNIVERSITY OF COLORADO",
  "org_prnt_uei_num": "",
  "org_uei_num": "SPVKK1RC2MZ3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Colorado at Boulder",
  "perf_str_addr": "3100 Marine Street, Room 481",
  "perf_city_name": "Boulder",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "803090572",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 70728.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 149086.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project investigated methods for combining observational data with a dynamical model to estimate the state of a dynamical system. These methods are used, for example, to assimilate atmospheric observations from a wide range of platforms into an initial condition for a weather forecast. Current state of the art methods are based on an ensemble of simulations, and many of these methods make unrealistic assumptions about the statistical distributions (e.g. everything is assumed Gaussian); these assumptions limit the performance of the methods while simultaneously enabling a method that is not too computationally expensive. Other methods exist that do not make these restrictive assumptions, but in practice they require far too much computational cost to be useful.</p>\n<p>This project developed methods that compromise between having, on the one hand, higher computational cost than current operational methods (i.e. requiring a larger ensemble forecast) and having less-restrictive assumptions about the distributions, while on the other hand having lower computational cost and more-restrictive assumptions than the aforementioned general but impractical methods.</p>\n<p>The project produced new statistical methods along with fast computational algorithms for implementing them. The new methods were still a bit too expensive for some large-scale applications, with the expense being related to the size of the ensemble forecast, so an initial foray was made into the development of new methods, based on data science and machine learning, for reducing the computational cost of an ensemble forecast.</p>\n<p>The project partially funded the education of two PhD students, both of whom are currently employed in academic and industrial research.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/01/2021<br>\n\t\t\t\t\tModified by: Ian&nbsp;G&nbsp;Grooms</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project investigated methods for combining observational data with a dynamical model to estimate the state of a dynamical system. These methods are used, for example, to assimilate atmospheric observations from a wide range of platforms into an initial condition for a weather forecast. Current state of the art methods are based on an ensemble of simulations, and many of these methods make unrealistic assumptions about the statistical distributions (e.g. everything is assumed Gaussian); these assumptions limit the performance of the methods while simultaneously enabling a method that is not too computationally expensive. Other methods exist that do not make these restrictive assumptions, but in practice they require far too much computational cost to be useful.\n\nThis project developed methods that compromise between having, on the one hand, higher computational cost than current operational methods (i.e. requiring a larger ensemble forecast) and having less-restrictive assumptions about the distributions, while on the other hand having lower computational cost and more-restrictive assumptions than the aforementioned general but impractical methods.\n\nThe project produced new statistical methods along with fast computational algorithms for implementing them. The new methods were still a bit too expensive for some large-scale applications, with the expense being related to the size of the ensemble forecast, so an initial foray was made into the development of new methods, based on data science and machine learning, for reducing the computational cost of an ensemble forecast.\n\nThe project partially funded the education of two PhD students, both of whom are currently employed in academic and industrial research.\n\n\t\t\t\t\tLast Modified: 10/01/2021\n\n\t\t\t\t\tSubmitted by: Ian G Grooms"
 }
}