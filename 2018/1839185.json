{
 "awd_id": "1839185",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Navigating the New Arctic (NNA): Soundscape ecology to assess environmental and anthropogenic controls on wildlife behavior",
 "cfda_num": "47.078",
 "org_code": "06090100",
 "po_phone": "7032927432",
 "po_email": "colstraw@nsf.gov",
 "po_sign_block_name": "Colleen Strawhacker",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 535581.0,
 "awd_amount": 535581.0,
 "awd_min_amd_letter_date": "2018-09-10",
 "awd_max_amd_letter_date": "2023-08-23",
 "awd_abstract_narration": "Across North America, Arctic and boreal regions have been warming at a rate two to three times higher than the global average. At the same time, human development continues to encroach and intensify, primarily due to demand for natural resources, such as oil and gas. The vast and remote nature of Arctic-boreal regions typify their landscapes, environment, wildlife, and people, but their size and isolation also make it difficult to study how their ecosystems are changing. To overcome these challenges, autonomous recording networks can be used to characterize \"soundscapes\" - a collection of sounds that emanate from landscapes. Unlike traditional observing methods that are expensive, labor-intensive, and logistically challenging, sound-recording networks provide a cost-effective means to both monitor and understand the response of wildlife to environmental and anthropogenic changes across vast areas. One particular challenge with this sound-measurement approach is extracting useful ecological information from the large volumes of soundscape data that are collected. This project will develop the techniques necessary to overcome this challenge.\r\n\r\nThe researchers' goal is to understand the influence of both environmental dynamics and increasing anthropogenic activity on the behavior and phenology of migratory caribou (Rangifer tarandus), waterfowl, and songbird communities in Arctic-boreal Alaska and northwestern Canada. Through co-production of knowledge with local land managers and indigenous communities, the research team will combine field observations, modeling, and analyses that include: (1) soundscape measurements, (2) camera-trap observations, (3) automated soundscape analyses, (4) analyses of camera-trap caribou observations, (5) high-resolution modeling of environmental variables, (6) statistical analyses including wildlife occupancy, diversity, and phenology modeling, and (7) a human-computation game to collect descriptions of our acoustic recordings that allows for the participation of local and Indigenous players of the game. The project will contribute understanding of how both avian communities and caribou populations are responding to spatiotemporal variations in environmental conditions and increasing development of the oil and gas industry in a region where such comprehensive, large-scale research has rarely been possible. Further, at the request of various Tribal organizations, our research will provide insight into how industrial noise influences traditional practices. In addition, our research will provide baseline data on all natural sounds, including data on bird and caribou activity, in the Arctic National Wildlife Refuge prior to oil and gas development. These datasets will be available to inform Indigenous practices and natural resource management, as well as facilitate future Environmental Assessments required by land managers and oil and gas developers.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "GEO",
 "org_dir_long_name": "Directorate for Geosciences",
 "div_abbr": "OPP",
 "org_div_long_name": "Office of Polar Programs (OPP)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Mandel",
   "pi_mid_init": "I",
   "pi_sufx_name": "",
   "pi_full_name": "Michael I Mandel",
   "pi_email_addr": "mim@sci.brooklyn.cuny.edu",
   "nsf_id": "000634756",
   "pi_start_date": "2018-09-10",
   "pi_end_date": "2023-08-23"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Johanna",
   "pi_last_name": "Devaney",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Johanna Devaney",
   "pi_email_addr": "johanna.devaney@brooklyn.cuny.edu",
   "nsf_id": "000660530",
   "pi_start_date": "2023-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "CUNY Brooklyn College",
  "inst_street_address": "2900 BEDFORD AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BROOKLYN",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "7189515622",
  "inst_zip_code": "112102850",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "NY09",
  "org_lgl_bus_name": "RESEARCH FOUNDATION OF THE CITY UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "XNAKYW3FTSE1"
 },
 "perf_inst": {
  "perf_inst_name": "CUNY Brooklyn College",
  "perf_str_addr": "2900 Bedford Ave",
  "perf_city_name": "Brooklyn",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "112102889",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "NY09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "522100",
   "pgm_ele_name": "ASSP-Arctic Social Science"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "072Z",
   "pgm_ref_txt": "NNA-Navigating the New Arctic"
  },
  {
   "pgm_ref_code": "1079",
   "pgm_ref_txt": "ARCTIC RESEARCH"
  }
 ],
 "app_fund": [
  {
   "app_code": "02XX",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "0100XXXXDB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 535581.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The overarching goal of the project was to develop state-of-the-art computational approaches to collecting and analyzing audio recordings of large wilderness areas. These recordings contain information about wildlife presence, behavior, and life events, as well as environmental conditions, insect activity, and human activity. These data can be quantitatively modeled to understand the influence of changing environmental conditions and increasing anthropogenic (human-based) activity on the behavioral patterns of migratory caribou, waterfowl, and songbird communities.</p>\r\n<p>To study this in Arctic-boreal Alaska and northwestern Canada, we recorded 168,736 hours (~19.5 years) of audio data from 98 recorders in 5 different regions (along the Dalton highway, along the Dempster highway, in Ivvavik national park, in the Prudhoe Bay region, and in the Arctic National Wildlife Refuge) between 2018 and 2024. We developed and fine-tuned a set of deep-learning-based hierarchical models to identify the occurrences of 11 specific categories of audio activity. These include both soundscape-level labels (e.g., anthrophony [sounds produced by humans], biophony [sounds produced by animals], and geophony [sounds produced by nature]) and more precise categories within these (aircraft in anthrophony, birds &nbsp;and insects in biophony, and rain and wind in geophony). Within the bird category, the models are also capable of predicting bird types, specifically songbird, waterfowl, and upland game bird.</p>\r\n<p>The development of these deep learning models made several contributions to the fields of computer science and machine learning. The project collected a large amount of audio data, but it was only feasible for humans to annotate a small portion of it with labels that could be used to train and evaluate these models. This is a general problem in the field, and the project made several contributions towards addressing it. We initially investigated whether existing general audio classification models could be repurposed to recognize the categories of interest here, which would require less labeled data. We found that they could, to some extent, but that models trained especially for this purpose with data labeled from our audio recordings were more accurate. We then showed that an innovative data valuation technique could identify both unreliable and redundant data and that by removing them we could train models that were as accurate or more accurate with substantially less labeled data. We also showed that automatically generated weather model data could be used to train audio classifiers to predict wind and rain at a finer temporal and spatial scale than a strictly audio-based model, although they were less accurate than those trained with human-generated labels. And finally, we experimented with multimodal large language models that process both text and audio to determine whether they could be trained from textual descriptions to recognize new sound classes like species-specific bird songs and calls. We showed that the current obstacle in these models for achieving these goals is that these models do not reason in similar ways about the text and the audio, a problem that must be overcome to enable this low-data application.</p>\r\n<p>To make our deep-learning models broadly accessible to scientists from other disciplines (such as ecologists and climatologists), we created and distributed a set of notebooks and tutorials to guide users through the notebooks. &nbsp;The co-investigators on the project used these tools, in collaboration with local land managers and indigenous communities, to examine how avian communities are responding to variations in environmental conditions across time and space as well as in human-generated noise and activity. Understanding the interrelationships among these systems is crucial to their survival and success in the face of changing climate regimes and expanding human presence on the landscape.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/05/2025<br>\nModified by: Johanna&nbsp;Devaney</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/1839185/1839185_10581254_1736039493956_dataset_map--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2025/1839185/1839185_10581254_1736039493956_dataset_map--rgov-800width.jpg\" title=\"Acoustic monitoring site locations\"><img src=\"/por/images/Reports/POR/2025/1839185/1839185_10581254_1736039493956_dataset_map--rgov-66x44.jpg\" alt=\"Acoustic monitoring site locations\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Locations of audio recording device in five different regions: along the Dalton highway, along the Dempster highway, in Ivvavik national park, in the Prudhoe Bay oil fields, and in the Arctic National Wildlife Refuge (ANWR).</div>\n<div class=\"imageCredit\">Enis Berk \ufffdoban</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Johanna&nbsp;Devaney\n<div class=\"imageTitle\">Acoustic monitoring site locations</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe overarching goal of the project was to develop state-of-the-art computational approaches to collecting and analyzing audio recordings of large wilderness areas. These recordings contain information about wildlife presence, behavior, and life events, as well as environmental conditions, insect activity, and human activity. These data can be quantitatively modeled to understand the influence of changing environmental conditions and increasing anthropogenic (human-based) activity on the behavioral patterns of migratory caribou, waterfowl, and songbird communities.\r\n\n\nTo study this in Arctic-boreal Alaska and northwestern Canada, we recorded 168,736 hours (~19.5 years) of audio data from 98 recorders in 5 different regions (along the Dalton highway, along the Dempster highway, in Ivvavik national park, in the Prudhoe Bay region, and in the Arctic National Wildlife Refuge) between 2018 and 2024. We developed and fine-tuned a set of deep-learning-based hierarchical models to identify the occurrences of 11 specific categories of audio activity. These include both soundscape-level labels (e.g., anthrophony [sounds produced by humans], biophony [sounds produced by animals], and geophony [sounds produced by nature]) and more precise categories within these (aircraft in anthrophony, birds and insects in biophony, and rain and wind in geophony). Within the bird category, the models are also capable of predicting bird types, specifically songbird, waterfowl, and upland game bird.\r\n\n\nThe development of these deep learning models made several contributions to the fields of computer science and machine learning. The project collected a large amount of audio data, but it was only feasible for humans to annotate a small portion of it with labels that could be used to train and evaluate these models. This is a general problem in the field, and the project made several contributions towards addressing it. We initially investigated whether existing general audio classification models could be repurposed to recognize the categories of interest here, which would require less labeled data. We found that they could, to some extent, but that models trained especially for this purpose with data labeled from our audio recordings were more accurate. We then showed that an innovative data valuation technique could identify both unreliable and redundant data and that by removing them we could train models that were as accurate or more accurate with substantially less labeled data. We also showed that automatically generated weather model data could be used to train audio classifiers to predict wind and rain at a finer temporal and spatial scale than a strictly audio-based model, although they were less accurate than those trained with human-generated labels. And finally, we experimented with multimodal large language models that process both text and audio to determine whether they could be trained from textual descriptions to recognize new sound classes like species-specific bird songs and calls. We showed that the current obstacle in these models for achieving these goals is that these models do not reason in similar ways about the text and the audio, a problem that must be overcome to enable this low-data application.\r\n\n\nTo make our deep-learning models broadly accessible to scientists from other disciplines (such as ecologists and climatologists), we created and distributed a set of notebooks and tutorials to guide users through the notebooks. The co-investigators on the project used these tools, in collaboration with local land managers and indigenous communities, to examine how avian communities are responding to variations in environmental conditions across time and space as well as in human-generated noise and activity. Understanding the interrelationships among these systems is crucial to their survival and success in the face of changing climate regimes and expanding human presence on the landscape.\r\n\n\n\t\t\t\t\tLast Modified: 01/05/2025\n\n\t\t\t\t\tSubmitted by: JohannaDevaney\n"
 }
}