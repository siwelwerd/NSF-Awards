{
 "awd_id": "1763033",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Workload Analysis of NSF Innovative HPC Program Resources",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924863",
 "po_email": "edwalker@nsf.gov",
 "po_sign_block_name": "Edward Walker",
 "awd_eff_date": "2017-11-15",
 "awd_exp_date": "2018-04-30",
 "tot_intn_awd_amt": 252451.0,
 "awd_amount": 252451.0,
 "awd_min_amd_letter_date": "2017-11-01",
 "awd_max_amd_letter_date": "2017-11-01",
 "awd_abstract_narration": "The NSF Innovative High Performance Computing (HPC) program provides critical computational and data analytics capabilities to thousands of computational scientists conducting leading-edge science and engineering research across the U.S.  The portfolio of systems supported by the program is intended to be technically diverse, reflecting changing and growing use of computation in both the research and education process.  In addition, the program complements and extends the capabilities provided by campus and other regional research cyberinfrastructures.  Given the important and unique role that the systems in the program play in the Nation's research portfolio, it is important to have a detailed understanding of its past and current workload. This project seeks to perform a workload trend analysis for all the systems in the NSF Innovative HPC program.  Workload characterization is important because it is an integral part of optimal performance tuning for HPC Systems.   In addition, examining all the systems within the Innovative HPC program collectively will not only aid holistic capacity planning for the wider HPC ecosystem, but also, reveal how the nature of computational science research itself is evolving over time.  \r\n \r\nThe workload analysis will address fundamental usage and performance questions such as: How much of the HPC program resources are consumed by high throughput applications (large numbers of loosely-coupled serial, single and small node count jobs) and gateway applications, and is this changing over time?  What are the characteristics of gateway jobs? How much of the resources are used for data analytics/data intensive computing? What is the run-time over-subscription capacity for the entire ecosystem?  Are there differences in the job mixes among the systems and if so, how does this impact job throughput?  \r\n\r\nThe study will leverage XDMoD (XD Metrics on Demand) which contains a data warehouse of detailed job level accounting and performance data for all the resources provided through the NSF Innovative HPC program.  Moreover, the results of this study will not only provide detailed operational and performance analytics for the broad community of users and maintainers of the systems in the program, but will also be used as a template for similar studies carried out on other advanced HPC systems. This transfer of knowledge will be facilitated through the use of Open XDMoD, which is already in wide use by HPC centers worldwide, as well as presentations at conferences and meetings.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thomas",
   "pi_last_name": "Furlani",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas R Furlani",
   "pi_email_addr": "furlani@buffalo.edu",
   "nsf_id": "000146269",
   "pi_start_date": "2017-11-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "DeLeon",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Robert L DeLeon",
   "pi_email_addr": "rldeleon@buffalo.edu",
   "nsf_id": "000163680",
   "pi_start_date": "2017-11-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Jones",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew D Jones",
   "pi_email_addr": "jonesm@ccr.buffalo.edu",
   "nsf_id": "000170376",
   "pi_start_date": "2017-11-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Joseph",
   "pi_last_name": "White",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Joseph P White",
   "pi_email_addr": "jpwhite4@buffalo.edu",
   "nsf_id": "000727254",
   "pi_start_date": "2017-11-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Nikolay",
   "pi_last_name": "Simakov",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Nikolay A Simakov",
   "pi_email_addr": "nikolays@buffalo.edu",
   "nsf_id": "000757479",
   "pi_start_date": "2017-11-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Buffalo",
  "inst_street_address": "520 LEE ENTRANCE STE 211",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "7166452634",
  "inst_zip_code": "142282577",
  "inst_country_name": "United States",
  "cong_dist_code": "26",
  "st_cong_dist_code": "NY26",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "GMZUKXFDJMA9",
  "org_uei_num": "LMCJKRFW5R81"
 },
 "perf_inst": {
  "perf_inst_name": "Center for Computational Research",
  "perf_str_addr": "701 Ellicott Street",
  "perf_city_name": "Buffalo",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "142033070",
  "perf_ctry_code": "US",
  "perf_cong_dist": "26",
  "perf_st_cong_dist": "NY26",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "747600",
   "pgm_ele_name": "XD-Extreme Digital"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7476",
   "pgm_ref_txt": "ETF"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 252451.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>High performance computing (HPC) systems, more commonly known as supercomputers, play a pivotal role in society today, including science and engineering and the U.S. economy.&nbsp; They are essential tools in a diverse range of areas including finance, oil and gas exploration, pharmaceutical drug design, medical and basic research, computer animation, aeronautics, and automotive design to name a few.&nbsp; Given the important role that supercomputers computers play in the economy and research in particular, it is important to understand how they are being used, who is using them, and how well they are meeting the needs of the scientific community using them so that new systems can be designed and deployed to adequately meet future needs. &nbsp;&nbsp;&nbsp;To answer these questions, a detailed workload analysis was carried out on the supercomputers comprising the NSF Innovative HPC program.&nbsp;&nbsp; The analysis looked at a wide range of metrics including utilization, job size, memory usage, science gateways, fields of science, and application use.&nbsp; The workload analysis also sought to illustrate a wide variety of usage patterns and performance requirements for the scientific jobs running on these systems.</p>\n<p>The analysis showed that growth in utilization of the NSF HPC resources has been substantial, it has increased by almost a factor of 100 by each of the NSF directorates since 2011 - providing strong evidence of the increasing importance of advanced computing to the advancement of science and engineering.&nbsp; &nbsp;&nbsp;This remarkable growth is also evident in an increase of more than 90% in the number of users over that same time period. &nbsp;&nbsp;&nbsp;Many other trends were observed that provide useful information to help inform NSF decisions regarding the size, and types of high performance computers to deploy to ensure that the U.S&rsquo;s preeminence in science and engineering is maintained.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/04/2018<br>\n\t\t\t\t\tModified by: Thomas&nbsp;R&nbsp;Furlani</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nHigh performance computing (HPC) systems, more commonly known as supercomputers, play a pivotal role in society today, including science and engineering and the U.S. economy.  They are essential tools in a diverse range of areas including finance, oil and gas exploration, pharmaceutical drug design, medical and basic research, computer animation, aeronautics, and automotive design to name a few.  Given the important role that supercomputers computers play in the economy and research in particular, it is important to understand how they are being used, who is using them, and how well they are meeting the needs of the scientific community using them so that new systems can be designed and deployed to adequately meet future needs.    To answer these questions, a detailed workload analysis was carried out on the supercomputers comprising the NSF Innovative HPC program.   The analysis looked at a wide range of metrics including utilization, job size, memory usage, science gateways, fields of science, and application use.  The workload analysis also sought to illustrate a wide variety of usage patterns and performance requirements for the scientific jobs running on these systems.\n\nThe analysis showed that growth in utilization of the NSF HPC resources has been substantial, it has increased by almost a factor of 100 by each of the NSF directorates since 2011 - providing strong evidence of the increasing importance of advanced computing to the advancement of science and engineering.    This remarkable growth is also evident in an increase of more than 90% in the number of users over that same time period.    Many other trends were observed that provide useful information to help inform NSF decisions regarding the size, and types of high performance computers to deploy to ensure that the U.S?s preeminence in science and engineering is maintained. \n\n \n\n\t\t\t\t\tLast Modified: 05/04/2018\n\n\t\t\t\t\tSubmitted by: Thomas R Furlani"
 }
}