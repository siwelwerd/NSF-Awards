{
 "awd_id": "1817245",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: RUI: Differentially Private Hypothesis Testing",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925177",
 "po_email": "asquicci@nsf.gov",
 "po_sign_block_name": "Anna Squicciarini",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 344683.0,
 "awd_amount": 344683.0,
 "awd_min_amd_letter_date": "2018-08-10",
 "awd_max_amd_letter_date": "2018-08-10",
 "awd_abstract_narration": "In today's world, private companies, hospitals, governments, and other entities frequently maintain large databases that would be hugely valuable to researchers in many fields. However, privacy concerns prevent these databases from being fully utilized. Differential privacy defines conditions under which information about these databases can be released while provably protecting the privacy of the individuals whose data they contain. This project develops differentially private hypothesis tests. Hypothesis tests are common statistical tools that are widely used in data analysis for social sciences, medicine, and public policy. This project aims to give researchers the tools they need to conduct standard statistical analyses on data that was previously inaccessible due to privacy concerns. The project makes extensive use of undergraduate researchers, helping to train a new generation of privacy experts.\r\n\r\nDifferentially private hypothesis tests allow researchers to answer relevant research questions without having direct access to sensitive data. This project develops private versions of many standard hypothesis tests like analysis of variance or survival analysis.  For each hypothesis test, there are three goals: (1) to develop a private test statistic, either by approximating the standard test statistic or by creating an entirely new test statistic, (2) to develop methods for converting this test statistic to a final, meaningful value such as a p-value, and (3) to conduct power analyses evaluating the utility of the hypothesis test. This project also aims to release a software package implementing these tests and explanatory materials to ease their adoption by non-specialists.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Adam",
   "pi_last_name": "Groce",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Adam Groce",
   "pi_email_addr": "agroce@reed.edu",
   "nsf_id": "000759176",
   "pi_start_date": "2018-08-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Anna",
   "pi_last_name": "Ritz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anna Ritz",
   "pi_email_addr": "aritz@reed.edu",
   "nsf_id": "000695042",
   "pi_start_date": "2018-08-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andrew",
   "pi_last_name": "Bray",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andrew Bray",
   "pi_email_addr": "abray@reed.edu",
   "nsf_id": "000759174",
   "pi_start_date": "2018-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Reed College",
  "inst_street_address": "3203 SE WOODSTOCK BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "PORTLAND",
  "inst_state_code": "OR",
  "inst_state_name": "Oregon",
  "inst_phone_num": "5037711112",
  "inst_zip_code": "972028138",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OR03",
  "org_lgl_bus_name": "THE REED INSTITUTE",
  "org_prnt_uei_num": "",
  "org_uei_num": "CMNJCKH6LTK6"
 },
 "perf_inst": {
  "perf_inst_name": "Reed College",
  "perf_str_addr": "",
  "perf_city_name": "Portland",
  "perf_st_code": "OR",
  "perf_st_name": "Oregon",
  "perf_zip_code": "972028199",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OR03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 344683.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>If a statistical analysis satisfies <em>differential privacy, </em>then it can be carried out on a database without any concern that the outputs of the analysis might violate the privacy of the people whose data is contained in that database.&nbsp; If we could create differentially private versions of standard statistical analyses, we would be able to carry out all sorts of important research (e.g., in medicine or social science) on data that would otherwise be inaccessible and without compromising anyone's privacy.</p>\n<p>Many researchers are working on coming up with new differentially private ways to analyze data.&nbsp; This project focused on hypothesis tests, extremely common statistical tools.&nbsp; Even though these are some of the first types of analyses you learn about in an introductory statistics class, many had no existing private versions before this work.</p>\n<p>We looked first at analysis of variance (ANOVA)-type tests, which are used when you want to see if a categorical variable is plausibly independent of a continuous variable.&nbsp; The first private test for this situation was developed as preliinary work for this grant, and then under the grant we found additional tests that improved the statistical power (that is, how much data you need to carry out the test) by orders of magnitude, with the test now requiring an amount of data closer to what is required in the non-private setting than to what was required in the initial work.&nbsp; The second major result was to find a way that any test could be automatically privatized in an easy way.&nbsp; Along the way, there were other papers and preprints regarding related results.</p>\n<p>These works were all published, and all incuded freely accessible code that would allow any analyst to carry out the methods we described.&nbsp; We gave proofs of their privacy and empirical analyses of their statistical power.</p>\n<p>This project focused on including undergraduates in the research.&nbsp; Undergraduates were involved at every step of the process, from problem selection to writing up final papers.&nbsp; They got excellent research experience, and several are already well on their way through successful graduate studies.</p>\n<p>The project also brought together faculty and students from computer science and statistics, sharing expertise and helping each other learn about the norms of the other field.&nbsp; This is necessary to make sure that differential privacy is held to standards of rigor that are no weaker/strong than the standard statistics it is attempting to substitute for.</p><br>\n<p>\n Last Modified: 01/05/2024<br>\nModified by: Adam&nbsp;Groce</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIf a statistical analysis satisfies differential privacy, then it can be carried out on a database without any concern that the outputs of the analysis might violate the privacy of the people whose data is contained in that database. If we could create differentially private versions of standard statistical analyses, we would be able to carry out all sorts of important research (e.g., in medicine or social science) on data that would otherwise be inaccessible and without compromising anyone's privacy.\n\n\nMany researchers are working on coming up with new differentially private ways to analyze data. This project focused on hypothesis tests, extremely common statistical tools. Even though these are some of the first types of analyses you learn about in an introductory statistics class, many had no existing private versions before this work.\n\n\nWe looked first at analysis of variance (ANOVA)-type tests, which are used when you want to see if a categorical variable is plausibly independent of a continuous variable. The first private test for this situation was developed as preliinary work for this grant, and then under the grant we found additional tests that improved the statistical power (that is, how much data you need to carry out the test) by orders of magnitude, with the test now requiring an amount of data closer to what is required in the non-private setting than to what was required in the initial work. The second major result was to find a way that any test could be automatically privatized in an easy way. Along the way, there were other papers and preprints regarding related results.\n\n\nThese works were all published, and all incuded freely accessible code that would allow any analyst to carry out the methods we described. We gave proofs of their privacy and empirical analyses of their statistical power.\n\n\nThis project focused on including undergraduates in the research. Undergraduates were involved at every step of the process, from problem selection to writing up final papers. They got excellent research experience, and several are already well on their way through successful graduate studies.\n\n\nThe project also brought together faculty and students from computer science and statistics, sharing expertise and helping each other learn about the norms of the other field. This is necessary to make sure that differential privacy is held to standards of rigor that are no weaker/strong than the standard statistics it is attempting to substitute for.\t\t\t\t\tLast Modified: 01/05/2024\n\n\t\t\t\t\tSubmitted by: AdamGroce\n"
 }
}