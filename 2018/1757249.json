{
 "awd_id": "1757249",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Assessment Practices of STEM Teachers",
 "cfda_num": "47.076",
 "org_code": "11040100",
 "po_phone": "7032922125",
 "po_email": "jtellis@nsf.gov",
 "po_sign_block_name": "Jennifer Ellis",
 "awd_eff_date": "2018-03-01",
 "awd_exp_date": "2024-02-29",
 "tot_intn_awd_amt": 1100000.0,
 "awd_amount": 1100000.0,
 "awd_min_amd_letter_date": "2018-02-08",
 "awd_max_amd_letter_date": "2018-02-08",
 "awd_abstract_narration": "With funding from the National Science Foundation's Noyce Program, Research Track 4, this partnership between the University of Massachusetts Boston and Boston Public Schools will characterize growth in the assessment practices of science, technology, engineering, and mathematics (STEM) teachers.  The goal is to understand how assessment practices may drive teacher effectiveness. This research study will include participation of 58 elementary, middle, and high school STEM teachers who previously participated in a Noyce-funded project and who have persisted in teaching in Boston or other nearby high-need districts. The project will compare differences in the assessment practices of these Noyce-program teachers to 29 other K-12 STEM teachers from the same area, but who participated in different training programs. The project aims to increase knowledge about STEM teacher effectiveness by how teacher effectiveness may relate to teachers measure their students' understanding. The project will examine changes in how STEM teachers measure student learning over several years, as the teachers gain more experience in the classroom. Outcomes from the research will help us understand how STEM teachers measure student learning and use that information to improve their teaching and to assign grades. \r\n\r\nThe goals of the research study are to: (a) Increase understanding of teachers' assessment practices, particularly for Noyce Scholars in comparison to other STEM teachers who also persist in teaching in high-need school districts; (b) Measure growth in the assessment practices of Noyce Scholars in comparison to other STEM teachers over time; and (c) Better understand the role of the conceptual, pedagogical, cultural and political challenges teachers face as their assessment practices change. The research employs both qualitative and quantitative methods, in an interaction analysis framework, to study four research questions about K-12 STEM teachers who have persisted in teaching in high-need districts: (1) What are the teachers' current assessment practices? (2) How have their assessment practices changed from when they began teaching in a high-need district? (3) How do salient retrospective conceptual, pedagogical, cultural, and political challenges negotiated by the teachers explain their current classroom formative assessment practices and changes over time in their assessment practices? and (4) For teachers who have persisted teaching in Boston Public Schools, how do assessment practices relate to student performance outcomes on classroom assessments and to district and State standardized mathematics and science exams? Across these questions, the research team will examine differences between Boston and other districts, as well as effects of other factors, including Noyce- vs. non-Noyce- prepared teachers, length of time teaching in high-need districts, and school-level influences such as school culture, accountability rating, stability of leadership, and professional development opportunities. The project will contribute to theory about teacher assessment practices and the degree to which interaction analysis is useful in studying these practices. The project will also contribute to educational policy implications for supporting teachers to navigate pedagogical perspectives, curricular expectations, administrative policies and procedures, and external pressures as they persist in STEM teaching careers in high-need districts.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DUE",
 "org_div_long_name": "Division Of Undergraduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hannah",
   "pi_last_name": "Sevian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hannah Sevian",
   "pi_email_addr": "hannah.sevian@umb.edu",
   "nsf_id": "000414946",
   "pi_start_date": "2018-02-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Lisa",
   "pi_last_name": "Gonsalves",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Lisa M Gonsalves",
   "pi_email_addr": "lisa.gonsalves@umb.edu",
   "nsf_id": "000103867",
   "pi_start_date": "2018-02-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Boston",
  "inst_street_address": "100 WILLIAM T MORRISSEY BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "DORCHESTER",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172875370",
  "inst_zip_code": "021253300",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "MA08",
  "org_lgl_bus_name": "UNIVERSITY OF MASS AT BOSTON",
  "org_prnt_uei_num": "CGCDJ24JJLZ1",
  "org_uei_num": "CGCDJ24JJLZ1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Boston",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021253300",
  "perf_ctry_code": "US",
  "perf_cong_dist": "08",
  "perf_st_cong_dist": "MA08",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "179500",
   "pgm_ele_name": "Robert Noyce Scholarship Pgm"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 1100000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-df2ce25d-7fff-005e-ca97-d47654ce0c5c\"> </span></p>\n<p dir=\"ltr\"><span>The studied four questions: RQ1-</span><span>What are teachers' current assessment practices? RQ2-How have their assessment practices changed from when they began teaching in a high-need district? RQ3-How do salient retrospective conceptual, pedagogical, cultural, and political challenges negotiated by the teachers explain their current classroom formative assessment practices and changes over time in their assessment practices? and RQ4-For teachers who have persisted teaching in a high-need district, how do assessment practices relate to student performance outcomes in science and mathematics. Collection of data in schools was hindered by COVID-19 school closures and associated later restrictions. The research relied on data collected prior to the pandemic, using historical data (time point 1, T1) and new data from this project (time point 2, T2) from participating teachers. Study focused on depth of analysis with the data. In all, T1 and T2 data were analyzed from the classrooms of 22 teachers, including elementary (n = 2), middle (n = 7), and high schools (n = 13). Both elementary teachers in the sample taught math, the middle school teachers taught math (n = 3) and general science (n = 4), and the high school teachers taught chemistry (n = 5), biology (n = 4), physics (n = 2), and math (n = 2). Teaching experience varied from three to twenty years, with a mean of eight years.&nbsp;</span></p>\n<p dir=\"ltr\"><span>A study published in </span><em>Teaching and Teacher Education</em><span> focused on RQ3, examining (1) video observations from two different units during a year; (2) formative assessment tasks, student artifacts, classroom recordings of groups of consented students, and teacher reflections about formative assessment; and (3) teacher's retrospective interviews about selected video clips from classroom activities. We characterized approaches and teaching mechanisms teachers use during class to support their intentions, through coding episodes to identify (1) teaching moves that used to support different levels of intellectual demand potential; and (2) mechanisms teachers use to support their intentions at a range of intellectual demand levels. We identified that both developing content knowledge (n= 96) and designing procedural engagement (n= 129) were the most prevalent teachers' intellectual demand levels in teachers' practices. Conceptual engagement (n= 68) and consequential engagement (n= 36) were least used by teachers. We observed that, when intellectual demand is lower, teachers used more authoritative approaches. With increasing intellectual demand, teachers used more dialogic approaches. To reveal relationships between teachers' strategies and mechanisms and authoritative and dialogic teaching moves that promote intellectual demand levels, we studied what underlies teachers' intentions of teaching, what they're teaching, and why teachers use particular teaching moves for specific levels of intellectual demand. We found that teachers used a broad range of teaching moves in class to support their intentions and to decide on a level of intellectual demand.</span></p>\n<p dir=\"ltr\"><span>Another research study focused on how teachers changed aspects of their teaching moves over time (RQ1 and RQ2). We examined two change variables: (1) shifts between teachers' eliciting and advancing teaching moves and (2) shifts between authoritative and dialogic discourse. We found five clusters: (1) Teachers (n = 4) who did not change the teaching moves in their classroom discourse; (2) Teachers (n = 4) who used more advancing moves in T2 when compared to T1 (13% to 29% more advancing moves than before); (3) Teachers (n = 3) who switched to mainly advancing moves (50% or more advancing moves than before); (4) Teachers (n = 9) who used more eliciting moves in T2 when compared to T1 (8% to 32% more eliciting moves than before); and Teachers (n = 2) who switched to mainly dialogic discourse in the classroom (50% or more dialogic moves than before).</span></p>\n<p dir=\"ltr\"><span>A third research study focused on how teachers' changes in assessment practices impacted changes in student outcomes (RQ4). Adapting a method by Brizuela et al. 2023, we measured the ratio of airtime for each teacher and their students for T1 and T2, timing student and teacher talk to the nearest second, during the videos of classroom formative assessment for the participating teachers in both T1 and T2 data. To measure levels of agency in student engagement, we analyzed all student talk utterances as responses to the teacher and to other students, coding in relation to the ideas or propositions in discourse play as \"not taken up\" (level 0, lowest agency level), \"neutral\" (level 1), \"accepted\" (level 2), and \"idea proposed\" or \"idea rejected\" (level 3, highest agency level). Overall, the fraction of airtime of students' voices (compared to teachers' voices) in the classroom increased from T1 to T2, from 23.4% to 27.4% of total airtime; this varied widely among teachers. Average student agency levels in classroom discourse (across all teachers) also changed from T1 to T2, with level 1 remaining similar, an overall increase in level 2, and an overall decrease in level 3. This also varied widely across teachers.</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 08/19/2024<br>\nModified by: Hannah&nbsp;Sevian</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThe studied four questions: RQ1-What are teachers' current assessment practices? RQ2-How have their assessment practices changed from when they began teaching in a high-need district? RQ3-How do salient retrospective conceptual, pedagogical, cultural, and political challenges negotiated by the teachers explain their current classroom formative assessment practices and changes over time in their assessment practices? and RQ4-For teachers who have persisted teaching in a high-need district, how do assessment practices relate to student performance outcomes in science and mathematics. Collection of data in schools was hindered by COVID-19 school closures and associated later restrictions. The research relied on data collected prior to the pandemic, using historical data (time point 1, T1) and new data from this project (time point 2, T2) from participating teachers. Study focused on depth of analysis with the data. In all, T1 and T2 data were analyzed from the classrooms of 22 teachers, including elementary (n = 2), middle (n = 7), and high schools (n = 13). Both elementary teachers in the sample taught math, the middle school teachers taught math (n = 3) and general science (n = 4), and the high school teachers taught chemistry (n = 5), biology (n = 4), physics (n = 2), and math (n = 2). Teaching experience varied from three to twenty years, with a mean of eight years.\n\n\nA study published in Teaching and Teacher Education focused on RQ3, examining (1) video observations from two different units during a year; (2) formative assessment tasks, student artifacts, classroom recordings of groups of consented students, and teacher reflections about formative assessment; and (3) teacher's retrospective interviews about selected video clips from classroom activities. We characterized approaches and teaching mechanisms teachers use during class to support their intentions, through coding episodes to identify (1) teaching moves that used to support different levels of intellectual demand potential; and (2) mechanisms teachers use to support their intentions at a range of intellectual demand levels. We identified that both developing content knowledge (n= 96) and designing procedural engagement (n= 129) were the most prevalent teachers' intellectual demand levels in teachers' practices. Conceptual engagement (n= 68) and consequential engagement (n= 36) were least used by teachers. We observed that, when intellectual demand is lower, teachers used more authoritative approaches. With increasing intellectual demand, teachers used more dialogic approaches. To reveal relationships between teachers' strategies and mechanisms and authoritative and dialogic teaching moves that promote intellectual demand levels, we studied what underlies teachers' intentions of teaching, what they're teaching, and why teachers use particular teaching moves for specific levels of intellectual demand. We found that teachers used a broad range of teaching moves in class to support their intentions and to decide on a level of intellectual demand.\n\n\nAnother research study focused on how teachers changed aspects of their teaching moves over time (RQ1 and RQ2). We examined two change variables: (1) shifts between teachers' eliciting and advancing teaching moves and (2) shifts between authoritative and dialogic discourse. We found five clusters: (1) Teachers (n = 4) who did not change the teaching moves in their classroom discourse; (2) Teachers (n = 4) who used more advancing moves in T2 when compared to T1 (13% to 29% more advancing moves than before); (3) Teachers (n = 3) who switched to mainly advancing moves (50% or more advancing moves than before); (4) Teachers (n = 9) who used more eliciting moves in T2 when compared to T1 (8% to 32% more eliciting moves than before); and Teachers (n = 2) who switched to mainly dialogic discourse in the classroom (50% or more dialogic moves than before).\n\n\nA third research study focused on how teachers' changes in assessment practices impacted changes in student outcomes (RQ4). Adapting a method by Brizuela et al. 2023, we measured the ratio of airtime for each teacher and their students for T1 and T2, timing student and teacher talk to the nearest second, during the videos of classroom formative assessment for the participating teachers in both T1 and T2 data. To measure levels of agency in student engagement, we analyzed all student talk utterances as responses to the teacher and to other students, coding in relation to the ideas or propositions in discourse play as \"not taken up\" (level 0, lowest agency level), \"neutral\" (level 1), \"accepted\" (level 2), and \"idea proposed\" or \"idea rejected\" (level 3, highest agency level). Overall, the fraction of airtime of students' voices (compared to teachers' voices) in the classroom increased from T1 to T2, from 23.4% to 27.4% of total airtime; this varied widely among teachers. Average student agency levels in classroom discourse (across all teachers) also changed from T1 to T2, with level 1 remaining similar, an overall increase in level 2, and an overall decrease in level 3. This also varied widely across teachers.\n\n\n\t\t\t\t\tLast Modified: 08/19/2024\n\n\t\t\t\t\tSubmitted by: HannahSevian\n"
 }
}