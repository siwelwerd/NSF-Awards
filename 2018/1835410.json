{
 "awd_id": "1835410",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Framework: Software: HDR: Building the Twenty-First Century Citizen Science Framework to Enable Scientific Discovery Across Disciplines",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924538",
 "po_email": "awalton@nsf.gov",
 "po_sign_block_name": "Amy Walton",
 "awd_eff_date": "2019-01-01",
 "awd_exp_date": "2021-12-31",
 "tot_intn_awd_amt": 85284.0,
 "awd_amount": 85284.0,
 "awd_min_amd_letter_date": "2018-08-27",
 "awd_max_amd_letter_date": "2018-08-27",
 "awd_abstract_narration": "A team of experts from five institutions (University of Minnesota, Adler Planetarium, University of Wyoming, Colorado State University, and UC San Diego) links field-based and online analysis capabilities to support citizen science, focusing on three research areas (cell biology, ecology, and astronomy).  The project builds on Zooniverse and CitSci.org, leverages the NSF Science Gateways Community Institute, and enhances the quality of citizen science and the experience of its participants.\r\n\r\nThis project creates an integrated Citizen Science Cyberinfrastructure (CSCI) framework that expands the capacity of research communities across several disciplines to use citizen science as a suitable and sustainable research methodology.  CSCI produces three improvements to the infrastructure for citizen science already provided by Zooniverse and CitSci.org: \r\n - Combining Modes - connecting the process of data collection and analysis; \r\n - Smart Assignment - improving the assignment of tasks during analysis; and \r\n - New Data Models - exploring the Data-as-Subject model.  By treating time series data as data, this model removes the need to create images for classification and facilitates more complex workflows.  These improvements are motivated and investigated through three distinct scientific cases:\r\n - Biomedicine (3D Morphology of Cell Nucleus).  Currently, Zooniverse 'Etch-a-Cell' volunteers provide annotations of cellular components in images from high-resolution microscopy, where a single cell provides a stack containing thousands of sliced images.  The Smart Task Assignment capability incorporates this information, so volunteers are not shown each image in a stack where machines or other volunteers have already evaluated some subset of data.\r\n - Ecology (Identifying Individual Animals).  When monitoring wide-ranging wildlife populations, identification of individual animals is needed for robust estimates of population sizes and trends.  This use case combines field collection and data analysis with deep learning to improve results.\r\n - Astronomy (Characterizing Lightcurves).  Astronomical time series data reveal a variety of behaviors, such as stellar flares or planetary transits.  The existing Zooniverse data model requires classification of individual images before aggregation of results and transformation back to refer to the original data.  By using the Data-as-Subject model and the Smart Task Assignment capability, volunteers will be able to scan through the entire time series in a machine-aided manner to determine specific light curve characteristics.\r\nThe team explores the use of recurrent neural networks (RNNs) to determine automated learning architectures best suited to the projects.  Of particular interest is how the degree to which neighboring subjects are coupled affects performance. The integration of existing tools, which is based on application programming interfaces (APIs), also facilitates further tool integration.  The effort creates a citizen science framework that directly advances knowledge for three science use cases in biomedicine, ecology, and astronomy, and combines field-collected data with data analysis. This has the ability to solve key problems in the individual applications, as well as benefiting the research of the dozens of projects on the Zooniverse platform. It provides benefits to researchers using citizen scientists, and to the nearly 1.6 million citizen scientists themselves.\r\n\r\nThis award by the Office of Advanced Cyberinfrastructure is jointly supported by the Division of Research on Learning in Formal and Informal Settings, within the NSF Directorate for Education and Human Resources.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sarah",
   "pi_last_name": "Benson-Amram",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sarah Benson-Amram",
   "pi_email_addr": "sbensona@uwyo.edu",
   "nsf_id": "000691388",
   "pi_start_date": "2018-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jeff",
   "pi_last_name": "Clune",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jeff Clune",
   "pi_email_addr": "jeffclune@uwyo.edu",
   "nsf_id": "000546028",
   "pi_start_date": "2018-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wyoming",
  "inst_street_address": "1000 E UNIVERSITY AVE",
  "inst_street_address_2": "",
  "inst_city_name": "LARAMIE",
  "inst_state_code": "WY",
  "inst_state_name": "Wyoming",
  "inst_phone_num": "3077665320",
  "inst_zip_code": "820712000",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "WY00",
  "org_lgl_bus_name": "UNIVERSITY OF WYOMING",
  "org_prnt_uei_num": "FDR5YF2K32X5",
  "org_uei_num": "FDR5YF2K32X5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wyoming",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "WY",
  "perf_st_name": "Wyoming",
  "perf_zip_code": "820712000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "WY00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725900",
   "pgm_ele_name": "AISL"
  },
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "077Z",
   "pgm_ref_txt": "CSSI-1: Cyberinfr for Sustained Scientif"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 85284.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project was part of a multi-institution collaborative research program that included faculty from the University of Minnesota, the University of Wyoming, Colorado State University, UC San Diego, and the Adler Planetarium. This portion of the research project was run out of the University of Wyoming and was focused on using machine learning to automate the process of recognizing individual animals from camera trap images and videos taken in the field. The ability to automatically identify individual wild animals without having to capture and mark them will fundamentally alter the way in which wildlife biologists, ecologists, and other researchers interact with, identify, and study wildlife. It will further benefit conservation by enabling us to gain accurate population counts of target species using camera trap images. Previous attempts to automate individual recognition failed to gain widespread use because they required carefully taken or cropped images of specific body parts, which are not plausible for large-scale studies of wildlife. Automated individual recognition of wild animals is only now a possibility due to advances in deep learning. However, in order for deep learning to be effective, it requires very large, labeled, training datasets.</p>\n<p>&nbsp;</p>\n<p>In this project, we used RFID technology to generate a large, labeled dataset of camera-trap images of wild urban mesocarnivores, including raccoons, striped skunks, and coyotes. We then tapped into a large network of community science volunteers through the Zooniverse platform to further categorize the dataset of images for training datasets for the machine learning algorithms. We did this because we found that there were difficulties in associating the RFID information for a given raccoon in an image due to the potential of non-RFID-tagged interlopers in the images, or the occlusion of the correct individual by structures in the image. Thus, the best possible approach was to limit the set for further development of machine learning for animal re-identification to those images with only one raccoon. These data were then used as input to train a machine-learning model. We found that the RFID labels were constraining the dataset so we then focused on training a model using only images that were labeled by Zooniverse volunteers. We are continuing to work with the dataset to generate individual-level identifications. Specifically, we are finalizing efforts to modify the triplet loss and facial recognition algorithms we have coded, apply them to the raccoon data and benchmark our results. We will also likely run a new Zooniverse project and will improve training of the community-science volunteers through use of natural data augmentation by selecting sequences of the same animals from video clips.</p>\n<p>&nbsp;</p>\n<p>The broader impacts of the project included the scientific training of three PhD students, one postdoctoral researcher, and one research scientist. Two undergraduate students from the University of Wyoming also received scientific training as part of this research. We also established the Raccoon Zooniverse animal identification project</p>\n<p><a href=\"https://www.zooniverse.org/projects/trouille/university-of-wyoming-raccoon-project\">https://www.zooniverse.org/projects/trouille/university-of-wyoming-raccoon-project</a>. This Zooniverse project engaged 3,804 citizen scientists who completed over 1.5 million classifications of camera-trap images.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/24/2022<br>\n\t\t\t\t\tModified by: Sarah&nbsp;Benson-Amram</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project was part of a multi-institution collaborative research program that included faculty from the University of Minnesota, the University of Wyoming, Colorado State University, UC San Diego, and the Adler Planetarium. This portion of the research project was run out of the University of Wyoming and was focused on using machine learning to automate the process of recognizing individual animals from camera trap images and videos taken in the field. The ability to automatically identify individual wild animals without having to capture and mark them will fundamentally alter the way in which wildlife biologists, ecologists, and other researchers interact with, identify, and study wildlife. It will further benefit conservation by enabling us to gain accurate population counts of target species using camera trap images. Previous attempts to automate individual recognition failed to gain widespread use because they required carefully taken or cropped images of specific body parts, which are not plausible for large-scale studies of wildlife. Automated individual recognition of wild animals is only now a possibility due to advances in deep learning. However, in order for deep learning to be effective, it requires very large, labeled, training datasets.\n\n \n\nIn this project, we used RFID technology to generate a large, labeled dataset of camera-trap images of wild urban mesocarnivores, including raccoons, striped skunks, and coyotes. We then tapped into a large network of community science volunteers through the Zooniverse platform to further categorize the dataset of images for training datasets for the machine learning algorithms. We did this because we found that there were difficulties in associating the RFID information for a given raccoon in an image due to the potential of non-RFID-tagged interlopers in the images, or the occlusion of the correct individual by structures in the image. Thus, the best possible approach was to limit the set for further development of machine learning for animal re-identification to those images with only one raccoon. These data were then used as input to train a machine-learning model. We found that the RFID labels were constraining the dataset so we then focused on training a model using only images that were labeled by Zooniverse volunteers. We are continuing to work with the dataset to generate individual-level identifications. Specifically, we are finalizing efforts to modify the triplet loss and facial recognition algorithms we have coded, apply them to the raccoon data and benchmark our results. We will also likely run a new Zooniverse project and will improve training of the community-science volunteers through use of natural data augmentation by selecting sequences of the same animals from video clips.\n\n \n\nThe broader impacts of the project included the scientific training of three PhD students, one postdoctoral researcher, and one research scientist. Two undergraduate students from the University of Wyoming also received scientific training as part of this research. We also established the Raccoon Zooniverse animal identification project\n\nhttps://www.zooniverse.org/projects/trouille/university-of-wyoming-raccoon-project. This Zooniverse project engaged 3,804 citizen scientists who completed over 1.5 million classifications of camera-trap images.\n\n \n\n\t\t\t\t\tLast Modified: 02/24/2022\n\n\t\t\t\t\tSubmitted by: Sarah Benson-Amram"
 }
}