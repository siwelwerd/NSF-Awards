{
 "awd_id": "1811661",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Highly Principled Data Science for Multi-Domain Astronomical Measurements and Analysis",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2018-07-15",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 100000.0,
 "awd_amount": 100000.0,
 "awd_min_amd_letter_date": "2018-07-11",
 "awd_max_amd_letter_date": "2018-07-11",
 "awd_abstract_narration": "Massive data resources are coming online in every conceivable area of human exploration, and particularly in fields that are heavily observation-based such as astronomy and astrophysics. To extract the most information from these data, scientists and statisticians need to conduct highly principled data science, by using methods that are scientifically justified, statistically principled, and computationally efficient. This project outlines plans to achieve this goal while addressing four specific challenges in astronomical data involving space, time and energy.  The proposed research has the dual impact of more reliable statistical methods in astronomy and of new general statistical inference and computational methods. In addition to providing methods and free software, the investigators also plan to communicate to the astronomical community the benefit of principled statistical methods through workshops and sessions at conferences. A fundamental impact of the proposed research is the more general acceptance and use of principled methods among astronomers. The general methods for efficient modeling of scientific phenomena, science-driven classification and clustering, and for statistical computing, can also help to solve complex data challenges throughout the natural, social, medical, and engineering sciences.\r\n\r\nStriking advances in both space-based and terrestrial instrumentation continuously increase the quality and quantity of data available to astronomers. Observations are made across the electromagnetic spectrum and compiled into enormous catalogs of high-resolution, but heterogeneous spectrograph, imaging, and time series data. The proposed research aims to use such multi-domain astronomical measurements to better understand the physical environment, structure, and evolution of astronomical individual sources, clusters, and ultimately of the entire universe. There are four major projects.  (1) The PIs will develop methodology to solve the instrument calibration problem, which is a fundamental challenge in astrophysics, by fitting scientifically motivated statistical models to data from multiple astronomical objects observed by multiple instruments. (2) The PIs propose a statistically and computationally efficient algorithm to detect the boundaries of a power law distribution prevalent in various areas of astronomy and of far-reaching importance. (3) The PIs will extend image-processing algorithms designed for detecting point sources to complex extended multi-scale structures via a post-hoc analysis, which makes the computation efficient. (4) With astronomical images exhibiting complex structure, the PIs propose to explore image segmentation methods to distinguish overlapping point sources; the algorithm achieves the flux-conserving property, which is crucial for giving physically meaningful estimates that existing methods lack. These projects all involve significant challenges in developing efficient statistical methods, designing fast computational algorithms, and balancing subtle trade-offs between complexity and practicality. With their extensive and successful track record, the PIs will address these challenges by developing inferential and efficient computational methods under highly-structured models that involve multi-scale structure and/or multiple levels of latent variables. The central theme of the proposed research is the integration and pursuit of three desiderata in each of its four projects: scientific justification, statistical principles, and computational efficiency. This triple-goal advances the development of specifically designed methods that leverage computationally efficient and statistically principled data-driven techniques which explicitly incorporate scientific understanding of the astronomical sources.  This ensures that the statistical analyses enhance the scientists' ability to answer specific questions about the underlying astronomical and physical processes. This strategy requires state-of-the-art statistical inference, sophisticated scientific computing, and careful model-checking procedures, all of which have been the hallmark of the work by this team of investigators.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thomas Chun Man",
   "pi_last_name": "Lee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas Chun Man Lee",
   "pi_email_addr": "tcmlee@ucdavis.edu",
   "nsf_id": "000301187",
   "pi_start_date": "2018-07-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Davis",
  "perf_str_addr": "1 Shields Avenue",
  "perf_city_name": "Davis",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956165270",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 100000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Many phenomena in the high-energy universe are time-variable, from coronal flares on the smallest stars to accretion events in the most massive black holes. Often, this variability can just be seen \"by-eye,\" but at other times, we need to use robust methods founded in statistics to distinguish random noise from significant variability. Realizing where the change has occurred is critical for subsequent scientific analyses; e.g., spectral fitting and light curve modeling. Such analyses must focus on those intervals in data space that are properly tied to the changes in the physical processes that generate the observed photons. Therefore, it is of importance to identify sources as well as to locate their spatial boundaries. A major contribution of this project is the development of an automatic method that detects those sudden changes that happened during the underlying astrophysical process.</p>\n<p>Another challenge often encountered in analyzing high-energy astronomical data is that the images are photon starved and sparse and contain many \"empty\" pixels. Unlike photon-rich images encountered at longer wavelengths, complex features in X-ray and gamma-ray data are difficult to recognize, characterize, and analyze. Working directly with photon counts, while simultaneously separating the contribution of the background, is a difficult process, especially when trying to detect faint non-uniform emission or separating faint point sources from larger scale diffuse emission. Finding the boundaries of such extended structures is thus a challenging problem. Another significant contribution of this project is the proposal of a novel method designed to tackle this problem.&nbsp;</p>\n<p>When applied to real data, both methods led to scientifically exciting results. Python modules implementing these methods are ready-for-use for practitioners.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/18/2021<br>\n\t\t\t\t\tModified by: Thomas Chun Man&nbsp;Lee</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMany phenomena in the high-energy universe are time-variable, from coronal flares on the smallest stars to accretion events in the most massive black holes. Often, this variability can just be seen \"by-eye,\" but at other times, we need to use robust methods founded in statistics to distinguish random noise from significant variability. Realizing where the change has occurred is critical for subsequent scientific analyses; e.g., spectral fitting and light curve modeling. Such analyses must focus on those intervals in data space that are properly tied to the changes in the physical processes that generate the observed photons. Therefore, it is of importance to identify sources as well as to locate their spatial boundaries. A major contribution of this project is the development of an automatic method that detects those sudden changes that happened during the underlying astrophysical process.\n\nAnother challenge often encountered in analyzing high-energy astronomical data is that the images are photon starved and sparse and contain many \"empty\" pixels. Unlike photon-rich images encountered at longer wavelengths, complex features in X-ray and gamma-ray data are difficult to recognize, characterize, and analyze. Working directly with photon counts, while simultaneously separating the contribution of the background, is a difficult process, especially when trying to detect faint non-uniform emission or separating faint point sources from larger scale diffuse emission. Finding the boundaries of such extended structures is thus a challenging problem. Another significant contribution of this project is the proposal of a novel method designed to tackle this problem. \n\nWhen applied to real data, both methods led to scientifically exciting results. Python modules implementing these methods are ready-for-use for practitioners. \n\n \n\n\t\t\t\t\tLast Modified: 12/18/2021\n\n\t\t\t\t\tSubmitted by: Thomas Chun Man Lee"
 }
}