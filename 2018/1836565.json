{
 "awd_id": "1836565",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Collaborative Research: An Unified Learnable Roadmap for Sequential Decision Making in Relational Domains",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 98522.0,
 "awd_amount": 98522.0,
 "awd_min_amd_letter_date": "2018-08-18",
 "awd_max_amd_letter_date": "2018-08-18",
 "awd_abstract_narration": "This project seeks to develop new algorithms and data structures for learning and planning in situations where the environment is represented with a set of relations between objects. Relational representations capture interactions between objects in a succinct and easily interpretable representation. Examples of domains that are well-suited to relational representations includes intelligent drones assisting soldiers, activities in a supply chain management, communication and friendship connections in a social network, and tracking individuals and activities in video.  Most recent advances in machine learning and planning, such as so-called \"deep neural networks\", however, employ simple \"flat\" representations, where the state of the world is an uninterpreted string of bits.  This project will make machine learning and planning methods easier to use and more robust by generalizing them so that they explicitly work with relational models and data.   The methods, theory, and data resulting from this proposal will impact the scientific community in several positive ways and will be made publicly available through an appropriate website. The research will be disseminated through refereed journals and conference proceedings and made available to researchers. Code for the proposed algorithms and descriptions of new benchmark problems will also be made publicly available. The investigators will work on organizing workshops and tutorials based on the challenges and findings arising from this project. \r\n\r\nMany special purpose solutions have been developed to address small parts of these problems, but there are no \r\ngeneral purpose tools that harness recent advances in machine learning to tackle this family of problems. This proposal seeks to develop such tools, drawing upon the investigators' prior experience in learning relational regression trees and experience in value function approximation for reinforcement learning. In addition, this project seeks to build a bridge between recent advances in deep learning, which generally has not been compatible with relational representations, and recent advances in relational learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sriraam",
   "pi_last_name": "Natarajan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sriraam Natarajan",
   "pi_email_addr": "sriraam.natarajan@utdallas.edu",
   "nsf_id": "000580911",
   "pi_start_date": "2018-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Dallas",
  "inst_street_address": "800 WEST CAMPBELL RD.",
  "inst_street_address_2": "SP2.25",
  "inst_city_name": "RICHARDSON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9728832313",
  "inst_zip_code": "750803021",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "TX24",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT DALLAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "EJCVPNN1WFS5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Dallas",
  "perf_str_addr": "800 W. Campbell Road",
  "perf_city_name": "Richardson",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "750803021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "TX24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 98522.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The key outcomes of this project are two-fold -- (1) developing the first set of learnable algorithms for reinforcement learning in structured domains with interacting objects and (2) developing probabilistic inference techniques that exploit underlying symmetries to efficeintly answer probabilistic queries. The outcomes of the two directions are clearly related. The grand vision of the proposal is to solve relational POMDPs i.e., learning to act in stochastic, noisy, partially observable structured domains. To realize this goal, it is important that the agent reasons with partial information which is achieved by lifted probabilistic inference (the PI has co-edited the first book in this topic and the book was released by MIT Press in August 2021). Once the probabilistic inference is performed, the agent has to efffectively use these probabilistic inference results in selecting the best set of actions. This is achieved by developing the efficient relational reinforcement learning methods, which is the first outcome. Our extensive experiments demonstrate that advancement in a single research area such as deep networks is not sufficient to realize the grand vision. Instead, progress in multiple areas such as deep networks, reinforcement learning, symbolic representations, and probabilistic inference, to name a few, are necessary. It is crucial that these different progresses are integrated in an AI system and our project takes a step in that direction.</p>\n<p>Collectively, the two outcomes of this project have allowed the group to take the first step towards realizing the grand vision of the proposal in particular and the AI community in general.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/15/2021<br>\n\t\t\t\t\tModified by: Sriraam&nbsp;Natarajan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe key outcomes of this project are two-fold -- (1) developing the first set of learnable algorithms for reinforcement learning in structured domains with interacting objects and (2) developing probabilistic inference techniques that exploit underlying symmetries to efficeintly answer probabilistic queries. The outcomes of the two directions are clearly related. The grand vision of the proposal is to solve relational POMDPs i.e., learning to act in stochastic, noisy, partially observable structured domains. To realize this goal, it is important that the agent reasons with partial information which is achieved by lifted probabilistic inference (the PI has co-edited the first book in this topic and the book was released by MIT Press in August 2021). Once the probabilistic inference is performed, the agent has to efffectively use these probabilistic inference results in selecting the best set of actions. This is achieved by developing the efficient relational reinforcement learning methods, which is the first outcome. Our extensive experiments demonstrate that advancement in a single research area such as deep networks is not sufficient to realize the grand vision. Instead, progress in multiple areas such as deep networks, reinforcement learning, symbolic representations, and probabilistic inference, to name a few, are necessary. It is crucial that these different progresses are integrated in an AI system and our project takes a step in that direction.\n\nCollectively, the two outcomes of this project have allowed the group to take the first step towards realizing the grand vision of the proposal in particular and the AI community in general. \n\n\t\t\t\t\tLast Modified: 09/15/2021\n\n\t\t\t\t\tSubmitted by: Sriraam Natarajan"
 }
}