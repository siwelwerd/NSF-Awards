{
 "awd_id": "1815047",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small:Collaborative Research: Decentralized Real-Time Machine Learning Systems on Near-User Edge Devices",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922594",
 "po_email": "kkaravan@nsf.gov",
 "po_sign_block_name": "Karen Karavanic",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 282000.0,
 "awd_min_amd_letter_date": "2018-08-13",
 "awd_max_amd_letter_date": "2020-05-08",
 "awd_abstract_narration": "The ever-increasing number of Internet of Things (IoT) devices generate large quantities of raw data that need to be processed and analyzed in real time.  Since conducting computationally expensive tasks, such as computer vision and natural language processing, is often a challenge for IoT devices, most of their computations are currently offloaded to cloud servers. However, this offloading leads to an increased risk for privacy as well as a dependency on network connectivity. To solve this challenge, the project utilizes the distributed computing power of already connected IoT devices to perform high computing power applications in real time.\r\n\r\nThe project is composed of three tasks. First is the development of distributed machine learning (ML) systems for multiple IoT devices.  The project will involve studying how to communicate between nodes with reliable connections and how to dynamically change the job of each node at run-time with little overhead. Second is the development of optimal task assignment and scheduling algorithms. Here, a machine learning approach will be used to generate a recognition model architecture optimal for each distributed system configuration. Third is the development of low-resolution deep neural network (DNN) systems to utilize low-power computing nodes. The development of these DNN systems will involve identifying multiple low-resolution filters that are optimal for varying configurations.\r\n\r\nThe proposed technical work will advance the state of the art in implementation of parallel and decentralized DNN systems, thereby benefiting all scientific fields of endeavor that rely on computing. The decentralized DNN system will offer new opportunities in power constrained mobile platforms for applications including surveillance and automotive. The research results will lead to new materials/courses for computer architecture and systems. The proposed infrastructure will also be used to guide undergraduate students' research activities. \r\n\r\nThe software infrastructure will be maintained as an open source project, which can be found at https://github.com/parallel-ml.  It will be updated periodically as new outcomes become available. The results will be published in conferences, journals and technical reports.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hyesoon",
   "pi_last_name": "Kim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hyesoon Kim",
   "pi_email_addr": "hyesoon@cc.gatech.edu",
   "nsf_id": "000084212",
   "pi_start_date": "2018-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 250000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Deep neural networks (DNNs) have seen rapid advancements in recent years, making them well-suited for computer vision, natural language processing, and video recognition on intelligent devices. However, these devices often need more computing power to handle high-performance DNN tasks. This program aims to find ways to effectively use low-power edge devices for complex DNN tasks by collaboratively exploring multiple devices or optimizing DNN computing systems and algorithms for edge devices.</p>\n<p>The major intellectual outcomes of this program in both system-level solutions and algorithmic-level solutions are as follows:</p>\n<p>(i) We developed distributing machine learning (ML) workloads across multiple edge devices. Our innovations propose systemic distribution methods and robust distribution methods.</p>\n<p>(ii) We developed algorithms that can extract critical information from low-resolution images, which reduces the amount of computing power needed. For example, we can maximize the information collected by utilizing multiple low-resolution image transformations.</p>\n<p>(iii) We developed and demonstrated automating the search and execution of the most effective ML algorithm and input settings for a given edge computing power and specific ML tasks. The fundamental idea is that depending on the input images or the tasks, different ML algorithms may perform optimally and reduce computation without quality degradation.</p>\n<p>(iv) We proposed a new CNN that captures motion information efficiently for video understanding and implemented a supervised label generation to further decrease edge computing requirements.</p>\n<p>(v) We demonstrated that by reducing the computing requirements of DNNs by utilizing quantization techniques or cascading multiple ML algorithms.</p>\n<p>Our findings have been published in various journals and conferences, such as SIGMOD, CVPR, NeurIPS, FPL, and IISWC, among others. We have advanced and developed new algorithmic and system-level optimization techniques to enable low-computing power devices to handle complex ML workloads.</p>\n<p>This project's outcomes have potential applications in fields such as robotics, surveillance, automotive, environment, military, and bio-medical. During the project, two Ph.D. students graduated, and the project leads held several workshops and tutorials related to ML and CV on edge devices and developed several open-source projects.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/15/2023<br>\n\t\t\t\t\tModified by: Hyesoon&nbsp;Kim</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDeep neural networks (DNNs) have seen rapid advancements in recent years, making them well-suited for computer vision, natural language processing, and video recognition on intelligent devices. However, these devices often need more computing power to handle high-performance DNN tasks. This program aims to find ways to effectively use low-power edge devices for complex DNN tasks by collaboratively exploring multiple devices or optimizing DNN computing systems and algorithms for edge devices.\n\nThe major intellectual outcomes of this program in both system-level solutions and algorithmic-level solutions are as follows:\n\n(i) We developed distributing machine learning (ML) workloads across multiple edge devices. Our innovations propose systemic distribution methods and robust distribution methods.\n\n(ii) We developed algorithms that can extract critical information from low-resolution images, which reduces the amount of computing power needed. For example, we can maximize the information collected by utilizing multiple low-resolution image transformations.\n\n(iii) We developed and demonstrated automating the search and execution of the most effective ML algorithm and input settings for a given edge computing power and specific ML tasks. The fundamental idea is that depending on the input images or the tasks, different ML algorithms may perform optimally and reduce computation without quality degradation.\n\n(iv) We proposed a new CNN that captures motion information efficiently for video understanding and implemented a supervised label generation to further decrease edge computing requirements.\n\n(v) We demonstrated that by reducing the computing requirements of DNNs by utilizing quantization techniques or cascading multiple ML algorithms.\n\nOur findings have been published in various journals and conferences, such as SIGMOD, CVPR, NeurIPS, FPL, and IISWC, among others. We have advanced and developed new algorithmic and system-level optimization techniques to enable low-computing power devices to handle complex ML workloads.\n\nThis project's outcomes have potential applications in fields such as robotics, surveillance, automotive, environment, military, and bio-medical. During the project, two Ph.D. students graduated, and the project leads held several workshops and tutorials related to ML and CV on edge devices and developed several open-source projects.\n\n \n\n\t\t\t\t\tLast Modified: 01/15/2023\n\n\t\t\t\t\tSubmitted by: Hyesoon Kim"
 }
}