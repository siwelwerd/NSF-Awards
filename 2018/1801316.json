{
 "awd_id": "1801316",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SaTC: CORE: Medium: Collaborative: Contextual Integrity: From Theory to Practice",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925177",
 "po_email": "asquicci@nsf.gov",
 "po_sign_block_name": "Anna Squicciarini",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 399482.0,
 "awd_amount": 431482.0,
 "awd_min_amd_letter_date": "2018-07-26",
 "awd_max_amd_letter_date": "2021-05-19",
 "awd_abstract_narration": "Current user-facing computer systems apply a \"notice and consent\" approach to managing user privacy: the user is presented with a privacy notice and then must consent to its terms. Decades of prior research show that this approach is unmanageable: policies are vague, ambiguous, and often include legal terms that make them very difficult to understand, if they are even read at all. These problems are magnified across Internet of Things (IoT) devices, which may not include displays to present privacy information, and may become so ubiquitous in the environment that users cannot possibly determine when their data is actually being captured. This project aims to solve these problems by designing new privacy management systems that automatically infer users' context-specific privacy expectations and then use them to manage the data-capture and data-sharing behaviors of mobile and IoT devices in users' environments. The goals of this research are to better understand privacy expectations, design privacy controls that require minimal user intervention, and demonstrate how emergent technologies can be designed to empower users to best manage their privacy.\r\n\r\nThe theory of \"Privacy as Contextual Integrity\" (CI) postulates that privacy expectations are based on contextual norms, and that privacy violations occur when data flows in ways that defy these norms. The framework can be applied by modeling data flows in terms of the data type, sender, recipient, as well as the specific context (i.e., the purpose for which data is being shared). While this model makes intuitive sense, there are several open research questions that have prevented it from being applied in computer systems. Specifically, the project investigates how privacy expectations change across varying contexts through the use of surveys, interviews, and behavioral studies, and designs systems to automatically infer contextual information so that the process of determining whether or not a data flow is likely to defy user expectations can be automated. The investigators develop a prototype of the novel privacy controls and validate their usability and privacy-preserving properties through iterative laboratory and field experiments.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Norman",
   "pi_last_name": "Sadeh",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Norman M Sadeh",
   "pi_email_addr": "sadeh@cs.cmu.edu",
   "nsf_id": "000468857",
   "pi_start_date": "2018-07-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carneige Mellon University",
  "perf_str_addr": "5000 Forbes Avenue WQED Building",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 125366.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 141137.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 148979.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The theory of privacy as contextual integrity (CI) asserts that people&rsquo;s privacy expectations are shaped by contextual informational norms; it predicts that practices breaching these norms will be experienced as privacy violations. The theory further asserts that contextual informational norms prescribe data flows according to social context, actors, information types, and transmission principles, and that all of these parameters must be specified in modeling privacy expectations. Failure to do so results in faulty practices and ambiguous notices. Thus, to improve end-user privacy, research is needed to: 1) map information flows in terms of CI parameters, 2) inform users about them, and 3) ascertain whether these flows meet contextual norms and/or users&rsquo; expectations.</p>\n<p>An important part of this project was to develop methods and techniques to identify attributes that influence people&rsquo;s privacy expectations in different contexts and in relation to different applications and platforms. What are the important constraints that lead to nuanced preferences? How can systems detect when an application has shifted from an allowable data-sharing context to an unallowable one? How can knowledge of a user&rsquo;s preferences in one context be used to infer her preferences in other contexts? The project focused in particular on contexts associated with mobile app privacy and Internet of Things &nbsp;(IoT) privacy.</p>\n<p>The following summarizes some of the project's main outcomes:</p>\n<p>-The project contributed extensive new insight into people's privacy attitudes across a wide range of contexts representative of recent deployments of video analytics functionality. Results from this research were shared with regulatory agencies, including the Federal Trade Commission</p>\n<p>-The project also contributed to the development of a novel privacy infrastructure for the Internet of Things (IoT), which allows people who control and/or deploy Internet of Things resources (e.g. cameras, smart sensors, etc.) to publicize the presence of these devices and their data practices. The infrastructure also includes an IoT assistant app available in both the iOS store and the Google Play store, which enables people to discover nearby IoT resources, information about the data they collect, and settings that might possibly be available for them to restrict the collection and/or processing of their data. This infrastructure hosts well over 100,000 IoT resource descriptions and the IoT assistant app has been downloaded by tens of thousands of users.</p>\n<p>-The project showed how it is possible to extend Contextual Integrity to study public health related privacy issues such as the acceptance of COVID vaccination mandates and certificates, leading to a study that shed new light on how different groups of people feel about such mandates and certificates in different contexts</p>\n<p>-The project also helped better understand how security and privacy nudges based on protection motivation theory can be used to help people better protect themselves and adopt safer security and privacy practices</p>\n<p>-The project also contributed a framework to help organize the space of possible privacy choices one can make available to users in the context of IoT scenarios</p>\n<p>-The project contributed to the design, evaluation and adoption of a \"Do Not Sell My Personal Information\" button and accompanying text, which have been adopted by the State of California in the context of the California Consumer Privacy Protection Act (CCPA).</p>\n<p>Research results from this project have also been incorporated in courses taught at Carnegie Mellon University and in particular in the context of the University's Privacy Engineering Program.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/02/2024<br>\nModified by: Norman&nbsp;M&nbsp;Sadeh</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1801316/1801316_10561938_1704233617456_Screenshot_2024_01_02_at_5.07.13__8239_PM--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1801316/1801316_10561938_1704233617456_Screenshot_2024_01_02_at_5.07.13__8239_PM--rgov-800width.png\" title=\"People's Privacy Attitudes Across a Range of Videoanalytics Deployments\"><img src=\"/por/images/Reports/POR/2024/1801316/1801316_10561938_1704233617456_Screenshot_2024_01_02_at_5.07.13__8239_PM--rgov-66x44.png\" alt=\"People's Privacy Attitudes Across a Range of Videoanalytics Deployments\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Analyzing people's privacy attitudes towards videoanalytics deployments, looking at comfort level, surprise level, notification preferences and willingness to grant/deny collection and processing.</div>\n<div class=\"imageCredit\">CC BY-NC-ND</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Norman&nbsp;M&nbsp;Sadeh\n<div class=\"imageTitle\">People's Privacy Attitudes Across a Range of Videoanalytics Deployments</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe theory of privacy as contextual integrity (CI) asserts that peoples privacy expectations are shaped by contextual informational norms; it predicts that practices breaching these norms will be experienced as privacy violations. The theory further asserts that contextual informational norms prescribe data flows according to social context, actors, information types, and transmission principles, and that all of these parameters must be specified in modeling privacy expectations. Failure to do so results in faulty practices and ambiguous notices. Thus, to improve end-user privacy, research is needed to: 1) map information flows in terms of CI parameters, 2) inform users about them, and 3) ascertain whether these flows meet contextual norms and/or users expectations.\n\n\nAn important part of this project was to develop methods and techniques to identify attributes that influence peoples privacy expectations in different contexts and in relation to different applications and platforms. What are the important constraints that lead to nuanced preferences? How can systems detect when an application has shifted from an allowable data-sharing context to an unallowable one? How can knowledge of a users preferences in one context be used to infer her preferences in other contexts? The project focused in particular on contexts associated with mobile app privacy and Internet of Things (IoT) privacy.\n\n\nThe following summarizes some of the project's main outcomes:\n\n\n-The project contributed extensive new insight into people's privacy attitudes across a wide range of contexts representative of recent deployments of video analytics functionality. Results from this research were shared with regulatory agencies, including the Federal Trade Commission\n\n\n-The project also contributed to the development of a novel privacy infrastructure for the Internet of Things (IoT), which allows people who control and/or deploy Internet of Things resources (e.g. cameras, smart sensors, etc.) to publicize the presence of these devices and their data practices. The infrastructure also includes an IoT assistant app available in both the iOS store and the Google Play store, which enables people to discover nearby IoT resources, information about the data they collect, and settings that might possibly be available for them to restrict the collection and/or processing of their data. This infrastructure hosts well over 100,000 IoT resource descriptions and the IoT assistant app has been downloaded by tens of thousands of users.\n\n\n-The project showed how it is possible to extend Contextual Integrity to study public health related privacy issues such as the acceptance of COVID vaccination mandates and certificates, leading to a study that shed new light on how different groups of people feel about such mandates and certificates in different contexts\n\n\n-The project also helped better understand how security and privacy nudges based on protection motivation theory can be used to help people better protect themselves and adopt safer security and privacy practices\n\n\n-The project also contributed a framework to help organize the space of possible privacy choices one can make available to users in the context of IoT scenarios\n\n\n-The project contributed to the design, evaluation and adoption of a \"Do Not Sell My Personal Information\" button and accompanying text, which have been adopted by the State of California in the context of the California Consumer Privacy Protection Act (CCPA).\n\n\nResearch results from this project have also been incorporated in courses taught at Carnegie Mellon University and in particular in the context of the University's Privacy Engineering Program.\n\n\n\t\t\t\t\tLast Modified: 01/02/2024\n\n\t\t\t\t\tSubmitted by: NormanMSadeh\n"
 }
}