{
 "awd_id": "1815361",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Collaborative Research: Generative Adversarial Privacy: A Data-driven Approach to Guaranteeing Privacy and Utility",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 308000.0,
 "awd_min_amd_letter_date": "2018-06-18",
 "awd_max_amd_letter_date": "2019-02-20",
 "awd_abstract_narration": "There is a growing need to publish datasets for both public benefit (via data-driven research) and private gains (enterprise data sharing). However, consumer privacy concerns have largely stymied such efforts since large datasets also contain confidential information about participating individuals. This project leverages recent advancements in learning generative models directly from the datasets to introduce a novel framework called generative adversarial privacy (GAP). GAP formalizes adversarial learning as a game between a privatizer that wishes to learn the optimal privacy mechanism and any statistical adversary intent on learning the confidential features. This formalization is crucial to evaluate data-driven approaches against adversaries with strong inferential capabilities. This project will include interactions with Honeywell Labs as well as outreach and dissemination with Stanford industry partners in the electricity and smart cities sector. Outreach programs include exposing middle- and high-school girls to social network privacy challenges at ASU and K-12 teacher training on data science through the Stanford Office of Science Outreach Program.\r\n\r\nThe project will focus on three foundational problems. The first two ensure privacy of confidential features in the published data and involve developing: (i) theoretical limits of the GAP formulation for a large class of loss functions that capture a range of adversarial capabilities; and (ii) convergence guarantees of the proposed GAP model. The third problem focuses on guaranteeing identity privacy via synthetic datasets using a combination of generative models (to generate synthetic data from training data) and classes of statistical adversaries to understand the efficacy of generating synthetic datasets with both utility and privacy guarantees. A key element of this project involves testing on both publicly available datasets as well as proprietary data.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lalitha",
   "pi_last_name": "Sankar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lalitha Sankar",
   "pi_email_addr": "lalithasankar@asu.edu",
   "nsf_id": "000547715",
   "pi_start_date": "2018-06-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "PO Box 6011",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852876011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 300000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-3d5a7c07-7fff-5969-09f5-66493d61e24a\">\n<p dir=\"ltr\"><span>There are several important impacts the work completed by the end of Year 5 of this funded grant have for the principal discipline, namely information and data science. These are listed below:</span></p>\n<ol>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Relating theoretical guarantees on fairness and censoring under the strongest MAP decoding adversary to those possible in practice allows better evaluation of guarantees by neural networks,</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>An interesting result from this grant was to quantify how minimum mean squared error (MMSE) can be estimated by a single hidden layer neural network (simplest neural network) and how close is such a quantification from the true value. This can help identify when neural networks can reliably estimate MMSE, a key quantity in communications and signal processing algorithms.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Design of deep networks modeling randomizing mappings via generative networks including variational autoencoders for a variety of datasets is still a challenge. In particular, processing categorical data through deep neural architectures isn&rsquo;t straightforward and this research has made significant breakthroughs on this front. This can significantly change the way privacy/fairness mechanisms are computed and guarantees are provided for both utility and privacy.&nbsp;</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Stronger composition guarantees for differential privacy using information theoretic mappings and relationships between (epsilon, delta)-DP and Renyi measures of information.&nbsp;</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>New robust differentially private mechanisms including stronger composition results</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>New results clarifying how GANs can be trained using a loss-function perspective to avoid training instabilities</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>A theory of robust learning and classification using tunable loss functions</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Mechanisms to assure fairness and accuracy in machine learning models</span></p>\n</li>\n</ol></span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/08/2024<br>\nModified by: Lalitha&nbsp;Sankar</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\nThere are several important impacts the work completed by the end of Year 5 of this funded grant have for the principal discipline, namely information and data science. These are listed below:\n\n\n\n\nRelating theoretical guarantees on fairness and censoring under the strongest MAP decoding adversary to those possible in practice allows better evaluation of guarantees by neural networks,\n\n\n\n\nAn interesting result from this grant was to quantify how minimum mean squared error (MMSE) can be estimated by a single hidden layer neural network (simplest neural network) and how close is such a quantification from the true value. This can help identify when neural networks can reliably estimate MMSE, a key quantity in communications and signal processing algorithms.\n\n\n\n\nDesign of deep networks modeling randomizing mappings via generative networks including variational autoencoders for a variety of datasets is still a challenge. In particular, processing categorical data through deep neural architectures isnt straightforward and this research has made significant breakthroughs on this front. This can significantly change the way privacy/fairness mechanisms are computed and guarantees are provided for both utility and privacy.\n\n\n\n\nStronger composition guarantees for differential privacy using information theoretic mappings and relationships between (epsilon, delta)-DP and Renyi measures of information.\n\n\n\n\nNew robust differentially private mechanisms including stronger composition results\n\n\n\n\nNew results clarifying how GANs can be trained using a loss-function perspective to avoid training instabilities\n\n\n\n\nA theory of robust learning and classification using tunable loss functions\n\n\n\n\nMechanisms to assure fairness and accuracy in machine learning models\n\n\n\n\n\t\t\t\t\tLast Modified: 03/08/2024\n\n\t\t\t\t\tSubmitted by: LalithaSankar\n"
 }
}