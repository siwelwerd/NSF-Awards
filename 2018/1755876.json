{
 "awd_id": "1755876",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: SHF: Enabling Neuroevolution in Hardware",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2018-01-15",
 "awd_exp_date": "2019-12-31",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2018-01-11",
 "awd_max_amd_letter_date": "2018-01-11",
 "awd_abstract_narration": "Over the past few years, machine learning algorithms, especially neural networks (NN) have seen a surge of popularity owing to their potential in solving a wide variety of complex problems across image classification and speech recognition. Unfortunately, in order to be effective, NNs need to have the appropriate topology (connections between neurons) for the task at hand and have the right weights on the connections. This is known as supervised learning and requires training the NN by running it through terabytes to petabytes of data. This form of machine learning is infeasible for the emerging domain of autonomous systems (robots/drones/cars) which will often operate in environments where the right topology for the task may be unknown or keep changing, and robust training data is not available. Autonomous systems need the ability to mirror human-like learning, where we are continuously learning, and often from experiences rather than being explicitly trained. This is known as reinforcement learning (RL). The goal of this project will be on enabling RL in energy-constrained autonomous devices. If successful, this research will enable mass proliferation of automated robots or drones to assist human society. The learnings will also be used to develop new courses on cross-layer support for machine learning. \r\n\r\nThe focus of the research will be on neuroevolution (NE), a class of RL algorithms that evolve NN topologies and weights using evolutionary algorithms.  The idea is to run multiple \"parent\" NNs in parallel, have the environment provide a reward (score) to the actions of all NNs, and create a population of new \"child\" NNs that preserve those nodes and connections from the parents that lead to actions producing the maximum reward. Running NE algorithms over multiple iterations has been shown to evolve complex behaviors in NNs. Unfortunately, NEs are computationally very expensive and have required large scale compute clusters running for hours before converging. A characterization of the computation and memory behavior of NE algorithms will be performed, and opportunities to massively parallelize these algorithms across genes (i.e., nodes and connections in the NN) will be explored. The evolutionary learning steps of crossover and mutation will be performed over specialized hardware engines, and a low-power architectural platform running NE algorithms at the edge will be demonstrated. Furthermore, the proposed research will serve as the foundation for further research in fast and energy-efficient RL algorithms to help realize general-purpose artificial intelligence.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tushar",
   "pi_last_name": "Krishna",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tushar Krishna",
   "pi_email_addr": "tushar@ece.gatech.edu",
   "nsf_id": "000711282",
   "pi_start_date": "2018-01-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p2\"><span class=\"s1\"><strong>Overview:</strong></span></p>\n<p class=\"p2\"><span class=\"s1\">Recent advancements in machine learning algorithms, especially the development of Deep Neural Networks (DNNs) have transformed the landscape of Artificial Intelligence (AI). With every passing day, deep learning based methods are applied to solve new problems with exceptional results.</span></p>\n<p class=\"p2\"><span class=\"s1\">The portal to the real world is the edge. The true impact of AI can be fully realized if we can have AI agents such as robots/drones continuously interacting with the real world and solving everyday problems across efficient logistics,&nbsp;healthcare, disaster management, and so on. Unfortunately, high compute and memory requirements of&nbsp;DNNs&nbsp;acts a huge barrier towards this vision. Today we circumvent this problem by deploying special purpose inference hardware on the edge while procuring trained models from the cloud. This approach, however, relies on constant interaction the cloud for transmitting all the data, training on massive&nbsp;GPU&nbsp;clusters, and downloading updated models. This is challenging for bandwidth, privacy, and constant connectivity concerns that autonomous agents may exhibit.</span></p>\n<p class=\"p2\"><span class=\"s1\">Through this grant, we evaluate techniques for enabling adaptive intelligence on edge devices with zero interaction with any high-end cloud/server.</span></p>\n<p class=\"p1\"><span class=\"s1\">&nbsp;</span></p>\n<p class=\"p2\"><span class=\"s1\"><strong>Intellectual Merit:</strong></span></p>\n<p class=\"p2\"><span class=\"s1\">Specifically, over the course of the last&nbsp; two years, we have been exploring the opportunities provided by \"Neuro-evolutionary\" algorithms to enable continuous learning on edge devices.&nbsp;Neuro-evolutionary use genetic algorithms to update the topology and weights of the DNN stochastically and pick the best DNNs for the task at hand. We&nbsp;have published two papers so far on this topic, and a third one is under submission.</span></p>\n<p class=\"p2\"><span class=\"s1\"><strong>Paper 1:&nbsp;</strong></span></p>\n<p class=\"p3\">Ananda Samajdar, Parth Mannan, Kartikay Garg, and Tushar Krishna, \"GeneSys: Enabling Continuous Learning through Neural Network Evolution in Hardware\", In Proc of 51st Annual IEEE/ACM International Symposium on Microarchitecture, Oct 2018.</p>\n<p class=\"p5\">&nbsp;</p>\n<p class=\"p4\">In this work, we characterized the compute and memory requirements of&nbsp;Neuro-evolutionary (NE) algorithms, and identified opportunities for getting performance speedups via parallelism. We&nbsp;<span class=\"s1\">developed GeneSys, a HW-SW prototype of a</span><span class=\"s1\">&nbsp;learning system, that comprises of a closed loop learning engine called EvE and an inference engine called ADAM. EvE can evolve the topology and weights of neural networks completely in hardware for the task at hand, without requiring hand-optimization or backpropogation training. ADAM continuously interacts with the environment and is optimized for efficiently running the irregular neural networks generated by EvE.&nbsp;GeneSys&nbsp;identifies and leverages multiple unique avenues of parallelism unique to EAs that we term &ldquo;gene&rdquo;- level parallelism, and &ldquo;population&rdquo;-level parallelism. We ran&nbsp;GeneSys&nbsp;with a suite of environments from OpenAI gym and observed 2-5 orders of magnitude higher energy-efficiency over state-of-the-art embedded and desktop CPU and GPU systems&nbsp;</span></p>\n<p class=\"p5\">&nbsp;</p>\n<p class=\"p5\">&nbsp;</p>\n<p class=\"p2\"><span class=\"s1\"><strong>Paper 2:&nbsp;</strong></span></p>\n<p class=\"p4\">Parth Mannan, Ananda Samajdar, and Tushar Krishna, \"CLAN: Exploring Continuous Learning on Commodity Edge Devices using Asynchronous Distributed Neuroevolution\", In Proc of the IEEE International Symposium on Performance Analysis of Systems and Software, April 2020.</p>\n<p class=\"p6\"><span class=\"s1\">&nbsp;</span></p>\n<p class=\"p6\"><span class=\"s1\">&nbsp;</span><span class=\"s2\">In this work, we built&nbsp;</span><span class=\"s1\">a prototype distributed system of Raspberry Pis called CLAN, communicating via WiFi running NeuroEvolutionary (NE) learning and inference. We evaluated the performance of such a collaborative system and detailed the compute/communication characteristics of different arrangements of the system that trade-off parallelism versus communication. Using insights from our analysis, we also proposed algorithmic modifications to reduce communication by up to 3.6x during the learning phase to enhance scalability even further and match performance of higher end computing devices at scale. We believe that these insights will enable algorithm-hardware co-design efforts for enabling continuous learning on the edge.&nbsp;</span></p>\n<p class=\"p5\">&nbsp;</p>\n<p class=\"p2\"><span class=\"s1\"><strong>Broader Impacts</strong></span></p>\n<p class=\"p3\"><span class=\"s2\">This grant funded the dissertation work of graduate students. The PI also hosted two undergraduate students and one High-School student in his lab to understand and deploy DNNs on&nbsp;</span><span class=\"s1\">Raspberry Pis and understand the performance limits. The PI also presented this research at the ARM Research Summit in Austin in September 2019 (attended by multiple industry researchers, faculty and students) and this work won the Best Presentation Award.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/08/2020<br>\n\t\t\t\t\tModified by: Tushar&nbsp;Krishna</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Overview:\nRecent advancements in machine learning algorithms, especially the development of Deep Neural Networks (DNNs) have transformed the landscape of Artificial Intelligence (AI). With every passing day, deep learning based methods are applied to solve new problems with exceptional results.\nThe portal to the real world is the edge. The true impact of AI can be fully realized if we can have AI agents such as robots/drones continuously interacting with the real world and solving everyday problems across efficient logistics, healthcare, disaster management, and so on. Unfortunately, high compute and memory requirements of DNNs acts a huge barrier towards this vision. Today we circumvent this problem by deploying special purpose inference hardware on the edge while procuring trained models from the cloud. This approach, however, relies on constant interaction the cloud for transmitting all the data, training on massive GPU clusters, and downloading updated models. This is challenging for bandwidth, privacy, and constant connectivity concerns that autonomous agents may exhibit.\nThrough this grant, we evaluate techniques for enabling adaptive intelligence on edge devices with zero interaction with any high-end cloud/server.\n \nIntellectual Merit:\nSpecifically, over the course of the last  two years, we have been exploring the opportunities provided by \"Neuro-evolutionary\" algorithms to enable continuous learning on edge devices. Neuro-evolutionary use genetic algorithms to update the topology and weights of the DNN stochastically and pick the best DNNs for the task at hand. We have published two papers so far on this topic, and a third one is under submission.\nPaper 1: \nAnanda Samajdar, Parth Mannan, Kartikay Garg, and Tushar Krishna, \"GeneSys: Enabling Continuous Learning through Neural Network Evolution in Hardware\", In Proc of 51st Annual IEEE/ACM International Symposium on Microarchitecture, Oct 2018.\n \nIn this work, we characterized the compute and memory requirements of Neuro-evolutionary (NE) algorithms, and identified opportunities for getting performance speedups via parallelism. We developed GeneSys, a HW-SW prototype of a learning system, that comprises of a closed loop learning engine called EvE and an inference engine called ADAM. EvE can evolve the topology and weights of neural networks completely in hardware for the task at hand, without requiring hand-optimization or backpropogation training. ADAM continuously interacts with the environment and is optimized for efficiently running the irregular neural networks generated by EvE. GeneSys identifies and leverages multiple unique avenues of parallelism unique to EAs that we term \"gene\"- level parallelism, and \"population\"-level parallelism. We ran GeneSys with a suite of environments from OpenAI gym and observed 2-5 orders of magnitude higher energy-efficiency over state-of-the-art embedded and desktop CPU and GPU systems \n \n \nPaper 2: \nParth Mannan, Ananda Samajdar, and Tushar Krishna, \"CLAN: Exploring Continuous Learning on Commodity Edge Devices using Asynchronous Distributed Neuroevolution\", In Proc of the IEEE International Symposium on Performance Analysis of Systems and Software, April 2020.\n \n In this work, we built a prototype distributed system of Raspberry Pis called CLAN, communicating via WiFi running NeuroEvolutionary (NE) learning and inference. We evaluated the performance of such a collaborative system and detailed the compute/communication characteristics of different arrangements of the system that trade-off parallelism versus communication. Using insights from our analysis, we also proposed algorithmic modifications to reduce communication by up to 3.6x during the learning phase to enhance scalability even further and match performance of higher end computing devices at scale. We believe that these insights will enable algorithm-hardware co-design efforts for enabling continuous learning on the edge. \n \nBroader Impacts\nThis grant funded the dissertation work of graduate students. The PI also hosted two undergraduate students and one High-School student in his lab to understand and deploy DNNs on Raspberry Pis and understand the performance limits. The PI also presented this research at the ARM Research Summit in Austin in September 2019 (attended by multiple industry researchers, faculty and students) and this work won the Best Presentation Award.\n\n \n\n\t\t\t\t\tLast Modified: 02/08/2020\n\n\t\t\t\t\tSubmitted by: Tushar Krishna"
 }
}