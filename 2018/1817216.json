{
 "awd_id": "1817216",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NeTS: Small: Support for Interactive AR/VR Video: Learning and Optimizing at the Network Edge",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922935",
 "po_email": "dmedhi@nsf.gov",
 "po_sign_block_name": "Deepankar Medhi",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2018-08-21",
 "awd_max_amd_letter_date": "2018-08-21",
 "awd_abstract_narration": "Augmented and virtual reality (AR/VR) are increasingly used in new application areas including entertainment, medicine, public safety, architecture, personnel training, etc. Mobile AR/VR systems allow users to be untethered, thus making it convenient for use in new settings. Edge networking and computing is a promising way to support demanding, low latency AR/VR applications, however there is a need for a deeper understanding of what functionality an edge system should provide to support those applications. \r\n\r\nThis project improves user experience with AR/VR applications by using compute capability in edge cloud nodes located close to the user. The goal is to implement a system for real-time streaming and analysis of AR/VR videos that jointly uses the network efficiently while maintaining a high user Quality of Experience (QoE). The first activity is to develop a common set of functional building blocks that implement a set of generic AR/VR applications.\r\nThe second goal is to develop the techniques to chain these building blocks together in a way that effectively uses an edge server composed of a mix of both set Central Processing Units (CPUs) and Graphics Processing Units (GPUs).  An evaluation will be performed on a testbed of AR/VR devices and smartphones through trace-driven simulations, using publicly-available user datasets.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jiasi",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jiasi Chen",
   "pi_email_addr": "jiasi@umich.edu",
   "nsf_id": "000702623",
   "pi_start_date": "2018-08-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kadangode",
   "pi_last_name": "Ramakrishnan",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Kadangode K Ramakrishnan",
   "pi_email_addr": "kk@cs.ucr.edu",
   "nsf_id": "000674291",
   "pi_start_date": "2018-08-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Riverside",
  "inst_street_address": "200 UNIVERSTY OFC BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "RIVERSIDE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9518275535",
  "inst_zip_code": "925210001",
  "inst_country_name": "United States",
  "cong_dist_code": "39",
  "st_cong_dist_code": "CA39",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA AT RIVERSIDE",
  "org_prnt_uei_num": "",
  "org_uei_num": "MR5QC5FCAVH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Riverside",
  "perf_str_addr": "308 Winston Chung Hall, 900 Univ",
  "perf_city_name": "Riverside",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "925210001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "39",
  "perf_st_cong_dist": "CA39",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-373f17e5-7fff-14ca-cbc1-20934526e6e8\" dir=\"ltr\"><span>This project studied several foundational building blocks of augmented and virtual reality (AR/VR) platforms to support applications on top. One computational bottleneck of AR/VR is device localization in the real world, which enables holograms to be accurately anchored to the real world and rendered at the right position and orientation. An AR/VR device does this by creating a 3D map of the world and localizing itself in that map. The process of creating the 3D map and tracking the device (localization) is commonly done using Simultaneous Localization and Mapping (SLAM), relying on camera and inertial measurement unit sensors.&nbsp;</span></p>\n<p dir=\"ltr\"><span>One main contribution of this project was exploring where computational building blocks such as SLAM should be run. Current multi-user AR platforms primarily allow asymmetric sharing of this SLAM information, with multiple \"secondary\" devices viewing holograms placed by a single \"primary\" device. In our SLAM-Share work (published in ACM CoNEXT'22), we enabled all AR devices to participate equally, by constructing a common global map to which all AR devices can contribute. Due to the resource constraints of mobile devices, an edge server performs many of the complex SLAM computations so that the client devices need only perform lightweight operations. The server utilizes a GPU, shared memory, and efficient map merging to build and update a global map from different clients. SLAM-Share is able to achieve significant tracking speedups (up to 50% latency reduction compared to alternative approaches) and maintain good localization accuracy by merging and updating maps very quickly. We also explored other solutions in the space of offloading strategies, such as peer-to-peer and hybrid architectures, and published the results in ACM SenSys'19 and ACM CoNEXT'20. The results from our investigations of various offloading architectures were synthesized into an IEEE Communications Magazine article. The article compared the pros and cons of different architectures for different use cases.</span></p>\n<p dir=\"ltr\"><span>Another key bottleneck of AR/VR is the communication of high resolution 360-degree VR videos from an edge server to client. Modeling and predicting user behavior (e.g., in terms of head movements or eye gaze) is necessary in order for an algorithm to decide what data to stream from an edge server to a client, and when. This project benchmarked the performance of several prediction algorithms of user head movements in order to provide quantitative guidance on how far into the future it is feasible to predict. The relative importance of network delay versus user variability on end-to-end latency was also explored.</span></p>\n<p dir=\"ltr\"><span>The project educated a number of students at the intersection of AR/VR and networking, a relatively unique topic, with 2 students receiving their PhDs on this topic. The project also trained several undergraduate students on AR/VR use cases such as public safety and education. Code for many of the research papers published as a result of this project are available on the PIs' webpages. Demos from this research were incorporated into undergraduate virtual reality classes at UCR as well as graduate courses on computer networking and cloud computing.</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/26/2024<br>\nModified by: Jiasi&nbsp;Chen</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project studied several foundational building blocks of augmented and virtual reality (AR/VR) platforms to support applications on top. One computational bottleneck of AR/VR is device localization in the real world, which enables holograms to be accurately anchored to the real world and rendered at the right position and orientation. An AR/VR device does this by creating a 3D map of the world and localizing itself in that map. The process of creating the 3D map and tracking the device (localization) is commonly done using Simultaneous Localization and Mapping (SLAM), relying on camera and inertial measurement unit sensors.\n\n\nOne main contribution of this project was exploring where computational building blocks such as SLAM should be run. Current multi-user AR platforms primarily allow asymmetric sharing of this SLAM information, with multiple \"secondary\" devices viewing holograms placed by a single \"primary\" device. In our SLAM-Share work (published in ACM CoNEXT'22), we enabled all AR devices to participate equally, by constructing a common global map to which all AR devices can contribute. Due to the resource constraints of mobile devices, an edge server performs many of the complex SLAM computations so that the client devices need only perform lightweight operations. The server utilizes a GPU, shared memory, and efficient map merging to build and update a global map from different clients. SLAM-Share is able to achieve significant tracking speedups (up to 50% latency reduction compared to alternative approaches) and maintain good localization accuracy by merging and updating maps very quickly. We also explored other solutions in the space of offloading strategies, such as peer-to-peer and hybrid architectures, and published the results in ACM SenSys'19 and ACM CoNEXT'20. The results from our investigations of various offloading architectures were synthesized into an IEEE Communications Magazine article. The article compared the pros and cons of different architectures for different use cases.\n\n\nAnother key bottleneck of AR/VR is the communication of high resolution 360-degree VR videos from an edge server to client. Modeling and predicting user behavior (e.g., in terms of head movements or eye gaze) is necessary in order for an algorithm to decide what data to stream from an edge server to a client, and when. This project benchmarked the performance of several prediction algorithms of user head movements in order to provide quantitative guidance on how far into the future it is feasible to predict. The relative importance of network delay versus user variability on end-to-end latency was also explored.\n\n\nThe project educated a number of students at the intersection of AR/VR and networking, a relatively unique topic, with 2 students receiving their PhDs on this topic. The project also trained several undergraduate students on AR/VR use cases such as public safety and education. Code for many of the research papers published as a result of this project are available on the PIs' webpages. Demos from this research were incorporated into undergraduate virtual reality classes at UCR as well as graduate courses on computer networking and cloud computing.\n\n\n\t\t\t\t\tLast Modified: 02/26/2024\n\n\t\t\t\t\tSubmitted by: JiasiChen\n"
 }
}