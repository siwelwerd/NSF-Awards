{
 "awd_id": "1825113",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Video Communication Technologies in Survey Data Collection",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927269",
 "po_email": "ceavey@nsf.gov",
 "po_sign_block_name": "Cheryl Eavey",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2022-04-30",
 "tot_intn_awd_amt": 581571.0,
 "awd_amount": 581571.0,
 "awd_min_amd_letter_date": "2018-08-17",
 "awd_max_amd_letter_date": "2018-08-17",
 "awd_abstract_narration": "This research project will examine data quality, participation, respondent experience, and costs in two promising but not yet widely deployed survey modes that use off-the-shelf video technology and are less costly than face to face (FTF) interviews: video-mediated (VM) interviews (live two-way communication via platforms like Skype) and video self-administered (VS) interviews, in which video-recorded interviewers ask the questions and respondents answer by typing or clicking. This project will compare these measures of data quality and costs in VM and VS interviews carried out by the same professional interviewers and in conventional online (textual) self-administered questionnaires, asking the same survey questions to members of a representative sample who are randomly assigned to one of these three modes. Because VM is synchronous and \"live\" like face-to-face (FTF) interviewing, and VS is asynchronous and recorded but still projects a human face, the project's comparisons will provide new insights regarding how these decomposable aspects of human contact affect behavior and experience in surveys. The project's results will reveal the extent to which, and for whom, less costly interaction (live but remote vs. recorded) with an interviewer promotes engagement and data quality comparable to what is found in similar FTF interviews. More generally, the findings will address when and in what ways modern communication modes that reduce social presence and are less personal might be equal to or even more effective than FTF interaction. Findings from this project will provide valuable information relevant to the future of survey measurement and will be of interest to survey researchers in the Federal statistical system and other survey organizations.\r\n\r\nEven as survey data continue to be central to public policy and decision-making, survey measurement is challenged by declining response rates, increasing costs, declining trust in survey organizations, and rapidly changing communication habits among the public.  Understanding how video technologies could fit into the future of survey data collection is important both because it may meet potential respondents \"where they live\" and because it may provide a significantly lower cost alternative to FTF interviewing. There is even the potential to reach some members of the public whose location makes FTF interviewing difficult or expensive, but who may well be able to participate in a video interview (e.g., people who live in remote rural areas or members of the military deployed overseas).  In comparing data quality across these three survey modes, the project will quantify participation rates, connectivity problems, respondent compliance with the video interviewing protocol, conscientious responding (giving precise answers to numerical questions, thoughtfully differentiating answers), and disclosure of sensitive information. The project will measure the potential impact of individual interviewers, feelings of engagement with the interview, rapport with the interviewer, and respondent satisfaction. The project also will allow assessment of data collection costs across these modes.  Access to and use of video technologies are not universal, and even among those with access some are willing to engage in video interaction while others are reluctant. The project will begin to address whether and how the effects of video technologies on survey data collection differ for participants with different levels of prior experience and preference for using the technologies.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Frederick",
   "pi_last_name": "Conrad",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Frederick G Conrad",
   "pi_email_addr": "fconrad@umich.edu",
   "nsf_id": "000163076",
   "pi_start_date": "2018-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "3003 S. State Street",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091274",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "133300",
   "pgm_ele_name": "Methodology, Measuremt & Stats"
  },
  {
   "pgm_ele_code": "880000",
   "pgm_ele_name": "SCIENCE RESOURCES STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 581571.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><blockquote>\n<div dir=\"ltr\">\n<div class=\"gmail_default\">\n<p style=\"padding-left: 30px; text-align: left;\">&nbsp;</p>\n<p>The project explored the costs and benefits of collecting survey data via live video interviews, as in a Zoom meeting, and prerecorded video interviews, i.e., a web survey in which respondents play a video recording of an interviewer reading each survey question&nbsp;and answer by typing or clicking. The main goal of the study was to compare the quality of survey responses collected in these interview modes to response quality in a conventional (textual) web survey. Data quality is assumed to be higher when respondents take fewer mental shortcuts and endorse answers that are less socially desirable (and presumably more candid). In addition, the respondents&rsquo; subjective experience (e.g., satisfaction, sense of privacy) is compared across the three modes. In contrast to live video interviews which are administered in real time by a live interviewer, prerecorded video interviews and the conventional web survey are considered self-administered in that a live interviewer is not involved. The prerecorded video mode was intended to be a hybrid &ndash; self-administered but the questions are presented orally by a recorded interviewer. In addition, the project investigated the extent to which live video and prerecorded video interviews produce interviewer effects, i.e., statistical clustering of responses due to the interviewers. This kind of clustering produces what is known as &ldquo;interviewer effects,&rdquo; and has been observed in in-person and telephone interviews but has not been previously studied in live video interviews or prerecorded video interviews. The concern about interviewer effects of this type is that they increase overall response variance, thus reducing the precision of the survey estimates based on those responses.</p>\n<p>Live video respondents provided higher quality data than did their counterparts in the self-administered modes for one measure of taking mental shortcuts,&nbsp;<em>non-differentiation,&nbsp;</em>i.e., selecting the same response option for all questions in a battery of questions that use the same response scale. More specifically, non-differentiation was less frequent in live video interviews than the other modes. This is likely attributable to the live interviewer engaging respondents and motivating them to be conscientious. The live video respondents also reported being more satisfied with their data collection experience. Despite these benefits there some costs are associated with live video interviews. In particular, they led to lower quality by their greater tendency to provide rounded numerical responses (divisible by ten) and more socially desirable responses than their counterparts in the two self-administered modes. The increased rounding in live video interviews is likely due to time pressure created by knowing that a live interviewer is waiting for an answer and the increased social desirability is presumably due to the mere presence of another person, albeit mediated by video, who might judge the respondent based on their answers, possibly conveyed through facial expressions.</p>\n<p>The prerecorded video mode did have some hybrid characteristics, combining some of the benefits of interviewer administration and the absence of an interviewer. Respondents interviewed in this mode rounded their answers to fewer questions than did their web survey counterparts, presumably because the presence of an interviewer, albeit recorded, motivated respondents to engage and invest effort (and the design of prerecorded video removed the time pressure likely present in live video interviews); at the same time, respondents in prerecorded video interviews selected sensitive answers for fewer questions than did their web survey counterparts which we attribute to their developing a kind of rapport with the video recorded interviewer, an interpretation echoed in how they reported their subjective experience: 71% of respondents in this mode reported being &ldquo;connected&rdquo; to the (recorded) interviewer and 69% reported being &ldquo;comfortable&rdquo; with the interviewer.</p>\n<p>Interviewer effects were rare in the two modes and to the extent they were observed they were small. This is reassuring for practitioners considering either live video or prerecorded video interviews for collecting survey data.</p>\n<p>Overall, if a study requires face-to-face, real time data collection, live video interviews may be a cost-effective alternative (no travel costs for interviewers in contrast to in-person data collection). If the study is a candidate for online data collection, prerecorded video may help improve data quality compared to a conventional web survey at marginal additional cost.&nbsp;&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p style=\"padding-left: 30px; text-align: left;\">&nbsp;</p>\n</div>\n</div>\n</blockquote><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/09/2022<br>\n\t\t\t\t\tModified by: Frederick&nbsp;G&nbsp;Conrad</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\n \n\nThe project explored the costs and benefits of collecting survey data via live video interviews, as in a Zoom meeting, and prerecorded video interviews, i.e., a web survey in which respondents play a video recording of an interviewer reading each survey question and answer by typing or clicking. The main goal of the study was to compare the quality of survey responses collected in these interview modes to response quality in a conventional (textual) web survey. Data quality is assumed to be higher when respondents take fewer mental shortcuts and endorse answers that are less socially desirable (and presumably more candid). In addition, the respondents\u2019 subjective experience (e.g., satisfaction, sense of privacy) is compared across the three modes. In contrast to live video interviews which are administered in real time by a live interviewer, prerecorded video interviews and the conventional web survey are considered self-administered in that a live interviewer is not involved. The prerecorded video mode was intended to be a hybrid &ndash; self-administered but the questions are presented orally by a recorded interviewer. In addition, the project investigated the extent to which live video and prerecorded video interviews produce interviewer effects, i.e., statistical clustering of responses due to the interviewers. This kind of clustering produces what is known as \"interviewer effects,\" and has been observed in in-person and telephone interviews but has not been previously studied in live video interviews or prerecorded video interviews. The concern about interviewer effects of this type is that they increase overall response variance, thus reducing the precision of the survey estimates based on those responses.\n\nLive video respondents provided higher quality data than did their counterparts in the self-administered modes for one measure of taking mental shortcuts, non-differentiation, i.e., selecting the same response option for all questions in a battery of questions that use the same response scale. More specifically, non-differentiation was less frequent in live video interviews than the other modes. This is likely attributable to the live interviewer engaging respondents and motivating them to be conscientious. The live video respondents also reported being more satisfied with their data collection experience. Despite these benefits there some costs are associated with live video interviews. In particular, they led to lower quality by their greater tendency to provide rounded numerical responses (divisible by ten) and more socially desirable responses than their counterparts in the two self-administered modes. The increased rounding in live video interviews is likely due to time pressure created by knowing that a live interviewer is waiting for an answer and the increased social desirability is presumably due to the mere presence of another person, albeit mediated by video, who might judge the respondent based on their answers, possibly conveyed through facial expressions.\n\nThe prerecorded video mode did have some hybrid characteristics, combining some of the benefits of interviewer administration and the absence of an interviewer. Respondents interviewed in this mode rounded their answers to fewer questions than did their web survey counterparts, presumably because the presence of an interviewer, albeit recorded, motivated respondents to engage and invest effort (and the design of prerecorded video removed the time pressure likely present in live video interviews); at the same time, respondents in prerecorded video interviews selected sensitive answers for fewer questions than did their web survey counterparts which we attribute to their developing a kind of rapport with the video recorded interviewer, an interpretation echoed in how they reported their subjective experience: 71% of respondents in this mode reported being \"connected\" to the (recorded) interviewer and 69% reported being \"comfortable\" with the interviewer.\n\nInterviewer effects were rare in the two modes and to the extent they were observed they were small. This is reassuring for practitioners considering either live video or prerecorded video interviews for collecting survey data.\n\nOverall, if a study requires face-to-face, real time data collection, live video interviews may be a cost-effective alternative (no travel costs for interviewers in contrast to in-person data collection). If the study is a candidate for online data collection, prerecorded video may help improve data quality compared to a conventional web survey at marginal additional cost.  \n\n \n\n \n \n\n\n\n\n\t\t\t\t\tLast Modified: 08/09/2022\n\n\t\t\t\t\tSubmitted by: Frederick G Conrad"
 }
}