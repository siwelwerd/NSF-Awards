{
 "awd_id": "1814745",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI:Small: Learning shape features with deep neural networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 449999.0,
 "awd_amount": 465999.0,
 "awd_min_amd_letter_date": "2018-08-11",
 "awd_max_amd_letter_date": "2019-04-18",
 "awd_abstract_narration": "This project investigates how to effectively learn shape features with deep neural networks from images. It has been commonly believed that features learned by deep neural networks from images include texture, color, and shape of objects. Although visualizations of learned features demonstrate that contours of objects are extracted in the process of deep learning, our preliminary results provide clear arguments that 2D shape features are not well captured by current deep neural networks. This project develops a framework for effective learning of shape features with deep neural networks. The research brings new insights to a core problem in computer vision: shape understanding, which relates to many subfields in computer vision ranging from low-level tasks, such as segmentation and image statistics, to high-level ones, such as visual retrieval and object detection in images. The project includes plan to deploy the research results directly to applications such as biodiversity study (species recognition). The project also involves high school students and undergraduates in research.\r\n\r\nThis project conducts both theoretical and experimental research to gain better understanding why shape features are not well captured by current deep neural networks. Then it develops new learning strategies specifically targeted for shape features by following two main alternatives: (1) constraining the filter learning for Convolutional Neural Networks so that they are more contour focused, and (2) designing special structures of Deep Neural Networks for learning shape representation. The project designs circular sequential networks for silhouette-based shape classification, which encode naturally contour context information while implicitly performing contour matching. It also extends these networks to sketches, which are composed of both closed and open contours. Attention models are investigated on shapes to analyze roles of parts in shape representations so as to improve further shape matching and recognition algorithms.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Longin Jan",
   "pi_last_name": "Latecki",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Longin Jan Latecki",
   "pi_email_addr": "latecki@temple.edu",
   "nsf_id": "000227657",
   "pi_start_date": "2018-08-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Haibin",
   "pi_last_name": "Ling",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Haibin Ling",
   "pi_email_addr": "hling@cs.stonybrook.edu",
   "nsf_id": "000516498",
   "pi_start_date": "2018-08-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Temple University",
  "inst_street_address": "1805 N BROAD ST",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2157077547",
  "inst_zip_code": "191226104",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "PA02",
  "org_lgl_bus_name": "TEMPLE UNIVERSITY-OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "QD4MGHFDJKU1",
  "org_uei_num": "QD4MGHFDJKU1"
 },
 "perf_inst": {
  "perf_inst_name": "Temple University",
  "perf_str_addr": "1925 N. 12th St.",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191221801",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "PA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 449999.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project has advanced object and activity recognition in images and videos by utilizing shape information of 2D objects, which is hard to capture by standard convolution based neural networks. We conducted both theoretical and experimental research to gain better understanding why shape features are not well captured by current deep neural networks. Then we developed new learning strategies specifically targeted for shape features. By utilizing shape context (SC) information, we were able to constrain the filter learning for Convolutional Neural Networks (CNNs) so that they are more contour focused. We have also utilized Transformers to improve shape-based object recognition. Transformers allow for attention modeling between different contour fragments, and hence they enhance the contribution of key shape features, e.g., those with high curvatures are more important for shape perception. Consequently, they improve shape matching and recognition algorithms. We applied the developed tools to classification and retrieval of sketches, which are composed of both closed and open contours. We have also utilized contours to improve semantic segmentation in deep learning frameworks, and applied the shape prior to downstream tasks such as visual tracking and image enhancement.</p>\n<p>The project has produced: over 40 publications presented in high-impact journals and at top vision conferences, open-source software, and served as a research material for two successfully defended PhD Theses. It has also provided training for undergraduate REU students at Temple University.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/15/2022<br>\n\t\t\t\t\tModified by: Longin Jan&nbsp;Latecki</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project has advanced object and activity recognition in images and videos by utilizing shape information of 2D objects, which is hard to capture by standard convolution based neural networks. We conducted both theoretical and experimental research to gain better understanding why shape features are not well captured by current deep neural networks. Then we developed new learning strategies specifically targeted for shape features. By utilizing shape context (SC) information, we were able to constrain the filter learning for Convolutional Neural Networks (CNNs) so that they are more contour focused. We have also utilized Transformers to improve shape-based object recognition. Transformers allow for attention modeling between different contour fragments, and hence they enhance the contribution of key shape features, e.g., those with high curvatures are more important for shape perception. Consequently, they improve shape matching and recognition algorithms. We applied the developed tools to classification and retrieval of sketches, which are composed of both closed and open contours. We have also utilized contours to improve semantic segmentation in deep learning frameworks, and applied the shape prior to downstream tasks such as visual tracking and image enhancement.\n\nThe project has produced: over 40 publications presented in high-impact journals and at top vision conferences, open-source software, and served as a research material for two successfully defended PhD Theses. It has also provided training for undergraduate REU students at Temple University.\n\n \n\n\t\t\t\t\tLast Modified: 10/15/2022\n\n\t\t\t\t\tSubmitted by: Longin Jan Latecki"
 }
}