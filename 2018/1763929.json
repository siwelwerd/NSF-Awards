{
 "awd_id": "1763929",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Collaborative Research: Mobile Elastic Edge Clouds for Scalable, Low-Latency Services",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Karen Karavanic",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 112614.0,
 "awd_amount": 120614.0,
 "awd_min_amd_letter_date": "2018-08-04",
 "awd_max_amd_letter_date": "2021-07-09",
 "awd_abstract_narration": "Smart wearables, the Internet of Things, and new application types, such as augmented reality promise to revolutionize how people interact with technology in their daily lives. While embedded and smart devices have growing capabilities, they still rely on a backend cloud infrastructure to provide additional storage and computational capacity. However, these new application types have characteristics such as strict performance requirements and frequent mobility that are ill suited for today's centralized clouds. This project will develop new system architectures that will increase the scalability, elasticity, and mobility of \"edge\" applications that connect to mobile users.\r\n\r\nTowards this end, the project will explore the communication and system architectures needed to effectively support edge cloud services. The project will leverage advances in network function virtualization to provide high performance networking, and will explore the communication and Operating System primitives needed to support scalable middleboxes and application endpoints. Using this platform as a base, the project will design models that capture the new challenges inherent in mobile edge cloud workloads. These models will be used to guide elastic scaling algorithms.\r\n\r\nWe are increasingly reliant on mobile computing devices to guide our cars, help us keep in touch with others, gather data of our surroundings, and more. The mobile elastic edge cloud platform being developed in this project will help improve the scalability, agility, and efficiency of edge clouds, allowing them to support new types of performance critical applications. The researchers will engage a broad range of students from the undergraduate to Ph.D. levels in the educational and research activities of this grant. \r\n\r\nThere will be a project website (http://faculty.cs.gwu.edu/timwood/projects/me2c) that includes all of the artifacts produced throughout the project as well as links to key related technologies and papers. The web repository will include all of the source code developed during the course of the project, documentation with guidance to adopters on using the software, and links to all the papers published and technical reports that are released publicly. The project web page will be maintained for a period of five years after the end of the project.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kadangode",
   "pi_last_name": "Ramakrishnan",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Kadangode K Ramakrishnan",
   "pi_email_addr": "kk@cs.ucr.edu",
   "nsf_id": "000674291",
   "pi_start_date": "2018-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Riverside",
  "inst_street_address": "200 UNIVERSTY OFC BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "RIVERSIDE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9518275535",
  "inst_zip_code": "925210001",
  "inst_country_name": "United States",
  "cong_dist_code": "39",
  "st_cong_dist_code": "CA39",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA AT RIVERSIDE",
  "org_prnt_uei_num": "",
  "org_uei_num": "MR5QC5FCAVH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Riverside",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "925210001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "39",
  "perf_st_cong_dist": "CA39",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 112614.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>New applications that promise to revolutionize how people interact with technology in their daily lives have unique characteristics such as strict latency requirements and frequent mobility that are ill suited for today's centralized clouds. We designed a new Mobile Elastic Edge Cloud (ME2C) architecture to provide a programmable, converged architecture that can be customized for the diverse needs of emerging applications.</p>\n<p>One of the primary contributions is to provide support on an edge platform for machine learning applications which require the computational support provided by GPU accelerators at the edge. Since many real-time applications require low-latency, high throughput machine learning (ML) functions resident in the network and in the cloud to perform learning and inference, having sufficient computing capability at the edge can be a significant enabler. We developed a better multiplexing on GPUs on edge cloud platforms to support running ML applications, especially Deep Neural Networks on high-end GPUs, such as the nVIDIA V100 GPUs. We created GSLICE, a framework to have controlled spatial and temporal sharing of the GPU by multiple DNNs. We have a true virtualization of the GPU that can be used my many of the applications using the edge cloud. We also used this to improve the tuning of DNNs, using Slice-Tune, which utilizes GSLICE as a base framework.</p>\n<p>The second area we have worked on has been to provide function as a service (serverless computing) on resource-constrained edge platforms. We have worked on Container Network Interface (CNI) plug-in evaluations, developing a better framework for autoscaling and function placement as well as load balancing in serverless edge computing, and also looking at using the extended Berkeley Packet Filter (eBPF) as a way to develop an improved side car for serverless computing in KNative. We extended the Knative serverless framework to improve its performance, scalability, and fairness for an edge cloud computing serverless platform that we call \"Mu\", primarily focused on the control plane. We also looked at supporting IoT workloads on edge clouds using Knative serverless frameworks and how to improve the support for it. We also looked at how CNIs can be improved to provide fast initialization of virtualization for an agile edge cloud computing environment. Finally, we developed an eBPF-based shared-memory framework called SPRIGHT that substantially enhances the data plane for serverless computing.</p>\n<p>A third area was to develop improved energy management in data centers, in particular leveraging the affinity of functions that communicate to place and migrate them so that related functions that communicate frequently are co-located. Our work in this area involved improving power management in Data Centers, especially smaller data centers. There were several aspects we worked on on. We combined Dynamic Voltage and Frequency Scaling (DVFS) techniques to take advantage of slack in latency of search queries and also Machine Learning techniques to predict the per-query service time and the error in the prediction to determine the right time to boost the CPU frequency.&nbsp; We also worked on improving our framework for improved consolidation of data centers while carefully factoring in the cost of migration of containerized applications from one server to another in a data center using graph-partitioning to improve placement and migration of containers.</p>\n<p>We have published several papers in all these areas. Two students got their PhDs (one advised by me, one advised by another colleague although I worked a lot with the student) and a 3<sup>rd</sup> PhD student is close to graduation at the time the project ended. I also supported a post-doctoral fellow who went on to a faculty position. The project also supported 3 undergraduate student researchers as part of a REU supplement. One undergraduate student (from an under-represented minority) worked on understanding and evaluating cloud orchestration environments and container networking interfaces (CNI). A second undergraduate student worked on understanding how to use edge clouds for automatic speech recognition, especially in the context of emergency management. A third undergraduate student examined using edge clouds, and shared memory for performing aggregation for Federated Learning. Multiple MS students also worked on projects related to this grant.</p>\n<p>The research on this project was done in close collaboration with our partner, Prof. Tim Wood of George Washington University. The project has led to several publications in international conferences and also journal publications. I believe that our ideas on GPU multiplexing will significantly improve how GPUs are used in edge clouds. Similarly, the control plane and data plane development will improve KNative and other Kubernetes based cloud environments to have a better autoscaling algorithm, placement/scheduling and an improved shared-memory based data plane. The use of eBPF to improve the sidecar functionality of serverless frameworks will also have long term impact.</p>\n<p>Overall, this has been a very successful series of efforts supported by the NSF grant, and we are very grateful to NSF for this support.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/29/2023<br>\n\t\t\t\t\tModified by: Kadangode&nbsp;K&nbsp;Ramakrishnan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nNew applications that promise to revolutionize how people interact with technology in their daily lives have unique characteristics such as strict latency requirements and frequent mobility that are ill suited for today's centralized clouds. We designed a new Mobile Elastic Edge Cloud (ME2C) architecture to provide a programmable, converged architecture that can be customized for the diverse needs of emerging applications.\n\nOne of the primary contributions is to provide support on an edge platform for machine learning applications which require the computational support provided by GPU accelerators at the edge. Since many real-time applications require low-latency, high throughput machine learning (ML) functions resident in the network and in the cloud to perform learning and inference, having sufficient computing capability at the edge can be a significant enabler. We developed a better multiplexing on GPUs on edge cloud platforms to support running ML applications, especially Deep Neural Networks on high-end GPUs, such as the nVIDIA V100 GPUs. We created GSLICE, a framework to have controlled spatial and temporal sharing of the GPU by multiple DNNs. We have a true virtualization of the GPU that can be used my many of the applications using the edge cloud. We also used this to improve the tuning of DNNs, using Slice-Tune, which utilizes GSLICE as a base framework.\n\nThe second area we have worked on has been to provide function as a service (serverless computing) on resource-constrained edge platforms. We have worked on Container Network Interface (CNI) plug-in evaluations, developing a better framework for autoscaling and function placement as well as load balancing in serverless edge computing, and also looking at using the extended Berkeley Packet Filter (eBPF) as a way to develop an improved side car for serverless computing in KNative. We extended the Knative serverless framework to improve its performance, scalability, and fairness for an edge cloud computing serverless platform that we call \"Mu\", primarily focused on the control plane. We also looked at supporting IoT workloads on edge clouds using Knative serverless frameworks and how to improve the support for it. We also looked at how CNIs can be improved to provide fast initialization of virtualization for an agile edge cloud computing environment. Finally, we developed an eBPF-based shared-memory framework called SPRIGHT that substantially enhances the data plane for serverless computing.\n\nA third area was to develop improved energy management in data centers, in particular leveraging the affinity of functions that communicate to place and migrate them so that related functions that communicate frequently are co-located. Our work in this area involved improving power management in Data Centers, especially smaller data centers. There were several aspects we worked on on. We combined Dynamic Voltage and Frequency Scaling (DVFS) techniques to take advantage of slack in latency of search queries and also Machine Learning techniques to predict the per-query service time and the error in the prediction to determine the right time to boost the CPU frequency.  We also worked on improving our framework for improved consolidation of data centers while carefully factoring in the cost of migration of containerized applications from one server to another in a data center using graph-partitioning to improve placement and migration of containers.\n\nWe have published several papers in all these areas. Two students got their PhDs (one advised by me, one advised by another colleague although I worked a lot with the student) and a 3rd PhD student is close to graduation at the time the project ended. I also supported a post-doctoral fellow who went on to a faculty position. The project also supported 3 undergraduate student researchers as part of a REU supplement. One undergraduate student (from an under-represented minority) worked on understanding and evaluating cloud orchestration environments and container networking interfaces (CNI). A second undergraduate student worked on understanding how to use edge clouds for automatic speech recognition, especially in the context of emergency management. A third undergraduate student examined using edge clouds, and shared memory for performing aggregation for Federated Learning. Multiple MS students also worked on projects related to this grant.\n\nThe research on this project was done in close collaboration with our partner, Prof. Tim Wood of George Washington University. The project has led to several publications in international conferences and also journal publications. I believe that our ideas on GPU multiplexing will significantly improve how GPUs are used in edge clouds. Similarly, the control plane and data plane development will improve KNative and other Kubernetes based cloud environments to have a better autoscaling algorithm, placement/scheduling and an improved shared-memory based data plane. The use of eBPF to improve the sidecar functionality of serverless frameworks will also have long term impact.\n\nOverall, this has been a very successful series of efforts supported by the NSF grant, and we are very grateful to NSF for this support.\n\n \n\n\t\t\t\t\tLast Modified: 06/29/2023\n\n\t\t\t\t\tSubmitted by: Kadangode K Ramakrishnan"
 }
}