{
 "awd_id": "1815538",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: A New Machine Learning Approach for Improved Entity Identification",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 320377.0,
 "awd_amount": 320377.0,
 "awd_min_amd_letter_date": "2018-08-15",
 "awd_max_amd_letter_date": "2021-09-13",
 "awd_abstract_narration": "Modern analytics rely on data integration to combine heterogeneous data into a unified repository they can tap into for insights, services, and scientific knowledge. The typical goal of data integration is to combine heterogeneous data about the same real-world entity into a canonical representation of that entity. Traditionally, entity canonicalization methods focus on structured data and leverage the semantics of the schema accompanying the data to come up with canonical entity representations. This dependency on data semantics makes existing entity canonicalization methods inapplicable to dark data, i.e., operational data that corresponds to unstructured, noisy, and incomplete data. This project will develop entity canonicalization methods that focus on unstructured and semi-structured data and are suitable for large-scale integration applications. This work will help ease the currently challenging procedure of heuristically consolidating matching information about the same entity into unified representations and thus enable dark data to be more effectively used in downstream analytics applications.\r\n\r\nThe emphasis of this work is on entity canonicalization techniques that leverage representation learning (a.k.a. feature learning) and deep learning. The combination of distributed representations with deep architectures has emerged as the de facto standard for analyzing and processing unstructured data. This project will develop new deep learning architectures for: (1) record linkage, i.e., clustering unstructured data records that provide information about the same entity; and (2) data fusion, i.e., combining matching unstructured records into a canonical representation of the underlying entity. For record linkage, this work will introduce new deep learning techniques that capture multi-context domain-specific knowledge to learn the semantic similarity between records. For data fusion, this project will design new multi-sequence to one-sequence encoder-decoder recurrent neural networks for data fusion with a particular focus on incomplete data. The outcomes of this project have the potential to advance the state-of-the-art in large scale data integration methods as well as machine learning methods for high-dimensional, sparse, and noisy data.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Theodoros",
   "pi_last_name": "Rekatsinas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Theodoros Rekatsinas",
   "pi_email_addr": "thodrek@cs.wisc.edu",
   "nsf_id": "000753548",
   "pi_start_date": "2018-08-15",
   "pi_end_date": "2021-09-13"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shivaram",
   "pi_last_name": "Venkataraman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shivaram Venkataraman",
   "pi_email_addr": "shivaram@cs.wisc.edu",
   "nsf_id": "000754274",
   "pi_start_date": "2021-09-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537151218",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 320377.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This NSF award allowed us to study new technologies that can be used to scale data integration over rich, heterogeneous data that capture relations over real-world entities. As part of our study we developed a diverse array of machine learning models to enable unsupervised data integration, we also introduced new primitives to allow users to form data integration workflows using vector similarity search, and finally we developed a new system for learning vector representations of large-scale graph-structured relational data in a resource-efficient manner. The work in the context of this award not only established new algorithmic methods for the problem of data integration but also introduced a new open-source system for scalable graph machine learning, called Marius. Here, graphs are essential to represent rich relational data. Our goal in Marius was to directly enable scientists to learn machine learning models on large graph structured data. Thus, we aimed to minimize the resources required for scaling graph machine learning methods and showed that Marius can support training ML models on billion-node graphs using just a single GPU. We also developed a high-level Python API that makes it simple for scientists to develop and train ML models. Marius has already been integrated in production deployments at industrial partners to enhance data integration pipelines. Marius is also available as open-source software at https://marius-project.org.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/03/2023<br>\n\t\t\t\t\tModified by: Shivaram&nbsp;Venkataraman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis NSF award allowed us to study new technologies that can be used to scale data integration over rich, heterogeneous data that capture relations over real-world entities. As part of our study we developed a diverse array of machine learning models to enable unsupervised data integration, we also introduced new primitives to allow users to form data integration workflows using vector similarity search, and finally we developed a new system for learning vector representations of large-scale graph-structured relational data in a resource-efficient manner. The work in the context of this award not only established new algorithmic methods for the problem of data integration but also introduced a new open-source system for scalable graph machine learning, called Marius. Here, graphs are essential to represent rich relational data. Our goal in Marius was to directly enable scientists to learn machine learning models on large graph structured data. Thus, we aimed to minimize the resources required for scaling graph machine learning methods and showed that Marius can support training ML models on billion-node graphs using just a single GPU. We also developed a high-level Python API that makes it simple for scientists to develop and train ML models. Marius has already been integrated in production deployments at industrial partners to enhance data integration pipelines. Marius is also available as open-source software at https://marius-project.org.\n\n\t\t\t\t\tLast Modified: 01/03/2023\n\n\t\t\t\t\tSubmitted by: Shivaram Venkataraman"
 }
}