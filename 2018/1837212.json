{
 "awd_id": "1837212",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: Medium: LEAR-CPS: Low-Energy computing for Autonomous mobile Robotic CPS via Co-Design of Algorithms and Integrated Circuits",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Linda Bushnell",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 1000000.0,
 "awd_amount": 1000000.0,
 "awd_min_amd_letter_date": "2018-09-10",
 "awd_max_amd_letter_date": "2018-09-10",
 "awd_abstract_narration": "The goal of this research is to enable a new era of low-energy mobile robotic Cyber-Physical Systems (CPS). The approach is the simultaneous design of the computing hardware with the computer algorithms, with input from the physics of the system. Applications include, but are not limited to, insect-size robotic bees for artificial pollination, robotic water striders for environmental monitoring, miniature underwater autonomous vehicles for inspection, orally-administered medical robotic vehicles that can intelligently navigate the digestive system, robotic gliders that can operate in the air or underwater for months at a time, and many more. The results will enable low-power computing for artificial intelligence and autonomy to complement the existing low-energy, miniature actuation and sensing systems that have already been developed. This will enable  low-energy, miniature mobile robotic CPSs that can still provide provable guarantees on completeness, optimality, robustness and safety. \r\n\r\nThis project will focus on the development of novel algorithms and novel computing hardware for miniature, energy-efficient mobile robotic CPS. The proposed research will enable low-energy computation for full autonomy by way of minimizing energy consumption during design time and run time, by simultaneously designing the algorithms and the computing hardware. Decision making algorithms will minimize computing energy during run time, for instance, by considering motions that may not require heavy computation for perception and planning. The project will demonstrate the new methods by constructing the smallest fully-autonomous aerial robotic vehicle ever built. We believe the proposed foundational research and the proposed demonstration will kickstart a new cyber-physical systems subfield at the intersection of the mobile robotics literature and the computing hardware (circuits) literature.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sertac",
   "pi_last_name": "Karaman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sertac Karaman",
   "pi_email_addr": "sertac@MIT.EDU",
   "nsf_id": "000635500",
   "pi_start_date": "2018-09-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Vivienne",
   "pi_last_name": "Sze",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Vivienne Sze",
   "pi_email_addr": "sze@mit.edu",
   "nsf_id": "000667275",
   "pi_start_date": "2018-09-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Ave.",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "791800",
   "pgm_ele_name": "CPS-Cyber-Physical Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 1000000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-0a2344b4-7fff-9ba2-8e58-16a651b8ff24\">\n<p dir=\"ltr\"><span>The major goal of the project is to develop the theories and methodologies for the co-design of computing hardware and algorithms that will enable low-energy robotic vehicles. Such vehicles include, but not limited to, miniature insect-size robotic systems, aerial or underwater gliders, lighter than air flyers, and many more can be enabled by low-energy computing. Applications in robotics range from robotic bees that can enable artificial pollination to tiny medical devices that can intelligently navigate in the human digestive system. It is worth noting that the application domain of this project reaches well beyond robotics, including virtual/augmented reality, medical implants, and pico-satellites. To achieve this goal, in this project we explored three key directions: efficient computing for mutual information, </span><span>balancing actuation and computing energy, and </span><span>efficient computing </span><span>depth estimation</span></p>\n<br />\n<p dir=\"ltr\"><span>A key bottleneck to robot exploration speed is the complexity of computing Shannon&rsquo;s mutual information (MI), which determines the next location that the robot should explore to reduce the uncertainty of an unknown environment. We applied multiple iterations of algorithm and hardware co-design to accelerate the computation of MI. First, we proposed a new algorithm that reorders the core operations to eliminate large summations resulting in orders of magnitude speed up and can compute MI directly on a compressed 3D map. Next, we designed a specialized memory subsystem that reduces read conflicts between parallel cores by optimizing memory mapping and arbitration, enabling a throughput at 94% of the theoretical limit.&nbsp; We then reformulated the MI algorithm to evaluate the entire map at once, revealing a recursive property that can be exploited for further reduction in computation. Finally, we showed how to handle the recursion dependencies using time-interleaved pipelining. Overall, we achieved seven orders of magnitude speed up, making it feasible to compute MI for an entire map in real-time for the first time.</span></p>\n<br />\n<p dir=\"ltr\"><span>We study a novel class of motion planning problems, inspired by emerging low-energy robotic vehicles, such as insect-size flyers, chip-size satellites, and high-endurance autonomous blimps, for which the energy consumed by computing hardware during planning a path can be as large as the energy consumed by actuation hardware during the execution of the same path. We propose a new algorithm, called Compute Energy Included Motion Planning (CEIMP). CEIMP operates similarly to any other anytime planning algorithm, except it stops when it estimates further computing will require more computing energy than potential savings in actuation energy. We show that CEIMP has the same asymptotic computational complexity as existing sampling-based motion planning algorithms, such as PRM*. We also show that CEIMP outperforms the average baseline of using maximum computing resources in realistic computational experiments involving 10 floor plans from MIT buildings. In one representative experiment, CEIMP outperforms the average baseline 90.6% of the time when energy to compute one more second is equal to the energy to move one more meter, and 99.7% of the time when energy to compute one more second is equal to or greater than the energy to move 3 more meters.</span></p>\n<br />\n<p dir=\"ltr\"><span>Depth sensing is a critical function for robotic tasks such as localization, mapping and obstacle detection. There has been a significant and growing interest in depth estimation from a single RGB image, due to the relatively low cost and size of monocular cameras.&nbsp; However, state-of-the-art single-view depth estimation algorithms are based on fairly complex deep neural networks that are too slow for real-time inference on an embedded platform, for instance, mounted on a micro aerial vehicle.&nbsp; We address the problem of fast depth estimation on embedded systems. We propose an efficient and lightweight encoder-decoder network architecture and apply network pruning to further reduce computational complexity and latency. In particular, we focus on the design of a low-latency decoder. Our methodology demonstrates that it is possible to achieve similar accuracy as prior work on depth estimation, but at inference speeds that are an order of magnitude faster. Our proposed network, FastDepth, runs at 178 fps on an NVIDIA Jetson TX2 GPU and at 27 fps when using only the TX2 CPU, with active power consumption under 10 W. FastDepth achieves close to state-of-the-art accuracy on the NYU Depth v2 dataset. This work demonstrates real-time monocular depth estimation using a deep neural network with the lowest latency and highest throughput on an embedded platform that can be carried by a micro aerial vehicle.</span></p>\n<br /></span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/11/2024<br>\nModified by: Sertac&nbsp;Karaman</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\nThe major goal of the project is to develop the theories and methodologies for the co-design of computing hardware and algorithms that will enable low-energy robotic vehicles. Such vehicles include, but not limited to, miniature insect-size robotic systems, aerial or underwater gliders, lighter than air flyers, and many more can be enabled by low-energy computing. Applications in robotics range from robotic bees that can enable artificial pollination to tiny medical devices that can intelligently navigate in the human digestive system. It is worth noting that the application domain of this project reaches well beyond robotics, including virtual/augmented reality, medical implants, and pico-satellites. To achieve this goal, in this project we explored three key directions: efficient computing for mutual information, balancing actuation and computing energy, and efficient computing depth estimation\n\n\n\n\nA key bottleneck to robot exploration speed is the complexity of computing Shannons mutual information (MI), which determines the next location that the robot should explore to reduce the uncertainty of an unknown environment. We applied multiple iterations of algorithm and hardware co-design to accelerate the computation of MI. First, we proposed a new algorithm that reorders the core operations to eliminate large summations resulting in orders of magnitude speed up and can compute MI directly on a compressed 3D map. Next, we designed a specialized memory subsystem that reduces read conflicts between parallel cores by optimizing memory mapping and arbitration, enabling a throughput at 94% of the theoretical limit. We then reformulated the MI algorithm to evaluate the entire map at once, revealing a recursive property that can be exploited for further reduction in computation. Finally, we showed how to handle the recursion dependencies using time-interleaved pipelining. Overall, we achieved seven orders of magnitude speed up, making it feasible to compute MI for an entire map in real-time for the first time.\n\n\n\n\nWe study a novel class of motion planning problems, inspired by emerging low-energy robotic vehicles, such as insect-size flyers, chip-size satellites, and high-endurance autonomous blimps, for which the energy consumed by computing hardware during planning a path can be as large as the energy consumed by actuation hardware during the execution of the same path. We propose a new algorithm, called Compute Energy Included Motion Planning (CEIMP). CEIMP operates similarly to any other anytime planning algorithm, except it stops when it estimates further computing will require more computing energy than potential savings in actuation energy. We show that CEIMP has the same asymptotic computational complexity as existing sampling-based motion planning algorithms, such as PRM*. We also show that CEIMP outperforms the average baseline of using maximum computing resources in realistic computational experiments involving 10 floor plans from MIT buildings. In one representative experiment, CEIMP outperforms the average baseline 90.6% of the time when energy to compute one more second is equal to the energy to move one more meter, and 99.7% of the time when energy to compute one more second is equal to or greater than the energy to move 3 more meters.\n\n\n\n\nDepth sensing is a critical function for robotic tasks such as localization, mapping and obstacle detection. There has been a significant and growing interest in depth estimation from a single RGB image, due to the relatively low cost and size of monocular cameras. However, state-of-the-art single-view depth estimation algorithms are based on fairly complex deep neural networks that are too slow for real-time inference on an embedded platform, for instance, mounted on a micro aerial vehicle. We address the problem of fast depth estimation on embedded systems. We propose an efficient and lightweight encoder-decoder network architecture and apply network pruning to further reduce computational complexity and latency. In particular, we focus on the design of a low-latency decoder. Our methodology demonstrates that it is possible to achieve similar accuracy as prior work on depth estimation, but at inference speeds that are an order of magnitude faster. Our proposed network, FastDepth, runs at 178 fps on an NVIDIA Jetson TX2 GPU and at 27 fps when using only the TX2 CPU, with active power consumption under 10 W. FastDepth achieves close to state-of-the-art accuracy on the NYU Depth v2 dataset. This work demonstrates real-time monocular depth estimation using a deep neural network with the lowest latency and highest throughput on an embedded platform that can be carried by a micro aerial vehicle.\n\n\n\n\n\t\t\t\t\tLast Modified: 03/11/2024\n\n\t\t\t\t\tSubmitted by: SertacKaraman\n"
 }
}