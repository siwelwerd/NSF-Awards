{
 "awd_id": "1843025",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Type II: Deep Learning and Combinatorial Algorithms for Inorganic Crystal Structure Prediction",
 "cfda_num": "47.049",
 "org_code": "03070000",
 "po_phone": "7032924942",
 "po_email": "dhess@nsf.gov",
 "po_sign_block_name": "Daryl Hess",
 "awd_eff_date": "2019-01-01",
 "awd_exp_date": "2022-12-31",
 "tot_intn_awd_amt": 299999.0,
 "awd_amount": 299999.0,
 "awd_min_amd_letter_date": "2018-08-22",
 "awd_max_amd_letter_date": "2018-08-22",
 "awd_abstract_narration": "NONTECHNICAL SUMMARY\r\nThis EAGER award supports research and education involving a new collaboration kindled at the MATDAT18 Datathon event focused on developing artificial intelligence methods to discover new materials or identify specific materials with desired properties for an application.  Methods involving computation, materials data, and the tools of data science offer the potential to find or design a material with desired properties much faster and at lower cost than traditional methods used by materials scientists and engineers. \r\n\r\nIn this project, the research team will develop novel machine learning techniques to mine knowledge from various publicly available databases on materials and their properties. The knowledge thus gained can be utilized for material selection and design.  The team will focus first on using the methods of data science and materials data from a large community repository obtained from using computers and theory to calculate the energy needed to form a material from its constitutive elements.  \r\n\r\nAll the techniques developed in this project will be coded as software for different computers. Software will be released as open source codes to the materials science and data science communities via a number of mechanisms including the GitHub. This project will also provide educational opportunities to graduate and undergraduate students and a first-hand research experience in data analysis for materials science. Results of this project will be incorporated in appropriate undergraduate and graduate courses. Strong efforts will be made to include minorities and women. Results of this project will be disseminated widely via publications in journals and international conferences.\r\n\r\nTECHNICAL SUMMARY\r\nThis EAGER award supports research and education involving a new collaboration kindled at the MATDAT18 Datathon event focused on developing deep learning predictors for formation energies and other materials properties. Large databases of computed material properties, such as The Materials Project and AFLOWLIB developed under Materials Genome Initiative, host properties of tens of thousands of materials. They are primarily employed to screen materials for various target applications such as photocatalysis and battery materials. Such databases can also be utilized to develop deep learning-based predictors of materials properties. These predictions are expected to be more accurate than predictions made using traditional machine learning (ML) techniques. \r\n\r\nEven cutting edge conventional ML methods such as Gradient Boosting or Random Forest of Trees have limited capacity, or the ability to learn, when compared to multi-layer deep artificial neural networks employed in deep learning to mine vast data. In this project the research team aims to develop a deep learning predictor for formation energy of crystals. The investigators also propose to develop other relevant combinatorial algorithms for solving this problem. Formation energy, which is the energy difference between the crystal and the constituent elements in their atomic form, is one of the most reliable properties available from these databases. The focus of this project is on fast and highly accurate prediction of formation energies and stability of materials by utilizing the superior capacity of deep learning systems and other algorithms to learn from big data.\r\n\r\nThe project will deliver a publicly accessible cyber infrastructure implementing a deep learning system capable of predicting formation energies for inorganic materials with an accuracy that is vastly superior to that of the predictors built with traditional ML models, and new forms of chemical representations of materials that can be reused to predict other properties of materials. One of the challenges in the employment of deep learning techniques is in the large training times taken by these algorithms. The research team plans to address this challenge with a variety of algorithmic innovations including novel parallel training algorithms. The investigators plan to employ a number of parallel architectures including CPU clusters and GPUs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMR",
 "org_div_long_name": "Division Of Materials Research",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanguthevar",
   "pi_last_name": "Rajasekaran",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sanguthevar Rajasekaran",
   "pi_email_addr": "rajasek@engr.uconn.edu",
   "nsf_id": "000096825",
   "pi_start_date": "2018-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Connecticut",
  "inst_street_address": "438 WHITNEY RD EXTENSION UNIT 1133",
  "inst_street_address_2": "",
  "inst_city_name": "STORRS",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "8604863622",
  "inst_zip_code": "062699018",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CT02",
  "org_lgl_bus_name": "UNIVERSITY OF CONNECTICUT",
  "org_prnt_uei_num": "",
  "org_uei_num": "WNTPS995QBM7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Connecticut",
  "perf_str_addr": "371 Fairfield Way, Unit 4155",
  "perf_city_name": "Storrs",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "062694155",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CT02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171200",
   "pgm_ele_name": "DMR SHORT TERM SUPPORT"
  },
  {
   "pgm_ele_code": "176500",
   "pgm_ele_name": "CONDENSED MATTER & MAT THEORY"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "054Z",
   "pgm_ref_txt": "(MGI) Materials Genome Initiative"
  },
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "9216",
   "pgm_ref_txt": "ADVANCED SOFTWARE TECH & ALGOR"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 299999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Background:</strong> Large databases of computed material properties, such as The Materials Project and AFLOWLIB developed under Materials Genome Initiative, host properties of tens of thousands of materials. They are primarily employed to screen materials for various target applications such as photocatalysis and battery materials. Such databases can be better utilized to develop deep learning based predictors of materials properties. These predictions are expected to be more accurate than predictions made using traditional machine learning (ML) techniques. Even cutting edge conventional ML methods such as Gradient Boosting or Random Forest of Trees have limited capacity (the ability to learn) when compared to multi-layer deep artificial neural networks employed in deep learning to mine such vast data. The focus of this project is on fast and highly accurate prediction of formation energies and stability of materials by utilizing the superior capacity of deep learning systems and other algorithms to learn from big data.</p>\n<p><strong>Intellectual Merit:</strong> A major product of this research is a learning system capable of predicting formation energies for inorganic materials with an accuracy that is vastly superior to that of the predictors built with traditional ML models, and new forms of chemical representations of materials that can be reused to predict other properties of materials. Some other specific contributions we have made include:&nbsp; a deep learning model called CrystalNet for the prediction of crystal properties, sparse deep learning models for materials science, an ML model for accurately predicting band gaps, an attention based subnetwork search algorithm for molecular property prediction, ML models for constructing biological scaffolds, language based models for materials genomics, a novel framework called KT (Knowledge Transfer) that can be used for transferring knowledge gained from a low capacity model to a high capacity model, and efficient randomized feature selection algorithms.&nbsp; Our research results have been published in top-notch journals and conferences such as Advances in Neural Information Processing Systems (NIPS), Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), ACM International Conference on Information and Knowledge Management (CIKM), International Joint Conference on AI (IJCAI), and Physical Review B. We have published a total of 17 research papers.</p>\n<p><strong>Broader Impact:</strong> To maximize scientific impact and use in industry and academia, the software tools we have built have been disseminated widely. Given the generic nature of the algorithms we have developed, they can be applied for different domains. For example, we have recently come up with a general technique called Knowledge Transfer that should be of interest in training large capacity ML models. 6 graduate students have worked on this project in the duration of the project. In addition, several undergraduate students have also worked. These students have received excellent training in materials and data science and conducting research. Some of these students have graduated with a Ph.D. and joined the industry. They are expected to apply the knowledge they have gained to solve real life problems. They will form the core of the highly trained workforce that is essential for the advanced industries that are so critical to the economies of our nation We have introduced the findings of this project in relevant courses as well. As a result, more students have been exposed to the topic of our research.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/06/2023<br>\n\t\t\t\t\tModified by: Sanguthevar&nbsp;Rajasekaran</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nBackground: Large databases of computed material properties, such as The Materials Project and AFLOWLIB developed under Materials Genome Initiative, host properties of tens of thousands of materials. They are primarily employed to screen materials for various target applications such as photocatalysis and battery materials. Such databases can be better utilized to develop deep learning based predictors of materials properties. These predictions are expected to be more accurate than predictions made using traditional machine learning (ML) techniques. Even cutting edge conventional ML methods such as Gradient Boosting or Random Forest of Trees have limited capacity (the ability to learn) when compared to multi-layer deep artificial neural networks employed in deep learning to mine such vast data. The focus of this project is on fast and highly accurate prediction of formation energies and stability of materials by utilizing the superior capacity of deep learning systems and other algorithms to learn from big data.\n\nIntellectual Merit: A major product of this research is a learning system capable of predicting formation energies for inorganic materials with an accuracy that is vastly superior to that of the predictors built with traditional ML models, and new forms of chemical representations of materials that can be reused to predict other properties of materials. Some other specific contributions we have made include:  a deep learning model called CrystalNet for the prediction of crystal properties, sparse deep learning models for materials science, an ML model for accurately predicting band gaps, an attention based subnetwork search algorithm for molecular property prediction, ML models for constructing biological scaffolds, language based models for materials genomics, a novel framework called KT (Knowledge Transfer) that can be used for transferring knowledge gained from a low capacity model to a high capacity model, and efficient randomized feature selection algorithms.  Our research results have been published in top-notch journals and conferences such as Advances in Neural Information Processing Systems (NIPS), Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), ACM International Conference on Information and Knowledge Management (CIKM), International Joint Conference on AI (IJCAI), and Physical Review B. We have published a total of 17 research papers.\n\nBroader Impact: To maximize scientific impact and use in industry and academia, the software tools we have built have been disseminated widely. Given the generic nature of the algorithms we have developed, they can be applied for different domains. For example, we have recently come up with a general technique called Knowledge Transfer that should be of interest in training large capacity ML models. 6 graduate students have worked on this project in the duration of the project. In addition, several undergraduate students have also worked. These students have received excellent training in materials and data science and conducting research. Some of these students have graduated with a Ph.D. and joined the industry. They are expected to apply the knowledge they have gained to solve real life problems. They will form the core of the highly trained workforce that is essential for the advanced industries that are so critical to the economies of our nation We have introduced the findings of this project in relevant courses as well. As a result, more students have been exposed to the topic of our research.\n\n \n\n\t\t\t\t\tLast Modified: 03/06/2023\n\n\t\t\t\t\tSubmitted by: Sanguthevar Rajasekaran"
 }
}