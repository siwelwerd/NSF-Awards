{
 "awd_id": "1838145",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: F: Collaborative Research: Collective Mining of Vertical Social Communities",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 427912.0,
 "awd_amount": 427912.0,
 "awd_min_amd_letter_date": "2018-09-06",
 "awd_max_amd_letter_date": "2023-08-15",
 "awd_abstract_narration": "A large fraction of internet social media content is found in thousands of specialized communities that are hosted by news outlets, typically in the form of reader forums or comments on news articles. The users of the such a site are said to form a vertical social community (VSC), because they deeply engage with a single media source.  While each VSC is tiny compared to broad communities such as Facebook, they are important because they expose how different segments of society feel about various world events. This can be a very useful resource for downstream intelligence and predictive analytics.  However, current web crawlers cannot effectively access VSCs. Thus their data is invisible to search engines, and remains hidden from analytics tools.  The goals of this project are to enable effective access to vertical social communities coalesced at news reports online, and to mine their comments and debates. This project will provide researchers with tools to collect data from these communities and analyze them.  The educational component of the project includes the involvement of graduate and undergraduate student training and research and the incorporation of research projects and results in courses.\r\n\r\nThe researchers will develop algorithms to unearth the content generated at thousands of vertical social communities and make their content transparently accessible to data management and analytics tools. The researchers will develop novel deep learning techniques for content detection, and build a novel scalable end-to-end system for real-time access and collective mining of these communities, capable of handling large parallel data streams based on shifting ideas. The specific algorithms will include user population estimation, bootstrap communication patterns for automatic crawling of content, and fine-grained sentiment analysis for intelligence and predictive analytics. Software tools will be made available to researchers in academe and industry. Distribution of free, open-source software for implementing the techniques developed will enhance existing research infrastructure.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eduard",
   "pi_last_name": "Dragut",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eduard Dragut",
   "pi_email_addr": "edragut@temple.edu",
   "nsf_id": "000583882",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Temple University",
  "inst_street_address": "1805 N BROAD ST",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2157077547",
  "inst_zip_code": "191226104",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "PA02",
  "org_lgl_bus_name": "TEMPLE UNIVERSITY-OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "QD4MGHFDJKU1",
  "org_uei_num": "QD4MGHFDJKU1"
 },
 "perf_inst": {
  "perf_inst_name": "Temple University - Of The Commonwealth System of Higher Edu",
  "perf_str_addr": "1801 North Broad Street,",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191226003",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "PA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 427912.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aimed to mine actionable data from vertical social communities (VSCs). VSCs referred to internet social media platforms that deeply engaged around a \"single\" media source, such as news comments on news sites. The core goals of the project were twofold: (1) to develop novel algorithms and deep (neural) linguistic models for content and sentiment analysis, and (2) to mine actionable content for collective social intelligence from vertical social communities.<br /><br />The project achieved the following main outcomes:<br /><br />A novel approach to web record extraction. Web records referred to structured data on a web page that embedded records retrieved from an underlying database using specific templates. Mining data records from the web enabled the integration of data from multiple websites to provide value-added services. The project revisited the assumptions commonly used in the literature for creating extraction algorithms and adapted them to reflect the characteristics of modern web pages. Based on these reformulated assumptions, the concept of invariants in web data records was introduced, along with a bottom-up, recursive approach to construct web records from these invariants. The proposed approach proved to be both effective and efficient, consistently outperforming state-of-the-art web record extraction methods on modern web pages.<br /><br />The first end-to-end large-scale crawling system for user comments. This project addressed two key problems: (1) locating comment sections on dynamically generated web pages and (2) interacting with commenting systems through query templates. An essential component of the system was an algorithm designed to predict the number of comments an article would receive. Another component analyzed the alignment of user comments with the content of an article. The proposed alignment algorithm matched user comments to articles based on content similarity, discussed entities, and topics.<br /><br />A novel framework for mining named entities from social media posts. This work introduced the Named Entity Recognition Globalizer pipeline, which was better suited for named entity recognition (NER) on microblog streams. It characterized the isolated message processing in existing NER systems as modeling local contextual embeddings, where knowledge from the immediate context of a message was used to suggest seed entity candidates. Additionally, it recognized that messages within a microblog stream were topically related and often repeated mentions of the same entity. By leveraging occurrence mining, the system extended traditional NER modeling by extracting additional mentions of seed entity candidates previously overlooked. These candidate mentions were grouped into well-defined clusters, which were used to generate pooled global embeddings from the collective context of the candidates within the stream. The global embeddings helped separate false positives from genuine entities, producing a refined NER output. The project also created a unified representation of entities and topics in online news using multilayer graphs. The graph layers represented articles and comments, respectively.<br /><br />A recommendation algorithm for predicting articles of interest. We developed a recommendation algorithm that predicted articles a user might find interesting based on their historical sequential commenting behavior on news articles. By analyzing this sequential behavior, the news recommendation problem was shown to belong to the class of session-based recommendations. The proposed method effectively captured the temporal dynamics of both users and news articles while maintaining interpretability. A lag-aware attention mechanism and a recency regularization technique were designed to model the time effects of news articles and comments.<br /><br />A study on Repeated Letter Forms (RLFs). This study examined the phenomenon of Repeated Letter Forms (RLFs), where individuals in online communication repeated letters within words to emphasize particular statements. These exaggerated spellings reflected users' attempts to mimic aspects of verbal speech in written messages. Traditional NLP tools often ignored or failed to recognize these nonstandard spellings. The study presented the first investigation into large language models (LLMs) and RLFs, introducing a two-stage Explainable Instruction Tuning framework to enhance both the performance and explainability of LLMs in handling RLFs. Additionally, a novel unified approach was proposed to quantify LLMs&rsquo; understanding of informal expressions. The research demonstrated that RLFs are expressive and can serve as indicators of document-level sentiment.<br /><br />A graph neural network-based learning-to-rank approach. We developed a graph neural network (GNN)-based learning-to-rank method capable of modeling both resource-query and resource-resource relationships. A pre-trained language model was utilized to extract semantic information from queries and resources. Additionally, a heterogeneous graph was explicitly constructed to preserve the structural information of query-resource relationships, with the GNN employed to extract this structural information. The graph was further enriched with resource-resource edges to enhance ranking accuracy. Extensive experiments on benchmark datasets demonstrated the high effectiveness of this approach for resource selection. The proposed method achieved state-of-the-art performance.<br /><br />Student involvement. The project engaged 5 PhD students, 2 MS students, and 5 undergraduate students. Among these, 3 PhD students, all MS students, and 3 undergraduate students graduated during the project. Notably, 5 of the students involved were female.<br /><br />Articts. The project resulted in 21 peer-reviewed publications as well as multiple datasets and source codes of our algorithms.</p><br>\n<p>\n Last Modified: 01/08/2025<br>\nModified by: Eduard&nbsp;Dragut</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project aimed to mine actionable data from vertical social communities (VSCs). VSCs referred to internet social media platforms that deeply engaged around a \"single\" media source, such as news comments on news sites. The core goals of the project were twofold: (1) to develop novel algorithms and deep (neural) linguistic models for content and sentiment analysis, and (2) to mine actionable content for collective social intelligence from vertical social communities.\n\nThe project achieved the following main outcomes:\n\nA novel approach to web record extraction. Web records referred to structured data on a web page that embedded records retrieved from an underlying database using specific templates. Mining data records from the web enabled the integration of data from multiple websites to provide value-added services. The project revisited the assumptions commonly used in the literature for creating extraction algorithms and adapted them to reflect the characteristics of modern web pages. Based on these reformulated assumptions, the concept of invariants in web data records was introduced, along with a bottom-up, recursive approach to construct web records from these invariants. The proposed approach proved to be both effective and efficient, consistently outperforming state-of-the-art web record extraction methods on modern web pages.\n\nThe first end-to-end large-scale crawling system for user comments. This project addressed two key problems: (1) locating comment sections on dynamically generated web pages and (2) interacting with commenting systems through query templates. An essential component of the system was an algorithm designed to predict the number of comments an article would receive. Another component analyzed the alignment of user comments with the content of an article. The proposed alignment algorithm matched user comments to articles based on content similarity, discussed entities, and topics.\n\nA novel framework for mining named entities from social media posts. This work introduced the Named Entity Recognition Globalizer pipeline, which was better suited for named entity recognition (NER) on microblog streams. It characterized the isolated message processing in existing NER systems as modeling local contextual embeddings, where knowledge from the immediate context of a message was used to suggest seed entity candidates. Additionally, it recognized that messages within a microblog stream were topically related and often repeated mentions of the same entity. By leveraging occurrence mining, the system extended traditional NER modeling by extracting additional mentions of seed entity candidates previously overlooked. These candidate mentions were grouped into well-defined clusters, which were used to generate pooled global embeddings from the collective context of the candidates within the stream. The global embeddings helped separate false positives from genuine entities, producing a refined NER output. The project also created a unified representation of entities and topics in online news using multilayer graphs. The graph layers represented articles and comments, respectively.\n\nA recommendation algorithm for predicting articles of interest. We developed a recommendation algorithm that predicted articles a user might find interesting based on their historical sequential commenting behavior on news articles. By analyzing this sequential behavior, the news recommendation problem was shown to belong to the class of session-based recommendations. The proposed method effectively captured the temporal dynamics of both users and news articles while maintaining interpretability. A lag-aware attention mechanism and a recency regularization technique were designed to model the time effects of news articles and comments.\n\nA study on Repeated Letter Forms (RLFs). This study examined the phenomenon of Repeated Letter Forms (RLFs), where individuals in online communication repeated letters within words to emphasize particular statements. These exaggerated spellings reflected users' attempts to mimic aspects of verbal speech in written messages. Traditional NLP tools often ignored or failed to recognize these nonstandard spellings. The study presented the first investigation into large language models (LLMs) and RLFs, introducing a two-stage Explainable Instruction Tuning framework to enhance both the performance and explainability of LLMs in handling RLFs. Additionally, a novel unified approach was proposed to quantify LLMs understanding of informal expressions. The research demonstrated that RLFs are expressive and can serve as indicators of document-level sentiment.\n\nA graph neural network-based learning-to-rank approach. We developed a graph neural network (GNN)-based learning-to-rank method capable of modeling both resource-query and resource-resource relationships. A pre-trained language model was utilized to extract semantic information from queries and resources. Additionally, a heterogeneous graph was explicitly constructed to preserve the structural information of query-resource relationships, with the GNN employed to extract this structural information. The graph was further enriched with resource-resource edges to enhance ranking accuracy. Extensive experiments on benchmark datasets demonstrated the high effectiveness of this approach for resource selection. The proposed method achieved state-of-the-art performance.\n\nStudent involvement. The project engaged 5 PhD students, 2 MS students, and 5 undergraduate students. Among these, 3 PhD students, all MS students, and 3 undergraduate students graduated during the project. Notably, 5 of the students involved were female.\n\nArticts. The project resulted in 21 peer-reviewed publications as well as multiple datasets and source codes of our algorithms.\t\t\t\t\tLast Modified: 01/08/2025\n\n\t\t\t\t\tSubmitted by: EduardDragut\n"
 }
}