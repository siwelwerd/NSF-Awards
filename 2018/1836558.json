{
 "awd_id": "1836558",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Influence of Head and Eye Movements on Retinal Input and Early Neural Encoding",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Lawrence Gottlob",
 "awd_eff_date": "2018-05-01",
 "awd_exp_date": "2019-02-28",
 "tot_intn_awd_amt": 91856.0,
 "awd_amount": 104414.0,
 "awd_min_amd_letter_date": "2018-08-02",
 "awd_max_amd_letter_date": "2018-08-02",
 "awd_abstract_narration": "Humans are normally not aware that their eyes and head are always in motion.  Small involuntary head and eye movements continually occur in the periods between voluntary relocations of gaze, even when attempting to maintain steady gaze on a single point.  These movements shift the stimulus on the retina in ways that would be immediately visible had the motion originated from objects in the scene rather than the observer's behavior.  Building on a large body of recent findings, this project investigates the hypothesis that fixational head and eye movements are not motor instabilities, but part of a precisely controlled motor strategy that facilitates the visual processing of fine spatial detail.  Elucidation of this hypothesis is important not only for advancing knowledge on the fundamental mechanisms of visual perception, but also because it implies that some visual acuity impairments may have unrecognized motor origins, and, conversely, that motor disturbances may have unsuspected sensory consequences. The research could have implications for the optimization of human visual performance in situations of restricted head movement. Also, by shedding light on how to achieve optimal sampling of visual information through coordinated movement, the research could also have implications for the design of artificial vision systems.\r\n\r\nThis project will follow an integrated theoretical and experimental approach, which combines psychophysical experiments with human subjects, statistical analysis of the stimulus on the retina, and modeling of neurons in the early stages of the visual system to examine the joint consequences of head and eye movements on the acquisition and encoding of fine spatial information.  Specifically, the investigators will measure fixational head and eye movements during the normal execution of high-acuity visual tasks. They will study how these movements interact, the degree of control involved in their interplay, and the nature of this interplay.  In parallel, the investigators will develop quantitative predictions by reconstructing the visual input signals experienced by the observers' retinas and by analyzing the impact of these signals on the responses of computational models of neurons in the visual system.  This synergy of experimental and theoretical methods will result in new knowledge in the fields of sensory perception and motor control.  It will contribute critical information on the joint characteristics of fixational head and eye movements, their visual functions, and help in identifying the sensory-motor strategies by which spatial information is represented in the brain.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michele",
   "pi_last_name": "Rucci",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michele Rucci",
   "pi_email_addr": "mrucci@ur.rochester.edu",
   "nsf_id": "000486601",
   "pi_start_date": "2018-08-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "518 Hylan Building",
  "perf_city_name": "Rochester",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146273847",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 89534.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 14880.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Humans are normally not aware that their eyes and head are always in motion. Small head and eye movements occur even in the fixation periods in between voluntary gaze shifts, the very periods in which visual information is acquired and processed. Little is known about the functional consequences of these movements for visual perception. To achieve high-resolution measurements, small eye movements are normally studied with the subject's head immobilized. But it has long been argued that this condition alters the natural visual flow to the retina as well as oculomotor behaviors.</p>\n<p>In this project, researchers at the University of Rochester have combined a variety of experimental approaches to achieve highly precise measurements of head and eye movements in humans and study the visual functions of this behavior.&nbsp; In three parallel aims, the researchers have examined the interplay between head and eye movements in high-acuity tasks (Aim 1); how this interplay structures the visual input to the retina (Aim 2); and the consequent impact of this input signal on neural processing (Aim 3). Specifically, the researchers have focused on the natural instability of visual fixation, a behavior that moves the image on the retina by relatively larger amounts.&nbsp; They have conducted experiments to examine the perceptual consequences of this behavior and used computational models of neurons in the early visual system to identify the strategies by which visual neurons encode fine spatial information during natural fixation.&nbsp;</p>\n<p>The results reported in this project have shed new light both on how humans move during the execution of high-acuity tasks and on the visual function of this motor activity.&nbsp; Before this project, it was assumed that, while focusing gaze on a point in the scene, the two eyes would move randomly and independently. &nbsp;Contrary to this assumption, the research of this project has shown that the fixational jitter of the eye partially compensates for the natural instability of the head in a way that is remarkably fast and consistent between the two eyes.&nbsp; That is, rather than an uncontrolled random process resulting from noise at the neural and/or muscular levels, the fixational motion of the eye represents a form of slow control aimed at maintaining ideal visual conditions.&nbsp; Furthermore, fast small gaze shifts, known as microsaccades, occur frequently during high acuity tasks.&nbsp; This research has shown that microsaccades are conjugated in the two eyes and precisely realign both eyes relative to the fine characteristics of the stimulus.&nbsp; Computer models of neurons in the early stages of the visual system have indicated that neural activity at this stage well account for human spatial and temporal sensitivity, but only when the &nbsp;spatiotemporal visual signals resulting from the natural head/eye interplay is taken into account.</p>\n<p><strong>Intellectual merit:&nbsp;&nbsp;</strong>This research has led to new knowledge in the fields of sensory perception and motor control.&nbsp; Results from this project have revealed finely orchestrated motor strategies that human use to acquire and process visual details.&nbsp; These strategies indicate that coordinated fixational head and eye movements are an integral component of the way spatial information is encoded in the visual system.</p>\n<p><strong>Broader impact: &nbsp;</strong>The existence of sophisticated visuomotor strategies for controlling the stimulus on the retina raises the hypothesis that impairments in fine spatial vision commonly attributed to dysfunctions in visual pathways may, in fact, originate from motor abnormalities.&nbsp; The identification of these strategies has already inspired the development of new neuromorphic systems for machine vision.&nbsp; Furthermore, the interdisciplinary nature of this research has offered valuable opportunities for training graduate and undergraduate students.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/21/2019<br>\n\t\t\t\t\tModified by: Michele&nbsp;Rucci</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nHumans are normally not aware that their eyes and head are always in motion. Small head and eye movements occur even in the fixation periods in between voluntary gaze shifts, the very periods in which visual information is acquired and processed. Little is known about the functional consequences of these movements for visual perception. To achieve high-resolution measurements, small eye movements are normally studied with the subject's head immobilized. But it has long been argued that this condition alters the natural visual flow to the retina as well as oculomotor behaviors.\n\nIn this project, researchers at the University of Rochester have combined a variety of experimental approaches to achieve highly precise measurements of head and eye movements in humans and study the visual functions of this behavior.  In three parallel aims, the researchers have examined the interplay between head and eye movements in high-acuity tasks (Aim 1); how this interplay structures the visual input to the retina (Aim 2); and the consequent impact of this input signal on neural processing (Aim 3). Specifically, the researchers have focused on the natural instability of visual fixation, a behavior that moves the image on the retina by relatively larger amounts.  They have conducted experiments to examine the perceptual consequences of this behavior and used computational models of neurons in the early visual system to identify the strategies by which visual neurons encode fine spatial information during natural fixation. \n\nThe results reported in this project have shed new light both on how humans move during the execution of high-acuity tasks and on the visual function of this motor activity.  Before this project, it was assumed that, while focusing gaze on a point in the scene, the two eyes would move randomly and independently.  Contrary to this assumption, the research of this project has shown that the fixational jitter of the eye partially compensates for the natural instability of the head in a way that is remarkably fast and consistent between the two eyes.  That is, rather than an uncontrolled random process resulting from noise at the neural and/or muscular levels, the fixational motion of the eye represents a form of slow control aimed at maintaining ideal visual conditions.  Furthermore, fast small gaze shifts, known as microsaccades, occur frequently during high acuity tasks.  This research has shown that microsaccades are conjugated in the two eyes and precisely realign both eyes relative to the fine characteristics of the stimulus.  Computer models of neurons in the early stages of the visual system have indicated that neural activity at this stage well account for human spatial and temporal sensitivity, but only when the  spatiotemporal visual signals resulting from the natural head/eye interplay is taken into account.\n\nIntellectual merit:  This research has led to new knowledge in the fields of sensory perception and motor control.  Results from this project have revealed finely orchestrated motor strategies that human use to acquire and process visual details.  These strategies indicate that coordinated fixational head and eye movements are an integral component of the way spatial information is encoded in the visual system.\n\nBroader impact:  The existence of sophisticated visuomotor strategies for controlling the stimulus on the retina raises the hypothesis that impairments in fine spatial vision commonly attributed to dysfunctions in visual pathways may, in fact, originate from motor abnormalities.  The identification of these strategies has already inspired the development of new neuromorphic systems for machine vision.  Furthermore, the interdisciplinary nature of this research has offered valuable opportunities for training graduate and undergraduate students.\n\n \n\n\t\t\t\t\tLast Modified: 07/21/2019\n\n\t\t\t\t\tSubmitted by: Michele Rucci"
 }
}