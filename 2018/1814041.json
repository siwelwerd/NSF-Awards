{
 "awd_id": "1814041",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CCF-BSF: AF: Small: Collaborative Research: Practice-Friendly Theory and Algorithms for Linear Regression Problems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922095",
 "po_email": "kwimmer@nsf.gov",
 "po_sign_block_name": "Karl Wimmer",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 249892.0,
 "awd_amount": 257892.0,
 "awd_min_amd_letter_date": "2018-08-27",
 "awd_max_amd_letter_date": "2023-06-15",
 "awd_abstract_narration": "The project focuses on one of the most fundamental problems in the intersection of applied mathematics and computer science: solving systems of multiple linear equations in multiple variables. Such systems, also known as linear regression problems, have applications in various fields, from classical engineering to data science and machine learning. These applications yield systems with millions of equations and variables. The design of very efficient solver algorithms is thus a problem of paramount importance. Over the last twenty years there has been a tremendous focus and progress in the theory of algorithms for solving certain types of linear systems that are ubiquitous in applications, despite the fact that they are somewhat restricted (e.g. each equation has only two variables). Along with these algorithms, a wealth of new notions, techniques and tools has been acquired. The project will develop extensions of these techniques, targeting concrete applications in related fields. Towards this end, the project includes research problems that are appropriate for advanced undergraduate and graduate students with complementary interests and skills, ranging from applied to theoretical. Research will be disseminated through all standard channels, importantly including free software.\r\n\r\nThe project will pursue three main directions: (i) Bring the recent progress from the theoretical to the practical realm. Linear system solvers are useful in a variety of contexts, implying a need for implementations in disparate computational environments, including basic consumer computers, graphical processing units, or big parallel and distributed systems. This necessitates the development of new theory and algorithms that are practice-friendly, i.e. designed with the practical performance end-goal in mind. (ii) The impact of linear system solvers in the downstream applications in Data Science and Machine Learning can be accelerated and strengthened by pursuing their tighter integration with the target applications. A second major goal of the project is thus to pursue an exportation of techniques and notions from the theory of linear regression to specific problems in Machine Learning. This will require the development of adaptations and enhancements of these techniques. (iii) The study of specific algorithmic applications in Machine Learning also serves the third major goal of the project: the design of solvers for regression problems that go beyond the restricted types for which efficient solvers are currently known.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Petros",
   "pi_last_name": "Drineas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Petros Drineas",
   "pi_email_addr": "pdrineas@purdue.edu",
   "nsf_id": "000117416",
   "pi_start_date": "2018-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "LWSN, 305 N University St",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072107",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "014Z",
   "pgm_ref_txt": "NSF and US-Israel Binational Science Fou"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "7933",
   "pgm_ref_txt": "NUM, SYMBOL, & ALGEBRA COMPUT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 249892.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The NSF-funded project on practice-friendly theory and algorithms for linear regression advanced the field of numerical linear algebra and computational optimization by creating efficient, practical tools for solving linear regression problems and related computational challenges. This work emphasized both intellectual merit and broader societal impacts.</p>\r\n<p><br />The project achieved significant progress in developing iterative solvers for linear regression, sparse regression, and optimization problems. These included the design of practical, efficient solvers for sparse and structured linear systems, which enhanced the ability to process large-scale data. It also produced novel algorithms for solving linear regression in streaming and dynamic environments, such as the sliding window model, providing solutions for real-time applications. Leveraging randomized linear algebra techniques, including leverage scores and randomized sampling, the research introduced faster and more accurate approaches for problems such as Fisher Discriminant Analysis, Sparse Principal Component Analysis, and interior point methods for linear programming. Furthermore, rigorous theoretical analyses of matrix sparsification and perturbation offered deeper insights into numerical stability and computational efficiency. These contributions resulted in multiple conference and journal publications and conference presentations and demonstrated both theoretical significance and practical applicability. The project's outcomes helped advance machine learning, data science, and optimization.</p>\r\n<p>The project had a significant educational impact by training multiple PhD students. Additionally, the project trained one undergraduate student through the Research Experiences for Undergraduates (REU) program. These training opportunities prepared participants for impactful careers in research and industry.</p>\r\n<p>The dissemination of the project's findings included a summer school on randomized algorithms for inverse problems, as well as workshops on randomized numerical linear algebra and theoretical data. Such events brought together researchers to work on the project's problems. The techniques developed under this grant have been applied to machine learning tasks, including dimensionality reduction, classification, and optimization. By combining advanced theoretical models with computational efficiency, the project bridged the gap between theory and practice, helping large-scale data analysis across scientific and industrial applications.</p>\r\n<p>In conclusion, this work significantly advanced our understanding of linear regression problems while preparing a new generation of researchers and practitioners to tackle emerging computational challenges.</p><br>\n<p>\n Last Modified: 12/16/2024<br>\nModified by: Petros&nbsp;Drineas</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe NSF-funded project on practice-friendly theory and algorithms for linear regression advanced the field of numerical linear algebra and computational optimization by creating efficient, practical tools for solving linear regression problems and related computational challenges. This work emphasized both intellectual merit and broader societal impacts.\r\n\n\n\nThe project achieved significant progress in developing iterative solvers for linear regression, sparse regression, and optimization problems. These included the design of practical, efficient solvers for sparse and structured linear systems, which enhanced the ability to process large-scale data. It also produced novel algorithms for solving linear regression in streaming and dynamic environments, such as the sliding window model, providing solutions for real-time applications. Leveraging randomized linear algebra techniques, including leverage scores and randomized sampling, the research introduced faster and more accurate approaches for problems such as Fisher Discriminant Analysis, Sparse Principal Component Analysis, and interior point methods for linear programming. Furthermore, rigorous theoretical analyses of matrix sparsification and perturbation offered deeper insights into numerical stability and computational efficiency. These contributions resulted in multiple conference and journal publications and conference presentations and demonstrated both theoretical significance and practical applicability. The project's outcomes helped advance machine learning, data science, and optimization.\r\n\n\nThe project had a significant educational impact by training multiple PhD students. Additionally, the project trained one undergraduate student through the Research Experiences for Undergraduates (REU) program. These training opportunities prepared participants for impactful careers in research and industry.\r\n\n\nThe dissemination of the project's findings included a summer school on randomized algorithms for inverse problems, as well as workshops on randomized numerical linear algebra and theoretical data. Such events brought together researchers to work on the project's problems. The techniques developed under this grant have been applied to machine learning tasks, including dimensionality reduction, classification, and optimization. By combining advanced theoretical models with computational efficiency, the project bridged the gap between theory and practice, helping large-scale data analysis across scientific and industrial applications.\r\n\n\nIn conclusion, this work significantly advanced our understanding of linear regression problems while preparing a new generation of researchers and practitioners to tackle emerging computational challenges.\t\t\t\t\tLast Modified: 12/16/2024\n\n\t\t\t\t\tSubmitted by: PetrosDrineas\n"
 }
}