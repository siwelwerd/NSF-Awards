{
 "awd_id": "1763503",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: Medium: Performant Architecturally Diverse Systems via Aspect-oriented Programming",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jason Hallstrom",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 1214675.0,
 "awd_amount": 1251075.0,
 "awd_min_amd_letter_date": "2018-08-16",
 "awd_max_amd_letter_date": "2022-05-06",
 "awd_abstract_narration": "Architecturally diverse computers are systems that incorporate hardware accelerators such as graphics engines, and reconfigurable logic to achieve some tangible benefits in terms improved performance, and decreased power are difficult to program. This project seeks to dramatically improve the programmability of architecturally diverse computers by enabling them to tune themselves, freeing the application developer to focus on correctness issues rather than performance issues.\r\n\r\nThis will be accomplished by using aspect-oriented programming techniques to expose tuning knobs that have direct impact on the benefit of interest, notably, performance or power consumption. Understanding the impact of these tuning knobs will be achieved using queueing network models which are automatically derived from the application's specification. The queueing models will be used to guide an automated control process that seeks to maximize the benefit of interest by adjusting the tuning knobs.\r\n\r\nThe project will utilize a number of computational science applications as test cases, providing benefits to both of the computational biology and data science communities.  Both graduate and undergraduate students will be involved in the research, and several university-level programs will be used to help attract members of underrepresented populations.\r\n\r\nRelevant data, code, and other supplementary materials will be placed in the university library's permanent repository at https://openscholarship.wustl.edu/data/. This repository will provide persistent, curated access to both code and data, including support for DOIs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Roger",
   "pi_last_name": "Chamberlain",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Roger D Chamberlain",
   "pi_email_addr": "roger@wustl.edu",
   "nsf_id": "000362967",
   "pi_start_date": "2018-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ron",
   "pi_last_name": "Cytron",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Ron K Cytron",
   "pi_email_addr": "cytron@cs.wustl.edu",
   "nsf_id": "000374266",
   "pi_start_date": "2018-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jeremy",
   "pi_last_name": "Buhler",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Jeremy D Buhler",
   "pi_email_addr": "jbuhler@wustl.edu",
   "nsf_id": "000376117",
   "pi_start_date": "2018-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "I-Ting",
   "pi_last_name": "Lee",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "I-Ting A Lee",
   "pi_email_addr": "angelee@wustl.edu",
   "nsf_id": "000678883",
   "pi_start_date": "2018-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Washington University",
  "inst_street_address": "1 BROOKINGS DR",
  "inst_street_address_2": "",
  "inst_city_name": "SAINT LOUIS",
  "inst_state_code": "MO",
  "inst_state_name": "Missouri",
  "inst_phone_num": "3147474134",
  "inst_zip_code": "631304862",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MO01",
  "org_lgl_bus_name": "WASHINGTON UNIVERSITY, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "L6NFUM28LQM5"
 },
 "perf_inst": {
  "perf_inst_name": "Washington University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MO",
  "perf_st_name": "Missouri",
  "perf_zip_code": "631304899",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "MO01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 303087.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 295165.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 303900.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 329623.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 19300.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The primary outcomes of this research can be divided into several distinct areas: exploitation of graphics engines beyond their initial scope of use, effective implementations of computations using field-programmable gate arrays, novel performance models that improve our understanding of streaming data computations, and adaptation of hardware designs using aspect-oriented programming techniques. Each of these will be described in turn below.</p>\n<p>Graphics engines were initially developed for the purpose of rendering images on computer screens, and they have subsequently been used for many computational tasks (e.g., convolutional neural networks) that have a similar structure (i.e., lots of vector-matrix multiplications) as the initial graphics computations. This research has explored the use of graphics engines on computational pipelines that are more irregular in nature.&nbsp; We have developed and extended an application design framework for executing irregular streaming data computations on graphics engines, called Mercator, that automatically restructures the data stream to effectively exploit the data-parallel nature of the graphics engine. Enhancements that are now included in the Mercator framework include scheduling of compute nodes that optimize throughput, support for generalized state information (i.e., decomposition of aggregate data types and their subsequent re-aggregation after performing computations on individual elements), optimizing the allocation of memory to queues between compute nodes, and evaluating the effectiveness of merging compute nodes.</p>\n<p>Field-programmable gate arrays (FPGAs) have the benefit of enabling custom data paths to be deployed for specialized computations. The difficulty, however, is that they have historically required application development to happen at a very low level of abstraction, using hardware description languages such as VHDL and Verilog. Recently, high-level synthesis (HLS) compilers/tools have become available from FPGA manufacturers that enable applications to be developed in higher-level languages such as C/C++. This research has explored the viability of using HLS techniques across a range of application areas, including graph neural networks, signal processing in a space-borne telescope, a suite of data integration applications, and computational biology. We have identified a range of challenges that still plague HLS development, and we have shown its effectiveness if careful exploration of the design space is carried out.</p>\n<p>The need for broad design space exploration in FPGA application development motivated a set of new analytic performance models for streaming data computations that could guide the exploration process. The resulting models are not limited to FPGA designs, but they are intentionally platform-agnostic. The initial models are queueing theory-based, expanding previously existing queueing models to handle variations in data volume throughout the computing pipeline and also supporting costing models so that predictions would not be limited to just performance, but can include cost effectiveness as well. Subsequently, we developed what we believe to be the first use of network calculus for streaming computations, adding predictions about buffering requirements and end-to-end delay (including buffering delays) to the model outputs without requiring full knowledge of the service distributions of the servers that compose the model.</p>\n<p>Finally, we have used aspect-oriented application development techniques to enhance the ability to specify hardware in a composable way. We have applied this to both finite-state machine design and cache subsystem design in the RISC-V ecosystem.</p><br>\n<p>\n Last Modified: 01/06/2024<br>\nModified by: Roger&nbsp;D&nbsp;Chamberlain</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe primary outcomes of this research can be divided into several distinct areas: exploitation of graphics engines beyond their initial scope of use, effective implementations of computations using field-programmable gate arrays, novel performance models that improve our understanding of streaming data computations, and adaptation of hardware designs using aspect-oriented programming techniques. Each of these will be described in turn below.\n\n\nGraphics engines were initially developed for the purpose of rendering images on computer screens, and they have subsequently been used for many computational tasks (e.g., convolutional neural networks) that have a similar structure (i.e., lots of vector-matrix multiplications) as the initial graphics computations. This research has explored the use of graphics engines on computational pipelines that are more irregular in nature. We have developed and extended an application design framework for executing irregular streaming data computations on graphics engines, called Mercator, that automatically restructures the data stream to effectively exploit the data-parallel nature of the graphics engine. Enhancements that are now included in the Mercator framework include scheduling of compute nodes that optimize throughput, support for generalized state information (i.e., decomposition of aggregate data types and their subsequent re-aggregation after performing computations on individual elements), optimizing the allocation of memory to queues between compute nodes, and evaluating the effectiveness of merging compute nodes.\n\n\nField-programmable gate arrays (FPGAs) have the benefit of enabling custom data paths to be deployed for specialized computations. The difficulty, however, is that they have historically required application development to happen at a very low level of abstraction, using hardware description languages such as VHDL and Verilog. Recently, high-level synthesis (HLS) compilers/tools have become available from FPGA manufacturers that enable applications to be developed in higher-level languages such as C/C++. This research has explored the viability of using HLS techniques across a range of application areas, including graph neural networks, signal processing in a space-borne telescope, a suite of data integration applications, and computational biology. We have identified a range of challenges that still plague HLS development, and we have shown its effectiveness if careful exploration of the design space is carried out.\n\n\nThe need for broad design space exploration in FPGA application development motivated a set of new analytic performance models for streaming data computations that could guide the exploration process. The resulting models are not limited to FPGA designs, but they are intentionally platform-agnostic. The initial models are queueing theory-based, expanding previously existing queueing models to handle variations in data volume throughout the computing pipeline and also supporting costing models so that predictions would not be limited to just performance, but can include cost effectiveness as well. Subsequently, we developed what we believe to be the first use of network calculus for streaming computations, adding predictions about buffering requirements and end-to-end delay (including buffering delays) to the model outputs without requiring full knowledge of the service distributions of the servers that compose the model.\n\n\nFinally, we have used aspect-oriented application development techniques to enhance the ability to specify hardware in a composable way. We have applied this to both finite-state machine design and cache subsystem design in the RISC-V ecosystem.\t\t\t\t\tLast Modified: 01/06/2024\n\n\t\t\t\t\tSubmitted by: RogerDChamberlain\n"
 }
}