{
 "awd_id": "1763562",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: RI: Medium: Collaborative Research: Understanding and Improving Optimization in Deep and Recurrent Networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 329074.0,
 "awd_amount": 329074.0,
 "awd_min_amd_letter_date": "2018-06-18",
 "awd_max_amd_letter_date": "2018-06-18",
 "awd_abstract_narration": "Machine learning using deep neural networks has recently demonstrated broad empirical success. Despite this success, the optimization procedures that fit deep neural networks to data are still poorly understood. Besides playing a crucial role in fitting deep neural networks to data, optimization also strongly affects the model's ability to generalize from training examples to unseen data. This project will establish a working theory for why and when large artificial neural networks train and generalize well, and use this theory to develop new optimization methods. The utility of the new methods will be demonstrated in applications involving language, speech, biological sequences and other sequence data. The project will involve training of graduate and undergraduate students, and the project leaders will offer tutorials aimed at both the machine learning community, and other researchers and engineers using machine learning tools. \r\n\r\nIn order to establish a theory of why and when non-convex optimization works well when training deep networks, both empirical top-down and analytic bottom-up approaches will be pursued. The top-down approach will involve phenomenological analysis of large scale deep models used in practice, both when presented with real data, and when presented with data specifically crafted to test the behavior of the network. The bottom-up approach will involve precise analytic investigation from increasingly more complex models, starting with linear models, and non-convex matrix factorization, progressing through linear neural networks, models with a small number of hidden layers, and eventually reaching deeper and more complex networks. The theory developed aims to be both explanatory and actionable, and will be used to derive new optimization methods and modifications to architectures that aid in optimization and generalization. A particularly important testbed is the case of recurrent neural networks. Recurrent neural networks are powerful sequence models that maintain state as they process an input sequence and are used for sequence data. Particularly challenging to optimize, recurrent neural networks still leave much room for a stronger principled understanding, which the project aims to provide.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ruslan",
   "pi_last_name": "Salakhutdinov",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ruslan Salakhutdinov",
   "pi_email_addr": "rsalakhu@andrew.cmu.edu",
   "nsf_id": "000722383",
   "pi_start_date": "2018-06-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 329074.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\"><span class=\"s1\">This NSF project aimed at working on<span>&nbsp;perhaps&nbsp;</span></span>one of the most challenging problems we face in Machine Learning and Deep Learning today &ndash; develop new tools and methods for better understanding of the optimization, generalization, and robustness of modern deep learning and deep reinforcement learning algorithms. Over the past decade, deep learning has gained a lot of interest from the machine learning community due to its wide applications. While modern deep learning methods have resulted in substantial advances in various domains, including robotics and computer vision, this technology is still largely poorly understood in terms of its optimization and generalization capabilities.</p>\n<p class=\"p1\">In this project we bridged the gap between modern deep learning algorithms and existing theory. We studied the theoretical limits of deep learning algorithms and built more efficient and more robust&nbsp; deep learning systems and benchmark suites based on these theoretical understandings. Our work&nbsp; work on developing robust deep learning methods with provable performance guarantees&nbsp; represents the necessary first step towards addressing these concerns. As a results of our theoretical work and corresponding practical algoritms on deep and reinforcement learning methods provides much needed a priori guarantees that make deep learning systems more robust and reliable in safety-critical applications.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>\n<p class=\"p2\">&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/11/2022<br>\n\t\t\t\t\tModified by: Ruslan&nbsp;Salakhutdinov</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "This NSF project aimed at working on perhaps one of the most challenging problems we face in Machine Learning and Deep Learning today &ndash; develop new tools and methods for better understanding of the optimization, generalization, and robustness of modern deep learning and deep reinforcement learning algorithms. Over the past decade, deep learning has gained a lot of interest from the machine learning community due to its wide applications. While modern deep learning methods have resulted in substantial advances in various domains, including robotics and computer vision, this technology is still largely poorly understood in terms of its optimization and generalization capabilities.\nIn this project we bridged the gap between modern deep learning algorithms and existing theory. We studied the theoretical limits of deep learning algorithms and built more efficient and more robust  deep learning systems and benchmark suites based on these theoretical understandings. Our work  work on developing robust deep learning methods with provable performance guarantees  represents the necessary first step towards addressing these concerns. As a results of our theoretical work and corresponding practical algoritms on deep and reinforcement learning methods provides much needed a priori guarantees that make deep learning systems more robust and reliable in safety-critical applications.                  \n \n\n\t\t\t\t\tLast Modified: 12/11/2022\n\n\t\t\t\t\tSubmitted by: Ruslan Salakhutdinov"
 }
}