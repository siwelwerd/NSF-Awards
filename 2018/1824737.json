{
 "awd_id": "1824737",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CompCog: A Machine Learning Approach to Human Perceptual Similarity",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2018-08-15",
 "awd_max_amd_letter_date": "2023-07-26",
 "awd_abstract_narration": "Similarity is fundamental to nearly all aspects of human cognition. Perception uses similarity: when viewing a person's face, we (unconsciously) calculate its similarity to the faces of people we know in order to recognize who we are looking at. Categorization uses similarity: when judging whether a building was designed by the architect Frank Lloyd Wright, we calculate its similarity to buildings known to have been designed by Wright in order to make our best estimate. Reasoning and problem solving use similarity: when attempting to solve a calculus problem, we calculate its similarity to previous problems that we have encountered in order to determine a good solution strategy. However, how people calculate the similarity of two items is not yet understood. Which features of items do people use to calculate similarity? And how are the feature values of items compared in order to calculate similarity? This research project will use human experimentation and computational modeling to address these questions when items are viewed or grasped. A long-term benefit of the project is that a greater understanding of people's perceptual similarity judgments will provide a foundation for understanding how people calculate and use similarity in other areas of cognition. While conducting the research, undergraduate and graduate students will be mentored in the cross-disciplinary approach embodied in our investigation through participation in both experimental and computational aspects of the research project. \r\n \r\nThis project focuses on developing a new empirical and theoretical foundation for understanding people's notions of similarity, particularly in the domain of perceptual similarity.  The field of cognitive science is well aware that understanding similarity is essential to understanding human cognition. Despite this, the primary motivation for this project is the belief that, to date, cognitive science's approach to the study of similarity judgments is much too simple---the restricted class of similarity metrics considered by cognitive scientists is unlikely to scale to large, realistic settings. The primary hypothesis of this project is that the field of machine learning---especially the study of metric learning---can supply cognitive science with a rich array of complex and sophisticated models, models that will be necessary to accurately characterize people's similarity notions in large, realistic domains. Machine learning has pioneered the study of mathematically rigorous linear and nonlinear similarity metrics. We believe that the time is ripe for the field of cognitive science to make use of machine learning's recent advances. Machine learning's metric learning framework extends and elaborates the cognitive science approach in principled and innovative new directions. Indeed, this framework presents an unparalleled opportunity for cognitive science with the potential for transforming this field. Using the empirical and theoretical findings from machine learning, cognitive scientists can now begin to explore human notions of similarity in more complex and sophisticated ways---and in more realistic domains---than has ever been possible. We regard the research project as an early step for cognitive science towards a more sophisticated understanding of people's notions of similarity. Because the project cannot study similarity in all domains of human cognition, it concentrates on perception. Future work will need to develop further the models proposed and evaluated here. If successful, the program will establish an empirical and theoretical foundation that can subsequently be extended to many other areas of human cognition.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Jacobs",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Robert A Jacobs",
   "pi_email_addr": "robbie@bcs.rochester.edu",
   "nsf_id": "000172078",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "BCS, RC Box 270268",
  "perf_city_name": "Rochester",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146270268",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project studied the factors underlying people's notions of perceptual similarity. For instance, when a person says that two objects look similar, what are the factors underlying this judgement?</p>\n<p><br />The project produced several outcomes. In one article, we used computational models known as \"deep neural networks\" to demonstrate how judgements of visual similarity can be influenced by prior experiences using other sensory modalities. Consider, for instance, a person with experience both seeing and grasping objects. For this person, the haptic percepts obtained during grasping may subsequently influence their visual similarity judgements.</p>\n<p><br />In another article, we used both behavioral experiments and computational models to argue that people judge the visual similarity of objects in an \"orientation invariant\" manner, meaning that these judgements do not depend on the specific orientations at which the objects are viewed. This invariance is achieved, at least in part, based on the similarity of objects' parts, thereby providing evidence that people mentally represent objects in terms of their constituent parts.</p>\n<p><br />In a third article, we used both behavioral experiments and computational models to study whether people are better at remembering a set of scenes that were recently viewed when the scenes are similar in the sense that they belong to the same category. For instance, are people better at remembering a set of four scenes when the scenes all depict fruits than when two scenes depict fruits and two scenes depict houses? The answer to this question is \"yes\", though there are some interesting and systematic exceptions to this rule.</p>\n<p><br />Finally, in a fourth article, we used behavioral experiments and computational models to study how people quickly learn to perform a novel task. Our hypothesis is that people quickly train a neural network using a small set of training data items obtained from memory. These data items are selected based on their task-relevance which, in turn, is based on their similarity to previously experienced data items. The results provide intriguing support for our hypothesis.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/30/2024<br>\nModified by: Robert&nbsp;A&nbsp;Jacobs</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project studied the factors underlying people's notions of perceptual similarity. For instance, when a person says that two objects look similar, what are the factors underlying this judgement?\n\n\n\nThe project produced several outcomes. In one article, we used computational models known as \"deep neural networks\" to demonstrate how judgements of visual similarity can be influenced by prior experiences using other sensory modalities. Consider, for instance, a person with experience both seeing and grasping objects. For this person, the haptic percepts obtained during grasping may subsequently influence their visual similarity judgements.\n\n\n\nIn another article, we used both behavioral experiments and computational models to argue that people judge the visual similarity of objects in an \"orientation invariant\" manner, meaning that these judgements do not depend on the specific orientations at which the objects are viewed. This invariance is achieved, at least in part, based on the similarity of objects' parts, thereby providing evidence that people mentally represent objects in terms of their constituent parts.\n\n\n\nIn a third article, we used both behavioral experiments and computational models to study whether people are better at remembering a set of scenes that were recently viewed when the scenes are similar in the sense that they belong to the same category. For instance, are people better at remembering a set of four scenes when the scenes all depict fruits than when two scenes depict fruits and two scenes depict houses? The answer to this question is \"yes\", though there are some interesting and systematic exceptions to this rule.\n\n\n\nFinally, in a fourth article, we used behavioral experiments and computational models to study how people quickly learn to perform a novel task. Our hypothesis is that people quickly train a neural network using a small set of training data items obtained from memory. These data items are selected based on their task-relevance which, in turn, is based on their similarity to previously experienced data items. The results provide intriguing support for our hypothesis.\n\n\n\t\t\t\t\tLast Modified: 10/30/2024\n\n\t\t\t\t\tSubmitted by: RobertAJacobs\n"
 }
}