{
 "awd_id": "1841075",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Methods for assessing replication",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Finbarr Sloane",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 1103188.0,
 "awd_amount": 1103188.0,
 "awd_min_amd_letter_date": "2018-08-07",
 "awd_max_amd_letter_date": "2018-08-07",
 "awd_abstract_narration": "Replication of prior findings and results is a fundamental feature of science and is part of the logic supporting the claim that science is self-correcting. However, there is little prior research on the methodology for studying replication.  Research involving meta-analysis and systematic reviews that summarizes a collection of research studies is more common. However, the question of whether the findings from a set of experimental studies replicate one another has received less attention.  There is no clearly defined and widely accepted definition of a successful replication study or statistical literature providing methodological guidelines on how to design single replication studies or a set of replication studies. The research proposed here builds this much needed methodology. This project is funded by the Discovery Research PreK-12 Program, which funds research and development on STEM innovations and approaches.\r\n\r\nThe goal of this project is to formalize subjective ideas about the important concept of replication, provide statistical analyses for evaluating replication studies, provide properties for evaluating the conclusiveness of replication studies, and provide principles for designing conclusive and efficient programs of replication studies. It addresses three fundamental problems. The first is how to define replication: What, precisely, should it mean to say that the results in a collection of studies replicate one another?  Second, given a definition of replication, what statistical analyses should be done to decide whether the collection of studies replicate one another and what are the properties of these analyses (e.g., sensitivity or statistical power)?  Third, how should one or more replication studies be designed to provide conclusive answers to questions of replication? The project has the potential for impact on a range of empirical sciences by providing statistical tools to evaluate the replicability of experimental findings, assessing the conclusiveness of replication attempts, and developing software to help plan programs of replication studies that can provide conclusive evidence of replicability of scientific findings.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Larry",
   "pi_last_name": "Hedges",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Larry V Hedges",
   "pi_email_addr": "l-hedges@northwestern.edu",
   "nsf_id": "000514339",
   "pi_start_date": "2018-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "2040 Sheridan Road",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602080855",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "764500",
   "pgm_ele_name": "Discovery Research K-12"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 1103188.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Replication is central to the rhetoric and the practice of science.&nbsp; Yet relatively little has been written about the methodology of replication.&nbsp; In particular, there has been very little written about how to define replication in mathematical and statistical terms, how to analyze ensembles of studies to determine whether the results replicate, or how to plan ensembles of studies to assess replication.&nbsp;</p>\n<p>&nbsp;</p>\n<p>This project addressed these needs by showing that the analysis of replication is linked to the statistical methodology of meta-analysis.&nbsp; It showed that there were alternative definitions of replication that were all reasonable, but subtly different.&nbsp; It also offered statistical analysis strategies for use with any of these strategies and provided an analysis of their decision theoretic properties.</p>\n<p>&nbsp;</p>\n<p>The project showed that the na&iuml;ve idea that replicability could best be addressed conducting a single replication study had a serious flaw: The analysis of whether the results of the two studies agreed would inevitably be weaker (have less statistical power) than either of the original studies. &nbsp;The project examined recent empirical studies of replication and showed that the analyses used were at best suboptimal and sometimes did not measure replicability at all.</p>\n<p>&nbsp;</p>\n<p>Finally the project developed principles for developing optimal designs for ensembles of studies intended to assess replicability of findings.</p><br>\n<p>\n Last Modified: 11/29/2023<br>\nModified by: Larry&nbsp;V&nbsp;Hedges</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nReplication is central to the rhetoric and the practice of science. Yet relatively little has been written about the methodology of replication. In particular, there has been very little written about how to define replication in mathematical and statistical terms, how to analyze ensembles of studies to determine whether the results replicate, or how to plan ensembles of studies to assess replication.\n\n\n\n\n\nThis project addressed these needs by showing that the analysis of replication is linked to the statistical methodology of meta-analysis. It showed that there were alternative definitions of replication that were all reasonable, but subtly different. It also offered statistical analysis strategies for use with any of these strategies and provided an analysis of their decision theoretic properties.\n\n\n\n\n\nThe project showed that the nave idea that replicability could best be addressed conducting a single replication study had a serious flaw: The analysis of whether the results of the two studies agreed would inevitably be weaker (have less statistical power) than either of the original studies. The project examined recent empirical studies of replication and showed that the analyses used were at best suboptimal and sometimes did not measure replicability at all.\n\n\n\n\n\nFinally the project developed principles for developing optimal designs for ensembles of studies intended to assess replicability of findings.\t\t\t\t\tLast Modified: 11/29/2023\n\n\t\t\t\t\tSubmitted by: LarryVHedges\n"
 }
}