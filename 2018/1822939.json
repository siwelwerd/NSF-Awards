{
 "awd_id": "1822939",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SPX: Collaborative research: Scalable Heterogeneous Migrating Threads for Post-Moore Computing",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ashok Srinivasan",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 524483.0,
 "awd_amount": 524483.0,
 "awd_min_amd_letter_date": "2018-08-27",
 "awd_max_amd_letter_date": "2018-08-27",
 "awd_abstract_narration": "The project will advance the state of the art in computer architecture and programming systems for extreme and heterogeneous parallelism. It is clear that the post-Moore' law era will require major disruptions in computing systems. This project will address computer architecture and programming system challenges for this new era, with a focus on approaches that are expected to be scalable in size, cost effectiveness, and usability by retaining some tenets of the von Neumann computing model (unlike more exploratory approaches like biological or quantum computing). By emphasizing data analytics, the work will also benefit a rapidly growing swatch of modern life (commercial, cyber, national security, social networks). A deeper understanding of how such applications can be made more scalable, and responsive enough to handle increasing real-time requirements, should lead to wider impacts across every-day life with significant potential for technology transition. There is also a direct connection to pedagogy and workforce development, since both hardware and software aspects of this proposal can enable a broad range of students to better understand the wider diversity of computing platforms projected in future technology roadmaps. \r\n\r\n\r\nThe SHMT (Scalable Heterogeneous Migrating Thread) model developed in this award will include extensions to the migrating threads and asynchronous task models to support heterogeneity, and extensions to the transaction and actor models to support data coherence. Further, the investigators propose to use data analytic graph problems to evaluate their research, since these applications are both important in practice and are challenging to solve on current systems. Given the expected continued increase in the size, complexity, and dynamic nature of such computations, it is of growing value to understand how to implement them in a manner that can scale to very high levels of concurrency in environments that include high rate streams of both updates and queries. These techniques can also apply to other application classes, such as scientific applications where data is sparse or irregular. The overall objective of this 3-year research project is to advance the foundations of computer architecture and programming systems to address the emerging challenges of scalable parallelism and extreme heterogeneity, with an emphasis on data analytics and solving data coherence, system management, resource allocation, and task scheduling issues. The investigators will leverage their distinct but synergistic expertise in the architecture and programming systems areas by building on, and integrating, their past work on migrating threads and near-memory processing, software support for asynchronous task parallelism for heterogeneous computing, and data analytics. The Center for Research into Novel Computing Hierarchies (CRNCH) at Georgia Tech will provide access to first-of-a-kind alternative systems for use in evaluating the new concepts. Industrial collaborators include Lexis-Nexis Risk Solutions and Kyndi, for whom graph data analytics are central to their business model.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Kogge",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Peter M Kogge",
   "pi_email_addr": "kogge@nd.edu",
   "nsf_id": "000235482",
   "pi_start_date": "2018-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Notre Dame",
  "inst_street_address": "940 GRACE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "NOTRE DAME",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "5746317432",
  "inst_zip_code": "465565708",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "IN02",
  "org_lgl_bus_name": "UNIVERSITY OF NOTRE DAME DU LAC",
  "org_prnt_uei_num": "FPU6XGFXMBE9",
  "org_uei_num": "FPU6XGFXMBE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Notre Dame",
  "perf_str_addr": "940 Grace Hall",
  "perf_city_name": "Notre Dame",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "465565708",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "IN02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 524483.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The basic unit of a modern computer today is a <em>core</em>. Modern computer systems have large numbers, up to millions, of such cores that must work together. With increasing frequency, such cores are <em>heterogeneous</em>, where different cores in the same system are designed to accelerate different kinds of computation.</p>\n<p>A core uses the information kept in one or more <em>threads</em> to execute the steps defined by some program one instruction at a time, in the proper sequence. With increasing frequency, threads must <em>migrate</em> between cores, either because different cores have access to different parts of the data or because different steps of the program must be executed on different types of cores. AI and its inclusion in everything from cell phones to supercomputers is an example of such applications.</p>\n<p>The problem with current architectures for such problems is that each migration, between either the same or different types of cores, must be handled by sophisticated software, and takes significant computing power just to move the computation. When the amount of needed processing &ldquo;over there&rdquo; is relatively small, as it is with increasing number of vitally important apps, the cost of migration far outweighs the computation time.</p>\n<p>One possible solution is to allow the hardware in each core to recognize when a migration is needed, and manage the migration on both ends without a software stack. Prototype machines with such characteristics, but where all the cores are the same, are available at Georgia Tech. The goal of this project, and the companion project at Georgia Tech, was to understand how to extend such architectures to the heterogeneous case where there is a mix of core types.</p>\n<p>The first step in this project was to understand the cost of such migrations and the improvements possible by hardware migration, particularly when applications are becoming much more irregular and unpredictable as to what kinds of cores are needed in a typical thread&rsquo;s path. Three different applications were studied: sparse matrix multiply, a streaming application, and one from machine learning, with implementations compared on both conventional system and the migrating systems at Georgia Tech. In all cases, the performances improvements were very significant, with the migrating thread versions capable of far better utilization, with far better efficiency, than possible with conventional designs.</p>\n<p>Extending these results to heterogeneous cores then required understanding how much information needs to be transferred in a migration between different types of cores, and how best to express in a program that such a transition should happen. The work in the companion study at Georgia Tech had indicated that the <em>Actor model</em> was a particularly effective one, where different actor threads handle different types of processing, and actors exchange &ldquo;messages&rdquo; to signify requests for processing. Today such messages are handled by the same types of software stacks as are the equivalent of migrations. With migrating thread architectures, however, these &ldquo;messages&rdquo; become &ldquo;active&rdquo; to the point of becoming migrating threads that the hardware can manage just as in the existing prototypes. Thus the latter half of this study developed an architecture where migrating thread cores would serve as either the &ldquo;conventional&rdquo; cores in a system, or as the interface to heterogeneous accelerator cores. Two experiments were then conducted to determine how much, of what kind of information, would be needed for such migrations between core types. Since prototypes of such heterogeneous migrating systems do not exist, these experiments were run on current heterogeneous systems but designed to elicit the desired information. One such system had a small number of conventional and accelerator cores that all shared the same memory. The other used a system with a larger GPU where each of the nearly 100 sub-cores in the GPU was treated as a separate node between which migrations might be necessary. On the first a variant of the machine learning problem from the first phase was implemented. On the second a large graph problem was implemented where the goal was to determine which vertices were &ldquo;most influential.&rdquo; This is typical of the problems encountered in big graph applications such as social media or on-line commerce. The results of both indicate that the information that must be passed to move to a different type of core fits within a migrating thread, and as before, using hardware-based migration should significantly improve the performance of large heterogeneous systems on such problems.</p>\n<p>In addition to involving multiple students (both graduate and undergraduate) in both stressing applications and new architectural ideas, this work also led the PIs from the Notre Dame and Georgia Tech projects to propose, and win, another grant to design a supercomputer-class migrating thread system capable of 100X+ performance over conventional systems for a set of large, irregular, and dynamic applications.&nbsp;&nbsp;</p><br>\n<p>\n Last Modified: 05/01/2024<br>\nModified by: Peter&nbsp;M&nbsp;Kogge</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe basic unit of a modern computer today is a core. Modern computer systems have large numbers, up to millions, of such cores that must work together. With increasing frequency, such cores are heterogeneous, where different cores in the same system are designed to accelerate different kinds of computation.\n\n\nA core uses the information kept in one or more threads to execute the steps defined by some program one instruction at a time, in the proper sequence. With increasing frequency, threads must migrate between cores, either because different cores have access to different parts of the data or because different steps of the program must be executed on different types of cores. AI and its inclusion in everything from cell phones to supercomputers is an example of such applications.\n\n\nThe problem with current architectures for such problems is that each migration, between either the same or different types of cores, must be handled by sophisticated software, and takes significant computing power just to move the computation. When the amount of needed processing over there is relatively small, as it is with increasing number of vitally important apps, the cost of migration far outweighs the computation time.\n\n\nOne possible solution is to allow the hardware in each core to recognize when a migration is needed, and manage the migration on both ends without a software stack. Prototype machines with such characteristics, but where all the cores are the same, are available at Georgia Tech. The goal of this project, and the companion project at Georgia Tech, was to understand how to extend such architectures to the heterogeneous case where there is a mix of core types.\n\n\nThe first step in this project was to understand the cost of such migrations and the improvements possible by hardware migration, particularly when applications are becoming much more irregular and unpredictable as to what kinds of cores are needed in a typical threads path. Three different applications were studied: sparse matrix multiply, a streaming application, and one from machine learning, with implementations compared on both conventional system and the migrating systems at Georgia Tech. In all cases, the performances improvements were very significant, with the migrating thread versions capable of far better utilization, with far better efficiency, than possible with conventional designs.\n\n\nExtending these results to heterogeneous cores then required understanding how much information needs to be transferred in a migration between different types of cores, and how best to express in a program that such a transition should happen. The work in the companion study at Georgia Tech had indicated that the Actor model was a particularly effective one, where different actor threads handle different types of processing, and actors exchange messages to signify requests for processing. Today such messages are handled by the same types of software stacks as are the equivalent of migrations. With migrating thread architectures, however, these messages become active to the point of becoming migrating threads that the hardware can manage just as in the existing prototypes. Thus the latter half of this study developed an architecture where migrating thread cores would serve as either the conventional cores in a system, or as the interface to heterogeneous accelerator cores. Two experiments were then conducted to determine how much, of what kind of information, would be needed for such migrations between core types. Since prototypes of such heterogeneous migrating systems do not exist, these experiments were run on current heterogeneous systems but designed to elicit the desired information. One such system had a small number of conventional and accelerator cores that all shared the same memory. The other used a system with a larger GPU where each of the nearly 100 sub-cores in the GPU was treated as a separate node between which migrations might be necessary. On the first a variant of the machine learning problem from the first phase was implemented. On the second a large graph problem was implemented where the goal was to determine which vertices were most influential. This is typical of the problems encountered in big graph applications such as social media or on-line commerce. The results of both indicate that the information that must be passed to move to a different type of core fits within a migrating thread, and as before, using hardware-based migration should significantly improve the performance of large heterogeneous systems on such problems.\n\n\nIn addition to involving multiple students (both graduate and undergraduate) in both stressing applications and new architectural ideas, this work also led the PIs from the Notre Dame and Georgia Tech projects to propose, and win, another grant to design a supercomputer-class migrating thread system capable of 100X+ performance over conventional systems for a set of large, irregular, and dynamic applications.\t\t\t\t\tLast Modified: 05/01/2024\n\n\t\t\t\t\tSubmitted by: PeterMKogge\n"
 }
}