{
 "awd_id": "1828105",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MRI Collaborative: Development of ESPRIT - Emerging systems' performance and energy evaluation instruments and testbench",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2018-09-08",
 "awd_max_amd_letter_date": "2022-09-07",
 "awd_abstract_narration": "Future computing nodes will most likely rely on heterogeneous processing and memory systems as well as networking technologies. Identifying the most suitable computing system for a given application requires the cumbersome task of evaluating the application's performance on as many alternatives as possible. This project develops ESPRIT (Emerging Systems PeRformance and Energy Evaluation Instrument and Testbench), a computing system capable of evaluating the most suitable system for specific classes of applications. If applications can be classified into groups based on their similarities along a wide range of performance characteristics, it may be possible to determine the system best suited for a specific class of applications. This work will help large-scale computing systems be configured for more efficient operation and lower energy use.\r\n\r\nThe ESPRIT project consist of state of the art computing nodes; system, memory, and power and energy simulators; benchmarks from different applications; a suite of measuring instruments; models for investigating application behaviors; statistical clustering and other machine learning techniques.The merit of this project resides in the development of instruments to evaluate applications along a number of performance characteristics of behaviors and classifying them into clusters in order to identify the most suitable design for energy efficiencies by varying capacities as well as technology scales. ESPRIT could be used to investigate new design choices, or tune applications for specific designs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Krishna",
   "pi_last_name": "Kavi",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Krishna M Kavi",
   "pi_email_addr": "krishna.kavi@unt.edu",
   "nsf_id": "000374348",
   "pi_start_date": "2018-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Song",
   "pi_last_name": "Fu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Song Fu",
   "pi_email_addr": "song.fu@unt.edu",
   "nsf_id": "000572723",
   "pi_start_date": "2018-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Hui",
   "pi_last_name": "Zhao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hui Zhao",
   "pi_email_addr": "Hui.Zhao@unt.edu",
   "nsf_id": "000740303",
   "pi_start_date": "2018-09-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Texas",
  "inst_street_address": "1112 DALLAS DR STE 4000",
  "inst_street_address_2": "",
  "inst_city_name": "DENTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9405653940",
  "inst_zip_code": "762051132",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "TX13",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH TEXAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "G47WN1XZNWX9"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Texas",
  "perf_str_addr": "3940 N. Elm Street",
  "perf_city_name": "Denton",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "762077102",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "TX13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "118900",
   "pgm_ele_name": "Major Research Instrumentation"
  },
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1189",
   "pgm_ref_txt": "MAJOR RESEARCH INSTRUMENTATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project was to create tools and techniques for measuring and predicting performance and energy efficiencies of various applications running on single computing nodes or small clusters.&nbsp;</p>\n<p>We developed several extensions to Gem5 simulator, a widely used full system simulator. These extensions permitted us to evaluate several page migration approaches in systems that use multiple memory systems (non-volatile memories, DRAMs and HBMs). We identified which application characteristics benefit from different page migration algorithms.</p>\n<p>We also extended Spike, a RISC V simulator to evaluate approaches to improve performance of ML inferencing on embedded and edge devices. We developed hardware and software techniques for improving performance of applications that rely on sparse data sets.&nbsp;</p>\n<p>We also created extensions to Gem5 that permit the inclusion of Processing-In-Memory or Near-Data-Processing hardware along the memory hierarchy of typical processing units, including L1, L2, LLC cache memories. Using these extensions, we investigated offloading memory related activities to PIMs and freeing the primary processing elements from memory access activities, which are primarily sequential in nature and involve only integer operations. We explored offloading accessing sparse data using complex indexing to PIMs and shown significant performance gains (on average 1.7 times over a single CPU performing all operations) for a variety of algorithms including convolutions, matrix-vector and matrix-matrix multiplications and graph traversals.&nbsp;</p>\n<p>We evaluated the use of PIMs for memory management (malloc) operations. We also used PIM like devices for detecting and mitigating some side-channel attacks and attacks based on speculative executions.</p>\n<p>We are currently exploring the use of near memory processing to aid with ML applications running on GPUs and other accelerators.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/11/2023<br>\n\t\t\t\t\tModified by: Krishna&nbsp;M&nbsp;Kavi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this project was to create tools and techniques for measuring and predicting performance and energy efficiencies of various applications running on single computing nodes or small clusters. \n\nWe developed several extensions to Gem5 simulator, a widely used full system simulator. These extensions permitted us to evaluate several page migration approaches in systems that use multiple memory systems (non-volatile memories, DRAMs and HBMs). We identified which application characteristics benefit from different page migration algorithms.\n\nWe also extended Spike, a RISC V simulator to evaluate approaches to improve performance of ML inferencing on embedded and edge devices. We developed hardware and software techniques for improving performance of applications that rely on sparse data sets. \n\nWe also created extensions to Gem5 that permit the inclusion of Processing-In-Memory or Near-Data-Processing hardware along the memory hierarchy of typical processing units, including L1, L2, LLC cache memories. Using these extensions, we investigated offloading memory related activities to PIMs and freeing the primary processing elements from memory access activities, which are primarily sequential in nature and involve only integer operations. We explored offloading accessing sparse data using complex indexing to PIMs and shown significant performance gains (on average 1.7 times over a single CPU performing all operations) for a variety of algorithms including convolutions, matrix-vector and matrix-matrix multiplications and graph traversals. \n\nWe evaluated the use of PIMs for memory management (malloc) operations. We also used PIM like devices for detecting and mitigating some side-channel attacks and attacks based on speculative executions.\n\nWe are currently exploring the use of near memory processing to aid with ML applications running on GPUs and other accelerators. \n\n \n\n\t\t\t\t\tLast Modified: 10/11/2023\n\n\t\t\t\t\tSubmitted by: Krishna M Kavi"
 }
}