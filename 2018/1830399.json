{
 "awd_id": "1830399",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: FND: COLLAB: Distributed Bayesian Learning and Safe Control for Autonomous Wildfire Detection",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928950",
 "po_email": "rwachter@nsf.gov",
 "po_sign_block_name": "Ralph Wachter",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2021-12-31",
 "tot_intn_awd_amt": 675000.0,
 "awd_amount": 689000.0,
 "awd_min_amd_letter_date": "2018-09-09",
 "awd_max_amd_letter_date": "2021-04-19",
 "awd_abstract_narration": "Wildfires destroy millions of hectares of forest, sensitive ecological systems, and human infrastructure. A critical aspect of mitigating wildfire-related damages is early fire detection, well before initiating fires grow to disastrous proportions. Current practices are based on expensive assets, such as satellites, watchtowers, and remote-piloted aircraft, that require constant human supervision, limiting their use to high-risk or high-value areas. This project aims to take advantage of the hyperconvergence of computation, storage, sensing, and communication in small unmanned aerial vehicles (UAVs) to realize large-scale mapping of environmental factors such as temperature, vegetation, pressure, and chemical concentration that contribute to fire initiation. UAV teams that recharge autonomously and communicate intermittently among each other and with static sensors is a compelling research objective that will aid firefighters with continuous real-time surveillance and early detection of ensuing fires.\r\n\r\nThis proposal offers three fundamental innovations to address the scientific challenges associated with autonomous, collaborative environmental monitoring. First, a new Satisfiability Modulo Optimal Control framework is proposed to handle mixed continuous flight dynamics and discrete constraints and ensure collision avoidance, persistent communication, and autonomous recharging for UAV navigation. Second, a distributed systems architecture using new uncertainty-weighted models will be developed to enable cooperative mapping across a heterogeneous team of UAVs and static sensors and avoid bandwidth-intensive data streaming. Lastly, a new Bayesian learning and inference approach is proposed to generate multi-modal (e.g., thermal, semantic, geometric, chemical) maps of real-time environmental conditions with adaptive accuracy and uncertainty quantification. This project with its focus on multi-robot teams benefits, e.g., conservation management and search-and-rescue operations. Both applications demand robot coordination, cooperation, and autonomy, including multi-modal mapping, collaborative inference over heterogeneous networks, and multi-objective navigation with safety, communication, and energy constraints.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nikolay",
   "pi_last_name": "Atanasov",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Nikolay A Atanasov",
   "pi_email_addr": "natanasov@ucsd.edu",
   "nsf_id": "000739678",
   "pi_start_date": "2018-09-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Tajana",
   "pi_last_name": "Rosing",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Tajana S Rosing",
   "pi_email_addr": "tajana@ucsd.edu",
   "nsf_id": "000485892",
   "pi_start_date": "2018-09-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sicun",
   "pi_last_name": "Gao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sicun Gao",
   "pi_email_addr": "sicung@ucsd.edu",
   "nsf_id": "000671306",
   "pi_start_date": "2018-09-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 Gilman Drive",
  "perf_city_name": "La Jolla",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930934",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 675000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 14000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Overview:</strong> This project developed robot autonomy capabilities for monitoring environmental factors that lead to the initiation of wildfires. Understanding the evolution of fuel, topography, temperature, and weather conditions at high spatial and temporal resolutions before a fire event is critical for reducing the chances of large fires by detecting fire initiation and predicting fire spread. The current practice of relying on satellite imagery, watchtowers, and manned or remote-piloted aircraft is expensive, requires significant human supervision and yet provides data with limited spatiotemporal resolution only at high-risk, high-value areas. This project focused on three scientific challenges, summarized in the next paragraph, to enable building up-to-date high-fidelity environment models using a team of unmanned aerial vehicles (UAVs).<br /><br /><strong>Intellectual Merit:</strong> The first contribution of the project are algorithms for metric-semantc mapping of indoor and outdoor environments using streaming camera measurements. We developed a graph convolutional network approach to reconstruct mesh models of outdoor terrain from aerial images. We also designed probabilistic estimation algorithms for multi-robot collaborative mapping of the topology and semantics of indoor or outdoor environments using streaming RGB and depth measurements. The second contribution of the project are techniques for UAV trajectory planning, which aim to minimize uncertainty in the environment models and take the robot team communication into account. We developed an approach to plan UAV trajectories that persistently monitor a set of points of interest in the environment, while satisfying UAV dynamics constraints (e.g., maximum velocity or acceleration) and planning battery recharging detours. We also considered communication channel assignment and communication power optimization to guarantee quality of service in multi-UAV coordination. The third contribution of the project is the development of learning-based methods for safety and stability guarantees of low-level UAV control. We developed neural network techniques to approximate Lyapunov functions and barrier functions from UAV trajectories, which are used as certificates for guaranteeing stability and stability, respectively, of trajectory tracking.<br /><br /><strong>Broader Impacts:</strong> Current deployments of UAV systems are not capable of generating 3D environment models in real time and following trajectories that minimize uncertainty in the environment models, while ensuring persistent communication, battery recharging, and safe operation. The research outcomes from this project allow UAVs to explore and map unknown environments autonomously, and have the potential to significantly improve the utility and safety of UAV deployments in environmental monitoring applications. Our research results have been disseminated via publications and presentations at robotics, control, communications, and machine learning conferences and journals. These publications are publicly available on the project website (http://existentialrobotics.org/nsf-nri-wildfire/) and have been deposited in the NSF Public Access Repository. On the education front, the project provided training and professional development opportunities to several PhD students at UCSD. In collaboration with San Diego State University, our education efforts also focused on student outreach and research initiation activities for undergraduate students. A major achievement was the planning, development, and organization of a series of seminars and tutorials on robotics, optimization, and machine learning introducing undergraduate students to the field of robotics. The slides, open-source algorithm implementations, and recordings of the tutorials are publicly available on the project website.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/17/2022<br>\n\t\t\t\t\tModified by: Nikolay&nbsp;A&nbsp;Atanasov</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650227305342_UAVExperiments--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650227305342_UAVExperiments--rgov-800width.jpg\" title=\"UAV Flight Test\"><img src=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650227305342_UAVExperiments--rgov-66x44.jpg\" alt=\"UAV Flight Test\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">UAV flight test at the Aerodrome facility at the University of California San Diego</div>\n<div class=\"imageCredit\">Thai Duong, Nikolay Atanasov</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Nikolay&nbsp;A&nbsp;Atanasov</div>\n<div class=\"imageTitle\">UAV Flight Test</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650227002375_UAVTrajectoryPlanning--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650227002375_UAVTrajectoryPlanning--rgov-800width.jpg\" title=\"UAV Persistent Monitoring and Recharging\"><img src=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650227002375_UAVTrajectoryPlanning--rgov-66x44.jpg\" alt=\"UAV Persistent Monitoring and Recharging\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">UAV trajectory planning for persistent monitoring of points of interest and rendezvous with a mobile recharging vehicle</div>\n<div class=\"imageCredit\">M. H. Ostertag, J. Ma, T. Rosing, \ufffdRemote Sensing with UAV and Mobile Recharging Vehicle Rendezvous,\ufffd\ufffd in Initiative on Autonomous Systems Design (ASD), Design, Automation and Test in Europe (DATE) Conference, 2022</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Nikolay&nbsp;A&nbsp;Atanasov</div>\n<div class=\"imageTitle\">UAV Persistent Monitoring and Recharging</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650227183058_NeuralLyapunovFunction--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650227183058_NeuralLyapunovFunction--rgov-800width.jpg\" title=\"Neural Lyapunov Function\"><img src=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650227183058_NeuralLyapunovFunction--rgov-66x44.jpg\" alt=\"Neural Lyapunov Function\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Neural network approximation of a Lyapunov function used to provide stability guarantees for UAV control</div>\n<div class=\"imageCredit\">Y. Chang, N. Roohi, S. Gao, Neural Lyapunov Control, Conference on Neural Information Processing Systems (NeurIPS), 2019</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Nikolay&nbsp;A&nbsp;Atanasov</div>\n<div class=\"imageTitle\">Neural Lyapunov Function</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650226897176_TerrainMappingFromAerialImages--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650226897176_TerrainMappingFromAerialImages--rgov-800width.jpg\" title=\"Terrain Mapping from Aerial Images\"><img src=\"/por/images/Reports/POR/2022/1830399/1830399_10581026_1650226897176_TerrainMappingFromAerialImages--rgov-66x44.jpg\" alt=\"Terrain Mapping from Aerial Images\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">3D terrain mapping from aerial images using visual-inertial odometry features and polygonal mesh reconstruction</div>\n<div class=\"imageCredit\">Q. Feng and N. Atanasov, Mesh Reconstruction from Aerial Images for Outdoor Terrain Mapping Using Joint 2D-3D Learning, IEEE International Conference on Robotics and Automation (ICRA), 2021</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Nikolay&nbsp;A&nbsp;Atanasov</div>\n<div class=\"imageTitle\">Terrain Mapping from Aerial Images</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nOverview: This project developed robot autonomy capabilities for monitoring environmental factors that lead to the initiation of wildfires. Understanding the evolution of fuel, topography, temperature, and weather conditions at high spatial and temporal resolutions before a fire event is critical for reducing the chances of large fires by detecting fire initiation and predicting fire spread. The current practice of relying on satellite imagery, watchtowers, and manned or remote-piloted aircraft is expensive, requires significant human supervision and yet provides data with limited spatiotemporal resolution only at high-risk, high-value areas. This project focused on three scientific challenges, summarized in the next paragraph, to enable building up-to-date high-fidelity environment models using a team of unmanned aerial vehicles (UAVs).\n\nIntellectual Merit: The first contribution of the project are algorithms for metric-semantc mapping of indoor and outdoor environments using streaming camera measurements. We developed a graph convolutional network approach to reconstruct mesh models of outdoor terrain from aerial images. We also designed probabilistic estimation algorithms for multi-robot collaborative mapping of the topology and semantics of indoor or outdoor environments using streaming RGB and depth measurements. The second contribution of the project are techniques for UAV trajectory planning, which aim to minimize uncertainty in the environment models and take the robot team communication into account. We developed an approach to plan UAV trajectories that persistently monitor a set of points of interest in the environment, while satisfying UAV dynamics constraints (e.g., maximum velocity or acceleration) and planning battery recharging detours. We also considered communication channel assignment and communication power optimization to guarantee quality of service in multi-UAV coordination. The third contribution of the project is the development of learning-based methods for safety and stability guarantees of low-level UAV control. We developed neural network techniques to approximate Lyapunov functions and barrier functions from UAV trajectories, which are used as certificates for guaranteeing stability and stability, respectively, of trajectory tracking.\n\nBroader Impacts: Current deployments of UAV systems are not capable of generating 3D environment models in real time and following trajectories that minimize uncertainty in the environment models, while ensuring persistent communication, battery recharging, and safe operation. The research outcomes from this project allow UAVs to explore and map unknown environments autonomously, and have the potential to significantly improve the utility and safety of UAV deployments in environmental monitoring applications. Our research results have been disseminated via publications and presentations at robotics, control, communications, and machine learning conferences and journals. These publications are publicly available on the project website (http://existentialrobotics.org/nsf-nri-wildfire/) and have been deposited in the NSF Public Access Repository. On the education front, the project provided training and professional development opportunities to several PhD students at UCSD. In collaboration with San Diego State University, our education efforts also focused on student outreach and research initiation activities for undergraduate students. A major achievement was the planning, development, and organization of a series of seminars and tutorials on robotics, optimization, and machine learning introducing undergraduate students to the field of robotics. The slides, open-source algorithm implementations, and recordings of the tutorials are publicly available on the project website.\n\n \n\n\t\t\t\t\tLast Modified: 04/17/2022\n\n\t\t\t\t\tSubmitted by: Nikolay A Atanasov"
 }
}