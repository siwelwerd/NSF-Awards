{
 "awd_id": "1812559",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Transforming Mobile Devices into Active Sonar Systems for Medical Applications",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Erik Brunvand",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2018-06-21",
 "awd_max_amd_letter_date": "2018-06-21",
 "awd_abstract_narration": "The project converts mobile systems including smartphones into active sonar systems by leveraging the speakers and microphones commonly available on existing mobile devices. Using this approach, the system addresses long-standing and increasingly urgent problems in two key healthcare domains: pharmacologically-induced apnea diagnosis and assistive interfaces for patients with muscular disorders. \r\n\r\nUnlike medical ultrasound devices that operate in the megahertz frequencies, microphones and speakers on smartphones are designed for much lower frequencies. The project answers fundamental questions about the feasibility of using active sonar on smartphones to address medical applications. It will produce algorithms that track breathing signals, required for pharmacologically-induced apnea detection, even in the presence of movements from other parts of the body. Finally, the project will result in algorithms that achieve tracking of the tongue motion from outside the mouth using the reflections from the acoustic signals as processed by the smartphone. \r\n \r\nMedical conditions that result in fatal apnea events have increasingly become a public health emergency. The project, if successful, would achieve a mobile system that can detect these events, thus providing an opportunity to potentially saving numerous lives. The second part of the project will create a tongue-based interaction toolkit that would help hundreds of thousands of patients with muscular disabilities to interact with existing mobile devices, using only a software app - a capability that currently does not exist. The resulting prototypes will be showcased at DawgBytes Summer Camps and University of Washington Women's Initiative. \r\n \r\nThe results of the project will be added to the project webpage. The data will be stripped of any private information and will be added to the project webpage. The resulting breathing signals and the benchmarks data from our deployments will be added to the webpage for independent analysis. The project webpage is at the following link: http://apnea.cs.washington.edu\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shyamnath",
   "pi_last_name": "Gollakota",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shyamnath Gollakota",
   "pi_email_addr": "gshyam@cs.washington.edu",
   "nsf_id": "000633974",
   "pi_start_date": "2018-06-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jacob",
   "pi_last_name": "Sunshine",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jacob Sunshine",
   "pi_email_addr": "jesun@uw.edu",
   "nsf_id": "000763146",
   "pi_start_date": "2018-06-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "185 Stevens Way, 352350",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981955320",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project is to transform mobile devices like phones and smart speakers into active sonar systems to help create medical diagnostic tools. To this end, the team has built a number of novel systems that use microphones and speakers on phones and smart speakers to screen various medical conditions as well as for monitoring physiological signals.&nbsp;</p>\n<p><strong>Sustained apnea detection using smartphones.</strong> We&nbsp; converted a  smartphone to detect changes in respiration that precede sustained apnea events. Using sonar, the smartphone detected respiratory depression  and apnea (temporary lack of breathing) in humans. Respiratory changes during  general anesthesia, which simulates opioid-induced overdose, were also  detected in a clinical setting. This work appeared in Science Translational Medicine.</p>\n<p><strong>Contactless infant monitoring using white noise</strong>. We created BreathJunior, the smart speaker&nbsp; system that plays white noise and records how the  noise is reflected back to detect breathing motions of infants? tiny  chests. We tested BreathJunior with five babies in a  local hospital?s neonatal intensive care unit. Our results showed that it detected respiratory  rates that closely matched the rates detected by standard vital sign  monitors. We presented these results in MobiCom 2019.&nbsp;</p>\n<p><strong>Using smart speakers to contactlessly monitor heart rhythm.</strong> Heart rhythm assessment is indispensable in diagnosis and management of  many cardiac conditions and to study heart rate variability in healthy  individuals. We designed and built a system for acquiring  individual heart beats using smart speakers in a fully contact-free  manner. Our algorithms transform the smart speaker into a short-range  active sonar system and measure heart rate and inter-beat intervals (R-R  intervals) for both regular and irregular rhythms. Compared to electrocardiogram (ECG) data, our system computed inter-heart beat intervals for healthy participants with a median error of 28&thinsp;ms over  12,280 heart beats. For  hospitalized cardiac patients, the median error was 30&thinsp;ms over 5639  heart beats. The increasing  adoption of smart speakers in hospitals and homes may provide a means to  realize the potential of our non-contact cardiac rhythm monitoring  system for monitoring of contagious or quarantined patients, skin  sensitive patients and in telemedicine settings. These results were presented at Communication Biology 2021.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/31/2021<br>\n\t\t\t\t\tModified by: Shyamnath&nbsp;Gollakota</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1812559/1812559_10552129_1640935548267_ScreenShot2021-12-30at11.25.51PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1812559/1812559_10552129_1640935548267_ScreenShot2021-12-30at11.25.51PM--rgov-800width.jpg\" title=\"Infant monitoring using smart speaker\"><img src=\"/por/images/Reports/POR/2021/1812559/1812559_10552129_1640935548267_ScreenShot2021-12-30at11.25.51PM--rgov-66x44.jpg\" alt=\"Infant monitoring using smart speaker\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Infant monitoring using smart speaker</div>\n<div class=\"imageCredit\">University of Washington</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Shyamnath&nbsp;Gollakota</div>\n<div class=\"imageTitle\">Infant monitoring using smart speaker</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1812559/1812559_10552129_1640935639809_ScreenShot2021-12-30at11.27.18PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1812559/1812559_10552129_1640935639809_ScreenShot2021-12-30at11.27.18PM--rgov-800width.jpg\" title=\"Cardiac rhythm monitoring\"><img src=\"/por/images/Reports/POR/2021/1812559/1812559_10552129_1640935639809_ScreenShot2021-12-30at11.27.18PM--rgov-66x44.jpg\" alt=\"Cardiac rhythm monitoring\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Contactless cardiac rhythm monitoring using smart speakers</div>\n<div class=\"imageCredit\">University of Washington</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Shyamnath&nbsp;Gollakota</div>\n<div class=\"imageTitle\">Cardiac rhythm monitoring</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe goal of this project is to transform mobile devices like phones and smart speakers into active sonar systems to help create medical diagnostic tools. To this end, the team has built a number of novel systems that use microphones and speakers on phones and smart speakers to screen various medical conditions as well as for monitoring physiological signals. \n\nSustained apnea detection using smartphones. We  converted a  smartphone to detect changes in respiration that precede sustained apnea events. Using sonar, the smartphone detected respiratory depression  and apnea (temporary lack of breathing) in humans. Respiratory changes during  general anesthesia, which simulates opioid-induced overdose, were also  detected in a clinical setting. This work appeared in Science Translational Medicine.\n\nContactless infant monitoring using white noise. We created BreathJunior, the smart speaker  system that plays white noise and records how the  noise is reflected back to detect breathing motions of infants? tiny  chests. We tested BreathJunior with five babies in a  local hospital?s neonatal intensive care unit. Our results showed that it detected respiratory  rates that closely matched the rates detected by standard vital sign  monitors. We presented these results in MobiCom 2019. \n\nUsing smart speakers to contactlessly monitor heart rhythm. Heart rhythm assessment is indispensable in diagnosis and management of  many cardiac conditions and to study heart rate variability in healthy  individuals. We designed and built a system for acquiring  individual heart beats using smart speakers in a fully contact-free  manner. Our algorithms transform the smart speaker into a short-range  active sonar system and measure heart rate and inter-beat intervals (R-R  intervals) for both regular and irregular rhythms. Compared to electrocardiogram (ECG) data, our system computed inter-heart beat intervals for healthy participants with a median error of 28&thinsp;ms over  12,280 heart beats. For  hospitalized cardiac patients, the median error was 30&thinsp;ms over 5639  heart beats. The increasing  adoption of smart speakers in hospitals and homes may provide a means to  realize the potential of our non-contact cardiac rhythm monitoring  system for monitoring of contagious or quarantined patients, skin  sensitive patients and in telemedicine settings. These results were presented at Communication Biology 2021.\n\n \n\n\t\t\t\t\tLast Modified: 12/31/2021\n\n\t\t\t\t\tSubmitted by: Shyamnath Gollakota"
 }
}