{
 "awd_id": "1822796",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Connections of Earth and Sky with Augmented Reality (CEASAR): Transforming Collaborative Learning Practices with Shared and Embedded Digital Models",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Robert Russell",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 748022.0,
 "awd_amount": 748022.0,
 "awd_min_amd_letter_date": "2018-09-13",
 "awd_max_amd_letter_date": "2019-04-22",
 "awd_abstract_narration": "Augmented reality (AR) technologies are becoming increasingly accessible and there are promising opportunities to develop interactive virtual content that can be shared and worked on by multiple users. The Connections of Earth and Sky to Augmented Reality (CEASAR) project will design and prototype immersive Augmented Reality (AR) learning scenarios that support collaborative interaction around solar engineering design challenges using models of planetary astronomy. This project aims to transform the way that AR is used to support small group collaboration with virtual models of scientific systems. The project envisions future workplace scenarios where teams are tasked with designing solutions to engineering problems that rely upon scientific models. Findings from this work will inform the practice of designing for computer-supported collaborative learning generally, as well as principles for designing effective immersive AR work and learning platforms. CEASAR aims to demonstrate efficacy of these extended AR capabilities for small group collaborative learning that can serve as a launching point for work and learning scenarios in medicine, engineering, science laboratories, industrial facilities, and other contexts. \r\n\r\nWhile there is evidence that AR can generate positive learning outcomes in comparison to traditional instructional methods, only recently has the technology offered collaborative engagement with shared virtual objects. The project will investigate collaborative learning practices in the context of immersive augmented reality. Specifically, the project will investigate the role of 1) coordinated visual models, 2) embodied interaction, and 3) personalized prompts and visualizations based on a collaborator's role. The project team will work directly with instructors from two local community colleges to design the collaborative learning scenarios and to recruit students for participation in design-based research studies. The project will apply available learning analytics techniques to detect and assess collaborative learning interactions within the CEASAR environment, explore ways of making the activities suitable for \"whole-class\" contexts, and create a set of design guidelines for supporting future AR workplace collaboration. Identifying practices and principles for effectively guiding learners' model engagement and design discourse through AR interactions will contribute to the research on human-computer interaction, computer-supported collaborative learning, and technology-enhanced STEM education.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robb",
   "pi_last_name": "Lindgren",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Robb W Lindgren",
   "pi_email_addr": "robblind@illinois.edu",
   "nsf_id": "000549185",
   "pi_start_date": "2018-09-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Nathan",
   "pi_last_name": "Kimball",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nathan Kimball",
   "pi_email_addr": "nkimball@concord.org",
   "nsf_id": "000100662",
   "pi_start_date": "2018-09-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Emma",
   "pi_last_name": "Mercier",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Emma Mercier",
   "pi_email_addr": "mercier@illinois.edu",
   "nsf_id": "000656659",
   "pi_start_date": "2018-09-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jina",
   "pi_last_name": "Kang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jina Kang",
   "pi_email_addr": "jinakang@illinois.edu",
   "nsf_id": "000789799",
   "pi_start_date": "2019-04-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "506 S. Wright St.",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "798000",
   "pgm_ele_name": "ECR-EDU Core Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  },
  {
   "pgm_ref_code": "8817",
   "pgm_ref_txt": "STEM Learning & Learning Environments"
  }
 ],
 "app_fund": [
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 748022.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Connections of Earth and Sky with Augmented Reality (CEASAR) project sought to identify the affordances of augmented reality (AR) environments for supporting collaborative learning in undergraduate STEM classrooms, and to test socio-technical configurations that optimize learning and engagement in these environments. To conduct this research we worked with community college astronomy instructors to develop small group collaborative learning activities that are aligned with the educational goals of a typical introductory astronomy course. To support these activities, we worked with technology developers at the Concord Consortium to develop a simulated night sky environment that could be accessed through interactions with both tablet computers and immersive headset technologies, with each offering different perspectives and different affordances for making observations and taking measurements in the course of problem solving. Due to a slower than expected release of our target AR headset, our first iteration of the CEASAR simulation environment utilized VR headsets. However, during the pandemic when we had limited access to classrooms, we converted the simulation to AR using the HoloLens 2 headset. This two-stage implementation with roughly the same educational activity meant that we could make some direct comparisons between AR and VR for supporting collaborative learning tasks. For example, we observed that inter-group communication was stronger with AR than with VR, likely because the AR users maintained visual awareness of their group members while using the immersive tech.&nbsp;</p>\n<p>The specific task that we designed for the CEASAR environment was called ?Lost at Sea.? In the narrative that accompanied the activity, a crewed space capsule has splashed down at night in an unknown ocean location. Groups of 3 to 4 students are tasked with using their night sky knowledge and the various devices that comprise the CEASAR simulation (2 tablet computers and one immersive headset) to determine the latitude and longitude of their capsule splash-down site. Both the headset and the tablet devices run a simulation that allows users to view and annotate the stars (e.g., draw lines to show constellations) and the simulation for a group is networked such that annotations from one user are visible to all users regardless of device. The headset devices offer the additional ability of viewing the stars from an embodied perspective, i.e., as if standing on the surface of the Earth and having the ability to point at the stars you are referencing. For the AR headsets, the stars appeared as a hologram that was projected around the classroom.&nbsp;</p>\n<p>The CEASAR platform and the associated Lost at Sea activity allowed the research team to collect data about how multi-device environments can potentially support communication and collaboration. Students were given opportunities to explore and experiment with the headsets and the night sky simulation prior to doing the Lost at Sea task, but once the activity began students were free to use whatever devices they wished. While the headsets did provide some key advantages and access to information, using the headsets was not required to complete the tasks, and unsurprisingly there were some groups that chose not to use the headsets. Our research on the behavior and learning of students in these classrooms found that groups that did use the headsets tended to engage in more exploratory behaviors which benefitted some of the learning outcomes of the tasks. We also found that groups that used the AR headsets tended to use more gestures, and these gestures helped these groups to create a ?shared representational understanding? of the problem-solving task. We even observed instances where students who never put on a headset were performing gestures that referenced star locations in the classroom based on their inferences about what the headset users in their group were seeing. An additional component of this project involved using logfiles from the various devices and applying learning analytics to observe patterns in student behavior. For example, we were able to develop a measure of ?shared view? that told us when students in the groups were visually attending to the same digital artifacts at the same time.&nbsp;</p>\n<p>Key outcomes of the CEASAR project include: 1) &nbsp;a robust and extendible night sky simulation that could be run on tablet computers, VR headsets, and AR headsets; 2) a collaborative learning task with associated pre- and post-learning assessments, 3) findings relevant to computer-supported collaborative learning (CSCL) and the ways students use ?multi-device ecosystems? to communicate and solve problems that were written up for numerous journal articles and conference papers, 4) guidelines for working with practitioner partners on design-based research projects that allow for changes in the design focus based on the needs and feedback of instructors.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/31/2023<br>\n\t\t\t\t\tModified by: Robb&nbsp;W&nbsp;Lindgren</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1822796/1822796_10582632_1675206703944_CEASAR--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1822796/1822796_10582632_1675206703944_CEASAR--rgov-800width.jpg\" title=\"CEASAR Group\"><img src=\"/por/images/Reports/POR/2023/1822796/1822796_10582632_1675206703944_CEASAR--rgov-66x44.jpg\" alt=\"CEASAR Group\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Students collaborating using the CEASAR simulation, including one student using an AR device</div>\n<div class=\"imageCredit\">Robb Lindgren</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Robb&nbsp;W&nbsp;Lindgren</div>\n<div class=\"imageTitle\">CEASAR Group</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe Connections of Earth and Sky with Augmented Reality (CEASAR) project sought to identify the affordances of augmented reality (AR) environments for supporting collaborative learning in undergraduate STEM classrooms, and to test socio-technical configurations that optimize learning and engagement in these environments. To conduct this research we worked with community college astronomy instructors to develop small group collaborative learning activities that are aligned with the educational goals of a typical introductory astronomy course. To support these activities, we worked with technology developers at the Concord Consortium to develop a simulated night sky environment that could be accessed through interactions with both tablet computers and immersive headset technologies, with each offering different perspectives and different affordances for making observations and taking measurements in the course of problem solving. Due to a slower than expected release of our target AR headset, our first iteration of the CEASAR simulation environment utilized VR headsets. However, during the pandemic when we had limited access to classrooms, we converted the simulation to AR using the HoloLens 2 headset. This two-stage implementation with roughly the same educational activity meant that we could make some direct comparisons between AR and VR for supporting collaborative learning tasks. For example, we observed that inter-group communication was stronger with AR than with VR, likely because the AR users maintained visual awareness of their group members while using the immersive tech. \n\nThe specific task that we designed for the CEASAR environment was called ?Lost at Sea.? In the narrative that accompanied the activity, a crewed space capsule has splashed down at night in an unknown ocean location. Groups of 3 to 4 students are tasked with using their night sky knowledge and the various devices that comprise the CEASAR simulation (2 tablet computers and one immersive headset) to determine the latitude and longitude of their capsule splash-down site. Both the headset and the tablet devices run a simulation that allows users to view and annotate the stars (e.g., draw lines to show constellations) and the simulation for a group is networked such that annotations from one user are visible to all users regardless of device. The headset devices offer the additional ability of viewing the stars from an embodied perspective, i.e., as if standing on the surface of the Earth and having the ability to point at the stars you are referencing. For the AR headsets, the stars appeared as a hologram that was projected around the classroom. \n\nThe CEASAR platform and the associated Lost at Sea activity allowed the research team to collect data about how multi-device environments can potentially support communication and collaboration. Students were given opportunities to explore and experiment with the headsets and the night sky simulation prior to doing the Lost at Sea task, but once the activity began students were free to use whatever devices they wished. While the headsets did provide some key advantages and access to information, using the headsets was not required to complete the tasks, and unsurprisingly there were some groups that chose not to use the headsets. Our research on the behavior and learning of students in these classrooms found that groups that did use the headsets tended to engage in more exploratory behaviors which benefitted some of the learning outcomes of the tasks. We also found that groups that used the AR headsets tended to use more gestures, and these gestures helped these groups to create a ?shared representational understanding? of the problem-solving task. We even observed instances where students who never put on a headset were performing gestures that referenced star locations in the classroom based on their inferences about what the headset users in their group were seeing. An additional component of this project involved using logfiles from the various devices and applying learning analytics to observe patterns in student behavior. For example, we were able to develop a measure of ?shared view? that told us when students in the groups were visually attending to the same digital artifacts at the same time. \n\nKey outcomes of the CEASAR project include: 1)  a robust and extendible night sky simulation that could be run on tablet computers, VR headsets, and AR headsets; 2) a collaborative learning task with associated pre- and post-learning assessments, 3) findings relevant to computer-supported collaborative learning (CSCL) and the ways students use ?multi-device ecosystems? to communicate and solve problems that were written up for numerous journal articles and conference papers, 4) guidelines for working with practitioner partners on design-based research projects that allow for changes in the design focus based on the needs and feedback of instructors.\n\n \n\n\t\t\t\t\tLast Modified: 01/31/2023\n\n\t\t\t\t\tSubmitted by: Robb W Lindgren"
 }
}