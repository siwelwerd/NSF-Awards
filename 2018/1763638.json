{
 "awd_id": "1763638",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Medium: Collaborative Research: Inverse Anatomical Modeling of the Face for Orthognathic Surgery",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2023-01-31",
 "tot_intn_awd_amt": 309957.0,
 "awd_amount": 319957.0,
 "awd_min_amd_letter_date": "2018-07-26",
 "awd_max_amd_letter_date": "2019-08-15",
 "awd_abstract_narration": "The face is the center of an individual's sense of identity and self-esteem, and plays a crucial role in interpersonal relationships. The current state of the art approaches computational modeling of human faces from two distinct angles. Computer graphics models feature high visual realism, as seen in the movies.  Whereas biomechanics focuses on physical realism, modeling the face as a sophisticated mechanical system that obeys the laws of physics. This project will bridge the gap between these two viewpoints and construct models of the face that offer both visual and physical realism. This is of the utmost importance in applications such as surgical prediction. Close to five percent of the population of the United States has a dentofacial anomaly that may require jaw surgery, which can have a profound effect on the appearance of the face. Virtually every patient asks, \"How will I look after the treatment?\" Even though this is an important and well-studied problem, there are currently no methods capable of predicting post-operative changes in facial expressions. By combining both visual and physical realism, this research will create the first system that can provide a natural, 3D visual answer to the patient's question by displaying a photorealistic facial animation after a simulated surgical procedure. Additional broad impact will derive from project outcomes because the new numerical techniques for the efficient simulation of biomaterials will provide a reusable foundation that can be leveraged for computational modeling of a variety of engineering materials that exhibit pronounced heterogeneity and anisotropy. The anatomical modeling framework developed in this work will also serve as a launchpad for future inquiry of interest to medical science (modeling of soft-tissue surgery, exploration of aging or pathology in the mechanics of facial expression, etc.).\r\n\r\nTo these ends, the project will create algorithms for the automated development of accurate patient-specific models of facial anatomy capable of representing realistic behavior of soft tissues, including the formation of facial expressions. The research aims at challenges which require coordinated efforts across various disciplines, including computer graphics, computer vision, biomechanics and craniofacial surgery. Novel computer vision methods will leverage information from 3D imaging (MRI/CT) to capture details of in-vivo human face deformations. The acquired data will serve as input to inverse finite element solvers, which will compute the unknown mechanical parameters of person-specific soft tissues, accounting for pre-strain and muscle activation units. This data-centric approach is a departure from established model-building methodologies, and has the potential to make a transformative impact on the anatomical modeling field. Furthermore, although the clinical application of orthognathic surgery is used as the motivation and key benchmark for the work, the algorithmic innovations produced in this activity transcend the specific scope of this task and deliver broader utility in the fields of visual computing and computational dynamics. Physics-based models of shape and deformation of elastic objects will be incorporated into visual acquisition systems as structural priors, enhancing the robustness and accuracy of the data collection.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eftychios",
   "pi_last_name": "Sifakis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eftychios Sifakis",
   "pi_email_addr": "sifakis@wisc.edu",
   "nsf_id": "000581486",
   "pi_start_date": "2018-07-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "1210 West Dayton Street",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537061204",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 309957.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 10000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research project sought to create innovative tools for modeling, simulating and interacting with virtual models of human faces, with the primary objective of using computer simulation and animation to model the effects of medical procedures or natural aging on clinical subjects that might undergo craniofacial repairs, such as jaw surgery. The specific features that this project sought to provide and enhance were: (a) the detail, resolution and biomechanical fidelity that could be accommodated in interactive simulations of surgical tissue manipulation, so that physics-based virtual editing tools can be used in real-time to re-create surgical procedures in a non-invasive setting, and animate outcomes of novel tissue manipulations, (b) using machine learning tools to generate simulation-ready models of human faces without recourse to anatomical first principles (i.e. modeling individual muscles, connective tissue and skeletal anatomy details), but using as source motion-captured performances of clinical subjects that provided merely an animated facial surface rather than deep-tissue composition, and (c) accommodating aging-related edits via neural networks and machine learning tools.&nbsp;</p>\n<p>The outcomes of this project include: A full-featured interactive surgical simulation capable of quick responsive deformations with high degree of physical fidelity, and resolutions reaching up to 1/4 million discrete elements. A system for creating facial models with automatically-inferred mechanisms of facial muscle articulation driven from surface-only performance data, which can be used to quickly craft subject-specific simulation models that can be virtually subjected to surgery. And, finally, a video-based, deep neural network system that can reliably predict the outcomes of aging on facial performances and can adjust the age of the performance subject within the 18-65 year interval.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/30/2023<br>\n\t\t\t\t\tModified by: Eftychios&nbsp;Sifakis</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688151525432_PRS--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688151525432_PRS--rgov-800width.jpg\" title=\"Murawski repair\"><img src=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688151525432_PRS--rgov-66x44.jpg\" alt=\"Murawski repair\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Illustration of the Murawski cleft lip repair using our interactive surgical simulator</div>\n<div class=\"imageCredit\">Murawski et al, 2022, J. Plastic and Reconstructive Surgery</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Eftychios&nbsp;Sifakis</div>\n<div class=\"imageTitle\">Murawski repair</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688151648022_1-s2.0-S016926072200116X-gr1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688151648022_1-s2.0-S016926072200116X-gr1--rgov-800width.jpg\" title=\"Abbe/Estlander\"><img src=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688151648022_1-s2.0-S016926072200116X-gr1--rgov-66x44.jpg\" alt=\"Abbe/Estlander\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Illustration of an Abbe/Estlander reconstruction in the upper lip, simulated using our physics-based simulator.</div>\n<div class=\"imageCredit\">Wang et al 2022, Comp. Meth. Biomedicine</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Eftychios&nbsp;Sifakis</div>\n<div class=\"imageTitle\">Abbe/Estlander</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688151913339_Screenshot2023-06-30at2.03.17PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688151913339_Screenshot2023-06-30at2.03.17PM--rgov-800width.jpg\" title=\"Data-driven model\"><img src=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688151913339_Screenshot2023-06-30at2.03.17PM--rgov-66x44.jpg\" alt=\"Data-driven model\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Data-driven quasistatic physics-model derived from performance data (juxtaposed with captured animation)</div>\n<div class=\"imageCredit\">Grama Srinivasan et al, 2021, ACM SIGGRAPH</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Eftychios&nbsp;Sifakis</div>\n<div class=\"imageTitle\">Data-driven model</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688153003321_Screenshot2023-06-30at2.22.14PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688153003321_Screenshot2023-06-30at2.22.14PM--rgov-800width.jpg\" title=\"Reaging\"><img src=\"/por/images/Reports/POR/2023/1763638/1763638_10561917_1688153003321_Screenshot2023-06-30at2.22.14PM--rgov-66x44.jpg\" alt=\"Reaging\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Automatic aging to older/younger version of an actor, using neural networks</div>\n<div class=\"imageCredit\">Zoss et al, 2022, ACM SIGGRAPH Asia</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Eftychios&nbsp;Sifakis</div>\n<div class=\"imageTitle\">Reaging</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis research project sought to create innovative tools for modeling, simulating and interacting with virtual models of human faces, with the primary objective of using computer simulation and animation to model the effects of medical procedures or natural aging on clinical subjects that might undergo craniofacial repairs, such as jaw surgery. The specific features that this project sought to provide and enhance were: (a) the detail, resolution and biomechanical fidelity that could be accommodated in interactive simulations of surgical tissue manipulation, so that physics-based virtual editing tools can be used in real-time to re-create surgical procedures in a non-invasive setting, and animate outcomes of novel tissue manipulations, (b) using machine learning tools to generate simulation-ready models of human faces without recourse to anatomical first principles (i.e. modeling individual muscles, connective tissue and skeletal anatomy details), but using as source motion-captured performances of clinical subjects that provided merely an animated facial surface rather than deep-tissue composition, and (c) accommodating aging-related edits via neural networks and machine learning tools. \n\nThe outcomes of this project include: A full-featured interactive surgical simulation capable of quick responsive deformations with high degree of physical fidelity, and resolutions reaching up to 1/4 million discrete elements. A system for creating facial models with automatically-inferred mechanisms of facial muscle articulation driven from surface-only performance data, which can be used to quickly craft subject-specific simulation models that can be virtually subjected to surgery. And, finally, a video-based, deep neural network system that can reliably predict the outcomes of aging on facial performances and can adjust the age of the performance subject within the 18-65 year interval.\n\n\t\t\t\t\tLast Modified: 06/30/2023\n\n\t\t\t\t\tSubmitted by: Eftychios Sifakis"
 }
}