{
 "awd_id": "1826097",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Learning to Control Dynamically Complex Objects",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032922633",
 "po_email": "aleoness@nsf.gov",
 "po_sign_block_name": "Alex Leonessa",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 349104.0,
 "awd_amount": 349104.0,
 "awd_min_amd_letter_date": "2018-09-06",
 "awd_max_amd_letter_date": "2018-09-06",
 "awd_abstract_narration": "Human sensorimotor capabilities vastly out-perform those of modern robots. Prior research suggests that humans achieve skillful movement by exploiting combinations of \"dynamic primitives\", which are robust building blocks of coordination that simplify control. Interaction with complex objects - such as spreading a tablecloth - requires prediction which, in turn, requires mental representations of the objects and environment.  This project explores the extent to which such mental models may also take the form of dynamic primitives.  The project team will perform fundamental research exploring: how humans learn to manipulate a complex flexible object through the composition of dynamic primitives; the impact of explicit instruction on the acquisition of the mental models; and whether a primitive-based control structure to be implemented in a robot can achieve skillful manipulation of complex objects and fluid interactions between humans and robot. This project serves the national interest because the resulting understanding of human sensorimotor control and robot control methods may result in improved efficacy of robot-assisted physical rehabilitation after neuromotor injuries such as stroke, where safe physical cooperation with humans is fundamental and mutual learning is of paramount importance.  The project will involve an educational component that provides engineering and research methods training to graduate and undergraduate students, as well as STEM outreach to individuals of all ages at the Museum of Science in Boston. Additional efforts will be made to attract and retain women into careers in science and engineering.\r\n\r\nThis research investigates a biomimetic approach to robot control that promise improved human-robot physical interaction during co-manipulation of flexible objects with complex continuum dynamics. Methods include skill acquisition experiments involving expert and novice human subjects to test how mental representations are formed and the extent to which they may be shaped by explicit instruction during training; a theoretical study of how motor learning may be facilitated using mental models based on dynamic primitives vs. lumped mechanical properties; and a study of human-robot co-manipulation of flexible objects wherein dynamic primitives provide the basis not only for robotic control, but also for communication and mutual learning between the human and robot partners. This research promises new insights into the manipulation of complex objects and tools, an area where humans still outperform machines.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Neville",
   "pi_last_name": "Hogan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Neville Hogan",
   "pi_email_addr": "neville@mit.edu",
   "nsf_id": "000215267",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 massachusetts Ave",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164200",
   "pgm_ele_name": "Special Initiatives"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "070E",
   "pgm_ref_txt": "INTEG OF HUMAN & COGNITIVE"
  },
  {
   "pgm_ref_code": "6856",
   "pgm_ref_txt": "ARTIFICIAL INTELL & COGNIT SCI"
  },
  {
   "pgm_ref_code": "7632",
   "pgm_ref_txt": "HUMAN-ROBOT INTERACTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 349104.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><h1>Learning to Control Dynamically Complex Objects</h1>\n<p>Despite impressive recent advances in robotics, humans vastly out-perform robots, especially in the manipulation of flexible objects such as clothing. Yet human muscles, nerves and brains are orders-of-magnitude slower than the corresponding robot components. How do humans do it? How do we achieve our spectacular performance despite these profound limitations? And how might we control robots to approach similar performance? The goals of this collaborative research project were to understand how humans control flexible objects; and to develop a comparable approach to controlling robots.</p>\n<ul>\n<li>We studied (with collaborators at Northeastern University) how humans learn to strike a target with a whip</li>\n<li>We tested (in simulation) whether a small number of building-block actions sufficed to strike a target with a whip</li>\n<li>We programmed a two-armed robot to spread a tablecloth on a surface that was beyond its reach</li>\n</ul>\n<p>&nbsp;Flexible objects commonly exhibit wave propagation, which is evoked when you flick a sheet or a whip. The mathematics of wave propagation are complex but we postulated that humans use a simplifying strategy: composing actions from well-learned 'building-block' actions, specifically 1) single movements; 2) continuous oscillations; and 3) the compliance of the limbs, which can be adjusted voluntarily. The key idea of this theory is that these 'building-block' actions do not require continuous intervention from the brain as they play out and produce behavior. In this way they work around the slow response of the brain, nerves and muscles.</p>\n<h2>Intellectual Merit</h2>\n<p>We developed computer simulations of a human arm wielding a whip to strike a range of distant targets. Using optimization, we showed that a single human-like movement (from rest at one configuration to rest at another) sufficed to strike most targets. For other targets, a single movement brought the (simulated) whip close to the target but did not strike it. In parallel experimental studies (at Northeastern University) we observed that human subjects used at least two movements. Returning to simulation, two movements (which could overlap in time) sufficed to strike all targets.</p>\n<p>A remarkable feature of these simulations was that the action was learned within a few hundred iterations. This is in stark contrast to state-of-the-art machine-learning approaches which require many thousands to millions of iterations to converge. It appears that this characteristically human movement (with a smooth, symmetrical bell-shaped speed profile) is well-suited to initiating and propagating a wave pulse along the whip, which can then be fine-tuned to reach a target.</p>\n<p>To translate these results to practical robot control, we programmed a low-cost two-armed Baxter robot to learn iteratively how to spread a tablecloth on a surface. The nearest edge of the surface was beyond the robot's reach so that the robot had to use the dynamics of the cloth to throw it over the surface. As in our simulations, we found that learning converged within a few hundred iterations.</p>\n<p>In other experiments we showed that humans can estimate the stiffness of a visually-presented computer-simulated arm without physical contact. That is remarkable because measuring stiffness or compliance fundamentally requires physical contact. However, the simulations presented were based on our theory that actions are composed of the building blocks described above. Subjects success suggests that they used a broadly similar control architecture as the basis of their estimates.</p>\n<h2>Broader Impact</h2>\n<p>Our results provide new insight about how humans achieve their remarkable performance. They also suggest a profound relation between motor and cognitive performance--how 'mind' may interact with 'movement'. Composing behavior from well-learned building-block actions may account for observed motor behavior and also for aspects of cognitive function, including at least some forms of perception and learning.</p>\n<p>Robot-aided rehabilitation of persons recovering from neurological injury such as stroke was pioneered by this laboratory. This newly-discovered relation between movement and cognition may enable robot-aided treatment to address cognitive as well as motor aspects of the recovery process.</p>\n<p>Our results also support an approach to robot programming based on composition of building-block actions. It is especially important for robots intended to contact and physically collaborate with humans. Robots that exhibit behavior composed in a way similar to human movement will be fundamentally more predictable by humans. We infer that they will also be more comprehensible by humans, and hence fundamentally more trustworthy and acceptable. This will facilitate future seamless integration of robotic technology into daily life and work. The societal impact (both positive and negative) could be profound.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/26/2022<br>\n\t\t\t\t\tModified by: Neville&nbsp;Hogan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Learning to Control Dynamically Complex Objects\n\nDespite impressive recent advances in robotics, humans vastly out-perform robots, especially in the manipulation of flexible objects such as clothing. Yet human muscles, nerves and brains are orders-of-magnitude slower than the corresponding robot components. How do humans do it? How do we achieve our spectacular performance despite these profound limitations? And how might we control robots to approach similar performance? The goals of this collaborative research project were to understand how humans control flexible objects; and to develop a comparable approach to controlling robots.\n\nWe studied (with collaborators at Northeastern University) how humans learn to strike a target with a whip\nWe tested (in simulation) whether a small number of building-block actions sufficed to strike a target with a whip\nWe programmed a two-armed robot to spread a tablecloth on a surface that was beyond its reach\n\n\n Flexible objects commonly exhibit wave propagation, which is evoked when you flick a sheet or a whip. The mathematics of wave propagation are complex but we postulated that humans use a simplifying strategy: composing actions from well-learned 'building-block' actions, specifically 1) single movements; 2) continuous oscillations; and 3) the compliance of the limbs, which can be adjusted voluntarily. The key idea of this theory is that these 'building-block' actions do not require continuous intervention from the brain as they play out and produce behavior. In this way they work around the slow response of the brain, nerves and muscles.\nIntellectual Merit\n\nWe developed computer simulations of a human arm wielding a whip to strike a range of distant targets. Using optimization, we showed that a single human-like movement (from rest at one configuration to rest at another) sufficed to strike most targets. For other targets, a single movement brought the (simulated) whip close to the target but did not strike it. In parallel experimental studies (at Northeastern University) we observed that human subjects used at least two movements. Returning to simulation, two movements (which could overlap in time) sufficed to strike all targets.\n\nA remarkable feature of these simulations was that the action was learned within a few hundred iterations. This is in stark contrast to state-of-the-art machine-learning approaches which require many thousands to millions of iterations to converge. It appears that this characteristically human movement (with a smooth, symmetrical bell-shaped speed profile) is well-suited to initiating and propagating a wave pulse along the whip, which can then be fine-tuned to reach a target.\n\nTo translate these results to practical robot control, we programmed a low-cost two-armed Baxter robot to learn iteratively how to spread a tablecloth on a surface. The nearest edge of the surface was beyond the robot's reach so that the robot had to use the dynamics of the cloth to throw it over the surface. As in our simulations, we found that learning converged within a few hundred iterations.\n\nIn other experiments we showed that humans can estimate the stiffness of a visually-presented computer-simulated arm without physical contact. That is remarkable because measuring stiffness or compliance fundamentally requires physical contact. However, the simulations presented were based on our theory that actions are composed of the building blocks described above. Subjects success suggests that they used a broadly similar control architecture as the basis of their estimates.\nBroader Impact\n\nOur results provide new insight about how humans achieve their remarkable performance. They also suggest a profound relation between motor and cognitive performance--how 'mind' may interact with 'movement'. Composing behavior from well-learned building-block actions may account for observed motor behavior and also for aspects of cognitive function, including at least some forms of perception and learning.\n\nRobot-aided rehabilitation of persons recovering from neurological injury such as stroke was pioneered by this laboratory. This newly-discovered relation between movement and cognition may enable robot-aided treatment to address cognitive as well as motor aspects of the recovery process.\n\nOur results also support an approach to robot programming based on composition of building-block actions. It is especially important for robots intended to contact and physically collaborate with humans. Robots that exhibit behavior composed in a way similar to human movement will be fundamentally more predictable by humans. We infer that they will also be more comprehensible by humans, and hence fundamentally more trustworthy and acceptable. This will facilitate future seamless integration of robotic technology into daily life and work. The societal impact (both positive and negative) could be profound.\n\n\t\t\t\t\tLast Modified: 11/26/2022\n\n\t\t\t\t\tSubmitted by: Neville Hogan"
 }
}