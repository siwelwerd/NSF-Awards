{
 "awd_id": "1812727",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Middleware Technologies for Multi-Accelerator Clusters",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2018-06-15",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 507896.0,
 "awd_amount": 507896.0,
 "awd_min_amd_letter_date": "2018-06-15",
 "awd_max_amd_letter_date": "2018-06-15",
 "awd_abstract_narration": "Today many computing systems include, besides traditional processors, a variety of hardware accelerators.  Hardware accelerators are devices that are not suited to run generic applications but can execute specific applications or portions of applications significantly faster than traditional processors. Two popular hardware accelerators are Graphics Processing Units (GPUs) and Field Programmable Gate Arrays (FPGAs), which are architecturally very diverse and provide various degrees of performance and power efficiency depending on the application they run. The combined use of these accelerators in a computing system, whether a single machine or a set of interconnected machines, involves significant challenges. \r\n\r\nThe goal of this project is to design a software layer allowing the effective use of diverse hardware accelerators on computing systems. Specifically, this work has the following objectives. First, the design of mapping techniques to execute applications on the available devices transparently from the end user's perspective while optimizing system utilization and maximizing performance (possibly under power consumption constraints). Second, the project will design a memory unification layer to abstract the underlying distributed memory system, while providing programmability, performance, memory protection and applications isolation. Third, the project will design various techniques to share FPGAs across applications.\r\n\r\nAs a broader impact, this project aims to facilitate the adoption of diverse accelerators on servers and compute clusters, allowing better performance and power efficiency without increasing the programming effort. Specifically, the combined use of GPUs and FPGAs can allow leveraging the various strengths of these devices on a broad range of applications with different computational patterns and resource requirements. Further, this project aims to improve software stacks to support the Open Computing Language framework on FPGAs. Finally, the impact will be extended by incorporating related topics in existing courses and involving undergraduate students in high-performance computing research.\r\n\r\nSoftware artifacts originated from this project will be stored on machines administered by North Carolina State Electrical and Computer Engineering's Information Technology team for a minimum of ten years. Some software artifacts will be released in open-source and made available through North Carolina State Github (https://github.ncsu.edu) or the investigators website. Instructional materials will be made available through North Carolina State's WolfWare system. Publications will be maintained and distributed by the appropriate journals and conference proceedings.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michela",
   "pi_last_name": "Becchi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michela Becchi",
   "pi_email_addr": "mbecchi@ncsu.edu",
   "nsf_id": "000573363",
   "pi_start_date": "2018-06-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "Engineering Building II",
  "perf_city_name": "Raleigh",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276957911",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 507896.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Today many computing systems include, besides traditional processors, a variety of hardware accelerators. Hardware accelerators are devices that are not suited to run generic applications but can execute specific applications or portions of applications significantly faster than traditional processors. Two popular hardware accelerators are Graphics Processing Units (GPUs) and Field Programmable Gate Arrays (FPGAs), which are architecturally very diverse and provide various degrees of performance and power efficiency depending on the application they run. More recently, Data Processing Units (DPUs) have been proposed to accelerate data processing, including data movements.&nbsp;The combined use of these accelerators in a computing system, whether a single machine or a set of interconnected machines, involves significant challenges.</span></p>\n<p><span>This proposal has contributed software technologies - including compiler and runtime techniques - to allow the effective use of diverse accelerators on computing systems. Some of the proposed techniques have targeted applications written using OpenCL - an open standard for heterogeneous systems that provides a uniform programming interface to diverse platforms, such as CPUs, GPUs, and FPGAs.&nbsp;</span></p>\n<p><span>Although OpenCL allows code portability and programmer productivity, it does&nbsp;not guarantee performance portability. Specifically, due to architectural differences across devices, an OpenCL code tailored to&nbsp;one platform often performs poorly on a different one. In addition, FPGAs have traditionally been programmed through low-level hardware definition languages, and achieving good performance on these devices using high-level programming interfaces is not trivial. The proposed compiler techniques have targeted these problems. Specifically, we have proposed mechanisms to improve the performance of OpenCL applications on FPGA and to retarget code written for GPU to FPGA devices. These includes thread coarsening (a technique to adjust the degree of parallelism of an application) and kernel restructuring through channels (a technique to decouple the computation and memory accesses performed by an application, leading to improved memory utilization and improved performance).</span></p>\n<p><span>The effective use of hardware accelerators in shared environments, such as high-performance computing clusters and clouds &ndash; is complicated by several challenges. First, multitenancy causes interference among applications competing for the same hardware resources. Second, scheduling on heterogeneous hardware requires the judicious use of all available computing devices. Third, the continuous increase in size of the data processes by applications impacts their memory and storage requirements, and often leads to significant communication costs. The runtime techniques we have proposed aim to address these issues. To this end, we have designed and implemented several runtime systems, including Pilot and Runway. Using specific scheduling policies, Pilot mitigates the performance impact of memory interference across applications sharing GPUs. To decrease memory and storage requirements and limit communication costs, Runway performs (transparently to the users) in-transit data compression for applications running on heterogeneous HPC systems, while properly scheduling the computation on the available computing devices. In addition, we have designed several compression mechanisms that can be integrated in Runway.</span></p>\n<p><span>Finally, the project has led to optimized implementations of machine learning algorithms &ndash; including forest classification and influence maximization - on heterogeneous devices (including GPUs and FPGAs).</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/17/2023<br>\nModified by: Michela&nbsp;Becchi</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1812727/1812727_10550977_1700256286193_runway_framework--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/1812727/1812727_10550977_1700256286193_runway_framework--rgov-800width.png\" title=\"Runway\"><img src=\"/por/images/Reports/POR/2023/1812727/1812727_10550977_1700256286193_runway_framework--rgov-66x44.png\" alt=\"Runway\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Overview of Runway's runtime system</div>\n<div class=\"imageCredit\">John Ravi, Michela Becchi, Suren Byna</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Michela&nbsp;Becchi\n<div class=\"imageTitle\">Runway</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/1812727/1812727_10550977_1700256231583_pilot--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/1812727/1812727_10550977_1700256231583_pilot--rgov-800width.png\" title=\"Pilot\"><img src=\"/por/images/Reports/POR/2023/1812727/1812727_10550977_1700256231583_pilot--rgov-66x44.png\" alt=\"Pilot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Overview of Pilot's runtime system</div>\n<div class=\"imageCredit\">John Ravi and Michela Becchi</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Michela&nbsp;Becchi\n<div class=\"imageTitle\">Pilot</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nToday many computing systems include, besides traditional processors, a variety of hardware accelerators. Hardware accelerators are devices that are not suited to run generic applications but can execute specific applications or portions of applications significantly faster than traditional processors. Two popular hardware accelerators are Graphics Processing Units (GPUs) and Field Programmable Gate Arrays (FPGAs), which are architecturally very diverse and provide various degrees of performance and power efficiency depending on the application they run. More recently, Data Processing Units (DPUs) have been proposed to accelerate data processing, including data movements.The combined use of these accelerators in a computing system, whether a single machine or a set of interconnected machines, involves significant challenges.\n\n\nThis proposal has contributed software technologies - including compiler and runtime techniques - to allow the effective use of diverse accelerators on computing systems. Some of the proposed techniques have targeted applications written using OpenCL - an open standard for heterogeneous systems that provides a uniform programming interface to diverse platforms, such as CPUs, GPUs, and FPGAs.\n\n\nAlthough OpenCL allows code portability and programmer productivity, it doesnot guarantee performance portability. Specifically, due to architectural differences across devices, an OpenCL code tailored toone platform often performs poorly on a different one. In addition, FPGAs have traditionally been programmed through low-level hardware definition languages, and achieving good performance on these devices using high-level programming interfaces is not trivial. The proposed compiler techniques have targeted these problems. Specifically, we have proposed mechanisms to improve the performance of OpenCL applications on FPGA and to retarget code written for GPU to FPGA devices. These includes thread coarsening (a technique to adjust the degree of parallelism of an application) and kernel restructuring through channels (a technique to decouple the computation and memory accesses performed by an application, leading to improved memory utilization and improved performance).\n\n\nThe effective use of hardware accelerators in shared environments, such as high-performance computing clusters and clouds  is complicated by several challenges. First, multitenancy causes interference among applications competing for the same hardware resources. Second, scheduling on heterogeneous hardware requires the judicious use of all available computing devices. Third, the continuous increase in size of the data processes by applications impacts their memory and storage requirements, and often leads to significant communication costs. The runtime techniques we have proposed aim to address these issues. To this end, we have designed and implemented several runtime systems, including Pilot and Runway. Using specific scheduling policies, Pilot mitigates the performance impact of memory interference across applications sharing GPUs. To decrease memory and storage requirements and limit communication costs, Runway performs (transparently to the users) in-transit data compression for applications running on heterogeneous HPC systems, while properly scheduling the computation on the available computing devices. In addition, we have designed several compression mechanisms that can be integrated in Runway.\n\n\nFinally, the project has led to optimized implementations of machine learning algorithms  including forest classification and influence maximization - on heterogeneous devices (including GPUs and FPGAs).\n\n\n\t\t\t\t\tLast Modified: 11/17/2023\n\n\t\t\t\t\tSubmitted by: MichelaBecchi\n"
 }
}