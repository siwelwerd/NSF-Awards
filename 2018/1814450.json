{
 "awd_id": "1814450",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS:Small:Utilizing synergy between human and computer information processing for complex visual information organization and use",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2018-07-15",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 497424.0,
 "awd_amount": 497424.0,
 "awd_min_amd_letter_date": "2018-07-09",
 "awd_max_amd_letter_date": "2023-02-27",
 "awd_abstract_narration": "CHS: Small: Utilizing synergy between human and computer information processing for complex visual information organization and use\r\n\r\nRecent years have brought important advances in the use of computational approaches to automatically extract the meaning of an image (aka, image semantics). But, understanding these images when they relate to specialized areas such as medicine is significantly more challenging because it depends on human expertise. This project brings together human and computer capabilities to discover image semantics by (1) encoding human image inspection and analysis behaviors that represent domain expertise, and (2) algorithmically fusing human expertise with image data. The outcomes will help to provide truly meaningful interpretations of complex images in areas such as medicine, science, and security intelligence. This interdisciplinary project will provide extensive research opportunities for undergraduate and graduate students and for broadening participation in computing. The team will leverage the college?s successful program for Women in Computing and PhD Program that has a strong track record in recruiting students from underrepresented and culturally-diverse groups. \r\nThe research will contribute novel computational models to capture the complex and unique features of human language and vision related to performing image understanding tasks, and an innovative probabilistic framework to fuse human knowledge data with image features. Interpretable knowledge patterns will be extracted to inform high-level abstractions of human expertise and establish cross-modality relationships. The hierarchical probabilistic framework will promote a systematic fusion of multimodal knowledge data with image content. By fusing data from multiple, complimentary modalities, the framework is robust to sparseness, noise, and ambiguity in human knowledge data while being flexible when one or more data modalities become unavailable. Through nonparametric modeling, the framework can account for the novel semantics resulting from human expertise, hence closely represent the knowledge-based processing in human image understanding.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Qi",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Qi Yu",
   "pi_email_addr": "qi.yu@rit.edu",
   "nsf_id": "000569636",
   "pi_start_date": "2018-07-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Anne",
   "pi_last_name": "Haake",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anne Haake",
   "pi_email_addr": "anne.haake@rit.edu",
   "nsf_id": "000178919",
   "pi_start_date": "2018-07-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Pengcheng",
   "pi_last_name": "Shi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pengcheng Shi",
   "pi_email_addr": "pengcheng.shi@rit.edu",
   "nsf_id": "000497834",
   "pi_start_date": "2018-07-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rui",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rui Li",
   "pi_email_addr": "rxlics@rit.edu",
   "nsf_id": "000711934",
   "pi_start_date": "2018-07-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rochester Institute of Tech",
  "inst_street_address": "1 LOMB MEMORIAL DR",
  "inst_street_address_2": "",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5854757987",
  "inst_zip_code": "146235603",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "ROCHESTER INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "J6TWTRKC1X14"
 },
 "perf_inst": {
  "perf_inst_name": "Rochester Institute of Tech",
  "perf_str_addr": "1 Lomb Memorial Drive",
  "perf_city_name": "Rochester",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146235603",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 497424.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-33c2a06e-7fff-aa1e-33d3-f897b017e2c6\"> </span></p>\n<p dir=\"ltr\"><span>This project has contributed a suite of novel computational models that enable intelligent machines to effectively learn from diverse forms of human knowledge in interactive learning environments. Specifically, we have developed: (1) a general multimodal knowledge data fusion framework that extracts interpretable patterns from multiple data modalities (e.g., verbal narrations, eye movements, and hand motions) and integrates them to support critical decision-making; (2) a series of active learning and testing techniques for multi-class, multi-label, and weakly supervised learning settings, providing a foundation for training and evaluating machine learning models with significantly reduced labeling costs&mdash;ideal for human-machine collaboration; and (3) fine-grained uncertainty decomposition strategies that facilitate knowledge exchange between humans and machines, thereby enhancing the trustworthiness of collaborative decision-making.</span></p>\n<p dir=\"ltr\"><span>In knowledge-rich fields such as medicine and bioinformatics, vast amounts of data are generated, yet the challenge lies in how to integrate crucial human domain knowledge to analyze, interpret, and use the data effectively. This project highlights the value of leveraging the synergy between human expertise and computational power to support complex, collaborative decision-making. It establishes important theoretical foundations while providing critical empirical evaluations on how human expertise can be infused into the design of intelligent systems. The proposed techniques have been applied across various domains, including medical diagnosis, behavioral analysis of children on the autism spectrum, and interactive surveillance video analysis. This research is broadly applicable to other knowledge-rich domains where human-machine collaboration is essential to solving highly complex computational tasks. The outcomes have been disseminated widely through curriculum materials, publications in leading machine learning, artificial intelligence, and computer vision venues, as well as exhibitions, tutorials, and invited talks.</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/20/2024<br>\nModified by: Qi&nbsp;Yu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThis project has contributed a suite of novel computational models that enable intelligent machines to effectively learn from diverse forms of human knowledge in interactive learning environments. Specifically, we have developed: (1) a general multimodal knowledge data fusion framework that extracts interpretable patterns from multiple data modalities (e.g., verbal narrations, eye movements, and hand motions) and integrates them to support critical decision-making; (2) a series of active learning and testing techniques for multi-class, multi-label, and weakly supervised learning settings, providing a foundation for training and evaluating machine learning models with significantly reduced labeling costsideal for human-machine collaboration; and (3) fine-grained uncertainty decomposition strategies that facilitate knowledge exchange between humans and machines, thereby enhancing the trustworthiness of collaborative decision-making.\n\n\nIn knowledge-rich fields such as medicine and bioinformatics, vast amounts of data are generated, yet the challenge lies in how to integrate crucial human domain knowledge to analyze, interpret, and use the data effectively. This project highlights the value of leveraging the synergy between human expertise and computational power to support complex, collaborative decision-making. It establishes important theoretical foundations while providing critical empirical evaluations on how human expertise can be infused into the design of intelligent systems. The proposed techniques have been applied across various domains, including medical diagnosis, behavioral analysis of children on the autism spectrum, and interactive surveillance video analysis. This research is broadly applicable to other knowledge-rich domains where human-machine collaboration is essential to solving highly complex computational tasks. The outcomes have been disseminated widely through curriculum materials, publications in leading machine learning, artificial intelligence, and computer vision venues, as well as exhibitions, tutorials, and invited talks.\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 10/20/2024\n\n\t\t\t\t\tSubmitted by: QiYu\n"
 }
}