{
 "awd_id": "1835473",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Elements: Data:  Integrating Human and Machine for Post-Disaster Visual Data Analytics:  A Modern Media-Oriented Approach",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032927092",
 "po_email": "alsuarez@nsf.gov",
 "po_sign_block_name": "Alejandro Suarez",
 "awd_eff_date": "2019-01-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 597955.0,
 "awd_amount": 597955.0,
 "awd_min_amd_letter_date": "2018-08-18",
 "awd_max_amd_letter_date": "2018-08-18",
 "awd_abstract_narration": "This project creates a science-oriented visual data service that facilitates the query of datasets based on visual content. The approach allows a user to search for data based on visual similarity, even in cases where a term for the failure or observation does not yet have a scientific name.  The visual analysis data and application services will be deployed on a cloud-based platform.  The results will produce a framework enabling access to and analysis of a large amount of imagery from diverse sources.  \r\n\r\nThe research team creates VISER (Visual Structural Expertise Replicator), which will serve as a comprehensive cloud-based data analytics service and will facilitate the use of and integrate data and applications most needed by the user.  The framework will implement two novel concepts: data-as-a-service and applications-as-a-service, which will bring data and applications to the user without the need to configure software systems or packages.  The approach also employs artificial intelligence to interpret the contents of the images.  VISER will use convolutional neural networks (CNNs) to train custom classifiers for new categories.  Three applications will be developed and deployed within VISER:  App1 will extract relevant visual context, App2 will facilitate similarity-based visual searching (through the use of a Siamese CNN), and App3 will help perform automatic extraction of pre-event/pre-disaster images based on Google Street View.  The application of these tools would advance both the science of automated pattern recognition and of more effective construction techniques.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shirley",
   "pi_last_name": "Dyke",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Shirley J Dyke",
   "pi_email_addr": "sdyke@purdue.edu",
   "nsf_id": "000312078",
   "pi_start_date": "2018-08-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Thomas",
   "pi_last_name": "Hacker",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas J Hacker",
   "pi_email_addr": "tjhacker@purdue.edu",
   "nsf_id": "000326229",
   "pi_start_date": "2018-08-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Bedrich",
   "pi_last_name": "Benes",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bedrich Benes",
   "pi_email_addr": "bbenes@purdue.edu",
   "nsf_id": "000291472",
   "pi_start_date": "2018-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "Young Hall",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072114",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "077Z",
   "pgm_ref_txt": "CSSI-1: Cyberinfr for Sustained Scientif"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 597955.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Goal</strong>: In the aftermath of each natural disaster, researchers travel to the site to collect perishable photographic evidence needed to document the performance of our infrastructure and learn from that event. In a past project we established the fundamental knowledge needed to successfully implement image classification methods on unstructured reconnaissance data to organize these data and accelerate their use for scientific purposes. A researcher-oriented tool, the&nbsp;<strong>Automated Reconnaissance Image Organizer</strong>&nbsp;(ARIO), was built by leveraging automated image classification in a domain-specific manner to assist users to automatically classify, sort and organize their image data.&nbsp;</p>\n<p>This project,&nbsp;<em>Integrating Human and Machine for Post-Disaster Visual Data Analytics: A Modern Media-Oriented Approach</em>, extended ARIO from a tool to a comprehensive cloud-based data analytics service,&nbsp;<strong>Visual Structural Expertise Replicator&nbsp;</strong>(ViSER). In our work machine learning (ML) is used not to replace a human expert, but to&nbsp;<strong><em>augment</em></strong>&nbsp;and&nbsp;<strong><em>support</em></strong>&nbsp;the human expert by improving productivity and consistency while reducing tedious and time-consuming tasks. The recent explosion in funding in ML, AI, and computer science has encouraged rapid development and supported a transition from their use solely for idealized \"toy\" problems to practical implementations. &nbsp;Our establishment of a curated dataset composed of 140,000 real-world field images from disaster scenes enabled the VISER platform to be realized here. VISER includes specialized modules for concrete buildings and bridges.&nbsp;</p>\n<p>ViSER consists of several components: a web-based post-disaster visual data organization and report generation application, an Infrastructure-as-Code based approach that seeks to create secure extend layer 2 services for provisioning bare systems (bare metal or virtual machines) over a wide area network, and a prototype image classification service that can be deployed on Purdue's community clusters. The fundamental applications (for buildings and bridges, and earthquakes and hurricanes) developed enable: (a) image localization within buildings to provide important context to the data; (b) similarity search to merge disparate data from a single structure; and (c) expanded the data schema and added relevant capabilities for organizing, searching, and filtering through image data.&nbsp;</p>\n<p>VISER provides researchers with the power to exploit vast amount of data and to rapidly search across construction type, damage features, geographical region, etc. Engineers will be empowered to design and construct a more resilient physical infrastructure using more comprehensive knowledge about structural performance, directly incorporated into building codes and influencing practice and policy.&nbsp;</p>\n<p><strong>Partnerships</strong>: Our team's April 2023 workshop \"Envisioning AI in a Decade\" engaging 30+ industry/academic participants to discuss future opportunities and challenges of using AI in this domain. These discussions revealed&nbsp;important practical lessons.&nbsp;Practicing structural engineers are quite eager to use ML to make their work more efficient, while directing their time and energy toward resolving problems. Engineers feel confident about such results when they are given information to help them&nbsp;<em>understand the rationale</em>&nbsp;behind a classification decision, rather than simply accepting the outcome. Insufficient background and training in AI methods are major barriers to achieving this goal. Thus, now is the time to establish strong partnerships between in industry and academia to address these barriers and realize the potential of ML in engineering practice.</p>\n<p>Partnering with a team of researchers from the Institute of Engineering-Mexico (UNAM) we integrated their post-earthquake survey experiences with our expertise on deep learning technologies. They shared the database they developed after the 2017 Puebla Earthquake with the Institute for Building Safety of Mexico City.&nbsp;</p>\n<p class=\"StyleJustifiedBefore6pt\">Furthermore, after the devastating Mw. 7.8 Kahramanmara&#351; Earthquake in Turkey, a member of our team travelled to Turkey, joining the ACI 133 Reconnaissance team. During this trip, she visited dozens of buildings and collected over 100GB of building imagery to support this research. &nbsp;</p>\n<p><strong>Impact on the Team</strong>: Research conducted by the graduate students at Purdue University includes work related to data collection, algorithm development and algorithm implementation. To participate in this process, they learned about the latest state of art on computer vision, building and infrastructure reconnaissance, visual inspection, data organization, technical writing, and the research process.&nbsp;</p>\n<p><strong>Impact on the Built Environment and Society:</strong></p>\n<p>The methods developed in this project converted unstructured data in the form of images, that would have been otherwise difficult to analyze into reliable and organized data with well-defined and structural engineering - oriented categories. These categories, meant to support engineers in their routine decision-making, will assist engineers in the creation of design guidelines and pre-standards grounded on the new knowledge generated by the organized data. Ultimately, these methods will directly impact the design codes to build a safer and more resilient infrastructure to support our communities and societies.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/28/2023<br>\n\t\t\t\t\tModified by: Shirley&nbsp;J&nbsp;Dyke</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1835473/1835473_10572988_1693691002731_VISERplatform--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1835473/1835473_10572988_1693691002731_VISERplatform--rgov-800width.jpg\" title=\"VISER\"><img src=\"/por/images/Reports/POR/2023/1835473/1835473_10572988_1693691002731_VISERplatform--rgov-66x44.jpg\" alt=\"VISER\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Description of the VISER platform and its functions.</div>\n<div class=\"imageCredit\">Shirley Dyke</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Shirley&nbsp;J&nbsp;Dyke</div>\n<div class=\"imageTitle\">VISER</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nGoal: In the aftermath of each natural disaster, researchers travel to the site to collect perishable photographic evidence needed to document the performance of our infrastructure and learn from that event. In a past project we established the fundamental knowledge needed to successfully implement image classification methods on unstructured reconnaissance data to organize these data and accelerate their use for scientific purposes. A researcher-oriented tool, the Automated Reconnaissance Image Organizer (ARIO), was built by leveraging automated image classification in a domain-specific manner to assist users to automatically classify, sort and organize their image data. \n\nThis project, Integrating Human and Machine for Post-Disaster Visual Data Analytics: A Modern Media-Oriented Approach, extended ARIO from a tool to a comprehensive cloud-based data analytics service, Visual Structural Expertise Replicator (ViSER). In our work machine learning (ML) is used not to replace a human expert, but to augment and support the human expert by improving productivity and consistency while reducing tedious and time-consuming tasks. The recent explosion in funding in ML, AI, and computer science has encouraged rapid development and supported a transition from their use solely for idealized \"toy\" problems to practical implementations.  Our establishment of a curated dataset composed of 140,000 real-world field images from disaster scenes enabled the VISER platform to be realized here. VISER includes specialized modules for concrete buildings and bridges. \n\nViSER consists of several components: a web-based post-disaster visual data organization and report generation application, an Infrastructure-as-Code based approach that seeks to create secure extend layer 2 services for provisioning bare systems (bare metal or virtual machines) over a wide area network, and a prototype image classification service that can be deployed on Purdue's community clusters. The fundamental applications (for buildings and bridges, and earthquakes and hurricanes) developed enable: (a) image localization within buildings to provide important context to the data; (b) similarity search to merge disparate data from a single structure; and (c) expanded the data schema and added relevant capabilities for organizing, searching, and filtering through image data. \n\nVISER provides researchers with the power to exploit vast amount of data and to rapidly search across construction type, damage features, geographical region, etc. Engineers will be empowered to design and construct a more resilient physical infrastructure using more comprehensive knowledge about structural performance, directly incorporated into building codes and influencing practice and policy. \n\nPartnerships: Our team's April 2023 workshop \"Envisioning AI in a Decade\" engaging 30+ industry/academic participants to discuss future opportunities and challenges of using AI in this domain. These discussions revealed important practical lessons. Practicing structural engineers are quite eager to use ML to make their work more efficient, while directing their time and energy toward resolving problems. Engineers feel confident about such results when they are given information to help them understand the rationale behind a classification decision, rather than simply accepting the outcome. Insufficient background and training in AI methods are major barriers to achieving this goal. Thus, now is the time to establish strong partnerships between in industry and academia to address these barriers and realize the potential of ML in engineering practice.\n\nPartnering with a team of researchers from the Institute of Engineering-Mexico (UNAM) we integrated their post-earthquake survey experiences with our expertise on deep learning technologies. They shared the database they developed after the 2017 Puebla Earthquake with the Institute for Building Safety of Mexico City. \nFurthermore, after the devastating Mw. 7.8 Kahramanmara&#351; Earthquake in Turkey, a member of our team travelled to Turkey, joining the ACI 133 Reconnaissance team. During this trip, she visited dozens of buildings and collected over 100GB of building imagery to support this research.  \n\nImpact on the Team: Research conducted by the graduate students at Purdue University includes work related to data collection, algorithm development and algorithm implementation. To participate in this process, they learned about the latest state of art on computer vision, building and infrastructure reconnaissance, visual inspection, data organization, technical writing, and the research process. \n\nImpact on the Built Environment and Society:\n\nThe methods developed in this project converted unstructured data in the form of images, that would have been otherwise difficult to analyze into reliable and organized data with well-defined and structural engineering - oriented categories. These categories, meant to support engineers in their routine decision-making, will assist engineers in the creation of design guidelines and pre-standards grounded on the new knowledge generated by the organized data. Ultimately, these methods will directly impact the design codes to build a safer and more resilient infrastructure to support our communities and societies. \n\n\t\t\t\t\tLast Modified: 09/28/2023\n\n\t\t\t\t\tSubmitted by: Shirley J Dyke"
 }
}