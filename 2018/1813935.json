{
 "awd_id": "1813935",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Transfer Learning using Transformation among Models and Samples",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 499938.0,
 "awd_amount": 515938.0,
 "awd_min_amd_letter_date": "2018-08-03",
 "awd_max_amd_letter_date": "2019-06-25",
 "awd_abstract_narration": "As huge volumes of unlabeled data are generated and made available in many domains, annotating data in these domains becomes burdensome and creates a major bottleneck in maintaining machine-learning databases.  This project will investigate a family of transfer-learning methods as an automatic annotation tool, without human involvement, in annotating data for various machine-learning settings.  The novelty of the project's transfer-learning approach is based on the common concept of matching-based optimization technique to solve the different forms of transfer learning.  The optimization will be carried out using transformations at different levels for different forms.  The planned transfer-learning framework will exploit lots of unlabeled data or a few labelled data in the target domain and prior knowledge in the form of labelled source data, source models or other auxiliary information in the source domain.  Using this common matching-based optimization framework, this will bring out a natural transition from low-level, sample-based matching to high-level, model-based matching for the different forms of transfer learning.  The family of transfer learning methods will have promising ramifications in diverse areas such as intelligent robots and self-driving cars so that they operate efficiently in new and changing environments without the need of large amount of annotated data in the new environments.\r\n\r\nThis project will investigate two major forms of transfer learning -- domain adaptation and few-shot learning.  The research will focus on studying the effect of the proposed matching-based optimization technique to solve the different forms of transfer learning.  The project will focus on three major tasks, depending on what information is available in each task: (Task 1) Unsupervised domain adaptation, where the source-domain data is labelled while the target-domain data is unlabeled.  In this case, the project team will investigate the optimization based on matching each source-domain sample with each target-domain sample to learn a generalizable target model; (Task 2) Hypothesis transfer learning, where the source and the target domain tasks are different, and only source models and sparsely labelled target domain data will be used to learn a generalizable target model.  The model will be learned using matching between source models and target-domain samples; (Task 3) Few-shot learning, where the goal is to learn a generalizable target model from a few labelled samples in the target domain by utilizing auxiliary source knowledge.  The project team will study whether transformation between source-model parameters can be substituted as useful auxiliary source-domain knowledge.  Hence, the planned research will minimize the requirement of obtaining lots of labelled samples used in machine learning, and it will realize robust learning systems that are generalizable across tasks and domains.  Furthermore, since the matching is carried out among each individual sample/model of information locally and explicitly, the results are expected to be better than previous methods.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chun-Sing",
   "pi_last_name": "Lee",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Chun-Sing G Lee",
   "pi_email_addr": "csglee@purdue.edu",
   "nsf_id": "000433325",
   "pi_start_date": "2018-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072035",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 499938.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project investigates methodologies that provide solutions to tackle the inherent problems of Online Unsupervised Domain Adaptation (OUDA), where the source-domain data is labeled while the target-domain data is unlabeled. The OUDA problem requires continuous adaptation of the learning model to the evolving distribution shift between the source and target domains while handling the online arrival of unlabeled target data.</p>\n<p>This project proposed two innovative and complementary approaches -- the manifold-based and the time-domain-based strategies -- to effectively address and solve the inherent problems of OUDA.&nbsp;&nbsp;These approaches are designed to enable the learning model to continuously adapt to the online arrival of evolving characteristics of target data.</p>\n<p>The manifold-based approach has introduced a multi-stage framework (see Figure 1) with novel techniques such as Incremental Computation of Mean-target Subspace (ICMS) and the harnessing power of Grassmann manifold projections for domain alignment. The manifold-based approach incorporates the domain alignment process in an incremental computation manner, and this novel technique/process leverages the computation of transformation matrices, based on the projection of both source and target data onto the Grassmann manifold. This projection aligns both domains by incrementally minimizing their dissimilarities, effectively ameliorating the divergence between the source and target data.&nbsp;&nbsp;This approach not only efficiently computes the mean-target subspace but also ensures robustness in the face of noisy online domain adaptation tasks.&nbsp;&nbsp;Additionally, it considers the cumulative temporal consistency of the target domain on the Grassmann manifold, culminating in an adaptive classifier suitable for online domain adaptation.&nbsp;</p>\n<p>The time-domain-based framework (see Figure 2) has capitalized on cluster-wise information and the flow of target features over time to accurately predict target labels in incoming target data, propagate consistently the class labels to future incoming target data, and efficiently utilize the predicted labels in the target data together with the source data to incrementally update the learning model in a supervised-learning scenario. This process effectively transforms the OUDA problem into a supervised-learning scenario.&nbsp;&nbsp;We leverage a neural-network-based model to align target features, cluster them class-wise and extend them linearly from the origin of the latent space as the time-step progresses. This alignment process enables accurate predictions and target label propagation based on the trajectories of the target features. We achieve target label propagation through the novel Flow-based Hierarchical Optimal Transport (FHOT) method, which considers element-wise, cluster-wise, and distribution-wise correspondences of adjacent target features. The learning model is continuously updated with incoming target data and their predicted labels.</p>\n<p>The contributions of this project extend not only to the advancement of OUDA solutions but also to the broader domain adaptation and machine learning, where the demands of real-world, data-driven applications continue to evolve and grow. The time-domain OUDA framework can be generalized and extended to many real-world applications in unsupervised learning such as data clustering, data-mining, data annotation, and pattern recognition/classification tasks.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/29/2023<br>\nModified by: Chun-Sing&nbsp;G&nbsp;Lee</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project investigates methodologies that provide solutions to tackle the inherent problems of Online Unsupervised Domain Adaptation (OUDA), where the source-domain data is labeled while the target-domain data is unlabeled. The OUDA problem requires continuous adaptation of the learning model to the evolving distribution shift between the source and target domains while handling the online arrival of unlabeled target data.\n\n\nThis project proposed two innovative and complementary approaches -- the manifold-based and the time-domain-based strategies -- to effectively address and solve the inherent problems of OUDA.These approaches are designed to enable the learning model to continuously adapt to the online arrival of evolving characteristics of target data.\n\n\nThe manifold-based approach has introduced a multi-stage framework (see Figure 1) with novel techniques such as Incremental Computation of Mean-target Subspace (ICMS) and the harnessing power of Grassmann manifold projections for domain alignment. The manifold-based approach incorporates the domain alignment process in an incremental computation manner, and this novel technique/process leverages the computation of transformation matrices, based on the projection of both source and target data onto the Grassmann manifold. This projection aligns both domains by incrementally minimizing their dissimilarities, effectively ameliorating the divergence between the source and target data.This approach not only efficiently computes the mean-target subspace but also ensures robustness in the face of noisy online domain adaptation tasks.Additionally, it considers the cumulative temporal consistency of the target domain on the Grassmann manifold, culminating in an adaptive classifier suitable for online domain adaptation.\n\n\nThe time-domain-based framework (see Figure 2) has capitalized on cluster-wise information and the flow of target features over time to accurately predict target labels in incoming target data, propagate consistently the class labels to future incoming target data, and efficiently utilize the predicted labels in the target data together with the source data to incrementally update the learning model in a supervised-learning scenario. This process effectively transforms the OUDA problem into a supervised-learning scenario.We leverage a neural-network-based model to align target features, cluster them class-wise and extend them linearly from the origin of the latent space as the time-step progresses. This alignment process enables accurate predictions and target label propagation based on the trajectories of the target features. We achieve target label propagation through the novel Flow-based Hierarchical Optimal Transport (FHOT) method, which considers element-wise, cluster-wise, and distribution-wise correspondences of adjacent target features. The learning model is continuously updated with incoming target data and their predicted labels.\n\n\nThe contributions of this project extend not only to the advancement of OUDA solutions but also to the broader domain adaptation and machine learning, where the demands of real-world, data-driven applications continue to evolve and grow. The time-domain OUDA framework can be generalized and extended to many real-world applications in unsupervised learning such as data clustering, data-mining, data annotation, and pattern recognition/classification tasks.\n\n\n\t\t\t\t\tLast Modified: 11/29/2023\n\n\t\t\t\t\tSubmitted by: Chun-SingGLee\n"
 }
}