{
 "awd_id": "1813081",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF:Small: Collaborative Research: Understanding, Modeling, and System Support for HPC Data Reduction",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2018-07-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 199898.0,
 "awd_amount": 199898.0,
 "awd_min_amd_letter_date": "2018-06-22",
 "awd_max_amd_letter_date": "2018-06-22",
 "awd_abstract_narration": "High-performance computing (HPC) enables high fidelity science missions that capture microscopic phenomena that were impossible to study in the past. In order to allow science missions to be accomplished in a timely manner, it is critical to manage the massive datasets that HPC generates in efficient way so that the time to knowledge can be shortened. This project aims to understand the role and usage of data reduction in large computational applications. Research and educational opportunities are provided to train a new generation of computer scientists and engineers, particularly those under-represented groups, to ensure the U.S. competitiveness in high-performance computing. \r\n\t\r\nThe goal of this project is to address a number of critical gaps in using data reduction for HPC-based science missions. In particular, 1) the impact of reduction error on scientific discovery is mathematically and experimentally studied; 2) analytical models are formulated to estimate the reduction performance, without forcing users to compress the full data. For data-intensive applications, having this capability is important so that domain scientists do not have to go through the cumbersome trial-and-error process to figure out what reduction can offer; 3) the project provides potentially more efficient data analysis and reduction capabilities for exascale computing. The integrated research activities in this NSF project will significantly improve the understanding and usage of data reduction on future systems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xubin",
   "pi_last_name": "He",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xubin He",
   "pi_email_addr": "xubin.he@temple.edu",
   "nsf_id": "000110014",
   "pi_start_date": "2018-06-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Temple University",
  "inst_street_address": "1805 N BROAD ST",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2157077547",
  "inst_zip_code": "191226104",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "PA02",
  "org_lgl_bus_name": "TEMPLE UNIVERSITY-OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "QD4MGHFDJKU1",
  "org_uei_num": "QD4MGHFDJKU1"
 },
 "perf_inst": {
  "perf_inst_name": "Temple University",
  "perf_str_addr": "1925 N. 12th Street",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191221801",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "PA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 199898.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Data reduction is an effective approach to dealing with the I/O bottleneck on large high-performance computing (HPC) systems. Prior research has mostly focused on improving reduction ratio and throughput, and there is a lack of understanding in the usage of various reduction techniques.</p>\n<p>This project addresses a number of critical gaps and challenges in data reduction for HPC from three aspects: 1) The impact of reduction error on scientific discovery is studied via two concrete case studies. 2) Analytical models are developed to estimate the reduction performance without forcing users to compress the full data. 3) The estimation capability is utilized and more efficient data analysis and reduction capabilities are provided for exascale systems.</p>\n<p>&nbsp;</p>\n<p>This project has a significant broader impact enabling data reduction to be an integral part of exascale science production. &nbsp;It also has significant institutional and community impact and helps promote research in data management systems at both Temple and NJIT, two diverse universities in the nation.</p>\n<p>&nbsp;</p>\n<p>Specifically, two Ph.D. students including one female student and one undergraduate student actively participated in this project to develop algorithms, shape the design, and evaluate different data reduction techniques and models for exascale systems. Together they published high-quality papers at prestigious venues such as ICPP, NAS, IEEE Transactions on Big Data, and IEEE Transactions on Parallel and Distributed Systems (TPDS) to report their research findings. One Ph.D. student supported via this project successfully defended the dissertation and joined the workforce in the field to contribute to our society.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/28/2022<br>\n\t\t\t\t\tModified by: Xubin&nbsp;He</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nData reduction is an effective approach to dealing with the I/O bottleneck on large high-performance computing (HPC) systems. Prior research has mostly focused on improving reduction ratio and throughput, and there is a lack of understanding in the usage of various reduction techniques.\n\nThis project addresses a number of critical gaps and challenges in data reduction for HPC from three aspects: 1) The impact of reduction error on scientific discovery is studied via two concrete case studies. 2) Analytical models are developed to estimate the reduction performance without forcing users to compress the full data. 3) The estimation capability is utilized and more efficient data analysis and reduction capabilities are provided for exascale systems.\n\n \n\nThis project has a significant broader impact enabling data reduction to be an integral part of exascale science production.  It also has significant institutional and community impact and helps promote research in data management systems at both Temple and NJIT, two diverse universities in the nation.\n\n \n\nSpecifically, two Ph.D. students including one female student and one undergraduate student actively participated in this project to develop algorithms, shape the design, and evaluate different data reduction techniques and models for exascale systems. Together they published high-quality papers at prestigious venues such as ICPP, NAS, IEEE Transactions on Big Data, and IEEE Transactions on Parallel and Distributed Systems (TPDS) to report their research findings. One Ph.D. student supported via this project successfully defended the dissertation and joined the workforce in the field to contribute to our society.\n\n\t\t\t\t\tLast Modified: 11/28/2022\n\n\t\t\t\t\tSubmitted by: Xubin He"
 }
}