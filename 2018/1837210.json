{
 "awd_id": "1837210",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: TTP Option: Medium: Collaborative Research: Smoothing Traffic via Energy-efficient Autonomous Driving (STEAD)",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "David Corman",
 "awd_eff_date": "2019-01-01",
 "awd_exp_date": "2021-12-31",
 "tot_intn_awd_amt": 229999.0,
 "awd_amount": 229999.0,
 "awd_min_amd_letter_date": "2018-09-13",
 "awd_max_amd_letter_date": "2018-09-13",
 "awd_abstract_narration": "Studies show five of the top 10 most-gridlocked cities in the world are in the United States. Traffic congestion puts undue burden on transportation systems across the United States, raising transportation costs and the energy footprint. Vehicle automation creates an opportunity to reduce traffic and improve efficiency of the transportation infrastructure. In particular, this project aims to reduce the energy footprint of phantom traffic jams, where dense traffic comes to a halt for no apparent reason, and also stop-and-go-waves in congestion. The research team aims to reduce the overall energy footprint of stop-and-go congestion by up to 40% via a small portion of connected and autonomous vehicles (CAVs) inserted into normal traffic with drivers, also known as manned traffic. The work will build models of mixed autonomy (a combination of CAVs and manned traffic), and test the ability for this portion of CAVs to smooth the flow of traffic in a controlled manner, and thus reduce the energy footprint. The research combines mathematics, control theory, machine learning, and transportation engineering. The project includes four universities and engages industry and government partners. The project will also engage students and community stakeholders, including State and Federal transportation agencies and CAV manufacturers.\r\n\r\nSpecifically, the technical contributions enabling traffic smoothing and reduction in the environmental footprint include new mean-field optimal control formulations for sparse control settings where only a subset of vehicles are CAVs and can be controlled. Investigators will develop data-driven control algorithms based on deep reinforcement learning designed to enable control in settings where analytical approaches to derive explicit controllers are too complex (e.g., due to multi-lane, ramps, and high variation of human driving styles). They will also develop tools based on Satisfiability Modulo Convex optimization to enable safety and robustness of these controllers. The approach will first be validated using microsimulation tools to assess their efficiency and their validity. Once validated in simulation, the project will then field test the algorithm with manned vehicles following real-time control commands of the system, executed by 100 human drivers following control signals communicated via a phone app with target speeds and lanes. After which, the system will be tested with up to 20 CAVs inserted onto a freeway stretch in the Transition to Practice component of the project.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "George",
   "pi_last_name": "Pappas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "George Pappas",
   "pi_email_addr": "pappasg@seas.upenn.edu",
   "nsf_id": "000156545",
   "pi_start_date": "2018-09-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of the University of Pennsylvania",
  "perf_str_addr": "3451 Walnut Street; 5th fl",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "033Y00",
   "pgm_ele_name": "S&CC: Smart & Connected Commun"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "042Z",
   "pgm_ref_txt": "S&CC: Smart and Connected Communities"
  },
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 229999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Deep learning has revolutionized computer vision, natural lanaguage processing, among other fields.&nbsp; This has encouraged researchers to use deep learning and deep reinforcement learning in safety-critical domains, such as autonomous systems. In order for such methods to be adopted, we need to develop methods that imporove the robustness of deep learning as well as methods that verify the safety of&nbsp; autonomoous systems with deep learning controllers.</p>\n<p><span>The specific scientific objectives of this part of the project are two fold.&nbsp; First, we would like to verity and analyze the safety and robustness properties of neural networks in isolation as stand alone systems.&nbsp; Second, we woul like to verify the safety of autonomous systems with neural network controllers (for example deep reinforcement learning controllers).</span></p>\n<p>Certifying the safety or robustness of neural networks against input uncertainties and adversarial attacks is an emerging challenge in the area of safe machine learning. To provide such guarantees, one must be able to bound the output of neural networks when their input changes within a bounded set. In this project, we proposed a semidefinite programming (SDP) framework to address this problem for feed-forward neural networks with general activation functions and input uncertainty sets. Our main approach in this effort is to analyze the safety properties of deep networks using semi-definite programming. Our approach allows us to reason about various properties of neural networks (safety, robustness, generalization, stability in closed-loop settings, etc.) via semidefinite programming.</p>\n<p>One major success of our approach is to compute the Lipschitz constant for deep neural networks (DNNs).&nbsp; This is useful in many applications ranging from robustness certification of classifiers to stability analysis of closed-loop systems with reinforcement learning controllers.&nbsp; In another application, w<span>e illustrated our method in a quadrotor example, in which we first approximate a nonlinear model predictive controller via a deep neural network and then apply our safety analysis tool to certify finite-time reachability and safety satisfaction of the autonomous system.</span></p>\n<p>The impact of our project is multi-fold.&nbsp; First, the publications of this project have hd immediate impact in the scientific community as witnessed by the very large number of citations of our work.&nbsp; Second, two of the primary students and postdocs that worked on this project are now faculty at Rensselaer and Johns Hopkins University.&nbsp; Finally all approaches in this project have resulted in open source software which can be accessed by the community from GitHub in order to assess the safety of neural networks in autonomous systems.&nbsp;&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/10/2022<br>\n\t\t\t\t\tModified by: George&nbsp;J&nbsp;Pappas</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDeep learning has revolutionized computer vision, natural lanaguage processing, among other fields.  This has encouraged researchers to use deep learning and deep reinforcement learning in safety-critical domains, such as autonomous systems. In order for such methods to be adopted, we need to develop methods that imporove the robustness of deep learning as well as methods that verify the safety of  autonomoous systems with deep learning controllers.\n\nThe specific scientific objectives of this part of the project are two fold.  First, we would like to verity and analyze the safety and robustness properties of neural networks in isolation as stand alone systems.  Second, we woul like to verify the safety of autonomous systems with neural network controllers (for example deep reinforcement learning controllers).\n\nCertifying the safety or robustness of neural networks against input uncertainties and adversarial attacks is an emerging challenge in the area of safe machine learning. To provide such guarantees, one must be able to bound the output of neural networks when their input changes within a bounded set. In this project, we proposed a semidefinite programming (SDP) framework to address this problem for feed-forward neural networks with general activation functions and input uncertainty sets. Our main approach in this effort is to analyze the safety properties of deep networks using semi-definite programming. Our approach allows us to reason about various properties of neural networks (safety, robustness, generalization, stability in closed-loop settings, etc.) via semidefinite programming.\n\nOne major success of our approach is to compute the Lipschitz constant for deep neural networks (DNNs).  This is useful in many applications ranging from robustness certification of classifiers to stability analysis of closed-loop systems with reinforcement learning controllers.  In another application, we illustrated our method in a quadrotor example, in which we first approximate a nonlinear model predictive controller via a deep neural network and then apply our safety analysis tool to certify finite-time reachability and safety satisfaction of the autonomous system.\n\nThe impact of our project is multi-fold.  First, the publications of this project have hd immediate impact in the scientific community as witnessed by the very large number of citations of our work.  Second, two of the primary students and postdocs that worked on this project are now faculty at Rensselaer and Johns Hopkins University.  Finally all approaches in this project have resulted in open source software which can be accessed by the community from GitHub in order to assess the safety of neural networks in autonomous systems.  \n\n\t\t\t\t\tLast Modified: 06/10/2022\n\n\t\t\t\t\tSubmitted by: George J Pappas"
 }
}