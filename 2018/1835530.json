{
 "awd_id": "1835530",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Framework: Software: HDR: Building the Twenty-First Century Citizen Science Framework to Enable Scientific Discovery Across Disciplines",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032928104",
 "po_email": "shabagch@nsf.gov",
 "po_sign_block_name": "Sharmistha Bagchi-Sen",
 "awd_eff_date": "2019-01-01",
 "awd_exp_date": "2023-12-31",
 "tot_intn_awd_amt": 945792.0,
 "awd_amount": 1134850.0,
 "awd_min_amd_letter_date": "2018-08-27",
 "awd_max_amd_letter_date": "2020-06-17",
 "awd_abstract_narration": "A team of experts from five institutions (University of Minnesota, Adler Planetarium, University of Wyoming, Colorado State University, and UC San Diego) links field-based and online analysis capabilities to support citizen science, focusing on three research areas (cell biology, ecology, and astronomy).  The project builds on Zooniverse and CitSci.org, leverages the NSF Science Gateways Community Institute, and enhances the quality of citizen science and the experience of its participants.\r\n\r\nThis project creates an integrated Citizen Science Cyberinfrastructure (CSCI) framework that expands the capacity of research communities across several disciplines to use citizen science as a suitable and sustainable research methodology.  CSCI produces three improvements to the infrastructure for citizen science already provided by Zooniverse and CitSci.org: \r\n - Combining Modes - connecting the process of data collection and analysis; \r\n - Smart Assignment - improving the assignment of tasks during analysis; and \r\n - New Data Models - exploring the Data-as-Subject model.  By treating time series data as data, this model removes the need to create images for classification and facilitates more complex workflows.  These improvements are motivated and investigated through three distinct scientific cases:\r\n - Biomedicine (3D Morphology of Cell Nucleus).  Currently, Zooniverse 'Etch-a-Cell' volunteers provide annotations of cellular components in images from high-resolution microscopy, where a single cell provides a stack containing thousands of sliced images.  The Smart Task Assignment capability incorporates this information, so volunteers are not shown each image in a stack where machines or other volunteers have already evaluated some subset of data.\r\n - Ecology (Identifying Individual Animals).  When monitoring wide-ranging wildlife populations, identification of individual animals is needed for robust estimates of population sizes and trends.  This use case combines field collection and data analysis with deep learning to improve results.\r\n - Astronomy (Characterizing Lightcurves).  Astronomical time series data reveal a variety of behaviors, such as stellar flares or planetary transits.  The existing Zooniverse data model requires classification of individual images before aggregation of results and transformation back to refer to the original data.  By using the Data-as-Subject model and the Smart Task Assignment capability, volunteers will be able to scan through the entire time series in a machine-aided manner to determine specific light curve characteristics.\r\n\r\nThe team explores the use of recurrent neural networks (RNNs) to determine automated learning architectures best suited to the projects.  Of particular interest is how the degree to which neighboring subjects are coupled affects performance. The integration of existing tools, which is based on application programming interfaces (APIs), also facilitates further tool integration.  The effort creates a citizen science framework that directly advances knowledge for three science use cases in biomedicine, ecology, and astronomy, and combines field-collected data with data analysis. This has the ability to solve key problems in the individual applications, as well as benefiting the research of the dozens of projects on the Zooniverse platform. It provides benefits to researchers using citizen scientists, and to the nearly 1.6 million citizen scientists themselves.\r\n\r\nThis award by the Office of Advanced Cyberinfrastructure is jointly supported by the Division of Research on Learning in Formal and Informal Settings, within the NSF Directorate for Education and Human Resources.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lucy",
   "pi_last_name": "Fortson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lucy Fortson",
   "pi_email_addr": "fortson@physics.umn.edu",
   "nsf_id": "000079170",
   "pi_start_date": "2018-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Craig",
   "pi_last_name": "Packer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Craig Packer",
   "pi_email_addr": "packer@umn.edu",
   "nsf_id": "000376315",
   "pi_start_date": "2018-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Lintott",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher Lintott",
   "pi_email_addr": "chris.lintott@physics.ox.ac.uk",
   "nsf_id": "000520905",
   "pi_start_date": "2018-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Boley",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel L Boley",
   "pi_email_addr": "boley@umn.edu",
   "nsf_id": "000667335",
   "pi_start_date": "2018-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "University of Minnesota-Twin Cities",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "554552070",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MN05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725900",
   "pgm_ele_name": "AISL"
  },
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "077Z",
   "pgm_ref_txt": "CSSI-1: Cyberinfr for Sustained Scientif"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 945792.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 189058.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"> </strong></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"><span style=\"font-size: 12pt;\">Overview:</span><span style=\"font-size: 12pt;\">&nbsp;</span></strong></p>\n<p><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"> </strong><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"> </strong></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"><span style=\"font-size: 12pt;\">Citizen science, when coupled with sophisticated cyberinfrastructure, has emerged as a powerful research approach to leverage the data revolution for innovative scientific inquiry. Our project aimed to advance this frontier by developing a more cohesive Citizen Science Cyberinfrastructure (CSCI) framework. Through collaborative efforts, we focused on three key areas: (1) connective infrastructure between citizen science platforms, (2) smart task assignment for humans and machines, and (3) presenting data-as-subject to participants. We carried out this effort within Zooniverse, the world&rsquo;s largest citizen science platform, with 2.7 million participants and over 80 live projects across the disciplines. We aimed to expand the capacity of research communities to utilize citizen science as a sustainable and effective research methodology.</span></strong></p>\n<p><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"> </strong><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\">\n<p style=\"line-height: 1.38; background-color: #ffffff; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; background-color: #ffffff; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">We structured our work around three disciplinary areas: Bioimage Analysis, Ecology and Astronomy; each illustrating the potential of citizen science enabled by novel cyberinfrastructure developments to impact critical research agendas hampered by large amounts of complex data.</span></p>\n<p style=\"line-height: 1.38; background-color: #ffffff; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Cyberinfrastructure Development:</span></p>\n<p style=\"line-height: 1.38; background-color: #ffffff; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;<span style=\"font-size: 12pt;\">Throughout the project, we achieved significant milestones in cyberinfrastructure development:</span></p>\n<ul style=\"margin-top: 0px; margin-bottom: 0px; padding-inline-start: 48px;\">\n<li style=\"list-style-type: disc; font-size: 12pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Connecting Cyberinfrastructure: Fostering collaboration, data reuse and data exchange, we established seamless integration between Zooniverse and other citizen science platforms including the data collection platforms CitSci.org and iNaturalist.org, as well as integrating Zooniverse project initiation with large astronomical facilities such as the Vera Rubin Legacy Survey of Space and Time.&nbsp;</span> </li>\n<li style=\"list-style-type: disc; font-size: 12pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Machine Learning Integration: To empower ecology research teams lacking machine learning expertise, we developed the Subject Assistant, facilitating automated inference and data selection. In addition, we developed the `Zoobot&rsquo; functionality enabling active learning where aggregated classifications are used to update a machine model which then posts the next best set of images to be classified by volunteers.</span> </li>\n<li style=\"list-style-type: disc; font-size: 12pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Smart Task Assignment: We enhanced volunteer engagement and project efficiency by implementing functionalities such as Correct-a-Machine, where volunteers correct machine predictions, and dynamic workflow allocation, where images or volunteers can be assigned to specific workflows based on volunteer annotations.</span> </li>\n<li style=\"list-style-type: disc; font-size: 12pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Data-as-Subject: By building an innovative tool that expands the options for data presentation, annotators are no longer constrained to working with static images of data but can interact directly with multiple data modalities thereby facilitating accelerated image processing and analysis.</span> </li>\n</ul>\n<br />\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Community Engagement:&nbsp;</span></p>\n</strong><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">We actively engaged with the research community using the citizen science methodology through surveys, workshops, meetings, and collaborative initiatives, fostering knowledge exchange and capacity building. Sustainability and data reuse are fostered through accessible documentation of cyberinfrastructure and encouraging project teams to use repositories such as LILA-BC (facilitated through this grant) which stores </span><span style=\"font-size: 12pt;\">label/image pairs generated from citizen science and other crowdsourcing platforms.</span></p>\n</strong><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"> <br />\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Project Impact:&nbsp;</span></p>\n</strong><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">By the end of the grant, nearly 300 unique projects with close to 1000 workflows used the cyberinfrastructure developed and supported by this grant to accelerate data analysis across a range of disciplines. The full collaboration provided cross-disciplinary training opportunities between nine software engineers, five post-doctoral scholars, at least 15 graduate students, and four undergraduates on data science, and machine learning applied across disciplines.</span></p>\n</strong><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"> <br />\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Our project facilitated transformative research outcomes across our three science drivers:</span></p>\n<ul style=\"margin-top: 0px; margin-bottom: 0px; padding-inline-start: 48px;\">\n<li style=\"list-style-type: disc; font-size: 12pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Biomedical Image Analysis: Our efforts in this domain streamlined the analysis of 3D cell nucleus morphology by integrating Smart Task Assignment cyberinfrastructure, reducing the burden on volunteers while maximizing efficiency. Integration of machine learning with crowdsourced image analysis showcased promising results, advancing our understanding of cellular structures and functions [see Figure 1].</span> </li>\n<li style=\"list-style-type: disc; font-size: 12pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Ecology:</span><span style=\"font-size: 12pt;\"> </span><span style=\"font-size: 12pt;\">Building cyberinfrastructure to streamline citizen science data collection, machine learning inference and analysis across ecosystems, we facilitated wildlife monitoring and individual animal identification [see Figure 2], contributing to effective conservation efforts across diverse ecosystems. Results include a global-scale study of 9 million images from 20,000 camera trap sites showing that most mammal species exhibit impermanent shifts in their daily habits relative to human activity.</span> </li>\n<li style=\"list-style-type: disc; font-size: 12pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Astronomy: We enhanced the Zooniverse platform to treat data as subjects, empowering volunteers to contribute to complex astronomical analyses with greater ease and accuracy. Results include the discovery by members of the public of many exoplanets through inspection of lightcurves from NASA&rsquo;s Transiting Exoplanet Survey Satellite [see Figure 3]. In addition, using 92 million annotations from the Galaxy Zoo project, our Zoobot infrastructure enabled the production of the largest galaxy morphology foundation model, now integrated into upcoming surveys such as Euclid and LSST.</span> </li>\n</ul>\n<br />\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Zooniverse was one of five awardees in the White House Office of Science and Technology Policy (OSTP) `Champion of Open Science Challenge 2023&rsquo;, filling the category of `Open Science to Advance Innovation&rsquo;. Zooniverse innovations in leveraging public participation in scientific research and driving discovery is a direct result of support and encouragement from the National Science Foundation over the years, including through this grant-funded effort.&nbsp;</span></p>\n<br />\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">Conclusion:&nbsp;</span></p>\n</strong><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt;\">This project exemplifies the transformative potential of citizen science cyberinfrastructure in enabling collaborative research and addressing complex scientific challenges. By empowering volunteers and researchers alike, we have laid the groundwork for a more inclusive and impactful scientific enterprise.</span></p>\n</strong><strong id=\"docs-internal-guid-aef5689c-7fff-cb33-6247-7ccba9d4862f\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"> </strong></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 04/30/2024<br>\nModified by: Lucy&nbsp;Fortson</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1835530/1835530_10576618_1714474347703_Figure2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1835530/1835530_10576618_1714474347703_Figure2--rgov-800width.png\" title=\"Figure 2\"><img src=\"/por/images/Reports/POR/2024/1835530/1835530_10576618_1714474347703_Figure2--rgov-66x44.png\" alt=\"Figure 2\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Volunteers draw the outlines of an elephant ear in the Elephant ID project, helping researchers re-identify elephants in the Magkadigkadi Pans National Park (MPMP) in Botswana. The ear contours are the most unique signature of individual elephants.</div>\n<div class=\"imageCredit\">https://www.zooniverse.org/projects/aeuk/elephant-id/about/research</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Lucy&nbsp;Fortson\n<div class=\"imageTitle\">Figure 2</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1835530/1835530_10576618_1714474129122_Figure1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1835530/1835530_10576618_1714474129122_Figure1--rgov-800width.png\" title=\"Figure 1\"><img src=\"/por/images/Reports/POR/2024/1835530/1835530_10576618_1714474129122_Figure1--rgov-66x44.png\" alt=\"Figure 1\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 1: Using volunteer annotations of the 2D image slices from the Etch-a-cell - Fat Checker project, we trained a novel 3D deep learning model to successfully predict the 3D fat droplet structures within volumetric microscopy datasets of liver tissue. From: https://blog.zooniverse.org/2023/12/05</div>\n<div class=\"imageCredit\">https://blog.zooniverse.org/2023/12/05/etch-a-cell-fat-checker-project-update/</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Lucy&nbsp;Fortson\n<div class=\"imageTitle\">Figure 1</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1835530/1835530_10576618_1714474482782_Figure3--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1835530/1835530_10576618_1714474482782_Figure3--rgov-800width.png\" title=\"Figure 3\"><img src=\"/por/images/Reports/POR/2024/1835530/1835530_10576618_1714474482782_Figure3--rgov-66x44.png\" alt=\"Figure 3\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Screen capture of the Zooniverse Talk post on the Planet Hunters TESS project showing the discovery lightcurve using data-as-subject and the ensuing publication of the two exoplanets discovered by volunteers. Note volunteers participating in the discovery are co-authors on the peer-reviewed paper.</div>\n<div class=\"imageCredit\">https://www.zooniverse.org/projects/nora-dot-eisner/planet-hunters-tess/talk/subjects/48214829</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Lucy&nbsp;Fortson\n<div class=\"imageTitle\">Figure 3</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nOverview:\n\n\n  \n\n\nCitizen science, when coupled with sophisticated cyberinfrastructure, has emerged as a powerful research approach to leverage the data revolution for innovative scientific inquiry. Our project aimed to advance this frontier by developing a more cohesive Citizen Science Cyberinfrastructure (CSCI) framework. Through collaborative efforts, we focused on three key areas: (1) connective infrastructure between citizen science platforms, (2) smart task assignment for humans and machines, and (3) presenting data-as-subject to participants. We carried out this effort within Zooniverse, the worlds largest citizen science platform, with 2.7 million participants and over 80 live projects across the disciplines. We aimed to expand the capacity of research communities to utilize citizen science as a sustainable and effective research methodology.\n\n\n \n\n\n\n\n\nWe structured our work around three disciplinary areas: Bioimage Analysis, Ecology and Astronomy; each illustrating the potential of citizen science enabled by novel cyberinfrastructure developments to impact critical research agendas hampered by large amounts of complex data.\n\n\n\n\n\nCyberinfrastructure Development:\n\n\nThroughout the project, we achieved significant milestones in cyberinfrastructure development:\n\nConnecting Cyberinfrastructure: Fostering collaboration, data reuse and data exchange, we established seamless integration between Zooniverse and other citizen science platforms including the data collection platforms CitSci.org and iNaturalist.org, as well as integrating Zooniverse project initiation with large astronomical facilities such as the Vera Rubin Legacy Survey of Space and Time. \nMachine Learning Integration: To empower ecology research teams lacking machine learning expertise, we developed the Subject Assistant, facilitating automated inference and data selection. In addition, we developed the `Zoobot functionality enabling active learning where aggregated classifications are used to update a machine model which then posts the next best set of images to be classified by volunteers. \nSmart Task Assignment: We enhanced volunteer engagement and project efficiency by implementing functionalities such as Correct-a-Machine, where volunteers correct machine predictions, and dynamic workflow allocation, where images or volunteers can be assigned to specific workflows based on volunteer annotations. \nData-as-Subject: By building an innovative tool that expands the options for data presentation, annotators are no longer constrained to working with static images of data but can interact directly with multiple data modalities thereby facilitating accelerated image processing and analysis. \n\n\n\n\n\nCommunity Engagement:\n\n\n\nWe actively engaged with the research community using the citizen science methodology through surveys, workshops, meetings, and collaborative initiatives, fostering knowledge exchange and capacity building. Sustainability and data reuse are fostered through accessible documentation of cyberinfrastructure and encouraging project teams to use repositories such as LILA-BC (facilitated through this grant) which stores label/image pairs generated from citizen science and other crowdsourcing platforms.\n \n\n\n\nProject Impact:\n\n\n\nBy the end of the grant, nearly 300 unique projects with close to 1000 workflows used the cyberinfrastructure developed and supported by this grant to accelerate data analysis across a range of disciplines. The full collaboration provided cross-disciplinary training opportunities between nine software engineers, five post-doctoral scholars, at least 15 graduate students, and four undergraduates on data science, and machine learning applied across disciplines.\n \n\n\n\nOur project facilitated transformative research outcomes across our three science drivers:\n\nBiomedical Image Analysis: Our efforts in this domain streamlined the analysis of 3D cell nucleus morphology by integrating Smart Task Assignment cyberinfrastructure, reducing the burden on volunteers while maximizing efficiency. Integration of machine learning with crowdsourced image analysis showcased promising results, advancing our understanding of cellular structures and functions [see Figure 1]. \nEcology: Building cyberinfrastructure to streamline citizen science data collection, machine learning inference and analysis across ecosystems, we facilitated wildlife monitoring and individual animal identification [see Figure 2], contributing to effective conservation efforts across diverse ecosystems. Results include a global-scale study of 9 million images from 20,000 camera trap sites showing that most mammal species exhibit impermanent shifts in their daily habits relative to human activity. \nAstronomy: We enhanced the Zooniverse platform to treat data as subjects, empowering volunteers to contribute to complex astronomical analyses with greater ease and accuracy. Results include the discovery by members of the public of many exoplanets through inspection of lightcurves from NASAs Transiting Exoplanet Survey Satellite [see Figure 3]. In addition, using 92 million annotations from the Galaxy Zoo project, our Zoobot infrastructure enabled the production of the largest galaxy morphology foundation model, now integrated into upcoming surveys such as Euclid and LSST. \n\n\n\n\n\nZooniverse was one of five awardees in the White House Office of Science and Technology Policy (OSTP) `Champion of Open Science Challenge 2023, filling the category of `Open Science to Advance Innovation. Zooniverse innovations in leveraging public participation in scientific research and driving discovery is a direct result of support and encouragement from the National Science Foundation over the years, including through this grant-funded effort.\n\n\n\n\nConclusion:\n\n\n\nThis project exemplifies the transformative potential of citizen science cyberinfrastructure in enabling collaborative research and addressing complex scientific challenges. By empowering volunteers and researchers alike, we have laid the groundwork for a more inclusive and impactful scientific enterprise.\n \n\n\n\n\n\n\t\t\t\t\tLast Modified: 04/30/2024\n\n\t\t\t\t\tSubmitted by: LucyFortson\n"
 }
}