{
 "awd_id": "1750649",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Robotic Manipulation Using Deep Deictic Reinforcement Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2025-08-31",
 "tot_intn_awd_amt": 499904.0,
 "awd_amount": 499904.0,
 "awd_min_amd_letter_date": "2018-03-22",
 "awd_max_amd_letter_date": "2020-07-23",
 "awd_abstract_narration": "As robot tasks and environments become more complex, it is getting too challenging to program every detail of the robot's behavior explicitly, by hand.  An alternate approach is to learn behaviors through experience, a type of machine learning known as ``reinforcement learning'', where the robot learns through trial and error. Pure trial and error, however, is inefficient, which means it takes the robot a long time to learn.  The goal of this project is to enable robots to focus attention on the parts of the environment that lead to effective learning and good generalization to new tasks.  A result of this research is the ability of assistive robots in the home, such as an assistive wheelchair equipped with a robotic arm, to learn how to better help the infirm and people with disabilities.\r\n\r\nThis project will develop a new approach to applying deep reinforcement learning (deep RL) to robotic manipulation problems by incorporating deictic representations. A deictic representation encodes state/action relative to a marker that the agent places in the environment. In this project, the marker is a 6-DOF reference frame, placed in a 3-D point cloud, or truncated signed distance function. The robot decides where to place the marker and how it should move relative to that marker by solving a Markov decision process using deep reinforcement learning. Preliminary results suggest that this new method can enable robots to learn control policies that solve complex manipulation problems without the need for precise geometric models of the objects being manipulated. While the method still estimates some elements of object pose implicitly, it does so in a way that generalizes well to novel objects and does not necessarily estimate full object pose unless required by the task.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Platt",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Robert Platt",
   "pi_email_addr": "r.platt@northeastern.edu",
   "nsf_id": "000601686",
   "pi_start_date": "2018-03-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 93658.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 96268.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 309978.0
  }
 ],
 "por": null
}