{
 "awd_id": "1826757",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CompCog: Advancing Understanding of Visual Crowding",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 689213.0,
 "awd_amount": 689213.0,
 "awd_min_amd_letter_date": "2018-09-06",
 "awd_max_amd_letter_date": "2023-06-01",
 "awd_abstract_narration": "Most of vision is peripheral vision. The central fovea comprises only 1.7 degrees of the visual field, leaving 99.99% of the visual input to fall on the peripheral retina. Peripheral vision differs from central vision in complex and interesting ways, most importantly due to 'crowding', in which identifying a peripheral stimulus can be substantially impaired by the presence of other, nearby stimuli. Crowding is a critical bottleneck in vision; substantial behavioral evidence demonstrates that crowding greatly limits our ability to perform most real-world visual tasks. The research team will pit a dominant class of models, known as pooling models, against a rich corpus of recent experimental work which has seemed to suggest that visual mechanisms might be more complicated and dynamic than previously thought. This work could enable development of improved materials and tools for those with age-related macular degeneration, in which patients lose central vision. It could also aid design of heads-up displays, user interfaces, and information visualizations such as situation maps for military decision-making.\r\n\r\nPooling models posit that crowding arises from averaging of features over large local regions, fixed in size, which grow linearly with distance from the point of fixation. The PI has spent the last decade developing the computational and behavioral methodologies that allow one to derive quantitative, testable predictions from a state-of-the-art pooling model. Using these tools, the PI will examine a definitive set of crowding phenomena that have appeared to challenge a unifying account in terms of a pooling mechanism. She will take a three-pronged approach: 1) using modeling and behavioral experiments to examine the assumptions underlying the model challenges; 2) using behavioral experiments to eliminate possible confounds; and 3) designing new experiments to directly test alternative theories. The expected overall impact is to fundamentally advance mechanistic understanding of a key bottleneck in peripheral processing, and thus in visual processing more generally.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Freeman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "William Freeman",
   "pi_email_addr": "wtf@ai.mit.edu",
   "nsf_id": "000418387",
   "pi_start_date": "2022-10-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Ruth",
   "pi_last_name": "Rosenholtz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ruth Rosenholtz",
   "pi_email_addr": "rruth@mit.edu",
   "nsf_id": "000414614",
   "pi_start_date": "2018-09-06",
   "pi_end_date": "2022-10-12"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ruth",
   "pi_last_name": "Rosenholtz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ruth Rosenholtz",
   "pi_email_addr": "rruth@mit.edu",
   "nsf_id": "000414614",
   "pi_start_date": "2022-10-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Ave",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "139700",
   "pgm_ele_name": "Cross-Directorate  Activities"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 689213.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Peripheral vision -- vision away from where one points one's eyes -- comprises over 99.99% of the visual field. Its strengths and limitations strongly constrain visual perception: what humans can see at a glance, and the processes by which they move their eyes to piece together information about the world. Peripheral vision captures rich information while also being degraded relative to central or foveal vision. Peripheral vision differs from foveal vision in complex and interesting ways, most importantly due to \"crowding,\" in which identifying a peripheral stimulus can be substantially impaired by the presence of other, nearby stimuli or clutter. Dr. Rosenholtz has an existing model of peripheral vision, in which crowding results from pooling or summarizing information over sizeable regions of the visual input.</p>\r\n<p>Two published papers resulting from this award examine empirical challenges to this relatively simple pooling model. A number of behavioral results have been taken to suggest that modeling crowding requires either additional mechanisms, or that the mechanisms flexibly change based on the visual input. Rosenholtz and colleagues use model predictions, other theoretical and computational analyses, and behavioral experiments to demonstrate that the aforementioned behavioral results do not in fact require a more complex model of peripheral vision. (1) The existing model can already explain some of the empirical challenges. This includes \"substitution effects\", in which a person asked for the identity of one of several peripheral objects reports the identity of the wrong one. It also includes a number of \"similarity effects\", in which observers can more readily report features of peripheral objects that are dissimilar to their neighbors. (2) The PI and colleagues show that some empirical challenges may require additional mechanisms, but these are general-purpose decision mechanisms that form a part of any working visual system, rather than mechanisms of peripheral vision, per se. These mechanisms choose and execute a good strategy based on the visual task and available information.&nbsp;</p>\r\n<p>Vision science has only recently come to have a better understanding of visual crowding. A number of older vision experiments, as a result, had confounds due to crowded stimuli. This was particularly true of experiments studying visual attention. Another paper resulting from this award reexamines the phenomenology and mechanisms of attention in light of modern understanding of visual mechanisms, including peripheral crowding. This paper proposes a new theory of visual attention that better captures a number of phenomena: &nbsp;the effectiveness of real-world vision, considerable perception outside the focus of attention (as demonstrated by distraction studies), limits on multitasking, inattentional blindness, and our ability to drive safely most of the time while also being subject to perils of distracted driving.</p>\r\n<p>Similarly, misattributing phenomena to visual attention instead of peripheral vision led to a big puzzle: why do people subjectively experience a rich awareness of the world around them, yet carefully designed experiments demonstrate that people lack awareness of the details? Another paper resulting from this award uses computational modeling to solve much of this puzzle using peripheral vision: The easy tasks are easy for peripheral vision, because substantial information survives to support, for example, rich awareness of a scene and navigate through the environment. The hard tasks are hard for peripheral vision; it loses the information necessary to report, for instance, the details of a particular vehicle in that scene.&nbsp;</p>\r\n<p>Understanding of peripheral vision, with a simple predictive model, has implications for a number of real-world applications. One paper provides information transfer to design of user interfaces and information visualization, and the PI has given numerous presentations to researchers in graphics and computer vision. Another paper examines peripheral vision for walking, driving, and aviation. Finally, three workshop papers provide an early examination of whether computer vision might benefit from adopting some of the same strategies for peripheral vision that human vision employs.</p><br>\n<p>\n Last Modified: 12/23/2024<br>\nModified by: Ruth&nbsp;Rosenholtz</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nPeripheral vision -- vision away from where one points one's eyes -- comprises over 99.99% of the visual field. Its strengths and limitations strongly constrain visual perception: what humans can see at a glance, and the processes by which they move their eyes to piece together information about the world. Peripheral vision captures rich information while also being degraded relative to central or foveal vision. Peripheral vision differs from foveal vision in complex and interesting ways, most importantly due to \"crowding,\" in which identifying a peripheral stimulus can be substantially impaired by the presence of other, nearby stimuli or clutter. Dr. Rosenholtz has an existing model of peripheral vision, in which crowding results from pooling or summarizing information over sizeable regions of the visual input.\r\n\n\nTwo published papers resulting from this award examine empirical challenges to this relatively simple pooling model. A number of behavioral results have been taken to suggest that modeling crowding requires either additional mechanisms, or that the mechanisms flexibly change based on the visual input. Rosenholtz and colleagues use model predictions, other theoretical and computational analyses, and behavioral experiments to demonstrate that the aforementioned behavioral results do not in fact require a more complex model of peripheral vision. (1) The existing model can already explain some of the empirical challenges. This includes \"substitution effects\", in which a person asked for the identity of one of several peripheral objects reports the identity of the wrong one. It also includes a number of \"similarity effects\", in which observers can more readily report features of peripheral objects that are dissimilar to their neighbors. (2) The PI and colleagues show that some empirical challenges may require additional mechanisms, but these are general-purpose decision mechanisms that form a part of any working visual system, rather than mechanisms of peripheral vision, per se. These mechanisms choose and execute a good strategy based on the visual task and available information.\r\n\n\nVision science has only recently come to have a better understanding of visual crowding. A number of older vision experiments, as a result, had confounds due to crowded stimuli. This was particularly true of experiments studying visual attention. Another paper resulting from this award reexamines the phenomenology and mechanisms of attention in light of modern understanding of visual mechanisms, including peripheral crowding. This paper proposes a new theory of visual attention that better captures a number of phenomena: the effectiveness of real-world vision, considerable perception outside the focus of attention (as demonstrated by distraction studies), limits on multitasking, inattentional blindness, and our ability to drive safely most of the time while also being subject to perils of distracted driving.\r\n\n\nSimilarly, misattributing phenomena to visual attention instead of peripheral vision led to a big puzzle: why do people subjectively experience a rich awareness of the world around them, yet carefully designed experiments demonstrate that people lack awareness of the details? Another paper resulting from this award uses computational modeling to solve much of this puzzle using peripheral vision: The easy tasks are easy for peripheral vision, because substantial information survives to support, for example, rich awareness of a scene and navigate through the environment. The hard tasks are hard for peripheral vision; it loses the information necessary to report, for instance, the details of a particular vehicle in that scene.\r\n\n\nUnderstanding of peripheral vision, with a simple predictive model, has implications for a number of real-world applications. One paper provides information transfer to design of user interfaces and information visualization, and the PI has given numerous presentations to researchers in graphics and computer vision. Another paper examines peripheral vision for walking, driving, and aviation. Finally, three workshop papers provide an early examination of whether computer vision might benefit from adopting some of the same strategies for peripheral vision that human vision employs.\t\t\t\t\tLast Modified: 12/23/2024\n\n\t\t\t\t\tSubmitted by: RuthRosenholtz\n"
 }
}