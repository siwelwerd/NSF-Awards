{
 "awd_id": "1815514",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Establishing Action Laws for Touch Interaction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 315478.0,
 "awd_amount": 315478.0,
 "awd_min_amd_letter_date": "2018-08-08",
 "awd_max_amd_letter_date": "2018-08-08",
 "awd_abstract_narration": "Theoretical action laws and quantitative models are foundational to any field. In human-computer interaction and ergonomics, Fitts' law is one of the theoretical foundations for interface and input device development and research.  It has served as a theoretical framework for evaluating input devices, a tool for computational interface design, and a logical basis for modeling more complex HCI tasks.  However, ample empirical evidence has shown that Fitts' law and other existing action laws encounter problems, or even fail, when modeling touch interaction, primarily because they do not account for the imprecision of finger touch in interaction. This research will establish robust new action laws for touch interaction, including both pointing and trajectory-based gesturing (steering), which will guide the design and evaluation of touch interfaces and serve as cornerstones for modeling complex tasks, computational interface design and optimization. Given the ubiquitous adoption of mobile devices where touch input is dominant, project outcomes are expected to have broad impact that will reach millions of users.  To demonstrate the practical value and effectiveness of the new touch action laws, they will be used to quantify the touch capacity of older adults, thereby laying the foundation for designing touch interfaces well-suited for that user community.\r\n\r\nThe starting point for this research will be the principal investigator's Finger-Fitts (FFitts) law derived from the Dual Gaussian Distribution Model and Fitts' law.  This preliminary work will be expanded to model 2D target selection and gesturing tasks.  The research will be carried out following standard practices in Human Computer Interaction (HCI), first deriving candidate models from existing models, hypotheses, and rational assumptions, and then conducting rigorous user studies to evaluate the new models. The experimental results will in turn be used to refine the new models, which again will be evaluated via studies. Project outcomes will include the following theoretical and empirical intellectual contributions: action laws for touch pointing, including both the task form of the FFitts law which will predict touch pointing time with nominal task parameters (i.e., finger travel distance A and target width W), and the bivariate FFitts law which will model 2D pointing tasks on rectangular targets such as buttons, check boxes and hyperlinks; action laws for trajectory gestures (Finger-Steering laws), including a basic form for steering along straight paths and a generic form for other paths; and a touch action law based understanding of older adults' touch interaction capacity.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiaojun",
   "pi_last_name": "Bi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaojun Bi",
   "pi_email_addr": "xiaojun@cs.stonybrook.edu",
   "nsf_id": "000738012",
   "pi_start_date": "2018-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "",
  "perf_city_name": "Stony Brook",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117944400",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 315478.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-415a781b-7fff-002a-ab72-f58c68df5e99\"> </span></p>\n<p dir=\"ltr\"><span>Finger touch input is now the predominant input modality on mobile computer devices such as smartphones and tablets. This project aimed to provide theoretical understanding (a.k.a action laws) of the regularities behind finger touch input, and apply the understanding to improve touchscreen interface design and interaction experience. Our research has led to the following outcomes, including new models and action laws for touch input, and their applications in improving touchscreen interaction.</span></p>\n<ol>\n<li>2D Finger Touch Fitts' law [4]. We have created the 2D Finger-Fitts law which relates the finger movement time to the size of the target and the travel distance of the input finger. Our experiment has shown that this new model outperforms the existing movement model such as Fitts' law for finger touch input. The work was published in a premier HCI conference, ACM UIST 2022, and won a Best Paper Honorable Mention award [4]. The model could serve as the cornerstone for touchscreen interface design, optimization, and evaluation, as it could predict the efficiency of interaction without running studies.&nbsp;</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Rotational Dual Gaussian Model [2]: A Model for Touch Point Distribution. We have created a model that predicts the distribution of touchpoints, taking into account the finger movement direction. This model is an improvement over the original Dual Gaussian model which leverages no information about the movement direction. The new model is more accurate than the original dual Gaussian model in predicting the touch point distribution. Our experiments showed that the Rotational Dual Gaussian model can improve the accuracy of touchscreen keyboard decoder, which is the core component for auto-correction and auto-completion of a touchscreen keyboard.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>A Mixture Model for Blind Users [3]. We have also created a new model that can predict the touch pointing performance of blind users who rely on screen readers to select targets on touch screens. </span><span>&nbsp;We discovered that the gliding trajectories of blind people are a mixture of two strategies: 1) ballistic movements with iterative corrections relying on non-visual feedback, and 2) multiple sub-movements separated by stops, and concatenated until the target is reached. Based on this finding, we propose the mixture pointing model, a model that relates movement time to distance and width of the target. The mixture model created based on this finding substantially improves the prediction accuracy of touchscreen target selection for blind users, over the traditional Fitts' law.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Improving touch-based selection accuracy with touch models [1]. We proposed a Suggestion-based Accurate Target Selection method, where target selection is formulated as a sequential decision problem. We then used Reinforcement Learning to train a policy that has the highest interaction efficiency. The proposed touch point distribution model serves as the generative model to simulate touch interaction, which is critical for the success of the method.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>This project has supported 5 Ph.D. students and 6 high school students. The Ph.D. students carried out research to create and evaluate models for touch pointing, and apply the created models to improve interaction experience. High school students worked mostly in summers in the past four years with these Ph.D. students, to gain experience of carrying out research.&nbsp;</span></p>\n</li>\n</ol>\n<p dir=\"ltr\"><span>[1] Zhi Li, Maozheng Zhao, Dibyendu Das, Hang Zhao, Yan Ma, Wanyu Liu, Michel Beaudouin-Lafon, Fusheng Wang, IV Ramakrishnan Xiaojun Bi (2022) \"Select or Suggest? Reinforcement Learning-based Method for High-Accuracy Target Selection on Touchscreens\". In Proceedings of CHI 2022 - the SIGCHI Conference on Human Factors in Computing Systems. Article No.: 494. Pages 1 - 15.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>[2] Yan Ma, Shumin Zhai, IV Ramakrishnan, Xiaojun Bi (2021) \"Modeling Touch Point Distribution with Rotational Dual Gaussian Model\". In Proceedings of UIST 2021 - The ACM Symposium on User Interface Software and Technology. pp 1197 - 1209.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>[3] Yu-Jung Ko, Aini Putkonen, Ali Selman Aydin, Shirin Feiz, Yuheng Wang, Vikas Ashok, IV Ramakrishnan, Antti Oulasvirta, Xiaojun Bi (2021) \"Modeling Gliding-based Target Selection for Blind Touchscreen Users\". In Proceedings of MobileHCI 2021- The ACM Conference on Human computer interaction with Mobile Devices and Services Article No. 29 pp 1- 14.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>[4] Yu-Jung Ko, Hang Zhao, Yoonsang Kim, IV Ramakrishnan, Shumin Zhai, Xiaojun Bi (2020) \"Modeling Two Dimensional Touch Pointing\". In Proceedings of UIST 2020 - The ACM Symposium on User Interface Software and Technology. Pages 858-868</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/23/2022<br>\n\t\t\t\t\tModified by: Xiaojun&nbsp;Bi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nFinger touch input is now the predominant input modality on mobile computer devices such as smartphones and tablets. This project aimed to provide theoretical understanding (a.k.a action laws) of the regularities behind finger touch input, and apply the understanding to improve touchscreen interface design and interaction experience. Our research has led to the following outcomes, including new models and action laws for touch input, and their applications in improving touchscreen interaction.\n\n2D Finger Touch Fitts' law [4]. We have created the 2D Finger-Fitts law which relates the finger movement time to the size of the target and the travel distance of the input finger. Our experiment has shown that this new model outperforms the existing movement model such as Fitts' law for finger touch input. The work was published in a premier HCI conference, ACM UIST 2022, and won a Best Paper Honorable Mention award [4]. The model could serve as the cornerstone for touchscreen interface design, optimization, and evaluation, as it could predict the efficiency of interaction without running studies. \n\nRotational Dual Gaussian Model [2]: A Model for Touch Point Distribution. We have created a model that predicts the distribution of touchpoints, taking into account the finger movement direction. This model is an improvement over the original Dual Gaussian model which leverages no information about the movement direction. The new model is more accurate than the original dual Gaussian model in predicting the touch point distribution. Our experiments showed that the Rotational Dual Gaussian model can improve the accuracy of touchscreen keyboard decoder, which is the core component for auto-correction and auto-completion of a touchscreen keyboard.\n\n\nA Mixture Model for Blind Users [3]. We have also created a new model that can predict the touch pointing performance of blind users who rely on screen readers to select targets on touch screens.  We discovered that the gliding trajectories of blind people are a mixture of two strategies: 1) ballistic movements with iterative corrections relying on non-visual feedback, and 2) multiple sub-movements separated by stops, and concatenated until the target is reached. Based on this finding, we propose the mixture pointing model, a model that relates movement time to distance and width of the target. The mixture model created based on this finding substantially improves the prediction accuracy of touchscreen target selection for blind users, over the traditional Fitts' law.\n\n\nImproving touch-based selection accuracy with touch models [1]. We proposed a Suggestion-based Accurate Target Selection method, where target selection is formulated as a sequential decision problem. We then used Reinforcement Learning to train a policy that has the highest interaction efficiency. The proposed touch point distribution model serves as the generative model to simulate touch interaction, which is critical for the success of the method.\n\n\nThis project has supported 5 Ph.D. students and 6 high school students. The Ph.D. students carried out research to create and evaluate models for touch pointing, and apply the created models to improve interaction experience. High school students worked mostly in summers in the past four years with these Ph.D. students, to gain experience of carrying out research. \n\n\n[1] Zhi Li, Maozheng Zhao, Dibyendu Das, Hang Zhao, Yan Ma, Wanyu Liu, Michel Beaudouin-Lafon, Fusheng Wang, IV Ramakrishnan Xiaojun Bi (2022) \"Select or Suggest? Reinforcement Learning-based Method for High-Accuracy Target Selection on Touchscreens\". In Proceedings of CHI 2022 - the SIGCHI Conference on Human Factors in Computing Systems. Article No.: 494. Pages 1 - 15.\n\n \n[2] Yan Ma, Shumin Zhai, IV Ramakrishnan, Xiaojun Bi (2021) \"Modeling Touch Point Distribution with Rotational Dual Gaussian Model\". In Proceedings of UIST 2021 - The ACM Symposium on User Interface Software and Technology. pp 1197 - 1209.\n\n \n[3] Yu-Jung Ko, Aini Putkonen, Ali Selman Aydin, Shirin Feiz, Yuheng Wang, Vikas Ashok, IV Ramakrishnan, Antti Oulasvirta, Xiaojun Bi (2021) \"Modeling Gliding-based Target Selection for Blind Touchscreen Users\". In Proceedings of MobileHCI 2021- The ACM Conference on Human computer interaction with Mobile Devices and Services Article No. 29 pp 1- 14.\n\n \n[4] Yu-Jung Ko, Hang Zhao, Yoonsang Kim, IV Ramakrishnan, Shumin Zhai, Xiaojun Bi (2020) \"Modeling Two Dimensional Touch Pointing\". In Proceedings of UIST 2020 - The ACM Symposium on User Interface Software and Technology. Pages 858-868\n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 08/23/2022\n\n\t\t\t\t\tSubmitted by: Xiaojun Bi"
 }
}