{
 "awd_id": "1837931",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: F: Computationally Efficient Algorithms for Large-Scale Crossed Random Effects Models",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 800000.0,
 "awd_amount": 800000.0,
 "awd_min_amd_letter_date": "2018-09-06",
 "awd_max_amd_letter_date": "2018-09-06",
 "awd_abstract_narration": "The problems of deciding what to buy, where to eat, which movie to watch, and so forth are of enormous economic value to consumers, sellers, and the people employed making those goods and services. Companies try to match people and products using vast data sets recording purchases and opinions. Even with a large data set it is a challenge to get reliable results. Measurements on the same or similar products are correlated, as are measurements by the same or similar people; however, correlated data yield less information than uncorrelated data.  Properly accounting for the correlation requires too much computation, even on modern large computers, because the amount of computation grows as a power of the size of the data.  Ignoring those correlations will produce an analysis that becomes overconfident and findings that are not reproducible, leading to inefficiency and wasteful decisions.  This project will develop computationally efficient and reliable methods to handle data of this kind as well as more complicated data structures.  The results of this research will benefit both industry and individuals making purchasing decisions.\r\n\r\nThe problems described above are known as crossed random effects in the statistical literature.  The statistically proper tools are linear mixed models and generalized linear mixed models.  The usual ways to fit linear mixed models have a cost that grows faster than linearly in the size of the data set.  The exponent is three halves.  The same cost arises in a Bayesian approach. With large modern data sets these costs are completely out of reach. Some recent solutions work with the method of moments at a cost that scales linearly with the data size.  This project will develop a backfitting method that starts with the moment method and then iterates towards the maximum likelihood solution.  It will also extend to the generalized linear mixed model case in order to handle binary outcomes, such as whether the customer did or did not buy a particular item.   While crossed random effects are prevalent in electronic commerce, they can arise in any setting where there are many to many relationships connecting one sort of entity to another.  Any place where we have observations on the edges of a bipartite graph is a place where crossed random effects may arise.   This work will also include random slope models.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Art",
   "pi_last_name": "Owen",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Art B Owen",
   "pi_email_addr": "owen@stat.stanford.edu",
   "nsf_id": "000472351",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Trevor",
   "pi_last_name": "Hastie",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Trevor J Hastie",
   "pi_email_addr": "hastie@stanford.edu",
   "nsf_id": "000447619",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "390 Serra Mall",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943054000",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "CA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 800000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Many data sets in business and science have a cross classification structure.<br />In electronic commerce, a company will have many customers and sell them<br />many products.&nbsp; They then get ratings or other data from customers about<br />those products.&nbsp; A crop scientist might study many environments for many<br />varieties of grain.&nbsp; When we find patterns in the data we want to know if those<br />patterns generalize beyond just the data we have.<br /><br />Ratings made on the same product tend to be correlated. If we ignore this<br />and treat them as two independent measurements, we would be overcounting<br />the evidence and end up with some false confidence.&nbsp; The same holds if we<br />ignore correlations between ratings made by the same customer.&nbsp; These<br />crossed random effects settings bring an immense tangle of correlations.<br /><br />Standard statistical methods exist for crossed random effects but they<br />are too expensive to use on big data.&nbsp; If there are N observations then<br />the time it takes to compute the standard methods grows at least as fast as <br />N raised to the power 1.5 and can be even worse.&nbsp;&nbsp; The goal of this project<br />is to find ways to handle large crossed random effects data sets with a<br />cost that grows proportionally to N only.&nbsp; We call that, linear cost.<br /><br />The project succeeded.&nbsp; We found five solutions for problems of this type.<br /><br />The first is a backfitting strategy for linear regression models plus<br />errors with a crossed random effects structure.&nbsp; The algorithm has<br />cost proportional to N for each iteration.&nbsp; We also proved conditions<br />under which the number of iterations stays bounded as N increases.<br />The algorithmic innovation was a kind of backfitting strategy to<br />handle the numerical algebra and the theoretical innovation was a<br />new model for which we were able to prove that the algorithm would<br />take a bounded number of iterations.<br /><br />The second solution was for logistic regression that handles yes/no<br />responses, such as whether a customer liked a product or a patient<br />recovered.&nbsp; For this, we were able to get an algorithm with linear cost<br />per iteration. In practice the number of iterations stayed bounded.<br /><br />The third solution was for a random slopes version of the model.<br />If the model wants to study how the price affects a customer's<br />happiness, then one might want to have a separate parameter<br />for every customer. Not everybody is equally price sensitive.<br />That is called a random slope model.&nbsp; We found a way to compute<br />those models using variational EM.<br /><br />The fourth solution was for another kind of yes/no response.&nbsp; The<br />model in use is known as a probit model.&nbsp; An additional difficulty<br />with this model is that it requires computation of a high dimensional<br />integral.&nbsp; In the example the dimension d was over 700,000.&nbsp; We showed<br />that this model can be estimated instead using d one dimensional<br />integration problems.&nbsp; That is far simpler to do computationally.<br />The idea is a new form of composite likelhood.<br /><br />The fifth solution was a Bayesian method, using the collapsed<br />Gibbs sampler instead of the backfitting algorithm.&nbsp; The theory<br />in that work was about connecting those two methods.&nbsp; The<br />cost was shown to be linear under even weaker assumptions<br />than in the backfitting paper.<br /><br />In addition to those results, there were over 40 other scholarly<br />works on a range of topics, supported by this grant.<br /><br />This work has some broader impacts. <br />Under this grant, one PhD student graduated and another<br />began her research and continues in it. <br /><br />Within statistics itself, we opened up some new theoretical directions: <br />new methods to bound the number of iterations of an algorithm, a new<br />kind of composite likelihood and some new work on Bayesian<br />estimation.&nbsp; Outside of statistics, the new methods will let people<br />do a better job of studying the error of their algorithms on data<br />from commerce, medicine, psychology and other areas where there<br />is a crossed random effects structure.<br /><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/20/2023<br>\n\t\t\t\t\tModified by: Art&nbsp;B&nbsp;Owen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMany data sets in business and science have a cross classification structure.\nIn electronic commerce, a company will have many customers and sell them\nmany products.  They then get ratings or other data from customers about\nthose products.  A crop scientist might study many environments for many\nvarieties of grain.  When we find patterns in the data we want to know if those\npatterns generalize beyond just the data we have.\n\nRatings made on the same product tend to be correlated. If we ignore this\nand treat them as two independent measurements, we would be overcounting\nthe evidence and end up with some false confidence.  The same holds if we\nignore correlations between ratings made by the same customer.  These\ncrossed random effects settings bring an immense tangle of correlations.\n\nStandard statistical methods exist for crossed random effects but they\nare too expensive to use on big data.  If there are N observations then\nthe time it takes to compute the standard methods grows at least as fast as \nN raised to the power 1.5 and can be even worse.   The goal of this project\nis to find ways to handle large crossed random effects data sets with a\ncost that grows proportionally to N only.  We call that, linear cost.\n\nThe project succeeded.  We found five solutions for problems of this type.\n\nThe first is a backfitting strategy for linear regression models plus\nerrors with a crossed random effects structure.  The algorithm has\ncost proportional to N for each iteration.  We also proved conditions\nunder which the number of iterations stays bounded as N increases.\nThe algorithmic innovation was a kind of backfitting strategy to\nhandle the numerical algebra and the theoretical innovation was a\nnew model for which we were able to prove that the algorithm would\ntake a bounded number of iterations.\n\nThe second solution was for logistic regression that handles yes/no\nresponses, such as whether a customer liked a product or a patient\nrecovered.  For this, we were able to get an algorithm with linear cost\nper iteration. In practice the number of iterations stayed bounded.\n\nThe third solution was for a random slopes version of the model.\nIf the model wants to study how the price affects a customer's\nhappiness, then one might want to have a separate parameter\nfor every customer. Not everybody is equally price sensitive.\nThat is called a random slope model.  We found a way to compute\nthose models using variational EM.\n\nThe fourth solution was for another kind of yes/no response.  The\nmodel in use is known as a probit model.  An additional difficulty\nwith this model is that it requires computation of a high dimensional\nintegral.  In the example the dimension d was over 700,000.  We showed\nthat this model can be estimated instead using d one dimensional\nintegration problems.  That is far simpler to do computationally.\nThe idea is a new form of composite likelhood.\n\nThe fifth solution was a Bayesian method, using the collapsed\nGibbs sampler instead of the backfitting algorithm.  The theory\nin that work was about connecting those two methods.  The\ncost was shown to be linear under even weaker assumptions\nthan in the backfitting paper.\n\nIn addition to those results, there were over 40 other scholarly\nworks on a range of topics, supported by this grant.\n\nThis work has some broader impacts. \nUnder this grant, one PhD student graduated and another\nbegan her research and continues in it. \n\nWithin statistics itself, we opened up some new theoretical directions: \nnew methods to bound the number of iterations of an algorithm, a new\nkind of composite likelihood and some new work on Bayesian\nestimation.  Outside of statistics, the new methods will let people\ndo a better job of studying the error of their algorithms on data\nfrom commerce, medicine, psychology and other areas where there\nis a crossed random effects structure.\n\n\n\n\n\t\t\t\t\tLast Modified: 10/20/2023\n\n\t\t\t\t\tSubmitted by: Art B Owen"
 }
}