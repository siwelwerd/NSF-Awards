{
 "awd_id": "1822731",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Teaching human motion at population scale",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Robert Russell",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 110773.0,
 "awd_amount": 110773.0,
 "awd_min_amd_letter_date": "2018-09-06",
 "awd_max_amd_letter_date": "2020-12-09",
 "awd_abstract_narration": "The project will develop technology and study methods for teaching motion tasks, with the teaching of sign language as a first application. Simultaneous placement or quick movement of parts of the body is hard to observe, explain, and execute. While tactile-sensing and augmented-reality systems have been developed to enable machine-human communication of physical processes, the focus has largely been on execution, rather than on teaching and learning. The initial focus of the project will be on teaching sign language, but principles and techniques discovered will be generalized to research the learning of increasingly complex physical motions, ranging from simple posing tasks to high-speed fine manipulation tasks. The proposed work is transformative in that it will directly address the scientific question of how to use technology to understand correct or incorrect human motion and provide constructive guidance, leading to a better understanding of human motion learning. The project will disseminate findings and resources through traditional scientific publications. In addition, models, algorithms, and designs for rapidly-prototyped tools for manipulation will be made available on the online. Results will also be communicated broadly through collaborations with local high schools and museums, and through participation in events such as the USA Science and Engineering Festival.\r\n\r\nThe task of teaching motion motivates the research of three fundamental challenges. First, closed-loop control is a core feature of cyber-physical systems. With a human participant in the system, how can the loop be closed around slow and low-bandwidth human attention? Actuation that guides the human must be easily communicated and sufficient to stabilize the human-suit system. Second, due to limitations in how much information may be communicated, complex human motions must be broken down, and components taught in isolation. How can these component motions be discovered, taught, and re-integrated? Third, algorithms and systems must be developed to measure the accuracy and retention of the learner during the teaching process, guiding repetition and selection of practice material. The project will design and build a lightweight sensing and guidance system that allows interactive communication about motion between human and computer. This technology will allow the investigators to address fundamental research questions in cyber-learning about how to better teach and learn human motion tasks. Research questions include how to measure and evaluate human motion with respect to the task, how to select sensory input to use as guidance, and how to selectively apply or remove training aids, until the learner can complete the motion task with no assistance.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Weifu",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Weifu Wang",
   "pi_email_addr": "wwang8@albany.edu",
   "nsf_id": "000732641",
   "pi_start_date": "2018-09-06",
   "pi_end_date": "2020-12-09"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gary",
   "pi_last_name": "Saulnier",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Gary J Saulnier",
   "pi_email_addr": "gsaulnier@albany.edu",
   "nsf_id": "000844861",
   "pi_start_date": "2020-12-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Albany",
  "inst_street_address": "1400 WASHINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "ALBANY",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5184374974",
  "inst_zip_code": "122220100",
  "inst_country_name": "United States",
  "cong_dist_code": "20",
  "st_cong_dist_code": "NY20",
  "org_lgl_bus_name": "RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE",
  "org_prnt_uei_num": "NHH3T1Z96H29",
  "org_uei_num": "NHH3T1Z96H29"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Albany",
  "perf_str_addr": "1400 Washington Ave",
  "perf_city_name": "ALBANY",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "122220100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "20",
  "perf_st_cong_dist": "NY20",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "005Y00",
   "pgm_ele_name": "STEM + Computing (STEM+C) Part"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 110773.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project was to investigate technological platforms, robotic analysis tools, and educational insights for how to teach human motions remotely without a human expert to direct input and interactions.<br /><br />On the technical side, major project outcomes of the University at Albany effort include the following:</p>\n<p>1), an integrated system that allows the demonstration and tracking of human motion in a relatively noisy environment.&nbsp; The tracking provides a visual feedback method for interactive teaching practices for human motion.</p>\n<p>2), Configuration and geometric-based motion segmentation methods that can be used to partition complex motions of different joints into simple straight line or arc motions and the use of these motion primitives to detect motion patterns, such as symmetry or periodicity. The approach tested on swimming motions were able to detect the human identified motion patterns but not yet able to generate higher level motion abstractions.<br /><br />The project also explored effective approaches for teaching human motion, understanding what is the best motion lessons for human perception, and working towards customized (automatic generated) motion plans for different individuals and motions intended to learn.<br /><br />The broader impact of this work is mostly educational, training the next generation of scientists and leaders. The project was the main source of support for one graduate student. The developed motion teaching platform was deployed for an initial round of testing to gather feedback from users to evaluate different lesson plans.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/21/2021<br>\n\t\t\t\t\tModified by: Gary&nbsp;J&nbsp;Saulnier</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this project was to investigate technological platforms, robotic analysis tools, and educational insights for how to teach human motions remotely without a human expert to direct input and interactions.\n\nOn the technical side, major project outcomes of the University at Albany effort include the following:\n\n1), an integrated system that allows the demonstration and tracking of human motion in a relatively noisy environment.  The tracking provides a visual feedback method for interactive teaching practices for human motion.\n\n2), Configuration and geometric-based motion segmentation methods that can be used to partition complex motions of different joints into simple straight line or arc motions and the use of these motion primitives to detect motion patterns, such as symmetry or periodicity. The approach tested on swimming motions were able to detect the human identified motion patterns but not yet able to generate higher level motion abstractions.\n\nThe project also explored effective approaches for teaching human motion, understanding what is the best motion lessons for human perception, and working towards customized (automatic generated) motion plans for different individuals and motions intended to learn.\n\nThe broader impact of this work is mostly educational, training the next generation of scientists and leaders. The project was the main source of support for one graduate student. The developed motion teaching platform was deployed for an initial round of testing to gather feedback from users to evaluate different lesson plans.\n\n\t\t\t\t\tLast Modified: 12/21/2021\n\n\t\t\t\t\tSubmitted by: Gary J Saulnier"
 }
}