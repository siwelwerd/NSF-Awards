{
 "awd_id": "1835863",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: HDR Elements: Software for a new machine learning based parameterization of moist convection for improved climate and weather prediction using deep learning",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032927092",
 "po_email": "alsuarez@nsf.gov",
 "po_sign_block_name": "Alejandro Suarez",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 289409.0,
 "awd_amount": 289409.0,
 "awd_min_amd_letter_date": "2018-08-13",
 "awd_max_amd_letter_date": "2018-08-13",
 "awd_abstract_narration": "This project targets a difficult problem in weather and climate prediction -- the representation of convection.  Accurate representation of convection is important, since a majority of current model predictions depend on it.  Unraveling the physics involved in convective conditions, clouds and aerosols may take years of modeling to fully understand; however, a set of machine learning techniques, known as \"neural net techniques\", may provide enhanced predictability in the interim, and this project explores their potential.\r\n\r\nThe project develops a Python library enabling the use of machine learning (artificial neural networks) in a broad range of science domains. The focus is on integration of convection and cloud formation within larger-scale climate models, with the Community Earth System Model (CESM) as an initial target.  The project develops a new set of machine learning climate model parameterizations to reduce uncertainty in weather and climate predictions.  The neural networks will be trained on high-fidelity simulations that explicitly resolve convection.  Two types of high-resolution simulations will be used for training the neural networks: 1) an augmented super-parameterized simulation, and 2) a full Global Cloud Resolving Model (GCRM) simulation based on the ICOsahedral Non-hydrostatic (ICON) modelling frameworks provided by the Max Planck Institute, using initial 5km horizontal resolution.  The effort has the potential to increase understanding of convection dynamics and processes across scales, and could potentially be implemented to address other scale problems as well, where it is too computationally costly or impractical to represent processes occurring at much finer scales than the main grid resolution.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Pritchard",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Pritchard",
   "pi_email_addr": "mspritch@uci.edu",
   "nsf_id": "000646133",
   "pi_start_date": "2018-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Irvine",
  "inst_street_address": "160 ALDRICH HALL",
  "inst_street_address_2": "",
  "inst_city_name": "IRVINE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9498247295",
  "inst_zip_code": "926970001",
  "inst_country_name": "United States",
  "cong_dist_code": "47",
  "st_cong_dist_code": "CA47",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA IRVINE",
  "org_prnt_uei_num": "MJC5FCYQTPE6",
  "org_uei_num": "MJC5FCYQTPE6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Irvine",
  "perf_str_addr": "University of California, Irvine",
  "perf_city_name": "Irvine",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "926973100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "47",
  "perf_st_cong_dist": "CA47",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "574000",
   "pgm_ele_name": "Climate & Large-Scale Dynamics"
  },
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "077Z",
   "pgm_ref_txt": "CSSI-1: Cyberinfr for Sustained Scientif"
  },
  {
   "pgm_ref_code": "4444",
   "pgm_ref_txt": "INTERDISCIPLINARY PROPOSALS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 289409.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-40c44d3a-7fff-5844-790f-8ee56f068d74\"><br />\n<p dir=\"ltr\"><span>Accurate representation of clouds and rain in climate models requires high-resolution physics calculations, which are very expensive to run. Replacing these calculations with machine learning (ML) parameterizations is an attractive way to reduce these costs, while keeping the small-scale physical processes intact.</span><span> </span><span>In this grant, we collaborated with computer scientists to develop new software that makes it easier to implement such ML calculations (typically written in Python) in climate models (which are typically written in Fortran). The resulting software is now being used across several national and international climate modeling agencies, as well as in other disciplines.</span></p>\n<p dir=\"ltr\">&nbsp;</p>\n<p dir=\"ltr\"><span>Along the way, we encountered a problem currently&nbsp; at the frontier of implementing ML in models: getting them to &ldquo;fit&rdquo; together. When ML parameterizations were embedded within active simulations of the global atmosphere</span><span>, and allowed to feed back with explicit fluid dynamics, compounding errors appeared that did not exist when the ML parameterization were initially trained</span><span>. In Brenowitz et al. (</span><span>JAS, </span><span>2021) we collaborated with a team at the University of Washington to study these common errors. We found that using multiple ML models (which independently predict the same thing at the same time, but produce slightly different answers because of random aspects of the optimization procedure) instead of individual ML models could reduce these errors in climate simulators that include ML components. We also developed new diagnostics to anticipate these errors.</span></p>\n<br />\n<p dir=\"ltr\"><span>Much of the previous work at this interface focused on hypothetical &ldquo;ocean-worlds&rdquo; that do not include the complexities of real continents and vegetation. To explore ML parameterization in a more operationally relevant setting, we generated a new training dataset and uncovered the error structures that occur in this challenging limit (Mooers et al., </span><span>JAMES</span><span>, 2020). We uncovered regions near the land surface where the ML methods especially struggle. As a result of this work, we have developed new hypotheses about better ways to design ML methods for physics calculations of clouds and rain near the land surface that take advantage of the randomness of the atmosphere (i.e., the so-called &ldquo;butterfly effect&rdquo;). The metrics we developed in this study are now being used by others, including the code we published to generate them.</span></p>\n<p dir=\"ltr\"><span>&nbsp;</span></p>\n<p dir=\"ltr\"><span>We then focused on solving a fundamental problem in traditional ML methods: they don&rsquo;t always follow the laws of physics. In Beucler et al. (</span><span>PRL, </span><span>2021) we developed an algorithm for incorporating the laws of physics in ML emulators of physical systems. This enabled ML emulators of clouds and rain to obey mass and energy conservation, where they previously did not. Surprisingly, these constraints did little to affect either the error characteristics or the trainability of the offline ML models, which is important to realize.</span></p>\n<p dir=\"ltr\"><span>&nbsp;</span></p>\n<p dir=\"ltr\"><span>Next we focused on another fundamental issue in using ML models for Earth physics emulation; can emulators trained in one climate work well in another? In other words, can ML emulators trained on data from the satellite period (~1970s to today) be used to accurately predict how Earth&rsquo;s climate responds to future increases in atmospheric greenhouse gas concentrations (which we haven&rsquo;t observed yet)? In Beucler et al. (arXiv, 2021) we proved that &ldquo;climate invariant&rdquo; ML emulators begin to be achieved through strategic mathematical manipulations of the input and output data that allow the emulator to perform well in unfamiliar climates. For example, one manipulation we employed was to rescale specific humidity, a measure of the number of water vapor molecules in the air, to relative humidity, a number which is bounded at 0 and slightly over 100. In any climate, relative humidity will stay between about 0 and 100, while specific humidity can increase exponentially with temperature.&nbsp; In this work we also used some &ldquo;interpretable-AI approaches&rdquo;, which led to&nbsp; helpful diagnostics. This was a broad collaboration with many external researchers thinking about similar issues.</span></p>\n<p dir=\"ltr\"><span>&nbsp;</span></p>\n<p dir=\"ltr\"><span>Finally, the scope of this grant also enabled some academic exploration of generative ML models to help analyze overwhelming and complex data from high resolution global cloud resolving simulations. In Mooers et al. (</span><span>Climate Informatics</span><span>, 2020) we showed that one type of generative model, &ldquo;variational autoencoders&rdquo; can summarize the most important features of atmospheric turbulence in a way that can&rsquo;t be done with conventional statistical methods. Mangipudi et al. (</span><span>NeurIPS, </span><span>2021) expanded this work in situations with added complexity. In Mooers et al. (arXiv, 2022) we exploited the above innovations to show that the wind behavior in three of the nine global storm resolving models in a state of the art international simulation archive is not like&nbsp; the other six, and developed novel metrics for model comparison along the way.</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/16/2023<br>\n\t\t\t\t\tModified by: Michael&nbsp;Pritchard</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\nAccurate representation of clouds and rain in climate models requires high-resolution physics calculations, which are very expensive to run. Replacing these calculations with machine learning (ML) parameterizations is an attractive way to reduce these costs, while keeping the small-scale physical processes intact. In this grant, we collaborated with computer scientists to develop new software that makes it easier to implement such ML calculations (typically written in Python) in climate models (which are typically written in Fortran). The resulting software is now being used across several national and international climate modeling agencies, as well as in other disciplines.\n \nAlong the way, we encountered a problem currently  at the frontier of implementing ML in models: getting them to \"fit\" together. When ML parameterizations were embedded within active simulations of the global atmosphere, and allowed to feed back with explicit fluid dynamics, compounding errors appeared that did not exist when the ML parameterization were initially trained. In Brenowitz et al. (JAS, 2021) we collaborated with a team at the University of Washington to study these common errors. We found that using multiple ML models (which independently predict the same thing at the same time, but produce slightly different answers because of random aspects of the optimization procedure) instead of individual ML models could reduce these errors in climate simulators that include ML components. We also developed new diagnostics to anticipate these errors.\n\n\nMuch of the previous work at this interface focused on hypothetical \"ocean-worlds\" that do not include the complexities of real continents and vegetation. To explore ML parameterization in a more operationally relevant setting, we generated a new training dataset and uncovered the error structures that occur in this challenging limit (Mooers et al., JAMES, 2020). We uncovered regions near the land surface where the ML methods especially struggle. As a result of this work, we have developed new hypotheses about better ways to design ML methods for physics calculations of clouds and rain near the land surface that take advantage of the randomness of the atmosphere (i.e., the so-called \"butterfly effect\"). The metrics we developed in this study are now being used by others, including the code we published to generate them.\n \nWe then focused on solving a fundamental problem in traditional ML methods: they don\u2019t always follow the laws of physics. In Beucler et al. (PRL, 2021) we developed an algorithm for incorporating the laws of physics in ML emulators of physical systems. This enabled ML emulators of clouds and rain to obey mass and energy conservation, where they previously did not. Surprisingly, these constraints did little to affect either the error characteristics or the trainability of the offline ML models, which is important to realize.\n \nNext we focused on another fundamental issue in using ML models for Earth physics emulation; can emulators trained in one climate work well in another? In other words, can ML emulators trained on data from the satellite period (~1970s to today) be used to accurately predict how Earth\u2019s climate responds to future increases in atmospheric greenhouse gas concentrations (which we haven\u2019t observed yet)? In Beucler et al. (arXiv, 2021) we proved that \"climate invariant\" ML emulators begin to be achieved through strategic mathematical manipulations of the input and output data that allow the emulator to perform well in unfamiliar climates. For example, one manipulation we employed was to rescale specific humidity, a measure of the number of water vapor molecules in the air, to relative humidity, a number which is bounded at 0 and slightly over 100. In any climate, relative humidity will stay between about 0 and 100, while specific humidity can increase exponentially with temperature.  In this work we also used some \"interpretable-AI approaches\", which led to  helpful diagnostics. This was a broad collaboration with many external researchers thinking about similar issues.\n \nFinally, the scope of this grant also enabled some academic exploration of generative ML models to help analyze overwhelming and complex data from high resolution global cloud resolving simulations. In Mooers et al. (Climate Informatics, 2020) we showed that one type of generative model, \"variational autoencoders\" can summarize the most important features of atmospheric turbulence in a way that can\u2019t be done with conventional statistical methods. Mangipudi et al. (NeurIPS, 2021) expanded this work in situations with added complexity. In Mooers et al. (arXiv, 2022) we exploited the above innovations to show that the wind behavior in three of the nine global storm resolving models in a state of the art international simulation archive is not like  the other six, and developed novel metrics for model comparison along the way.\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 02/16/2023\n\n\t\t\t\t\tSubmitted by: Michael Pritchard"
 }
}