{
 "awd_id": "1754211",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Visual Perception as Retrospective Bayesian Decoding from High- to Low-level Features in Working Memory",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2018-04-01",
 "awd_exp_date": "2022-03-31",
 "tot_intn_awd_amt": 513163.0,
 "awd_amount": 513163.0,
 "awd_min_amd_letter_date": "2018-03-05",
 "awd_max_amd_letter_date": "2019-08-08",
 "awd_abstract_narration": "When looking at a scene, we typically have a quick and accurate perceptual understanding of its high-level category, for example, a home, office, street, or jungle. We rarely pay attention to the scene's low-level properties such as luminance values at various spots unless we are asked to report them, and even then, we are not very accurate about them. The fact that higher-level properties of a scene are more relevant to our behavior than low-level properties has informed global precedence theories of perception. However, experimental studies of the brain have established that lower-level features in a scene are detected before higher-level features; this result somehow led to the commonly used, but rarely tested, assumption that visual perception follows the same low-to-high-level hierarchy of feature detection. This project attempts to resolve this apparent contradiction by separating feature detection and perception, and by integrating visual perception and working memory, the brain's short-term storage of relevant visual information. The project will provide a new computational framework for understanding perception and memory which challenges traditional theories.\r\n\r\nTechnically, vision can be viewed as involving both encoding and decoding. Encoding refers to how visual stimuli evoke sensory responses in the brain whereas decoding concerns how these responses eventually lead to the subjective perception of the stimuli. A common assumption of many existing models is that decoding follows the same low-to-high-level hierarchy as encoding, but this was never rigorously tested. Additionally, under natural viewing conditions, the small fovea and frequent saccades introduce delays between sensory encoding of different parts of a scene and perceptual integration of the whole scene, suggesting that working memory must be involved in perceptual decoding; yet previous decoding models do not consider working memory. This project aims to address these issues using psychophysical and computational methods, with the specific goal of elucidating the nature of decoding hierarchy in light of working-memory properties. Specifically, compared with lower-level stimulus features, higher-level features are more invariant and categorical, thus requiring less information to specify and permitting more stable maintenance in noisy working memory. The brain should therefore prioritize decoding of reliable higher-level features and then use them to constrain and improve the decoding of unstable lower-level features in memory (when necessary). The project will test some surprising predictions of this retrospective Bayesian decoding theory and develop a neural network implementation of the theory.\r\n\u00a0\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ning",
   "pi_last_name": "Qian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ning Qian",
   "pi_email_addr": "nq6@columbia.edu",
   "nsf_id": "000125534",
   "pi_start_date": "2018-03-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "The Trustees of Columbia University in the City of New York",
  "perf_str_addr": "3227 Broadway, Quad 5B",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100277922",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 166365.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 346798.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>This project focuses on mechanisms of visual perception: how the processes in the brain allow us to see the world around us. Vision can be divided into two parts: encoding and decoding. The former is about how things in the world activate neurons in the brain whereas the latter concerns how the neuronal activities lead to our perception of the world. This is somewhat (but not precisely) analogous to how your voice activates the electronics in your phone (encoding) and how the electronic activities eventually reproduce your voice in your friends&rsquo; phones (decoding). Most of the existing theories assume that both the encoding and decoding in the brain follow a low-to-high-level hierarchy, namely that the brain first processes simple things (such as line segments) then moves on to more complex things (such as relationships between line segments). However, our previous work led us to the proposal that unlike the encoding, the decoding proceeds from high-to-low-level features in working memory (a form of short-term memory that stores relevant items selected from the encoding process). In this project, we proposed both behavioral and computational studies to test our theory. The behavioral studies confirmed a few key predictions of the theory. The computational studies demonstrated how the theory may be realized with plausible neural circuits and how the circuits work. Collectively, these studies provide new insights into the brain mechanisms of visual perception, which might lead to engineering or clinical applications in the future. </strong></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/01/2022<br>\n\t\t\t\t\tModified by: Ning&nbsp;Qian</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project focuses on mechanisms of visual perception: how the processes in the brain allow us to see the world around us. Vision can be divided into two parts: encoding and decoding. The former is about how things in the world activate neurons in the brain whereas the latter concerns how the neuronal activities lead to our perception of the world. This is somewhat (but not precisely) analogous to how your voice activates the electronics in your phone (encoding) and how the electronic activities eventually reproduce your voice in your friends\u2019 phones (decoding). Most of the existing theories assume that both the encoding and decoding in the brain follow a low-to-high-level hierarchy, namely that the brain first processes simple things (such as line segments) then moves on to more complex things (such as relationships between line segments). However, our previous work led us to the proposal that unlike the encoding, the decoding proceeds from high-to-low-level features in working memory (a form of short-term memory that stores relevant items selected from the encoding process). In this project, we proposed both behavioral and computational studies to test our theory. The behavioral studies confirmed a few key predictions of the theory. The computational studies demonstrated how the theory may be realized with plausible neural circuits and how the circuits work. Collectively, these studies provide new insights into the brain mechanisms of visual perception, which might lead to engineering or clinical applications in the future. \n\n \n\n\t\t\t\t\tLast Modified: 05/01/2022\n\n\t\t\t\t\tSubmitted by: Ning Qian"
 }
}