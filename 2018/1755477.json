{
 "awd_id": "1755477",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Attention and Neural Oscillations in Perceptual Integration",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032924502",
 "po_email": "dkravitz@nsf.gov",
 "po_sign_block_name": "Dwight Kravitz",
 "awd_eff_date": "2018-05-15",
 "awd_exp_date": "2024-04-30",
 "tot_intn_awd_amt": 574252.0,
 "awd_amount": 574252.0,
 "awd_min_amd_letter_date": "2018-05-31",
 "awd_max_amd_letter_date": "2023-04-05",
 "awd_abstract_narration": "Sensations and perceptions of the world are typically accurate, especially with focused attention. However, they are sometimes inaccurate, which can lead to damaging consequences. Understanding how the human brain processes sensory information to form coherent and representative perceptions of the world is therefore scientifically important and has broad implications for national health (e.g., radiologists detecting a tumor), security and defense (e.g., accurately responding to a perceived threat), and general safety and well-being (e.g., correctly perceiving the color of a traffic light). With funding from the National Science Foundation, this research assesses how attention and associated changes in brain activity facilitate the successful combination of different types of sensory information into accurate perceptions. By focusing on errors in perceptual binding, such as misperceiving the color of one object as being the color of another nearby object, these studies will provide insights into the brain states that allow perception to proceed with precision and those that cause perception to fail. In addition to advancing scientific knowledge about the brain, this research will provide training opportunities to many students, including high school and undergraduate students as well as underrepresented students in the STEM fields. \r\n\r\nThe proposed experiments will examine the cognitive and neural mechanisms involved with visual feature binding and multisensory integration. The investigators will use converging methods to test whether modulations of attention and neural oscillations affect sensory integration. These methods include structural and functional magnetic resonance imaging (MRI) to measure neural activity during successful and unsuccessful visual feature binding and multisensory integration, electroencephalography (EEG) and fast signal optical imaging to measure changes in oscillatory neural activity prior to and after sensory integration, and rhythmic transcranial magnetic stimulation (TMS) to alter sensory integration by modulating and inducing phase-controlled neural oscillations. These studies will shed light on how sensory information that is processed in discrete regions of the human brain might be combined through neural oscillations to produce coherent representations of the external world. They will also provide a better understanding of failures in perception. By examining how different brain regions integrate information through synchronized neural activity, these studies may also provide important clues for generating strategies and rehabilitative tools for individuals with a variety of congenital, developmental, and acquired impairments that affect sensory processing.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tony",
   "pi_last_name": "Ro",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tony Ro",
   "pi_email_addr": "tro@gc.cuny.edu",
   "nsf_id": "000453113",
   "pi_start_date": "2018-05-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "CUNY Graduate School University Center",
  "inst_street_address": "365 5TH AVE STE 8113",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128177526",
  "inst_zip_code": "100164309",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NY12",
  "org_lgl_bus_name": "RESEARCH FOUNDATION OF THE CITY UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "QVW9TFAZJFE7"
 },
 "perf_inst": {
  "perf_inst_name": "CUNY Graduate School University Center",
  "perf_str_addr": "365 Fifth Avenue",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100164309",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NY12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169900",
   "pgm_ele_name": "Cognitive Neuroscience"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1699",
   "pgm_ref_txt": "COGNEURO"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 574252.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research has provided new insights into how the human brain processes and integrates sensory information. The results from these studies show that touch perception is processed in ways that are similar or identical to visual perception, suggesting a common architecture for processing different types of sensory information in different regions of the brain. Consistent with those results, we also found that visual signals alone, under some circumstances, can produce sensations of touch from evoked neural activity in touch processing regions of the brain. These results have broad implications for understanding some of the general principles of sensory information processing and may provide insight into the development of sensory prosthetic and/or substitution devices.</p>\n<p>In addition to demonstrating interactions between different sensory modalities, this project also uncovered some of the ways in which information within a sensory modality, namely different visual features of objects, such as their color and shape, are integrated after being processed in separate regions of the brain. The results showed a distinct time window of neural processing during which information from different features are integrated. These findings suggest that certain failures in perceptual integration may occur during this period after initial sensory processing and may facilitate in the design of more effective visual displays in which accurate perception of visual information is essential.</p>\n<p>Finally, this project has provided fundamental scientific training to several individuals from underrepresented groups, thereby contributing towards increasing the diversity in this field and the STEM-related workforce.</p><br>\n<p>\n Last Modified: 09/13/2024<br>\nModified by: Tony&nbsp;Ro</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis research has provided new insights into how the human brain processes and integrates sensory information. The results from these studies show that touch perception is processed in ways that are similar or identical to visual perception, suggesting a common architecture for processing different types of sensory information in different regions of the brain. Consistent with those results, we also found that visual signals alone, under some circumstances, can produce sensations of touch from evoked neural activity in touch processing regions of the brain. These results have broad implications for understanding some of the general principles of sensory information processing and may provide insight into the development of sensory prosthetic and/or substitution devices.\n\n\nIn addition to demonstrating interactions between different sensory modalities, this project also uncovered some of the ways in which information within a sensory modality, namely different visual features of objects, such as their color and shape, are integrated after being processed in separate regions of the brain. The results showed a distinct time window of neural processing during which information from different features are integrated. These findings suggest that certain failures in perceptual integration may occur during this period after initial sensory processing and may facilitate in the design of more effective visual displays in which accurate perception of visual information is essential.\n\n\nFinally, this project has provided fundamental scientific training to several individuals from underrepresented groups, thereby contributing towards increasing the diversity in this field and the STEM-related workforce.\t\t\t\t\tLast Modified: 09/13/2024\n\n\t\t\t\t\tSubmitted by: TonyRo\n"
 }
}