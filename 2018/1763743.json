{
 "awd_id": "1763743",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: Medium: Collaborative Research: Interweaving the Parallel Software/Hardware Stack",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 909275.0,
 "awd_amount": 957275.0,
 "awd_min_amd_letter_date": "2018-08-17",
 "awd_max_amd_letter_date": "2022-07-31",
 "awd_abstract_narration": "This project seeks to advance the state of the art of parallel systems.   Usually, the layers of a parallel system - the compiler, run-time system, operating system, and hardware - are considered as separate entities with a rigid division of labor.  This project investigates an alternative model, \"interweaving,\" in which these layers are integrated as needed to improve the performance, scalability, and efficiency of the specific parallel system.  \r\n\r\nThe research involves five thrusts: (1) Blending studies using compiler technology to achieve integration of code that would normally be found in distinct, separately compiled layers.   (2) Coherence considers hardware without memory coherence and its implications throughout the \"interwoven\" parallel system.  (3) Predictability studies the integration of hard real-time behavior into a parallel system through hardware and compiler support.  (4) Mapping considers address translation for parallel systems given hardware and compiler support.  (5) Debugging studies how to debug an interwoven system.  These investigations go hand-in-hand with the continual development of a prototype and its evaluation.\r\n\r\nParallel systems are of critical importance for science and engineering, and have become ubiquitous; even simple devices like smartphones incorporate growing parallelism.   The project thus has the potential to improve a wide range of applications both through its ideas and is open code.  It will also train Ph.D. and undergraduate students, and enhance collaborations between two Chicago-area universities. \r\n\r\nCode, data, and results will be maintained publicly (http://interweaving.org) for the project's duration, and requests considered for five years afterwards.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Dinda",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Peter A Dinda",
   "pi_email_addr": "pdinda@northwestern.edu",
   "nsf_id": "000341788",
   "pi_start_date": "2018-08-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Nikos",
   "pi_last_name": "Hardavellas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nikos Hardavellas",
   "pi_email_addr": "nikos@northwestern.edu",
   "nsf_id": "000538510",
   "pi_start_date": "2018-08-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Simone",
   "pi_last_name": "Campanoni",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Simone Campanoni",
   "pi_email_addr": "simonec@eecs.northwestern.edu",
   "nsf_id": "000710339",
   "pi_start_date": "2018-08-17",
   "pi_end_date": "2022-07-31"
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "2145 Sheridan Road",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602080834",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 301885.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 298987.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 324403.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><h2 id=\"docs-internal-guid-0f964efe-7fff-0878-0982-7bbfeabfc08a\" style=\"line-height: 1.38; margin-top: 18pt; margin-bottom: 6pt;\" dir=\"ltr\"><span style=\"font-size: 16pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Outcomes of the Interweaving Project</span></h2>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Parallel computing is indispensable to delivering the high computing performance necessary for science and engineering, as well as machine learning/AI. &nbsp; Almost all computers, even the smallest ones, are now parallel computers. &nbsp; The goal of this project was to explore a new model, the &ldquo;Interweaving Model&rdquo;, for the structure of the hardware/software stack for parallel computing.&nbsp; In Interweaving, the traditional layering of the programming language, compiler, run-time system, operating system, and architecture is discarded.&nbsp; Instead, Interweaving introduces and combines functionality at different layers to create bespoke stacks that are specific to particular languages or execution models, and achieve performance and efficiency gains over traditional stacks.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The Interweaving model proved largely promising, with some outcomes being of particular note.&nbsp; Many parallel execution models demand careful synchronization.&nbsp; The project demonstrated how to achieve this in two novel ways:&nbsp; through custom hardware and by leveraging hard real-time scheduling technology in a custom kernel. &nbsp; The project also deeply explored the interaction of compiler technology with the kernel and hardware. &nbsp; One chain of work demonstrated how to achieve very low overhead timing through compiler transforms instead of hardware timer interrupts. &nbsp; Another demonstrated the feasibility of using novel compiler analysis and transformations combined with special kernel support to achieve the purposes of address translation without requiring paging hardware.&nbsp; Finally, the need for (expensive) hardware coherence was carefully considered in several contexts, and it was found that certain access guarantees available in high-level parallel language runtimes could be readily signaled to custom coherence protocols.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The project's approach was largely empirical. &nbsp; The project developed and/or expanded its own kernel (Nautilus framework), compiler technology (NOELLE framework), and custom hardware designs.&nbsp; One important empirical outcome was three different designs for integrating the OpenMP parallel language between compiler, run-time, and kernel. &nbsp; The implementations of these designs ran on some of the largest single-node computers available.&nbsp; A range of other software tools were also developed. &nbsp; The software, and hardware designs&nbsp; developed in pursuing this research has been made publically available with open-source licensing (typically MIT, BSD, or GPL licenses).&nbsp;&nbsp;&nbsp;&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Significant training opportunities resulted from the project.&nbsp; Across the two collaborating institutions (Northwestern and IIT), 17 Ph.D. students, 8 MS students, 14 REU students, 10 undergraduates, and 2 high school students have been involved in the project.&nbsp; Three Ph.D. students graduated over the course of the project with directly related dissertations. &nbsp; Several of the M.S. and undergraduate students have gone on to Ph.D. programs. &nbsp; One undergraduate and one Ph.D. student on the project were awarded prestigious DOE CSGF fellowships.&nbsp; Two undergrads received honorable mentions in the national CRA undergraduate research awards. Northwestern&rsquo;s undergraduate operating systems course was entirely redesigned, leveraging the Nautilus kernel framework to create labs. &nbsp; A Northwestern graduate course in kernel and other low-level software development was created, and has so far trained over 100 students in this esoteric topic.&nbsp; A Northwestern course on compiler analysis and transformation was created, and Northwestern&rsquo;s compiler sequence was&nbsp; also considerably enhanced.</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The positive results of the Interweaving Project have, so far, resulted in two follow-on projects (along with two other institutions) that are expanding the effort to rethink the parallel computing stack from algorithms down through hardware. &nbsp; The codebases described above form key parts of enabling this work.</span></p><br>\n<p>\n Last Modified: 11/26/2023<br>\nModified by: Peter&nbsp;A&nbsp;Dinda</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "Outcomes of the Interweaving Project\n\n\nParallel computing is indispensable to delivering the high computing performance necessary for science and engineering, as well as machine learning/AI.  Almost all computers, even the smallest ones, are now parallel computers.  The goal of this project was to explore a new model, the Interweaving Model, for the structure of the hardware/software stack for parallel computing. In Interweaving, the traditional layering of the programming language, compiler, run-time system, operating system, and architecture is discarded. Instead, Interweaving introduces and combines functionality at different layers to create bespoke stacks that are specific to particular languages or execution models, and achieve performance and efficiency gains over traditional stacks.\n\n\n\n\n\nThe Interweaving model proved largely promising, with some outcomes being of particular note. Many parallel execution models demand careful synchronization. The project demonstrated how to achieve this in two novel ways: through custom hardware and by leveraging hard real-time scheduling technology in a custom kernel.  The project also deeply explored the interaction of compiler technology with the kernel and hardware.  One chain of work demonstrated how to achieve very low overhead timing through compiler transforms instead of hardware timer interrupts.  Another demonstrated the feasibility of using novel compiler analysis and transformations combined with special kernel support to achieve the purposes of address translation without requiring paging hardware. Finally, the need for (expensive) hardware coherence was carefully considered in several contexts, and it was found that certain access guarantees available in high-level parallel language runtimes could be readily signaled to custom coherence protocols.\n\n\n\n\n\nThe project's approach was largely empirical.  The project developed and/or expanded its own kernel (Nautilus framework), compiler technology (NOELLE framework), and custom hardware designs. One important empirical outcome was three different designs for integrating the OpenMP parallel language between compiler, run-time, and kernel.  The implementations of these designs ran on some of the largest single-node computers available. A range of other software tools were also developed.  The software, and hardware designs developed in pursuing this research has been made publically available with open-source licensing (typically MIT, BSD, or GPL licenses).\n\n\n\n\n\nSignificant training opportunities resulted from the project. Across the two collaborating institutions (Northwestern and IIT), 17 Ph.D. students, 8 MS students, 14 REU students, 10 undergraduates, and 2 high school students have been involved in the project. Three Ph.D. students graduated over the course of the project with directly related dissertations.  Several of the M.S. and undergraduate students have gone on to Ph.D. programs.  One undergraduate and one Ph.D. student on the project were awarded prestigious DOE CSGF fellowships. Two undergrads received honorable mentions in the national CRA undergraduate research awards. Northwesterns undergraduate operating systems course was entirely redesigned, leveraging the Nautilus kernel framework to create labs.  A Northwestern graduate course in kernel and other low-level software development was created, and has so far trained over 100 students in this esoteric topic. A Northwestern course on compiler analysis and transformation was created, and Northwesterns compiler sequence was also considerably enhanced.\n\n\n\n\n\nThe positive results of the Interweaving Project have, so far, resulted in two follow-on projects (along with two other institutions) that are expanding the effort to rethink the parallel computing stack from algorithms down through hardware.  The codebases described above form key parts of enabling this work.\t\t\t\t\tLast Modified: 11/26/2023\n\n\t\t\t\t\tSubmitted by: PeterADinda\n"
 }
}