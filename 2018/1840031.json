{
 "awd_id": "1840031",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FW-HTF: Collaborative Research: The Next Mobile Office: Safe and Productive Work in Automated Vehicles",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032925365",
 "po_email": "jberg@nsf.gov",
 "po_sign_block_name": "Jordan Berg",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 399958.0,
 "awd_amount": 457890.0,
 "awd_min_amd_letter_date": "2018-09-10",
 "awd_max_amd_letter_date": "2021-04-28",
 "awd_abstract_narration": "The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim, by examining whether and how a new technology can safely improve worker productivity, and well-being.\r\n \r\nCurrent trends in the automobile industry make cars increasingly automated, allowing them to take on a growing number of driving tasks, while freeing the driver to engage in other activities. Millions of people spend nearly an hour of each work day commuting by car. Automated vehicles could allow part of the time currently spent driving to be used for work-related efforts. The goal of this project is to understand how current and future technologies might enable work to be done in automated vehicles. Reclaiming productive time from time currently taken up by driving could increase economic productivity, worker wellbeing, and firm profitability. The project focuses on understanding how technology can allow commuters to safely combine or switch between work and driving tasks. A new multi-interface in-vehicle environment for the support of work-related tasks, as well as safe driving, in automated vehicles will be developed and tested in driving simulators and real vehicles.  The innovative contributions to the in-vehicle use of speech and spoken interactions, augmented reality, and tangible user interfaces will have applicability to a broad range of settings, including for non-drivers and in mobile environments beyond the car. The project also includes activities to promote the participation of women in Science, Technology, Engineering and Mathematics. \r\n \r\nCreating the systems that will allow drivers to safely engage in work-related activities in automated vehicles requires an interdisciplinary effort. This project will explore what types of work in automated vehicles can improve workers' job satisfaction and productivity, and the productivity and profitability of firms. Based on these findings, the team will create in-vehicle user interfaces that support work tasks, as well as safe transitions between engaging in work tasks and in driving.  Three types of user interfaces will be integrated: voice interfaces, augmented reality interfaces, and tangible interfaces. The team will also develop a probabilistic model to examine the ability of the in-vehicle interfaces to communicate to the driver the mode and limitations of the vehicle automation. The model will incorporate cases when the user transitions between the work task and the driving task. This will allow designing the interfaces such that they provide adequate support for the safe transition from the work task to the driving task, as well as an efficient transition back to the work task. The team will close the loop with design guidelines, by providing researchers, practitioners, and policy makers a broad set of guidelines, along with careful reasoning for their application in the design of human-machine interaction to support the work-related tasks of workers in automated vehicles.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Orit",
   "pi_last_name": "Shaer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Orit Shaer",
   "pi_email_addr": "oshaer@wellesley.edu",
   "nsf_id": "000547518",
   "pi_start_date": "2018-09-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Wellesley College",
  "inst_street_address": "106 CENTRAL ST",
  "inst_street_address_2": "",
  "inst_city_name": "WELLESLEY HILLS",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "7812832079",
  "inst_zip_code": "024818203",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "WELLESLEY COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "Z17DSLNJ1DX1"
 },
 "perf_inst": {
  "perf_inst_name": "Wellesley College",
  "perf_str_addr": "106 Central st",
  "perf_city_name": "Wellesley",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "024818204",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "082Y00",
   "pgm_ele_name": "FW-HTF-Adv Cogn & Phys Capblty"
  },
  {
   "pgm_ele_code": "158Y00",
   "pgm_ele_name": "COVID-19 Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "030E",
   "pgm_ref_txt": "CONTROL SYSTEMS"
  },
  {
   "pgm_ref_code": "034E",
   "pgm_ref_txt": "Dynamical systems"
  },
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "096Z",
   "pgm_ref_txt": "COVID-19 Research"
  },
  {
   "pgm_ref_code": "116E",
   "pgm_ref_txt": "RESEARCH EXP FOR UNDERGRADS"
  },
  {
   "pgm_ref_code": "8024",
   "pgm_ref_txt": "Complex Systems"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9231",
   "pgm_ref_txt": "SUPPL FOR UNDERGRAD RES ASSIST"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 399958.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 49932.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The overarching goal of this project is to create systems that allow workers to safely engage in work-related tasks in automated vehicles, such that these tasks improve their job satisfaction, creativity, and productivity. The project originally focused of five specific goals: Goal1) Identifying the needs of workers and managers related to work in automated vehicles; Goal 2) Designing and evaluating new user interfaces for the support of work-related tasks, as well as safe driving, in automated vehicles; Goal 3) Modeling the process of transitioning to and from in-vehicle sub-tasks, work-related, and driving-related, at a high level of abstraction; and Goal 4) Identifying design guidelines, for the design of human-machine interaction to support the work-related tasks of knowledge workers in automated vehicles; Additionally, during COVID-19 we received a supplement to accomplish Goal 5) Enhancing our ongoing work focused on working from the car environment to study and support the productivity, creativity and wellbeing of working from home environments.</p>\n<p>Under the original four goals of this project, we first studied the non-driving related tasks that knowledge workers seek to engage in while commuting. Our findings also indicate that in automated vehicles knowledge workers will take advantage of their newfound freedom from driving and will expand engagement in both work and personal activities. We should build on this result and design systems that help workers strike a balance between work productivity and personal wellbeing as they engage in non-driving activities safely during their commutes in automated vehicles. We then defined a theoretical framework for how drivers will take back control in automated vehicles, and evaluated it using a driving &nbsp;simulator test. Finally, we explored the use of augmented reality and speech interfaces in automated vehicles, and in what ways users will be able to engage in non-driving tasks in automated vehicles safely.</p>\n<p>Under Goal 5, we conducted time-use studies that highlighted the impact of the transition to working from home arrangements on knowledge workers and managers, indicating that while some workers were able to reallocate their commute time to personal time, managers reallocated commuting time to work related time. We found that the workdays of managers were more fragmented during COVID, with an increase in the number of activities, with shorter activity durations, and with activities that were more dispersed across the day, resulting in a longer workday. &nbsp;Our research also provided some new insights on the impact of distracted participants on group performance and creativity during remote meetings. Our findings indicate that divided attention participants are still able to contribute in a meaningful way. Hence, by developing solutions that support multi-tasking, remote meetings tools can be designed to enhance the overall creativity of a group. To further understand new ways to support working from home, we conducted a remote 9-weeks study, which examined how experiencing nature through a virtual reality device, and then also engaging in mindfulness practices, affected focus, stress, and creativity of remote workers. The results showed that 10-minutes a day of VR nature experience increased participants? focus, and when VR was combined with mindfulness the experience also contributed to improving some aspects of creativity.</p>\n<p>Overall, about 20 graduate and undergraduate students from multiple institutions worked on this project in an interdisciplinary collaborative environment. They received training in software and hardware design and development, experimental and user study research methods, statistical analysis, and paper writing. All findings were disseminated through publications in journals and presentations at technical conferences. The research was further promoted to diverse audiences through formal and informal activities, including talks, demonstrations, and presentations, as well as cover in highly visible media such as Harvard Business Review, and Harvard Business School Working Knowledge.&nbsp;The PIs founded a new conference series in cooperation with ACM SIGCHI called CHIWork: Symposium on Human-Computer Interaction for Work.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/20/2022<br>\n\t\t\t\t\tModified by: Orit&nbsp;Shaer</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1840031/1840031_10581499_1668904687995_ScreenShot2022-11-19at7.35.47PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1840031/1840031_10581499_1668904687995_ScreenShot2022-11-19at7.35.47PM--rgov-800width.jpg\" title=\"An augmented reality windshield display for drivers to engage safely in non-driving related task when driving future automated vehicles\"><img src=\"/por/images/Reports/POR/2022/1840031/1840031_10581499_1668904687995_ScreenShot2022-11-19at7.35.47PM--rgov-66x44.jpg\" alt=\"An augmented reality windshield display for drivers to engage safely in non-driving related task when driving future automated vehicles\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An augmented reality windshield display for drivers to engage safely in non-driving related task when driving future automated vehicles.</div>\n<div class=\"imageCredit\">Wellesley HCILab</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Orit&nbsp;Shaer</div>\n<div class=\"imageTitle\">An augmented reality windshield display for drivers to engage safely in non-driving related task when driving future automated vehicles</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1840031/1840031_10581499_1668904804324_ScreenShot2022-11-19at7.35.24PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1840031/1840031_10581499_1668904804324_ScreenShot2022-11-19at7.35.24PM--rgov-800width.jpg\" title=\"A driving simulator experiment to study how drivers will take back control in automated vehicles\"><img src=\"/por/images/Reports/POR/2022/1840031/1840031_10581499_1668904804324_ScreenShot2022-11-19at7.35.24PM--rgov-66x44.jpg\" alt=\"A driving simulator experiment to study how drivers will take back control in automated vehicles\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A driving simulator experiment to study how drivers will take back control in automated vehicles</div>\n<div class=\"imageCredit\">UNH HCI Lab</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Orit&nbsp;Shaer</div>\n<div class=\"imageTitle\">A driving simulator experiment to study how drivers will take back control in automated vehicles</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe overarching goal of this project is to create systems that allow workers to safely engage in work-related tasks in automated vehicles, such that these tasks improve their job satisfaction, creativity, and productivity. The project originally focused of five specific goals: Goal1) Identifying the needs of workers and managers related to work in automated vehicles; Goal 2) Designing and evaluating new user interfaces for the support of work-related tasks, as well as safe driving, in automated vehicles; Goal 3) Modeling the process of transitioning to and from in-vehicle sub-tasks, work-related, and driving-related, at a high level of abstraction; and Goal 4) Identifying design guidelines, for the design of human-machine interaction to support the work-related tasks of knowledge workers in automated vehicles; Additionally, during COVID-19 we received a supplement to accomplish Goal 5) Enhancing our ongoing work focused on working from the car environment to study and support the productivity, creativity and wellbeing of working from home environments.\n\nUnder the original four goals of this project, we first studied the non-driving related tasks that knowledge workers seek to engage in while commuting. Our findings also indicate that in automated vehicles knowledge workers will take advantage of their newfound freedom from driving and will expand engagement in both work and personal activities. We should build on this result and design systems that help workers strike a balance between work productivity and personal wellbeing as they engage in non-driving activities safely during their commutes in automated vehicles. We then defined a theoretical framework for how drivers will take back control in automated vehicles, and evaluated it using a driving  simulator test. Finally, we explored the use of augmented reality and speech interfaces in automated vehicles, and in what ways users will be able to engage in non-driving tasks in automated vehicles safely.\n\nUnder Goal 5, we conducted time-use studies that highlighted the impact of the transition to working from home arrangements on knowledge workers and managers, indicating that while some workers were able to reallocate their commute time to personal time, managers reallocated commuting time to work related time. We found that the workdays of managers were more fragmented during COVID, with an increase in the number of activities, with shorter activity durations, and with activities that were more dispersed across the day, resulting in a longer workday.  Our research also provided some new insights on the impact of distracted participants on group performance and creativity during remote meetings. Our findings indicate that divided attention participants are still able to contribute in a meaningful way. Hence, by developing solutions that support multi-tasking, remote meetings tools can be designed to enhance the overall creativity of a group. To further understand new ways to support working from home, we conducted a remote 9-weeks study, which examined how experiencing nature through a virtual reality device, and then also engaging in mindfulness practices, affected focus, stress, and creativity of remote workers. The results showed that 10-minutes a day of VR nature experience increased participants? focus, and when VR was combined with mindfulness the experience also contributed to improving some aspects of creativity.\n\nOverall, about 20 graduate and undergraduate students from multiple institutions worked on this project in an interdisciplinary collaborative environment. They received training in software and hardware design and development, experimental and user study research methods, statistical analysis, and paper writing. All findings were disseminated through publications in journals and presentations at technical conferences. The research was further promoted to diverse audiences through formal and informal activities, including talks, demonstrations, and presentations, as well as cover in highly visible media such as Harvard Business Review, and Harvard Business School Working Knowledge. The PIs founded a new conference series in cooperation with ACM SIGCHI called CHIWork: Symposium on Human-Computer Interaction for Work.\n\n \n\n\t\t\t\t\tLast Modified: 11/20/2022\n\n\t\t\t\t\tSubmitted by: Orit Shaer"
 }
}