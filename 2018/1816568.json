{
 "awd_id": "1816568",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Computational and Physiological Studies of Complex Neural Codes in the Early Visual Cortex",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 499994.0,
 "awd_amount": 527594.0,
 "awd_min_amd_letter_date": "2018-08-14",
 "awd_max_amd_letter_date": "2023-06-21",
 "awd_abstract_narration": "In this interdisciplinary project, machine learning approaches are coupled with neurophysiological studies of primate early visual cortex  to investigate the functional, coding and computational benefits of the observed neural representation and computing architecture.  Neural models, with recurrent connections and the proposed dual-code strategy, will be developed to solve multiple vision problems simultaneously and to fit neurophysiological data.  The representations will be studied from both coding perspectives and computational perspectives, based on scene statistics and their relevance for solving vision problems. The research program will be facilitated by international collaboration and tightly integrated with undergraduate and graduate education in neural computation.   The proposed project wide provide new insights to the computations and functions of the biological visual system, as well as new ideas and inspirations for developing machine learning systems that can learn from limited data and function robustly and flexibly in novel complex situations, potentially with broad societal and technological impact.\r\n\r\nCurrent deep learning neural networks utilize tens or hundreds of layers to learn solutions for specific computer vision problems. The mammalian visual system has much fewer layers, and yet can solve many tasks in a variety of novel and complex situations. The nervous system might achieve this feat by having neuronal circuits with loops and recurrent connections, and with order of magnitude more neurons in each \"layer.\" Recent neurophysiological findings suggest that neurons in the primary visual cortex (V1) of primates are not simply oriented edge and bar detectors as described in textbooks, but respond strongly to highly specific complex local patterns, although they also respond to many other patterns with much weaker responses.  The PI proposed that the individual neurons are not amorphous entities, functioning facelessly in a large population, but are distinct and unique individuals that serve as specialists for some specific tasks and as generalists in other tasks. They participate in population encoding of  information with strong sparse codes or weak distributed codes respectively, depending on the functional roles they serve.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tai Sing",
   "pi_last_name": "Lee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tai Sing Lee",
   "pi_email_addr": "tai@cnbc.cmu.edu",
   "nsf_id": "000181351",
   "pi_start_date": "2018-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 Forbes Avenue",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152132685",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 499994.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 14000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 13600.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we studied how visual concepts are represented in primate brains using deep learning techniques and explored the computational advantages of these representational strategies in computer vision. In neurophysiological studies based on single unit recording and 2-photon calcium imaging in the early visual areas (V1, V2, and V4) of non-human primates, we found that individual neurons use strong responses to represent specific visual prototype patterns, such as curves, corners, and rings, that are more complex than simply the oriented edges as commonly assumed. We used deep neural networks to model and create a digital twin for each neuron. Our investigation of these digital twins revealed that a significant proportion of the complex pattern selectivity in V1 arises from local recurrent neural circuits. We studied the neural representation of visual prototype concepts rendered realistically or in abstraction, specifically in photographs, cartoons, and line drawings. We found that visual concepts rendered in different cues share similar geometric structures in neural population activities, and these geometric structures are stable across different populations of neurons and across different visual areas. As information processing progresses downstream to V4. The visual concepts represented become increasingly elaborated. Neurons representing a variety of concepts are organized in a topological map with distinct domains tuned to a variety of natural scene features, some tuned for surface properties of objects, while others tuned for object shapes. These neurophysiological results suggest that neurons in the early visual cortex can encode prototype concepts with strong responses and serve as a distributed code with weaker responses. We investigated the implications of these neuroscience findings in machine learning deep neural network systems by dissecting the information encoded in their units. We found that the strong responses in the units tend to encode foreground structural shape information, while weak responses tend to encode texture and background information. By preserving the strong responses and suppressing the weak responses during neural network training, we can induce the neurons to explicitly encode local visual concepts of shapes.&nbsp; We explored the use of these prototype codes in deep learning networks for image generation and image analysis. We found that neural networks trained with prototype codes for object recognition exhibit stronger shape bias, a human perceptual trait lacking in convolutional neural networks. In generative AI systems, these prototype codes enable neural networks to learn with fewer examples to synthesize images with more structurally correct objects with coherent parts and overall shapes.&nbsp; This project integrated neuroscience and artificial intelligence with broad implications in both fields. It leveraged machine learning techniques to understand neural codes for visual representation, addressing fundamental problems in neuroscience and psychology. The insights from the neuroscience findings, in turn, help advance deep learning approaches.&nbsp; The observation that the neurons might serve as prototype codes challenged provided impetus for developing a new generation of deep networks that can reason more symbolically and conceptually like humans. The findings of this project were disseminated in competitive peer-reviewed conferences and journals. They are also incorporated in courses taught at Carnegie Mellon, lectures delivered in conference workshops, and national summer programs for college and high school students. These efforts promoted public awareness of computational neuroscience and artificial intelligence and the dissemination of scientific knowledge in industry and in the scientific community.&nbsp;</p><br>\n<p>\n Last Modified: 09/22/2024<br>\nModified by: Tai Sing&nbsp;Lee</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1816568/1816568_10570470_1727035419020_RF_visualization--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1816568/1816568_10570470_1727035419020_RF_visualization--rgov-800width.png\" title=\"Encoding of prototype visual concepts in the primary visual cortex\"><img src=\"/por/images/Reports/POR/2024/1816568/1816568_10570470_1727035419020_RF_visualization--rgov-66x44.png\" alt=\"Encoding of prototype visual concepts in the primary visual cortex\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Neurons in the primary visual cortex are found to encode a diversity of specific visual patterns with strong responses. Each square depicts the most exciting stimulus for a neuron. They can be considered as a form of prototype codes.</div>\n<div class=\"imageCredit\">Gao S., Wang., T, Jue X, Wang D, Lee TS, SM Tang A large dataset of Macaque V1 responses to natural images revealed complexity in V1 neural codes. Computational and System Neuroscience (COSYNE)</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Tai Sing&nbsp;Lee\n<div class=\"imageTitle\">Encoding of prototype visual concepts in the primary visual cortex</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1816568/1816568_10570470_1727036202393_TopK_Net--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1816568/1816568_10570470_1727036202393_TopK_Net--rgov-800width.png\" title=\"Prototype codes enhance image analysis and synthesis in deep networks\"><img src=\"/por/images/Reports/POR/2024/1816568/1816568_10570470_1727036202393_TopK_Net--rgov-66x44.png\" alt=\"Prototype codes enhance image analysis and synthesis in deep networks\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Prototype codes or strong responses in the units of deep networks encode shape information, while weak responses tend to encode texture information (A,B). prototype memory allows  generative AI systems to learn to synthesize more structurally coherent objects with fewer training examples (C,D).</div>\n<div class=\"imageCredit\">Li et al. (2024) NeurIPS. Li et al. (2022) ICLR.</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Tai Sing&nbsp;Lee\n<div class=\"imageTitle\">Prototype codes enhance image analysis and synthesis in deep networks</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1816568/1816568_10570470_1727035805716_V4map--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1816568/1816568_10570470_1727035805716_V4map--rgov-800width.png\" title=\"Diversity and organization of V4 encoding of natural image features\"><img src=\"/por/images/Reports/POR/2024/1816568/1816568_10570470_1727035805716_V4map--rgov-66x44.png\" alt=\"Diversity and organization of V4 encoding of natural image features\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Calcium imaging of macaque V4 and deep learning techniques revealed distinct clusters of neurons preferring a variety of global natural image prototype features, organized in topological map. Some clusters prefer surface features (e.g. color. texture). Others prefer shapes and forms (e.g. face).</div>\n<div class=\"imageCredit\">Wang T., TS Lee,* Yao Hao*, Hong J, Li Y, Jiang H, IM, Andolina, S.M Tang (2024) Large-scale calcium imaging reveals a systematic V4 map for encoding natural scenes. * co-first author. Nature Communication 15. 6410).</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Tai Sing&nbsp;Lee\n<div class=\"imageTitle\">Diversity and organization of V4 encoding of natural image features</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn this project, we studied how visual concepts are represented in primate brains using deep learning techniques and explored the computational advantages of these representational strategies in computer vision. In neurophysiological studies based on single unit recording and 2-photon calcium imaging in the early visual areas (V1, V2, and V4) of non-human primates, we found that individual neurons use strong responses to represent specific visual prototype patterns, such as curves, corners, and rings, that are more complex than simply the oriented edges as commonly assumed. We used deep neural networks to model and create a digital twin for each neuron. Our investigation of these digital twins revealed that a significant proportion of the complex pattern selectivity in V1 arises from local recurrent neural circuits. We studied the neural representation of visual prototype concepts rendered realistically or in abstraction, specifically in photographs, cartoons, and line drawings. We found that visual concepts rendered in different cues share similar geometric structures in neural population activities, and these geometric structures are stable across different populations of neurons and across different visual areas. As information processing progresses downstream to V4. The visual concepts represented become increasingly elaborated. Neurons representing a variety of concepts are organized in a topological map with distinct domains tuned to a variety of natural scene features, some tuned for surface properties of objects, while others tuned for object shapes. These neurophysiological results suggest that neurons in the early visual cortex can encode prototype concepts with strong responses and serve as a distributed code with weaker responses. We investigated the implications of these neuroscience findings in machine learning deep neural network systems by dissecting the information encoded in their units. We found that the strong responses in the units tend to encode foreground structural shape information, while weak responses tend to encode texture and background information. By preserving the strong responses and suppressing the weak responses during neural network training, we can induce the neurons to explicitly encode local visual concepts of shapes. We explored the use of these prototype codes in deep learning networks for image generation and image analysis. We found that neural networks trained with prototype codes for object recognition exhibit stronger shape bias, a human perceptual trait lacking in convolutional neural networks. In generative AI systems, these prototype codes enable neural networks to learn with fewer examples to synthesize images with more structurally correct objects with coherent parts and overall shapes. This project integrated neuroscience and artificial intelligence with broad implications in both fields. It leveraged machine learning techniques to understand neural codes for visual representation, addressing fundamental problems in neuroscience and psychology. The insights from the neuroscience findings, in turn, help advance deep learning approaches. The observation that the neurons might serve as prototype codes challenged provided impetus for developing a new generation of deep networks that can reason more symbolically and conceptually like humans. The findings of this project were disseminated in competitive peer-reviewed conferences and journals. They are also incorporated in courses taught at Carnegie Mellon, lectures delivered in conference workshops, and national summer programs for college and high school students. These efforts promoted public awareness of computational neuroscience and artificial intelligence and the dissemination of scientific knowledge in industry and in the scientific community.\t\t\t\t\tLast Modified: 09/22/2024\n\n\t\t\t\t\tSubmitted by: Tai SingLee\n"
 }
}