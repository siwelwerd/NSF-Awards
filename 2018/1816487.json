{
 "awd_id": "1816487",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Collaborative Research: Improving Latency in Geo-Replicated Storage by Relaxing Consistency Requirements",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jason Hallstrom",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 241852.0,
 "awd_amount": 241852.0,
 "awd_min_amd_letter_date": "2018-07-23",
 "awd_max_amd_letter_date": "2018-07-23",
 "awd_abstract_narration": "Recent years have seen a tremendous growth in the popularity of cloud services. Distributed storage systems are a key component of the cloud computing revolution. Distributed storage systems are designed to achieve a suitable trade-off between latency, data consistency and dependability. This project addresses development of new consistency models that take into account application characteristics and hybrid fault models. The ultimate goal is to improve our understanding of the trade-offs between consistency, latency, and dependability in distributed storage systems.\r\n \r\nThe project includes two synergistic thrusts. First, the project explores consistency models that consider graph-based application characteristics. For example, social and trust graphs model user relation and interaction for many applications. The first thrust explores graph-based consistency models that are acceptable for the applications, and yet improve latency of client operations. Second, prior storage systems typically either only tolerate benign failures, or tolerate worst-case faults with high overhead. This project considers non-colluding faults as well as Byzantine faults, and investigates approaches to reduce overhead by relaxing some of the requirements imposed by prior systems.\r\n \r\nProposed research is expected to improve the understanding of the impact of application characteristics and different types of faults on consistency-latency trade-off in distributed storage systems. Tolerance of more severe faults is likely to become important for future critical web-based services and applications. Additionally, with the tremendous growth in social and trust networks, mechanisms to improve their performance are of interest. This project helps achieve such improvements through the development of new consistency models. Additionally, the project provides research opportunities to undergraduate and graduate students, and a post-doctoral researcher.\r\n\r\nThe data from the project is to be retained for at least two years after the completion of this project, and stored in local computers and online shared storage. The URL for the repository of the data, publications and software resulting from the project is https://sites.google.com/site/nsfgeoconsistency/.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lewis",
   "pi_last_name": "Tseng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lewis Tseng",
   "pi_email_addr": "lewis_tseng@uml.edu",
   "nsf_id": "000764377",
   "pi_start_date": "2018-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Boston College",
  "inst_street_address": "140 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHESTNUT HILL",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6175528000",
  "inst_zip_code": "024673800",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MA04",
  "org_lgl_bus_name": "TRUSTEES OF BOSTON COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "MJ3JH8CRJBZ7"
 },
 "perf_inst": {
  "perf_inst_name": "Boston College",
  "perf_str_addr": "140 Commonwealth Avenue",
  "perf_city_name": "Chestnut Hill",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "024673800",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 241852.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-d3c4e986-7fff-3900-7ce0-ec8bd785ddab\" style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Recent years have seen a significant growth in the popularity of online services accessed over the Internet. As industry and individuals rely increasingly on the cloud services, their availability becomes increasingly important. The availability is improved in practice via replication, which brings with it the problem of maintaining consistency across the replicas.</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Modern key-value stores support many different consistency models. Among the consistency models that have been explored in the prior literature, causal consistency is of particular interest. Causal consistency allows for low-latency operation while supporting a causal view of the execution for the users. Intuitively, when a user reads a certain value of a key, it can also correctly obtain all causally preceding updates to other keys. We identified the minimum number of servers required to implement a causal distributed storage when a certain number of machines may suffer crash or Byzantine failures in a communication network that might lose messages (i.e., lossy communication).&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Second, we improved the performance of distributed storages for large data. We proposed an erasure coding-based protocol that implements a distributed storage with atomicity and near-optimal storage cost. Our protocol supports concurrent read and write operations while tolerating crash failures of any client and some fraction of servers. One novel feature of our protocol is a tunable knob between the number of supported concurrent operations, availability, and storage cost. We implement our protocol into Cassandra, namely CassandrEAS (Cassandra + Erasure-coding Atomic Storage). Evaluation using YCSB on Google Cloud Platform with different configurations shows that CassandrEAS incurs moderate penalty on latency and throughput, yet saves a significant amount of storage space.</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Third, we studied approaches to implement atomic snapshot objects (ASO). Intuitively, ASO allows a distributed storage system to support a read transaction in a non-blocking manner. ASO ensures linearizability. Our algorithms tolerate crash and Byzantine faults in asynchronous networks, and achieves amortized constant round complexity. We also studied a relaxed version of snapshot objects, namely sequentially consistent snapshot objects (SSO). Compared to ASO, SSO satisfies only sequential consistency; however, it supports more efficient operations, which is appealing for geo-replicated storage systems.</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Fourth, we investigated checkpointing and rollback mechanisms under four different consistency models: (i) linearizability, (ii) sequential consistency, (iii) causal consistency, and (iv) eventual consistency. Linearizability is the strongest consistency model among these four, and eventual consistency is the weakest consistency model. Implementing a stronger consistency model results in the state of the distributed storage replicas satisfying stronger properties, when compared to weaker models. These stronger properties may potentially be exploited to improve the overhead of checkpointing algorithms. We developed checkpointing and rollback mechanisms for each of the four implementations, and demonstrated that it is possible to exploit stronger consistency model implementations to develop more efficient checkpointing and rollback mechanisms.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Finally, we considered the state-machine replication (SMR) problem, which is a key mechanism to implement fault-tolerant storage systems. However, SMR is known to be difficult to understand and implement. We proposed Rabia, a simple and high performance framework for implementing SMR within a datacenter. The main innovation of Rabia is in using randomization to simplify the design. Rabia provides the following features: (i) It does not need any fail-over protocol and supports trivial auxiliary protocols like log compaction, snapshotting, and reconfiguration, these components often considered the most challenging when developing SMR systems; and (ii) It provides high performance, up to 1.5x higher throughput than the closest competitor (i.e., EPaxos) in an ideal setup (same availability zone with 3 replicas) and comparable with a larger number of replicas or when deployed in multiple zones.</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Selected results from the project have been published in peer-reviewed venues. Due to the increasing deployment of distributed storages, the results from this project have a significant potential for impact. Also, some of our fundamental results are expected to have an impact on future research in the area.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2022<br>\n\t\t\t\t\tModified by: Lewis&nbsp;Tseng</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Recent years have seen a significant growth in the popularity of online services accessed over the Internet. As industry and individuals rely increasingly on the cloud services, their availability becomes increasingly important. The availability is improved in practice via replication, which brings with it the problem of maintaining consistency across the replicas.\n\n \nModern key-value stores support many different consistency models. Among the consistency models that have been explored in the prior literature, causal consistency is of particular interest. Causal consistency allows for low-latency operation while supporting a causal view of the execution for the users. Intuitively, when a user reads a certain value of a key, it can also correctly obtain all causally preceding updates to other keys. We identified the minimum number of servers required to implement a causal distributed storage when a certain number of machines may suffer crash or Byzantine failures in a communication network that might lose messages (i.e., lossy communication). \n\n \nSecond, we improved the performance of distributed storages for large data. We proposed an erasure coding-based protocol that implements a distributed storage with atomicity and near-optimal storage cost. Our protocol supports concurrent read and write operations while tolerating crash failures of any client and some fraction of servers. One novel feature of our protocol is a tunable knob between the number of supported concurrent operations, availability, and storage cost. We implement our protocol into Cassandra, namely CassandrEAS (Cassandra + Erasure-coding Atomic Storage). Evaluation using YCSB on Google Cloud Platform with different configurations shows that CassandrEAS incurs moderate penalty on latency and throughput, yet saves a significant amount of storage space.\n\n \nThird, we studied approaches to implement atomic snapshot objects (ASO). Intuitively, ASO allows a distributed storage system to support a read transaction in a non-blocking manner. ASO ensures linearizability. Our algorithms tolerate crash and Byzantine faults in asynchronous networks, and achieves amortized constant round complexity. We also studied a relaxed version of snapshot objects, namely sequentially consistent snapshot objects (SSO). Compared to ASO, SSO satisfies only sequential consistency; however, it supports more efficient operations, which is appealing for geo-replicated storage systems.\n\n \nFourth, we investigated checkpointing and rollback mechanisms under four different consistency models: (i) linearizability, (ii) sequential consistency, (iii) causal consistency, and (iv) eventual consistency. Linearizability is the strongest consistency model among these four, and eventual consistency is the weakest consistency model. Implementing a stronger consistency model results in the state of the distributed storage replicas satisfying stronger properties, when compared to weaker models. These stronger properties may potentially be exploited to improve the overhead of checkpointing algorithms. We developed checkpointing and rollback mechanisms for each of the four implementations, and demonstrated that it is possible to exploit stronger consistency model implementations to develop more efficient checkpointing and rollback mechanisms. \n\n \nFinally, we considered the state-machine replication (SMR) problem, which is a key mechanism to implement fault-tolerant storage systems. However, SMR is known to be difficult to understand and implement. We proposed Rabia, a simple and high performance framework for implementing SMR within a datacenter. The main innovation of Rabia is in using randomization to simplify the design. Rabia provides the following features: (i) It does not need any fail-over protocol and supports trivial auxiliary protocols like log compaction, snapshotting, and reconfiguration, these components often considered the most challenging when developing SMR systems; and (ii) It provides high performance, up to 1.5x higher throughput than the closest competitor (i.e., EPaxos) in an ideal setup (same availability zone with 3 replicas) and comparable with a larger number of replicas or when deployed in multiple zones.\n\n \nSelected results from the project have been published in peer-reviewed venues. Due to the increasing deployment of distributed storages, the results from this project have a significant potential for impact. Also, some of our fundamental results are expected to have an impact on future research in the area.\n\n\t\t\t\t\tLast Modified: 11/29/2022\n\n\t\t\t\t\tSubmitted by: Lewis Tseng"
 }
}