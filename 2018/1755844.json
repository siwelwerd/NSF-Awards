{
 "awd_id": "1755844",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: RI: Towards Human-Level Assessment of Speech Quality and Intelligibility in Real-World Environments",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2018-06-01",
 "awd_exp_date": "2021-05-31",
 "tot_intn_awd_amt": 174995.0,
 "awd_amount": 174995.0,
 "awd_min_amd_letter_date": "2018-04-13",
 "awd_max_amd_letter_date": "2018-04-13",
 "awd_abstract_narration": "Separating speech from background noise is crucial for many speech-based applications, including hearing prostheses, robotics, and multimedia communication. Many speech separation algorithms perform reasonably well when they are tested in simulated environments, but this level of performance does not always carry over to real environments that are more nuanced. For example, a common complaint of many hearing aid users is that their hearing aid is not effective in noisy environments such as restaurants. Current computational measures do not enable practical or convenient speech assessment in everyday environments, and this is a major hurdle for improving real-world separation performance. In addition, the end-user has largely been left out of the development and evaluation process, which is not ideal since an approach's usefulness is ultimately determined by people. The objective of this project is to develop computational evaluation algorithms to better assess speech quality and intelligibility in real environments. \r\n\r\nA key area of research focuses on developing novel, data-driven assessment algorithms that use deep learning to predict human assessment scores, which enables testing in real environments.  Considering the recent success that deep learning has had in speech processing, this new assessment approach is promising and offers substantial differences from prior approaches. The relationship between spectral-temporal speech attributes and human assessment scores are determined as a result of this project. Quantifying this relationship ensures that assessment algorithms are accurate and have strong agreement with human evaluations. An effective integration of human assessment in speech separation algorithm development should result in improved separation algorithms, which ultimately benefits users and applications. This is expected since accurate assessment enables researchers to more easily identify and correct weaknesses based on real-world environmental factors. The research activities lay the foundation for the emerging research area of improving realism in speech processing applications and offer key insights on human perception to the larger scientific community.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Donald",
   "pi_last_name": "Williamson",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Donald S Williamson",
   "pi_email_addr": "williamson.413@osu.edu",
   "nsf_id": "000737871",
   "pi_start_date": "2018-04-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Indiana University",
  "inst_street_address": "107 S INDIANA AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BLOOMINGTON",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "3172783473",
  "inst_zip_code": "474057000",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IN09",
  "org_lgl_bus_name": "TRUSTEES OF INDIANA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "YH86RTW2YVJ4"
 },
 "perf_inst": {
  "perf_inst_name": "Indiana University",
  "perf_str_addr": "",
  "perf_city_name": "Bloomington",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "474057104",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IN09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 174995.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Competing background sounds often interfere with speech reliant devices, such as hearing aids, home assistants, and multimedia communication systems, which increases the need for noise-reduction algorithms that effectively separate speech from unwanted noise. Unfortunately, many noise-reduction algorithms do not always perform well in real environments that differ from the laboratory or simulated environments that they are initially evaluated in. For example, a common complaint of many hearing aid users is that their hearing aid is not effective in noisy environments such as restaurants. Many efforts strive to address this problem by exploring more effective machine learning approaches that generate better representations, or experimenting with more effective computational assessment metrics. These approaches, though valid, do not address two major issues: (1) commonly-used computational speech assessment measures cannot be used in real world environments and (2) these measures also are not always strongly correlated with human perceptual assessments.</p>\n<p>The main objective of this project was to develop computational assessment algorithms that better assess speech in real environments. To accomplish this, we first conducted a large-scale listening study to collect human-annotated speech quality ratings of speech that is captured in real and everyday environments. Hence, the amount and types of unwanted background sounds varied, as desired. This study was conducted online in a crowdsourced manner and resulted in the annotation of 36000 speech signals. In total, 180000 quality ratings were collected. To the best of our knowledge, this resulted in the first freely-available, large-scale speech corpus that contains human-annotated perceptual quality ratings.</p>\n<p>This corpus then enabled us to develop two computational assessment algorithms that directly predict the human-annotated quality rating from the speech waveform. Prior approaches, including some of our own, have shown that non-human assessed quality ratings can be predicted, but those ratings are not always correlated with human assessments. &nbsp;To address this problem, we developed novel deep learning-based algorithms that were trained to estimate the human-annotated quality score by only receiving the speech signal as an input. Our approaches generate meaningful representations and consider structure within the speech signal. Ultimately, our approaches performed well according to multiple computational measures of success, where they outperformed comparison approaches. These results show that it is possible to develop machine learning algorithms that directly estimate human-annotated data, which opens the door for more human-inspired machine learning approaches.</p>\n<p><strong>Intellectual Merit</strong>. This project resulted in two data-driven algorithms that predict human assessment scores of speech in everyday environments. This is a new and expandable research area, where our work has helped establish the foundation of this field. Our results also provide insights about human perception in different noisy environments.</p>\n<p><strong>Broader Impacts</strong>. This work aids the development of more effective noise-reduction algorithms, as the data-driven human-assessment algorithms can be used to optimize performance of noise-reduction approaches. Additionally, many graduate and undergraduate students were able to hone skills in many fields, including signal processing, computer science, machine learning, psychoacoustics and hearing science, which helps them become more well-rounded scientists and engineers. The findings will also be incorporated into future courses to help train the next generation of scientist and engineers that specialize in human-inspired machine learning.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/07/2021<br>\n\t\t\t\t\tModified by: Donald&nbsp;S&nbsp;Williamson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nCompeting background sounds often interfere with speech reliant devices, such as hearing aids, home assistants, and multimedia communication systems, which increases the need for noise-reduction algorithms that effectively separate speech from unwanted noise. Unfortunately, many noise-reduction algorithms do not always perform well in real environments that differ from the laboratory or simulated environments that they are initially evaluated in. For example, a common complaint of many hearing aid users is that their hearing aid is not effective in noisy environments such as restaurants. Many efforts strive to address this problem by exploring more effective machine learning approaches that generate better representations, or experimenting with more effective computational assessment metrics. These approaches, though valid, do not address two major issues: (1) commonly-used computational speech assessment measures cannot be used in real world environments and (2) these measures also are not always strongly correlated with human perceptual assessments.\n\nThe main objective of this project was to develop computational assessment algorithms that better assess speech in real environments. To accomplish this, we first conducted a large-scale listening study to collect human-annotated speech quality ratings of speech that is captured in real and everyday environments. Hence, the amount and types of unwanted background sounds varied, as desired. This study was conducted online in a crowdsourced manner and resulted in the annotation of 36000 speech signals. In total, 180000 quality ratings were collected. To the best of our knowledge, this resulted in the first freely-available, large-scale speech corpus that contains human-annotated perceptual quality ratings.\n\nThis corpus then enabled us to develop two computational assessment algorithms that directly predict the human-annotated quality rating from the speech waveform. Prior approaches, including some of our own, have shown that non-human assessed quality ratings can be predicted, but those ratings are not always correlated with human assessments.  To address this problem, we developed novel deep learning-based algorithms that were trained to estimate the human-annotated quality score by only receiving the speech signal as an input. Our approaches generate meaningful representations and consider structure within the speech signal. Ultimately, our approaches performed well according to multiple computational measures of success, where they outperformed comparison approaches. These results show that it is possible to develop machine learning algorithms that directly estimate human-annotated data, which opens the door for more human-inspired machine learning approaches.\n\nIntellectual Merit. This project resulted in two data-driven algorithms that predict human assessment scores of speech in everyday environments. This is a new and expandable research area, where our work has helped establish the foundation of this field. Our results also provide insights about human perception in different noisy environments.\n\nBroader Impacts. This work aids the development of more effective noise-reduction algorithms, as the data-driven human-assessment algorithms can be used to optimize performance of noise-reduction approaches. Additionally, many graduate and undergraduate students were able to hone skills in many fields, including signal processing, computer science, machine learning, psychoacoustics and hearing science, which helps them become more well-rounded scientists and engineers. The findings will also be incorporated into future courses to help train the next generation of scientist and engineers that specialize in human-inspired machine learning.\n\n\t\t\t\t\tLast Modified: 09/07/2021\n\n\t\t\t\t\tSubmitted by: Donald S Williamson"
 }
}