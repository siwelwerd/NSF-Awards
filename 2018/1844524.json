{
 "awd_id": "1844524",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Reconciling Model Discrepancies in Human-Robot Teams",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 249929.0,
 "awd_amount": 249929.0,
 "awd_min_amd_letter_date": "2018-08-13",
 "awd_max_amd_letter_date": "2018-08-13",
 "awd_abstract_narration": "Robots greatly complement human capabilities in many domains, but having them function as teammates has often proven to be challenging. This is due in part to a lack of understanding of robots, which often leads humans to find that their expectations of robotic teammates are not met in reality.  The proposed research addresses this by having robots reason about the models people have of them and using those models to either behave in ways that meet the expectations more closely or explain the perceived differences.  The work can have a significant impact on critical domains that involve human-in-the-loop AI systems, such as decision support, automated manufacturing, eldercare, and medical robotics. \r\n\r\nTo become reliable teammates, robots must understand the expectations of their human partners regarding the robots' tasks and abilities, and be able to seek reconciliation between the expected and actual models. In this project, reconciliation will be achieved either by 1) biasing the robot's behavior to implicitly accommodate model differences; or 2) communicating to explicitly reduce the differences. The first approach, termed model reconciliation planning, will be formulated as an optimization problem that generates a plan for the robot to execute while minimizing its distance to the expected plan that the human envisions. Heuristic search methods will be developed to accommodate this approach. The second approach will generate explanations to update the human's model of the robot in such a way that the robot's plan more closely matches that of the human's expectation in the updated model.  In addition, machine learning will be used to approximate the model of human expectation when not provided explicitly, and methods for model reconciliation with these learned and incomplete models will be developed.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yu",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yu Zhang",
   "pi_email_addr": "Yu.Zhang.442@asu.edu",
   "nsf_id": "000719058",
   "pi_start_date": "2018-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "ORSPA",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852816011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 249929.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Robots are an increasingly common presence in human-inhabited environments. As they become more autonomous with advanced planning and learning algorithms built-in, they also become more complex externally from humans' perspectives. Soon, we will no longer view them as simple tools that operate separately and far away from us. Instead, humans and robots in teams will cooperate more integratively and closely as in human-human teams instead of like archipelagos. A key challenge of such robotic technologies is understanding the differences between humans and robots and accommodating them via model reconciliation methods. The corresponding problem is a subproblem of enabling robots to think like us--they only need to understand us.&nbsp;</p>\n<p><br />The results of our theoretical and experimental work have provided us with new insights into the components that are critical for robots' decision-making under a human-robot teaming setting. Our results have shown that the awareness of the differences between humans and robots can be essential to maintaining fluent human-robot interaction. The differences can come from senses, knowledge, motivation, and cognition. We focused in this project on the differences in knowledge in a sequential decision-making setting, including explicable planning and explanation generation. However, the proposed research suggests a significant revamp of today's state-of-the-art robotic technologies to prepare them for a teaming capability. In particular, our research on model reconciliation planning contributes uniquely to the paradigm shift that aims to generalize planning methods to real-world domains with humans in the loop. Simultaneously, our preliminary investigation in learning advocates a paradigm shift in the design of such methods to generalize to a human-robot teaming setting. Model reconciliation learning methods bridge an essential gap towards achieving explainable and safe AI and robotics, which will play a critical role in applications involving human-AI and human-robot interactions. The model reconciliation problem is a generalization of the value alignment problem to consider the various differences between humans and robots.&nbsp;</p>\n<p><br />The award also supported training graduate students, integration of research and education, community engagement, and career development.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/26/2021<br>\n\t\t\t\t\tModified by: Yu&nbsp;Zhang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nRobots are an increasingly common presence in human-inhabited environments. As they become more autonomous with advanced planning and learning algorithms built-in, they also become more complex externally from humans' perspectives. Soon, we will no longer view them as simple tools that operate separately and far away from us. Instead, humans and robots in teams will cooperate more integratively and closely as in human-human teams instead of like archipelagos. A key challenge of such robotic technologies is understanding the differences between humans and robots and accommodating them via model reconciliation methods. The corresponding problem is a subproblem of enabling robots to think like us--they only need to understand us. \n\n\nThe results of our theoretical and experimental work have provided us with new insights into the components that are critical for robots' decision-making under a human-robot teaming setting. Our results have shown that the awareness of the differences between humans and robots can be essential to maintaining fluent human-robot interaction. The differences can come from senses, knowledge, motivation, and cognition. We focused in this project on the differences in knowledge in a sequential decision-making setting, including explicable planning and explanation generation. However, the proposed research suggests a significant revamp of today's state-of-the-art robotic technologies to prepare them for a teaming capability. In particular, our research on model reconciliation planning contributes uniquely to the paradigm shift that aims to generalize planning methods to real-world domains with humans in the loop. Simultaneously, our preliminary investigation in learning advocates a paradigm shift in the design of such methods to generalize to a human-robot teaming setting. Model reconciliation learning methods bridge an essential gap towards achieving explainable and safe AI and robotics, which will play a critical role in applications involving human-AI and human-robot interactions. The model reconciliation problem is a generalization of the value alignment problem to consider the various differences between humans and robots. \n\n\nThe award also supported training graduate students, integration of research and education, community engagement, and career development.\n\n\t\t\t\t\tLast Modified: 10/26/2021\n\n\t\t\t\t\tSubmitted by: Yu Zhang"
 }
}