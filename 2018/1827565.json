{
 "awd_id": "1827565",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "PFI-TT: Software for Automated Real-time Electroencephalogram Seizure Detection in Intensive Care Units",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032927795",
 "po_email": "jsoriano@nsf.gov",
 "po_sign_block_name": "Jesus Soriano Molla",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 199999.0,
 "awd_amount": 215999.0,
 "awd_min_amd_letter_date": "2018-07-23",
 "awd_max_amd_letter_date": "2020-03-02",
 "awd_abstract_narration": "The broader impact/commercial potential of this PFI project is that it will lead to improved clinical outcomes for neurological patients in intensive care units (ICUs). Although the data acquired using continuous electroencephalography (EEG) in the ICU is inexpensive to record and a rich source of information for guiding clinical decision making, it is often not used because it takes too long to be analyzed manually. The proposed technology will be capable of evaluating EEGs in real-time in order to alert doctors when clinically relevant events such as seizures occur. This will improve patient outcomes by allowing doctors to intervene with medications in a timelier and more precise fashion. This work will also have the broader impact of improving science's understanding of the fundamentals of how machine learning can be applied specifically to neural signal processing, which is currently a poorly understood area. \r\n\r\nThe proposed project will enable and accelerate the commercialization of software technology that detects seizures and abnormal brain activity in Intensive Care Unit patients. This will be accomplished with three main tasks. In the first task, the existing seizure detection software, which currently works offline, will be converted to work in real-time with a target latency of 20 seconds to detect a seizure. This will be accomplished through intelligent memory handling and by developing a low-latency, highly optimized post-processing algorithm. The second task will strengthen the existing seizure detection code to operate at clinically acceptable levels of sensitivity and false alarm rates. This will be achieved by retraining our algorithms on a significantly more diverse and complex EEG database in order to expose the software to as many variations of seizure presentation as possible. In the third and final task, extensive software testing will be conducted in order to optimize the machine learning configuration that maximizes the gains achieved in Tasks 1 and 2.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Iyad",
   "pi_last_name": "Obeid",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Iyad Obeid",
   "pi_email_addr": "iobeid@temple.edu",
   "nsf_id": "000231883",
   "pi_start_date": "2018-07-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Joseph",
   "pi_last_name": "Picone",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Joseph Picone",
   "pi_email_addr": "joseph.picone@gmail.com",
   "nsf_id": "000301445",
   "pi_start_date": "2018-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Temple University",
  "inst_street_address": "1805 N BROAD ST",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2157077547",
  "inst_zip_code": "191226104",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "PA02",
  "org_lgl_bus_name": "TEMPLE UNIVERSITY-OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "QD4MGHFDJKU1",
  "org_uei_num": "QD4MGHFDJKU1"
 },
 "perf_inst": {
  "perf_inst_name": "Temple University",
  "perf_str_addr": "1947 N 12th St, ENGR 703A",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191226018",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "PA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "166200",
   "pgm_ele_name": "PFI-Partnrships for Innovation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1662",
   "pgm_ref_txt": "PARTNRSHIPS FOR INNOVATION-PFI"
  },
  {
   "pgm_ref_code": "8042",
   "pgm_ref_txt": "Health and Safety"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 199999.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We have developed a high-performance real-time seizure detection system that achieves a performance of 42.05% sensitivity with 5.78 false alarm per 24&nbsp;hours on the development dataset of v1.5.2 of the Temple University Hospital Seizure Detection Corpus (Figures 1-3). The system can easily run in real-time using a single core CPU, operating at 0.58&nbsp;xRT on a 1.7&nbsp;GHz processor in 16&nbsp;Gbytes of memory with a latency of 300&nbsp;msec. This system compares favorably with the best systems evaluated in the Neureka 2020 Epilepsy Challenge (which the PIs co-organized) and is the only system of those that runs in real-time and is suitable for clinical applications.</p>\n<p>Scalp electroencephalogram (EEG) signals inherently have a low signal-to-noise ratio due to the way the signal is electrically transduced. Temporal and spatial information must be exploited to achieve accurate detection of seizure events. Most popular approaches to seizure detection using deep learning focus on modeling temporal or spatial information, but do not jointly model this information. We exploit both simultaneously by converting the multichannel signal to a grayscale image and using transfer learning approaches to achieve high performance. The proposed system is trained end-to-end with only very simple pre- and post-processing operations which are computationally lightweight and have low latency, making them conducive to clinical applications that require real-time processing.</p>\n<p class=\"Default\">We also demonstrated that non-real-time approaches benefitted from separating the seizure detection problem into a two-phase problem &ndash; epileptiform activity detection followed by seizure detection. In the first phase, we used a sequential neural network algorithm known as a long short-term memory (LSTM) network to identify channel-specific epileptiform discharges associated with seizures. In the second phase, the feature vector is augmented with posteriors that represent the onset and offset of ictal activities. These augmented features are applied to a multichannel convolutional neural network (CNN) followed by an LSTM network. The multiphase model was evaluated on a blind evaluation set and was shown to detect &nbsp;segment boundaries within a -second margin of error. Our previous best system, which delivers state-of-the-art performance on this task, correctly detected only 9 segment boundaries. Our multiphase system was also shown to be robust by performing well on two blind evaluation sets. Seizure detection performance on the TU Seizure Detection (TUSZ) Corpus development set is &nbsp;sensitivity with &nbsp;false alarms/&nbsp;hours (FAs/24&nbsp;hrs). Performance on the corresponding evaluation set is &nbsp;sensitivity with &nbsp;FAs/&nbsp;hrs. Performance on a previously unseen corpus, the Duke University Seizure (DUSZ) Corpus is &nbsp;sensitivity with &nbsp;FAs/&nbsp;hrs. Our previous best system yields &nbsp;sensitivity with &nbsp;FAs/&nbsp;hrs on the TUSZ development set, &nbsp;sensitivity with 1&nbsp;FAs/&nbsp;hrs on the TUSZ evaluation set and &nbsp;sensitivity with &nbsp;FAs/&nbsp;hrs on DUSZ. The multiphase system represents our best overall performance for a non-real-time system.</p>\n<p class=\"Default\">Finally, a major goal in this project was to develop deep learning-based architectures that capture spatial and temporal correlations in an EEG signal. We began this activity by developing a variety of architectures based on popular deep learning networks such as LSTMs and CNNs. We demonstrated that performance of a system trained only on Temple University Seizure Corpus (TUSZ) data transfers to a blind evaluation set (DUSZ) and the Emory University Seizure Corpus (EUSZ). This type of generalization is very important since complex high-dimensional deep learning systems tend to overtrain. In clinical settings, we cannot control the ambient recording conditions, so demonstrating an ability to handle previously unseen data is important. We also developed some effective visualization tools to understand exactly what the network is learning and demonstrated that encoding long-term temporal relationships is still a challenging problem. Because of the complexity of these deep learning systems, it is extremely difficult to visualize the internal states of the system and understand what it has learned relative to the problem of interest. The techniques we developed, based on a process where you maximize activations at the input layer and explore the weights of the internal connections based on density maps, are demonstrated in Figure 4.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/27/2021<br>\n\t\t\t\t\tModified by: Joseph&nbsp;Picone</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640639409383_figure_01--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640639409383_figure_01--rgov-800width.jpg\" title=\"An image processing approach to seizure detection\"><img src=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640639409383_figure_01--rgov-66x44.jpg\" alt=\"An image processing approach to seizure detection\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An image processing approach to seizure detection.</div>\n<div class=\"imageCredit\">Joseph Picone</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Joseph&nbsp;Picone</div>\n<div class=\"imageTitle\">An image processing approach to seizure detection</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640639574642_figure_03--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640639574642_figure_03--rgov-800width.jpg\" title=\"An overview of the ResNet-18 architecture\"><img src=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640639574642_figure_03--rgov-66x44.jpg\" alt=\"An overview of the ResNet-18 architecture\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An overview of the ResNet-18 architecture</div>\n<div class=\"imageCredit\">Joseph Picone</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Joseph&nbsp;Picone</div>\n<div class=\"imageTitle\">An overview of the ResNet-18 architecture</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640639728203_figure_02--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640639728203_figure_02--rgov-800width.jpg\" title=\"A typical block in the ResNet-18 architecture\"><img src=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640639728203_figure_02--rgov-66x44.jpg\" alt=\"A typical block in the ResNet-18 architecture\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A typical block in the ResNet-18 architecture</div>\n<div class=\"imageCredit\">Joseph Picone</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Joseph&nbsp;Picone</div>\n<div class=\"imageTitle\">A typical block in the ResNet-18 architecture</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640642624267_figure_04--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640642624267_figure_04--rgov-800width.jpg\" title=\"An example of a network visualization\"><img src=\"/por/images/Reports/POR/2021/1827565/1827565_10560499_1640642624267_figure_04--rgov-66x44.jpg\" alt=\"An example of a network visualization\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The visualization of the first 10 time-distributed filters in our deep learning-based system.</div>\n<div class=\"imageCredit\">Joseph Picone</div>\n<div class=\"imageSubmitted\">Joseph&nbsp;Picone</div>\n<div class=\"imageTitle\">An example of a network visualization</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nWe have developed a high-performance real-time seizure detection system that achieves a performance of 42.05% sensitivity with 5.78 false alarm per 24 hours on the development dataset of v1.5.2 of the Temple University Hospital Seizure Detection Corpus (Figures 1-3). The system can easily run in real-time using a single core CPU, operating at 0.58 xRT on a 1.7 GHz processor in 16 Gbytes of memory with a latency of 300 msec. This system compares favorably with the best systems evaluated in the Neureka 2020 Epilepsy Challenge (which the PIs co-organized) and is the only system of those that runs in real-time and is suitable for clinical applications.\n\nScalp electroencephalogram (EEG) signals inherently have a low signal-to-noise ratio due to the way the signal is electrically transduced. Temporal and spatial information must be exploited to achieve accurate detection of seizure events. Most popular approaches to seizure detection using deep learning focus on modeling temporal or spatial information, but do not jointly model this information. We exploit both simultaneously by converting the multichannel signal to a grayscale image and using transfer learning approaches to achieve high performance. The proposed system is trained end-to-end with only very simple pre- and post-processing operations which are computationally lightweight and have low latency, making them conducive to clinical applications that require real-time processing.\nWe also demonstrated that non-real-time approaches benefitted from separating the seizure detection problem into a two-phase problem &ndash; epileptiform activity detection followed by seizure detection. In the first phase, we used a sequential neural network algorithm known as a long short-term memory (LSTM) network to identify channel-specific epileptiform discharges associated with seizures. In the second phase, the feature vector is augmented with posteriors that represent the onset and offset of ictal activities. These augmented features are applied to a multichannel convolutional neural network (CNN) followed by an LSTM network. The multiphase model was evaluated on a blind evaluation set and was shown to detect  segment boundaries within a -second margin of error. Our previous best system, which delivers state-of-the-art performance on this task, correctly detected only 9 segment boundaries. Our multiphase system was also shown to be robust by performing well on two blind evaluation sets. Seizure detection performance on the TU Seizure Detection (TUSZ) Corpus development set is  sensitivity with  false alarms/ hours (FAs/24 hrs). Performance on the corresponding evaluation set is  sensitivity with  FAs/ hrs. Performance on a previously unseen corpus, the Duke University Seizure (DUSZ) Corpus is  sensitivity with  FAs/ hrs. Our previous best system yields  sensitivity with  FAs/ hrs on the TUSZ development set,  sensitivity with 1 FAs/ hrs on the TUSZ evaluation set and  sensitivity with  FAs/ hrs on DUSZ. The multiphase system represents our best overall performance for a non-real-time system.\nFinally, a major goal in this project was to develop deep learning-based architectures that capture spatial and temporal correlations in an EEG signal. We began this activity by developing a variety of architectures based on popular deep learning networks such as LSTMs and CNNs. We demonstrated that performance of a system trained only on Temple University Seizure Corpus (TUSZ) data transfers to a blind evaluation set (DUSZ) and the Emory University Seizure Corpus (EUSZ). This type of generalization is very important since complex high-dimensional deep learning systems tend to overtrain. In clinical settings, we cannot control the ambient recording conditions, so demonstrating an ability to handle previously unseen data is important. We also developed some effective visualization tools to understand exactly what the network is learning and demonstrated that encoding long-term temporal relationships is still a challenging problem. Because of the complexity of these deep learning systems, it is extremely difficult to visualize the internal states of the system and understand what it has learned relative to the problem of interest. The techniques we developed, based on a process where you maximize activations at the input layer and explore the weights of the internal connections based on density maps, are demonstrated in Figure 4.\n\n \n\n\t\t\t\t\tLast Modified: 12/27/2021\n\n\t\t\t\t\tSubmitted by: Joseph Picone"
 }
}