{
 "awd_id": "1763793",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF:Medium:Collaborative Research:Fine-Grain Multithreading through Hardware/Software Co-Design",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Danella Zhao",
 "awd_eff_date": "2018-07-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 474981.0,
 "awd_amount": 522478.0,
 "awd_min_amd_letter_date": "2018-06-18",
 "awd_max_amd_letter_date": "2021-05-19",
 "awd_abstract_narration": "The supercomputing landscape has fundamentally changed in the past fifteen years. Chips have evolved from single-thread, single-core to multi-threaded, many-core chips. Even mainstream high-performance chips offer close to 100 hardware threads.  At the same time, accelerators, featuring hundreds or even thousands of hardware threads, have allowed scientists to obtain major performance speedups for certain classes of scientific kernels, thanks to their inherent massively parallel nature. From the software side, programming languages can provide a way to create various types of parallelism, from traditional data-parallel constructs to fine-grain, data-driven ones: directives have been added to leverage instruction-level parallelism (ILP), thus allowing the programmer to identify when the code is vectorizable; accelerator-friendly directives allow code to execute on GPUs or the Intel Xeon Phi; finally, new keywords enable the programmer to express task-dependent parallelism. In order to evaluate the hardware-software trade-offs, the investigators plan to design and develop an abstract machine model for scalable parallel and distributed computing, designing and implementing hardware-assisted mechanisms to realize it. Through a broad dissemination of the research findings and tools to the community via conferences and publications, seminars, and a dedicated website, this research has the potential to foster new directions in holistic and comprehensive solutions important to humanity. In addition, the investigators have recently co-founded a Special Technical Community (Parallel Models & Systems) of the IEEE Computer Society with the specific purpose of fostering research and education in the domain across US and the world.\r\n\r\nThis project seeks to develop an asynchronous fine-grain event-driven program execution model, Codelet Abstract Machine model (CAM), for thread management in parallel and distributed systems. The research tasks include three major extensions to a dataflow codelet model, implementing CAM by a hardware/software co-design approach and evaluating it using a set of benchmarks and applications. The proposed FPGA-based prototype is built in combination with general-purpose multicore chips and compiler and runtime system currently under development are designed be part of the system to allow high-level programmers to exploit the resulting system targeted to applications ranging from traditional HPC, parallel graph processing, as well as big data frameworks.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jean-Luc",
   "pi_last_name": "Gaudiot",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jean-Luc Gaudiot",
   "pi_email_addr": "gaudiot@uci.edu",
   "nsf_id": "000465406",
   "pi_start_date": "2018-06-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Irvine",
  "inst_street_address": "160 ALDRICH HALL",
  "inst_street_address_2": "",
  "inst_city_name": "IRVINE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9498247295",
  "inst_zip_code": "926970001",
  "inst_country_name": "United States",
  "cong_dist_code": "47",
  "st_cong_dist_code": "CA47",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA IRVINE",
  "org_prnt_uei_num": "MJC5FCYQTPE6",
  "org_uei_num": "MJC5FCYQTPE6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Irvine",
  "perf_str_addr": "Engineering Hall, #4424",
  "perf_city_name": "Irvine",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "926972625",
  "perf_ctry_code": "US",
  "perf_cong_dist": "47",
  "perf_st_cong_dist": "CA47",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 337805.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 137176.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 47497.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>For this project, we sought to develop new hardware assisted parallelism models to address the challenges in several high-performance areas, such as:</p>\n<ol>\n<li>The high degree of complexity of delivering      parallelism by a purely software approach,</li>\n<li>The low scalability and efficiency of      conventional parallel computing models, </li>\n<li>The high complexity of software and      multi-hardware cooperation, </li>\n<li>The overwhelming energy and power      consumption issues, and</li>\n<li>Artificial intelligence assisted      heterogeneous resource management. </li>\n</ol>\n<p>&nbsp;</p>\n<p>The project has seen the following major outcomes:</p>\n<ol>\n<li>Formally defined the      Sequential Codelet Model -- a Super Codelet Mode, the hierarchical Turing      Machine, the Hierarchical von Neumann Model and the SuperCodelet      Architecture. [Master Thesis of <a href=\"https://www.overleaf.com/project/63211acc568dea0d6ba27246\">Matt      Matusek</a> 2023, Fox et.al. 2023, PhD Thesis of Monsalve Diaz      2021, Monsalve et.al 2022].</li>\n<li>Designed DEMAC-II as a      second version of a low-cost, flexible, scalable, open-source platform for      hardware-software co-design. Define a multi-node, multi-core      infrastructure with distributed memory and no enforced memory model to      test Codelet model runtime applications [Roa et.al. 2023].</li>\n<li>Created the SCMUlate      Emulation infrastructure composed of a runtime, an abstract machine      mapping to commodity architectures, an Application Programming interface,      and a profiling tool.</li>\n<li>Evaluated the SCMUlate      Emulation infrastructure and the SuperCodelet Architecture by means of      microkernels: Vector addition and Matrix Multiplication.</li>\n<li>Created a mathematical      model for calculating the proper size of Codelets at different levels of      the SuperCodelet architecture.</li>\n<li>Master Thesis of <a href=\"https://www.overleaf.com/project/63211acc568dea0d6ba27246\">Matt      Matusek</a> titled: &ldquo;Transparent And Elastic Computing Through The      Adaptive In-Network Codelet Compute Model&rdquo; presented and approved on May      of 2023. </li>\n<li>Defined Dataflow      Software Pipelining for Codelet Model and proposed extension to Codelet      Model to enable it. Extended Codelet Model runtime - DARTS with these      extensions.</li>\n<li>Introduced Codelet Pipe      memory construct as communication channel between producer-consumer      codelets. Realized hardware-software co-designed implementation of Codelet      Pipe using&nbsp; OpenCL for Intel Iris      Pro graphics architecture. </li>\n<li>Implemented      clCodeletPipe API to ease with the programmability as well as to enforce      construction of well behaved codelet graphs. </li>\n<li>Implemented the      distributed runtime (DECARD) as an extension of the existing runtime      (DARTS) to support the execution of programs in a multi-node environment      connected through a network. A github repository has been created to      maintain the code. [Fox et.al. 2023]</li>\n<li>Defined hardware      structures based on the Codelet model to enhance the synergy and      integration of the machine with the codelet model.&nbsp; Assess the viability of hardware      implementations using FPGAs to support the execution of programs described      under the Codelet Model framework. </li>\n</ol> <ol>\n<li>The optimized      online-offline performance prediction model has been integrated into the      Artificial intelligence (AI)-assisted heterogeneous Resource Management to      increase the accuracy of the performance prediction. More ML algorithms      and a new evaluation strategy are integrated into ML models to improve      offline prediction accuracy and reduce&nbsp;      total&nbsp; training time [Geng et      al. IJPP, final version]. </li>\n<li>The optimized      single-node Graph-based dynamic and adaptive Runtime System is implemented      by integrating graph-based services to reduce memory footprint and reduce      total communication cost. </li>\n<li>The integration of      scalable Codelet Graph Model and single-node graph-based Runtime system is      to support both dense and sparse graph workload allocation. </li>\n<li>A new distributed      Heterogeneous Runtime System (DH-DARTS) is designed to support task      scheduling of exascale applications onto multi-nodes. </li>\n<li>All the software has      been uploaded to GitHub</li>\n<li>Produced the PhD thesis      and Dissertation of Nazanin Ghasemian Moghaddam titled: The Effects of      System Characteristics on the Performance of Resource Allocation      Algorithms in a Heterogeneous Environment on 2021</li>\n<li>The model to      examine the collective behavior of concept drift across multiple models      and discerned associations between models that may share a susceptibility      based on their feature views, providing the means for a global drift      detector, has been developed.</li>\n</ol>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/10/2023<br>\n\t\t\t\t\tModified by: Jean-Luc&nbsp;Gaudiot</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nFor this project, we sought to develop new hardware assisted parallelism models to address the challenges in several high-performance areas, such as:\n\nThe high degree of complexity of delivering      parallelism by a purely software approach,\nThe low scalability and efficiency of      conventional parallel computing models, \nThe high complexity of software and      multi-hardware cooperation, \nThe overwhelming energy and power      consumption issues, and\nArtificial intelligence assisted      heterogeneous resource management. \n\n\n \n\nThe project has seen the following major outcomes:\n\nFormally defined the      Sequential Codelet Model -- a Super Codelet Mode, the hierarchical Turing      Machine, the Hierarchical von Neumann Model and the SuperCodelet      Architecture. [Master Thesis of Matt      Matusek 2023, Fox et.al. 2023, PhD Thesis of Monsalve Diaz      2021, Monsalve et.al 2022].\nDesigned DEMAC-II as a      second version of a low-cost, flexible, scalable, open-source platform for      hardware-software co-design. Define a multi-node, multi-core      infrastructure with distributed memory and no enforced memory model to      test Codelet model runtime applications [Roa et.al. 2023].\nCreated the SCMUlate      Emulation infrastructure composed of a runtime, an abstract machine      mapping to commodity architectures, an Application Programming interface,      and a profiling tool.\nEvaluated the SCMUlate      Emulation infrastructure and the SuperCodelet Architecture by means of      microkernels: Vector addition and Matrix Multiplication.\nCreated a mathematical      model for calculating the proper size of Codelets at different levels of      the SuperCodelet architecture.\nMaster Thesis of Matt      Matusek titled: \"Transparent And Elastic Computing Through The      Adaptive In-Network Codelet Compute Model\" presented and approved on May      of 2023. \nDefined Dataflow      Software Pipelining for Codelet Model and proposed extension to Codelet      Model to enable it. Extended Codelet Model runtime - DARTS with these      extensions.\nIntroduced Codelet Pipe      memory construct as communication channel between producer-consumer      codelets. Realized hardware-software co-designed implementation of Codelet      Pipe using  OpenCL for Intel Iris      Pro graphics architecture. \nImplemented      clCodeletPipe API to ease with the programmability as well as to enforce      construction of well behaved codelet graphs. \nImplemented the      distributed runtime (DECARD) as an extension of the existing runtime      (DARTS) to support the execution of programs in a multi-node environment      connected through a network. A github repository has been created to      maintain the code. [Fox et.al. 2023]\nDefined hardware      structures based on the Codelet model to enhance the synergy and      integration of the machine with the codelet model.  Assess the viability of hardware      implementations using FPGAs to support the execution of programs described      under the Codelet Model framework. \n \nThe optimized      online-offline performance prediction model has been integrated into the      Artificial intelligence (AI)-assisted heterogeneous Resource Management to      increase the accuracy of the performance prediction. More ML algorithms      and a new evaluation strategy are integrated into ML models to improve      offline prediction accuracy and reduce       total  training time [Geng et      al. IJPP, final version]. \nThe optimized      single-node Graph-based dynamic and adaptive Runtime System is implemented      by integrating graph-based services to reduce memory footprint and reduce      total communication cost. \nThe integration of      scalable Codelet Graph Model and single-node graph-based Runtime system is      to support both dense and sparse graph workload allocation. \nA new distributed      Heterogeneous Runtime System (DH-DARTS) is designed to support task      scheduling of exascale applications onto multi-nodes. \nAll the software has      been uploaded to GitHub\nProduced the PhD thesis      and Dissertation of Nazanin Ghasemian Moghaddam titled: The Effects of      System Characteristics on the Performance of Resource Allocation      Algorithms in a Heterogeneous Environment on 2021\nThe model to      examine the collective behavior of concept drift across multiple models      and discerned associations between models that may share a susceptibility      based on their feature views, providing the means for a global drift      detector, has been developed.\n\n\n \n\n\t\t\t\t\tLast Modified: 09/10/2023\n\n\t\t\t\t\tSubmitted by: Jean-Luc Gaudiot"
 }
}