{
 "awd_id": "1750575",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: New Paradigms for Online Machine Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2018-03-15",
 "awd_exp_date": "2023-02-28",
 "tot_intn_awd_amt": 550000.0,
 "awd_amount": 550000.0,
 "awd_min_amd_letter_date": "2018-03-15",
 "awd_max_amd_letter_date": "2022-06-24",
 "awd_abstract_narration": "We live in a technology-driven world, where users interact with large-scale, automated systems on a daily basis. Online recommendation systems, search engines and personalized medicine are just a few examples of  systems that use Machine Learning (ML) algorithms at their core. The long term success of ML as a field relies on transforming it into an easily usable, seamless technology with rigorous, provable guarantees on performance. Further, to have a positive impact on society, ML technologies need to be equipped to handle the social challenges that accompany any large multi-user systems. The overarching goal of this CAREER project is to make socially-responsible ML a readily accessible black-box technology that is applicable in large multi-user interactive systems.  In particular, the project focuses on three concrete challenges. The first challenge is to make ML a plug-and-play technology by automating the process of designing task specific ML algorithms. The second challenge is to develop ML methods for modern applications such as predicting user preferences in social networks, where data is evolving and complexly interconnected. The third challenge is to develop theory and algorithms for recommendation systems that are socially responsible and do not polarize its users. \r\n\r\nIn recent years, exploring inherent connections between probability theory and sequential prediction problems have lead to a unifying theory and algorithm design principles for online learning. This CAREER project will build on these developments. Using the so called Burkholder method from probability theory and advances in the field of mathematical programming, the project will aim at automating the process of designing new and effective online learning algorithms. Building on the recently developed idea of online relaxations, the project will introduce novel methodology for designing computationally efficient algorithms for learning from interconnected data points. Finally, using and extending ideas from classical statistics to deal with control and nuisance variables, the project will develop new methods for recommender systems that can avoid polarizing users. The CAREER program will advance STEM education by developing new educational components related to ML. ``Machine Learning for the Masses'' workshops will be co-organized with Women In Computing at Cornell aimed at involving women and underrepresented minorities and exposing undergraduates to research and job opportunities in the field of ML during their formative years.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Karthik",
   "pi_last_name": "Sridharan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Karthik Sridharan",
   "pi_email_addr": "sridharan@cs.cornell.edu",
   "nsf_id": "000678997",
   "pi_start_date": "2018-03-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "107 Hoy Road",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148507501",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 130501.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 134016.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 137540.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 123767.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 24176.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 1\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p class=\"p1\"><span class=\"s1\">Machine Learning (ML) systems are often deployed&nbsp;</span><span class=\"s2\">in large-scale, multi-user,&nbsp;&nbsp;interactive systems, and need to&nbsp;</span><span class=\"s1\">continually update themselves with incoming data. ML systems deployed in such dynamic environment involving&nbsp;</span><span class=\"s2\">interconnected users pose new challenges, both technical and social. The overarching goal of this research project was to develop a plug and play algorithm design framework for online machine learning capable of dealing with interconnected instances and capable of adressing design challengesof building&nbsp; socially responsible ML systems.</span></p>\n<p class=\"p2\"><span class=\"s2\">&nbsp;</span></p>\n<p class=\"p3\"><span class=\"s2\">Technical Outcomes:&nbsp;</span></p>\n<ol class=\"ol1\">\n<li class=\"li4\"><span class=\"s3\">&nbsp;</span><span class=\"s1\">Plug and Play Machine Learning: Designing machine learning methods specific to each task can be a tedious task. One of the main goals of this project&nbsp;</span><span class=\"s2\">was to achieve this level of plug-&amp;-play ability for online machine learning. We would like to design a machine learning system where, once a practitioner specifies the model or hypothesis class to use, a meta algorithm would produce as output a learning algorithm with strong theoretical performance guarantee. The first success of this achieved by the PI along with collaborators was to introduce the so called Burkholder method [1] for design of such meta algorithms. The PI and collaborators in [2] used these general principles to design a generic logistic regression algorithm that for any class of models, using improper learning that obtained doubly exponential improvement over previous best known algorithms with respect to certain problem parameter. Stochastic gradient descent (SGD) has emerged as general purpose ML algorithm. In [8,9] the PI and collaborators provided a general approach for understanding the empirical success of SGD for large dimensional non-convex learning.&nbsp;</span><span class=\"s1\">&nbsp;In [7,10] algorithm desing and theory for Reinforcement Learning (RL) in rich state space setting are considered.&nbsp;</span></li>\n<li class=\"li5\"><span class=\"s2\">Learning from Interconnected Instances:&nbsp;ML algorithms are typically required to make predictions on interconnected input instances. For instance, we might need to make prediction for users that are neighbors in a social network or in RL, some states might share similar features and hence one might obtain similar rewards. Such information is often best represented by a graph explicitly capturing such connections. PI with collaborators considered the feedback graph model to capture this information. In [3] a generic adaptive algorithm that captures the optimal rates from simple so called multi-armed bandit setting to more complicated semi-bandit and contextual bandit settings is considered. In [6] learning under such feedback is extended to the RL setting as well.</span></li>\n<li class=\"li5\"><span class=\"s2\">Socially Responsible Machine Learning:&nbsp;ML systems deployed in the real world have tremendous societal impact. To ensure the impact is positive, one needs to be careful designing ML algorithms. Concerns such as fairness of the ML algorithm for users or vendors that use the system, concerns about polarization of the systems users and other safety concerns need to be addressed right at the initial algorithmic design phase. The works of PI and collaborators in [4,5] provide a general algorithmic framework that can be used to capture general (non-convex) constraints such as fairness constraints&nbsp;in ML algorithms along with generalization.&nbsp;</span></li>\n</ol>\n<p class=\"p3\"><span class=\"s2\">&nbsp;</span></p>\n<p class=\"p3\"><span class=\"s2\">Academic Outcomes:&nbsp;&nbsp;The technical tools and results established in this project have been included in the graduate course of the PI on theoretical machine learning and high level findings are included in lectures of undergraduate course titled Mathematical Foundations of Machine Learning </span>at Cornell University.&nbsp;</p>\n<p class=\"p3\"><span class=\"s2\">&nbsp;</span></p>\n<p class=\"p3\"><span class=\"s2\">Broader Impact:&nbsp;The research outcomes of this project have had broader impact beyond the scope of this project as the tools developed have subsequently been used not only by the PIs but others to tackle various machine learning problems.&nbsp;</span></p>\n<p class=\"p3\"><span class=\"s2\"><br />[1] D. Foster, A. Rakhlin, and K. Sridharan. \"Online Learning: Sufficient Statistics and the Burkholder Method\", COLT,&nbsp;2018.</span></p>\n<p class=\"p3\"><span class=\"s2\">[2]&nbsp;</span><span class=\"s4\">D. Foster, S. Kale, H. Luo, M. Mohri and&nbsp;K. Sridharan. &ldquo;Logistic Regression: The Importance of Being Improper&rdquo;</span><span class=\"s2\">, COLT,&nbsp;2018.</span></p>\n<p class=\"p6\"><span class=\"s2\">[3] T. Lykouris,&nbsp;K. Sridharan and E. Tardos. &ldquo;Small-loss bounds for online learning with partial information&rdquo;</span><span class=\"s1\">, COLT,&nbsp;2018.</span></p>\n<p class=\"p6\">[4]&nbsp;<span class=\"s2\">A. Cotter, H. Jiang and K. Sridharan.</span>&nbsp;&ldquo;<span class=\"s2\">Two-Player Games for Efficient Non-Convex Constrained Optimization&rdquo;, ALT, 2019</span></p>\n<p class=\"p6\">[5]&nbsp;<span class=\"s2\">A. Cotter, M. Gupta, H. Jiang, N. Srebro, K. Sridharan, S. Wang, B. Woodworth and S. You.&nbsp;&ldquo;Training Well-Generalizing Classifiers for Fairness Metrics and Other Data-Dependent Constraints&rdquo;, ICML, 2019.</span></p>\n<p class=\"p6\">[6]&nbsp;<span class=\"s2\">C. Dann, M. Mohri, Y. Mansour, A. Sekhari and K. Sridharan.&nbsp;&ldquo;</span><span class=\"s5\">Reinforcement Learning with Feedback Graphs</span><span class=\"s2\">&rdquo;. NeurIPS, 2020</span></p>\n<p class=\"p6\">[7]&nbsp;<span class=\"s2\">C. Dann, M. Mohri, Y. Mansour, A. Sekhari and K. Sridharan.&nbsp;&ldquo;Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations&rdquo;. NeurIPS, 2021</span></p>\n<p class=\"p6\">[8]&nbsp;<span class=\"s2\">S. Kale, A. Sekhari and K. Sridharan.&nbsp;&ldquo;SGD: The Role of Implicit Regularization, Batch-size and Multiple-epochs&rdquo;. NeurIPS, 2021</span></p>\n<p class=\"p6\">[9]&nbsp;<span class=\"s2\">C. De Sa, S. Kale, J. D. Lee, A. Sekhari, K. Sridharan.&nbsp;&ldquo;From Gradient Flow on Population Loss to Learning with Stochastic Gradient Descent&rdquo; NeurIPS, 2022.&nbsp;</span></p>\n<p class=\"p6\">[10]&nbsp;<span class=\"s2\">D. Foster, A. Rakhlin, A. Sekhari, K. Sridharan.&nbsp;&ldquo;On the Complexity of Adversarial Decision Making&rdquo;, NeurIPS, 2022.</span></p>\n</div>\n</div>\n</div><br>\n<p>\n Last Modified: 02/20/2024<br>\nModified by: Karthik&nbsp;Sridharan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\nMachine Learning (ML) systems are often deployedin large-scale, multi-user,interactive systems, and need tocontinually update themselves with incoming data. ML systems deployed in such dynamic environment involvinginterconnected users pose new challenges, both technical and social. The overarching goal of this research project was to develop a plug and play algorithm design framework for online machine learning capable of dealing with interconnected instances and capable of adressing design challengesof building socially responsible ML systems.\n\n\n\n\n\nTechnical Outcomes:\n\nPlug and Play Machine Learning: Designing machine learning methods specific to each task can be a tedious task. One of the main goals of this projectwas to achieve this level of plug-&-play ability for online machine learning. We would like to design a machine learning system where, once a practitioner specifies the model or hypothesis class to use, a meta algorithm would produce as output a learning algorithm with strong theoretical performance guarantee. The first success of this achieved by the PI along with collaborators was to introduce the so called Burkholder method [1] for design of such meta algorithms. The PI and collaborators in [2] used these general principles to design a generic logistic regression algorithm that for any class of models, using improper learning that obtained doubly exponential improvement over previous best known algorithms with respect to certain problem parameter. Stochastic gradient descent (SGD) has emerged as general purpose ML algorithm. In [8,9] the PI and collaborators provided a general approach for understanding the empirical success of SGD for large dimensional non-convex learning.In [7,10] algorithm desing and theory for Reinforcement Learning (RL) in rich state space setting are considered.\nLearning from Interconnected Instances:ML algorithms are typically required to make predictions on interconnected input instances. For instance, we might need to make prediction for users that are neighbors in a social network or in RL, some states might share similar features and hence one might obtain similar rewards. Such information is often best represented by a graph explicitly capturing such connections. PI with collaborators considered the feedback graph model to capture this information. In [3] a generic adaptive algorithm that captures the optimal rates from simple so called multi-armed bandit setting to more complicated semi-bandit and contextual bandit settings is considered. In [6] learning under such feedback is extended to the RL setting as well.\nSocially Responsible Machine Learning:ML systems deployed in the real world have tremendous societal impact. To ensure the impact is positive, one needs to be careful designing ML algorithms. Concerns such as fairness of the ML algorithm for users or vendors that use the system, concerns about polarization of the systems users and other safety concerns need to be addressed right at the initial algorithmic design phase. The works of PI and collaborators in [4,5] provide a general algorithmic framework that can be used to capture general (non-convex) constraints such as fairness constraintsin ML algorithms along with generalization.\n\n\n\n\n\n\nAcademic Outcomes:The technical tools and results established in this project have been included in the graduate course of the PI on theoretical machine learning and high level findings are included in lectures of undergraduate course titled Mathematical Foundations of Machine Learning at Cornell University.\n\n\n\n\n\nBroader Impact:The research outcomes of this project have had broader impact beyond the scope of this project as the tools developed have subsequently been used not only by the PIs but others to tackle various machine learning problems.\n\n\n\n[1] D. Foster, A. Rakhlin, and K. Sridharan. \"Online Learning: Sufficient Statistics and the Burkholder Method\", COLT,2018.\n\n\n[2]D. Foster, S. Kale, H. Luo, M. Mohri andK. Sridharan. Logistic Regression: The Importance of Being Improper, COLT,2018.\n\n\n[3] T. Lykouris,K. Sridharan and E. Tardos. Small-loss bounds for online learning with partial information, COLT,2018.\n\n\n[4]A. Cotter, H. Jiang and K. Sridharan.Two-Player Games for Efficient Non-Convex Constrained Optimization, ALT, 2019\n\n\n[5]A. Cotter, M. Gupta, H. Jiang, N. Srebro, K. Sridharan, S. Wang, B. Woodworth and S. You.Training Well-Generalizing Classifiers for Fairness Metrics and Other Data-Dependent Constraints, ICML, 2019.\n\n\n[6]C. Dann, M. Mohri, Y. Mansour, A. Sekhari and K. Sridharan.Reinforcement Learning with Feedback Graphs. NeurIPS, 2020\n\n\n[7]C. Dann, M. Mohri, Y. Mansour, A. Sekhari and K. Sridharan.Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations. NeurIPS, 2021\n\n\n[8]S. Kale, A. Sekhari and K. Sridharan.SGD: The Role of Implicit Regularization, Batch-size and Multiple-epochs. NeurIPS, 2021\n\n\n[9]C. De Sa, S. Kale, J. D. Lee, A. Sekhari, K. Sridharan.From Gradient Flow on Population Loss to Learning with Stochastic Gradient Descent NeurIPS, 2022.\n\n\n[10]D. Foster, A. Rakhlin, A. Sekhari, K. Sridharan.On the Complexity of Adversarial Decision Making, NeurIPS, 2022.\n\n\n\t\t\t\t\tLast Modified: 02/20/2024\n\n\t\t\t\t\tSubmitted by: KarthikSridharan\n"
 }
}