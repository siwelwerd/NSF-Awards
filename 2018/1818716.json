{
 "awd_id": "1818716",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Stochastic Methods for Complex Systems",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922113",
 "po_email": "ygorb@nsf.gov",
 "po_sign_block_name": "Yuliya Gorb",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 98134.0,
 "awd_amount": 98134.0,
 "awd_min_amd_letter_date": "2018-07-26",
 "awd_max_amd_letter_date": "2018-07-26",
 "awd_abstract_narration": "This project addresses computational challenges in materials science, chemistry, uncertainty quantification, and related fields.  Quantities of interest such as chemical reaction rates, strength of alloys, and more, can be estimated using a common mathematical modeling framework that computes mean values and provides quantification of the variance about the means.  Estimating these quantities by computer simulation can be particularly challenging when the property that one wishes to study is rare and many repeated computer simulations would be required to estimate the mean value and the variance.  While this challenge is somewhat alleviated by growth in computing power, some simulations, including chemical reaction rates, cannot be addressed via brute force computation.  Rather than rely on raw computing power, the investigators intend to develop novel computer algorithms and approximations that will allow for more efficient and more accurate predictions.  This includes the use of interacting copies of mathematical models, which communicate information between one another, resulting in higher quality estimates.  These algorithms and approximations will allow more faithful prediction of quantities of interest and access to bigger models (such as larger, more complicated molecules).  Mathematically the project will provide a rigorous understanding of the computer algorithms, providing confidence to scientists in a variety of fields. \r\n \r\nMultiscale distributions appear in a variety of applications, including materials science, chemistry, and uncertainty quantification.  Given efficient sampling strategies, one can compute a variety of quantities of interest, including ensemble averages, mean first passage times, and probabilities of rare events.  However, multiscale distributions in high number of dimensions are particularly challenging to sample.  One example is the Boltzmann distribution induced by an energy landscape containing superbasins.  Such a landscape features clusters of local minima that correspond to close groupings of modes in the distribution.  This project will investigate four sampling algorithms: weighted ensemble sampling, parallel replica dynamics, local entropy smoothing, and piecewise deterministic Markov processes.  Weighted ensemble sampling partitions state space into bins and then elects to sample within those bins in an optimal way.  The project will investigate the choice of the sample allocation strategy and consider both finite and infinite system size limits for the method.  Parallel replica dynamics also involves using an ensemble of samples, but, in contrast to weighted ensemble, it uses the replicas to efficiently find first exits out of one metastable region and into another.  Local entropy smoothing removes the superbasin features of the energy landscape by performing local ensemble sampling and averaging.  Finally, the investigators will use piecewise deterministic Markov processes to perform rejection free sampling without requiring estimates of gradients.  These algorithms will be rigorously analyzed, and they will be tested on a variety of realistic high-dimensional problems including chemical reaction networks and stochastic molecular dynamics.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gideon",
   "pi_last_name": "Simpson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gideon Simpson",
   "pi_email_addr": "grs53@drexel.edu",
   "nsf_id": "000632595",
   "pi_start_date": "2018-07-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Drexel University",
  "inst_street_address": "3141 CHESTNUT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158956342",
  "inst_zip_code": "191042875",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "DREXEL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "XF3XM9642N96"
 },
 "perf_inst": {
  "perf_inst_name": "Drexel University",
  "perf_str_addr": "",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191042875",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 98134.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Many complex systems, across a variety of disciplines and applications, require computations on complicated energy landscapes.&nbsp; Physical energy landscapes, which may be thought of as generalizations of topographic maps, can characterize preferentially favorable arrangements of atoms in structures like biological proteins and metal alloys.&nbsp; Synthetic energy landscapes have become an essential tool for contemporary problems in data science, data assimilation, and machine learning, where the artificial energy quantities the amount of misfit between model predictions and available measurements.&nbsp; Here, lower energy corresponds to better agreement between models and data.</p>\n<p>&nbsp;</p>\n<p>Energy landscapes manifest themselves in two ways in computer simulations and computations undertaken for these applications.&nbsp; The first challenge is that of minimization ?&nbsp;efficiently finding the troughs of the landscape.&nbsp; Such minimizers correspond to stable configurations of atoms in physical systems or best predictions in data science problems, given the available measurements.&nbsp; The second challenge is associated with sampling, which is to say, the generation, in the computer, of random samples using a so-called Boltzmann distribution.&nbsp; In this setting, low energy configurations are more likely than high energy ones.&nbsp; This probabilistic (or stochastic) framework allows us to account for the fluctuations of atoms in physical systems and noise in measurements in data science.</p>\n<p>&nbsp;</p>\n<p>In this project, we studied numerical algorithms for efficiently finding minimizers and generating samples.&nbsp; A key concern was to establish, in a mathematically rigorous sense, the validity and optimality of our methods.&nbsp; By providing such a robust basis for the algorithms, scientists, and engineers in other fields, including chemistry, materials science, dynamical systems, mechanics, and uncertainty quantification may use our methods with confidence.&nbsp; Provided their questions are within the scope we have examined, and the methods are properly implemented in software, the outputs will be valid.</p>\n<p>&nbsp;</p>\n<p>As examples of our contributions, we examined Weighted Ensemble, a method for improving the performance of sampling to reduce the variance, a form of error, in averages.&nbsp; Of particular interest for this method is the estimation of chemical reaction rates.&nbsp; In addition to studying the method, we developed a freely available software package to allow individuals to easily use this method.&nbsp; Another sampling challenge we examined was that of rough energy landscapes, which may have a colossal number of local minimizers.&nbsp; Here, we were able to explain why some classical tacts succeed while others fail, and we proposed alternative methods to improve performance.&nbsp; In a data assimilation type problem, were we sought to make inferences of an unknown based on a sequence of noisy measurements, we were able to show that a simple modification, averaging the sequence, of a classical method, called 3DVAR, could make it nearly as optimal as more computationally expensive alternatives.</p>\n<p>&nbsp;</p>\n<p>In addition to solving these mathematical aspects, this project supported the training of two graduate PhD students in mathematics.&nbsp; As part of their work on this project, they were trained in contemporary challenges in computational statistics, data science, and uncertainty quantification, and they have also been exposed to high performance computing, making them ready for professional opportunities in the field of data science.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/18/2022<br>\n\t\t\t\t\tModified by: Gideon&nbsp;Simpson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMany complex systems, across a variety of disciplines and applications, require computations on complicated energy landscapes.  Physical energy landscapes, which may be thought of as generalizations of topographic maps, can characterize preferentially favorable arrangements of atoms in structures like biological proteins and metal alloys.  Synthetic energy landscapes have become an essential tool for contemporary problems in data science, data assimilation, and machine learning, where the artificial energy quantities the amount of misfit between model predictions and available measurements.  Here, lower energy corresponds to better agreement between models and data.\n\n \n\nEnergy landscapes manifest themselves in two ways in computer simulations and computations undertaken for these applications.  The first challenge is that of minimization ? efficiently finding the troughs of the landscape.  Such minimizers correspond to stable configurations of atoms in physical systems or best predictions in data science problems, given the available measurements.  The second challenge is associated with sampling, which is to say, the generation, in the computer, of random samples using a so-called Boltzmann distribution.  In this setting, low energy configurations are more likely than high energy ones.  This probabilistic (or stochastic) framework allows us to account for the fluctuations of atoms in physical systems and noise in measurements in data science.\n\n \n\nIn this project, we studied numerical algorithms for efficiently finding minimizers and generating samples.  A key concern was to establish, in a mathematically rigorous sense, the validity and optimality of our methods.  By providing such a robust basis for the algorithms, scientists, and engineers in other fields, including chemistry, materials science, dynamical systems, mechanics, and uncertainty quantification may use our methods with confidence.  Provided their questions are within the scope we have examined, and the methods are properly implemented in software, the outputs will be valid.\n\n \n\nAs examples of our contributions, we examined Weighted Ensemble, a method for improving the performance of sampling to reduce the variance, a form of error, in averages.  Of particular interest for this method is the estimation of chemical reaction rates.  In addition to studying the method, we developed a freely available software package to allow individuals to easily use this method.  Another sampling challenge we examined was that of rough energy landscapes, which may have a colossal number of local minimizers.  Here, we were able to explain why some classical tacts succeed while others fail, and we proposed alternative methods to improve performance.  In a data assimilation type problem, were we sought to make inferences of an unknown based on a sequence of noisy measurements, we were able to show that a simple modification, averaging the sequence, of a classical method, called 3DVAR, could make it nearly as optimal as more computationally expensive alternatives.\n\n \n\nIn addition to solving these mathematical aspects, this project supported the training of two graduate PhD students in mathematics.  As part of their work on this project, they were trained in contemporary challenges in computational statistics, data science, and uncertainty quantification, and they have also been exposed to high performance computing, making them ready for professional opportunities in the field of data science.\n\n \n\n\t\t\t\t\tLast Modified: 11/18/2022\n\n\t\t\t\t\tSubmitted by: Gideon Simpson"
 }
}