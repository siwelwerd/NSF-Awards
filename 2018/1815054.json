{
 "awd_id": "1815054",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Combining Stochastics and Numerics for Improved Scalable Matrix Computations",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Wei Ding",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2018-08-17",
 "awd_max_amd_letter_date": "2018-08-17",
 "awd_abstract_narration": "Data are often modeled as matrices.  As a result, linear algebraic algorithms, and in particular matrix decompositions, have proven extremely successful in the analysis of datasets in the form of matrices.  RandNLA (Randomized Numerical Linear Algebra), which integrates the complementary perspectives that theoretical computer science and numerical linear algebra bring to matrix computations, has led to nontrivial theory and high-quality implementations, and it has proven useful in a range of scientific and internet applications.  This project will addresses statistical properties of RandNLA algorithms, and how these algorithms are used in downstream convex and non-convex optimization pipelines.  This project will facilitate the development of algorithmic methods for the extraction of knowledge from large genetic, medical, internet, financial, astronomical, and other scientific data sets, and it will also focus on broader interdisciplinary educational opportunities, including undergraduate courses on the mathematics of data science. \r\n\r\nExamples of technical challenges of interest include that the randomness inside the algorithm can lead to implicit regularization, and that it can also lead to usefulness in downstream applications that is not captured by existing theory.  These and other challenges will be addressed in several complementary ways.  First, by developing bootstrapping methods for core RandNLA algorithms.  Second, by developing improved statistical analysis of core RandNLA algorithms.  Third, by developing non-linear leverage scores for more general statistical objectives.  Fourth, by developing methods to combine in a principled manner SGD and RandNLA.  And fifth, by providing implementations addressing scientific data analysis applications, and also by considering longer-term directions of interdisciplinary interest.  In each case, there will be a focus on complementary stochastic and numerical aspects of RandNLA algorithms, as well as on how RandNLA primitives are used in realistic convex and non-convex machine learning pipelines.  This will lead to new insights in algorithmic and statistical theory, as well as more useful algorithms in practical implementations and applications.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Mahoney",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Mahoney",
   "pi_email_addr": "mmahoney@icsi.berkeley.edu",
   "nsf_id": "000661349",
   "pi_start_date": "2018-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "International Computer Science Institute",
  "inst_street_address": "2150 SHATTUCK AVE",
  "inst_street_address_2": "SUITE 250",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106662900",
  "inst_zip_code": "947041345",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "INTERNATIONAL COMPUTER SCIENCE INSTITUTE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GSRMP1QCXU74"
 },
 "perf_inst": {
  "perf_inst_name": "International Computer Science Institute",
  "perf_str_addr": "1947 Center Street Suite 600",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947041105",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Complementary stochastic and numerical aspects of RandNLA (Randomized Numerical Linear Algebra) algorithms, as well as how RandNLA primitives are used in realistic convex and non-convex machine learning pipelines, have been addressed.&nbsp; While RandNLA has been extensively studied in Theoretical Computer Science and Numerical Linear Algebra, leading to nontrivial theory and high-quality implementations, there has (surprisingly) been relatively little analysis of the statistical properties of these algorithms, or of the interplay between statistical properties and numerical aspects of implementations, e.g., how randomness inside the algorithm can lead to implicit regularization in downstream applications.&nbsp; The work involved looking inside the black box of existing RandNLA algorithms to develop, analyze, implement, and apply matrix algorithms that exploit numerical-statistical tradeoffs in novel and more refined ways.&nbsp; This has lead to new insights in algorithmic and statistical theory, as well as more useful algorithms in practical implementations and applications.&nbsp; Results have been obtained in three main areas: revisiting traditional statistical methodologies in light of modern computational demands and constraints; using RandNLA methods in convex and non-convex optimization algorithms to understand the stochastic-numerical interplay between solving primitive linear algebra problems and the corresponding iterative wrapping procedures; and applying these methods on real scientific data.&nbsp; Interdisciplinary education has also been enhanced, as the ideas have been incorporated into graduate and undergraduate teaching; and the development of algorithmic methods for the extraction of knowledge from large genetic, medical, internet, financial, astronomical, and other scientific data sets has been facilitated.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/20/2021<br>\n\t\t\t\t\tModified by: Michael&nbsp;Mahoney</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nComplementary stochastic and numerical aspects of RandNLA (Randomized Numerical Linear Algebra) algorithms, as well as how RandNLA primitives are used in realistic convex and non-convex machine learning pipelines, have been addressed.  While RandNLA has been extensively studied in Theoretical Computer Science and Numerical Linear Algebra, leading to nontrivial theory and high-quality implementations, there has (surprisingly) been relatively little analysis of the statistical properties of these algorithms, or of the interplay between statistical properties and numerical aspects of implementations, e.g., how randomness inside the algorithm can lead to implicit regularization in downstream applications.  The work involved looking inside the black box of existing RandNLA algorithms to develop, analyze, implement, and apply matrix algorithms that exploit numerical-statistical tradeoffs in novel and more refined ways.  This has lead to new insights in algorithmic and statistical theory, as well as more useful algorithms in practical implementations and applications.  Results have been obtained in three main areas: revisiting traditional statistical methodologies in light of modern computational demands and constraints; using RandNLA methods in convex and non-convex optimization algorithms to understand the stochastic-numerical interplay between solving primitive linear algebra problems and the corresponding iterative wrapping procedures; and applying these methods on real scientific data.  Interdisciplinary education has also been enhanced, as the ideas have been incorporated into graduate and undergraduate teaching; and the development of algorithmic methods for the extraction of knowledge from large genetic, medical, internet, financial, astronomical, and other scientific data sets has been facilitated.\n\n\t\t\t\t\tLast Modified: 10/20/2021\n\n\t\t\t\t\tSubmitted by: Michael Mahoney"
 }
}