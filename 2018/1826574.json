{
 "awd_id": "1826574",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Empirical Software Engineering for  Computational  Science",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Stefan Robila",
 "awd_eff_date": "2018-05-01",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 124628.0,
 "awd_amount": 124628.0,
 "awd_min_amd_letter_date": "2018-04-16",
 "awd_max_amd_letter_date": "2018-04-16",
 "awd_abstract_narration": "Science has become increasingly reliant on Computational Science methods implemented in software. These methods are complex, and therefore the software that implements them is prone to errors. This projects seeks to transformatively improve the state of the practice in the development of Computational Science software by applying systematic, data-driven methods (known as empirical methods) to evaluate how software is being developed and to suggest improvements. Improving the software engineering methods of Computational Science would result in higher quality software, and consequently increase our confidence in the research in scientific phenomena conducted by Computational Scientists, \r\n\r\nMuch of the work in Computational Science is related to the software that implements it. In this project, the researcher will apply state of the art empirical software engineering methods to Computational Science software. Qualitative methods will be applied to conduct large scale surveys of computational science. Quantitative data mining tools (classifiers, intelligent data preprocessor, automatic hyperparameter optimizers) will be used to can learn predictive models of time series of SE data such as \"Where in this system should we look for current bugs?\" and \"How many bugs are left on the system?\". These models can be used to guide developer effort in building new code or maintaining old code.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "Menzies",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy J Menzies",
   "pi_email_addr": "timm@ieee.org",
   "nsf_id": "000248284",
   "pi_start_date": "2018-04-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276958206",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "800400",
   "pgm_ele_name": "Software Institutes"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  },
  {
   "pgm_ref_code": "8004",
   "pgm_ref_txt": "Software Institutes"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 124628.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;</p>\n<div>What   (if   anything)   can computational   science   learn from empirical software engineering  (SE)?  Decades  of  empirical   SE   has   found   useful quality assurance methods for Google,  Facebook,  Microsoft-style  software. But   are   such   methods   useful  for  software  that  explores (e.g.) astronomy, astrophysics, chemistry, weather prediction, economics,  genomics,  molecular   biology,    oceanography, physics,  political  science,  and many engineering fields?</div>\n<div>This is an important question.  Computational science is becoming more dependent on software.  For example,  in  2013  a  Nobel  Prize  went  to  chemists  using  computer  models  to  explore  chemical  reactions during  photosynthesis. In  the  press  release  of  the  award,  the  Nobel  Prize  committee  wrote  &ldquo;Today  the</div>\n<div>computer is just as important a tool for chemists as the test tube&rdquo;.</div>\n<div>But building software is hard and building quality software is even harder.  This is especially true in computational science where many software developers have not formally studied computer science or software engineering.  The proposal claims that empirical SE methods can help bridge the skill gap via</div>\n<div>automatic agents that can suggest to developers when (e.g.)  they should redo part of their code. &nbsp;&nbsp;</div>\n<p>&nbsp;</p>\n<div>In this work, we &nbsp;showed that &nbsp;empirical SE quality assurance operators can be applied, usefully, &nbsp;computational science. To ensure scalability, our operators &nbsp;use automatic instruments based on some kind of data mining algorithm.</div>\n<div>&nbsp;</div>\n<div>We found that we had to adjust those instruments to handle the particulars of &nbsp;computational science software. We also found that that tuning was not an arduous or &nbsp; time-consuming process (indeed, it could be done automatically within minimal additional CPU resources). &nbsp;And after&nbsp;tuning,  those quality operators yielded &nbsp;higher performance (e.g. better defect detection) when applied to computational science software.</div>\n<p>&nbsp;</p>\n<p>The above results come from a study&nbsp;&nbsp;of a dozen computational science projects. The next steps are to scale the above results to to far more projects.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/13/2019<br>\n\t\t\t\t\tModified by: Timothy&nbsp;J&nbsp;Menzies</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nWhat   (if   anything)   can computational   science   learn from empirical software engineering  (SE)?  Decades  of  empirical   SE   has   found   useful quality assurance methods for Google,  Facebook,  Microsoft-style  software. But   are   such   methods   useful  for  software  that  explores (e.g.) astronomy, astrophysics, chemistry, weather prediction, economics,  genomics,  molecular   biology,    oceanography, physics,  political  science,  and many engineering fields?\nThis is an important question.  Computational science is becoming more dependent on software.  For example,  in  2013  a  Nobel  Prize  went  to  chemists  using  computer  models  to  explore  chemical  reactions during  photosynthesis. In  the  press  release  of  the  award,  the  Nobel  Prize  committee  wrote  \"Today  the\ncomputer is just as important a tool for chemists as the test tube\".\nBut building software is hard and building quality software is even harder.  This is especially true in computational science where many software developers have not formally studied computer science or software engineering.  The proposal claims that empirical SE methods can help bridge the skill gap via\nautomatic agents that can suggest to developers when (e.g.)  they should redo part of their code.   \n\n \nIn this work, we  showed that  empirical SE quality assurance operators can be applied, usefully,  computational science. To ensure scalability, our operators  use automatic instruments based on some kind of data mining algorithm.\n \nWe found that we had to adjust those instruments to handle the particulars of  computational science software. We also found that that tuning was not an arduous or   time-consuming process (indeed, it could be done automatically within minimal additional CPU resources).  And after tuning,  those quality operators yielded  higher performance (e.g. better defect detection) when applied to computational science software.\n\n \n\nThe above results come from a study  of a dozen computational science projects. The next steps are to scale the above results to to far more projects.\n\n\t\t\t\t\tLast Modified: 08/13/2019\n\n\t\t\t\t\tSubmitted by: Timothy J Menzies"
 }
}