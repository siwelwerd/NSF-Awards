{
 "awd_id": "1815760",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Using Learning Objectives for Visualization Design",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 499747.0,
 "awd_amount": 515747.0,
 "awd_min_amd_letter_date": "2018-08-09",
 "awd_max_amd_letter_date": "2019-05-16",
 "awd_abstract_narration": "There are two main types of information visualizations: those used to find insights, and those used to communicate them. While the communicative form is far more common, most research has focused on the insight-finding type.  This is problematic for designers of communicative visualization who do not have a great set of tools to test if their design goals are being met. Specifically, it is difficult to answer the question: did the viewer of the visualization learn anything from the visualization or did they simply \"read it and forget it?\" Without better ways to describe their specific goals and evaluate success, communicative visualization designers often rely on generic heuristic advice about chart types, encodings, narrative techniques, and other design elements to use.  This project seeks to create methods and tools for helping designers concretely define their goals in terms of learning objectives, as well as tests and tools to determine if the objectives are met. This, in turn, should improve numerical and graphical literacy as well as enhanced understanding of complex information in domains from news to finance. The research will support growing job categories including visualization designers, computational journalists, and data analysts, as well as organizations focused on public communication.  The project activities will also provide research and practical training for undergraduates, graduates, and professionals, while project results will be integrated into accessible educational materials for both visualization-specific classes and as modules for related courses in, e.g., exploratory data analysis, computational journalism, and medical communication.  \r\n\r\nProviding a learning-objective and testing framework for building communicative visualizations requires a deep understanding of how and why designers build their visualizations. Specifically, the goals of this project are (a) developing a learning-objectives \"language\" for describing communicative intent (e.g.,  \"the viewer will be able to describe the different kinds of trends in the price-rent ratio data\"), (b) designing correct and effective testing mechanisms to ensure that these objectives are achieved (e.g., \"Based on the price-rent ratio, which of the following cities is displaying a 'bubble' pattern?\"), and (c) providing tools -- both workflows and software -- to help designers create learning objectives and tests for readers, as well as for the evaluation of their visualizations.  By emphasizing learning objectives for building visualizations, designers will have more confidence that their intended message is communicated by designs that metrics predict will be more successful in communicating that message. Even when no design is optimal across all objectives, the trade-offs will be more salient and easier to understand, allowing designers to make better decisions. Although the focus of this work is on static communicative visualizations for broader public consumption, such as data associated with news stories, the research can be extended to other applications including interactive visualizations, visual analysis systems, explanatory and educational graphics in digital and paper textbooks, and expert-focused forms such as graphics in scientific documents or corporate reports.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eytan",
   "pi_last_name": "Adar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eytan Adar",
   "pi_email_addr": "eadar@umich.edu",
   "nsf_id": "000543609",
   "pi_start_date": "2018-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "3003 South State Street",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091274",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 499747.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The \"Using Learning Objectives for Visualization Design\" grant was a five-year project to help visualization designers better create and evaluate <em>communicative data visualizations</em>. The project sought to address the limitations in conventional design approaches that focused on low-level perceptual features of visualizations rather than designer intents.</p>\n<p>As varied as data visualizations can be, they are largely used for two purposes: exploratory and communicative. Exploratory visualizations are created to answer some questions or to enable decisions. They are often viewed only by the person who created them. Communicative visualizations, which are far more common, are more likely created by one person to be viewed by another. They appear in everything from academic articles to business reports to instructional materials and to sports and weather pages. The intent of the designers creating these can be as varied as where they are used and who their audience is. Unfortunately, deciding if such a visualization is \"good\" is extremely challenging. Conventional measures, used in practice and in academia, often focus on low-level perceptual or cognitive experiments and guidelines. We know that a bar chart is usually better than a pie chart for comparing two pieces of data because it's easier to read the length of a line rather than the angle. This is a good starting point but doesn't say much beyond basic readability. The information can still \"go in one ear (eye, in this case), and out the other.\"&nbsp;</p>\n<p>Our research program has focused on a different way of thinking about communicative visualizations: the designer created them to <em>teach</em> the reader something. What they are teaching might be a specific value (e.g., unemployment levels last quarter) or patterns (e.g., common trend in team's performance in the latter half of the season) or procedures (e.g., how to triage a patient). These are not low-level perceptual problems, so the quality of a communicative visualization needs to be evaluated in a different way. To tackle this, we utilized the language of \"learning objectives,\" a specific framing used by instructors to describe the outcomes they want for their students. For example, \"the reader will recall the unemployment level last quarter,\" or \"the reader will determine the best treatment plan for a patient.\" Starting with existing learning objective frameworks, we produced a taxonomy/language to describe visualization intents. This taxonomy was evaluated by design practitioners and validated and we found it significantly improved reader performance. By clearly specifying the objectives, we showed that it was possible to create \"exams\" (e.g., multiple choice questions) that would tell a designer which of their designs was good and where a design might be lacking.</p>\n<p>Through our early research, we found that \"cognitive\" objectives (remember, understand, analyze, etc.) were not the only type of intent a designer might have. This is because visualizations are inherently not neutral. Whether intentional or not, the designer makes a choice of which data to show and what to emphasize. A visualization published as part of a call for donations is intended to make the reader react emotionally and convince them to believe or act in a certain way (i.e., donate). We call these types of intents \"affective.\" We created a second taxonomy for these types of learning objectives.</p>\n<p>As a final element of this grant, we have focused on creating tools and learning modules to support students and practitioners in their creation of objectives and assessments. For example, we have built software that can semi-automatically create multiple-choice exams to test different visualizations. Our work has generated instructional material to teach novice designers how to think through their creations using the learning objectives framework.&nbsp;</p>\n<p>Researchers and practitioners are adopting both cognitive and affective taxonomies (http://www.visualobjectives.net) as a way of creating, critiquing, and evaluating visualizations. Elements of the work have been published in academic venues such as the IEEE Visualization conference and in practitioner media (e.g., the Data Visualization Society's <em>Nightingale</em> magazine). The grant has supported a number of PhD, masters, and undergrad students in developing research expertise. We have also used materials developed through the grant to teach hundreds of students in our courses and have made the materials available to other instructors. This research has also allowed the research team to develop a number of ongoing collaborations that will allow us to apply and expand our methodology.</p><br>\n<p>\n Last Modified: 05/31/2024<br>\nModified by: Eytan&nbsp;Adar</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1815760/1815760_10568305_1717181642383_revisedafftaxon--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1815760/1815760_10568305_1717181642383_revisedafftaxon--rgov-800width.png\" title=\"Affective Taxonomy\"><img src=\"/por/images/Reports/POR/2024/1815760/1815760_10568305_1717181642383_revisedafftaxon--rgov-66x44.png\" alt=\"Affective Taxonomy\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A taxonomy for describing affective learning objectives for visualization design. The verbs include: observe, place, strengthen, connect, behave and the nouns are: appraisal, attitude, value, and value system.</div>\n<div class=\"imageCredit\">Eytan Adar</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Eytan&nbsp;Adar\n<div class=\"imageTitle\">Affective Taxonomy</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1815760/1815760_10568305_1717181758879_cogtaxon--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1815760/1815760_10568305_1717181758879_cogtaxon--rgov-800width.png\" title=\"Cognitive Taxonomy\"><img src=\"/por/images/Reports/POR/2024/1815760/1815760_10568305_1717181758879_cogtaxon--rgov-66x44.png\" alt=\"Cognitive Taxonomy\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A taxonomy of cognitive visualization objectives based on Bloom's taxonomy. These describe both verbs (remember, understand, apply, analyze, evaluate, and create) and nouns (factual, conceptual, procedural, metacognitive). Source: http://visualobjectives.net/</div>\n<div class=\"imageCredit\">Eytan Adar</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Eytan&nbsp;Adar\n<div class=\"imageTitle\">Cognitive Taxonomy</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe \"Using Learning Objectives for Visualization Design\" grant was a five-year project to help visualization designers better create and evaluate communicative data visualizations. The project sought to address the limitations in conventional design approaches that focused on low-level perceptual features of visualizations rather than designer intents.\n\n\nAs varied as data visualizations can be, they are largely used for two purposes: exploratory and communicative. Exploratory visualizations are created to answer some questions or to enable decisions. They are often viewed only by the person who created them. Communicative visualizations, which are far more common, are more likely created by one person to be viewed by another. They appear in everything from academic articles to business reports to instructional materials and to sports and weather pages. The intent of the designers creating these can be as varied as where they are used and who their audience is. Unfortunately, deciding if such a visualization is \"good\" is extremely challenging. Conventional measures, used in practice and in academia, often focus on low-level perceptual or cognitive experiments and guidelines. We know that a bar chart is usually better than a pie chart for comparing two pieces of data because it's easier to read the length of a line rather than the angle. This is a good starting point but doesn't say much beyond basic readability. The information can still \"go in one ear (eye, in this case), and out the other.\"\n\n\nOur research program has focused on a different way of thinking about communicative visualizations: the designer created them to teach the reader something. What they are teaching might be a specific value (e.g., unemployment levels last quarter) or patterns (e.g., common trend in team's performance in the latter half of the season) or procedures (e.g., how to triage a patient). These are not low-level perceptual problems, so the quality of a communicative visualization needs to be evaluated in a different way. To tackle this, we utilized the language of \"learning objectives,\" a specific framing used by instructors to describe the outcomes they want for their students. For example, \"the reader will recall the unemployment level last quarter,\" or \"the reader will determine the best treatment plan for a patient.\" Starting with existing learning objective frameworks, we produced a taxonomy/language to describe visualization intents. This taxonomy was evaluated by design practitioners and validated and we found it significantly improved reader performance. By clearly specifying the objectives, we showed that it was possible to create \"exams\" (e.g., multiple choice questions) that would tell a designer which of their designs was good and where a design might be lacking.\n\n\nThrough our early research, we found that \"cognitive\" objectives (remember, understand, analyze, etc.) were not the only type of intent a designer might have. This is because visualizations are inherently not neutral. Whether intentional or not, the designer makes a choice of which data to show and what to emphasize. A visualization published as part of a call for donations is intended to make the reader react emotionally and convince them to believe or act in a certain way (i.e., donate). We call these types of intents \"affective.\" We created a second taxonomy for these types of learning objectives.\n\n\nAs a final element of this grant, we have focused on creating tools and learning modules to support students and practitioners in their creation of objectives and assessments. For example, we have built software that can semi-automatically create multiple-choice exams to test different visualizations. Our work has generated instructional material to teach novice designers how to think through their creations using the learning objectives framework.\n\n\nResearchers and practitioners are adopting both cognitive and affective taxonomies (http://www.visualobjectives.net) as a way of creating, critiquing, and evaluating visualizations. Elements of the work have been published in academic venues such as the IEEE Visualization conference and in practitioner media (e.g., the Data Visualization Society's Nightingale magazine). The grant has supported a number of PhD, masters, and undergrad students in developing research expertise. We have also used materials developed through the grant to teach hundreds of students in our courses and have made the materials available to other instructors. This research has also allowed the research team to develop a number of ongoing collaborations that will allow us to apply and expand our methodology.\t\t\t\t\tLast Modified: 05/31/2024\n\n\t\t\t\t\tSubmitted by: EytanAdar\n"
 }
}