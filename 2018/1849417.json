{
 "awd_id": "1849417",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: FND: Scalable, Customizable Sensory Solutions for Dexterous Robotic Hands",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 421727.0,
 "awd_amount": 421727.0,
 "awd_min_amd_letter_date": "2018-08-15",
 "awd_max_amd_letter_date": "2018-08-15",
 "awd_abstract_narration": "This project aims to enhance the sense of touch for robotic hands. The main goal is to develop prosthetic hands with a sense of touch. The touch sensor's primary application is for upper limb amputees. The research team plans both fundamental research and its application. The types of applications of this kind of sensor include: humanoid robots for assistive work and elder-care, surgical robotics, underwater robotic manipulators and spacesuits. Additionally, educational initiatives including internships, training of under-represented minority, and research experiences and summer modules for high school students are planned through the Johns Hopkins Center for Talented Youth. \r\n\r\nThe technical goal of the project is to build a highly scalable sensor design mimicking different tactile receptors in human skins and encode information from the sensors in a manner analogous to the neural activity of the tactile receptors. The sensor will encode the tactile information at multiple scales, firstly based on different receptor properties, and secondly based on neuron-like encoding of the sensor signals. This technique of encoding the neural activity, known as neuromorphic encoding, converts the sensor activity as an event stream, and from that data obtains finer features. The receptor based sensing along with the various neural network algorithms, for the first time, will provide an approach to texture and shape recognition and, as such, can also be useful for intelligent palpation and tactile perception by dexterous robotic hands.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nitish",
   "pi_last_name": "Thakor",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Nitish V Thakor",
   "pi_email_addr": "nthakor@bme.jhu.edu",
   "nsf_id": "000277439",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rahul",
   "pi_last_name": "Kaliki",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Rahul R Kaliki",
   "pi_email_addr": "rahul@i-biomed.com",
   "nsf_id": "000755153",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "3400 N. Charles Street",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182608",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 421727.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project was to do transformative research on tactile perception, modelling the sensors after human skin receptors and neural encoding, and to develop highly relevant and novel solutions for upper limb dexterous prostheses. Our broad goal was to lay the foundation for providing sensory perception to dexterous robotic hands for medical, industrial, and hazardous environments.</p>\n<p>&nbsp;</p>\n<p>The first aim was to develop high density tactile sensor arrays to provide high resolution and efficient information about the environment. Using spatial frequency encoding, we developed flexible asynchronous flexible tactile sensor arrays that use fewer wires and have high spatial and temporal resolution. These developments produce arrays that are more robust and computationally efficient.</p>\n<p>&nbsp;</p>\n<p>The next aim was to model the processing of biological mechanoreceptors with neural encoding algorithms and use those encodings for tactile pattern recognition. Using the textile-based tactile sensor we were able to discriminate between a set of 3 textures. This was done by converting force readings from the sensor array into spiking activity that mimicked the behaviour of slowly adapting (SA) and rapidly adapting (RA) mechanoreceptors. Then, the spiking data was classified using an unsupervised learning algorithm and an adaptation classification algorithm (determining how many textures the data was representing). Additionally, a scalable channel selection algorithm was developed that chose the optimal set of spiking activity for texture classification.</p>\n<p>&nbsp;</p>\n<p>Finally, we wanted to build on this work to instrument a dexterous prosthesis with tactile sensors and neural encoding solutions. We integrated the sensing and algorithms with a pneumatically actuated soft robotic finger to make biomimetic robotic fingers. This complete system was validated both with computational discrimination of texture data and also by using the signals from the finger to provide stimulation patterns to the nerves of able bodied subjects who used the sensory feedback to distinguish the textures as well.</p>\n<p><strong>&nbsp;</strong></p>\n<p class=\"float-left\">In our field, this research demonstrates the utility of combining sensing technologies with biomimetic conformable soft-robotic technology. In this case, the soft-finger was able to successfully discriminate between textures. Secondly, the neuromorphic algorithms will allow for sensing systems to become faster, more power efficient, and more robust to environmental variance. On top of this, it will enable naturalistic sensory feedback to humans. This research provides justification for and a technical basis for the incorporation of soft robotics and neuromorphic engineering in robotic sensory applications.</p>\n<p><strong>&nbsp;</strong></p>\n<p class=\"float-left\">In terms of physical resources, this research will enable robotics to more capably and dexterously interact with the environment because of the sensory information that they will be able to capture. For example, this will enable further robotic autonomy for manufacturing or surgical applications. Additionally, the work on neuromorphic encoding of information to detect texture and shape allows for naturalistic sensory feedback to humans. This can enable new paradigms of human-robot interaction. For instance, a person could teleoperate a robot more effectively through sensory feedback without having to put themselves in physical risk of danger (such as controlling manufacturing equipment).<strong></strong></p>\n<p><strong>&nbsp;</strong></p>\n<p>In terms of socity, this work will have direct impact on the lives of amputees by giving them more autonomy and functionality in their daily lives. The restoration of their ability to naturalistically perceive the world around them will improve their embodiment of the prosthesis (which means they are much more likely to continue to use it) and will improve their ability to control the prosthesis for functional use.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/25/2023<br>\n\t\t\t\t\tModified by: Nitish&nbsp;V&nbsp;Thakor</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this project was to do transformative research on tactile perception, modelling the sensors after human skin receptors and neural encoding, and to develop highly relevant and novel solutions for upper limb dexterous prostheses. Our broad goal was to lay the foundation for providing sensory perception to dexterous robotic hands for medical, industrial, and hazardous environments.\n\n \n\nThe first aim was to develop high density tactile sensor arrays to provide high resolution and efficient information about the environment. Using spatial frequency encoding, we developed flexible asynchronous flexible tactile sensor arrays that use fewer wires and have high spatial and temporal resolution. These developments produce arrays that are more robust and computationally efficient.\n\n \n\nThe next aim was to model the processing of biological mechanoreceptors with neural encoding algorithms and use those encodings for tactile pattern recognition. Using the textile-based tactile sensor we were able to discriminate between a set of 3 textures. This was done by converting force readings from the sensor array into spiking activity that mimicked the behaviour of slowly adapting (SA) and rapidly adapting (RA) mechanoreceptors. Then, the spiking data was classified using an unsupervised learning algorithm and an adaptation classification algorithm (determining how many textures the data was representing). Additionally, a scalable channel selection algorithm was developed that chose the optimal set of spiking activity for texture classification.\n\n \n\nFinally, we wanted to build on this work to instrument a dexterous prosthesis with tactile sensors and neural encoding solutions. We integrated the sensing and algorithms with a pneumatically actuated soft robotic finger to make biomimetic robotic fingers. This complete system was validated both with computational discrimination of texture data and also by using the signals from the finger to provide stimulation patterns to the nerves of able bodied subjects who used the sensory feedback to distinguish the textures as well.\n\n \nIn our field, this research demonstrates the utility of combining sensing technologies with biomimetic conformable soft-robotic technology. In this case, the soft-finger was able to successfully discriminate between textures. Secondly, the neuromorphic algorithms will allow for sensing systems to become faster, more power efficient, and more robust to environmental variance. On top of this, it will enable naturalistic sensory feedback to humans. This research provides justification for and a technical basis for the incorporation of soft robotics and neuromorphic engineering in robotic sensory applications.\n\n \nIn terms of physical resources, this research will enable robotics to more capably and dexterously interact with the environment because of the sensory information that they will be able to capture. For example, this will enable further robotic autonomy for manufacturing or surgical applications. Additionally, the work on neuromorphic encoding of information to detect texture and shape allows for naturalistic sensory feedback to humans. This can enable new paradigms of human-robot interaction. For instance, a person could teleoperate a robot more effectively through sensory feedback without having to put themselves in physical risk of danger (such as controlling manufacturing equipment).\n\n \n\nIn terms of socity, this work will have direct impact on the lives of amputees by giving them more autonomy and functionality in their daily lives. The restoration of their ability to naturalistically perceive the world around them will improve their embodiment of the prosthesis (which means they are much more likely to continue to use it) and will improve their ability to control the prosthesis for functional use.\n\n\t\t\t\t\tLast Modified: 10/25/2023\n\n\t\t\t\t\tSubmitted by: Nitish V Thakor"
 }
}