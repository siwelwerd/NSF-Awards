{
 "awd_id": "1830497",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: FND: Probabilistic Hypothesis-Driven Adaptive Human-Robot Teams",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928074",
 "po_email": "jdonlon@nsf.gov",
 "po_sign_block_name": "James Donlon",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 663869.0,
 "awd_amount": 663869.0,
 "awd_min_amd_letter_date": "2018-08-18",
 "awd_max_amd_letter_date": "2018-08-18",
 "awd_abstract_narration": "Teams of humans and robots working together have the potential to transform search and rescue operations, given the maturation of robotic technology and the ability to task each (human or robot) individually and collaboratively. Example applications include locating survivors or gas leaks after earthquakes or fires, where the safe access for first responders is limited, and locating a chemical/biological release in an urban environment. The disaster response example offers a broad motivational challenge, given the potentially hazardous situations for humans, trapped survivors, fast changing conditions, and communication uncertainties. The key challenge in developing truly efficient and high performing human-robot teams is enabling the team to intelligently reason and act together.  This research project will address this challenge by developing hypothesis-based methods to communicate between humans and robots to enable their collective perception about the environment, and to develop sub-teams and tasks to address the search problem as it evolves. Broader educational impacts include having undergraduate and high school students collaborate with the research team to perform experiments and data collection. Outcomes include open source algorithms and data logs for researchers in the community, and for robotics and controls classes; dissemination through publications, conferences, workshops and NRI meetings; and the inclusion of undergrad and high school students and diversity programs collaborating in the interdisciplinary area of human-robot teaming.\r\n\r\nThe goal of this research project is to develop foundational theory and validated algorithms for human-robot teams which can uniquely operate in, and adapt to, a complex and changing environment, particularly as knowledge of the environment/tasks evolves over time. The technical approach uses a probabilistic hypothesis formulation as a basis to formulate both the Process Inference and Team Forming problems. Formal modeling methods will connect human's natural language to hypotheses of the perception and teaming tasks, thereby allowing humans and robots to communicate efficiently and collaboratively. Hypotheses will be evaluated by the robots for information content using physical and data driven models to capture the processes and sensing. Importantly, both the inference and teaming will evolve as the complex processes evolve. The hypothesis-based approaches and team adaptation will be validated in a series of human-robot search experiments, and scaling will be validated via large scale simulations. The approach also enables the perception and planning to evolve as the scene evolves. This project aims to advance cooperative robot collaboration via human-robot information exchange; the scalability of cooperative robot teams where the team itself adapts over time as information is collected and knowledge is formed; and demonstrate the role for physical embodiment of intelligent systems as human-robot teams address complex applicable models.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Campbell",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Mark E Campbell",
   "pi_email_addr": "mc288@cornell.edu",
   "nsf_id": "000214501",
   "pi_start_date": "2018-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "124 Hoy Rd",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148537501",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 663869.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Teams of humans and robots working together have the potential to transform search and rescue operations, given the maturation of robotic technology and the ability to task each (human or robot) individually and collaboratively. Key challenges exist in the state of the art due to robustness to uncertainty, particularly as the scene evolves over time. The disaster response example offers a broad motivational challenge, given the potentially hazardous situations for humans, trapped survivors, fast changing conditions, and communication uncertainties. This research project developed approaches that directly include probabilistic uncertainty in their formulation, and allow evolution and update over time. Areas of fundamental research included reasoning between humans and robots to enable their collective perception; and development and update of sub-teams and tasks to meet mission goals, particularly as the scene evolves. The following summarizes specific outcomes of the project:</span><span>&nbsp;</span></p>\n<p><strong><span>Multi-Robot Planning:</span></strong><span> A key area of research in this project was path and task planning for multiple, heterogenous robots and humans, where uncertainty in the scene is directly modeled. One contribution was to develop a Mixed-Integer Linear Programming (MILP) optimization solution to the search problem, where a team of robots is deployed in a graph-represented environment to capture a moving target within a given deadline. The approach is the first to encompass multiple searchers, arbitrary capture ranges, and false negatives simultaneously. A second contribution is a graph-based variant for path planning arising in hostile environments, where a robot must reach a given destination while avoiding being intercepted by probabilistic entities which exist in the graph with a given probability and move according to a probabilistic motion pattern. A third contribution is a probabilistic path planning methodology for complex, uncertain scenes where scene attributes and associated uncertainties are inferred, and plans are updated over time. The planner generates path hypotheses, trading between safety and path length to intelligently optimize the best route.</span></p>\n<p><strong><span>Interactive Natural Language between Humans and Robotics:</span></strong><span> The project developed a novel approach using natural language with sensory images to improve applications such as person search and danger avoidance. Specifically, models were developed relating human natural language to scene understanding such as locating a person of interest or characterizing the danger level of a scene. An iterative question-answering strategy was developed to enable robots to request additional information to reduce uncertainty (about the person&rsquo;s appearance or danger level). The questions were ranked in terms of their significance and their length dynamically adjusted based on the model uncertainty of the human-robot interaction. In another contribution, natural language data from firefighters was collected to capture both scene danger and mission priorities. A risk-aware variant of the multi-robot planner then utilized this probabilistic model directly in its formulation in order to account for high-risk locations in the environment when planning the searchers&rsquo; paths. Results enable robots to plan safer yet highly successful search missions, ensuring both searchers&rsquo; and victim safety.</span></p>\n<p><strong><span>Team Forming: </span></strong><span>The project developed a novel approach to team forming and tasking, in the presence of evolving uncertainty. Specifically, the simultaneous task and path allocation problem was formalized by &nbsp;combining concepts from probability and set theory, as well as Markov processes, to propose a mission evolution model capable of capturing a heterogeneous team of agents, probabilistic task knowledge, and spatially distributed tasks in a dynamic environment that changes over time. The model predicts the probabilities of success for different types of tasks while accounting for the viability of each agent&rsquo;s path, scene evolution, task type, and look ahead time-steps.</span></p>\n<p><strong><span>Danger-language-visual dataset:</span></strong><span> The project created a danger-language-visual dataset by leveraging movies to enable multi-modal information fusion, with evaluation based on planning within in simulated search and rescue environments. While there has been a lot of prior work towards improving robot perception and navigation, their application in hazardous environments (e.g. during a fire or an earthquake), is limited. This is partly due to a lack of data in hazardous environments for training and testing, and partly due to the inability to take advantage of the multi-modal data available. The enormous amount of visual content available from movies and TV shows was harnessed to develop a dataset that can represent hazardous environments encountered in the real world. The data is annotated with high-level danger ratings for realistic disaster images, and corresponding keywords are provided that summarize the content of the scene. The dataset was open-sourced to the community.</span></p>\n<p><strong><span>Transition and Training:</span></strong><span> In addition to the generation of algorithms and data, a total of 11 conference/journal papers were published. We open-sourced the danger-language-visual dataset to the community, and for most papers, open-sourced the original code with links within papers. A total of three PhD students were funded under this project, of which two graduated with their PhD degrees. We mentored five undergraduates to support simulation, data collection, and model development.</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/10/2024<br>\nModified by: Mark&nbsp;E&nbsp;Campbell</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nTeams of humans and robots working together have the potential to transform search and rescue operations, given the maturation of robotic technology and the ability to task each (human or robot) individually and collaboratively. Key challenges exist in the state of the art due to robustness to uncertainty, particularly as the scene evolves over time. The disaster response example offers a broad motivational challenge, given the potentially hazardous situations for humans, trapped survivors, fast changing conditions, and communication uncertainties. This research project developed approaches that directly include probabilistic uncertainty in their formulation, and allow evolution and update over time. Areas of fundamental research included reasoning between humans and robots to enable their collective perception; and development and update of sub-teams and tasks to meet mission goals, particularly as the scene evolves. The following summarizes specific outcomes of the project:\n\n\nMulti-Robot Planning: A key area of research in this project was path and task planning for multiple, heterogenous robots and humans, where uncertainty in the scene is directly modeled. One contribution was to develop a Mixed-Integer Linear Programming (MILP) optimization solution to the search problem, where a team of robots is deployed in a graph-represented environment to capture a moving target within a given deadline. The approach is the first to encompass multiple searchers, arbitrary capture ranges, and false negatives simultaneously. A second contribution is a graph-based variant for path planning arising in hostile environments, where a robot must reach a given destination while avoiding being intercepted by probabilistic entities which exist in the graph with a given probability and move according to a probabilistic motion pattern. A third contribution is a probabilistic path planning methodology for complex, uncertain scenes where scene attributes and associated uncertainties are inferred, and plans are updated over time. The planner generates path hypotheses, trading between safety and path length to intelligently optimize the best route.\n\n\nInteractive Natural Language between Humans and Robotics: The project developed a novel approach using natural language with sensory images to improve applications such as person search and danger avoidance. Specifically, models were developed relating human natural language to scene understanding such as locating a person of interest or characterizing the danger level of a scene. An iterative question-answering strategy was developed to enable robots to request additional information to reduce uncertainty (about the persons appearance or danger level). The questions were ranked in terms of their significance and their length dynamically adjusted based on the model uncertainty of the human-robot interaction. In another contribution, natural language data from firefighters was collected to capture both scene danger and mission priorities. A risk-aware variant of the multi-robot planner then utilized this probabilistic model directly in its formulation in order to account for high-risk locations in the environment when planning the searchers paths. Results enable robots to plan safer yet highly successful search missions, ensuring both searchers and victim safety.\n\n\nTeam Forming: The project developed a novel approach to team forming and tasking, in the presence of evolving uncertainty. Specifically, the simultaneous task and path allocation problem was formalized by combining concepts from probability and set theory, as well as Markov processes, to propose a mission evolution model capable of capturing a heterogeneous team of agents, probabilistic task knowledge, and spatially distributed tasks in a dynamic environment that changes over time. The model predicts the probabilities of success for different types of tasks while accounting for the viability of each agents path, scene evolution, task type, and look ahead time-steps.\n\n\nDanger-language-visual dataset: The project created a danger-language-visual dataset by leveraging movies to enable multi-modal information fusion, with evaluation based on planning within in simulated search and rescue environments. While there has been a lot of prior work towards improving robot perception and navigation, their application in hazardous environments (e.g. during a fire or an earthquake), is limited. This is partly due to a lack of data in hazardous environments for training and testing, and partly due to the inability to take advantage of the multi-modal data available. The enormous amount of visual content available from movies and TV shows was harnessed to develop a dataset that can represent hazardous environments encountered in the real world. The data is annotated with high-level danger ratings for realistic disaster images, and corresponding keywords are provided that summarize the content of the scene. The dataset was open-sourced to the community.\n\n\nTransition and Training: In addition to the generation of algorithms and data, a total of 11 conference/journal papers were published. We open-sourced the danger-language-visual dataset to the community, and for most papers, open-sourced the original code with links within papers. A total of three PhD students were funded under this project, of which two graduated with their PhD degrees. We mentored five undergraduates to support simulation, data collection, and model development.\n\n\n\t\t\t\t\tLast Modified: 01/10/2024\n\n\t\t\t\t\tSubmitted by: MarkECampbell\n"
 }
}