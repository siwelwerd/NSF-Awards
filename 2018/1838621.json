{
 "awd_id": "1838621",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SCH: INT: Collaborative Research: Novel Computational Methods for Continuous Objective Multimodal Pain Assessment Sensing System (COMPASS)",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 171560.0,
 "awd_amount": 171560.0,
 "awd_min_amd_letter_date": "2018-09-06",
 "awd_max_amd_letter_date": "2018-09-06",
 "awd_abstract_narration": "Few objective pain assessment techniques are currently available for use in clinical settings. Clinicians typically use subjective pain scales for pain assessment and management, which has resulted in suboptimal treatment plans, delayed responses to patient needs, over-prescription of opioids, and drug-seeking behavior among patients. This project will investigate science-based methods to build a robust Continuous Objective Multimodal Pain Assessment Sensing System (COMPASS) and a clinical interface capable of generating objective measurements of pain from multimodal physiological signals and facial expressions. COMPASS will allow objective measurements that can be used to significantly improve pain assessment, pain management strategies, reduce opioid dependency, and advance the field of pain-related research. The educational plan will include activities to engage patient training, K-12 students, minorities and underrepresented groups, as well as general public. These outcomes will also lead to development of a diverse work force needed to support advanced medical technologies and services.\r\n\r\nUsing advanced biosensing systems, data fusion algorithms and machine learning models, this project will develop a robust, reliable, and accurate pain intensity classification system, COMPASS, for estimating pain intensity experienced by patients in real-time on a 0-10 scale, which is the standard scale used by physicians in clinical settings. In the initial phase of the project, the team will conduct a pilot at Brigham and Women's Hospital to experiment with the different elements for developing the sensing systems and collect data to develop data fusion algorithms and machine learning models. In the later phase of the project, the team will collect an extensive set of data to train and validate the fully implemented COMPASS. Physiological sensor data from electroencephalograph, facial-expression, patient self-reported pain scales, and physician/nurse assessed pain scales will be collected from the subjects as they experience pain modulated by medical therapies that cause patients pain. The project will investigate evidence-based machine learning and feature extraction methods for physiological signals and facial-expression images. This highly interdisciplinary research will make significant contributions to the areas of pain assessment and management, human factors and patient safety.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yan",
   "pi_last_name": "Xiao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yan Xiao",
   "pi_email_addr": "yan.xiao@uta.edu",
   "nsf_id": "000232144",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Arlington",
  "inst_street_address": "701 S NEDDERMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "ARLINGTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "8172722105",
  "inst_zip_code": "760199800",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT ARLINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "LMLUKUPJJ9N3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Arlington",
  "perf_str_addr": "411 S. Nedderman Dr",
  "perf_city_name": "Arlington",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "760190001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  },
  {
   "pgm_ref_code": "8062",
   "pgm_ref_txt": "SCH Type II: INT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 171560.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>About 20% of the US adult population experienced chronic pain. While measurement of human clinical conditions has increasingly been objective and quantitative, pain assessment is nearly exclusively by subjective self-reporting. In this project by three collaborative institutions, we systematically investigated a set of non-invasive bio-sensing modalities to classify levels of pain. Although pain is frequently described as a subjective experience, physiological and emotional expressions are frequently used by professionals and laypersons in assessing pain. We developed a portable data collection system, conducted lab and clinic based experiments using three pain models, assessed accuracy of pain classification algorithm outputs against self-reported levels of pain, and assessed relative accuracies of different modalities and their combination. We also developed an mHealth application to demonstrate the potential of the project in future remote, home based pain assessment and management based on bio-sensors. Among the bio-sensing modalities, facial expression was found to provide a high level of accuracy in classifying levels of pain (about 80% by one measure), if sequential images are used. Electroencephalography (EEG), although more difficult to deploy in comparison to facial expression capture, was found to be highly predictive of pain levels. Several zones and bands of EEG were found to be predictive. Three other modalities (skin conductance, blood volume pulse, and blood pressure) were also found to detect different pain states. Four modalities (pupillary unrest, electromyography, respiration rate, and skin temperature) were found to be less reliable in detecting pain. The project advanced the field of objective pain assessment and provided a basis for using physiological sensors and facial expression as potential &ldquo;digital&rdquo; end-points in therapeutic development and chronic pain management program assessment. The project demonstrated the value of computational and sensor technologies in a measurement that historically has been relying on self-reporting as a gold standard. For those patients who are no able to report, such as infants, cognitively impaired, or in intensive care, such &ldquo;gold-standard&rdquo; methods of pain measurement are not possible. &nbsp;The project also brought valuable education opportunities to Masters and doctoral level students to apply computational techniques to health challenges. The training through this project provided these students with experiences in conducting bio-sensing human subject experiments, some of which were conducted in clinical settings. The project also enabled new partnerships for future computational research. The concepts, methods, and data collected in this project support potential development of non-invasive assessment techniques on human emotion and stress, vital for newer generations of human-computer interfaces and performance supporting technologies. More broadly, chronic pain affects work and daily lives of a large number of adults in the United States and around the world. Under treatment or mistreatment of chronic pain introduce additional societal costs, such as suicide, opioid overdose, and lost productivity. Opioid overdose, for example, is blamed for over 100,000 death each year in the US. As a public health crisis, chronic pain requires innovation in pain assessment beyond solely relying on subjective reporting. Underserved populations are frequently confronted with language and healthcare access barriers. Using subjective reporting methods will likely exacerbate health disparity. Those living in rural area are often limited by how often they can visit with health professionals. Social distancing measures during pandemics introduce barriers to care access. The advances made in this project support development of remote, home-based pain assessment tools, as demonstrated by the m-health application developed in the project. The outcomes of this study could improve patients&rsquo; experience of pain measurement in telehealthcare, especially during a pandemic when most people had to stay at home. With potentially continuous monitoring of pain levels, even remotely, the sensor technology and algorithms developed by the project laid a foundation for assessing pain control objectively with different treatment methods, especially those without opioids.</p>\n<p>@font-face \t{font-family:Helvetica; \tpanose-1:0 0 0 0 0 0 0 0 0 0; \tmso-font-charset:0; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:-536870145 1342208091 0 0 415 0;}@font-face \t{font-family:SimSun; \tpanose-1:2 1 6 0 3 1 1 1 1 1; \tmso-font-alt:&#23435;&#20307;; \tmso-font-charset:134; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:515 680460288 22 0 262145 0;}@font-face \t{font-family:\"Cambria Math\"; \tpanose-1:2 4 5 3 5 4 6 3 2 4; \tmso-font-charset:0; \tmso-generic-font-family:roman; \tmso-font-pitch:variable; \tmso-font-signature:-536870145 1107305727 0 0 415 0;}@font-face \t{font-family:Calibri; \tpanose-1:2 15 5 2 2 2 4 3 2 4; \tmso-font-alt:\"Arial Rounded MT Bold\"; \tmso-font-charset:0; \tmso-generic-font-family:swiss; \tmso-font-pitch:variable; \tmso-font-signature:-536859905 -1073732485 9 0 511 0;}@font-face \t{font-family:\"\\@SimSun\"; \tpanose-1:2 1 6 0 3 1 1 1 1 1; \tmso-font-charset:134; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:515 680460288 22 0 262145 0;}p.MsoNormal, li.MsoNormal, div.MsoNormal \t{mso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-parent:\"\"; \tmargin:0in; \tmso-pagination:widow-orphan; \tfont-size:11.0pt; \tfont-family:\"Calibri\",sans-serif; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:SimSun; \tmso-fareast-theme-font:minor-fareast; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi; \tmso-fareast-language:ZH-CN;}.MsoChpDefault \t{mso-style-type:export-only; \tmso-default-props:yes; \tfont-size:11.0pt; \tmso-ansi-font-size:11.0pt; \tmso-bidi-font-size:11.0pt; \tfont-family:\"Calibri\",sans-serif; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:SimSun; \tmso-fareast-theme-font:minor-fareast; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi; \tmso-font-kerning:0pt; \tmso-ligatures:none; \tmso-fareast-language:ZH-CN;}div.WordSection1 \t{page:WordSection1;}</p><br>\n<p>\n Last Modified: 12/21/2023<br>\nModified by: Yan&nbsp;Xiao</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nAbout 20% of the US adult population experienced chronic pain. While measurement of human clinical conditions has increasingly been objective and quantitative, pain assessment is nearly exclusively by subjective self-reporting. In this project by three collaborative institutions, we systematically investigated a set of non-invasive bio-sensing modalities to classify levels of pain. Although pain is frequently described as a subjective experience, physiological and emotional expressions are frequently used by professionals and laypersons in assessing pain. We developed a portable data collection system, conducted lab and clinic based experiments using three pain models, assessed accuracy of pain classification algorithm outputs against self-reported levels of pain, and assessed relative accuracies of different modalities and their combination. We also developed an mHealth application to demonstrate the potential of the project in future remote, home based pain assessment and management based on bio-sensors. Among the bio-sensing modalities, facial expression was found to provide a high level of accuracy in classifying levels of pain (about 80% by one measure), if sequential images are used. Electroencephalography (EEG), although more difficult to deploy in comparison to facial expression capture, was found to be highly predictive of pain levels. Several zones and bands of EEG were found to be predictive. Three other modalities (skin conductance, blood volume pulse, and blood pressure) were also found to detect different pain states. Four modalities (pupillary unrest, electromyography, respiration rate, and skin temperature) were found to be less reliable in detecting pain. The project advanced the field of objective pain assessment and provided a basis for using physiological sensors and facial expression as potential digital end-points in therapeutic development and chronic pain management program assessment. The project demonstrated the value of computational and sensor technologies in a measurement that historically has been relying on self-reporting as a gold standard. For those patients who are no able to report, such as infants, cognitively impaired, or in intensive care, such gold-standard methods of pain measurement are not possible. The project also brought valuable education opportunities to Masters and doctoral level students to apply computational techniques to health challenges. The training through this project provided these students with experiences in conducting bio-sensing human subject experiments, some of which were conducted in clinical settings. The project also enabled new partnerships for future computational research. The concepts, methods, and data collected in this project support potential development of non-invasive assessment techniques on human emotion and stress, vital for newer generations of human-computer interfaces and performance supporting technologies. More broadly, chronic pain affects work and daily lives of a large number of adults in the United States and around the world. Under treatment or mistreatment of chronic pain introduce additional societal costs, such as suicide, opioid overdose, and lost productivity. Opioid overdose, for example, is blamed for over 100,000 death each year in the US. As a public health crisis, chronic pain requires innovation in pain assessment beyond solely relying on subjective reporting. Underserved populations are frequently confronted with language and healthcare access barriers. Using subjective reporting methods will likely exacerbate health disparity. Those living in rural area are often limited by how often they can visit with health professionals. Social distancing measures during pandemics introduce barriers to care access. The advances made in this project support development of remote, home-based pain assessment tools, as demonstrated by the m-health application developed in the project. The outcomes of this study could improve patients experience of pain measurement in telehealthcare, especially during a pandemic when most people had to stay at home. With potentially continuous monitoring of pain levels, even remotely, the sensor technology and algorithms developed by the project laid a foundation for assessing pain control objectively with different treatment methods, especially those without opioids.\n\n\n@font-face \t{font-family:Helvetica; \tpanose-1:0 0 0 0 0 0 0 0 0 0; \tmso-font-charset:0; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:-536870145 1342208091 0 0 415 0;}@font-face \t{font-family:SimSun; \tpanose-1:2 1 6 0 3 1 1 1 1 1; \tmso-font-alt:&#23435;&#20307;; \tmso-font-charset:134; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:515 680460288 22 0 262145 0;}@font-face \t{font-family:\"Cambria Math\"; \tpanose-1:2 4 5 3 5 4 6 3 2 4; \tmso-font-charset:0; \tmso-generic-font-family:roman; \tmso-font-pitch:variable; \tmso-font-signature:-536870145 1107305727 0 0 415 0;}@font-face \t{font-family:Calibri; \tpanose-1:2 15 5 2 2 2 4 3 2 4; \tmso-font-alt:\"Arial Rounded MT Bold\"; \tmso-font-charset:0; \tmso-generic-font-family:swiss; \tmso-font-pitch:variable; \tmso-font-signature:-536859905 -1073732485 9 0 511 0;}@font-face \t{font-family:\"\\@SimSun\"; \tpanose-1:2 1 6 0 3 1 1 1 1 1; \tmso-font-charset:134; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:515 680460288 22 0 262145 0;}p.MsoNormal, li.MsoNormal, div.MsoNormal \t{mso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-parent:\"\"; \tmargin:0in; \tmso-pagination:widow-orphan; \tfont-size:11.0pt; \tfont-family:\"Calibri\",sans-serif; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:SimSun; \tmso-fareast-theme-font:minor-fareast; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi; \tmso-fareast-language:ZH-CN;}.MsoChpDefault \t{mso-style-type:export-only; \tmso-default-props:yes; \tfont-size:11.0pt; \tmso-ansi-font-size:11.0pt; \tmso-bidi-font-size:11.0pt; \tfont-family:\"Calibri\",sans-serif; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:SimSun; \tmso-fareast-theme-font:minor-fareast; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi; \tmso-font-kerning:0pt; \tmso-ligatures:none; \tmso-fareast-language:ZH-CN;}div.WordSection1 \t{page:WordSection1;}\t\t\t\t\tLast Modified: 12/21/2023\n\n\t\t\t\t\tSubmitted by: YanXiao\n"
 }
}