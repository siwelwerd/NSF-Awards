{
 "awd_id": "1837827",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: NCS-FO: Learning Efficient Visual Representations From Realistic Environments Across Time Scales",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Roger Mailler",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 459047.0,
 "awd_amount": 459047.0,
 "awd_min_amd_letter_date": "2018-07-19",
 "awd_max_amd_letter_date": "2018-07-19",
 "awd_abstract_narration": "Computer vision algorithms examine images and make sense of what these images depict. Current computer vision algorithms  are able to interpret images at the level of a typical middle school student for many image interpretation tasks.  Recent advances in computer vision have led to rapid technological advances which are still unfolding but affect not only the technology industry, but education,  national security and health care. However, these new algorithms are as yet poorly understood and do not describe how natural learners such as a typical middle school student learn to understand the visual world.  This proposal draws together a team of cognitive psychologists, neuroscientists, and computer scientists to develop a new class of algorithms for computer vision inspired by the way people learn.  \r\n\r\nThe key insight of this proposal is that human learners, unlike many leading computer vision techniques, make extensive use of the temporal structure of visual experience to extract structure.  In the real world the image  on the human retina is almost never static.   Changes in eye position and movements of the head and body create a rich and complex temporal structure over a range of scales from hundreds of milliseconds up to days and weeks. This proposal a) develops databases of realistic and dynamically changing images in the real world and in immersive virtual reality environments, b) develops computational models for learning visual representations from temporally structured experiences  and, c) examines the brain structures supporting representations integrating time and space across scales using fMRI. The algorithms pursued in this project are inspired by recent theoretical work in the neuroscience of scale-invariant memory.  However, because the databases will be made publicly available, other researchers will be able to develop other algorithms that exploit temporal and spatial correlations.  Taken together, these efforts are intended to catalyze a new generation of techniques for human-like machine learning algorithms with applications in computer vision.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Per",
   "pi_last_name": "Sederberg",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Per B Sederberg",
   "pi_email_addr": "pbs5u@virginia.edu",
   "nsf_id": "000599927",
   "pi_start_date": "2018-07-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Virginia Main Campus",
  "inst_street_address": "1001 EMMET ST N",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTESVILLE",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "4349244270",
  "inst_zip_code": "229034833",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "VA05",
  "org_lgl_bus_name": "RECTOR & VISITORS OF THE UNIVERSITY OF VIRGINIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJG6HU8PA4S5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Virginia Main Campus",
  "perf_str_addr": "Gilmer Hall",
  "perf_city_name": "Charlottesville",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "229041002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "VA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "798000",
   "pgm_ele_name": "ECR-EDU Core Research"
  },
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "8551",
   "pgm_ref_txt": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0416",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001617DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 459046.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-005669be-7fff-d4ab-f77e-ec49323fafe6\"> </span></p>\n<p dir=\"ltr\"><span>Recent research has demonstrated that the mammalian brain contains \"time cells\" that provide a logarithmically-compressed temporal history of recent experience. In other words, the brain stores information over long temporal scales by harnessing fewer resources to represent events that occurred longer in the past at the cost of being less accurate about when they happened. This project brought together a team of cognitive psychologists, cognitive neuroscientists, and machine-learning researchers to understand how the brain constructs and harnesses this scale invariant representation to support learning (i.e., extracting structure) over a wide range of temporal scales.&nbsp;</span></p>\n<p dir=\"ltr\"><span>The project entailed large-scale data collection of participants exploring visually-complex environments (both in the natural world and in virtual reality) and then providing neural data while being tested on their ability to remember details of their experiences. In parallel, the project team implemented novel computational models that tested the hypothesis that the brain constructs a scale invariant temporal history (SITH) by means of a population of neurons that decay at different rates, creating a Laplace transform of experience. Inverting this Laplace transform gives rise to the time cells observed in a wide range of brain areas. Machine-learning models built with SITH were shown to outperform a simple fixed duration buffer (a common notion of how the brain stores information from the recent past) when tasked with learning to play video games or predict the next word in written text. Larger-scale artificial intelligence models built with multiple SITH layers could perform at or near state of the art in many standard temporal decoding tasks.&nbsp;</span></p>\n<p>Together, these results suggest that logarithmically-spaced representations of experience may underlie many aspects of cognitive processing. Critically, it is possible to extend the Laplace transform of time to other dimensions of experience, such as number, spatial relations, and decision-making, suggesting that the brain could perform a vast array of cognitive operations all via the same simple neural computation based on layers of Laplace transforms. More broadly, the project provided evidence that models built on the SITH representation have the potential to impact a wide range of fields that currently benefit from artificial intelligence, but are limited by memory constraints or failure to generalize.</p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/26/2021<br>\n\t\t\t\t\tModified by: Per&nbsp;B&nbsp;Sederberg</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nRecent research has demonstrated that the mammalian brain contains \"time cells\" that provide a logarithmically-compressed temporal history of recent experience. In other words, the brain stores information over long temporal scales by harnessing fewer resources to represent events that occurred longer in the past at the cost of being less accurate about when they happened. This project brought together a team of cognitive psychologists, cognitive neuroscientists, and machine-learning researchers to understand how the brain constructs and harnesses this scale invariant representation to support learning (i.e., extracting structure) over a wide range of temporal scales. \nThe project entailed large-scale data collection of participants exploring visually-complex environments (both in the natural world and in virtual reality) and then providing neural data while being tested on their ability to remember details of their experiences. In parallel, the project team implemented novel computational models that tested the hypothesis that the brain constructs a scale invariant temporal history (SITH) by means of a population of neurons that decay at different rates, creating a Laplace transform of experience. Inverting this Laplace transform gives rise to the time cells observed in a wide range of brain areas. Machine-learning models built with SITH were shown to outperform a simple fixed duration buffer (a common notion of how the brain stores information from the recent past) when tasked with learning to play video games or predict the next word in written text. Larger-scale artificial intelligence models built with multiple SITH layers could perform at or near state of the art in many standard temporal decoding tasks. \n\nTogether, these results suggest that logarithmically-spaced representations of experience may underlie many aspects of cognitive processing. Critically, it is possible to extend the Laplace transform of time to other dimensions of experience, such as number, spatial relations, and decision-making, suggesting that the brain could perform a vast array of cognitive operations all via the same simple neural computation based on layers of Laplace transforms. More broadly, the project provided evidence that models built on the SITH representation have the potential to impact a wide range of fields that currently benefit from artificial intelligence, but are limited by memory constraints or failure to generalize.\n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 08/26/2021\n\n\t\t\t\t\tSubmitted by: Per B Sederberg"
 }
}