{
 "awd_id": "1814880",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Collaborative Research: Generative Adversarial Privacy: A Data-driven Approach to Guaranteeing Privacy and Utility",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2018-06-18",
 "awd_max_amd_letter_date": "2018-06-18",
 "awd_abstract_narration": "There is a growing need to publish datasets for both public benefit (via data-driven research) and private gains (enterprise data sharing). However, consumer privacy concerns have largely stymied such efforts since large datasets also contain confidential information about participating individuals. This project leverages recent advancements in learning generative models directly from the datasets to introduce a novel framework called generative adversarial privacy (GAP). GAP formalizes adversarial learning as a game between a privatizer that wishes to learn the optimal privacy mechanism and any statistical adversary intent on learning the confidential features. This formalization is crucial to evaluate data-driven approaches against adversaries with strong inferential capabilities. This project will include interactions with Honeywell Labs as well as outreach and dissemination with Stanford industry partners in the electricity and smart cities sector. Outreach programs include exposing middle- and high-school girls to social network privacy challenges at ASU and K-12 teacher training on data science through the Stanford Office of Science Outreach Program.\r\n\r\nThe project will focus on three foundational problems. The first two ensure privacy of confidential features in the published data and involve developing: (i) theoretical limits of the GAP formulation for a large class of loss functions that capture a range of adversarial capabilities; and (ii) convergence guarantees of the proposed GAP model. The third problem focuses on guaranteeing identity privacy via synthetic datasets using a combination of generative models (to generate synthetic data from training data) and classes of statistical adversaries to understand the efficacy of generating synthetic datasets with both utility and privacy guarantees. A key element of this project involves testing on both publicly available datasets as well as proprietary data.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ram",
   "pi_last_name": "Rajagopal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ram Rajagopal",
   "pi_email_addr": "ramr@stanford.edu",
   "nsf_id": "000583877",
   "pi_start_date": "2018-06-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "473 Via Ortega",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943054020",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Enhancing Data Privacy with Generative Adversarial Privacy</p>\n<p>In today's data-driven society, the sharing of datasets is essential for innovation and societal advancement. Whether for public benefit through data-driven research or for private enterprise gains, the availability of large datasets fuels progress. However, privacy concerns have significantly impeded these efforts. Traditional anonymization methods, such as removing personally identifiable information, are no longer sufficient to protect against sophisticated correlation and linkage attacks. While differential privacy offers strong theoretical guarantees, it often results in diminished data utility and increased complexity, making it less practical for real-world applications.</p>\n<p>Our project tackled this critical challenge by introducing a novel framework called <strong>Generative Adversarial Privacy (GAP)</strong>. Leveraging recent advancements in generative models and adversarial learning, GAP offers a data-driven approach that balances privacy and utility more effectively than traditional methods.</p>\n<p>One of our key achievements was the development of GAP for image privacy on mobile devices. We designed a method using autoencoder neural networks within a Generative Adversarial Network (GAN) framework to privatize images directly on devices like smartphones. By adding noise to a compressed representation of an image, we ensured that the transformed image remained realistic while obscuring sensitive attributes such as gender or the presence of glasses. This approach is computationally efficient, making it suitable for devices with limited processing power and battery life.</p>\n<p>We also extended the GAP framework to protect time-series data in energy systems, such as smart meters and electric vehicle charging data. By carefully optimizing the addition of noise to individual load sequences, we preserved the utility of the data for optimizing energy resources while safeguarding consumer privacy. This method addresses a significant barrier in deploying distributed energy resources and demand response programs, promoting fairness across different socio-economic groups.</p>\n<p>To provide a solid theoretical foundation for GAP, we developed its underlying principles under linear transformations. This allowed us to characterize optimal data-releasing mechanisms through convex optimization, bridging the gap between theoretical privacy guarantees and practical implementation. Our work lays the groundwork for future research and development in data privacy.</p>\n<p>Recognizing that traditional GAN training requires centralized data&mdash;which poses privacy risks&mdash;we designed a new algorithm for training GANs using federated learning. Our algorithm enables multiple devices to collaboratively train a model without sharing raw data, ensuring privacy and reducing communication complexity. We demonstrated the effectiveness of this approach on image datasets like MNIST, CIFAR-10, and CelebA.</p>\n<p>The broader impacts of our work are significant. The GAP framework advances data privacy techniques by offering practical solutions for data sharing across various domains, balancing the need for privacy with the utility of data. Our methods are both theoretically sound and practically implementable, contributing meaningfully to the field.</p>\n<p>In critical sectors such as energy systems, applying GAP promotes the adoption of smart grids and renewable energy resources while safeguarding consumer data. In mobile technology, our image privatization techniques enhance user privacy without compromising the functionality of applications that rely on image data.</p>\n<p>The project also provided valuable training and professional development opportunities. Four graduate students and a postdoctoral researcher were involved, gaining hands-on experience and contributing to groundbreaking research. Team members presented their findings at prestigious conferences like the IEEE Conference on Decision and Control and the International Conference on Learning Representations (ICLR), enhancing their professional growth.</p>\n<p>Additionally, we developed a \"Data Thinking\" outreach program for middle and high school students in the Bay Area. The program educates young learners about energy consumption, data analysis, and the importance of data privacy, fostering the next generation of informed citizens and professionals.</p>\n<p>Our research led to several significant publications in refereed journals and conferences, contributing to the academic community's understanding of data privacy. These publications not only disseminate our findings but also inspire further research in the field.</p>\n<p>In conclusion, this project made significant strides in addressing the complex challenge of data privacy in the modern digital landscape. By developing and applying the Generative Adversarial Privacy framework, we provided tools and methodologies that enable secure data sharing without sacrificing utility. Our work advances academic understanding and has practical implications for technology, energy systems, and society at large.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/05/2024<br>\nModified by: Ram&nbsp;Rajagopal</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nEnhancing Data Privacy with Generative Adversarial Privacy\n\n\nIn today's data-driven society, the sharing of datasets is essential for innovation and societal advancement. Whether for public benefit through data-driven research or for private enterprise gains, the availability of large datasets fuels progress. However, privacy concerns have significantly impeded these efforts. Traditional anonymization methods, such as removing personally identifiable information, are no longer sufficient to protect against sophisticated correlation and linkage attacks. While differential privacy offers strong theoretical guarantees, it often results in diminished data utility and increased complexity, making it less practical for real-world applications.\n\n\nOur project tackled this critical challenge by introducing a novel framework called Generative Adversarial Privacy (GAP). Leveraging recent advancements in generative models and adversarial learning, GAP offers a data-driven approach that balances privacy and utility more effectively than traditional methods.\n\n\nOne of our key achievements was the development of GAP for image privacy on mobile devices. We designed a method using autoencoder neural networks within a Generative Adversarial Network (GAN) framework to privatize images directly on devices like smartphones. By adding noise to a compressed representation of an image, we ensured that the transformed image remained realistic while obscuring sensitive attributes such as gender or the presence of glasses. This approach is computationally efficient, making it suitable for devices with limited processing power and battery life.\n\n\nWe also extended the GAP framework to protect time-series data in energy systems, such as smart meters and electric vehicle charging data. By carefully optimizing the addition of noise to individual load sequences, we preserved the utility of the data for optimizing energy resources while safeguarding consumer privacy. This method addresses a significant barrier in deploying distributed energy resources and demand response programs, promoting fairness across different socio-economic groups.\n\n\nTo provide a solid theoretical foundation for GAP, we developed its underlying principles under linear transformations. This allowed us to characterize optimal data-releasing mechanisms through convex optimization, bridging the gap between theoretical privacy guarantees and practical implementation. Our work lays the groundwork for future research and development in data privacy.\n\n\nRecognizing that traditional GAN training requires centralized datawhich poses privacy riskswe designed a new algorithm for training GANs using federated learning. Our algorithm enables multiple devices to collaboratively train a model without sharing raw data, ensuring privacy and reducing communication complexity. We demonstrated the effectiveness of this approach on image datasets like MNIST, CIFAR-10, and CelebA.\n\n\nThe broader impacts of our work are significant. The GAP framework advances data privacy techniques by offering practical solutions for data sharing across various domains, balancing the need for privacy with the utility of data. Our methods are both theoretically sound and practically implementable, contributing meaningfully to the field.\n\n\nIn critical sectors such as energy systems, applying GAP promotes the adoption of smart grids and renewable energy resources while safeguarding consumer data. In mobile technology, our image privatization techniques enhance user privacy without compromising the functionality of applications that rely on image data.\n\n\nThe project also provided valuable training and professional development opportunities. Four graduate students and a postdoctoral researcher were involved, gaining hands-on experience and contributing to groundbreaking research. Team members presented their findings at prestigious conferences like the IEEE Conference on Decision and Control and the International Conference on Learning Representations (ICLR), enhancing their professional growth.\n\n\nAdditionally, we developed a \"Data Thinking\" outreach program for middle and high school students in the Bay Area. The program educates young learners about energy consumption, data analysis, and the importance of data privacy, fostering the next generation of informed citizens and professionals.\n\n\nOur research led to several significant publications in refereed journals and conferences, contributing to the academic community's understanding of data privacy. These publications not only disseminate our findings but also inspire further research in the field.\n\n\nIn conclusion, this project made significant strides in addressing the complex challenge of data privacy in the modern digital landscape. By developing and applying the Generative Adversarial Privacy framework, we provided tools and methodologies that enable secure data sharing without sacrificing utility. Our work advances academic understanding and has practical implications for technology, energy systems, and society at large.\n\n\n\t\t\t\t\tLast Modified: 10/05/2024\n\n\t\t\t\t\tSubmitted by: RamRajagopal\n"
 }
}