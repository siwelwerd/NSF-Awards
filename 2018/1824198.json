{
 "awd_id": "1824198",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Research Coordination Network: Cognitive Functions in the Learning of Symbolic Signals & Systems",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927878",
 "po_email": "slim@nsf.gov",
 "po_sign_block_name": "Soo-Siang Lim",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 538500.0,
 "awd_min_amd_letter_date": "2018-08-15",
 "awd_max_amd_letter_date": "2022-08-04",
 "awd_abstract_narration": "The objective of this Research Coordination Network (RCN) is to advance understanding of how biological systems learn complex symbolic signals, and create artificial systems with similar capabilities. By defining a common framework to describe these signals, and their variability across space and time, the RCN will develop methods and tools applicable to a wide range of domains, including language, music, action, perception, and navigation. The RCN will build upon research in Neuromorphic Engineering and its development of bio-inspired, low-power computing platforms, sensors, and signal processing. Using these tools, the RCN will focus on high-level cognitive functions, to create complex, bio-inspired systems that learn through engagement in tasks. The network will bring together neuroscience, cognitive science, applied mathematics, computer science, and engineering, with emphasis on machine learning and artificial intelligence. Network members will participate in a yearly three-week, hands-on workshop, that will develop and test new tools and ideas, stimulate new collaborations, and educate students on unique interdisciplinary skills. \r\n\r\nThe RCN will facilitate interactions and collaborative projects among participating researchers employing a wide range of paradigms that specifically deal with three thrusts: the role of neural plasticity for learning symbolic systems; the adaptive mechanisms underlying the learning of sensory-motor tasks; and transitioning to real-world applications such as automatic speech and dynamic scene understanding, neuromorphic hardware implementations, cognitive computational algorithms, and databases acquisition. Specific examples of such diverse projects include brain process models that assess learning and expertise; algorithms, based on physiological or abstract events, that process input from neuromorphic hardware; and development of software and neuromorphic hardware for signal interpretation and action execution.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cornelia",
   "pi_last_name": "Fermuller",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Cornelia M Fermuller",
   "pi_email_addr": "fer@cfar.umd.edu",
   "nsf_id": "000235233",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Shihab",
   "pi_last_name": "Shamma",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Shihab A Shamma",
   "pi_email_addr": "sas@isr.umd.edu",
   "nsf_id": "000461861",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ralph",
   "pi_last_name": "Etienne-Cummings",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ralph Etienne-Cummings",
   "pi_email_addr": "retienne@jhu.edu",
   "nsf_id": "000360105",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "3112 Lee Bldg 7809 Regents Drive",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425103",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "004Y00",
   "pgm_ele_name": "Science of Learning"
  },
  {
   "pgm_ele_code": "058Y00",
   "pgm_ele_name": "M3X - Mind, Machine, and Motor"
  },
  {
   "pgm_ele_code": "127Y00",
   "pgm_ele_name": "Sci of Lrng & Augmented Intel"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "070E",
   "pgm_ref_txt": "INTEG OF HUMAN & COGNITIVE"
  },
  {
   "pgm_ref_code": "059Z",
   "pgm_ref_txt": "Science of Learning"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 500000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 22500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Research Coordination Network: </strong></p>\n<p class=\"Default\"><strong>Cognitive Functions in the Learning of Symbolic Signals &amp; Systems</strong><strong> </strong></p>\n<p class=\"Default\">This Research Coordination Network (RCN) funded research collaborations that investigated how biological systems learn complex spatiotemporal symbolic signals in time and how to create artificial systems with similar capabilities. It introduced new frameworks to learn from spatiotemporal signals and developed common methods and tools that are applicable to a wide range of domains previously studied separately, including language and music perception, action perception and execution, and perception for navigation. The RCN built upon two decades of research in the field of Neuromorphic Engineering and its development of bio-inspired, low-power computing platforms, sensors, and signal processing engines. To further advance the field, the network brought together neuroscience, cognitive science, applied mathematics, computer science and engineering to bridge the gap between insights from biological sciences and recent developments in machine learning and software engineering.&nbsp; Over its four-year duration the project funded two working groups and an annual three-week, hands-on workshop, which was held twice physically, and twice remotely. &nbsp;The workshop allowed to engage the involvement of the interdisciplinary research community and to educate students on unique interdisciplinary skills.&nbsp;&nbsp;</p>\n<p class=\"Default\">Next three promising frameworks arising from the collaboration are described.</p>\n<p>A framework for modeling observed human actions at multiple timescales using a rule-based, compositional modeling based on motion primitives was developed. Building on studies in industrial psychology that analyzed the movements of workers, a set of action primitives was identified that uniquely describe any action. These are then combined into more complex actions and further into sequences constituting activities. The description allows introducing constraints over the sequences of action primitives, which aids knowledge for resolving inconsistent interpretation and temporal prediction. In the approach, high-level actions are grounded in atomic actions which are in turn grounded in the video. Thus, the approach points to a way of closing the gap between symbols and signals, and a general methodology for describing spatiotemporal signals.</p>\n<p>The framework of Hyperdimensional (HD) computing, a brain-inspired machine learning paradigm that can transform data into knowledge at very low cost, was adopted by the neuromorphic community. HD computing encodes the raw data into high-dimensional vectors, and processing the data requires simple arithmetic operations, all of which are easy to accelerate in hardware making it an attractive tool for edge applications. &nbsp;Most important for neuromorphic engineering, HD and related approaches known as Vector Symbolic Architectures (VSA) allow the integration of heterogenous signals, and provide a way to integrate perception, action and cognition and create memories of combined representations of different modalities. Thus, HD and VSAs lend themselves as unifying tool for complex signal representation.</p>\n<p>A framework for the learning of sensorimotor tasks inspired by sensorimotor neural interactions in the human cortical speech system was proposed. It was implemented in a neural architecture called MirrorNet, a constrained autoencoder architecture consisting of a forward and a backward module. The forward module provides predictive signals for anticipating actions and their consequences during performance and the backward module learns in an unsupervised way the inverse mapping relating perceptual features to motor parameters. MirrorNet was demonstrated on a range of auditory tasks both to explain neuroscience and in algorithmic solutions, and it promises to be a universal tool to discover from sensory data the controls of arbitrary motor-plants.</p>\n<p>The Research Coordination network and prior NSF funding for the Neuromorphic Cognition Workshop have been a major force in advancing the field of Neuromorphic Engineering. In recent years many new neuromorphic hardware and accompanying software solutions have emerged that allow rather complex signal processing applications and tasks involving sensory motor integration to run efficiently at comparable performance to state of the art, but a much lower power consumption. By now the work has extended from academic environments to industry, with large companies investing in spiking hardware and processing, and multiple small companies creating neuromorphic hardware. Most of these works trace their origin to the Workshop sponsored by NSF, and they have been collaborating and supporting the RCN.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/03/2022<br>\n\t\t\t\t\tModified by: Cornelia&nbsp;M&nbsp;Fermuller</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nResearch Coordination Network: \nCognitive Functions in the Learning of Symbolic Signals &amp; Systems \nThis Research Coordination Network (RCN) funded research collaborations that investigated how biological systems learn complex spatiotemporal symbolic signals in time and how to create artificial systems with similar capabilities. It introduced new frameworks to learn from spatiotemporal signals and developed common methods and tools that are applicable to a wide range of domains previously studied separately, including language and music perception, action perception and execution, and perception for navigation. The RCN built upon two decades of research in the field of Neuromorphic Engineering and its development of bio-inspired, low-power computing platforms, sensors, and signal processing engines. To further advance the field, the network brought together neuroscience, cognitive science, applied mathematics, computer science and engineering to bridge the gap between insights from biological sciences and recent developments in machine learning and software engineering.  Over its four-year duration the project funded two working groups and an annual three-week, hands-on workshop, which was held twice physically, and twice remotely.  The workshop allowed to engage the involvement of the interdisciplinary research community and to educate students on unique interdisciplinary skills.  \nNext three promising frameworks arising from the collaboration are described.\n\nA framework for modeling observed human actions at multiple timescales using a rule-based, compositional modeling based on motion primitives was developed. Building on studies in industrial psychology that analyzed the movements of workers, a set of action primitives was identified that uniquely describe any action. These are then combined into more complex actions and further into sequences constituting activities. The description allows introducing constraints over the sequences of action primitives, which aids knowledge for resolving inconsistent interpretation and temporal prediction. In the approach, high-level actions are grounded in atomic actions which are in turn grounded in the video. Thus, the approach points to a way of closing the gap between symbols and signals, and a general methodology for describing spatiotemporal signals.\n\nThe framework of Hyperdimensional (HD) computing, a brain-inspired machine learning paradigm that can transform data into knowledge at very low cost, was adopted by the neuromorphic community. HD computing encodes the raw data into high-dimensional vectors, and processing the data requires simple arithmetic operations, all of which are easy to accelerate in hardware making it an attractive tool for edge applications.  Most important for neuromorphic engineering, HD and related approaches known as Vector Symbolic Architectures (VSA) allow the integration of heterogenous signals, and provide a way to integrate perception, action and cognition and create memories of combined representations of different modalities. Thus, HD and VSAs lend themselves as unifying tool for complex signal representation.\n\nA framework for the learning of sensorimotor tasks inspired by sensorimotor neural interactions in the human cortical speech system was proposed. It was implemented in a neural architecture called MirrorNet, a constrained autoencoder architecture consisting of a forward and a backward module. The forward module provides predictive signals for anticipating actions and their consequences during performance and the backward module learns in an unsupervised way the inverse mapping relating perceptual features to motor parameters. MirrorNet was demonstrated on a range of auditory tasks both to explain neuroscience and in algorithmic solutions, and it promises to be a universal tool to discover from sensory data the controls of arbitrary motor-plants.\n\nThe Research Coordination network and prior NSF funding for the Neuromorphic Cognition Workshop have been a major force in advancing the field of Neuromorphic Engineering. In recent years many new neuromorphic hardware and accompanying software solutions have emerged that allow rather complex signal processing applications and tasks involving sensory motor integration to run efficiently at comparable performance to state of the art, but a much lower power consumption. By now the work has extended from academic environments to industry, with large companies investing in spiking hardware and processing, and multiple small companies creating neuromorphic hardware. Most of these works trace their origin to the Workshop sponsored by NSF, and they have been collaborating and supporting the RCN.\n\n \n\n\t\t\t\t\tLast Modified: 11/03/2022\n\n\t\t\t\t\tSubmitted by: Cornelia M Fermuller"
 }
}