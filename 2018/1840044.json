{
 "awd_id": "1840044",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FW-HTF: First Person View and Augmented Reality for Airborne Embodied Intelligent Cognitive Assistants",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 1500000.0,
 "awd_amount": 1500000.0,
 "awd_min_amd_letter_date": "2018-08-31",
 "awd_max_amd_letter_date": "2021-05-27",
 "awd_abstract_narration": "The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim. \r\n\r\nThe future of work will involve human operators and semi-autonomous robotic systems. Human workers control the robots, extending their sensing and physical capabilities. This technology-empowered workforce will do remote, dangerous, and increasingly specialized work. An example use of this work might be the inspection of hard-to-access bridge supports. This project will explore the use of intelligent airborne drones to help ground-based operators in the inspection of highway bridges. Through the careful integration of augmented reality (AR) with first-person-view (FPV) operator interfaces this research will enhance worker performance across a wide range of otherwise very difficult tasks. \r\n\r\nThe research program will address key challenges in the use of embodied intelligent cognitive assistants (e-ICAs) for infrastructure inspection. New principles of shared situation awareness will be developed for human/robot collaboration through AR/FPV user interfaces and these principles will inform interface design guidelines and evaluation measures. The research program will also emphasize collaborative perception and planning, such as peripheral/central computer vision to enhance shared situation awareness, gaze-informed adaptive viewpoint planning for improved image quality, and a global planning method for partially known and uncertain maps that adapts the plan in real-time as the worker discovers new information. Tunable control system performance will allow the worker and the e-ICA to collaborate in managing disturbance energy to optimize mission data quality and flight endurance while ensuring safety of flight. The parallel development of a public repository containing annotated deterioration imagery will support artificial intelligence based defect analytics to provide the human worker with real-time inspection cues. A parallel and coordinated economic and workforce analysis will assess the impact of airborne e-ICAs, controlled using FPV with augmented reality, on the future of work in infrastructure inspection and beyond.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Craig",
   "pi_last_name": "Woolsey",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Craig Woolsey",
   "pi_email_addr": "cwoolsey@vt.edu",
   "nsf_id": "000258419",
   "pi_start_date": "2018-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Joseph",
   "pi_last_name": "Gabbard",
   "pi_mid_init": "L",
   "pi_sufx_name": "Jr",
   "pi_full_name": "Joseph L Gabbard",
   "pi_email_addr": "jgabbard@vt.edu",
   "nsf_id": "000356087",
   "pi_start_date": "2018-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Pratap",
   "pi_last_name": "Tokekar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pratap Tokekar",
   "pi_email_addr": "tokekar@umd.edu",
   "nsf_id": "000703094",
   "pi_start_date": "2018-08-31",
   "pi_end_date": "2020-03-27"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Hebdon",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew H Hebdon",
   "pi_email_addr": "mhebdon@vt.edu",
   "nsf_id": "000780371",
   "pi_start_date": "2018-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Polytechnic Institute and State University",
  "inst_street_address": "300 TURNER ST NW",
  "inst_street_address_2": "STE 4200",
  "inst_city_name": "BLACKSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "5402315281",
  "inst_zip_code": "240603359",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "VA09",
  "org_lgl_bus_name": "VIRGINIA POLYTECHNIC INSTITUTE & STATE UNIVERSITY",
  "org_prnt_uei_num": "X6KEFGLHSJX7",
  "org_uei_num": "QDE5UHE5XD16"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Polytechnic Institute and State University",
  "perf_str_addr": "",
  "perf_city_name": "Blacksburg",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "240610001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "VA09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "082y00",
   "pgm_ele_name": "FW-HTF-Adv Cogn & Phys Capblty"
  },
  {
   "pgm_ele_code": "082Y00",
   "pgm_ele_name": "FW-HTF-Adv Cogn & Phys Capblty"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 1500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Motivated by the challenges of developing augmented reality/first person view (AR/FPV) enabled aerial robots to assist bridge inspectors, this project involved developing and validating fundamental principles concerning shared situation awareness; methods for quickly planning efficient global and local paths; worker-responsive adaptive visual perception; variable-performance stability augmentation for aerial robots; and defect analytics to improve the efficiency and effectiveness with which human workers may assess the health of civil infrastructure. Project research outcomes include new principles of shared situation awareness that inform interface design; new path planning methods adapted to inspecting a complex structure; new control design methods that ensure safe, controlled flight of aerial robots; new computer vision and delay mitigation methods to improve operator performance when using telerobotic interfaces; and new concepts for damage detection and prediction that support human workers inspecting civil infrastructure. Beyond the advancement of theory and technology to enable safer, more efficient and effective inspection of civil infrastructure, the program involved economic and workforce analysis of the potential for AR/FPV and aerial robots to support or disrupt existing industries and economies; engagement with a team of industry and government stakeholders; development of Quadditch, an FPV drone competition that is a scaffold for STEM outreach, education, and research; the creation or amendment of engineering courses on Ethics and Autonomous Systems, Steel Bridge Design, and Visual Displays; and the mentorship of four doctoral students and dozens of undergraduate students.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/03/2023<br>\n\t\t\t\t\tModified by: Craig&nbsp;Woolsey</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1840044/1840044_10578987_1672758915347_ARFPVInspection--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1840044/1840044_10578987_1672758915347_ARFPVInspection--rgov-800width.jpg\" title=\"ARFPV Bridge Inspection\"><img src=\"/por/images/Reports/POR/2023/1840044/1840044_10578987_1672758915347_ARFPVInspection--rgov-66x44.jpg\" alt=\"ARFPV Bridge Inspection\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Composite image comprising a bridge inspector using an AR/FPV interface and a bridge being imaged by an aerial robot.</div>\n<div class=\"imageCredit\">Jared Van Dam</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Craig&nbsp;Woolsey</div>\n<div class=\"imageTitle\">ARFPV Bridge Inspection</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1840044/1840044_10578987_1672759016955_ConditionStatePredictions--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1840044/1840044_10578987_1672759016955_ConditionStatePredictions--rgov-800width.jpg\" title=\"Bridge condition state predictions\"><img src=\"/por/images/Reports/POR/2023/1840044/1840044_10578987_1672759016955_ConditionStatePredictions--rgov-66x44.jpg\" alt=\"Bridge condition state predictions\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Composite image showing several examples of damage to a bridge as well as superimposed condition state predictions.</div>\n<div class=\"imageCredit\">Eric Bianchi</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Craig&nbsp;Woolsey</div>\n<div class=\"imageTitle\">Bridge condition state predictions</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1840044/1840044_10578987_1672759592715_QuadditchScreenshot--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1840044/1840044_10578987_1672759592715_QuadditchScreenshot--rgov-800width.jpg\" title=\"Quadditch Screenshot\"><img src=\"/por/images/Reports/POR/2023/1840044/1840044_10578987_1672759592715_QuadditchScreenshot--rgov-66x44.jpg\" alt=\"Quadditch Screenshot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Screen capture from the Quadditch operator interface showing the georectified goal along with the possession indicator and scoreboard.</div>\n<div class=\"imageCredit\">Matthew Foran</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Craig&nbsp;Woolsey</div>\n<div class=\"imageTitle\">Quadditch Screenshot</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nMotivated by the challenges of developing augmented reality/first person view (AR/FPV) enabled aerial robots to assist bridge inspectors, this project involved developing and validating fundamental principles concerning shared situation awareness; methods for quickly planning efficient global and local paths; worker-responsive adaptive visual perception; variable-performance stability augmentation for aerial robots; and defect analytics to improve the efficiency and effectiveness with which human workers may assess the health of civil infrastructure. Project research outcomes include new principles of shared situation awareness that inform interface design; new path planning methods adapted to inspecting a complex structure; new control design methods that ensure safe, controlled flight of aerial robots; new computer vision and delay mitigation methods to improve operator performance when using telerobotic interfaces; and new concepts for damage detection and prediction that support human workers inspecting civil infrastructure. Beyond the advancement of theory and technology to enable safer, more efficient and effective inspection of civil infrastructure, the program involved economic and workforce analysis of the potential for AR/FPV and aerial robots to support or disrupt existing industries and economies; engagement with a team of industry and government stakeholders; development of Quadditch, an FPV drone competition that is a scaffold for STEM outreach, education, and research; the creation or amendment of engineering courses on Ethics and Autonomous Systems, Steel Bridge Design, and Visual Displays; and the mentorship of four doctoral students and dozens of undergraduate students.\n\n\t\t\t\t\tLast Modified: 01/03/2023\n\n\t\t\t\t\tSubmitted by: Craig Woolsey"
 }
}