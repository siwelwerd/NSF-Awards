{
 "awd_id": "1762363",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF: Medium: Collaborative Research: Computer-Aided Programming for Data Science",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922585",
 "po_email": "pprabhak@nsf.gov",
 "po_sign_block_name": "Pavithra Prabhakar",
 "awd_eff_date": "2018-06-01",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2018-04-23",
 "awd_max_amd_letter_date": "2021-08-20",
 "awd_abstract_narration": "The goal of this project, named DataWizard, is to dramatically simplify the effort that is currently required for data analytics through the use of computer-aided programming. Specifically, this project aims to semi-automate data collection, querying, and wrangling tasks by automatically generating programs from informal specifications. As a result, the DataWizard project will allow domain scientists to focus on more interesting data analytics and visualization tasks, leaving the \"grunt work\" of data science to computer-aided programming tools. The project will also advance the state-of-the-art in automated program synthesis and natural language processing and apply these techniques to the burgeoning field of big data analytics. \r\n\r\nFrom a technical perspective, the goals of the DataWizard project are three-fold. First, this project develops novel programming-by-example and information extraction techniques to address challenges that arise in data collection, including consolidation of different data sources, transformations between hierarchical and relational data, and extraction of information from unstructured data sources. Second, this project explores new techniques for querying data using natural language descriptions. In particular, this project considers data extraction from relational and noSQL databases as well as semi-structured data sources, such as XML and JSON. Third, this project develops novel program synthesis methods for automating data wrangling, cleaning, and imputation tasks that commonly arise in data analytics. Overall, these techniques  make it significantly easier for data scientists to gain insights from messy data.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ruben",
   "pi_last_name": "Goncalves Martins",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ruben Goncalves Martins",
   "pi_email_addr": "rubenm@andrew.cmu.edu",
   "nsf_id": "000732534",
   "pi_start_date": "2018-04-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "8206",
   "pgm_ref_txt": "Formal Methods and Verification"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 74416.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 37223.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 38361.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The DataWizard project developed ideas and tools that make it significantly easier for data scientists to gain insights from big data. By automating crucial yet tedious aspects of data preparation, DataWizard lowered the amount of programming expertise needed to make sense of messy data. Furthermore, DataWizard can save even qualified data scientists significant time, allowing them to focus on interesting data analytics tasks.</p>\n<p>In this project, we developed novel program synthesis methods for automating data wrangling, cleaning, and imputation tasks that commonly arise in data analytics. For instance, we developed tools that can help data scientists perform complex queries to databases using a combination of examples and natural language. All these operations are done seamlessly without any coding or expertise from the user.</p>\n<p>The work done in this project goes beyond data-wrangling tasks and can reduce the effort of many other tasks performed by data scientists. For instance, in this project, we have shown how computer-aided programming can help data scientists update their libraries to a more recent version and locate potential buggy lines in their code.</p>\n<p>By investigating new program synthesis techniques using examples and natural language, this project advanced the state of the art in computer-aided programming. The techniques used in this project incorporated ideas from programming languages, natural language, machine learning, and data science.</p>\n<p>The main outcomes of this project are:</p>\n<p>1. We proposed a new conflict-driven program synthesis technique capable of learning from past mistakes and combining logic with machine learning approaches to improve synthesis tools' performance further. Our experiments show that our approach is particularly effective for data-wrangling tasks. We published this work at the Programming Language Design and Implementation Conference 2018. This groundbreaking work received a distinguished paper award.</p>\n<p>2. We developed a general-purpose framework called Trinity that can be used to quickly build domain-specific program synthesizers for automating many tedious tasks that arise in data science. Many researchers currently use this framework, and it was the foundation for several Master's theses. We published this work at the International Conference on Very Large Data Bases 2019.</p>\n<p>3. We developed a program synthesis tool called SQUARES for querying databases. SQUARES is based on input-output examples and can help data analysts extract and transform data by synthesizing SQL queries and table manipulation programs using the R language. We published this work at the International Conference on Very Large Data Bases in 2020. The successor of SQUARES is currently being used in industry by OutSystems and is publicly available at https://github.com/OutSystems/CUBES</p>\n<p>4. We developed multiple approaches to clean, visualize, and validate data. For instance, users can combine examples and natural language to clean up messy tabular data. They can also use our approach to reproduce existing charts when the data used to create them is no longer available. Finally, when creating forms to collect information, data scientists can use our tools to generate regular expressions that can validate the data introduced by users. These works were published at the Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering 2018, the International Conference on Automated Software Engineering 2020, and the International Conference on Tools and Algorithms for the Construction and Analysis of Systems 2021, respectively.</p>\n<p>5. We proposed multiple approaches that help data scientists refactor their code and update it to use newer versions of libraries. We introduced a novel technique that requires no training data to achieve API migration and refactoring. Our approach relies only on the documentation that is readily available at the release of the library to learn API representations and mapping between libraries. This work was published at the International Conference on Software Engineering 2021. We also introduced a new approach that generates lightweight API migration rules directly from pull requests in popular library repositories. Our key insight is that pull requests merged into open-source libraries are a rich source of information sufficient to mine API migration rules. By leveraging code examples mined from libraries and automatically generated code examples using large language models based on the pull requests, we infer transformation rules that users can easily use to update their code. This work was published at the International Conference on Automated Software Engineering 2023.</p>\n<p>6. We also propose to use large language models to locate buggy lines in programmers' code. Specifically, we propose to use existing large language models and fine-tune them using a small set of bidirectional adapter layers. Our language-agnostic approach does not rely on test cases or compilable code. Experimental results on Python, Java, and C code show that our technique achieves substantially more confidence in fault localization when built on the larger models, with bug localization performance scaling consistently with the large language model size. This work was published at the International Conference on Software Engineering 2024.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/01/2023<br>\n\t\t\t\t\tModified by: Ruben&nbsp;Goncalves Martins</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe DataWizard project developed ideas and tools that make it significantly easier for data scientists to gain insights from big data. By automating crucial yet tedious aspects of data preparation, DataWizard lowered the amount of programming expertise needed to make sense of messy data. Furthermore, DataWizard can save even qualified data scientists significant time, allowing them to focus on interesting data analytics tasks.\n\nIn this project, we developed novel program synthesis methods for automating data wrangling, cleaning, and imputation tasks that commonly arise in data analytics. For instance, we developed tools that can help data scientists perform complex queries to databases using a combination of examples and natural language. All these operations are done seamlessly without any coding or expertise from the user.\n\nThe work done in this project goes beyond data-wrangling tasks and can reduce the effort of many other tasks performed by data scientists. For instance, in this project, we have shown how computer-aided programming can help data scientists update their libraries to a more recent version and locate potential buggy lines in their code.\n\nBy investigating new program synthesis techniques using examples and natural language, this project advanced the state of the art in computer-aided programming. The techniques used in this project incorporated ideas from programming languages, natural language, machine learning, and data science.\n\nThe main outcomes of this project are:\n\n1. We proposed a new conflict-driven program synthesis technique capable of learning from past mistakes and combining logic with machine learning approaches to improve synthesis tools' performance further. Our experiments show that our approach is particularly effective for data-wrangling tasks. We published this work at the Programming Language Design and Implementation Conference 2018. This groundbreaking work received a distinguished paper award.\n\n2. We developed a general-purpose framework called Trinity that can be used to quickly build domain-specific program synthesizers for automating many tedious tasks that arise in data science. Many researchers currently use this framework, and it was the foundation for several Master's theses. We published this work at the International Conference on Very Large Data Bases 2019.\n\n3. We developed a program synthesis tool called SQUARES for querying databases. SQUARES is based on input-output examples and can help data analysts extract and transform data by synthesizing SQL queries and table manipulation programs using the R language. We published this work at the International Conference on Very Large Data Bases in 2020. The successor of SQUARES is currently being used in industry by OutSystems and is publicly available at https://github.com/OutSystems/CUBES\n\n4. We developed multiple approaches to clean, visualize, and validate data. For instance, users can combine examples and natural language to clean up messy tabular data. They can also use our approach to reproduce existing charts when the data used to create them is no longer available. Finally, when creating forms to collect information, data scientists can use our tools to generate regular expressions that can validate the data introduced by users. These works were published at the Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering 2018, the International Conference on Automated Software Engineering 2020, and the International Conference on Tools and Algorithms for the Construction and Analysis of Systems 2021, respectively.\n\n5. We proposed multiple approaches that help data scientists refactor their code and update it to use newer versions of libraries. We introduced a novel technique that requires no training data to achieve API migration and refactoring. Our approach relies only on the documentation that is readily available at the release of the library to learn API representations and mapping between libraries. This work was published at the International Conference on Software Engineering 2021. We also introduced a new approach that generates lightweight API migration rules directly from pull requests in popular library repositories. Our key insight is that pull requests merged into open-source libraries are a rich source of information sufficient to mine API migration rules. By leveraging code examples mined from libraries and automatically generated code examples using large language models based on the pull requests, we infer transformation rules that users can easily use to update their code. This work was published at the International Conference on Automated Software Engineering 2023.\n\n6. We also propose to use large language models to locate buggy lines in programmers' code. Specifically, we propose to use existing large language models and fine-tune them using a small set of bidirectional adapter layers. Our language-agnostic approach does not rely on test cases or compilable code. Experimental results on Python, Java, and C code show that our technique achieves substantially more confidence in fault localization when built on the larger models, with bug localization performance scaling consistently with the large language model size. This work was published at the International Conference on Software Engineering 2024.\n\n\t\t\t\t\tLast Modified: 10/01/2023\n\n\t\t\t\t\tSubmitted by: Ruben Goncalves Martins"
 }
}