{
 "awd_id": "1755676",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: III: Statistical Learning and Inference Methods for Automated Data Cleaning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Wei Ding",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2018-03-28",
 "awd_max_amd_letter_date": "2018-03-28",
 "awd_abstract_narration": "The recent investments in information retrieval, natural language processing, and AI have enabled computers to interpret what they see; read and analyze unstructured data; answer complex questions; and interact with their environment. There is a hidden catch, however: the reliance of all these state-of-the-art systems on high-effort tasks like data preparation and data cleaning. It is estimated that 70% to 80% percent of the time devoted on analytics projects is spent on checking and organizing data. The challenge is that data collection often introduces incomplete, erroneous, replicated, or conflicting data records. The burden of data preparation has led to many efforts in automating isolated tasks related to data cleaning, such as record de-duplication. However, success with end-to-end data cleaning has been limited, especially in the presence of critical data driven applications. Here, human engagement is normally required to guide and evaluate the impact of data cleaning. This project investigates the design of partly-automated, interactive data cleaning systems that are efficient for large-scale applications and come with formal accuracy guarantees. \r\n\r\nThe emphasis of this work is on data cleaning methods that combine human expertise with statistical learning and probabilistic inference to model the inherent noise of raw data; and repair incomplete, inconsistent or erroneous records. The main hypothesis driving this work is that statistical learning allows us to reason about heterogeneous signals that are indicative of the correct latent value of a data record. This project will develop a formal statistical framework for data cleaning and weakly supervised machine learning solutions for interactive data cleaning over structured or semi-structured data. The outcomes of this project will have the power to significantly ease the currently challenging procedure of manually inspecting data to be used in downstream analytical tasks.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Theodoros",
   "pi_last_name": "Rekatsinas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Theodoros Rekatsinas",
   "pi_email_addr": "thodrek@cs.wisc.edu",
   "nsf_id": "000753548",
   "pi_start_date": "2018-03-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537151218",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This award allowed us t<span>o study the foundational connections between modern machine learning and data cleaning, a notorious challenge in business analytics and data integration platforms. As part of our study we extended our work on the&nbsp;</span>HoloClean project and introduced scalable, weakly-supervised machine learning solutions to the problem of error detection and automatic repair through a series of contributions: Modeling diverse set of signals both statistical and logical as factors in a probabilistic graphical model to infer the repairs of dirty data; Attention-based mechanisms for contextual representation of data cells and inference using neural models trained in self-supervised manner; few-shot learning to train an error detection machine learning model with techniques to manufacture training errors examples; and multiple theoretical results on dealing with dirty data as a probabilistic uncertain data to reason about how data was generated and how errors were introduced using probabilistic models. More importantly, the work in the context of this award established new connections between data cleaning and repair models studied in other communities beyond the data management community, such as the noisy-channel model in the Natural Language Processing and Information Theory communities.&nbsp;<span>The algorithms and ideas from this award have already been commercialised and integrated into multiple production pipelines.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/03/2022<br>\n\t\t\t\t\tModified by: Theodoros&nbsp;Rekatsinas</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis award allowed us to study the foundational connections between modern machine learning and data cleaning, a notorious challenge in business analytics and data integration platforms. As part of our study we extended our work on the HoloClean project and introduced scalable, weakly-supervised machine learning solutions to the problem of error detection and automatic repair through a series of contributions: Modeling diverse set of signals both statistical and logical as factors in a probabilistic graphical model to infer the repairs of dirty data; Attention-based mechanisms for contextual representation of data cells and inference using neural models trained in self-supervised manner; few-shot learning to train an error detection machine learning model with techniques to manufacture training errors examples; and multiple theoretical results on dealing with dirty data as a probabilistic uncertain data to reason about how data was generated and how errors were introduced using probabilistic models. More importantly, the work in the context of this award established new connections between data cleaning and repair models studied in other communities beyond the data management community, such as the noisy-channel model in the Natural Language Processing and Information Theory communities. The algorithms and ideas from this award have already been commercialised and integrated into multiple production pipelines.\n\n\t\t\t\t\tLast Modified: 06/03/2022\n\n\t\t\t\t\tSubmitted by: Theodoros Rekatsinas"
 }
}