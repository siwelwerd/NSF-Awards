{
 "awd_id": "1749050",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER: Multimodal Photodetectors",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": "7032922980",
 "po_email": "ddagenai@nsf.gov",
 "po_sign_block_name": "Dominique Dagenais",
 "awd_eff_date": "2018-03-01",
 "awd_exp_date": "2023-02-28",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2018-03-01",
 "awd_max_amd_letter_date": "2018-03-01",
 "awd_abstract_narration": "Machine intelligence has acquired unprecedented power with the recent progress of deep learning. When paired with sensory functions, autonomous machines with even rudimentary intelligence are expected to revolutionize the world's economy. Today, the vision that most machines have is based on traditional intensity pictures of a scene, just as humans use. This vision modality has many limitations: it is impaired by fog and rain, and it offers no spectral information other than combinations of three fundamental colors. These issues greatly limit the practical use of autonomous machines due to their stringent safety and reliability requirements. As a result, expensive optical instruments are being used to assist conventional vision in accomplishing special tasks. The proposed project has the potential to overcome the fundamental issues of traditional imaging technologies. It is based on a new type of light-sensing pixels that can measure multimodal information of light, such as incident angle, wavelength, and phase. They could offer unprecedented scene awareness for pervasive use in future machines.\r\nLight-sensitive pixels used in today's camera can only detect the intensity of light. The intensity information is sufficient for conventional applications such as photography, its limitations become apparent in advanced vision tasks. This project will develop a new class of photodetectors to measure multimodal information of light waves. They are compact and can form high density arrays as imaging chips. Although multimodal information can be measured through conventional optical components, such as lenses, prisms, and gratings, these components are expensive to integrate. They also degrade spatial resolution and decrease operational speed. This project uses novel nanostructures to exploit unique optical interactions. Multi-modal pixels will be designed using full wave simulation and fabricated with photo-lithography. The multimodal pixels are completely compatible with existing semiconductor fabrication facilities and could potentially be mass-produced at the cost of consumer electronics. The project will also develop new machine learning algorithms to exploit multimodal information to perform vision tasks far beyond those possible with today's intensity-only approach.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zongfu",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zongfu Yu",
   "pi_email_addr": "zyu54@wisc.edu",
   "nsf_id": "000652763",
   "pi_start_date": "2018-03-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "1415 Engineering Drive",
  "perf_city_name": "madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537151218",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "151700",
   "pgm_ele_name": "EPMD-ElectrnPhoton&MagnDevices"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "091E",
   "pgm_ref_txt": "Light generation & detection"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project demonstrated two types of novel image sensors that can extend the capability of modern camera. Conventional vision systems are mostly based on imaging sensors consisting of arrays of light-sensitive pixels, each of which measures the intensity of light falling upon it. The issue with such pixels is that they are incapable of acquiring other important multimodal information of light, such as its incident angle, wavelength, and phase. While the intensity information is sufficient for conventional applications such as photography, its limitations become apparent in advanced vision tasks. This project developed sensors that can measure the spectral information and phase front information. New algorithms were developed to exploit multimodal information to perform vision tasks far beyond those possible with today&rsquo;s intensity-only approach, including hyperspectral imaging and surface morphology measurement.<strong>&nbsp;</strong></p>\n<p>The difficulty of achieving such sensors comes from the reduction of conventional optical components&mdash;such as lenses, prisms, and gratings&mdash; to chip-scale sizes. To achieve such miniaturization, this project uses novel nanostructures to exploit coherent interactions among nearby photo-sensitive materials. The multimodal states of incident light affect how light waves interact with nanostructured materials, thereby affecting the distribution of optical energy. By measuring this distribution, multimodal information of light is inferred. These multimodal pixels are completely compatible with existing CMOS fabrication methods and could be mass-produced at the cost of consumer electronics.</p>\n<p>This Project Outcomes Report for the General Public is displayed verbatim as submitted by the Principal Investigator (PI) for this award. Any opinions, findings, and conclusions or recommendations expressed in this Report are those of the PI and do not necessarily reflect the views of the National Science Foundation; NSF has not approved or endorsed its content.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/25/2023<br>\n\t\t\t\t\tModified by: Zongfu&nbsp;Yu</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1749050/1749050_10532586_1687728165187_Picture1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1749050/1749050_10532586_1687728165187_Picture1--rgov-800width.jpg\" title=\"Multimodal Sensor\"><img src=\"/por/images/Reports/POR/2023/1749050/1749050_10532586_1687728165187_Picture1--rgov-66x44.jpg\" alt=\"Multimodal Sensor\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A nanostructured image sensor can measure spectral information of light in an ultra compact form factor</div>\n<div class=\"imageCredit\">Zongfu Yu</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Zongfu&nbsp;Yu</div>\n<div class=\"imageTitle\">Multimodal Sensor</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe project demonstrated two types of novel image sensors that can extend the capability of modern camera. Conventional vision systems are mostly based on imaging sensors consisting of arrays of light-sensitive pixels, each of which measures the intensity of light falling upon it. The issue with such pixels is that they are incapable of acquiring other important multimodal information of light, such as its incident angle, wavelength, and phase. While the intensity information is sufficient for conventional applications such as photography, its limitations become apparent in advanced vision tasks. This project developed sensors that can measure the spectral information and phase front information. New algorithms were developed to exploit multimodal information to perform vision tasks far beyond those possible with today\u2019s intensity-only approach, including hyperspectral imaging and surface morphology measurement. \n\nThe difficulty of achieving such sensors comes from the reduction of conventional optical components&mdash;such as lenses, prisms, and gratings&mdash; to chip-scale sizes. To achieve such miniaturization, this project uses novel nanostructures to exploit coherent interactions among nearby photo-sensitive materials. The multimodal states of incident light affect how light waves interact with nanostructured materials, thereby affecting the distribution of optical energy. By measuring this distribution, multimodal information of light is inferred. These multimodal pixels are completely compatible with existing CMOS fabrication methods and could be mass-produced at the cost of consumer electronics.\n\nThis Project Outcomes Report for the General Public is displayed verbatim as submitted by the Principal Investigator (PI) for this award. Any opinions, findings, and conclusions or recommendations expressed in this Report are those of the PI and do not necessarily reflect the views of the National Science Foundation; NSF has not approved or endorsed its content.\n\n \n\n\t\t\t\t\tLast Modified: 06/25/2023\n\n\t\t\t\t\tSubmitted by: Zongfu Yu"
 }
}