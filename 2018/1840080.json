{
 "awd_id": "1840080",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FW-HTF: Future of Firefighting and Career Training - Advancing Cognitive, Communication, and Decision Making Capabilities of Firefighters",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927280",
 "po_email": "nlutz@nsf.gov",
 "po_sign_block_name": "Nancy Lutz",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 1494976.0,
 "awd_amount": 1494976.0,
 "awd_min_amd_letter_date": "2018-09-06",
 "awd_max_amd_letter_date": "2020-12-03",
 "awd_abstract_narration": "The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim. \r\n\r\nThis project will enhance firefighting through a novel augmentation technology system.  The project will involve advanced data, machines, tools, and human-technology relationships.  Cognitive and social science studies will examine the impact of the new technology on human cognition and firefighters' work, training, and quality of life.  The resulting augmentation technology will enhance the cognition, communication, and decision-making capabilities of firefighters. This project will have broader impacts at multiple levels ranging from individual firefighters to organizations and society.  For firefighters, the new technology will enhance well-being and improve their job satisfaction and safety. The new technology will also help firefighters save lives and better protect property and the environment.  The project's approach and result can be further extended to other types of emergency response workers, such as police, security, and disaster management and recovery.\r\n\r\nThis convergent project will advance the research frontiers of technology and social science with a specialized, scalable, and adaptable data infrastructure.  The project will involve new methods of multi-source non-intrusive data collection; model-based and learning-based analyses and fire modeling algorithms suited for data-rich environments; immersive and cross-platform visualizations improving on-site investigation; and multi-sensory interaction, communication, and decision-making mechanisms.  Cognitive and social science research will reveal how the augmentation technology can transform the firefighter's work and provide guidance to effectively design human-technology interactions.  The project will adopt a mixed-methods approach including lab experiments, two major public report data sources, and two-waves of surveys and interviews of firefighters. The research team will also develop multidisciplinary course modules for undergraduate and graduate students and tutorials to be offered at major conferences in order to recruit a broad participants including women and under-represented students.  Both technical modules and education materials will be accessible through online platforms including GitHub after evaluation and improvements.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aidong",
   "pi_last_name": "Lu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aidong Lu",
   "pi_email_addr": "alu1@uncc.edu",
   "nsf_id": "000286346",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Weichao",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Weichao Wang",
   "pi_email_addr": "wwang22@uncc.edu",
   "nsf_id": "000288470",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Aixi",
   "pi_last_name": "Zhou",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aixi Zhou",
   "pi_email_addr": "azhou@nsu.edu",
   "nsf_id": "000545860",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Wei",
   "pi_last_name": "Zhao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wei Zhao",
   "pi_email_addr": "weiz@ucr.edu",
   "nsf_id": "000569375",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Charlotte",
  "inst_street_address": "9201 UNIVERSITY CITY BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTE",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "7046871888",
  "inst_zip_code": "282230001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NC12",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHARLOTTE",
  "org_prnt_uei_num": "NEYCH3CVBTR6",
  "org_uei_num": "JB33DT84JNA5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Charlotte",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "282230001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NC12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "082Y00",
   "pgm_ele_name": "FW-HTF-Adv Cogn & Phys Capblty"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 1494976.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-ad4b72bb-7fff-cf58-b969-376c269e5407\" dir=\"ltr\"><span>Firefighting is important but dangerous. This project is to improve the efficiency of communication and enhance the decision making of firefighters through a novel augmentation technology system. The team has explored the latest technologies and developed new ways to collect, analyze, and present information to firefighters effectively. We describe our key results in the following.</span></p>\r\n<p dir=\"ltr\"><span>Focusing on the firebrand phenomenon, we developed a machine learning-based approach to model fire development. This work was to predict the firebrand areal mass density and firebrand areal number density of landing firebrands using a large set of data from full-scale laboratory firebrand production experiments. We demonstrated that the non-linear non-parametric ML model, K-nearest neighbors, worked the best for this purpose with an accuracy higher than 90%. The current ML model can be used to predict locations with high risk of spotting ignition potential. The results of this work can be expanded to other ML-based fire modeling work.&nbsp;&nbsp;</span></p>\r\n<p dir=\"ltr\"><span>We explored wireless sensors that firefighters wear to accomplish the data collection and activity recognition tasks. We built a system to assess the weight lifting activities of end users based on measurements from the wrist region with Photoplethysmography sensors. Considering that different individuals respond to weight lifting differently based on their strength and health conditions, we developed a machine learning based training model for the system. We experimented with different classification algorithms and achieved a very good classification accuracy with a small training data set. This work minimized impacts to the training activities while collecting adequate data for subsequent analysis.</span></p>\r\n<p dir=\"ltr\"><span>We designed mechanisms for edge embedded data sharing and aggregation for the firefighting command center. The edge computing module was connected with the fire modeling and decision making modules, and virtualization engine. Our approach effectively assesses the quality of information from different sources through a hidden Markov model to determine the aggregation priority. Our long short term memory based approach uses partial visibility of environment states and a state translator to calculate the belief probability in the environment state. The calculation results can be used to support localized decision making and provide support for firefighters.&nbsp;&nbsp;</span></p>\r\n<p dir=\"ltr\"><span>We explored the latest mixed reality devices including Microsoft HoloLens and Meta Quest for firefighter tasks. Focusing on new ways of information visualization on site, we designed immersive maps to show data collections from analysis results of sensors and fire models. Through a user study with factors of information amount in the immersive map and danger degree of tasks, we captured statistical features of user behaviors. Our results confirmed the advantages of real-time information for firefighter tasks and differences of user behaviors under dangerous situations. We also investigated a collaborative, cross-platform immersive system to improve the team navigation through effective real-time communication. Our results demonstrate the effects of immersive visualization for improving 3D navigation and coordination for on-site collaboration in a real physical environment.</span></p>\r\n<p dir=\"ltr\"><span>We explored the sensemaking process in an immersive environment through studying both internal and external user behaviors. We found that increased interactions and cerebral hemodynamic responses were associated with more accurate performance, especially on cognitively demanding trials. We discussed how these findings inform the design and evaluation of immersive systems and offer theoretical insights about sensemaking from the perspective of embodied and distributed cognition.</span></p>\r\n<p dir=\"ltr\"><span>To support recognition of human actions during the firefighting tasks, we explored approaches including a spatial-temporal masked autoencoder and a mixed transformer model with a frequency-aware attention module. To address the application environments with limited resources, we also developed a lightweight architecture that reduced the model complexity. Our comprehensive evaluations demonstrated that our model outperformed other state-of-the-art methods with a good balance between efficiency and accuracy.</span></p>\r\n<p dir=\"ltr\"><span>We analyzed the data from multiple sources, primarily the interviews of firefighters, to examine the social factors in technology framing. Emphasizing the dual nature of technology as both a physical and a social objective, we have further developed a theoretical framework that highlights firefighter&rsquo;s dual interpretations of technologies in terms of their technical functionality and symbolic meanings through the lens of professional identity. The dual interpretations generated tensions and created different foci and interplays in technology framing, ultimately leading to different technology adoption patterns. Those technologies with strong symbolic meanings and closely attached to firefighters&rsquo; professional identity were more likely to face resistance to changes. But technology perception could also evolve over time along with reconstructed professional identity.</span></p>\r\n<p dir=\"ltr\"><span>Our team has worked closely with local Fire Departments in North Carolina. Our results are based on lab experiments, professional training, and surveys and interviews of firefighters. To date, the project has produced nineteen peer-reviewed publications, with several additional manuscripts under review. Hundreds of graduate and undergraduate students were trained in the multidisciplinary courses and research fields. The results of this project have been presented to both academic communities (including Computer Science, Fire Engineering, and Social Science) and firefighter communities.</span></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/22/2025<br>\nModified by: Aidong&nbsp;Lu</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/1840080/1840080_10580068_1737593247700_f3--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1840080/1840080_10580068_1737593247700_f3--rgov-800width.png\" title=\"Behavior Visualization\"><img src=\"/por/images/Reports/POR/2025/1840080/1840080_10580068_1737593247700_f3--rgov-66x44.png\" alt=\"Behavior Visualization\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We developed a visualization system for analyzing human behaviors in mixed reality. The interface allows analysis of the detailed data sequences, 3D and statistical data features.</div>\n<div class=\"imageCredit\">Alexia Galati, Riley Schoppa, Aidong Lu</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Aidong&nbsp;Lu\n<div class=\"imageTitle\">Behavior Visualization</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1840080/1840080_10580068_1737592929079_f1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1840080/1840080_10580068_1737592929079_f1--rgov-800width.png\" title=\"Virtual simulation\"><img src=\"/por/images/Reports/POR/2025/1840080/1840080_10580068_1737592929079_f1--rgov-66x44.png\" alt=\"Virtual simulation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We developed virtual simulations of fire scenes and immersive maps with different information levels to support firefighters on site.</div>\n<div class=\"imageCredit\">Shahin Doroudian, Zekun Wu, Weichao Wang, Alexia Galati, Aidong Lu</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Aidong&nbsp;Lu\n<div class=\"imageTitle\">Virtual simulation</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1840080/1840080_10580068_1737593034241_f2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1840080/1840080_10580068_1737593034241_f2--rgov-800width.png\" title=\"Immersive cross-platform collaboration\"><img src=\"/por/images/Reports/POR/2025/1840080/1840080_10580068_1737593034241_f2--rgov-66x44.png\" alt=\"Immersive cross-platform collaboration\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We developed a cross-platform immersive system to support collaborative navigation with mobile devices (iPad) and AR HMDs (HoloLens).</div>\n<div class=\"imageCredit\">Akshay Ayyanchira, Elias Mahfoud, Weichao Wang, Aidong Lu</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Aidong&nbsp;Lu\n<div class=\"imageTitle\">Immersive cross-platform collaboration</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nFirefighting is important but dangerous. This project is to improve the efficiency of communication and enhance the decision making of firefighters through a novel augmentation technology system. The team has explored the latest technologies and developed new ways to collect, analyze, and present information to firefighters effectively. We describe our key results in the following.\r\n\n\nFocusing on the firebrand phenomenon, we developed a machine learning-based approach to model fire development. This work was to predict the firebrand areal mass density and firebrand areal number density of landing firebrands using a large set of data from full-scale laboratory firebrand production experiments. We demonstrated that the non-linear non-parametric ML model, K-nearest neighbors, worked the best for this purpose with an accuracy higher than 90%. The current ML model can be used to predict locations with high risk of spotting ignition potential. The results of this work can be expanded to other ML-based fire modeling work.\r\n\n\nWe explored wireless sensors that firefighters wear to accomplish the data collection and activity recognition tasks. We built a system to assess the weight lifting activities of end users based on measurements from the wrist region with Photoplethysmography sensors. Considering that different individuals respond to weight lifting differently based on their strength and health conditions, we developed a machine learning based training model for the system. We experimented with different classification algorithms and achieved a very good classification accuracy with a small training data set. This work minimized impacts to the training activities while collecting adequate data for subsequent analysis.\r\n\n\nWe designed mechanisms for edge embedded data sharing and aggregation for the firefighting command center. The edge computing module was connected with the fire modeling and decision making modules, and virtualization engine. Our approach effectively assesses the quality of information from different sources through a hidden Markov model to determine the aggregation priority. Our long short term memory based approach uses partial visibility of environment states and a state translator to calculate the belief probability in the environment state. The calculation results can be used to support localized decision making and provide support for firefighters.\r\n\n\nWe explored the latest mixed reality devices including Microsoft HoloLens and Meta Quest for firefighter tasks. Focusing on new ways of information visualization on site, we designed immersive maps to show data collections from analysis results of sensors and fire models. Through a user study with factors of information amount in the immersive map and danger degree of tasks, we captured statistical features of user behaviors. Our results confirmed the advantages of real-time information for firefighter tasks and differences of user behaviors under dangerous situations. We also investigated a collaborative, cross-platform immersive system to improve the team navigation through effective real-time communication. Our results demonstrate the effects of immersive visualization for improving 3D navigation and coordination for on-site collaboration in a real physical environment.\r\n\n\nWe explored the sensemaking process in an immersive environment through studying both internal and external user behaviors. We found that increased interactions and cerebral hemodynamic responses were associated with more accurate performance, especially on cognitively demanding trials. We discussed how these findings inform the design and evaluation of immersive systems and offer theoretical insights about sensemaking from the perspective of embodied and distributed cognition.\r\n\n\nTo support recognition of human actions during the firefighting tasks, we explored approaches including a spatial-temporal masked autoencoder and a mixed transformer model with a frequency-aware attention module. To address the application environments with limited resources, we also developed a lightweight architecture that reduced the model complexity. Our comprehensive evaluations demonstrated that our model outperformed other state-of-the-art methods with a good balance between efficiency and accuracy.\r\n\n\nWe analyzed the data from multiple sources, primarily the interviews of firefighters, to examine the social factors in technology framing. Emphasizing the dual nature of technology as both a physical and a social objective, we have further developed a theoretical framework that highlights firefighters dual interpretations of technologies in terms of their technical functionality and symbolic meanings through the lens of professional identity. The dual interpretations generated tensions and created different foci and interplays in technology framing, ultimately leading to different technology adoption patterns. Those technologies with strong symbolic meanings and closely attached to firefighters professional identity were more likely to face resistance to changes. But technology perception could also evolve over time along with reconstructed professional identity.\r\n\n\nOur team has worked closely with local Fire Departments in North Carolina. Our results are based on lab experiments, professional training, and surveys and interviews of firefighters. To date, the project has produced nineteen peer-reviewed publications, with several additional manuscripts under review. Hundreds of graduate and undergraduate students were trained in the multidisciplinary courses and research fields. The results of this project have been presented to both academic communities (including Computer Science, Fire Engineering, and Social Science) and firefighter communities.\r\n\n\n\t\t\t\t\tLast Modified: 01/22/2025\n\n\t\t\t\t\tSubmitted by: AidongLu\n"
 }
}