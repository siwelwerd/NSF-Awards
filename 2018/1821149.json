{
 "awd_id": "1821149",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: A Tensor-Based Computational Framework for Model Reduction and Structured Matrices",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Christopher Stark",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 140000.0,
 "awd_amount": 140000.0,
 "awd_min_amd_letter_date": "2018-08-11",
 "awd_max_amd_letter_date": "2019-08-12",
 "awd_abstract_narration": "Many tasks in scientific computing involve either data or operators that are inherently multidimensional: for example, a database of gray-scale images constitutes a three-dimensional array when each image is stored in a standard two-dimensional array format. Yet many standard numerical methods treat the data and associated operators as two-dimensional arrays, or matrices. This suggests that additional structure that could be leveraged for computational gain may be going undiscovered and underutilized. Recent research has shown that tensors (multidimensional arrays) and several types of corresponding decomposition methods can be instrumental in revealing latent correlations of both data and operators residing in high-dimensional spaces. Indeed, tensor decompositions can be provably superior to matrix-based counterparts in representation of certain types of data. This research project tackles two important questions: (1) how to uncover latent structure in data and operators using multidimensional tensor factorizations, and (2) how to use these revealed structures to develop a powerful computational framework that can harvest the benefits of this structure. Hands-on teaching material for graduate courses will be developed on randomized matrix methods and tensor decompositions. This teaching material, in the form of Python notebooks, along with the code developed as a part of this project, will be freely available as a software library under an open source license.\r\n\r\nThe investigators aim to answer these questions in the context of two applications in scientific computing of major importance and far-reaching consequences: model reduction, a mathematical framework for reducing the computational cost associated with high-fidelity simulations of complicated physical phenomena, and structured matrix approximation, which is important in applications such as parametric partial differential equations and image deblurring. The work will approach these questions through an entirely new, multidimensional lens with the advantages of providing new computational efficiencies and structure that can only be obtained by moving to a higher-dimensional regime. Two signature features of the project are: (1) design and analysis of structured tensor decompositions that are efficient in terms of computations and memory accesses, by using randomized matrix methods and the algebraic structure of tensor decompositions; and (2) use of tensor models, and a corresponding suite of structured decompositions, to exploit latent multidimensional structure in model reduction and structured matrix approximations. The research is expected to benefit numerous other applications in science and engineering as well.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Arvind",
   "pi_last_name": "Saibaba",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Arvind K Saibaba",
   "pi_email_addr": "asaibab@ncsu.edu",
   "nsf_id": "000702534",
   "pi_start_date": "2018-08-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "2108 SAS Hall",
  "perf_city_name": "Raleigh",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276958205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 46258.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 93742.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project used tensor decompositions to uncover and exploit latent multidimensional structure in a range of problems in scientific computing and data science. The state-of-the-art techniques in this area typically treated the data and operators as two-dimensional arrays and then used matrix-based methods. In contrast, our tensor-based techniques often performed much better in terms of storage costs and accuracy due to their ability to better exploit the multidimensional structure. A key ingredient in our approach was the development of novel randomized numerical linear algebra algorithms and analysis, which led to dramatic reduction in computational costs with provable probabilistic guarantees. The key outcomes of this project are:</p>\n<p>1. Development of randomized algorithms for tensor decompositions in the Tucker and Tensor Train formats.</p>\n<p>2. Development of novel randomized and tensor algorithms for projection-based nonlinear model reduction for partial differential equations.</p>\n<p>3. Development of tensor-based algorithms for function and kernel approximations with an application to rank-structured matrices.</p>\n<p>4. Development of randomized algorithms for generalized SVD with applications to sensitivity analysis.</p>\n<p>5. Development of randomized matrix and tensor-based algorithms for subspace system identification.</p>\n<p>6. Development of efficient algorithms for storing and representing structured matrices by using invertible matrix-to-tensor mappings.</p>\n<p>7. Development of tensor-based methods for optimal sensor placement for flow reconstructions.</p>\n<p>&nbsp;</p>\n<p>The novel algorithms developed as part of this project were demonstrated on a range of test problems, involving both synthetic and real-world data across a range of applications and disciplines. We believe the advances in this project will not only benefit other areas of computational mathematics such as model reduction and sensitivity analysis but also benefit areas of science and engineering such as Statistics, Electrical and Mechanical Engineering, and the cross-cutting area of Fluid Dynamics.</p>\n<p>&nbsp;</p>\n<p>The project led to multiple software codes on randomized tensor decompositions, system identification, and flow reconstructions, which were released to the public via Github along with appropriate licenses.</p>\n<p>&nbsp;</p>\n<p>The project supported the PhD studies of one PhD student (North Carolina State University, or NC State) and two Master?s students (Tufts University), who were exposed to modern research areas in scientific computing and data science and an interdisciplinary research environment.</p>\n<p>&nbsp;</p>\n<p>This  project also led to the development of educational materials for a special topics class held at NC State. The PIs also  developed tutorials on tensor decompositions and randomized algorithms and delivered them at  several international conferences and workshops. The PIs also organized minisymposia on tensor  decompositions at international conferences with an emphasis on inviting  early career researchers and graduate students.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/13/2022<br>\n\t\t\t\t\tModified by: Arvind&nbsp;K&nbsp;Saibaba</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project used tensor decompositions to uncover and exploit latent multidimensional structure in a range of problems in scientific computing and data science. The state-of-the-art techniques in this area typically treated the data and operators as two-dimensional arrays and then used matrix-based methods. In contrast, our tensor-based techniques often performed much better in terms of storage costs and accuracy due to their ability to better exploit the multidimensional structure. A key ingredient in our approach was the development of novel randomized numerical linear algebra algorithms and analysis, which led to dramatic reduction in computational costs with provable probabilistic guarantees. The key outcomes of this project are:\n\n1. Development of randomized algorithms for tensor decompositions in the Tucker and Tensor Train formats.\n\n2. Development of novel randomized and tensor algorithms for projection-based nonlinear model reduction for partial differential equations.\n\n3. Development of tensor-based algorithms for function and kernel approximations with an application to rank-structured matrices.\n\n4. Development of randomized algorithms for generalized SVD with applications to sensitivity analysis.\n\n5. Development of randomized matrix and tensor-based algorithms for subspace system identification.\n\n6. Development of efficient algorithms for storing and representing structured matrices by using invertible matrix-to-tensor mappings.\n\n7. Development of tensor-based methods for optimal sensor placement for flow reconstructions.\n\n \n\nThe novel algorithms developed as part of this project were demonstrated on a range of test problems, involving both synthetic and real-world data across a range of applications and disciplines. We believe the advances in this project will not only benefit other areas of computational mathematics such as model reduction and sensitivity analysis but also benefit areas of science and engineering such as Statistics, Electrical and Mechanical Engineering, and the cross-cutting area of Fluid Dynamics.\n\n \n\nThe project led to multiple software codes on randomized tensor decompositions, system identification, and flow reconstructions, which were released to the public via Github along with appropriate licenses.\n\n \n\nThe project supported the PhD studies of one PhD student (North Carolina State University, or NC State) and two Master?s students (Tufts University), who were exposed to modern research areas in scientific computing and data science and an interdisciplinary research environment.\n\n \n\nThis  project also led to the development of educational materials for a special topics class held at NC State. The PIs also  developed tutorials on tensor decompositions and randomized algorithms and delivered them at  several international conferences and workshops. The PIs also organized minisymposia on tensor  decompositions at international conferences with an emphasis on inviting  early career researchers and graduate students. \n\n \n\n\t\t\t\t\tLast Modified: 12/13/2022\n\n\t\t\t\t\tSubmitted by: Arvind K Saibaba"
 }
}