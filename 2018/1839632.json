{
 "awd_id": "1839632",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Real-Time: Learning, Selection, and Control in Residential Demand Response for Grid Reliability",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Donald Wunsch",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 283800.0,
 "awd_min_amd_letter_date": "2018-09-19",
 "awd_max_amd_letter_date": "2019-08-29",
 "awd_abstract_narration": "As renewable energy sources increase and conventional generators retire, demand response (DR) has been utilized to address the reliability issue on balancing real-time demand and supply in power grids. However, the potential of residential DR, which is the largest share of electricity demands, has not been fully exploited in practice. Existing pilots reveal many issues, such as i) small monetary rewards which play a limited role in user participation, ii) user dissatisfaction when utility companies exploit DR resources extensively, and iii) the lack of reliability due to the unpredictability of user behavior. In collaboration with ThinkEco Inc, this proposal will develop novel and applicable approaches for residential DR with provable guarantees. The method will learn DR behavior, select the correct residential users, and automatically control residential appliances -- all in the service of enhancing system reliability. The research will be tested and validated on real-world residential DR programs using ThinkEco platforms. The research results will advance real-time learning for human-in-the-loop societal systems with applications ranging from transportation to power grids to AI-enabled systems of the future. The team is strongly committed to providing opportunities in STEM to K-12, women, and under-represented minorities. Moreover, the close collaboration between academia and industry promises a fast and effective transition of academic results to industry practice.\r\n \r\nSpecifically, by understanding users' energy consumption behavior from both historical and real-time measurements, and adjusting user selection and control strategies in real-time, this proposed research will invent DR learning and control mechanisms to satisfy various power grid operation requirements. A major theme in this proposal is to close the loop between learning (exploration) and control (exploitation) in human-in-the-loop societal systems: how to learn (explore) user behavior while taking good control actions (exploitation) at the same time.  There is a fundamental tradeoff between exploration and exploitation, and the proposed research aims to uncover the tradeoff and design real-time decision-making rules to achieve near-optimal performance for residential DR. Different from the conventional approaches to learning in computer science or statistics, this proposal aims to tackle the challenge of intertwined interactions between human users and the engineered systems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Na",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Na Li",
   "pi_email_addr": "nali@seas.harvard.edu",
   "nsf_id": "000654507",
   "pi_start_date": "2018-09-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Parkes",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "David C Parkes",
   "pi_email_addr": "parkes@eecs.harvard.edu",
   "nsf_id": "000210273",
   "pi_start_date": "2018-09-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "President and Fellows of Harvard College",
  "perf_str_addr": "33 oxford street MD 345",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021382933",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760700",
   "pgm_ele_name": "EPCN-Energy-Power-Ctrl-Netwrks"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "155E",
   "pgm_ref_txt": "Electric power networks"
  },
  {
   "pgm_ref_code": "1653",
   "pgm_ref_txt": "Adaptive & intelligent systems"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 250000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 33800.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div id=\":1tl\" class=\"Ar Au Ao\">\n<div id=\":1th\" class=\"Am Al editable LW-avf tS-tW tS-tY\">\n<p>In collaboration with a leading Internet-of-Things (IoT) technology company, ThinkEco Inc, this project develops novel and applicable approaches for residential DR with provable guarantees. The developed methods learn DR behavior, select the right residential users, and automatically control residential appliances all in the service of enhancing system reliability. By understanding users' energy consumption behavior from both historical and real-time measurements, and adjusting user selection and control strategies in real-time, this project invents DR learning and control mechanisms to satisfy various power grid operation requirements.&nbsp;</p>\n<p>This project accomplished three main tasks, i) analyzing users' behavior and appliance models from historical data using statistical (online) learning approaches, ii) designing real-time/online learning and control approaches such as multi-armed bandits and reinforcement learning to learn the user opt-in/out behavior, and iii) integrating the offline learning, online learning, and distributed control, to develop practical residential DR schemes which take into account both the engineering and human factors and validating the algorithms through ThinkEco pilots. The developed demand response algorithms close the loop between learning (exploration) and control (exploitation): how to learn (explore) user behavior while taking good control actions (exploitation) at the same time? More specifically, this project&nbsp;ultimately develops incentive-based real-time residential DR programs that learn and control DR loads to optimize DR performances for different system-level objectives, such as minimizing the total load or closely tracking a target power trajectory.&nbsp;To this end, a novel framework is developed to model the real-time DR control as a multi-period stochastic optimization problem that integrates thermal dynamics and customer behavior transitions. Gaussian process (GP) is adopted to build a non-parametric indoor thermal dynamical model from historical metering data, and logistic regression is used to model the customer opt-out behaviors under the influence of environmental factors. Based on the Thompson sampling (TS) framework, a distributed online DR control algorithm is developed to learn the customer opt-out behaviors and make real-time power control decisions. The main merits of the proposed algorithm are summarized as follows: 1) The individual preferences of customers and time-varying environmental factors are taken into account, which improves the predictions on customer opt-out behaviors and leads to efficient control schemes. 2) This algorithm is implemented in a distributed manner and thus can be directly embedded in local household AC&nbsp;appliances, smart plugs, or smartphone apps. Moreover, the communication burdens are mitigated and customer privacy can be preserved. 3) this algorithm has a convenient decomposition structure of learning and optimization and strikes an effective balance between exploration and exploitation in the online learning process.&nbsp;</p>\n<p>Broad Impact: 1) The developed&nbsp;methods not only work for residential demand response programs but also suit other power-system-related applications, especially when there are end-users in the loop such as EV-charging. Moreover, this project advances real-time learning for human-in-the-loop societal systems, especially in regard to understanding the role of preferences and user behavior in the face of fast-growing information and automation technologies. The applications range from transportation to the power grid to other AI-enabled systems of the future. 2) Throughout the projects, 4 papers were published, 3 of which are published in top journals. The research results are also incorporated into the curriculum design. The PI has delivered many talks on this project to workshops and conferences, both domestic and international. 3) 3 Ph.D. students who were partially advised under this project have graduated, 2 of whom were women. One student is an assistant professor at Columbia University, one is a postdoc at UIUC and is on the academic job market, one is going to be a postdoc at MIT.</p>\n</div>\n</div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/12/2022<br>\n\t\t\t\t\tModified by: Na&nbsp;Li</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1839632/1839632_10583815_1645896486752_figure3-report--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1839632/1839632_10583815_1645896486752_figure3-report--rgov-800width.jpg\" title=\"Real-time learning and control of residential demand response\"><img src=\"/por/images/Reports/POR/2022/1839632/1839632_10583815_1645896486752_figure3-report--rgov-66x44.jpg\" alt=\"Real-time learning and control of residential demand response\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Schematic of one of our proposed distributed online DR control algorithm. Details are presented in the paper, Online Learning and Distributed Control for Residential Demand Response, Chen et. al, 2021</div>\n<div class=\"imageCredit\">Xin Chen, Yingying Li, Jun Shimada, Na Li</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Na&nbsp;Li</div>\n<div class=\"imageTitle\">Real-time learning and control of residential demand response</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1839632/1839632_10583815_1645896673088_figure1-report--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1839632/1839632_10583815_1645896673088_figure1-report--rgov-800width.jpg\" title=\"ThinkEco pilot study on residential DR\"><img src=\"/por/images/Reports/POR/2022/1839632/1839632_10583815_1645896673088_figure1-report--rgov-66x44.jpg\" alt=\"ThinkEco pilot study on residential DR\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The schematic figure of ThinkEco\ufffds residential DR pilot system. It consists of SmartAC devices which can control the AC and send real-time measurement to the control center. Users can choose to opt in or opt out the demand response event at any time.</div>\n<div class=\"imageCredit\">ThinkEco & Harvard SEAS</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Na&nbsp;Li</div>\n<div class=\"imageTitle\">ThinkEco pilot study on residential DR</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n\n\nIn collaboration with a leading Internet-of-Things (IoT) technology company, ThinkEco Inc, this project develops novel and applicable approaches for residential DR with provable guarantees. The developed methods learn DR behavior, select the right residential users, and automatically control residential appliances all in the service of enhancing system reliability. By understanding users' energy consumption behavior from both historical and real-time measurements, and adjusting user selection and control strategies in real-time, this project invents DR learning and control mechanisms to satisfy various power grid operation requirements. \n\nThis project accomplished three main tasks, i) analyzing users' behavior and appliance models from historical data using statistical (online) learning approaches, ii) designing real-time/online learning and control approaches such as multi-armed bandits and reinforcement learning to learn the user opt-in/out behavior, and iii) integrating the offline learning, online learning, and distributed control, to develop practical residential DR schemes which take into account both the engineering and human factors and validating the algorithms through ThinkEco pilots. The developed demand response algorithms close the loop between learning (exploration) and control (exploitation): how to learn (explore) user behavior while taking good control actions (exploitation) at the same time? More specifically, this project ultimately develops incentive-based real-time residential DR programs that learn and control DR loads to optimize DR performances for different system-level objectives, such as minimizing the total load or closely tracking a target power trajectory. To this end, a novel framework is developed to model the real-time DR control as a multi-period stochastic optimization problem that integrates thermal dynamics and customer behavior transitions. Gaussian process (GP) is adopted to build a non-parametric indoor thermal dynamical model from historical metering data, and logistic regression is used to model the customer opt-out behaviors under the influence of environmental factors. Based on the Thompson sampling (TS) framework, a distributed online DR control algorithm is developed to learn the customer opt-out behaviors and make real-time power control decisions. The main merits of the proposed algorithm are summarized as follows: 1) The individual preferences of customers and time-varying environmental factors are taken into account, which improves the predictions on customer opt-out behaviors and leads to efficient control schemes. 2) This algorithm is implemented in a distributed manner and thus can be directly embedded in local household AC appliances, smart plugs, or smartphone apps. Moreover, the communication burdens are mitigated and customer privacy can be preserved. 3) this algorithm has a convenient decomposition structure of learning and optimization and strikes an effective balance between exploration and exploitation in the online learning process. \n\nBroad Impact: 1) The developed methods not only work for residential demand response programs but also suit other power-system-related applications, especially when there are end-users in the loop such as EV-charging. Moreover, this project advances real-time learning for human-in-the-loop societal systems, especially in regard to understanding the role of preferences and user behavior in the face of fast-growing information and automation technologies. The applications range from transportation to the power grid to other AI-enabled systems of the future. 2) Throughout the projects, 4 papers were published, 3 of which are published in top journals. The research results are also incorporated into the curriculum design. The PI has delivered many talks on this project to workshops and conferences, both domestic and international. 3) 3 Ph.D. students who were partially advised under this project have graduated, 2 of whom were women. One student is an assistant professor at Columbia University, one is a postdoc at UIUC and is on the academic job market, one is going to be a postdoc at MIT.\n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 03/12/2022\n\n\t\t\t\t\tSubmitted by: Na Li"
 }
}