{
 "awd_id": "1827864",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Enabling decision-relevant debates about human genome editing",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927263",
 "po_email": "roconnor@nsf.gov",
 "po_sign_block_name": "Robert O'Connor",
 "awd_eff_date": "2018-07-01",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 449977.0,
 "awd_amount": 449977.0,
 "awd_min_amd_letter_date": "2018-06-14",
 "awd_max_amd_letter_date": "2020-04-02",
 "awd_abstract_narration": "Recent breakthroughs in gene editing using CRISPR/Cas-9 and other tools allow scientists to edit the human genome in safer, faster, and more effective ways than ever before. This new technology also has the potential to cure as many as 6,000 genetically-inherited diseases and to transform healthcare in the U.S. At the same time, other potential applications have raised serious moral and ethical concerns. Given the wide variety of possible applications in fields ranging from medicine to national security, innovations in human gene editing (HGE) will increasingly necessitate public debate and societal decision making. However, as popular awareness of HGE grows, public discussions of the technology have the potential to become divisive in ways that could compromise meaningful and responsible development. The potential for this outcome is visible in controversies currently surrounding genetically modified organisms (GMOs), an issue that raises similar technical and ethical questions, and which has led to consumer behavior that is often at odds with the best available scientific evidence. Thus, to encourage responsible innovation, this project develops and evaluates public engagement modalities that facilitate the productive exchange of ideas about HGE between groups with different values. The findings from this project help guide broader, emerging debates about HGE and will help ensure that policy and consumer choices are shaped both by the best available science and citizens' values and concerns. \r\n\r\nTo accomplish its goals, this project integrates and advances diverse strands of theory and research on biased information processing concerning science and value-laden policy issues. In particular, it tests the potential for different informational and social environments to minimize polarization in public debate. The first phase uses laboratory and survey experiments to examine how values and information together shape opinions about HGE, and to test approaches for alleviating the negative effects of information processing that is biased toward predetermined conclusions. The findings from the first phase guide implementation and evaluation of a public workshop that will bring together diverse members of the public, including researchers in HGE, to interact with each other and discuss the technology. Insights from the workshop inform concrete strategies and best-practices that other organizations can adapt, scale, and apply to facilitate effective public engagement and healthy decision making across diverse publics.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dietram",
   "pi_last_name": "Scheufele",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Dietram A Scheufele",
   "pi_email_addr": "scheufele@wisc.edu",
   "nsf_id": "000333278",
   "pi_start_date": "2018-06-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Dominique",
   "pi_last_name": "Brossard",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dominique Brossard",
   "pi_email_addr": "dbrossard@wisc.edu",
   "nsf_id": "000176923",
   "pi_start_date": "2018-06-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Xenos",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Michael A Xenos",
   "pi_email_addr": "xenos@wisc.edu",
   "nsf_id": "000754419",
   "pi_start_date": "2018-06-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537151218",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132100",
   "pgm_ele_name": "Decision, Risk & Mgmt Sci"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 97456.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 119471.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 233050.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The purpose of this project was to explore ways in which our society can debate the important political, regulatory, and moral questions raised by modern science, while avoiding ideological or value-based divisions between different publics that can hinder responsible innovation in a host of areas, ranging from medicine to military. As our project progressed, the COVID-19 pandemic provided a powerful illustration of the value and urgency of this kind of scholarship, as it demonstrated the societal consequences we incur when subsets of the population are unable or unwilling to cooperate in response to emergent risks. To ensure responsible innovation and effective democratic decision-making about the future of high-impact areas of science and technology, we need to examine how we can bring conflicted groups together to engage in &ldquo;good-faith&rdquo; discussions that are scaffolded by mutual acknowledgment of the best available scientific evidence.</p>\n<p>Within this broad and urgent context, our project involved two main research activities: (1) Synthesizing and examining existing literature about alleged &ldquo;crises&rdquo; of public opinion regarding science, particularly misinformation and mistrust, which are often implicated in discussions of intergroup conflict over science issues, and (2) Empirically testing the relative efficacy of interventions that could theoretically reduce barriers to successful intergroup interaction about science. Across both of these major workstreams, our research has yielded conceptual and empirical insights that will be valuable for social scientists, policy actors, and practitioners. Concretely, practitioners who may be interested in our results include science and risk communicators, public health professionals, and organizations that are actively designing and fielding science engagement initiatives with diverse publics.</p>\n<p>Key outcomes of our work include the following:</p>\n<p>First, we have produced a series of critical essays, published in various peer-reviewed journals (such as the Proceedings of the National Academy of Sciences) as well as magazines (such as American Scientist), examining existing scholarship and action on misinformation and mistrust in science. In these essays, we have argued for more nuanced conceptualizations of &ldquo;trust in science,&rdquo; as well as \"misinformation\" and \"disinformation,\" especially when scientific evidence is rapidly shifting (as was the case during COVID-19). We have offered conceptual frameworks to begin addressing our concerns, as well as revised research agendas outlining productive pathways forward.</p>\n<p>Second, we conducted a series of &ldquo;intervention&rdquo; experiments. The first two were designed to understand why the mere anticipation of discussing scientific issues can sometimes induce &ldquo;aversion&rdquo; in people, essentially causing them to avoid joining or expressing themselves. Overall, we found that it is possible to set expectations for science discussions in ways that are theoretically useful for deliberation. Telling people one (or both) of the following things before the discussion begins can foster greater participation, self-expression, or positive beliefs about people who disagree: (a) that members of the discussion will be expected to express and justify their opinions, and (b) that the discussion topic and environment is characterized by people grappling with their own beliefs. In our final experiment, we hypothesized that extant efforts by the WHO and the CDC to correct misperceptions about COVID-19 mRNA vaccines would do \"collateral damage\" to other science attitudes. Ultimately, we found support for the \"collateral damage effect,&rdquo; thereby demonstrating that some misinformation interventions which are intended to mitigate polarization through increased belief accuracy can sometimes have unintended consequences. We therefore strongly recommend more research into the possible adverse effects of various misinformation interventions before disseminating these &ldquo;treatments.&rdquo;</p>\n<p>Generally, the outcomes of this project will encourage more focused and effective research on misinformation and mistrust in science, and, in so doing, will contribute to the broader project of bridging societal divides surrounding science. Further, our empirical insights about audience aversion to conflict-laden science discussions can inform both the structure and content of real-world public engagement exercises in ways that could overcome the common problem of biased participation (in which only the most dogmatic or the least conflict-averse individuals &ldquo;show up&rdquo; and &ldquo;speak up&rdquo;).</p>\n<p>To increase impact, our results have been disseminated widely via publications, conference presentations, and educational materials within university coursework. Our project has also directly informed the PIs&rsquo; work advising groups like the NASEM, to name just one example, on more effective infrastructures for engaging publics on controversial technologies from climate change to CRISPR. Further, although this project has ended, we are continuing all of our key research areas via a grant-funded Civic Science Fellowship with the John Templeton Foundation (which stemmed directly from this original award). We have also established infrastructure at the University of Wisconsin &ndash; Madison for ongoing survey research that will address the broader social scientific question of how individuals in polarized environments engage with information and other people on pressing political and scientific issues, and how we can harness the science of science communication to produce more productive and constructive policy debates about emerging science.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/02/2022<br>\n\t\t\t\t\tModified by: Dietram&nbsp;A&nbsp;Scheufele</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe purpose of this project was to explore ways in which our society can debate the important political, regulatory, and moral questions raised by modern science, while avoiding ideological or value-based divisions between different publics that can hinder responsible innovation in a host of areas, ranging from medicine to military. As our project progressed, the COVID-19 pandemic provided a powerful illustration of the value and urgency of this kind of scholarship, as it demonstrated the societal consequences we incur when subsets of the population are unable or unwilling to cooperate in response to emergent risks. To ensure responsible innovation and effective democratic decision-making about the future of high-impact areas of science and technology, we need to examine how we can bring conflicted groups together to engage in \"good-faith\" discussions that are scaffolded by mutual acknowledgment of the best available scientific evidence.\n\nWithin this broad and urgent context, our project involved two main research activities: (1) Synthesizing and examining existing literature about alleged \"crises\" of public opinion regarding science, particularly misinformation and mistrust, which are often implicated in discussions of intergroup conflict over science issues, and (2) Empirically testing the relative efficacy of interventions that could theoretically reduce barriers to successful intergroup interaction about science. Across both of these major workstreams, our research has yielded conceptual and empirical insights that will be valuable for social scientists, policy actors, and practitioners. Concretely, practitioners who may be interested in our results include science and risk communicators, public health professionals, and organizations that are actively designing and fielding science engagement initiatives with diverse publics.\n\nKey outcomes of our work include the following:\n\nFirst, we have produced a series of critical essays, published in various peer-reviewed journals (such as the Proceedings of the National Academy of Sciences) as well as magazines (such as American Scientist), examining existing scholarship and action on misinformation and mistrust in science. In these essays, we have argued for more nuanced conceptualizations of \"trust in science,\" as well as \"misinformation\" and \"disinformation,\" especially when scientific evidence is rapidly shifting (as was the case during COVID-19). We have offered conceptual frameworks to begin addressing our concerns, as well as revised research agendas outlining productive pathways forward.\n\nSecond, we conducted a series of \"intervention\" experiments. The first two were designed to understand why the mere anticipation of discussing scientific issues can sometimes induce \"aversion\" in people, essentially causing them to avoid joining or expressing themselves. Overall, we found that it is possible to set expectations for science discussions in ways that are theoretically useful for deliberation. Telling people one (or both) of the following things before the discussion begins can foster greater participation, self-expression, or positive beliefs about people who disagree: (a) that members of the discussion will be expected to express and justify their opinions, and (b) that the discussion topic and environment is characterized by people grappling with their own beliefs. In our final experiment, we hypothesized that extant efforts by the WHO and the CDC to correct misperceptions about COVID-19 mRNA vaccines would do \"collateral damage\" to other science attitudes. Ultimately, we found support for the \"collateral damage effect,\" thereby demonstrating that some misinformation interventions which are intended to mitigate polarization through increased belief accuracy can sometimes have unintended consequences. We therefore strongly recommend more research into the possible adverse effects of various misinformation interventions before disseminating these \"treatments.\"\n\nGenerally, the outcomes of this project will encourage more focused and effective research on misinformation and mistrust in science, and, in so doing, will contribute to the broader project of bridging societal divides surrounding science. Further, our empirical insights about audience aversion to conflict-laden science discussions can inform both the structure and content of real-world public engagement exercises in ways that could overcome the common problem of biased participation (in which only the most dogmatic or the least conflict-averse individuals \"show up\" and \"speak up\").\n\nTo increase impact, our results have been disseminated widely via publications, conference presentations, and educational materials within university coursework. Our project has also directly informed the PIs\u2019 work advising groups like the NASEM, to name just one example, on more effective infrastructures for engaging publics on controversial technologies from climate change to CRISPR. Further, although this project has ended, we are continuing all of our key research areas via a grant-funded Civic Science Fellowship with the John Templeton Foundation (which stemmed directly from this original award). We have also established infrastructure at the University of Wisconsin &ndash; Madison for ongoing survey research that will address the broader social scientific question of how individuals in polarized environments engage with information and other people on pressing political and scientific issues, and how we can harness the science of science communication to produce more productive and constructive policy debates about emerging science.\n\n\t\t\t\t\tLast Modified: 08/02/2022\n\n\t\t\t\t\tSubmitted by: Dietram A Scheufele"
 }
}