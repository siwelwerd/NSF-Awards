{
 "awd_id": "1822864",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Data-Driven, Human-in-the-Loop Support for Facilitating Participatory Learning Activities",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925126",
 "po_email": "abaylor@nsf.gov",
 "po_sign_block_name": "Amy Baylor",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 400681.0,
 "awd_amount": 400681.0,
 "awd_min_amd_letter_date": "2018-08-17",
 "awd_max_amd_letter_date": "2022-09-20",
 "awd_abstract_narration": "Museums are increasingly developing digital learning experiences where visitors generate interesting usage data, but these data are rarely used to support learning. This project poses a \"human-in-the-loop\" model of facilitation where museum experts are provided with data visualizations and other feedback derived by mining exhibit use data. These visuals will be used as coaching support for facilitators as they help visitors make sense of the rich learning experiences that digital exhibits now offer. While this approach is immediately relevant to museum learning, human-in-the-loop systems represent a new take on cyberlearning systems that will be applicable to many other formal and informal STEM learning environments that demand immediate, just-in-time reflection that is guided by an expert observer.\r\n\r\nThe intervention will be used in the context of an open-ended, participatory exhibit that invites up to 50 visitors at a time to manipulate a simulated ecosystem, with the goal of having visitors engage with concepts related to sustainability and complex systems by exploring emergent phenomena. Open-ended learning experiences are common to museum exhibits but are under-studied in the Educational Data Mining (EDM) community. This research will add to the growing EDM literature on open-ended problems and provide insights for how museum exhibits can be designed to supply data that can be useful for analytics and data mining. A goal of this research is to develop and refine a typology of the forms of information that museum and other facilitators working with real-time data can make sense of and act on, which could be used to inform both the analytics and the software design for future tools to facilitate learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Stephen",
   "pi_last_name": "Uzzo",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Stephen M Uzzo",
   "pi_email_addr": "uzzo@momath.org",
   "nsf_id": "000181215",
   "pi_start_date": "2021-04-20",
   "pi_end_date": "2022-09-20"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Katherine",
   "pi_last_name": "McMillan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Katherine McMillan",
   "pi_email_addr": "kculp@nyscience.org",
   "nsf_id": "000278544",
   "pi_start_date": "2022-09-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Leilah",
   "pi_last_name": "Lyons",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Leilah Lyons",
   "pi_email_addr": "llyons@nysci.org",
   "nsf_id": "000618030",
   "pi_start_date": "2018-08-17",
   "pi_end_date": "2021-04-20"
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Stephen",
   "pi_last_name": "Uzzo",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Stephen M Uzzo",
   "pi_email_addr": "uzzo@momath.org",
   "nsf_id": "000181215",
   "pi_start_date": "2018-08-17",
   "pi_end_date": "2021-04-20"
  }
 ],
 "inst": {
  "inst_name": "New York Hall of Science",
  "inst_street_address": "4701 111TH ST",
  "inst_street_address_2": "",
  "inst_city_name": "CORONA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "7185959173",
  "inst_zip_code": "113682950",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "NY06",
  "org_lgl_bus_name": "NEW YORK HALL OF SCIENCE",
  "org_prnt_uei_num": "",
  "org_uei_num": "UQ7FBRE34HS5"
 },
 "perf_inst": {
  "perf_inst_name": "New York Hall of Science",
  "perf_str_addr": "47-01 111th Street",
  "perf_city_name": "Corona",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "113682950",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NY06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "005Y00",
   "pgm_ele_name": "STEM + Computing (STEM+C) Part"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  }
 ],
 "app_fund": [
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 400681.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-5e6bd6a6-7fff-63be-b4f3-f0d9c4e92525\"> </span></p>\n<p dir=\"ltr\"><span>This project explored how data can be used to improve the learning experiences of museum visitors who are engaged with exhibits that are immersive, open-ended, and collaborative. We used the New York Hall of Science&rsquo;s award-winning Connected Worlds exhibit as a testbed. Connected Worlds is a 2,300 square foot fully immersive, digitally rendered simulation of an ecosystem. Up to 50 visitors at a time can interact with the ecosystem&rsquo;s rich, complex phenomena by gesturing and moving objects around in the space. Their decisions determine the health of the ecosystem, which in turn influences which creatures and plants thrive or decline. This project sought to help visitors better understand how their actions contribute towards or disrupt the sustainability of the ecosystem. We explored an approach that allowed a member of the museum&rsquo;s interpretive staff to use a tablet computer to monitor and share visualizations of ongoing exhibit use data to support their conversations with visitors. We used an iterative approach to develop three aspects of this data-driven, human-in-the-loop interpretation support system: (1) how meaningful information can be extracted from a rich, open-ended learning environment (Data Analytics), (2)how an interface can be designed to make that information perceivable and actionable (User Interface and Data Visualization design); and (3) how the information and its delivery can be situated within existing interpretation practices, and in turn, can shape new interpretation practices (Interpretation Practice).&nbsp;</span></p>\n<p dir=\"ltr\"><span>In the course of this project we had to invent a number of methods for documenting and making sense of the visitors&rsquo; engagement with the exhibit, and with each other.</span></p>\n<p dir=\"ltr\"><span>We </span><strong>developed a new privacy-preserving measure of &ldquo;collaborative opportunity temperature.&rdquo; </strong><span>Collaborative learning is usually studied in small groups, but we chose to &ldquo;zoom out&rdquo; and develop an approach that can describe how a large group of visitors, as a whole, are engaging with one another. Are they clumping together in ways that support conversation? Are they moving around, allowing ideas to get shared throughout the whole group? How do these behaviors change over time? We used computer vision to transform video feeds of visitors into anonymous skeletal models of visitors to protect their privacy. We were able to show that this measure was useful for detecting differences in how groups of learners responded to data-driven visualizations.</span></p>\n<p dir=\"ltr\"><span>We </span><strong>developed a new approach to giving learners guidance in open-ended learning environments</strong><span>. Computer-generated guidance is often given to classroom learners, and is usually based on how close or far away the learner is from the &ldquo;correct&rdquo; solution. We explored what it means to give guidance to learners who are not in a classroom, who are exploring and thus not in pursuit of a single correct solution, and who are not learning alone. Existing approaches to automatically generating guidance do not work under these conditions. We had to reconceptualize what it means to provide data-driven guidance to learners in open-ended learning environments, and invent new approaches to mining data and visualizing the results for learners. Our approach is unique in that it helps learners reflect and make choices about what to do next while preserving their free choice, which is necessary for supporting open-ended learning.</span></p>\n<p dir=\"ltr\"><span>We <strong>developed </strong></span><strong>a new approach to documenting the collaborative problem solving that happens in highly-immersive learning environments</strong><span>. We extended existing ways of describing how small groups of learners manage their joint problem solving with more traditional classroom tasks (i.e., collaborative problem solving regulation) so we could describe how large groups of learners problem solve in immersive learning environments. The change in scope and setting meant we had to pay additional attention to which people are being regulated, and in service of whose goals. This work earned a best graduate paper award at the American Educational Research Association conference.&nbsp;</span></p>\n<p dir=\"ltr\"><span>We <strong>developed </strong></span><strong>a novel approach to designing social technologies, called situated-relational design</strong><span><strong>, which is designed to help a mix of participants with wildly different backgrounds work together to imagine new social uses of technology</strong>. Specifically, we wanted to help participants explore how social situations can demand the innovation of new technological approaches, and at the same time, how new technological approaches permit new ways for people to interact with each other. The design approach uses a mix of physical prompts (like cards and worksheets) and structured phases to help participants build a mutual understanding of both the social and technical opportunities and constraints, and to reaffirm to every participant that their contributions are valuable.&nbsp;</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/30/2023<br>\nModified by: Katherine&nbsp;Mcmillan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThis project explored how data can be used to improve the learning experiences of museum visitors who are engaged with exhibits that are immersive, open-ended, and collaborative. We used the New York Hall of Sciences award-winning Connected Worlds exhibit as a testbed. Connected Worlds is a 2,300 square foot fully immersive, digitally rendered simulation of an ecosystem. Up to 50 visitors at a time can interact with the ecosystems rich, complex phenomena by gesturing and moving objects around in the space. Their decisions determine the health of the ecosystem, which in turn influences which creatures and plants thrive or decline. This project sought to help visitors better understand how their actions contribute towards or disrupt the sustainability of the ecosystem. We explored an approach that allowed a member of the museums interpretive staff to use a tablet computer to monitor and share visualizations of ongoing exhibit use data to support their conversations with visitors. We used an iterative approach to develop three aspects of this data-driven, human-in-the-loop interpretation support system: (1) how meaningful information can be extracted from a rich, open-ended learning environment (Data Analytics), (2)how an interface can be designed to make that information perceivable and actionable (User Interface and Data Visualization design); and (3) how the information and its delivery can be situated within existing interpretation practices, and in turn, can shape new interpretation practices (Interpretation Practice).\n\n\nIn the course of this project we had to invent a number of methods for documenting and making sense of the visitors engagement with the exhibit, and with each other.\n\n\nWe developed a new privacy-preserving measure of collaborative opportunity temperature. Collaborative learning is usually studied in small groups, but we chose to zoom out and develop an approach that can describe how a large group of visitors, as a whole, are engaging with one another. Are they clumping together in ways that support conversation? Are they moving around, allowing ideas to get shared throughout the whole group? How do these behaviors change over time? We used computer vision to transform video feeds of visitors into anonymous skeletal models of visitors to protect their privacy. We were able to show that this measure was useful for detecting differences in how groups of learners responded to data-driven visualizations.\n\n\nWe developed a new approach to giving learners guidance in open-ended learning environments. Computer-generated guidance is often given to classroom learners, and is usually based on how close or far away the learner is from the correct solution. We explored what it means to give guidance to learners who are not in a classroom, who are exploring and thus not in pursuit of a single correct solution, and who are not learning alone. Existing approaches to automatically generating guidance do not work under these conditions. We had to reconceptualize what it means to provide data-driven guidance to learners in open-ended learning environments, and invent new approaches to mining data and visualizing the results for learners. Our approach is unique in that it helps learners reflect and make choices about what to do next while preserving their free choice, which is necessary for supporting open-ended learning.\n\n\nWe developed a new approach to documenting the collaborative problem solving that happens in highly-immersive learning environments. We extended existing ways of describing how small groups of learners manage their joint problem solving with more traditional classroom tasks (i.e., collaborative problem solving regulation) so we could describe how large groups of learners problem solve in immersive learning environments. The change in scope and setting meant we had to pay additional attention to which people are being regulated, and in service of whose goals. This work earned a best graduate paper award at the American Educational Research Association conference.\n\n\nWe developed a novel approach to designing social technologies, called situated-relational design, which is designed to help a mix of participants with wildly different backgrounds work together to imagine new social uses of technology. Specifically, we wanted to help participants explore how social situations can demand the innovation of new technological approaches, and at the same time, how new technological approaches permit new ways for people to interact with each other. The design approach uses a mix of physical prompts (like cards and worksheets) and structured phases to help participants build a mutual understanding of both the social and technical opportunities and constraints, and to reaffirm to every participant that their contributions are valuable.\n\n\n\t\t\t\t\tLast Modified: 12/30/2023\n\n\t\t\t\t\tSubmitted by: KatherineMcmillan\n"
 }
}