{
 "awd_id": "1816611",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Cost-Aware Cloud Profiling, Prediction, and Provisioning as a Service",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2018-08-30",
 "awd_max_amd_letter_date": "2018-08-30",
 "awd_abstract_narration": "Cloud computing has the potential to transform computational practice by enabling immediate, on-demand access to large-scale computing resources. But large-scale cloud computing can easily be costly. The Scalable Cost-Aware Cloud Infrastructure Management and Provisioning (SCRIMP) project aims to develop new cloud access methods that will reduce the complexity and cost and improve the efficiency of using cloud resources. The project will innovate in three areas: profiling, prediction, and provisioning. Its new machine learning-based profiling techniques aim to predict application performance, at different levels of accuracy, across a diverse set of cloud resources, based upon derivation of comparable and related instance classes, explorative profiling techniques, and analysis of historical usage. Its ensemble-based market prediction models will allow the many existing cloud market prediction models to be easily compared and then combined so that their collective strengths can be used to predict costs with the aim of minimizing cost, price risk, and likelihood of instance revocation. Finally, its overarching provisioning model will combine application profiles and market prediction models to enable automated, cost-efficient, policy-based cloud provisioning as well as efficient placement and migration of workload within the resulting dynamically provisioned environment.\r\n\r\nSCRIMP will advance the use of computation across the sciences, particularly within smaller institutions, by simplifying access to on-demand cloud computing and improving the efficiency with which researchers make use of cloud infrastructure. By lowering scientific computing costs and complexity for many users, SCRIMP will enable more efficient use of cloud credits (whether from cloud providers or funding agencies), democratize access to cloud computing by researchers without dedicated computing infrastructure or expertise, and allow researchers and students to conduct increasingly complex analytics, on larger datasets, and at higher resolution. SCRIMP will also be directly relevant in education, allowing educators to provide access to large resource pools at low cost with guaranteed performance.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kyle",
   "pi_last_name": "Chard",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kyle Chard",
   "pi_email_addr": "chard@uchicago.edu",
   "nsf_id": "000694050",
   "pi_start_date": "2018-08-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ian",
   "pi_last_name": "Foster",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ian Foster",
   "pi_email_addr": "foster@uchicago.edu",
   "nsf_id": "000234022",
   "pi_start_date": "2018-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606375418",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-f1ea1154-7fff-8781-6910-98e986dbbbe4\">\n<p dir=\"ltr\"><span>The Scalable Cost-Aware Cloud Infrastructure Management and Provisioning (SCRIMP) project developed new methods and open-source software for profiling, predicting, and provisioning cloud resources. The project created new methods for profiling application performance across diverse cloud resources, new techniques for predicting cloud costs in preemptible and volatile cloud markets, and developed a user-facing provisioning service that leverages profiling and prediction models to enable users to quantify, balance, and optimize tradeoffs in terms of application performance (e.g., accuracy) and costs (e.g., time, budget, and energy consumption).&nbsp;</span></p>\n<p dir=\"ltr\"><span>&nbsp;</span>The SCRIMP profiling framework is designed to automatically and efficiently profile application performance on different cloud and edge resources. The framework is able to capture a multidimensional notion of cost, for example, cloud computing costs, startup costs, data movement costs, and computing resources used. It also considers various measures of performance, such as result quality or application accuracy. Such flexibility is crucial, for example, in machine learning training, as the profiling framework can capture model accuracy and thus enable downstream exploration of the tradeoff between training time and model accuracy. The profiling framework can automatically explore wide input parameter spaces for applications, investigating different parameterizations to estimate performance and costs. The profiling framework uses active learning/experiment design methods to reduce profiling costs via targeted samples across the search space.&nbsp; Experiment results show that the profiling framework can accurately predict costs on heterogeneous distributed resources.&nbsp;</p>\n<p dir=\"ltr\"><span>The project created new methods to predict cloud computing costs based on analysis and modeling of cloud markets. Analysis of AWS spot market dynamics contributed to&nbsp; understanding of the &ldquo;predictability&rdquo; of the spot market over a long period of time. This analysis highlighted important changes to the market that altered the prediction dynamics, and ultimately showed that recent changes dramatically simplified the market making it far less dynamic than it was previously. As a result, even simple statistical methods can accurately forecast prices into the future. The project developed and evaluated neural network and statistical models to forecast prices. Evaluation showed that even ARIMA models achieved an order of magnitude improvement in accuracy when applied to recent spot market data compared to historical data. These prediction methods make it easy to forecast future prices and when used with real applications can significantly reduce costs and resource waste.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Finally, the project created a new service called DELTA that combines these profiling and prediction methods to automatically provision and schedule execution of user workloads across distributed and&nbsp; heterogeneous resources. DELTA enables applications to be executed without requiring users to consider the complex costs that exist in cloud and edge systems (e.g., provisioning delays, transfer costs, container deployment time). DELTA implements an extensible architecture in which different predictors and scheduling algorithms can be integrated to provide dynamically evolving estimates of costs on different resources. These estimates can be used to determine the most appropriate location for execution. Experiments across diverse resources, including cloud and edge devices, showed that DELTA&nbsp; can significantly reduce workload makespan when compared with a strategy that selects the fastest resource.&nbsp;</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/28/2024<br>\nModified by: Kyle&nbsp;Chard</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\nThe Scalable Cost-Aware Cloud Infrastructure Management and Provisioning (SCRIMP) project developed new methods and open-source software for profiling, predicting, and provisioning cloud resources. The project created new methods for profiling application performance across diverse cloud resources, new techniques for predicting cloud costs in preemptible and volatile cloud markets, and developed a user-facing provisioning service that leverages profiling and prediction models to enable users to quantify, balance, and optimize tradeoffs in terms of application performance (e.g., accuracy) and costs (e.g., time, budget, and energy consumption).\n\n\nThe SCRIMP profiling framework is designed to automatically and efficiently profile application performance on different cloud and edge resources. The framework is able to capture a multidimensional notion of cost, for example, cloud computing costs, startup costs, data movement costs, and computing resources used. It also considers various measures of performance, such as result quality or application accuracy. Such flexibility is crucial, for example, in machine learning training, as the profiling framework can capture model accuracy and thus enable downstream exploration of the tradeoff between training time and model accuracy. The profiling framework can automatically explore wide input parameter spaces for applications, investigating different parameterizations to estimate performance and costs. The profiling framework uses active learning/experiment design methods to reduce profiling costs via targeted samples across the search space. Experiment results show that the profiling framework can accurately predict costs on heterogeneous distributed resources.\n\n\nThe project created new methods to predict cloud computing costs based on analysis and modeling of cloud markets. Analysis of AWS spot market dynamics contributed to understanding of the predictability of the spot market over a long period of time. This analysis highlighted important changes to the market that altered the prediction dynamics, and ultimately showed that recent changes dramatically simplified the market making it far less dynamic than it was previously. As a result, even simple statistical methods can accurately forecast prices into the future. The project developed and evaluated neural network and statistical models to forecast prices. Evaluation showed that even ARIMA models achieved an order of magnitude improvement in accuracy when applied to recent spot market data compared to historical data. These prediction methods make it easy to forecast future prices and when used with real applications can significantly reduce costs and resource waste.\n\n\nFinally, the project created a new service called DELTA that combines these profiling and prediction methods to automatically provision and schedule execution of user workloads across distributed and heterogeneous resources. DELTA enables applications to be executed without requiring users to consider the complex costs that exist in cloud and edge systems (e.g., provisioning delays, transfer costs, container deployment time). DELTA implements an extensible architecture in which different predictors and scheduling algorithms can be integrated to provide dynamically evolving estimates of costs on different resources. These estimates can be used to determine the most appropriate location for execution. Experiments across diverse resources, including cloud and edge devices, showed that DELTA can significantly reduce workload makespan when compared with a strategy that selects the fastest resource.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 02/28/2024\n\n\t\t\t\t\tSubmitted by: KyleChard\n"
 }
}