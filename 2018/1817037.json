{
 "awd_id": "1817037",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF:Small: Tensor-Based Algorithm and Hardware Co-Optimization for Neural Network Architecture",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-03-31",
 "tot_intn_awd_amt": 499998.0,
 "awd_amount": 499998.0,
 "awd_min_amd_letter_date": "2018-06-19",
 "awd_max_amd_letter_date": "2021-04-21",
 "awd_abstract_narration": "Machine learning plays an important role in our daily life, including medical data analysis, finance, autonomous driving and computer vision. Many popular machine learning models are both data-intensive and computationally expensive. In order to address this challenge, algorithm and architecture co-design and co-optimizations are required to achieve better performance and energy efficiency. This project aims to develop a more powerful learning architecture by simultaneously optimizing the neural network algorithm and its hardware implementation. The project will have a broad impact. The AI applications will gain a significant performance boost if the computational and storage cost of its algorithm can be reduced significantly.  It will improve many applications such as data mining, medical imaging analysis, computational biology, and financial analysis.  The project will greatly enrich the undergraduate and graduate course curriculum and attract graduate and undergraduate students to participate in this project and related workshops. Finally, this project will develop new AI, VLSI and computer architecture workforce with solid background in several areas including computational math, machine learning, and hardware design.\r\n\r\nTensors are a generalization of vectors and matrices, and they are promising tools to represent and numerically process high-dimensional data arrays. Leveraging the high effectiveness of tensor computation in big-data analysis, this project will investigate three specific topics towards designing high-performance and energy-efficient machine learning hardware. First, theoretically sound and novel tensor numerical algorithms will be developed to significantly reduce the training and inference cost of deep learning. Second, the algorithm framework will be optimized on existing hardware (e.g., GPU and FPGA) to achieve better performance, and to examine the main challenges when running on hardware platforms. Finally, emerging design technologies (e.g., 3-D process-in-memory) will be investigated to design specific hardware libraries to perform fundamental tensor computation and to further boost the performance and energy efficiency of the whole machine learning architecture.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zheng",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zheng Zhang",
   "pi_email_addr": "zhengzhang@ece.ucsb.edu",
   "nsf_id": "000753421",
   "pi_start_date": "2018-06-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Yuan",
   "pi_last_name": "Xie",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yuan Xie",
   "pi_email_addr": "yuanxie@ece.ucsb.edu",
   "nsf_id": "000203143",
   "pi_start_date": "2018-06-19",
   "pi_end_date": "2021-04-21"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yufei",
   "pi_last_name": "Ding",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yufei Ding",
   "pi_email_addr": "yufeiding@ucsd.edu",
   "nsf_id": "000760744",
   "pi_start_date": "2021-04-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Barbara",
  "inst_street_address": "3227 CHEADLE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA BARBARA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8058934188",
  "inst_zip_code": "931060001",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SANTA BARBARA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G9QBQDH39DF4"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Barbara",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "931069560",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 499998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has investigated the algorithm/hardware co-design of tensor computational methods for neural networks. One of the main challenge of training and deploying neural networks is the huge model size, which consumes a huge amount of computing and energy resources on the hardware. In this project, PI Zhang and the co-PI Yuan Xie (later Yufei Ding) achieved the following results:</p>\n<p>1. Ultra memory-efficient end-to-end tensor compressed training framework. Instead of compressing a pre-trained huge neural network, we have developed a Bayesian framework to automatically determine the tensor ranks and compression ratio in the training process. This method can greatly reduce the number of training varialbes in the training process, therefore saving a huge amount of memory and computing resources. With an advanced variational inference method, we have been able to perform compressed trainining on fully connected neural networks, convolutional neural networks, natural language processing models, and large-scale deep learning recommendation system models. The compression ratio in training is about 26000X in deep learning recommendation system, as shown in our attached Figure 1.&nbsp;</p>\n<p>&nbsp;</p>\n<p>2. Demo of on-FPGA training training acceletator. Due to the high reduction ratio of training variables, the tensor-compressed methods allow us to perform resource-efficeint and energy-efficient training on edge devices. As shown in Fig. 2, we have developed an FPGA prototyope for a two-layer neural network, which achieved about 300X reduction of model parameters. This allows effficient processing with on-chip memory, leading to&nbsp;<span>&nbsp;59X speedup and&nbsp;</span><span>&nbsp;123X energy reduction compared to embedded CPU.</span></p>\n<p>&nbsp;</p>\n<p><span>3. Architecture-level design for tensor computation framework. Specifically, we have designed an FPGA accelerator for Tucker-format tensor decomposition. We have also designed a tensor-train processing engine,&nbsp; which achiees<span>&nbsp;on average&nbsp;</span><span id=\"MathJax-Element-1-Frame\" class=\"MathJax\"><span id=\"MathJax-Span-1\" class=\"math\"><span><span><span id=\"MathJax-Span-2\" class=\"mrow\"><span id=\"MathJax-Span-3\" class=\"mn\">14.9</span><span id=\"MathJax-Span-4\" class=\"mo\">X</span></span></span></span></span></span><span>&nbsp;?&nbsp;</span><span id=\"MathJax-Element-2-Frame\" class=\"MathJax\"><span id=\"MathJax-Span-5\" class=\"math\"><span><span><span id=\"MathJax-Span-6\" class=\"mrow\"><span id=\"MathJax-Span-7\" class=\"mn\">36.9</span><span id=\"MathJax-Span-8\" class=\"mo\">X</span></span></span></span></span></span><span>&nbsp;speedup over CPU implementations and&nbsp;</span><span id=\"MathJax-Element-3-Frame\" class=\"MathJax\"><span id=\"MathJax-Span-9\" class=\"math\"><span><span><span id=\"MathJax-Span-10\" class=\"mrow\"><span id=\"MathJax-Span-11\" class=\"mn\">4.1</span><span id=\"MathJax-Span-12\" class=\"mo\">X</span></span></span></span></span></span><span>&nbsp;?&nbsp;</span><span id=\"MathJax-Element-4-Frame\" class=\"MathJax\"><span id=\"MathJax-Span-13\" class=\"math\"><span><span><span id=\"MathJax-Span-14\" class=\"mrow\"><span id=\"MathJax-Span-15\" class=\"mn\">9.9</span><span id=\"MathJax-Span-16\" class=\"mo\">X</span></span></span></span></span></span><span>&nbsp;speedup compared to the GPU baseline. Finally, we also deveploed an efficient processing architecture for sparse tensor decomposition via unified abstraction and PE-interactive architecture. This method can achieve&nbsp;<span>can achieve an average speedup of 45x over CPU and 29x over GPU.</span></span></span></p>\n<p>&nbsp;</p>\n<p><span><span><span>Besides regular conference presentations, the research results of this project have been presented at over 20 research instutitions and industrial research labs.&nbsp;The research results have been integrated with the UCSB's graduate course of tensor computation, and the lecture notes have been offered to many peer research groups for free. Four graduate students, one postdoc, and 2 undergraduate students have participated in this project.&nbsp;</span></span></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/01/2022<br>\n\t\t\t\t\tModified by: Zheng&nbsp;Zhang</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1817037/1817037_10551559_1659380137961_overview--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1817037/1817037_10551559_1659380137961_overview--rgov-800width.jpg\" title=\"TT-compressed training\"><img src=\"/por/images/Reports/POR/2022/1817037/1817037_10551559_1659380137961_overview--rgov-66x44.jpg\" alt=\"TT-compressed training\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 1: (a) Key idea of our work. Conventional train-then-compress approaches have high training costs. In constrast, the proposed end-to-end tensorized training can reduce the training variables significantly and directly produce ultra-compact neural networks. (b) Results on DLRM.</div>\n<div class=\"imageCredit\">Zheng Zhang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Zheng&nbsp;Zhang</div>\n<div class=\"imageTitle\">TT-compressed training</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1817037/1817037_10551559_1659380806908_tensor-FPGA--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1817037/1817037_10551559_1659380806908_tensor-FPGA--rgov-800width.jpg\" title=\"tensorFPGA\"><img src=\"/por/images/Reports/POR/2022/1817037/1817037_10551559_1659380806908_tensor-FPGA--rgov-66x44.jpg\" alt=\"tensorFPGA\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 2: the architecture of our proposed on-FPGA tensor-compressed training accelerator.</div>\n<div class=\"imageCredit\">Zheng Zhang</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Zheng&nbsp;Zhang</div>\n<div class=\"imageTitle\">tensorFPGA</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project has investigated the algorithm/hardware co-design of tensor computational methods for neural networks. One of the main challenge of training and deploying neural networks is the huge model size, which consumes a huge amount of computing and energy resources on the hardware. In this project, PI Zhang and the co-PI Yuan Xie (later Yufei Ding) achieved the following results:\n\n1. Ultra memory-efficient end-to-end tensor compressed training framework. Instead of compressing a pre-trained huge neural network, we have developed a Bayesian framework to automatically determine the tensor ranks and compression ratio in the training process. This method can greatly reduce the number of training varialbes in the training process, therefore saving a huge amount of memory and computing resources. With an advanced variational inference method, we have been able to perform compressed trainining on fully connected neural networks, convolutional neural networks, natural language processing models, and large-scale deep learning recommendation system models. The compression ratio in training is about 26000X in deep learning recommendation system, as shown in our attached Figure 1. \n\n \n\n2. Demo of on-FPGA training training acceletator. Due to the high reduction ratio of training variables, the tensor-compressed methods allow us to perform resource-efficeint and energy-efficient training on edge devices. As shown in Fig. 2, we have developed an FPGA prototyope for a two-layer neural network, which achieved about 300X reduction of model parameters. This allows effficient processing with on-chip memory, leading to  59X speedup and  123X energy reduction compared to embedded CPU.\n\n \n\n3. Architecture-level design for tensor computation framework. Specifically, we have designed an FPGA accelerator for Tucker-format tensor decomposition. We have also designed a tensor-train processing engine,  which achiees on average 14.9X ? 36.9X speedup over CPU implementations and 4.1X ? 9.9X speedup compared to the GPU baseline. Finally, we also deveploed an efficient processing architecture for sparse tensor decomposition via unified abstraction and PE-interactive architecture. This method can achieve can achieve an average speedup of 45x over CPU and 29x over GPU.\n\n \n\nBesides regular conference presentations, the research results of this project have been presented at over 20 research instutitions and industrial research labs. The research results have been integrated with the UCSB's graduate course of tensor computation, and the lecture notes have been offered to many peer research groups for free. Four graduate students, one postdoc, and 2 undergraduate students have participated in this project. \n\n \n\n\t\t\t\t\tLast Modified: 08/01/2022\n\n\t\t\t\t\tSubmitted by: Zheng Zhang"
 }
}