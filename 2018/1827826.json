{
 "awd_id": "1827826",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Participatory Technology Assessment and Cultures of Expertise",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Frederick Kronz",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-02-28",
 "tot_intn_awd_amt": 96096.0,
 "awd_amount": 96096.0,
 "awd_min_amd_letter_date": "2018-08-15",
 "awd_max_amd_letter_date": "2020-07-17",
 "awd_abstract_narration": "This award supports a research project that studies efforts to democratize expertise in the context of federal agency decision-making. It investigates whether and how participatory technology assessments have change expert cultures at NASA, NOAA, and DOE. Very little is known about how participatory technology assessments, which are public engagement exercises where different stakeholder groups (including citizen organizations, state systems, and non-government agencies) interact with technical scientist and technical expert groups, impact agency decision-making processes and the ways that technical experts think about lay citizens. The case studies of federal government agencies and their participatory technology assessment practices that are to be developed in this project have the potential to inform how numerous types of technical experts plan and implement such assessments in practice; it will result in practical lessons learned for improving future collaborations. Beyond academic publications and conference presentations, the results of this study will be used to develop a best practices handbook for effective collaboration between boundary organizations that specialize in public engagement and government agencies. Results will be presented at the Arizona State Consortium for Science Policy Outcomes seminar series in Washington, DC, which has a long history of engaging local and federal agencies, NGOs, and academics interested in the practical application of research.\r\n\r\nThis research project will use a combination of in-depth interviews and document analysis to assess whether and how participatory technology assessments lead to reflexive changes in expert views on public input and knowledge, including how experts perceive and implement public engagement practices in decision making. The research team has access to technical expert decision-makers in the U.S. federal government context. As a result, the study will be able to address fundamental knowledge gaps in the public engagement and expertise literature. It will provide a comparative, applied account of federal agency expert reflections on their participation in the adoption, framing, and implementation of participatory technology assessment and the integration of assessment results into decision-making processes. It will bring to light how particular federal agency experts and expert groups are influenced by and challenge the assessment process, and it will explore the extent to which such assessments serve the role of a reflexive learning device for technical expert decision-makers. It may also serve to substantiate existing theories in the public engagement and expertise literature that merely postulates improvements in decision making processes and techno-scientific cultural change through public engagement exercises.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Tomblin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Tomblin",
   "pi_email_addr": "dtomblin@umd.edu",
   "nsf_id": "000740713",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "3112 Lee Bldg 7809 Regents Drive",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425103",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760300",
   "pgm_ele_name": "STS-Sci, Tech & Society"
  },
  {
   "pgm_ele_code": "762600",
   "pgm_ele_name": "SciSIP-Sci of Sci Innov Policy"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7567",
   "pgm_ref_txt": "SOC STUDIES OF SCI, ENG & TECH"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 26816.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 26025.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 43255.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our study explored two important previously understudied facets of the process of adopting, designing, implementing, and evaluating participatory technology assessment (pTA) forums (a method for collecting diverse, informed public knowledge about science and technology issues) in the U.S. government agency context: 1) the bureaucratic complexity and challenges of doing pTA, and 2) the contextual implementation and adaptation of pTA methods to different U.S. agency contexts. Our findings are derived from the review of over 100 documents and 32 interviews of public engagement organizers, federal government agency personnel, and government contractors involved with pTA projects at the National Aeronautics and Space Administration (NASA), Department of Energy (DOE), and the National Oceanic and Atmospheric Administration (NOAA).</p>\n<p>The first part of the study shined light on the internal workings of government agencies adopting pTA as a public engagement strategy. Our findings show that the process of developing pTA can be facilitated or hindered depending on three conditions: 1) organizational culture (e.g., historical experience with the public; how controversial a topic is; whether experimentation with public engagement is encouraged); &nbsp;2) the influence of broader political controls that constrain an agency?s freedom to independently make decisions (e.g., changing presidential administrations; existing federal laws governing how government agencies can interact with the public); and 3) the presence or absence of agency personnel that have working knowledge of the value and methods of pTA and how to navigate existing federal laws that govern agency interactions with the public (or public engagement methods in general). These findings will help government agencies facilitate the adoption of pTA as a public engagement practice.&nbsp;</p>\n<p>The second part of the study took a deep look at how pTA methods developed by a single pTA practitioner network change from context to context. This is important because little is known about how the procedures and norms of this method are influenced by institutional context. One concern often expressed in the literature about using pTA in the government is that it is implemented as a one-size-fits-all process that serves as a check-the-box exercise for rubber-stamping existing policy commitments. This study shows the contrary. The development of pTA forums varied from context to context, involving intense negotiations between the pTA practitioners and government agency personnel on the purpose of the forums, the framing of the public inquiry, and the meaning of the public outputs.</p>\n<p>Furthermore, for agency personnel that participated in the design of the forums, pTA came to mean many things and helped structure important conversations about science and technology issues that otherwise wouldn?t have happened. Depending on the context, agency personnel see pTA as a process and a platform for collaborative experiments; participatory planning; understanding public values; reframing an agency issue or goal; building public trust and ownership of a policy or issue; informing decision making; reaching and hearing underrepresented communities; reflecting on organizational commitments; and expanding collective literacy or capacity of the public. These findings demonstrate that pTA is a highly flexible and adaptable public engagement tool that not only offers opportunities for empowering the public in science and technology decision-making matters, but also promotes co-learning among the public, agency personnel, and pTA practitioners. pTA also serves the diverse needs of different government agencies and the issues they are contending with and offers important reflection points for agency personnel on science and technology policy and the role of the public in decision-making.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/21/2023<br>\n\t\t\t\t\tModified by: David&nbsp;Tomblin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOur study explored two important previously understudied facets of the process of adopting, designing, implementing, and evaluating participatory technology assessment (pTA) forums (a method for collecting diverse, informed public knowledge about science and technology issues) in the U.S. government agency context: 1) the bureaucratic complexity and challenges of doing pTA, and 2) the contextual implementation and adaptation of pTA methods to different U.S. agency contexts. Our findings are derived from the review of over 100 documents and 32 interviews of public engagement organizers, federal government agency personnel, and government contractors involved with pTA projects at the National Aeronautics and Space Administration (NASA), Department of Energy (DOE), and the National Oceanic and Atmospheric Administration (NOAA).\n\nThe first part of the study shined light on the internal workings of government agencies adopting pTA as a public engagement strategy. Our findings show that the process of developing pTA can be facilitated or hindered depending on three conditions: 1) organizational culture (e.g., historical experience with the public; how controversial a topic is; whether experimentation with public engagement is encouraged);  2) the influence of broader political controls that constrain an agency?s freedom to independently make decisions (e.g., changing presidential administrations; existing federal laws governing how government agencies can interact with the public); and 3) the presence or absence of agency personnel that have working knowledge of the value and methods of pTA and how to navigate existing federal laws that govern agency interactions with the public (or public engagement methods in general). These findings will help government agencies facilitate the adoption of pTA as a public engagement practice. \n\nThe second part of the study took a deep look at how pTA methods developed by a single pTA practitioner network change from context to context. This is important because little is known about how the procedures and norms of this method are influenced by institutional context. One concern often expressed in the literature about using pTA in the government is that it is implemented as a one-size-fits-all process that serves as a check-the-box exercise for rubber-stamping existing policy commitments. This study shows the contrary. The development of pTA forums varied from context to context, involving intense negotiations between the pTA practitioners and government agency personnel on the purpose of the forums, the framing of the public inquiry, and the meaning of the public outputs.\n\nFurthermore, for agency personnel that participated in the design of the forums, pTA came to mean many things and helped structure important conversations about science and technology issues that otherwise wouldn?t have happened. Depending on the context, agency personnel see pTA as a process and a platform for collaborative experiments; participatory planning; understanding public values; reframing an agency issue or goal; building public trust and ownership of a policy or issue; informing decision making; reaching and hearing underrepresented communities; reflecting on organizational commitments; and expanding collective literacy or capacity of the public. These findings demonstrate that pTA is a highly flexible and adaptable public engagement tool that not only offers opportunities for empowering the public in science and technology decision-making matters, but also promotes co-learning among the public, agency personnel, and pTA practitioners. pTA also serves the diverse needs of different government agencies and the issues they are contending with and offers important reflection points for agency personnel on science and technology policy and the role of the public in decision-making.\n\n\t\t\t\t\tLast Modified: 06/21/2023\n\n\t\t\t\t\tSubmitted by: David Tomblin"
 }
}