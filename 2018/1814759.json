{
 "awd_id": "1814759",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: LDPD-Net: A Framework for Accelerated Architectures for Low-Density Permuted-Diagonal Deep Neural Networks",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 275000.0,
 "awd_amount": 291000.0,
 "awd_min_amd_letter_date": "2018-06-22",
 "awd_max_amd_letter_date": "2020-04-17",
 "awd_abstract_narration": "Deep learning has emerged as an important form of machine-learning where multiple layers of neural networks can learn the system function from available input-output data. Deep learning has outperformed traditional machine-learning algorithms based on feature engineering in fields such as image recognition, healthcare, and autonomous vehicles. These are widely used in cloud computing where large amount of computational resources are available. Deep neural networks are typically trained using graphic processing units (GPUs) or tensor processing units (TPUs). The training time and energy consumption grow with the complexity of the neural network. This project attempts to impose sparsity and regularity as constraints on the structure of the deep neural networks to reduce complexity and energy consumption by orders of magnitude, possibly at the expense of a slight degradation in the performance. The impacts lie in the formulation of a new family of structures for neural networks referred to as Low-Density Permuted Diagonal Network or LDPD-Net. The approach will enable the deployment of deep neural networks in energy-constrained and resource-constrained embedded platforms for inference tasks, including, but not limited to, unmanned vehicles/aerial systems, personalized healthcare, wearable and implantable devices, and mobile intelligent systems. In addition, the design methodology/techniques developed in this project can facilitate investigation of efficient computing of other matrix/tensor-based big data processing and analysis approaches. These approaches may also find applications in data-driven neuroscience and data-driven signal processing. In addition to graduate students, the project will involve undergraduates via senior design projects and research experiences for undergraduates. The results of the project will be disseminated to the broader community by publications, presentations, talks at various industries and other academic institutions. \r\n\r\nThe main barriers to wide adoption of deep learning networks include computational resource constraints and energy consumption constraints. These barriers can be relaxed by imposing sparsity and regularity among different layers of the deep neural network. The proposed low-density permuted-diagonal (LDPD) network can lead to orders of magnitude reduction in computation complexity, storage space and energy consumption. The LDPD-Net will not be retrained by first training a regular network and then only retaining the weights corresponding to the LDPD-Net. Instead, the proposed network will be trained from scratch. The proposed LDPD-Net can enable scaling of the network for a specified computational platform. The proposed research has three thrusts: 1) develop novel resource-constrained and energy-constrained inference and training systems;  2) develop novel efficient hardware architectures that can fully exploit the advantages of the LDPD-Net to achieve high performance; and 3) perform novel software and hardware co-design and co-optimization to explore the design space of the LDPD-Net. Using these, the efficacy of the proposed LDPD-net will be validated and evaluated, via software implementations on high-performance systems, low-power embedded systems, and a hardware prototype on FPGA development boards.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Keshab",
   "pi_last_name": "Parhi",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Keshab K Parhi",
   "pi_email_addr": "parhi@umn.edu",
   "nsf_id": "000208606",
   "pi_start_date": "2018-06-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "University of Minnesota-Twin Cities",
  "perf_str_addr": "200 Union St. S.E.",
  "perf_city_name": "Minneapolis",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "554550172",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MN05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 275000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Artificial intelligence (AI) plays a major role in our lives. Reducing energy consumption during training and inference of AI systems is crucial for scalability and sustainability, and is the main focus of this project.</p>\n<p>Intellectual Merit: Three main approaches are proposed for reducing memory access, latency and energy consumption during inference. First, a novel approach to regular sparsity in convolutional neural network, referred to as permuted diagonal approach, is introduced. The proposed approach can reduce energy consumption by factor of 3-5. Second, a novel fast two-dimensional convolution is proposed and applied to reduce the number of multiplications in convolutional neural networks. Third, hyperdimensional computing, a form of brain-inspired computing, is applied to detect seizures. With respect to reducing energy consumption in training neural networks, a novel gradient interleaving approach is introduced to reduce memory access and latency during backpropagation. The computations of the gradients of the loss function with respect to the activation and weight coefficients can be computed in an interleaved manner in the same systolic array as opposed to in a sequential manner.</p>\n<p>Braoder Impact: The broader impact of the research lies in reducing energy consumption in inference and tarining of neural networks. The energy reduction is critical for both edge and cloud devices.&nbsp; The project has trained two Ph.D. students and five undergraduates (including 4 NSF REU students). Two of the undergraduates have published first-authored conference papers. One of the undergraduate students won the NSF GRFP and started his Ph.D. at the University of Michigan. Two tutorial papers have been published to disseminate foundational knowledge. A tutorial paper on brain-inspired computing has been published in IEEE Open Journal on Circuits and Systems (OJCAS). A tutorial paper on hyperdimensional computing has been published in IEEE Circuits and Systems Magazine. Original research papers have been published in IEEE Trans. Circuits and Systems-I and&nbsp; IEEE OJCAS. The research results have been disseminated at conferences such as IEEE ISCAS, IEEE ICASSP, ACM/IEEE MICRO and Asilomar. The results of the research have been disseminated at several industries, at conference tutorials, and at various institutions as part of IEEE Circuits and Systems society distinguished lecturer program.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/09/2022<br>\n\t\t\t\t\tModified by: Keshab&nbsp;K&nbsp;Parhi</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1814759/1814759_10552273_1667987895246_parhi4-3163075-large--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1814759/1814759_10552273_1667987895246_parhi4-3163075-large--rgov-800width.jpg\" title=\"Hyperdimensional Computing\"><img src=\"/por/images/Reports/POR/2022/1814759/1814759_10552273_1667987895246_parhi4-3163075-large--rgov-66x44.jpg\" alt=\"Hyperdimensional Computing\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Seizure detection using Hyperdimensional Computing from Power Spectral Density of iEEG</div>\n<div class=\"imageCredit\">IEEE OJCAS 2022</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Keshab&nbsp;K&nbsp;Parhi</div>\n<div class=\"imageTitle\">Hyperdimensional Computing</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nArtificial intelligence (AI) plays a major role in our lives. Reducing energy consumption during training and inference of AI systems is crucial for scalability and sustainability, and is the main focus of this project.\n\nIntellectual Merit: Three main approaches are proposed for reducing memory access, latency and energy consumption during inference. First, a novel approach to regular sparsity in convolutional neural network, referred to as permuted diagonal approach, is introduced. The proposed approach can reduce energy consumption by factor of 3-5. Second, a novel fast two-dimensional convolution is proposed and applied to reduce the number of multiplications in convolutional neural networks. Third, hyperdimensional computing, a form of brain-inspired computing, is applied to detect seizures. With respect to reducing energy consumption in training neural networks, a novel gradient interleaving approach is introduced to reduce memory access and latency during backpropagation. The computations of the gradients of the loss function with respect to the activation and weight coefficients can be computed in an interleaved manner in the same systolic array as opposed to in a sequential manner.\n\nBraoder Impact: The broader impact of the research lies in reducing energy consumption in inference and tarining of neural networks. The energy reduction is critical for both edge and cloud devices.  The project has trained two Ph.D. students and five undergraduates (including 4 NSF REU students). Two of the undergraduates have published first-authored conference papers. One of the undergraduate students won the NSF GRFP and started his Ph.D. at the University of Michigan. Two tutorial papers have been published to disseminate foundational knowledge. A tutorial paper on brain-inspired computing has been published in IEEE Open Journal on Circuits and Systems (OJCAS). A tutorial paper on hyperdimensional computing has been published in IEEE Circuits and Systems Magazine. Original research papers have been published in IEEE Trans. Circuits and Systems-I and  IEEE OJCAS. The research results have been disseminated at conferences such as IEEE ISCAS, IEEE ICASSP, ACM/IEEE MICRO and Asilomar. The results of the research have been disseminated at several industries, at conference tutorials, and at various institutions as part of IEEE Circuits and Systems society distinguished lecturer program.\n\n\t\t\t\t\tLast Modified: 11/09/2022\n\n\t\t\t\t\tSubmitted by: Keshab K Parhi"
 }
}