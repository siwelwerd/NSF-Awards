{
 "awd_id": "1749204",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Safe and Efficient Robot Learning from Demonstration in the Real World",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Juan Wachs",
 "awd_eff_date": "2018-06-01",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 524605.0,
 "awd_amount": 524605.0,
 "awd_min_amd_letter_date": "2018-03-23",
 "awd_max_amd_letter_date": "2020-06-01",
 "awd_abstract_narration": "General purpose robots are poised to enter the home and workplace in unprecedented numbers in coming years, but face the significant challenge of customization - the ability to perform user-specified tasks in many different unstructured environments. In response to this need, robot learning from demonstration (LfD) has emerged as a paradigm that allows users to quickly and naturally program robots by simply showing them how to perform a task, rather than by writing code. This methodology aims to allow non-expert users to program robots, as well as communicate embodied knowledge that is difficult to translate into formal code. However, current state-of-the-art LfD algorithms are not yet ready for widespread deployment, as they are often unreliable, need too much data, and are designed to learn in a single session in a laboratory setting.  This work addresses these issues to help enable future robots to perform important tasks ranging from in-home elderly care to reconfigurable manufacturing.\r\n\r\nSpecifically, this work identifies three significant technical improvements to current LfD algorithms that are needed before they can be deployed in the real world: the need for safety guarantees, the ability to learn from very limited amounts of data, and the ability to continually improve in an ongoing, life-long fashion.  A formal theory of safe LfD is developed, along with practical algorithms that provide strong probabilistic lower bounds on agent performance.  Algorithmic efficiency is addressed via a re-examining of common statistical assumptions (such as independent and identically distributed data) and through the use of multimodal side-information, such as natural language and gaze.  Finally, active learning strategies and modeling of human beliefs are used to enable interactive, continual learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Scott",
   "pi_last_name": "Niekum",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Scott D Niekum",
   "pi_email_addr": "sniekum@cs.umass.edu",
   "nsf_id": "000663218",
   "pi_start_date": "2018-03-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "2317 Speedway",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121757",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 137302.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 141013.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 24412.0
  }
 ],
 "por": null
}