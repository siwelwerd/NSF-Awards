{
 "awd_id": "1830146",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: FND: COLLAB: Intuitive, Wearable Haptic Devices for Communication with Ubiquitous Robots",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Harry Dankowicz",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 327242.0,
 "awd_amount": 375242.0,
 "awd_min_amd_letter_date": "2018-08-27",
 "awd_max_amd_letter_date": "2022-03-31",
 "awd_abstract_narration": "This National Robotics Initiative (NRI) project will promote the progress of science and beneficially impact human health and quality of life by developing wearable soft robotic devices with distributed tactile stimulation that enable new forms of communication. Human-robot interactions will be commonplace in the near future.  In applications such as self-driving cars and physically assistive devices, interaction will require effective and intuitive bidirectional communication.  Transferring information through vision and sound can be slow and inappropriate in many circumstances.  This project focuses on haptic (touch-based) robotics to enable communication in a salient but private manner that alleviates demands on other sensory channels. This project serves the national interest by advancing knowledge in the fields of human perception, psychology and neuroscience, while developing novel, convergent technology that integrates concepts across the fields of robotics, haptics, and control engineering. Project results will be disseminated through tactile haptic devices for education and publicly available software and data. The project aims to broaden participation of underrepresented groups in engineering through outreach programs, public lab tours, and the mentoring of female and minority graduate students, undergraduates, and high school students.\r\n\r\nWearable haptic systems have the potential to enable private, salient communication between humans and intelligent systems through an underutilized sensory channel (somatosensation). In this research, information will be transmitted through the haptic channel via wearable, ubiquitous, soft robotic devices that provide both passive and active touch interactions with the human user. This research is comprised of four main objectives. First, a characterization of human perception of the forearm will set the requirements for the frequency, amplitude, directions, spacing, and temporal actuation patterns for a two-dimensional array of haptic stimulators that are able to convey a range of haptic cues. Second, the project will develop a wearable, soft, haptic device able to stimulate the skin of one forearm, while also providing mechanical stimuli that are intended to be explored by the fingertips of the other hand. Third, the project will develop rendering algorithms for the haptic device that take into consideration human perceptual abilities for passive stimulation of the arm and active exploration by the fingertips. Fourth, the project team will create application scenarios to evaluate and refine the system. Wearable haptic systems have potential to improve human health and well-being through a variety of applications including: physical cueing for rehabilitation/movement therapy; explosive ordnance defusing; feedback from assistive devices including mobile robots in the home; tactile communication to enable design and e-commerce; immersion in virtual worlds for education; and the facilitation of remote interaction between people.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Marcia",
   "pi_last_name": "O'Malley",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Marcia K O'Malley",
   "pi_email_addr": "omalleym@rice.edu",
   "nsf_id": "000274808",
   "pi_start_date": "2018-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "William Marsh Rice University",
  "inst_street_address": "6100 MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "Houston",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7133484820",
  "inst_zip_code": "770051827",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "TX09",
  "org_lgl_bus_name": "WILLIAM MARSH RICE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "K51LECU1G8N3"
 },
 "perf_inst": {
  "perf_inst_name": "William Marsh Rice University",
  "perf_str_addr": "",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "770051827",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "TX09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "116E",
   "pgm_ref_txt": "RESEARCH EXP FOR UNDERGRADS"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9231",
   "pgm_ref_txt": "SUPPL FOR UNDERGRAD RES ASSIST"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 327242.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Haptic devices allow touch-based information transfer between humans and intelligent systems -- enabling communication in a salient but private manner that frees other sensory channels. For such devices to become ubiquitous, they must be intuitive, unobtrusive, and wearable. However, the amount of information that can be transmitted through touch is limited in large part by the location and distribution of human mechanoreceptors. Our goal was to create wearable soft devices with distributed multi-modal haptic actuation that is mounted on the body and can also be actively touched by the fingertips. This approach could provide low-resolution haptic feedback appropriate for human perceptual abilities on the body (passive feeling), and also takes advantage of fingertip perception by allowing high- resolution information transfer when needed by the user (active touching). This project aimed to create new forms of communication and lead to increased capabilities of wearable devices that could impact human health and quality of life.</p>\n<p>In this project, we developed several open source tools to design, fabricate, and control wearable devices that provide haptic feedback to users. Snaptics (snaptics.org) is a low-cost platform designed for rapid prototyping of fully wearable multi-sensory haptic devices. Snaptics uses modular framework allowing designers to quickly test and replace snaptic modules as desired. All modules are designed to be assembled using 3D printed components and inexpensive off-the-shelf actuators to minimize costs to the designer. Our platform exists to increase community engagement with and accessibility of wearable haptic devices by lowering the technical barrier to entry and cost of creating a wearable haptic device. Syntacts (syntacts.org) is a haptic rendering framework for vibrotactile feedback. It eliminates the need for expensive haptic controllers or custom electronics by leveraging commercial-off-the-shelf audio interfaces. As a complete package, Syntacts provides the software and hardware needed to interface audio devices with low latency, synthesize complex waveforms, and amplify signals to appropriate levels.</p>\n<p>We conducted psychophysical experiments with human subjects to better understand the perception of multi-sensory haptic cues that combine vibration, skin stretch, and squeeze. We demonstrated the saliency and usability of Snaptics devices with their equivalent research grade counterparts in two experiments. Results indicate that users perform equally well in perceiving cue sets and in completing tasks when using Snaptics devices as compared to when using their research grade counterparts. Using a custom-designed test bed, we showed that cue amplitude and separate distances affect accurate perception of multi-sensory cues. We also demonstrated that users can detect discrete cues that are provided simultaneously with continuous cues. We designed a custom vibrotactile sleeve (the VT Sleeve) and investigated how cue durations of 100, 200, and 400ms affect the overall localizability of tactile cues presented along the forearm by measuring the response means to six tactile cues, as well as the response variance to each cue (to determine error in response). Tactile location had a significant effect on overall localizability but the durations considered had no effect. We are currently investigating tactile durations outside the 100-400ms range.&nbsp;</p>\n<p>We designed hardware and conducted experiments to better understand the relationship between haptic cue perception and the contact mechanics occurring between the haptic device end effector and the skin. We used our novel grounded test bed to complete formal psychophysical tests under position and force control, to measure the maximum comfort threshold, minimum felt threshold, and the perceptual resolution. Correlations between the psychophysical and contact mechanics measurements show strong correlations between the elastic strain energy measured from the force data in the normal and shear experiments and the comfort threshold and discrimination thresholds in the normal and shear directions. The resulting data inform device design processes and provides a framework for achievable performance on an individualized basis, leading to more salient and effective haptic feedback devices.</p>\n<p>Finally, we developed wearable haptic devices and explored through pilot experiments how such devices can be used to elicit predictable emotional responses in users, with the goal of incorporating these devices as tools for emotion regulation, an approach used to treat mental disorders. We also conducted pilot experiments to better understand the neural correlates of haptic perception. We conducted an exploratory study to evaluate Representational Similarity Analysis (RSA) of electroencephalography (EEG) signals as a general method and specifically used our EEG-RSA framework to evaluate changes in the neural representation of haptic cues after association training, where the subject learned to map discrete phonemes to multi-sensory haptic cues. Our results suggest that training leads to a sharpening of the sensory response to haptic cues such that after training the neural representation of haptic cues starts to reflect the features of the cues themselves.</p>\n<p>Throughout the project effort, we developed educational materials to teach concepts with haptics, we provided our tools and results through open access (software and publications), and we disseminated our findings through publications and presentations.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/07/2022<br>\n\t\t\t\t\tModified by: Marcia&nbsp;K&nbsp;O'malley</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nHaptic devices allow touch-based information transfer between humans and intelligent systems -- enabling communication in a salient but private manner that frees other sensory channels. For such devices to become ubiquitous, they must be intuitive, unobtrusive, and wearable. However, the amount of information that can be transmitted through touch is limited in large part by the location and distribution of human mechanoreceptors. Our goal was to create wearable soft devices with distributed multi-modal haptic actuation that is mounted on the body and can also be actively touched by the fingertips. This approach could provide low-resolution haptic feedback appropriate for human perceptual abilities on the body (passive feeling), and also takes advantage of fingertip perception by allowing high- resolution information transfer when needed by the user (active touching). This project aimed to create new forms of communication and lead to increased capabilities of wearable devices that could impact human health and quality of life.\n\nIn this project, we developed several open source tools to design, fabricate, and control wearable devices that provide haptic feedback to users. Snaptics (snaptics.org) is a low-cost platform designed for rapid prototyping of fully wearable multi-sensory haptic devices. Snaptics uses modular framework allowing designers to quickly test and replace snaptic modules as desired. All modules are designed to be assembled using 3D printed components and inexpensive off-the-shelf actuators to minimize costs to the designer. Our platform exists to increase community engagement with and accessibility of wearable haptic devices by lowering the technical barrier to entry and cost of creating a wearable haptic device. Syntacts (syntacts.org) is a haptic rendering framework for vibrotactile feedback. It eliminates the need for expensive haptic controllers or custom electronics by leveraging commercial-off-the-shelf audio interfaces. As a complete package, Syntacts provides the software and hardware needed to interface audio devices with low latency, synthesize complex waveforms, and amplify signals to appropriate levels.\n\nWe conducted psychophysical experiments with human subjects to better understand the perception of multi-sensory haptic cues that combine vibration, skin stretch, and squeeze. We demonstrated the saliency and usability of Snaptics devices with their equivalent research grade counterparts in two experiments. Results indicate that users perform equally well in perceiving cue sets and in completing tasks when using Snaptics devices as compared to when using their research grade counterparts. Using a custom-designed test bed, we showed that cue amplitude and separate distances affect accurate perception of multi-sensory cues. We also demonstrated that users can detect discrete cues that are provided simultaneously with continuous cues. We designed a custom vibrotactile sleeve (the VT Sleeve) and investigated how cue durations of 100, 200, and 400ms affect the overall localizability of tactile cues presented along the forearm by measuring the response means to six tactile cues, as well as the response variance to each cue (to determine error in response). Tactile location had a significant effect on overall localizability but the durations considered had no effect. We are currently investigating tactile durations outside the 100-400ms range. \n\nWe designed hardware and conducted experiments to better understand the relationship between haptic cue perception and the contact mechanics occurring between the haptic device end effector and the skin. We used our novel grounded test bed to complete formal psychophysical tests under position and force control, to measure the maximum comfort threshold, minimum felt threshold, and the perceptual resolution. Correlations between the psychophysical and contact mechanics measurements show strong correlations between the elastic strain energy measured from the force data in the normal and shear experiments and the comfort threshold and discrimination thresholds in the normal and shear directions. The resulting data inform device design processes and provides a framework for achievable performance on an individualized basis, leading to more salient and effective haptic feedback devices.\n\nFinally, we developed wearable haptic devices and explored through pilot experiments how such devices can be used to elicit predictable emotional responses in users, with the goal of incorporating these devices as tools for emotion regulation, an approach used to treat mental disorders. We also conducted pilot experiments to better understand the neural correlates of haptic perception. We conducted an exploratory study to evaluate Representational Similarity Analysis (RSA) of electroencephalography (EEG) signals as a general method and specifically used our EEG-RSA framework to evaluate changes in the neural representation of haptic cues after association training, where the subject learned to map discrete phonemes to multi-sensory haptic cues. Our results suggest that training leads to a sharpening of the sensory response to haptic cues such that after training the neural representation of haptic cues starts to reflect the features of the cues themselves.\n\nThroughout the project effort, we developed educational materials to teach concepts with haptics, we provided our tools and results through open access (software and publications), and we disseminated our findings through publications and presentations.\n\n \n\n\t\t\t\t\tLast Modified: 10/07/2022\n\n\t\t\t\t\tSubmitted by: Marcia K O'malley"
 }
}