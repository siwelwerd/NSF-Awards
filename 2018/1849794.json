{
 "awd_id": "1849794",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CDS&E-MSS/Collaborative Research:   Sequential Design for Stochastic Control: Active Learning of Optimal Policies",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Christopher Stark",
 "awd_eff_date": "2018-02-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 19806.0,
 "awd_amount": 19806.0,
 "awd_min_amd_letter_date": "2018-08-21",
 "awd_max_amd_letter_date": "2018-08-21",
 "awd_abstract_narration": "This research project aims to build new cross-disciplinary algorithms that blend concepts from applied probability, control, and statistical modeling to tackle computational challenges in large-scale optimization. Creation of such new links is another step in building a next-generation of high-performance algorithms needed to meet the increasingly complex problems arising in applications as diverse as finance, energy storage and security, and the management of epidemics. The project's research agenda is grounded in two concrete application areas where it is crucial to tackle industrial-grade high-fidelity models. One is the efficient management of cycled commodity assets, including gas storage, battery storage, or fleets of power plants as energy infrastructure is transitioned to the \"smart grid.\" A second is timely and effective response to unfolding infectious disease outbreaks, notably influenza. Both present major cross-disciplinary challenges. We see vast potential for algorithms which expand capabilities for aspects of quantitative control, and thus provide higher quality information to decision makers. Our goal is to produce a smarter, more targeted, use of random numbers in a new wave of lean stochastic solvers, and subsequently an expansion of the size of problems that can be tackled with existing computing capabilities. The educational core of the project contributes to inter-disciplinary training in mathematical sciences across undergraduate, graduate and postdoctoral levels. The collaborative initiatives will also enhance the research infrastructure through exchange of ideas between the two campuses (Univesrity of California-Santa Barbara and University of Chicago) and communities of statisticians, operations researchers and engineers. All algorithms would be documented and publicly released to the wider scientific community. \r\n\r\nDeployment of simulation based schemes remains key for control of stochastic systems that require realistic high-fidelity representations. This project will develop new Monte Carlo algorithms for a class of stochastic control problems by erecting novel bridges between dynamic control and methods of sequential design and statistical learning. Our research agenda hinges on sequential, active learning of optimal action sets, so that the algorithms adaptively allocate computing resources to better enhance fidelity of the approximated control strategies. Such targeted use of Monte Carlo simulations links approximate dynamic programming with response surface modeling, marrying two so-far disparate areas of applied mathematics and statistics. The resulting adaptive schemes will facilitate orders of magnitude savings in simulation budgets, expanding the frontier for predictive modeling and decision making under uncertainty. The proposed research will advance the theory of algorithms for dynamic control over massive multi-dimensional state spaces, where curses of dimensionality are unavoidable. Simultaneously, integration of the statistical and computational theories in this direction will open new lines of interdisciplinary quantitative research. Through enhancing knowledge discovery in large-scale control settings, the projects will facilitate transition to practice in novel contexts. With the aim of reaching out to diverse users from the mathematical, biological, physical and engineering sciences, producing general purpose open-source software via R packages is a primary deliverable of the project, and will be supplemented by a database of case studies.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Gramacy",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Robert B Gramacy",
   "pi_email_addr": "rbg@vt.edu",
   "nsf_id": "000614645",
   "pi_start_date": "2018-08-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Polytechnic Institute and State University",
  "inst_street_address": "300 TURNER ST NW",
  "inst_street_address_2": "STE 4200",
  "inst_city_name": "BLACKSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "5402315281",
  "inst_zip_code": "240603359",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "VA09",
  "org_lgl_bus_name": "VIRGINIA POLYTECHNIC INSTITUTE & STATE UNIVERSITY",
  "org_prnt_uei_num": "X6KEFGLHSJX7",
  "org_uei_num": "QDE5UHE5XD16"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Polytechnic Institute and State University",
  "perf_str_addr": "300 Turner Street NW",
  "perf_city_name": "Blacksburg",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "240610001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "VA09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "006Y00",
   "pgm_ele_name": "OE Operations Engineering"
  },
  {
   "pgm_ele_code": "125300",
   "pgm_ele_name": "OFFICE OF MULTIDISCIPLINARY AC"
  },
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8084",
   "pgm_ref_txt": "CDS&E"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 19806.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Historically, design and analysis of computer experiments focused on deterministic solvers from the physical sciences via Gaussian process (GP) interpolation. But nowadays computer modeling is common in the social,&nbsp;management&nbsp;and biological&nbsp;sciences, where stochastic simulations abound.&nbsp;<a href=\"https://en.wikipedia.org/wiki/Queueing_theory\">Queueing systems</a>&nbsp;and&nbsp;<a href=\"https://en.wikipedia.org/wiki/Agent-based_model\">agent-based models</a>&nbsp;replace finite elements and simple Monte Carlo with geometric convergence. Data in geostatistics&nbsp;and machine learning&nbsp;<span class=\"citation\">(ML)</span>&nbsp;are not only noisy but frequently involve signal-to-noise ratios that are low or changing over the input space. Noisier simulations/observations demand bigger experiments/studies to isolate signal from noise, and more sophisticated GP models &ndash; not just adding nuggets to smooth the noise, but variance processes to track changes in noise throughout the input space in the face of that&nbsp;<em>heteroskedasticity</em>.</p>\n<p>Modeling methodology for large simulation efforts with intrinsic stochastic dynamics has lagged until recently. Partitioning is one option, but leaves something to be desired when underlying processes are smooth and signal-to-noise ratios are low. A theme in outcomes from this funded research that&nbsp;<em>replication</em>, a tried and true design strategy for separating signal from noise, can play crucial role in computationally efficient heteroskedastic modeling, especially with GPs. In&nbsp;<a href=\"https://en.wikipedia.org/wiki/Operations_research\">operations research</a>, stochastic kriging&nbsp;<span class=\"citation\">(SK)</span>&nbsp;offers approximate methods that exploit large degrees of replication. Its independent&nbsp;<a href=\"https://en.wikipedia.org/wiki/Method_of_moments_(statistics)\">method of moments</a>-based inferential framework can yield an efficient heteroskedastic modeling capability. However the setup exploited by SK is highly specialized; moment-based estimation can strain coherency in a likelihood dominated surrogate landscape. We developed a heteroskedastic GP technology&nbsp;that offers a modern blend of SK and ideas from ML&nbsp;<span class=\"citation\">(largely predating SK)</span>.</p>\n<p>Besides leveraging replication in design, the idea is: what&rsquo;s good for the mean is good for the variance. If it&rsquo;s sensible to model the a latent (mean) field via GPs, why not extend that to variance too? Unfortunately latent variance fields are not as easy to integrate out. (Variances must also be positive, whereas means are less constrained.) Numerical schemes are required for latent learning, and there are a myriad of strategies.&nbsp; The&nbsp;scheme we developed remains within a familiar class of library-based (e.g., BFGS) likelihood-optimizing methodology.&nbsp; We paired this tractible hetGP model, paired with software released publically on CRAN,&nbsp; with tractable strategies for sequential design&nbsp;and Bayesian optimization (BO). Other approaches achieving a degree of input-dependent variance include quantile kriging&nbsp;<span class=\"citation\">(QK)</span>; use of pseudoinputs&nbsp;or predictive process; and (non-GP-based) tree methods. Unfortunately, none of those important methodological contributions, to our knowledge, pair with design, BO or open source implementation the way that hetGP does.&nbsp;&nbsp;</p>\n<p>With the release of transparent methodology and public implementation on CRAN we hope that researchers from wide swaths of applied science are able to make use of hetGP-based surrogate modeling strategies in practice.&nbsp; We have found success in applications from inventory management, epidemiology, predator-pray dynamics, modeling of ocean oxygen concentration, study of Bayes factors in MCMC-based model selection, and more.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/09/2019<br>\n\t\t\t\t\tModified by: Robert&nbsp;B&nbsp;Gramacy</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nHistorically, design and analysis of computer experiments focused on deterministic solvers from the physical sciences via Gaussian process (GP) interpolation. But nowadays computer modeling is common in the social, management and biological sciences, where stochastic simulations abound. Queueing systems and agent-based models replace finite elements and simple Monte Carlo with geometric convergence. Data in geostatistics and machine learning (ML) are not only noisy but frequently involve signal-to-noise ratios that are low or changing over the input space. Noisier simulations/observations demand bigger experiments/studies to isolate signal from noise, and more sophisticated GP models &ndash; not just adding nuggets to smooth the noise, but variance processes to track changes in noise throughout the input space in the face of that heteroskedasticity.\n\nModeling methodology for large simulation efforts with intrinsic stochastic dynamics has lagged until recently. Partitioning is one option, but leaves something to be desired when underlying processes are smooth and signal-to-noise ratios are low. A theme in outcomes from this funded research that replication, a tried and true design strategy for separating signal from noise, can play crucial role in computationally efficient heteroskedastic modeling, especially with GPs. In operations research, stochastic kriging (SK) offers approximate methods that exploit large degrees of replication. Its independent method of moments-based inferential framework can yield an efficient heteroskedastic modeling capability. However the setup exploited by SK is highly specialized; moment-based estimation can strain coherency in a likelihood dominated surrogate landscape. We developed a heteroskedastic GP technology that offers a modern blend of SK and ideas from ML (largely predating SK).\n\nBesides leveraging replication in design, the idea is: what?s good for the mean is good for the variance. If it?s sensible to model the a latent (mean) field via GPs, why not extend that to variance too? Unfortunately latent variance fields are not as easy to integrate out. (Variances must also be positive, whereas means are less constrained.) Numerical schemes are required for latent learning, and there are a myriad of strategies.  The scheme we developed remains within a familiar class of library-based (e.g., BFGS) likelihood-optimizing methodology.  We paired this tractible hetGP model, paired with software released publically on CRAN,  with tractable strategies for sequential design and Bayesian optimization (BO). Other approaches achieving a degree of input-dependent variance include quantile kriging (QK); use of pseudoinputs or predictive process; and (non-GP-based) tree methods. Unfortunately, none of those important methodological contributions, to our knowledge, pair with design, BO or open source implementation the way that hetGP does.  \n\nWith the release of transparent methodology and public implementation on CRAN we hope that researchers from wide swaths of applied science are able to make use of hetGP-based surrogate modeling strategies in practice.  We have found success in applications from inventory management, epidemiology, predator-pray dynamics, modeling of ocean oxygen concentration, study of Bayes factors in MCMC-based model selection, and more.\n\n \n\n\t\t\t\t\tLast Modified: 09/09/2019\n\n\t\t\t\t\tSubmitted by: Robert B Gramacy"
 }
}