{
 "awd_id": "1822872",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ROBO-VI: A Virtual-Internship-Based Hybrid Learning Technology to Prepare Traditional and Non-Traditional Students to Work with Collaborative Robots",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928447",
 "po_email": "cshen@nsf.gov",
 "po_sign_block_name": "Chia Shen",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 499123.0,
 "awd_amount": 499123.0,
 "awd_min_amd_letter_date": "2018-08-03",
 "awd_max_amd_letter_date": "2018-08-03",
 "awd_abstract_narration": "Collaborative robots are emerging as a new family of advanced technologies that are designed to work side-by-side with people in industrial settings. These robots can improve the productivity and flexibility in manufacturing and logistics industries, while also assisting workers in repetitive, and unhealthy or unsafe work conditions. Unlike traditional factory robots that are programmed and configured by engineers to function independently for long periods of time, collaborative robots require human workers to frequently interact with the robot, including training the robot, making the necessary changes in the environment for the robot to function, and supervising the robot's work to ensure its successful operation. The integration of collaborative robots into and operation within existing industrial settings require expert skills that many workers lack, and that current educational programs do not cover, highlighting a skills mismatch from the demands of an increasingly automated future of work. This project will develop an understanding of what skills workers will need to perform these tasks effectively and to design a hybrid digital-physical educational technology that will support worker education and training in these skills in classrooms and industrial-training facilities. The research team will evaluate the effects of the technology on skill development among trainees and make recommendations for future job-training programs. \r\n\r\nThe new hybrid technology will include an expert system computer program that will provide learners with explanations, visualizations, and simulations of key concepts and a robotic assistant that will provide physical demonstrations. This hybrid physical-digital learning environment will be used in expert-led instruction of traditional and non-traditional students in collaborative robotics. The research team will (1) develop an empirical model of expertise in working with collaborative robots through observations of and interviews with experts and analyses of expert-training programs and (2) iteratively design, build, and test a digital-physical hybrid learning environment, integrating an Expert-View Dashboard (EVD), to support expert-led instruction in educational and industrial-training settings. The resulting educational technology will provide educators and trainers with a powerful educational tool that will supplement the development of expertise in working with autonomous, intelligent, and collaborative technologies to meet the demands of an increasingly automated jobs landscape.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bilge",
   "pi_last_name": "Mutlu",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Bilge D Mutlu",
   "pi_email_addr": "bilge@cs.wisc.edu",
   "nsf_id": "000546805",
   "pi_start_date": "2018-08-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Shaffer",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "David W Shaffer",
   "pi_email_addr": "dws@education.wisc.edu",
   "nsf_id": "000169660",
   "pi_start_date": "2018-08-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andrew",
   "pi_last_name": "Ruis",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Andrew R Ruis",
   "pi_email_addr": "arruis@wisc.edu",
   "nsf_id": "000441037",
   "pi_start_date": "2018-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "1210 W Dayton St",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537061613",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 499123.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-79989037-7fff-064c-fb6c-5a72d9105b4e\"> <span id=\"docs-internal-guid-f86b0877-7fff-1312-8289-4ef4f91b0f01\"> </span></span></p>\n<p dir=\"ltr\">The use of collaborative robots, commonly referred to as \"cobots,\" is expected to greatly improve the safety, capability, and efficiency of work, especially in light-to-medium manufacturing and healthcare industries. Unlike conventional manufacturing-focused robots, cobots are designed to be safe around people. They can work directly alongside human workers, in human spaces, actively assisting them as they complete tasks by positioning materials in helpful ways, performing challenging actions, or simply acting as a second worker. To engage in these activities, cobots must be programmed and integrated into new tasks and work environments by experts with skills and knowledge in cobot programming and integration. Furthermore, people working alongside cobots must be able to operate, troubleshoot, and make minor modifications to robot programs without the need to rely on experts. However, experts, such as staff engineers and external robot specialists, lack the tools, experience, and expertise for such integration, and workers lack the tools and training to engage in the day-to-day operations of a cobot. As a result, despite their great promise, we see slow adoption and low utilization of cobots in industry. In order to address this challenge, this project aimed to address the skills gap in integrating and operating cobots by first understanding how cobot experts approach these problems and then applying that approach to create a system that supports engineers and workers in learning and programming cobots.</p>\n<p dir=\"ltr\"><img src=\"https://lh3.googleusercontent.com/PDkPBJC8tDjq4XQAVv_NO39jC27jyDCekvozlsyHsIbflmaKgxOpxJTzGfNppvOFSYT3jU7IGnU6V5R4PX3950dnq_9LTiK0738nXoRxu1rH5WUVyFdxenmBEu2D8LFSNBurO4kMFsg9SgerLtwhUQJBJ3he4z6p71jxlUpY_c2z3se0QPzd16yEueWr5w\" alt=\"\" width=\"436\" height=\"290\" /></p>\n<p dir=\"ltr\"><strong>Figure 1:</strong>&nbsp;A worker collaborates on a task with a robot</p>\n<p dir=\"ltr\">To better understand how cobot experts approached the problem of programming cobots to perform a given task and integrating them into specific work environments, the research team interviewed a diverse group of experts, developing an \"expert model\" of cobot programming and integration, called Safety First. The model took the form of a network with nodes representing the concepts and edges representing the strength of the connection between them. For example, the network shows strong connections between the&nbsp;<em>application</em>&nbsp;(the cobot's task) and concerns about the&nbsp;<em>operator</em>&nbsp;(the worker's task). To translate this model into a learning environment, the research team converted these concepts and connections into a set of four interrelated expert \"frames\" that provide different perspectives with which to evaluate a candidate cobot program. These frames were&nbsp;robot performance,&nbsp;safety concerns,&nbsp;program quality, and&nbsp;business objectives. Each frame enables the learner to consider a set of potential issues. For example, within the frame of safety concerns, issues include collisions or pinch points, while robot performance considers joint speed and reachability, among others.&nbsp;</p>\n<p dir=\"ltr\"><img src=\"https://lh6.googleusercontent.com/0ho4xV1vHeKGztxOEPsIQDotVPXtoOQbLo6zsQOLaDYJoh0eSHnGWgD45cTBq_x_RgdvndxdX-5LTKMDfWcT-qpm4SkHcesWo6YUm5NV2LN7aho9WbQqfJzbFdDuEzo13IwwcpFBUbt9zSWXnrA2I0YaBi_abA4hL9dfjuJ1Qu9Sd71fkgnuIChMgAkzLQ\" alt=\"\" width=\"555\" height=\"426\" /></p>\n<p dir=\"ltr\"><strong>Figure 2:</strong>&nbsp;Visualization of the expert model as well as the derived expert frames</p>\n<p dir=\"ltr\">These expert frames were incorporated into a new combined education-programming system called CoFrame, a web-based, open-source software tool that integrates built-in simulation, visual editing, and rich feedback. Using CoFrame, cobot programming novices can use the visual programming environment to construct a robot program and then request feedback from the various expert frames. By responding to the issues raised in each frame and navigating through their tradeoffs and dependencies, users can learn about the concepts within the expert model and the connections among them.</p>\n<p dir=\"ltr\"><img src=\"https://lh3.googleusercontent.com/6i9So0KeVQCHX1FCnWwjo69ClB_TIQjiDMZDFfbD6QZ8rDtZWnKXjwnEv59udKRBcBj3GUGDoj20EEB1Bsr7zU_Yg5w6nRgnZuwn4xaQDPsoJ_3wppffo-6kc8RUG6S8xZZXXv3ISUCYH-G4Ip06DZR3C5qiSYGDyHIQ7VEKSriBNQMFJI4BTLINt_rPrg\" alt=\"\" width=\"624\" height=\"335\" /></p>\n<p dir=\"ltr\"><strong>Figure 3:&nbsp;</strong>The CoFrame system. In this view, a user previews the current robot motion.</p>\n<p dir=\"ltr\">Concurrently with the development of the CoFrame system, the project team completed a set of studies to better understand considerations that arise when working with and tending to cobots regarding \"human-robot teaming.\" The first study applied concepts originating in human-animal teaming to human-robot teams, considering three levels of interdependence: pooled (independent, simultaneous work), sequential (alternating between two individuals), and reciprocal (subtasks are coordinated by specialization). Results showed that worker stress was minimized in reciprocal interdependence, while simultaneously eliciting a more collaborative perspective of the cobot. Another study investigated how attention management could be relevant to tasks such as machine tending, considering various approaches for robots to communicate upcoming tending or collaborative needs. This study resulted in the development of a method, called \"predictive robot attention demand (pRAD),\" that visualized the cobot's current and future task state to make working with a cobot less onerous and usable to workers.</p>\n<p dir=\"ltr\">The Safety First expert model, the pRAD method, human-robot teaming studies, and the CoFrame software, generated as part of this project, have furthered the scientific understanding of cobot usage and design, while introducing software and techniques of practical use for workers and businesses. Findings from the project have been shared with the public in the form of scientific publications, public lectures, and videos that have been published online. Software developed as part of the project has been made open source to bootstrap future development.&nbsp;The project provided four doctoral students in computer science with opportunities for advanced training and professional development. Multiple computer science undergraduate students gained hands-on research experience and received academic mentoring by participating in this project.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2022<br>\n\t\t\t\t\tModified by: Bilge&nbsp;D&nbsp;Mutlu</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1822872/1822872_10565821_1669783240389_Figure1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1822872/1822872_10565821_1669783240389_Figure1--rgov-800width.jpg\" title=\"Figure 1\"><img src=\"/por/images/Reports/POR/2022/1822872/1822872_10565821_1669783240389_Figure1--rgov-66x44.jpg\" alt=\"Figure 1\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A worker collaborates on a task with a robot</div>\n<div class=\"imageCredit\">Olivia Zhao</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Figure 1</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1822872/1822872_10565821_1669783295302_Figure2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1822872/1822872_10565821_1669783295302_Figure2--rgov-800width.jpg\" title=\"Figure 2\"><img src=\"/por/images/Reports/POR/2022/1822872/1822872_10565821_1669783295302_Figure2--rgov-66x44.jpg\" alt=\"Figure 2\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Visualization of the expert model, as well as the derived expert frames</div>\n<div class=\"imageCredit\">Andrew Schoen</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Figure 2</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1822872/1822872_10565821_1669783369742_Figure3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1822872/1822872_10565821_1669783369742_Figure3--rgov-800width.jpg\" title=\"Figure 3\"><img src=\"/por/images/Reports/POR/2022/1822872/1822872_10565821_1669783369742_Figure3--rgov-66x44.jpg\" alt=\"Figure 3\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The CoFrame system. In this view, a user previews the current robot motion.</div>\n<div class=\"imageCredit\">Andrew Schoen</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Figure 3</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n  \nThe use of collaborative robots, commonly referred to as \"cobots,\" is expected to greatly improve the safety, capability, and efficiency of work, especially in light-to-medium manufacturing and healthcare industries. Unlike conventional manufacturing-focused robots, cobots are designed to be safe around people. They can work directly alongside human workers, in human spaces, actively assisting them as they complete tasks by positioning materials in helpful ways, performing challenging actions, or simply acting as a second worker. To engage in these activities, cobots must be programmed and integrated into new tasks and work environments by experts with skills and knowledge in cobot programming and integration. Furthermore, people working alongside cobots must be able to operate, troubleshoot, and make minor modifications to robot programs without the need to rely on experts. However, experts, such as staff engineers and external robot specialists, lack the tools, experience, and expertise for such integration, and workers lack the tools and training to engage in the day-to-day operations of a cobot. As a result, despite their great promise, we see slow adoption and low utilization of cobots in industry. In order to address this challenge, this project aimed to address the skills gap in integrating and operating cobots by first understanding how cobot experts approach these problems and then applying that approach to create a system that supports engineers and workers in learning and programming cobots.\n\nFigure 1: A worker collaborates on a task with a robot\nTo better understand how cobot experts approached the problem of programming cobots to perform a given task and integrating them into specific work environments, the research team interviewed a diverse group of experts, developing an \"expert model\" of cobot programming and integration, called Safety First. The model took the form of a network with nodes representing the concepts and edges representing the strength of the connection between them. For example, the network shows strong connections between the application (the cobot's task) and concerns about the operator (the worker's task). To translate this model into a learning environment, the research team converted these concepts and connections into a set of four interrelated expert \"frames\" that provide different perspectives with which to evaluate a candidate cobot program. These frames were robot performance, safety concerns, program quality, and business objectives. Each frame enables the learner to consider a set of potential issues. For example, within the frame of safety concerns, issues include collisions or pinch points, while robot performance considers joint speed and reachability, among others. \n\nFigure 2: Visualization of the expert model as well as the derived expert frames\nThese expert frames were incorporated into a new combined education-programming system called CoFrame, a web-based, open-source software tool that integrates built-in simulation, visual editing, and rich feedback. Using CoFrame, cobot programming novices can use the visual programming environment to construct a robot program and then request feedback from the various expert frames. By responding to the issues raised in each frame and navigating through their tradeoffs and dependencies, users can learn about the concepts within the expert model and the connections among them.\n\nFigure 3: The CoFrame system. In this view, a user previews the current robot motion.\nConcurrently with the development of the CoFrame system, the project team completed a set of studies to better understand considerations that arise when working with and tending to cobots regarding \"human-robot teaming.\" The first study applied concepts originating in human-animal teaming to human-robot teams, considering three levels of interdependence: pooled (independent, simultaneous work), sequential (alternating between two individuals), and reciprocal (subtasks are coordinated by specialization). Results showed that worker stress was minimized in reciprocal interdependence, while simultaneously eliciting a more collaborative perspective of the cobot. Another study investigated how attention management could be relevant to tasks such as machine tending, considering various approaches for robots to communicate upcoming tending or collaborative needs. This study resulted in the development of a method, called \"predictive robot attention demand (pRAD),\" that visualized the cobot's current and future task state to make working with a cobot less onerous and usable to workers.\nThe Safety First expert model, the pRAD method, human-robot teaming studies, and the CoFrame software, generated as part of this project, have furthered the scientific understanding of cobot usage and design, while introducing software and techniques of practical use for workers and businesses. Findings from the project have been shared with the public in the form of scientific publications, public lectures, and videos that have been published online. Software developed as part of the project has been made open source to bootstrap future development. The project provided four doctoral students in computer science with opportunities for advanced training and professional development. Multiple computer science undergraduate students gained hands-on research experience and received academic mentoring by participating in this project.\n\n\t\t\t\t\tLast Modified: 11/29/2022\n\n\t\t\t\t\tSubmitted by: Bilge D Mutlu"
 }
}