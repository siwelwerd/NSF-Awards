{
 "awd_id": "1841569",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: An Integrated Inferential Framework for Big Data Research and Education",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 347702.0,
 "awd_amount": 347702.0,
 "awd_min_amd_letter_date": "2018-08-29",
 "awd_max_amd_letter_date": "2022-06-17",
 "awd_abstract_narration": "This project addresses several fundamental challenges in modern data analysis and aims to create a new research area named Big Data Inference. Currently available literature regarding Big Data research mainly focuses on developing new estimators for complex data. However, most of these estimators are still in lack of systematic inferential methods for uncertainty assessment. This project hopes to bridge this gap by developing new inferential theory for modern estimators unique to Big Data analysis.  The deliverables of this project include easy-to-use software packages, which directly help scientists to explore and analyze complex datasets. The principal investigator is also actively collaborating with many scientists to ensure the more direct impact of this project to the targeted scientific communities.\r\n\r\nThis project aims to develop novel inferential methods for assessing uncertainty (e.g., constructing confidence intervals or testing hypotheses) of modern statistical procedures unique to Big Data analysis. In particular, it develops innovative statistical inferential tools for a variety of machine learning methods which have not yet been equipped with inferential power. It also provides necessary inferential tools for the next generation of scientists to be competitive in modern data analysis.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Han",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Han Liu",
   "pi_email_addr": "hanliu@northwestern.edu",
   "nsf_id": "000582220",
   "pi_start_date": "2018-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "1801 Maple Ave.",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602013149",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  },
  {
   "pgm_ele_code": "804800",
   "pgm_ele_name": "Division Co-Funding: CAREER"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 11002.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 64002.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 65327.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 104936.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 102434.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This proposal is not just about developing inferential methods for assessing uncertainty unique to Big Data analysis. It's about developing innovative inferential tools that will revolutionize the way we approach machine learning methods. These tools, which have not yet been equipped with inferential power, will open up new possibilities and avenues for research. This is an exciting opportunity to be at the forefront of innovation in Big Data analysis.</p>\n<p>This proposal is framed within the context of a new generation of statistical methods designed to handle the increasing complexities of modern data. However, most of these methods provide only point estimates of parameters, which may not be sufficient for practitioners who often require more sophisticated inferential statements to assess uncertainty. For instance, in genomics, the p-value of a significance test of a biomarker is scientifically more informative than simply reporting whether this marker is selected or not. Therefore, a significant gap exists between the newly developed methods and their practical applications.</p>\n<p>Classical inferential theory has struggled to keep pace with the rapid development of these new methods, primarily due to several unique challenges posed by Big Data. Firstly, the challenge of high-dimensional data necessitates the development of estimators for simultaneous model selection and parameter estimation. Most classical inferential methods do not consider model selection uncertainty. Secondly, the challenge of massive data requires the development of heterogeneous modeling and divide-and-conquer estimators. In contrast, classical inferential theory assumes the data are homogeneous and stored in a central database. Thirdly, the challenge of complex data, such as heavy-tailed and missing data, motivates the development of highly robust estimators. The inferential theory for these estimators is much less developed.</p>\n<p>This proposal puts forward new methods for inferential analysis that handle the above challenges in a general abstract fashion. It equally emphasizes both research and education under an integrated framework.<br />The research outcomes include three aims, each addressing a unique challenge of Big Data. We develop novel and systematic inferential methods for various estimators under parametric, nonparametric, semiparametric, and misspecified models within each aim. The targeted scientific applications include computational neuroscience, computational biology, and computational finance.&nbsp;&nbsp;</p>\n<p>Aim 1: Develop inferential methods for high-dimensional data. High dimensionality motivates sparse estimation. We develop valid confidence intervals and a new score-, Wald-, and likelihood ratio (LRT) tests for high-dimensional parametric estimators. We also prove the optimality of these methods and extend them for high-dimensional estimators under the nonparametric sparse additive models (SpAM) and semiparametric proportional hazards models. In addition, we carefully studied their misspecified model extensions.</p>\n<p>Aim 2: Develop inferential methods for massive data. Massive data motivate heterogeneous modeling and divide-and-conquer estimators. We propose scalable bootstrap algorithms for inferring sparse estimators in high dimensions. We also develop new divide-and-conquer inferential methods for nonparametric and semiparametric estimators under the general reproducing kernel Hilbert space (RKHS) framework. Lastly, we plan to explore new inferential tools for testing the heterogeneity of large-rank correlation matrices.</p>\n<p>Aim 3: Develop inferential methods for complex data. Complex data motivate robust statistical procedures. We have successfully developed new inferential methods for robust penalized quantile regression under parametric linear models and nonparametric sparse additive models. We also explored the inferential theory of estimators based on the U-, L-, and R-statistics, which have critical applications in fitting semiparametric generalized linear models and testing the structure of high-dimensional distributions.</p>\n<p><strong>Intellectual Merit</strong></p>\n<p>This proposal addresses several fundamental challenges in modern inferential analysis and will lead to the creation of a new research area named Big Data Inference. The current literature on Big Data research mainly focuses on developing new estimators for complex data. However, most of these estimators still lack systematic inferential methods for uncertainty assessment. The proposed research bridges this gap by developing a new generation of inferential methods for Big Data analysis. In addition, this proposal will push the frontiers of modern statistical science by developing new technical tools ranging from nonasymptotic concentration inequalities to asymptotic limiting theorems for many complex estimators.</p>\n<p><strong>Broader Impact</strong></p>\n<p>This proposal has pushed the integration of Statistics and Machine Learning and have broader impact in 3 aspects: (i) The proposed education plan develops strategies and curriculum to train a new generation of researchers from many disciplines that are better equipped with modern inferential methodologies.(ii) This proposal emphasizes integrating the research and education for undergraduates and underrepresented minority groups. (iii) The deliverables of the proposed research include easy-to-use software packages, which directly help scientists to explore and analyze complex datasets. In particular, the PI has been actively collaborating with many scientists, which ensures the direct impact of this project to the targeted scientific communities.</p><br>\n<p>\n Last Modified: 04/12/2024<br>\nModified by: Han&nbsp;Liu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis proposal is not just about developing inferential methods for assessing uncertainty unique to Big Data analysis. It's about developing innovative inferential tools that will revolutionize the way we approach machine learning methods. These tools, which have not yet been equipped with inferential power, will open up new possibilities and avenues for research. This is an exciting opportunity to be at the forefront of innovation in Big Data analysis.\n\n\nThis proposal is framed within the context of a new generation of statistical methods designed to handle the increasing complexities of modern data. However, most of these methods provide only point estimates of parameters, which may not be sufficient for practitioners who often require more sophisticated inferential statements to assess uncertainty. For instance, in genomics, the p-value of a significance test of a biomarker is scientifically more informative than simply reporting whether this marker is selected or not. Therefore, a significant gap exists between the newly developed methods and their practical applications.\n\n\nClassical inferential theory has struggled to keep pace with the rapid development of these new methods, primarily due to several unique challenges posed by Big Data. Firstly, the challenge of high-dimensional data necessitates the development of estimators for simultaneous model selection and parameter estimation. Most classical inferential methods do not consider model selection uncertainty. Secondly, the challenge of massive data requires the development of heterogeneous modeling and divide-and-conquer estimators. In contrast, classical inferential theory assumes the data are homogeneous and stored in a central database. Thirdly, the challenge of complex data, such as heavy-tailed and missing data, motivates the development of highly robust estimators. The inferential theory for these estimators is much less developed.\n\n\nThis proposal puts forward new methods for inferential analysis that handle the above challenges in a general abstract fashion. It equally emphasizes both research and education under an integrated framework.\nThe research outcomes include three aims, each addressing a unique challenge of Big Data. We develop novel and systematic inferential methods for various estimators under parametric, nonparametric, semiparametric, and misspecified models within each aim. The targeted scientific applications include computational neuroscience, computational biology, and computational finance.\n\n\nAim 1: Develop inferential methods for high-dimensional data. High dimensionality motivates sparse estimation. We develop valid confidence intervals and a new score-, Wald-, and likelihood ratio (LRT) tests for high-dimensional parametric estimators. We also prove the optimality of these methods and extend them for high-dimensional estimators under the nonparametric sparse additive models (SpAM) and semiparametric proportional hazards models. In addition, we carefully studied their misspecified model extensions.\n\n\nAim 2: Develop inferential methods for massive data. Massive data motivate heterogeneous modeling and divide-and-conquer estimators. We propose scalable bootstrap algorithms for inferring sparse estimators in high dimensions. We also develop new divide-and-conquer inferential methods for nonparametric and semiparametric estimators under the general reproducing kernel Hilbert space (RKHS) framework. Lastly, we plan to explore new inferential tools for testing the heterogeneity of large-rank correlation matrices.\n\n\nAim 3: Develop inferential methods for complex data. Complex data motivate robust statistical procedures. We have successfully developed new inferential methods for robust penalized quantile regression under parametric linear models and nonparametric sparse additive models. We also explored the inferential theory of estimators based on the U-, L-, and R-statistics, which have critical applications in fitting semiparametric generalized linear models and testing the structure of high-dimensional distributions.\n\n\nIntellectual Merit\n\n\nThis proposal addresses several fundamental challenges in modern inferential analysis and will lead to the creation of a new research area named Big Data Inference. The current literature on Big Data research mainly focuses on developing new estimators for complex data. However, most of these estimators still lack systematic inferential methods for uncertainty assessment. The proposed research bridges this gap by developing a new generation of inferential methods for Big Data analysis. In addition, this proposal will push the frontiers of modern statistical science by developing new technical tools ranging from nonasymptotic concentration inequalities to asymptotic limiting theorems for many complex estimators.\n\n\nBroader Impact\n\n\nThis proposal has pushed the integration of Statistics and Machine Learning and have broader impact in 3 aspects: (i) The proposed education plan develops strategies and curriculum to train a new generation of researchers from many disciplines that are better equipped with modern inferential methodologies.(ii) This proposal emphasizes integrating the research and education for undergraduates and underrepresented minority groups. (iii) The deliverables of the proposed research include easy-to-use software packages, which directly help scientists to explore and analyze complex datasets. In particular, the PI has been actively collaborating with many scientists, which ensures the direct impact of this project to the targeted scientific communities.\t\t\t\t\tLast Modified: 04/12/2024\n\n\t\t\t\t\tSubmitted by: HanLiu\n"
 }
}