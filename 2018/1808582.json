{
 "awd_id": "1808582",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CDS&E: Theoretical Foundations and Algorithms for L1-Norm-Based Reliable Multi-Modal Data Analysis",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Seung-Jong Park",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 323973.0,
 "awd_amount": 323973.0,
 "awd_min_amd_letter_date": "2018-08-27",
 "awd_max_amd_letter_date": "2018-08-27",
 "awd_abstract_narration": "In modern applications of science and engineering, large volumes of data are collected from diverse sensor modalities, commonly stored in the form of high-order arrays (tensors), and jointly analyzed in order to extract information about underlying phenomena. This joint tensor analysis can exploit inherent dependencies across data modalities and allow for markedly enhanced inference. Standard methods for tensor analysis rely on formulations that are sensitive to heavily corrupted points among the processed data (outliers). To counteract the destructive impact of outliers in modern data analysis (and thereto relying applications), this project will investigate new theory and robust algorithmic methods. The performance benefits of the developed tools will be evaluated in applications from the fields of data analytics, machine learning and computer vision. Thus, this research aspires to increase significantly the reliability of data-enabled research across science and engineering. Combining theoretical explorations, with practical algorithmic solutions for data analysis and experimental evaluations, this project has the potential to build significant future capacity not only for U.S. academic institutions but also for the U.S. government and industry. Thus, apart from promoting the progress of science, this project could contribute to advances in the national prosperity and welfare. In addition, research activities under this project will be integrated with education. Participating students, at both graduate and undergraduate levels, will gain important experience in optimization theory, machine learning, computer vision, and data mining, among other areas. Moreover, the project plan includes multiple STEM outreach activities and supports diversity in STEM by involving students from underrepresented groups.\r\n\r\nIn this project, the theoretical underpinnings of L1-norm tensor analysis will be investigated, with a focus on its computational hardness and exact solution. Then, based on these new foundations, efficient/practical algorithms for L1-norm tensor analysis will be explored, together with scalable and distributed software implementations. These theoretical and algorithmic investigations are expected to advance significantly the knowledge in the currently under-explored area of L1-norm tensor analysis and deliver highly impactful methodologies for outlier-resistant multimodal data processing. Next, the PIs will employ the newly developed algorithmic tools in key problems from the fields of data analytics, machine learning and computer vision. In addition, research activities under this project will be integrated with education. Participating students, at both graduate and undergraduate levels, will gain important experience in optimization theory, machine learning, computer vision, and data mining, among other areas. Moreover, the project plan includes multiple STEM outreach activities?and supports diversity in STEM by involving?students from underrepresented groups.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Panagiotis",
   "pi_last_name": "Markopoulos",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Panagiotis Markopoulos",
   "pi_email_addr": "panagiotis.markopoulos@utsa.edu",
   "nsf_id": "000732610",
   "pi_start_date": "2018-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andreas",
   "pi_last_name": "Savakis",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Andreas E Savakis",
   "pi_email_addr": "andreas.savakis@rit.edu",
   "nsf_id": "000239740",
   "pi_start_date": "2018-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rochester Institute of Tech",
  "inst_street_address": "1 LOMB MEMORIAL DR",
  "inst_street_address_2": "",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5854757987",
  "inst_zip_code": "146235603",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "ROCHESTER INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "J6TWTRKC1X14"
 },
 "perf_inst": {
  "perf_inst_name": "Rochester Institute of Technology",
  "perf_str_addr": "141 Lomb Memorial Drive",
  "perf_city_name": "Rochester",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146235603",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  },
  {
   "pgm_ele_code": "808400",
   "pgm_ele_name": "CDS&E"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "8084",
   "pgm_ref_txt": "CDS&E"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 323973.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this last (no-cost-extension) year, we continued and completed the research objectives of our project. Our new contributions include novel algorithms for robust (L1-norm based) singular-value estimation, robust stochastic PCA, FFT-based L1-PCA, L1-norm tensor decomposition, and rank-update based incremental learning in neural networks. In addition, we explored the asymptotic properties of L1-PCA as the number of data points increases (big data). Details follow.&nbsp;</p>\n<ul>\n<li>We presented a novel L1-norm-based matrix analysis formulation, focusing on robust diagonalization and singular value estimation. Based on this formulation, we developed multiple efficient algorithms that manage to deliver singular-value estimates that are robust against heavy-tail noise and oultliers.&nbsp;</li>\n<li>We explored and unveiled the asymptotic properties of L1-PCA, as the number of processed data points increases asymptotically, and revieled a non-obvious theoretical connection between the L1-PC and L2-PC subspaces.&nbsp;</li>\n<li>We presented an algorithmic framework for robust PCA, based on the generic Barron Loss formulation. We showed that the parametrized formulation of the loss boils down to a similarly parametrized step-size of gradient-descent updates. The proposed method adaptively deals with the trade-off between robustness and speed of convergence.&nbsp;</li>\n<li>We proposed a novel method for L1-PCA based on standard FFT computations.&nbsp;</li>\n<li>We presented an improved method for L1-norm-based tensor analysis, based on both projection maximization and fitting-error minimization, that attains enhanced resistance against outlier contaminations.&nbsp;</li>\n<li>We presented a new paradigm for incremental training of neural networks, based on rank-updates of their matrix-structured learnable parameters. Our method facilitates incremental task learning without forgetting, towards continual learning. &nbsp;</li>\n</ul>\n<p>Ultimately, in this project we set the theoretical foundations of L1-norm matrix/tensor decomposition, developed efficient/practical decomposition algorithms, and tested them to a wide range of key applications. Also, we studied and developed methods for alternative robust matrix/tensor analysis formulations, such as the Barron Loss. Moreover, we studied the asymptotic properties of L1-norm decomposition and we developed stochastic and dynamic algorithms for its computation. Finally, we explored tensor factorization approaches for efficient and compact neural-network training.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/29/2022<br>\n\t\t\t\t\tModified by: Panagiotis&nbsp;Markopoulos</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this last (no-cost-extension) year, we continued and completed the research objectives of our project. Our new contributions include novel algorithms for robust (L1-norm based) singular-value estimation, robust stochastic PCA, FFT-based L1-PCA, L1-norm tensor decomposition, and rank-update based incremental learning in neural networks. In addition, we explored the asymptotic properties of L1-PCA as the number of data points increases (big data). Details follow. \n\nWe presented a novel L1-norm-based matrix analysis formulation, focusing on robust diagonalization and singular value estimation. Based on this formulation, we developed multiple efficient algorithms that manage to deliver singular-value estimates that are robust against heavy-tail noise and oultliers. \nWe explored and unveiled the asymptotic properties of L1-PCA, as the number of processed data points increases asymptotically, and revieled a non-obvious theoretical connection between the L1-PC and L2-PC subspaces. \nWe presented an algorithmic framework for robust PCA, based on the generic Barron Loss formulation. We showed that the parametrized formulation of the loss boils down to a similarly parametrized step-size of gradient-descent updates. The proposed method adaptively deals with the trade-off between robustness and speed of convergence. \nWe proposed a novel method for L1-PCA based on standard FFT computations. \nWe presented an improved method for L1-norm-based tensor analysis, based on both projection maximization and fitting-error minimization, that attains enhanced resistance against outlier contaminations. \nWe presented a new paradigm for incremental training of neural networks, based on rank-updates of their matrix-structured learnable parameters. Our method facilitates incremental task learning without forgetting, towards continual learning.  \n\n\nUltimately, in this project we set the theoretical foundations of L1-norm matrix/tensor decomposition, developed efficient/practical decomposition algorithms, and tested them to a wide range of key applications. Also, we studied and developed methods for alternative robust matrix/tensor analysis formulations, such as the Barron Loss. Moreover, we studied the asymptotic properties of L1-norm decomposition and we developed stochastic and dynamic algorithms for its computation. Finally, we explored tensor factorization approaches for efficient and compact neural-network training.\n\n\t\t\t\t\tLast Modified: 07/29/2022\n\n\t\t\t\t\tSubmitted by: Panagiotis Markopoulos"
 }
}