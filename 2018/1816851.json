{
 "awd_id": "1816851",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: Adversarial ML in Traffic Analysis",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 515840.0,
 "awd_min_amd_letter_date": "2018-08-09",
 "awd_max_amd_letter_date": "2020-07-28",
 "awd_abstract_narration": "Surveillance and tracking on the Internet are growing more pervasive and threaten privacy and freedom of expression. The Tor anonymity system protects the privacy of millions of users, including ordinary citizens, journalists, whistle-blowers, military intelligence, police, businesses, and people living under censorship and surveillance. Unfortunately, Tor is vulnerable to website fingerprinting (WF) attacks in which an eavesdropper uses a machine learning (ML) classifier to identify which website the user is visiting from its traffic patterns. The research team's state-of-the-art WF attack using a deep learning classifier reaches 98% accuracy, which is deeply concerning to Tor and its users. The goal of this project is to explore the new landscape of WF attacks and defenses in light of the team's findings with deep learning. A key aspect of the work is to build upon recent advances in fooling deep learning classifiers and apply these new findings to the context of anonymity systems. Based on this focus on adversarial machine learning, the project will create a new course and an accessible summer camp module on the topic, as well as launch a podcast on Cybersecurity Research featuring interviews with top researchers in the fields of adversarial machine learning and anonymity.\r\n\r\nThe research has three thrusts. First, the team is exploring the impact that these attacks can have for Tor users by addressing how the attacks can generalize to different network conditions and Tor versions, how they can be better adapted to realistic settings, and how they are impacted by real-world user behaviors in Tor. Second, since recent work has shown that it is possible to reliably fool deep learning classifiers, the team is studying how to adapt these techniques for robust and efficient defense. Prior work has primarily been in the image classification domain, whereas network traffic is more challenging to manipulate, so the team is designing new methods that account for this difference. In the third thrust, recognizing that researchers are actively seeking robust classifiers that are harder to fool, the team aims to understand new ways to build robust classifiers and explore their properties. While this aspect of the project means potentially finding stronger WF attacks against Tor, robust classifiers would be helpful for the myriad applications of deep learning, such as self-driving cars, stylometry, malware detection, processing drone and satellite imagery, and more.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Wright",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew Wright",
   "pi_email_addr": "matthew.wright@rit.edu",
   "nsf_id": "000735285",
   "pi_start_date": "2018-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rochester Institute of Tech",
  "inst_street_address": "1 LOMB MEMORIAL DR",
  "inst_street_address_2": "",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5854757987",
  "inst_zip_code": "146235603",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "ROCHESTER INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "J6TWTRKC1X14"
 },
 "perf_inst": {
  "perf_inst_name": "Rochester Institute of Tech",
  "perf_str_addr": "1 Lomb Memorial Dr.",
  "perf_city_name": "Rochester",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146235603",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 500000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 15840.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-707f720e-7fff-1bf6-84f4-800a67b01f2d\"> </span></p>\n<p dir=\"ltr\"><span>This project explored the potential dangers of attacks on Tor, the online privacy system, which can be used to expose what people are doing online, and ways to defend against these attacks. One such attack is called website fingerprinting, and it enables an attacker who can eavesdrop on a Tor user's network traffic to identify some of the websites that the user is visiting. This project found several new website fingerprinting attacks based on deep learning methods previously used for computer vision. These attacks are far more effective and dangerous than the prior generation of attacks, and unfortunately, they can even work against the defenses that researchers had proposed to stop them. The attacks we found were among the first to use deep learning, the first to investigate the importance of timing information, and the first to work effectively with limited training data, which makes them more practical and therefore more dangerous.&nbsp;</span></p>\n<p dir=\"ltr\"><span>To defend against website fingerprinting attacks, this project developed two novel defenses. The first defense uses information about the attacker's deep-learning classifier to understand the parts of web traffic that most need to be protected, and then it applies extra protections to those parts. The other defense uses a technique from the computer vision field that fools deep-learning classifiers and adapts it to this problem. Both defenses suggest ideas that could be honed in future research. The project also developed more metrics for defenses and comprehensively examined all existing approaches to defending against website fingerprinting attacks. We found that nearly all existing defenses are either not practical to implement or are very expensive in the amount of extra network traffic that needs to be added. This suggests that future research continues to be needed to address this problem.</span></p>\n<p dir=\"ltr\"><span>Another attack against Tor that this project studied is an end-to-end traffic analysis attack. In this attack, the adversary must eavesdrop on both the Tor user and some other network that Tor connects to, and tries to link the user's traffic with the other traffic. If the two connections are indeed linked, then the attack reveals where the user is connecting to on the Internet. Prior work had found that the attack is dangerous, but expensive and error prone. In our study, led by our partners at the University of Minnesota, we discovered a new attack that is significantly less expensive and much more accurate. This attack shows that Tor is highly vulnerable to end-to-end traffic analysis, motivating the need for new defenses.</span></p>\n<p dir=\"ltr\"><span>Beyond these studies on Tor, the project supported related investigations involving deep learning and security and privacy problems, such as reidentifying encrypted voice commands for services like Amazon Alexa, protections against attacks that fool deep-learning classifiers, identifying misbehaving users on the Freenet privacy system, and more.</span></p>\n<p dir=\"ltr\"><span>The project also helped to educate and train the next generation of security and privacy researchers, through classroom and outreach experiences highlighting the intersection of deep learning and security.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/22/2022<br>\n\t\t\t\t\tModified by: Matthew&nbsp;Wright</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1816851/1816851_10568313_1669129078112_WF-overview--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1816851/1816851_10568313_1669129078112_WF-overview--rgov-800width.jpg\" title=\"Website Fingerprinting in Tor\"><img src=\"/por/images/Reports/POR/2022/1816851/1816851_10568313_1669129078112_WF-overview--rgov-66x44.jpg\" alt=\"Website Fingerprinting in Tor\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An overview of the attacker model</div>\n<div class=\"imageCredit\">Matthew Wright</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Matthew&nbsp;Wright</div>\n<div class=\"imageTitle\">Website Fingerprinting in Tor</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1816851/1816851_10568313_1669128959337_DF-overview--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1816851/1816851_10568313_1669128959337_DF-overview--rgov-800width.jpg\" title=\"Deep Fingerprinting\"><img src=\"/por/images/Reports/POR/2022/1816851/1816851_10568313_1669128959337_DF-overview--rgov-66x44.jpg\" alt=\"Deep Fingerprinting\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The key insight of the deep fingerprinting attack which makes it so much more effective than prior work.</div>\n<div class=\"imageCredit\">Matthew Wright</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Matthew&nbsp;Wright</div>\n<div class=\"imageTitle\">Deep Fingerprinting</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nThis project explored the potential dangers of attacks on Tor, the online privacy system, which can be used to expose what people are doing online, and ways to defend against these attacks. One such attack is called website fingerprinting, and it enables an attacker who can eavesdrop on a Tor user's network traffic to identify some of the websites that the user is visiting. This project found several new website fingerprinting attacks based on deep learning methods previously used for computer vision. These attacks are far more effective and dangerous than the prior generation of attacks, and unfortunately, they can even work against the defenses that researchers had proposed to stop them. The attacks we found were among the first to use deep learning, the first to investigate the importance of timing information, and the first to work effectively with limited training data, which makes them more practical and therefore more dangerous. \nTo defend against website fingerprinting attacks, this project developed two novel defenses. The first defense uses information about the attacker's deep-learning classifier to understand the parts of web traffic that most need to be protected, and then it applies extra protections to those parts. The other defense uses a technique from the computer vision field that fools deep-learning classifiers and adapts it to this problem. Both defenses suggest ideas that could be honed in future research. The project also developed more metrics for defenses and comprehensively examined all existing approaches to defending against website fingerprinting attacks. We found that nearly all existing defenses are either not practical to implement or are very expensive in the amount of extra network traffic that needs to be added. This suggests that future research continues to be needed to address this problem.\nAnother attack against Tor that this project studied is an end-to-end traffic analysis attack. In this attack, the adversary must eavesdrop on both the Tor user and some other network that Tor connects to, and tries to link the user's traffic with the other traffic. If the two connections are indeed linked, then the attack reveals where the user is connecting to on the Internet. Prior work had found that the attack is dangerous, but expensive and error prone. In our study, led by our partners at the University of Minnesota, we discovered a new attack that is significantly less expensive and much more accurate. This attack shows that Tor is highly vulnerable to end-to-end traffic analysis, motivating the need for new defenses.\nBeyond these studies on Tor, the project supported related investigations involving deep learning and security and privacy problems, such as reidentifying encrypted voice commands for services like Amazon Alexa, protections against attacks that fool deep-learning classifiers, identifying misbehaving users on the Freenet privacy system, and more.\nThe project also helped to educate and train the next generation of security and privacy researchers, through classroom and outreach experiences highlighting the intersection of deep learning and security.\n\n\t\t\t\t\tLast Modified: 11/22/2022\n\n\t\t\t\t\tSubmitted by: Matthew Wright"
 }
}