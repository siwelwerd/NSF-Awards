{
 "awd_id": "1839429",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Real-Time: Reinforcement, Meta, and Episodic Learning for Control under Uncertainty",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Lawrence Goldberg",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 299333.0,
 "awd_amount": 299333.0,
 "awd_min_amd_letter_date": "2018-09-16",
 "awd_max_amd_letter_date": "2018-09-16",
 "awd_abstract_narration": "Machine learning and artificial intelligence are among the most important general purpose technologies for the coming decades, with potential to transform all aspects of society from health, to manufacturing, to business, to education, and to security. In the last decade, there have been very important and impressive advances in machine learning driven by the use of deep neural networks, innovative training algorithms, computational resources including specialized hardware (graphics processors, tensor processing units), and large datasets. Some of these developments have connections to emerging understanding from neuroscience on how the human brain learns to makes decisions in real-time. However, there are major challenges in the use of these techniques in real-time control and decision making for engineering systems where stability, reliability, and safety are paramount concerns. This project aims to connect major advances in machine learning and neuroscience to control systems and thereby advance myriad application domains. Modern engineered systems are increasingly complicated. They comprise large heterogeneous distributed networks of (IoT) connected devices, systems, and human/social agents, e.g., transportation, energy, water, manufacturing, health and agriculture. A major challenge is performance, stability and reliability of these systems under large uncertainties. The goal is to expand our understanding and integration of learning and control to derive principles and algorithms for the development of learning-based control systems for a variety of engineering applications.  \r\n\r\nWhile there are significant historical connections between reinforcement learning and stochastic dynamic control, the potential for leveraging ongoing and future advances in machine learning for control remains significantly under- explored. The field of control systems has deep and solid theoretical and mathematical foundations with comprehensive and well-established frameworks for linear, nonlinear, robust, adaptive, stochastic, distributed, and model-predictive control systems. Equally importantly, control systems have applications in multiple domains, such as aerospace, automotive, manufacturing, energy, transportation, agriculture, water, and many other engineered and socio-technical systems. Despite this rich spectrum of theoretical foundations and important applications, the domain of applicability of traditional control techniques is limited to situations where good mathematical models of the underlying systems are available, and where the environmental uncertainty is not too large. This exploratory research project is aimed at overcoming these limitations via novel problem formulations in systems and control inspired by new insights coming from recent developments in machine learning.  A key focus will be on novel control architectures inspired by neuroscience and reinforcement learning. Besides architectural innovations, the project will explore questions of stability, performance, and uncertainty by integrating ideas from rapid (one-shot) learning, meta-learning, and episodic control into control algorithms. The ideas from this project will be at the core of a new graduate level course in learning for control which will be taught at the University of California, Irvine. The resulting course materials will be made available to the research community and will benefit interested graduate students across the nation. In addition, short courses will be offered at major professional conferences, e. g., American Control Conference, IEEE Conference on Decision and Control.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Pramod",
   "pi_last_name": "Khargonekar",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Pramod P Khargonekar",
   "pi_email_addr": "pramod.khargonekar@uci.edu",
   "nsf_id": "000267666",
   "pi_start_date": "2018-09-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Pierre",
   "pi_last_name": "Baldi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pierre Baldi",
   "pi_email_addr": "pfbaldi@ics.uci.edu",
   "nsf_id": "000440884",
   "pi_start_date": "2018-09-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Irvine",
  "inst_street_address": "160 ALDRICH HALL",
  "inst_street_address_2": "",
  "inst_city_name": "IRVINE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9498247295",
  "inst_zip_code": "926970001",
  "inst_country_name": "United States",
  "cong_dist_code": "47",
  "st_cong_dist_code": "CA47",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA IRVINE",
  "org_prnt_uei_num": "MJC5FCYQTPE6",
  "org_uei_num": "MJC5FCYQTPE6"
 },
 "perf_inst": {
  "perf_inst_name": "The Regents of the University of California, Irvine",
  "perf_str_addr": "160 Aldrich Hall",
  "perf_city_name": "Irvine",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "926973175",
  "perf_ctry_code": "US",
  "perf_cong_dist": "47",
  "perf_st_cong_dist": "CA47",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760700",
   "pgm_ele_name": "EPCN-Energy-Power-Ctrl-Netwrks"
  },
  {
   "pgm_ele_code": "763300",
   "pgm_ele_name": "EFRI Research Projects"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "092E",
   "pgm_ref_txt": "Control systems & applications"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 299333.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Major goal of this project was to explore the confluence of advanced machine learning and control systems. More specifically, this research project was aimed at leveraging latest advances in machine learning to overcome limitations of traditional model-based control design and analysis via novel problem formulations in systems and control. A key focus was on novel control architectures and algorithms inspired by neuroscience, cognitive science, and machine learning.&nbsp; Besides architectural innovations, the investigators explored important questions of stability, performance, and uncertainty by integrating ideas from rapid (one-shot) learning, meta-learning, and episodic control into control algorithms. We developed the new concept of cognitive cyber-physical systems as a vision for future development of smart control systems in conjunction with physical engineered systems. A specific example of this is cognitive manufacturing systems.</p>\n<p>A key idea was to incorporate external memory, with suitable read and write algorithms, into traditional control systems. This turned out to be quite fruitful as we were able to obtain several results on stability and performance of the resulting control algorithms. We also explored meta-learning --- learning how to learn --- and developed new theoretical tools and results for performance analysis of such meta-learning algorithms in control systems settings. We also investigated applications of machine learning driven control and anomaly detection algorithms for smart power grids and manufacturing.</p>\n<p>We also investigated the foundations of deep learning and derived a complete theory of neural network capacity. In addition, we introduced a new class of learnable activation functions that increases not only the accuracy of neural networks, but also their robustness against adversarial attacks, which is a significant concern in several applications. We also investigated convolutional neural networks for computer vision applications where the weight sharing assumption is relaxed. This assumption is not realistic for many physical and biological neural systems, and we demonstrated that approximate weight sharing emerges naturally from certain invariances. On the application side, we used deep learning to tackle problems in the natural sciences.</p>\n<p>Recently, deep reinforcement learning algorithms combined with self-play have achieved superhuman proficiency in Go, Chess, and Shogi without human data or domain knowledge. In these environments, a reward is always received at the end of the game; however, for many combinatorial optimization environments, rewards are sparse, and episodes are not guaranteed to terminate. We introduce Autodidactic Iteration: a novel reinforcement learning algorithm that is able to teach itself how to solve the Rubik?s Cube with no human assistance.</p>\n<p>We developed a graduate level seminar style course entitled Confluence of Machine Learning and Control for aspiring doctoral students in engineering and computer science. We have also introduced a new course entitled AI Frontiers: Technical, Ethical, and Societal. We have taught these courses three (respectively two) times in the last three years. Student interest in these courses has been high. Many students have gone to doctoral studies or jobs in industry. One of us published a new book entitled Deep Learning in Science with Cambridge University Press.</p>\n<p>We also mentored several undergraduate and graduate students, including students from underrepresented groups in STEM education. The undergraduate students are all pursuing admission to doctoral programs at leading universities. One of them won the highly prestigious Goldwater Scholarship. The graduate students are on track for successfully completing their PhD degree. They have participated in various summer internships. One African-American student graduated and is now an assistant professor at a leading university.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/31/2021<br>\n\t\t\t\t\tModified by: Pramod&nbsp;P&nbsp;Khargonekar</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMajor goal of this project was to explore the confluence of advanced machine learning and control systems. More specifically, this research project was aimed at leveraging latest advances in machine learning to overcome limitations of traditional model-based control design and analysis via novel problem formulations in systems and control. A key focus was on novel control architectures and algorithms inspired by neuroscience, cognitive science, and machine learning.  Besides architectural innovations, the investigators explored important questions of stability, performance, and uncertainty by integrating ideas from rapid (one-shot) learning, meta-learning, and episodic control into control algorithms. We developed the new concept of cognitive cyber-physical systems as a vision for future development of smart control systems in conjunction with physical engineered systems. A specific example of this is cognitive manufacturing systems.\n\nA key idea was to incorporate external memory, with suitable read and write algorithms, into traditional control systems. This turned out to be quite fruitful as we were able to obtain several results on stability and performance of the resulting control algorithms. We also explored meta-learning --- learning how to learn --- and developed new theoretical tools and results for performance analysis of such meta-learning algorithms in control systems settings. We also investigated applications of machine learning driven control and anomaly detection algorithms for smart power grids and manufacturing.\n\nWe also investigated the foundations of deep learning and derived a complete theory of neural network capacity. In addition, we introduced a new class of learnable activation functions that increases not only the accuracy of neural networks, but also their robustness against adversarial attacks, which is a significant concern in several applications. We also investigated convolutional neural networks for computer vision applications where the weight sharing assumption is relaxed. This assumption is not realistic for many physical and biological neural systems, and we demonstrated that approximate weight sharing emerges naturally from certain invariances. On the application side, we used deep learning to tackle problems in the natural sciences.\n\nRecently, deep reinforcement learning algorithms combined with self-play have achieved superhuman proficiency in Go, Chess, and Shogi without human data or domain knowledge. In these environments, a reward is always received at the end of the game; however, for many combinatorial optimization environments, rewards are sparse, and episodes are not guaranteed to terminate. We introduce Autodidactic Iteration: a novel reinforcement learning algorithm that is able to teach itself how to solve the Rubik?s Cube with no human assistance.\n\nWe developed a graduate level seminar style course entitled Confluence of Machine Learning and Control for aspiring doctoral students in engineering and computer science. We have also introduced a new course entitled AI Frontiers: Technical, Ethical, and Societal. We have taught these courses three (respectively two) times in the last three years. Student interest in these courses has been high. Many students have gone to doctoral studies or jobs in industry. One of us published a new book entitled Deep Learning in Science with Cambridge University Press.\n\nWe also mentored several undergraduate and graduate students, including students from underrepresented groups in STEM education. The undergraduate students are all pursuing admission to doctoral programs at leading universities. One of them won the highly prestigious Goldwater Scholarship. The graduate students are on track for successfully completing their PhD degree. They have participated in various summer internships. One African-American student graduated and is now an assistant professor at a leading university.\n\n \n\n\t\t\t\t\tLast Modified: 12/31/2021\n\n\t\t\t\t\tSubmitted by: Pramod P Khargonekar"
 }
}