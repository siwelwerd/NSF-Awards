{
 "awd_id": "1833287",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Machine Learning through the Lens of Economics (And Vice Versa)",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2020-01-31",
 "tot_intn_awd_amt": 310469.0,
 "awd_amount": 310469.0,
 "awd_min_amd_letter_date": "2018-06-25",
 "awd_max_amd_letter_date": "2019-02-11",
 "awd_abstract_narration": "Machine Learning (ML) is the study of leveraging data and computational resources to obtain prediction and decision-making algorithms that function well in the presence of uncertainty. The techniques employed to design and study ML algorithms typically involve concepts and tools from probability, statistics, and optimization; the language of economics, on the other hand, is conspicuously absent. It is rare to encounter terms such as marginal price, utility, equilibrium, risk aversion, and such, in the ML research literature. This gap is significant and belies the reality that the broad interest in Machine Learning, and its sudden growth spurt as a research field, can be ascribed to its potential for generating economic value across many segments of society. This NSF CAREER projectadvances an already-emerging relationship between Machine Learning and the fields of microeconomic theory and finance. This will begin with the development of mathematical tools that enable a semantic correspondence between learning-theoretic objects and economic abstractions. For example, the project shows that many algorithms can be viewed as implementing a market economy, where learning parameters are associated with prices, parameter updates are viewed as transactions, and under certain conditions learned hypotheses can be extracted as market-clearing price equilibria. In addition to developing this link, the project research raises a number of intriguing questions and explores several surprising and novel applications with benefits to computer science more broadly. \r\n\r\nAmong several such applications stemming from the new theoretical connections are:\r\n1. Developing new models for distributed computing for learning and estimation tasks: The economic lens gives new insights into a robust and effective model for decentralization of data-focused tasks.\r\n2. Designing new techniques for crowdsourcing and labor decentralization via collaborative mechanisms involving financial payment schemes: This builds off of the success of platforms like Amazon's Mechanical Turk as well as the Netflix Prize and the prediction challenge company Kaggle.\r\n3. Developing a market-oriented model for data brokerage and financially-efficient learning: As information is increasingly traded in market environments, we aim to answer questions such as \"what is the marginal value of a unit of data?\"\r\n\r\nThe project will also develop the Michigan Prediction Team, a data-science focused program for formulating and solving prediction and learning challenges that develop from across the University of Michigan as well as externally. The group primarily targets undergraduates with graduate student mentors, and Team has a strong interdisciplinary focus.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jacob",
   "pi_last_name": "Abernethy",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Jacob D Abernethy",
   "pi_email_addr": "prof@gatech.edu",
   "nsf_id": "000662896",
   "pi_start_date": "2018-06-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue NW",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 17826.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 95032.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 97518.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 100093.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project began as an attempt to draw stronger connections between machine learning and economic theory, particularly in the realm of finance and microeconomics. Much of my early work during my phd initiated this line of thinking, as I drew a lot of inspiration from ideas around gambling, financial markets, hedging, and game theory. I wrote my CAREER proposal with the goal of showing that many more tools from economics could be utilized in machine learning, and many machine learning methods could be used to improve market mechanisms such as auctions and order book exchanges.</p>\n<p>The project went into a number of different directions, some of which I fully expected, and some of which were quite surprising yet ended up being unusually fruitful. Here are some of the threads which fell directly in line with the research laid out in the original proposal:</p>\n<ul>\n<li>Sequential market making using online learning tools</li>\n<li>The design of pricing mechanisms in repeated auctions that generate much more efficient allocation</li>\n<li>Sequential purchasing of data to optimize learning under a budget</li>\n<li>Dynamic pricing strageies of fixed goods to maximize revenue using multi-armed bandit methods</li>\n<li>Using market mechanisms as a tool in sensor fusion for robotics applications</li>\n</ul>\n<p>What I did not expect is a heavy move into the computation of equilibria of zero-sum games. In working with students, we found a nice idea that connected many of the core results in optimization theory to the solution of min-max problems using no-regret learning algorithms. This led to a sequence of papers where we showed that many known and unknown algorithms can be derived as a special case of learning dynamics, with a simple analysis framework to go along. This focus on min-max problems was also important since at the time two ideas were growing in popularity in the deep learning community: generative adversarial networks, and adversarial robustness to data perturbation. Suddenly min-max problems were becoming hugely important for more empirical problems.</p>\n<p>Let me finish by mentioning a project that developed out of this award in an surprising way.&nbsp;In my CAREER proposal I put forward an educational outreach initiative in which I would develop a competitive/collaborative student group to organize and engage in prize-driven data science challenges. The main purpose, as I saw it, was to experiment with ``mechanisms'' to incentivize groups to form and work on well-defined prediction tasks. This group became known as the Michigan Data Science Team (MDST) and was soon the premier data hacking organization on campus. After about a year or so, when MDST was in full swing, the students implemented a number of unique features and activities that are innovative even by today's standards. The group had attendence from students from over 12 departments, from students at every year level of both our undergraduate and graduate programs, as well as postdoctoral fellows and several faculty members (including me). The organization proved to be highly productive, both at training but also at research. We were cited by the National Academies Press in their report ENVISIONING THE DATA SCIENCE DISCIPLINE: THE UNDERGRADUATE PERSPECTIVE.</p>\n<p>Perhaps the single biggest event that helped to jump start MDST success was our involvement in Flint's water crisis remediation efforts, starting in mid-2016. MDST was asked to help study water contamination issues in the city, towards the design of a citizen-facing web and mobile application that would communicate key information to Flint's residents. The student team crowdsourced the development of a predictive model for lead contamination, and these results were not only provided to residents through the mywater-flint.com app, but also to policy-makers and government officials working in the city. Details of this work were published in 2017 at KDD, the premier data science conference. I continued my work in Flint, in collaboration with Dr. Eric Schwartz at UM, as well as a grad student Jared Webb, to help Flint's pipe replacement program find their lead pipes. This pipe project, which had us directly working with city policymakers for over a year, involved a lot of interesting data science tools and machine learning methods.&nbsp;Our work on Flint's pipes was published in 2018 KDD paper that won a Best Student Paper award. This work is still ongoing, four year later. (A recent article:&nbsp;https://www.mlive.com/news/flint/2020/06/new-map-shows-where-lead-water-pipes-remain-in-flint.html)</p>\n<p>I am very happy to share this final story because it led me to a very unusual and exciting line of work that was personally very fulfilling. And notably it grew, In a quite interesting way, out of an outreach effort proposed as part of my CAREER and funded by the National Science Foundation. I would like to offer a very big thanks to the NSF for supporting this work.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/28/2020<br>\n\t\t\t\t\tModified by: Jacob&nbsp;Abernethy</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project began as an attempt to draw stronger connections between machine learning and economic theory, particularly in the realm of finance and microeconomics. Much of my early work during my phd initiated this line of thinking, as I drew a lot of inspiration from ideas around gambling, financial markets, hedging, and game theory. I wrote my CAREER proposal with the goal of showing that many more tools from economics could be utilized in machine learning, and many machine learning methods could be used to improve market mechanisms such as auctions and order book exchanges.\n\nThe project went into a number of different directions, some of which I fully expected, and some of which were quite surprising yet ended up being unusually fruitful. Here are some of the threads which fell directly in line with the research laid out in the original proposal:\n\nSequential market making using online learning tools\nThe design of pricing mechanisms in repeated auctions that generate much more efficient allocation\nSequential purchasing of data to optimize learning under a budget\nDynamic pricing strageies of fixed goods to maximize revenue using multi-armed bandit methods\nUsing market mechanisms as a tool in sensor fusion for robotics applications\n\n\nWhat I did not expect is a heavy move into the computation of equilibria of zero-sum games. In working with students, we found a nice idea that connected many of the core results in optimization theory to the solution of min-max problems using no-regret learning algorithms. This led to a sequence of papers where we showed that many known and unknown algorithms can be derived as a special case of learning dynamics, with a simple analysis framework to go along. This focus on min-max problems was also important since at the time two ideas were growing in popularity in the deep learning community: generative adversarial networks, and adversarial robustness to data perturbation. Suddenly min-max problems were becoming hugely important for more empirical problems.\n\nLet me finish by mentioning a project that developed out of this award in an surprising way. In my CAREER proposal I put forward an educational outreach initiative in which I would develop a competitive/collaborative student group to organize and engage in prize-driven data science challenges. The main purpose, as I saw it, was to experiment with ``mechanisms'' to incentivize groups to form and work on well-defined prediction tasks. This group became known as the Michigan Data Science Team (MDST) and was soon the premier data hacking organization on campus. After about a year or so, when MDST was in full swing, the students implemented a number of unique features and activities that are innovative even by today's standards. The group had attendence from students from over 12 departments, from students at every year level of both our undergraduate and graduate programs, as well as postdoctoral fellows and several faculty members (including me). The organization proved to be highly productive, both at training but also at research. We were cited by the National Academies Press in their report ENVISIONING THE DATA SCIENCE DISCIPLINE: THE UNDERGRADUATE PERSPECTIVE.\n\nPerhaps the single biggest event that helped to jump start MDST success was our involvement in Flint's water crisis remediation efforts, starting in mid-2016. MDST was asked to help study water contamination issues in the city, towards the design of a citizen-facing web and mobile application that would communicate key information to Flint's residents. The student team crowdsourced the development of a predictive model for lead contamination, and these results were not only provided to residents through the mywater-flint.com app, but also to policy-makers and government officials working in the city. Details of this work were published in 2017 at KDD, the premier data science conference. I continued my work in Flint, in collaboration with Dr. Eric Schwartz at UM, as well as a grad student Jared Webb, to help Flint's pipe replacement program find their lead pipes. This pipe project, which had us directly working with city policymakers for over a year, involved a lot of interesting data science tools and machine learning methods. Our work on Flint's pipes was published in 2018 KDD paper that won a Best Student Paper award. This work is still ongoing, four year later. (A recent article: https://www.mlive.com/news/flint/2020/06/new-map-shows-where-lead-water-pipes-remain-in-flint.html)\n\nI am very happy to share this final story because it led me to a very unusual and exciting line of work that was personally very fulfilling. And notably it grew, In a quite interesting way, out of an outreach effort proposed as part of my CAREER and funded by the National Science Foundation. I would like to offer a very big thanks to the NSF for supporting this work.\n\n\t\t\t\t\tLast Modified: 06/28/2020\n\n\t\t\t\t\tSubmitted by: Jacob Abernethy"
 }
}