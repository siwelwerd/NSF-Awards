{
 "awd_id": "1828187",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MRI: Acquisition of an HPC System for Data-Driven Discovery in Computational Astrophysics, Biology, Chemistry, and Materials Science",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032927092",
 "po_email": "alsuarez@nsf.gov",
 "po_sign_block_name": "Alejandro Suarez",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 3699317.0,
 "awd_amount": 3699317.0,
 "awd_min_amd_letter_date": "2018-08-24",
 "awd_max_amd_letter_date": "2022-09-07",
 "awd_abstract_narration": "The project funds the purchase of a high-performance computing and storage system at the Georgia Institute of Technology. This computing instrument will support data-driven research in astrophysics, biosciences, computational chemistry, materials and manufacturing, and computational science. These projects contribute to national initiatives in big data, strategic computing, materials genome, and manufacturing partnership; and NSF supported observatories such as the gravitational wave observatory and the South Pole neutrino observatory. The system also serves as a springboard for developments of codes, software prototyping, and scalability studies prior to using national supercomputers. Advances made in computational methods and scientific software are disseminated in the form of open-source codes and data analysis portals. Over 33 faculty, 54 research scientists/postdocs, 195 graduate students, and 56 undergraduate students will immediately benefit from the instrument. In addition, the system provides training opportunity at all levels from undergraduate students to early career researchers, in important interdisciplinary areas of national need. A fifth of the system capacity is utilized to enable research activities of regional partners, researchers from minority serving institutions, and other users nationally through XSEDE participation. The project involves undergraduate student participation from historically black colleges from Atlanta metropolitan area. Public outreach efforts are planned through videos of public interest and local events such as the Atlanta Science Festival.\r\n\r\nThe cluster will combine regular compute nodes with others configured to emphasize one of the following: big memory, big local storage, solid state storage, Graphics Processing Units (GPU), and ARM processors. In doing so, the system can be employed by a diversity of projects. In astrophysics, the instrument bolsters data-driven research including detection of gravitational waves, astrophysical neutrinos, and gamma rays. It does it by leveraging data from leading astroparticle observatories and contributing to their mission. It also leads to improved insights into formation of supermassive black holes and large-scale structure of the universe. The computing system also aids the development of parallel software in computational genomics, systems biology, and health analytics. Important applications in assembly and network analysis of plant genomes, and environmental metagenomics are pursued. The instrument also enables next generation algorithms and software for computational chemistry and expands the boundaries of molecular simulation. The system enables advances in density function theory, enhances studies of crystal defects and nanostructures, and injects novel use of machine learning techniques in computational chemistry. It also fosters the development of data science methodologies to identify building blocks of materials at multiple scales, thus significantly reducing the development and deployments cycles for new materials.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Srinivas",
   "pi_last_name": "Aluru",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Srinivas Aluru",
   "pi_email_addr": "aluru@cc.gatech.edu",
   "nsf_id": "000388133",
   "pi_start_date": "2018-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Surya",
   "pi_last_name": "Kalidindi",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Surya R Kalidindi",
   "pi_email_addr": "surya.kalidindi@me.gatech.edu",
   "nsf_id": "000269633",
   "pi_start_date": "2018-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Charles",
   "pi_last_name": "Sherrill",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Charles D Sherrill",
   "pi_email_addr": "sherrill@gatech.edu",
   "nsf_id": "000349219",
   "pi_start_date": "2018-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Deirdre",
   "pi_last_name": "Shoemaker",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Deirdre M Shoemaker",
   "pi_email_addr": "deirdre.shoemaker@austin.utexas.edu",
   "nsf_id": "000220118",
   "pi_start_date": "2018-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Vuduc",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Richard W Vuduc",
   "pi_email_addr": "richie@cc.gatech.edu",
   "nsf_id": "000080331",
   "pi_start_date": "2018-08-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "118900",
   "pgm_ele_name": "Major Research Instrumentation"
  },
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "1189",
   "pgm_ref_txt": "MAJOR RESEARCH INSTRUMENTATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 3699317.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project funded the acquisition of a high-performance computing cluster named Hive to support data-driven research in multiple fields including astrophysics, data-enabled chemistry, biology and health, and materials science and manufacturing. The Hive cluster consists of 484 Xeon compute nodes and 2.5 petabytes of storage, connected by 100 GB/s EDR Infiniband interconnection network. Some of the nodes are enhanced/specialized to meet different application requirements ? 16 nodes with quad V100 NVIDIA GPUs, 16 with large local disks, 16 with large local Solid State Disks (SSDs), and four with much larger main memory. In addition, a 16 node HPE/Cray NSP-1 system with Fujitsu 48-core A64FX ARM-based processors and 32 GB High Bandwidth Memory is procured. The Hive cluster is used as primary resource for computation and data-enabled research of 35 faculty members and their research groups totaling about 250 users during its span of operation. In addition, the system is made available via the NSF XSEDE network by deploying the Hive gateway using SciGaP?s Apache Airavata framework.</p>\n<p><strong>Intellectual merit</strong>: The project funded instrumentation that simultaneously impacted multiple disciplines. Research in astrophysics has contributed to our understanding of binary black holes, gravitational waves, and the first generations of stars and galaxies in the early Universe. Computational chemistry research created detailed machine learning models for numerous reactions and materials. The research has provided further insight into electrochemistry, filling in some details of fundamental processes by atomistic simulation. Hive allowed for the first systematic investigation of the range-dependence of intermolecular interactions in molecular crystals, which should help theorists who are designing improved algorithms for rapidly computing accurate lattice energies. Multi-scale datasets generated by materials science researchers on Hive are now allowing us to harvest a new class of materials knowledge systems that are focused on accelerating the rate of materials discovery, development, and deployment in practical advanced technology applications, directly in support of the national Materials Genome Initiative. Finally, research in high performance computing led to the development of parallel algorithms and software tools for learning graphical models, constructing tensor decompositions, and carrying out analytics on hypergraphs.</p>\n<p><strong>Broader impacts</strong>: The project led to multiple open-source software products that contributed to the high-performance computing software ecosystem that exists in several science and engineering disciplines. For example, the SPARC DFT software helps accelerate the speed of computational chemistry research. Research in materials science supported the continued development of www.pymks.org as an open-source repository for codes capable of establishing process-structure-property linkages needed to accelerate materials innovation efforts (in direct support of the federal Materials Genome Initiative). Researchers also contributed data and software to Materials Commons (https://materialscommons.org/), and continued the development of www.materialhub.org as an open-access sharing repository for material microstructure datasets. During Covid, some capacity of the cluster is redirected in support of scientific work to fight the pandemic. Research studies conducted on Hive of the main protease in the SARS-CoV-2 virus revealed that binding of inhibitors can shift the dominant protonation states, an important consideration for drug design efforts.</p>\n<p>The project also created valuable datasets that are useful in the respective scientific communities. For example, the computational chemistry datasets generated are being utilized by theoretical chemistry methods developers and for machine learning applications in helping parameterize, train, or calibrate new methods. The knowledge created using the Hive cluster was critical in establishing the start-up company Multiscale Technologies, Inc., which provides software and hardware solutions aimed at accelerating materials innovation/design cycles for its customers using emergent AI/ML and high-throughput strategies.</p>\n<p>In addition to supporting research by Georgia Tech investigators, up to 20% of the capacity of the Hive cluster is set aside for external users, with particular focus on HBCUs and MSIs.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/22/2023<br>\n\t\t\t\t\tModified by: Srinivas&nbsp;Aluru</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1828187/1828187_10575830_1682204245201_hive--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1828187/1828187_10575830_1682204245201_hive--rgov-800width.jpg\" title=\"Hive cluster\"><img src=\"/por/images/Reports/POR/2023/1828187/1828187_10575830_1682204245201_hive--rgov-66x44.jpg\" alt=\"Hive cluster\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Image of the Hive cluster.</div>\n<div class=\"imageCredit\">Georgia Tech</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Srinivas&nbsp;Aluru</div>\n<div class=\"imageTitle\">Hive cluster</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1828187/1828187_10575830_1682204524853_BH-binaries--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1828187/1828187_10575830_1682204524853_BH-binaries--rgov-800width.jpg\" title=\"Black hole binaries\"><img src=\"/por/images/Reports/POR/2023/1828187/1828187_10575830_1682204524853_BH-binaries--rgov-66x44.jpg\" alt=\"Black hole binaries\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Multi-messenger signatures of massive black hole binaries.</div>\n<div class=\"imageCredit\">Georgia Tech</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Srinivas&nbsp;Aluru</div>\n<div class=\"imageTitle\">Black hole binaries</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe project funded the acquisition of a high-performance computing cluster named Hive to support data-driven research in multiple fields including astrophysics, data-enabled chemistry, biology and health, and materials science and manufacturing. The Hive cluster consists of 484 Xeon compute nodes and 2.5 petabytes of storage, connected by 100 GB/s EDR Infiniband interconnection network. Some of the nodes are enhanced/specialized to meet different application requirements ? 16 nodes with quad V100 NVIDIA GPUs, 16 with large local disks, 16 with large local Solid State Disks (SSDs), and four with much larger main memory. In addition, a 16 node HPE/Cray NSP-1 system with Fujitsu 48-core A64FX ARM-based processors and 32 GB High Bandwidth Memory is procured. The Hive cluster is used as primary resource for computation and data-enabled research of 35 faculty members and their research groups totaling about 250 users during its span of operation. In addition, the system is made available via the NSF XSEDE network by deploying the Hive gateway using SciGaP?s Apache Airavata framework.\n\nIntellectual merit: The project funded instrumentation that simultaneously impacted multiple disciplines. Research in astrophysics has contributed to our understanding of binary black holes, gravitational waves, and the first generations of stars and galaxies in the early Universe. Computational chemistry research created detailed machine learning models for numerous reactions and materials. The research has provided further insight into electrochemistry, filling in some details of fundamental processes by atomistic simulation. Hive allowed for the first systematic investigation of the range-dependence of intermolecular interactions in molecular crystals, which should help theorists who are designing improved algorithms for rapidly computing accurate lattice energies. Multi-scale datasets generated by materials science researchers on Hive are now allowing us to harvest a new class of materials knowledge systems that are focused on accelerating the rate of materials discovery, development, and deployment in practical advanced technology applications, directly in support of the national Materials Genome Initiative. Finally, research in high performance computing led to the development of parallel algorithms and software tools for learning graphical models, constructing tensor decompositions, and carrying out analytics on hypergraphs.\n\nBroader impacts: The project led to multiple open-source software products that contributed to the high-performance computing software ecosystem that exists in several science and engineering disciplines. For example, the SPARC DFT software helps accelerate the speed of computational chemistry research. Research in materials science supported the continued development of www.pymks.org as an open-source repository for codes capable of establishing process-structure-property linkages needed to accelerate materials innovation efforts (in direct support of the federal Materials Genome Initiative). Researchers also contributed data and software to Materials Commons (https://materialscommons.org/), and continued the development of www.materialhub.org as an open-access sharing repository for material microstructure datasets. During Covid, some capacity of the cluster is redirected in support of scientific work to fight the pandemic. Research studies conducted on Hive of the main protease in the SARS-CoV-2 virus revealed that binding of inhibitors can shift the dominant protonation states, an important consideration for drug design efforts.\n\nThe project also created valuable datasets that are useful in the respective scientific communities. For example, the computational chemistry datasets generated are being utilized by theoretical chemistry methods developers and for machine learning applications in helping parameterize, train, or calibrate new methods. The knowledge created using the Hive cluster was critical in establishing the start-up company Multiscale Technologies, Inc., which provides software and hardware solutions aimed at accelerating materials innovation/design cycles for its customers using emergent AI/ML and high-throughput strategies.\n\nIn addition to supporting research by Georgia Tech investigators, up to 20% of the capacity of the Hive cluster is set aside for external users, with particular focus on HBCUs and MSIs.\n\n\t\t\t\t\tLast Modified: 04/22/2023\n\n\t\t\t\t\tSubmitted by: Srinivas Aluru"
 }
}