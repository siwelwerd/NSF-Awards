{
 "awd_id": "1830965",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase II:  Fast Creation of Photorealistic 3D Models using Consumer Hardware",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 750000.0,
 "awd_amount": 750000.0,
 "awd_min_amd_letter_date": "2018-09-04",
 "awd_max_amd_letter_date": "2018-09-04",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project will be substantial: a successful project would transform the construction industry, making it far more efficient by reducing legal conflicts, schedule slips and poor decision making. The proposed work will enable the fast and easy creation of 100% complete visual documentation of a physical space; this documentation can be generated many times throughout the course of construction. In so doing, the proposed project will allow professionals in the construction industry to track progress and communicate with their teams far more efficiently than ever before. A second outcome of the project will be the creation of vast, detailed, never before seen datasets of construction projects and real estate, allowing technical innovations in artificial intelligence and computer vision to impact one of the largest industries in the nation and the world. For example, systems could be trained to automatically spot safety concerns, augmenting the efforts of safety managers and keeping workers safer than ever before.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase II project will develop a fast, easy to use and cheap method to create photorealistic immersive models using off the shelf consumer hardware. Technical hurdles include validating the quality and efficacy of models generated with consumer hardware and automatic creation of routes through the 3D space without human annotation. Technical milestones involve using various sensor streams as well as other prior data to build these routes. With these hurdles cleared, advanced work may include automated analytics between and among 3D models of the same site captured over time. Because of the system's ease of use, it will enable the collection of large, totally novel datasets. The goal of the research is to produce a prototype that a layperson can use to create an immersive model of a physical site in order to document it with no annotation effort. The plan to reach these goals includes iterative software development against the hurdles listed above, as well as continuous user feedback to guide and refine development.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeevan",
   "pi_last_name": "Kalanithi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jeevan Kalanithi",
   "pi_email_addr": "zoinks@gmail.com",
   "nsf_id": "000737545",
   "pi_start_date": "2018-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Openspace",
  "inst_street_address": "333 KEARNY ST FL 4",
  "inst_street_address_2": "",
  "inst_city_name": "SAN FRANCISCO",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "4159947035",
  "inst_zip_code": "94108",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "CA11",
  "org_lgl_bus_name": "OPEN SPACE LABS, INC",
  "org_prnt_uei_num": "",
  "org_uei_num": "YRV5DN7DX1V1"
 },
 "perf_inst": {
  "perf_inst_name": "Openspace",
  "perf_str_addr": "1533 Sanchez St",
  "perf_city_name": "San Francisco",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "941312136",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "CA11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537300",
   "pgm_ele_name": "SBIR Phase II"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5373",
   "pgm_ref_txt": "SMALL BUSINESS PHASE II"
  },
  {
   "pgm_ref_code": "8033",
   "pgm_ref_txt": "Hardware Software Integration"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 750000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>OpenSpace's technology development has been support by the National Science Foundation SBIR grant program via a Phase I and Phase II grant. The work sought to build computer vision technology that translated videos from 360 cameras into navigable spaces accessible on the web and on mobile: a good comparison is the user experience of \"Google Streeview\" on Google maps.</p>\n<p>The use case was designed for construction professionals that wanted an easy, simple way to create full visual documentation of their jobsites, so that they could review and collaborate on work without physically needing to be present on the jobsite for every issue. In addition, these visual data sets can be built up over time, so that builders, their partners, and their clients can review prior states of the site. The critical technology step was to remove all manual work from the capture process, such that a construction worker could simply walk the site as they normally would with the camera capturing video in the background: the technology would then take that video and automatically map to architectural floorplans.</p>\n<p>The technology work has been successful, and is now deployed in 40 countries and has processed more than 4 Billion square feet of data to date.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/23/2021<br>\n\t\t\t\t\tModified by: Jeevan&nbsp;Kalanithi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOpenSpace's technology development has been support by the National Science Foundation SBIR grant program via a Phase I and Phase II grant. The work sought to build computer vision technology that translated videos from 360 cameras into navigable spaces accessible on the web and on mobile: a good comparison is the user experience of \"Google Streeview\" on Google maps.\n\nThe use case was designed for construction professionals that wanted an easy, simple way to create full visual documentation of their jobsites, so that they could review and collaborate on work without physically needing to be present on the jobsite for every issue. In addition, these visual data sets can be built up over time, so that builders, their partners, and their clients can review prior states of the site. The critical technology step was to remove all manual work from the capture process, such that a construction worker could simply walk the site as they normally would with the camera capturing video in the background: the technology would then take that video and automatically map to architectural floorplans.\n\nThe technology work has been successful, and is now deployed in 40 countries and has processed more than 4 Billion square feet of data to date.\n\n\t\t\t\t\tLast Modified: 03/23/2021\n\n\t\t\t\t\tSubmitted by: Jeevan Kalanithi"
 }
}