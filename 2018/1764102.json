{
 "awd_id": "1764102",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: Medium: Declarative Programmable Storage",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Alexander Jones",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 850000.0,
 "awd_amount": 850000.0,
 "awd_min_amd_letter_date": "2018-08-13",
 "awd_max_amd_letter_date": "2019-09-18",
 "awd_abstract_narration": "Everyone who processes large amounts of data - biologists and physicists, data scientists, and computer scientists of all stripes - must rely on distributed storage systems.  Storage systems deal with conflicting demands: they must accommodate the changing workloads of the domain experts who use them, while ensuring good performance by taking advantage of changing hardware such as faster disks and networks - and guaranteeing that data is safely stored.  This means that they must be rigid and flexible at the same time. Declarative programmable storage attempts to provide the best of both worlds by providing a simple, concise language for describing new storage interfaces, and using techniques from database optimization to automatically find correct and efficient implementations of the interface.\r\n\r\nDeclarative programmable storage identifies key opportunities to apply classic data management systems concepts - such as declarative language and cost-based query optimization - to the domain of large-scale storage systems, allowing for cross-pollination between the storage, data management and distributed systems research communities.  Additionally, this project requires novel research into cost modeling and query planning in the context of the storage domain. \r\n\r\nBy decoupling the specification of new storage application programming interfaces (a task that should be undertaken by domain experts - e.g., physicists - in a high-level language) from their concrete implementations (a low-level task that can be automated), this project will free the users of distributed storage systems from the need to be experts in the internals of such systems.  Consequently, these domain experts will be able to focus on innovation within their own area of expertise rather than becoming expert storage system programmers as well.  These application programming interfaces can be specified once and re-optimized whenever device characteristics change.  Hence the labor of these users will be made \"future-proof\" against the rapid evolution of storage hardware, software and configurations.   \r\n\r\nScientific results, software, and data from the work performed under this grant will be made available to the public under a free and open source software license. The project repository will be available at https://declstore.soe.ucsc.edu/ backed up by departmental backup systems to ensure long-term preservation of digital artifacts. In the long-term, this project will aim to engage open-source software communities to maintain and evolve software created under this grant.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Alvaro",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Peter A Alvaro",
   "pi_email_addr": "palvaro@ucsc.edu",
   "nsf_id": "000727366",
   "pi_start_date": "2018-08-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Carl",
   "pi_last_name": "Maltzahn",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Carl G Maltzahn",
   "pi_email_addr": "carlosm@ucsc.edu",
   "nsf_id": "000419997",
   "pi_start_date": "2018-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Cruz",
  "inst_street_address": "1156 HIGH ST",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA CRUZ",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8314595278",
  "inst_zip_code": "950641077",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "CA19",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA SANTA CRUZ",
  "org_prnt_uei_num": "",
  "org_uei_num": "VXUFPE4MCZH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Cruz",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "950641077",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "CA19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 279144.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 570856.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-027ec5bd-7fff-854c-a1a0-be89d35a8311\"> </span></p>\n<p dir=\"ltr\"><span>The Declarative Programmable Storage (DPS) project began as an attempt to tame the complexity of Programmable Storage (PS) by applying ideas from data management.&nbsp; PS (as best exemplified by Malacology [Eurosys'19]) brought about a sea change in how applications and infrastructures could utilize distributed storage systems such as Ceph. By exposing reusable units of distributed functionality, PS evolved from a narrow API into a </span><em>platform</em><span> upon which new distributed applications could be constructed. With this freedom, however, came hazards, as application programmers were no longer shielded from the rapid changes in storage systems software, hardware, and media.&nbsp; Even minor changes in the underlying system (e.g. a version change in Ceph) led to performance drops of an order of magnitude.</span></p>\n<p dir=\"ltr\"><span>The original vision of DPS was to enable </span><em>data independence</em><span> for programmers of storage systems by adapting classical database concepts &ndash; most importantly, using optimization to search a space of equivalent implementations of a high-level program, and using cardinality estimation (i.e., informed guesses about result sizes) to provide the optimizer with a concept of cost. In this way, programmers could write an application once, and optimize it as often as necessary to adapt to changes in the storage environment.&nbsp; Key to enabling this freedom were creation of an orchestration system (Skyhook) that could translate a global data processing or retrieval intent into low-level commands to run on storage servers or devices [Vault'19, USENIX login;</span><span>45(2)</span><span>], and adoption of a common format for data representation (Apache Arrow) among distributed nodes [PDSW'19, BigData'21].</span></p>\n<p dir=\"ltr\"><span>As the project progressed, our team began to discern that the most difficult decisions facing an optimizer often involve faithfully predicting the scenarios in which performing work at the storage tier, which increases the length and complexity of of the data processing pipeline in exchange for access to more parallel processing power, will provide any performance benefit versus simply doing the work at the client [HotEdge'20, arXiv'22]. Even just greedily considering a single such offloading decision is nontrivial; the overheads of serialization, for example, will often bottleneck an offload, and precise estimation of how an offloaded function will reduce its inputs is required to make intelligent decisions. Our most recent work [HPEC'22] confirms our intuition that cardinality estimation work from the database community can yield returns in this space.</span></p>\n<p dir=\"ltr\"><span>We have disseminated the results of the DPS project to the public at every available opportunity.&nbsp; This includes publication in top peer-reviewed venues and collaborations with national labs, but also trade publications and incorporation into course material at UC Santa Cruz.&nbsp; Materially and via mentorship these projects supported four Doctoral students and two Masters students.</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/04/2023<br>\nModified by: Peter&nbsp;A&nbsp;Alvaro</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThe Declarative Programmable Storage (DPS) project began as an attempt to tame the complexity of Programmable Storage (PS) by applying ideas from data management. PS (as best exemplified by Malacology [Eurosys'19]) brought about a sea change in how applications and infrastructures could utilize distributed storage systems such as Ceph. By exposing reusable units of distributed functionality, PS evolved from a narrow API into a platform upon which new distributed applications could be constructed. With this freedom, however, came hazards, as application programmers were no longer shielded from the rapid changes in storage systems software, hardware, and media. Even minor changes in the underlying system (e.g. a version change in Ceph) led to performance drops of an order of magnitude.\n\n\nThe original vision of DPS was to enable data independence for programmers of storage systems by adapting classical database concepts  most importantly, using optimization to search a space of equivalent implementations of a high-level program, and using cardinality estimation (i.e., informed guesses about result sizes) to provide the optimizer with a concept of cost. In this way, programmers could write an application once, and optimize it as often as necessary to adapt to changes in the storage environment. Key to enabling this freedom were creation of an orchestration system (Skyhook) that could translate a global data processing or retrieval intent into low-level commands to run on storage servers or devices [Vault'19, USENIX login;45(2)], and adoption of a common format for data representation (Apache Arrow) among distributed nodes [PDSW'19, BigData'21].\n\n\nAs the project progressed, our team began to discern that the most difficult decisions facing an optimizer often involve faithfully predicting the scenarios in which performing work at the storage tier, which increases the length and complexity of of the data processing pipeline in exchange for access to more parallel processing power, will provide any performance benefit versus simply doing the work at the client [HotEdge'20, arXiv'22]. Even just greedily considering a single such offloading decision is nontrivial; the overheads of serialization, for example, will often bottleneck an offload, and precise estimation of how an offloaded function will reduce its inputs is required to make intelligent decisions. Our most recent work [HPEC'22] confirms our intuition that cardinality estimation work from the database community can yield returns in this space.\n\n\nWe have disseminated the results of the DPS project to the public at every available opportunity. This includes publication in top peer-reviewed venues and collaborations with national labs, but also trade publications and incorporation into course material at UC Santa Cruz. Materially and via mentorship these projects supported four Doctoral students and two Masters students.\n\n\n\t\t\t\t\tLast Modified: 12/04/2023\n\n\t\t\t\t\tSubmitted by: PeterAAlvaro\n"
 }
}