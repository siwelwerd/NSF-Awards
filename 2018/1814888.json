{
 "awd_id": "1814888",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Communication-Efficient Distributed Algorithms for Machine Learning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2018-07-15",
 "awd_exp_date": "2022-12-31",
 "tot_intn_awd_amt": 464412.0,
 "awd_amount": 464412.0,
 "awd_min_amd_letter_date": "2018-07-02",
 "awd_max_amd_letter_date": "2018-07-17",
 "awd_abstract_narration": "Advances in sensing and processing technologies, communication capabilities and smart devices have enabled deployment of systems where a massive amount of data is collected and then processed in order to make decisions. The platforms that process this vast amount of data differ depending on the application. Among these, data centers are powerful platforms with vast computational resources where the collected data can be distributed over multiple processors that are all connected through a high-bandwidth network. Data can also be generated and processed in multi-agent systems which are made up of multiple interacting computational units (such as smart devices connected through wireless internet) with limited resources in terms of storage, power, computation, and communication capabilities. Data communication costs, which include the bandwidth and latency, often dominate floating point operation costs thus the performance of optimization algorithms when operating on large data sets is bounded by data communication for both multi-agent systems and data centers. This project proposes novel communication-efficient methods for a class of distributed optimization problems arising in large-scale data analysis and machine learning. The methods and techniques developed under the scope of this project contribute to the efficiency, practical performance and to the mathematical foundations of distributed optimization algorithms. The project is also developing a high-performance software framework that allows the dissemination of efficient domain-specific software and benchmarks.\r\n\r\nThe project has three goals: the first goal is to improve the communication efficiency of existing algorithms for solving distributed optimization problems in the context of multi-agent systems, through a distributed algorithm for improving the total number of communications required in consensus iterations. The approach is based on leveraging the notion of the effective resistance of a link to identify bottleneck edges for communication purposes, and modifying the classical consensus averaging by taking effective resistances into account. The second goal is to develop communication-avoiding algorithms for data centers, through a framework that allows for reduction in communication by a tunable amount while keeping the arithmetic costs and bandwidth costs the same for a number of applications and existing algorithms. The third goal is to improve communication for hybrid systems which interpolate between multi-agents systems and data centers in terms of communication structure, using a framework that generates algorithm- and architecture-aware codes for reducing communication over these hybrid platforms.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Maryam",
   "pi_last_name": "Mehri Dehnavi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maryam Mehri Dehnavi",
   "pi_email_addr": "maryam.mehri@rutgers.edu",
   "nsf_id": "000710463",
   "pi_start_date": "2018-07-02",
   "pi_end_date": "2018-07-17"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mert",
   "pi_last_name": "Gurbuzbalaban",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mert Gurbuzbalaban",
   "pi_email_addr": "mg1366@rutgers.edu",
   "nsf_id": "000739809",
   "pi_start_date": "2018-07-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Maryam",
   "pi_last_name": "Mehri Dehnavi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maryam Mehri Dehnavi",
   "pi_email_addr": "maryam.mehri@rutgers.edu",
   "nsf_id": "000710463",
   "pi_start_date": "2018-07-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Mert",
   "pi_last_name": "Gurbuzbalaban",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mert Gurbuzbalaban",
   "pi_email_addr": "mg1366@rutgers.edu",
   "nsf_id": "000739809",
   "pi_start_date": "2018-07-02",
   "pi_end_date": "2018-07-17"
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "CORE 715, 96 Frelinghuysen Rd",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548058",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 464412.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Advances in sensing and processing technologies, communication capabilities, and smart devices have enabled the deployment of systems where massive data is collected and processed to make decisions. The platforms that process this vast amount of data differ depending on the application, including data classification and prediction based on machine learning and artificial intelligence techniques. Among these, data centers are powerful platforms with vast computational resources where the collected data can be distributed over multiple processors connected through a high-bandwidth network. Data can also be generated and processed in multi-agent systems, which comprise multiple interacting computational units (such as smart devices connected through wireless internet) with limited resources in terms of storage, power, computation, and communication capabilities. Data communication costs, which include bandwidth and latency, often dominate local computational costs; thus, the performance of optimization algorithms when operating on large data is bound by data communication for both multi-agent systems and data centers.</p>\n<p>In this project, we developed several communication-efficient methods for distributed optimization problems arising in large-scale data analysis. Our algorithms can be applied to both data centers and multi-agent systems. Our theoretical and numerical results resulted in more efficient state-of-the-art distributed algorithms. Also, this project contributed to the foundations of data science by analyzing many optimization algorithms arising in such big data settings both empirically and theoretically, allowing us to develop novel algorithms with optimal data communication in some settings. In addition, we developed new techniques to study and quantify the performance and robustness of predictive models trained from data using optimization algorithms such as <em>stochastic gradient descent methods</em> and their variants. The practical algorithms and theoretical results we developed have direct applications to large-scale data analysis and machine learning. Furthermore, the project contributed to the thesis of three Ph.D. students at Rutgers University and allowed new incoming graduate students to be trained at Rutgers.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/08/2023<br>\n\t\t\t\t\tModified by: Mert&nbsp;Gurbuzbalaban</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAdvances in sensing and processing technologies, communication capabilities, and smart devices have enabled the deployment of systems where massive data is collected and processed to make decisions. The platforms that process this vast amount of data differ depending on the application, including data classification and prediction based on machine learning and artificial intelligence techniques. Among these, data centers are powerful platforms with vast computational resources where the collected data can be distributed over multiple processors connected through a high-bandwidth network. Data can also be generated and processed in multi-agent systems, which comprise multiple interacting computational units (such as smart devices connected through wireless internet) with limited resources in terms of storage, power, computation, and communication capabilities. Data communication costs, which include bandwidth and latency, often dominate local computational costs; thus, the performance of optimization algorithms when operating on large data is bound by data communication for both multi-agent systems and data centers.\n\nIn this project, we developed several communication-efficient methods for distributed optimization problems arising in large-scale data analysis. Our algorithms can be applied to both data centers and multi-agent systems. Our theoretical and numerical results resulted in more efficient state-of-the-art distributed algorithms. Also, this project contributed to the foundations of data science by analyzing many optimization algorithms arising in such big data settings both empirically and theoretically, allowing us to develop novel algorithms with optimal data communication in some settings. In addition, we developed new techniques to study and quantify the performance and robustness of predictive models trained from data using optimization algorithms such as stochastic gradient descent methods and their variants. The practical algorithms and theoretical results we developed have direct applications to large-scale data analysis and machine learning. Furthermore, the project contributed to the thesis of three Ph.D. students at Rutgers University and allowed new incoming graduate students to be trained at Rutgers. \n\n \n\n\t\t\t\t\tLast Modified: 03/08/2023\n\n\t\t\t\t\tSubmitted by: Mert Gurbuzbalaban"
 }
}