{
 "awd_id": "1820531",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SFS-Capacity: Collaborative: Validation of Concept Assessment Tools for Cybersecurity",
 "cfda_num": "47.076",
 "org_code": "11010000",
 "po_phone": "7032922677",
 "po_email": "liyang@nsf.gov",
 "po_sign_block_name": "Li Yang",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 190033.0,
 "awd_amount": 190033.0,
 "awd_min_amd_letter_date": "2018-06-08",
 "awd_max_amd_letter_date": "2018-06-08",
 "awd_abstract_narration": "The project at the University of Maryland, Baltimore County (UMBC) aims to evaluate two cybersecurity educational assessment tools: the Cybersecurity Concept Inventory (CCI) and the Cybersecurity Curriculum Assessment (CCA). The CCI assesses the quality of instruction of any first course in cybersecurity; the CCA assesses how well a college curriculum prepares graduates for a career in cybersecurity. The evaluation will consist of student interviews, expert reviews, and statistical analyses to examine the efficacy of these tools. In addition, the project will provide initial insights into the efficacy of educational approaches by comparing student performance relative to their instructors? teaching practices. At present, there is not a rigorous, research-based method for measuring the quality of cybersecurity instruction. Validated assessment tools such as the ones in development at UMBC are essential so that educators have trusted methods for discerning whether efforts to improve student preparation are successful. This validation study will complete an essential part of the broader Cybersecurity Assessment Tools project, which will provide rigorous, evidence-based instruments for assessing and evaluating educational practices. \r\n\r\nTo develop evidence for the validity of the CCI?s and CCA?s measurement of student conceptual understanding of cybersecurity, the project will complete six tasks for each assessment tool: (1) conduct at least thirty cognitive interviews of students thinking aloud while answering the draft questions, and use results to improve the validity of the questions; (2) collect and use feedback on the draft questions from at least twenty experts in cybersecurity or cybersecurity education; (3) administer the draft tool to at least 200 students and use psychometric methods of analysis on the results; (4) revise the draft questions in light of tasks 1-3; (5) administer the revised tool to at least 1,000 students and use psychometric analysis on the results; and (6) hold workshops at four cybersecurity education meetings to promote awareness of, and to seek additional feedback on the tools. By following well-established rigorous methods for developing CCIs, this project will help the cybersecurity educational community to develop and improve curricula and instructional methods and materials.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DGE",
 "org_div_long_name": "Division Of Graduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Geoffrey",
   "pi_last_name": "Herman",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Geoffrey L Herman",
   "pi_email_addr": "glherman@illinois.edu",
   "nsf_id": "000592249",
   "pi_start_date": "2018-06-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618207473",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "166800",
   "pgm_ele_name": "CYBERCORPS: SCHLAR FOR SER"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7254",
   "pgm_ref_txt": "CYBER SECURITY ACT PROPOSALS"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 190033.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>As computing becomes increasingly pervasive in our lives, the security of those computing systems is likewise becoming increasingly important. If we want to ensure a safe and secure future for computing, we need to be able to effectively train cybersecurity professionals using evidence-based techniuqes. Unfortunately, we have not historicaly had rigorous, research-based methods for measuring whether cybersecurity instruction is effective. In other words, we have no basis for making evidence-based decisions.</p>\n<p>Through a multi-institution collaboration, we worked to refine two Cybersecurity Assessment Tools and create a body of evidence that demonstrates why researchers and instructors can trust the results that these assessments give. The first tool was the Cybersecurity Concept Inventory (CCI) that measures how well students understand basic concepts in cybersecurity (especially adversarial thinking) after a first course in the field. The second tool was the Cybersecurity Curriculum Assessment (CCA) that measures how well students understand core concepts after completing a full cybersecurity curriculum.</p>\n<p>We conducted a number of interviews with students as they solved questions on the CCI and CCA to make sure that questions were worded clearly by a diverse range of students. We likewise collected feedback from a panel of cybersecurity professionals and professors to make sure that the content of the CCI and CCA accurately represented information that cybersecurity students would need to know. Lastly, we administered the CCI to 600 students and the CCA to 200 students from 30 colleges and universities across the United States. These large scale studies provided evidence that the CCI and CCA were neither too easy nor too difficult and provided rich information about what students knew about cybersecurity.</p>\n<p>With this evidence, we are beginning to work with instructors at a variety of institutions to begin large scale studies to explore how we can best teach cybersecurity professionals and create a safer, more secure future.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/03/2022<br>\n\t\t\t\t\tModified by: Geoffrey&nbsp;L&nbsp;Herman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAs computing becomes increasingly pervasive in our lives, the security of those computing systems is likewise becoming increasingly important. If we want to ensure a safe and secure future for computing, we need to be able to effectively train cybersecurity professionals using evidence-based techniuqes. Unfortunately, we have not historicaly had rigorous, research-based methods for measuring whether cybersecurity instruction is effective. In other words, we have no basis for making evidence-based decisions.\n\nThrough a multi-institution collaboration, we worked to refine two Cybersecurity Assessment Tools and create a body of evidence that demonstrates why researchers and instructors can trust the results that these assessments give. The first tool was the Cybersecurity Concept Inventory (CCI) that measures how well students understand basic concepts in cybersecurity (especially adversarial thinking) after a first course in the field. The second tool was the Cybersecurity Curriculum Assessment (CCA) that measures how well students understand core concepts after completing a full cybersecurity curriculum.\n\nWe conducted a number of interviews with students as they solved questions on the CCI and CCA to make sure that questions were worded clearly by a diverse range of students. We likewise collected feedback from a panel of cybersecurity professionals and professors to make sure that the content of the CCI and CCA accurately represented information that cybersecurity students would need to know. Lastly, we administered the CCI to 600 students and the CCA to 200 students from 30 colleges and universities across the United States. These large scale studies provided evidence that the CCI and CCA were neither too easy nor too difficult and provided rich information about what students knew about cybersecurity.\n\nWith this evidence, we are beginning to work with instructors at a variety of institutions to begin large scale studies to explore how we can best teach cybersecurity professionals and create a safer, more secure future.\n\n\t\t\t\t\tLast Modified: 02/03/2022\n\n\t\t\t\t\tSubmitted by: Geoffrey L Herman"
 }
}