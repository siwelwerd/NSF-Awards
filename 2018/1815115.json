{
 "awd_id": "1815115",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Collaborative Research: Multi-tier Service Architecture in IoT-Edge-Cloud Paradigms",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 461127.0,
 "awd_amount": 467175.0,
 "awd_min_amd_letter_date": "2018-09-02",
 "awd_max_amd_letter_date": "2019-04-22",
 "awd_abstract_narration": "Edge computing is an emerging paradigm in which computing and storage are placed at multiple locations between the endpoint Internet of Things (IoT) devices and the cloud. This is seen as a driving force behind the next wave of advances in IoT solutions. Edge services are predicted to become the next multi-billion dollar technology market and disrupt the current cloud computing based industry. Active industry-wide development and standardization efforts for edge computing are under way to define related architectures. Against this backdrop, this project designs and implements a system architecture to optimize multi-tier service orchestration across IoT devices, edge servers, and the cloud. In contrast to the typical per-application optimization approach, this project takes a unique view of joint, concurrent optimization of multiple applications. This architecture encourages the development of new distributed algorithms for decomposing the processing semantics of IoT applications. Further, the project contributes techniques and reference models to industry standardization efforts.\r\n\r\nHarnessing edge capabilities to transform the IoT service landscape requires novel distributed algorithms and system architectures. This goes far beyond existing approaches for application code partitioning and computation offloading for individual applications. To that end, this project aims to build a system runtime that abstracts away the infrastructure complexity while automating the optimization of application processing. On the compute path, the project highlights new types of correlated computation, where the corresponding input and output are similar but not identical. Eliminating this holds the key to simultaneously optimizing for the computation latency and results quality. The techniques developed further provide primitives to restructure the processing pipelines of these applications. On the control path, the project departs from the existing server-centric control in a single client-server tier, and instead proposes client-centric control in a nested server model to leverage multiple tiers of computing capabilities. Finally, the above techniques are integrated into a system runtime, which further provides simple APIs (application programming interface) and generic system level support such as scheduling.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Wenjun",
   "pi_last_name": "Hu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wenjun Hu",
   "pi_email_addr": "wenjun.hu@yale.edu",
   "nsf_id": "000677005",
   "pi_start_date": "2018-09-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Yale University",
  "inst_street_address": "150 MUNSON ST",
  "inst_street_address_2": "",
  "inst_city_name": "NEW HAVEN",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "2037854689",
  "inst_zip_code": "065113572",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "CT03",
  "org_lgl_bus_name": "YALE UNIV",
  "org_prnt_uei_num": "FL6GV84CKN57",
  "org_uei_num": "FL6GV84CKN57"
 },
 "perf_inst": {
  "perf_inst_name": "Yale University",
  "perf_str_addr": "17 Hillhouse Avenue",
  "perf_city_name": "New Haven",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "065208263",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "CT03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 461127.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 6048.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Over the last few years, edge intelligence has emerged as a key driving force behind ongoing advances in Internet-of-Things (IoT) solutions permeating everyday life. In contrast to cloud computing, computing and storage are placed at or near the IoT devices and data sources, motivated by reduced network latency, reduced access link bandwidth requirements, and/or data privacy protection. Further, learning-based computation increasingly dominates edge workloads. Against this backdrop, this project designs and implements systems to optimize for the programmability and performance of edge workloads across heterogeneous scenarios. Algorithmically, we have proposed a new paradigm of harnessing semantic correlation between learning-based computation instances, in the form of semantically <em>approximate computation reuse</em>. This highlights a new direction for approximate computing, by leveraging the semantics of the compute task (not just the precision of the results), as well as a new optimization strategy for deep learning inference, by leveraging its statistical nature. With this paradigm, we have restructured the computation flow, building concise indices for highly redundant raw data and deep learning models trained on such data, and reusing previous inference results on semantically similar though non-identical input data. From the system perspective, we have proposed a series of abstractions, which collectively provide frameworks to handle application development and deployment at scale over diverse edge scenarios.</p>\n<p><br />To optimize for the compute path, we proposed algorithms to assess the hidden correlation between the semantics of the input data, the neural network models, and the deployment environments, and then merge common processing steps to minimize redundancy. The benefits of these approaches are substantial. Potluck and FoggyCache, for example, have provided several folds of reduction in the processing time and energy consumption on the mobile devices, equivalent to significant resource efficiency. Remarkably, this shows the potential for software runtime optimizations, against the backdrop of significant investment into hardware acceleration. Mistify provides orders of magnitude of saving in the computation and manual efforts needed. On the other hand, each work identifies missing support from existing ecosystems and adds a new intermediate service layer. For example, Mistify adds a model porting stage to decouple model design and deployment; Sommelier adds an indexing layer above an existing repository, which currently provides a barebone filesystem; Potluck and FoggyCache add caching layers on the compute path. We further took early steps to generalize these further, by extending analytics support from a single modality (e.g., video) to multiple input streams (e.g., also audio and text), masking heterogeneous edge execution scenarios through containerization, providing end-to-end optimization by pruning redundant modalities, and a device-centric scheduling layer.</p>\n<p><br />The above results have been widely disseminated in leading systems and data management venues, including publications at ACM MobiCom'18, USENIX NSDI'21, and ACM SIGMOD'22. Results were also disseminated in invited talks, including a keynote at the New England Networks and Systems Workshop, lightning talks at Google's Federated Learning and Analytics Workshop, and seminars at Carnegie Mellon University, the Ohio State University, On-Device ML Tech Talk at Google, and the NSF AI Institute on Edge Computing.</p>\n<p><br />The system abstractions from the thesis work can lead to a redesign of learning based software systems, while the algorithmic approaches provide tools to analyze and explain the internal structures of deep learning models. Practically, we have produced a toolkit to help practitioners, which can be an enabler for more diverse IoT application scenarios. We have open-sourced the code for several system components as standalone tools. For example, Mistify and Sommelier were built on TensorFlow and provide a model management layer to decouple and bridge the training and serving phases. We are currently exploring further technical transfer opportunities. <br /><br />From an educational perspective, the project provided several opportunities for research, teaching and mentoring in science and engineering. These include training PhD students, research experience for undergraduates via REU and senior theses, teaching material for the PI's classes, and mentoring at N2Women events.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/29/2023<br>\n\t\t\t\t\tModified by: Wenjun&nbsp;Hu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOver the last few years, edge intelligence has emerged as a key driving force behind ongoing advances in Internet-of-Things (IoT) solutions permeating everyday life. In contrast to cloud computing, computing and storage are placed at or near the IoT devices and data sources, motivated by reduced network latency, reduced access link bandwidth requirements, and/or data privacy protection. Further, learning-based computation increasingly dominates edge workloads. Against this backdrop, this project designs and implements systems to optimize for the programmability and performance of edge workloads across heterogeneous scenarios. Algorithmically, we have proposed a new paradigm of harnessing semantic correlation between learning-based computation instances, in the form of semantically approximate computation reuse. This highlights a new direction for approximate computing, by leveraging the semantics of the compute task (not just the precision of the results), as well as a new optimization strategy for deep learning inference, by leveraging its statistical nature. With this paradigm, we have restructured the computation flow, building concise indices for highly redundant raw data and deep learning models trained on such data, and reusing previous inference results on semantically similar though non-identical input data. From the system perspective, we have proposed a series of abstractions, which collectively provide frameworks to handle application development and deployment at scale over diverse edge scenarios.\n\n\nTo optimize for the compute path, we proposed algorithms to assess the hidden correlation between the semantics of the input data, the neural network models, and the deployment environments, and then merge common processing steps to minimize redundancy. The benefits of these approaches are substantial. Potluck and FoggyCache, for example, have provided several folds of reduction in the processing time and energy consumption on the mobile devices, equivalent to significant resource efficiency. Remarkably, this shows the potential for software runtime optimizations, against the backdrop of significant investment into hardware acceleration. Mistify provides orders of magnitude of saving in the computation and manual efforts needed. On the other hand, each work identifies missing support from existing ecosystems and adds a new intermediate service layer. For example, Mistify adds a model porting stage to decouple model design and deployment; Sommelier adds an indexing layer above an existing repository, which currently provides a barebone filesystem; Potluck and FoggyCache add caching layers on the compute path. We further took early steps to generalize these further, by extending analytics support from a single modality (e.g., video) to multiple input streams (e.g., also audio and text), masking heterogeneous edge execution scenarios through containerization, providing end-to-end optimization by pruning redundant modalities, and a device-centric scheduling layer.\n\n\nThe above results have been widely disseminated in leading systems and data management venues, including publications at ACM MobiCom'18, USENIX NSDI'21, and ACM SIGMOD'22. Results were also disseminated in invited talks, including a keynote at the New England Networks and Systems Workshop, lightning talks at Google's Federated Learning and Analytics Workshop, and seminars at Carnegie Mellon University, the Ohio State University, On-Device ML Tech Talk at Google, and the NSF AI Institute on Edge Computing.\n\n\nThe system abstractions from the thesis work can lead to a redesign of learning based software systems, while the algorithmic approaches provide tools to analyze and explain the internal structures of deep learning models. Practically, we have produced a toolkit to help practitioners, which can be an enabler for more diverse IoT application scenarios. We have open-sourced the code for several system components as standalone tools. For example, Mistify and Sommelier were built on TensorFlow and provide a model management layer to decouple and bridge the training and serving phases. We are currently exploring further technical transfer opportunities. \n\nFrom an educational perspective, the project provided several opportunities for research, teaching and mentoring in science and engineering. These include training PhD students, research experience for undergraduates via REU and senior theses, teaching material for the PI's classes, and mentoring at N2Women events.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 01/29/2023\n\n\t\t\t\t\tSubmitted by: Wenjun Hu"
 }
}