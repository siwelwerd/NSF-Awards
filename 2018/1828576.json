{
 "awd_id": "1828576",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MRI: Development of Reconfigurable Environmental Intelligence Platform",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Nicholas Goldsmith",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 600000.0,
 "awd_amount": 600000.0,
 "awd_min_amd_letter_date": "2018-09-11",
 "awd_max_amd_letter_date": "2022-09-07",
 "awd_abstract_narration": "This project, developing a Reconfigurable Environmental Intelligence Platform (REIP) aims to alleviate many complex aspects of remote sensing, including sensor node design, software stack implementation, privacy issues, bandwidth, and centralized compute limitations, bringing down start up times from years to weeks. REIP will be a plug-and-play remote sensing infrastructure with advanced edge processing capabilities for in situ- insight generation. Sensor networks have dynamically expanded our ability to monitor and study our world Sensor networks have already deployed specialized sensor networks for many applications, including monitoring pedestrian traffic and outdoor noise monitoring and the need for sensing networks keeps increasing as the use cases for sensor networks expands and becomes more complex. Sensors no longer simply record data, they process and transforms it into something useful before sending it to central servers. \r\n\r\nAt the core of REIP is a set of hardware modules that connect together to form a sensing solution. Each sensing module will come in a number of variants allowing the user to find the proper tradeoff between complexity/ ost and power/features. The REIP infrastructure will expand the use of audio-visual sensing architectures beyond the highly specialized research groups that are able to design, build, and purchase all the necessary components and make it available to a wider community as a research infrastructure. REIP will be tested on real-world applications, including observation, integrated sensing transportation networks, and indoor sensing for reducing waste in HVAC (Heating, Ventilating, and Air Conditioning) systems. Experts will be able to customize each application domain.\r\n \r\nLed by a team of researchers with expertise in sensor networks, machine learning, deep learning, visualization, data analysis, human computing interface, engineering, and occupational therapy, this work will contribute to a variety of projects and is bound to have significant broader impacts. REIP and this research will directly impact a diverse population of students and foster education in science, technology, engineering, and math (STEM). Mentoring opportunities will be provided for all the involved graduate and undergraduate students\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Claudio",
   "pi_last_name": "Silva",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Claudio T Silva",
   "pi_email_addr": "csilva@nyu.edu",
   "nsf_id": "000124941",
   "pi_start_date": "2018-09-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kaan",
   "pi_last_name": "Ozbay",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Kaan M Ozbay",
   "pi_email_addr": "kaan.ozbay@nyu.edu",
   "nsf_id": "000239120",
   "pi_start_date": "2018-09-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Juan",
   "pi_last_name": "Bello",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Juan P Bello",
   "pi_email_addr": "jpbello@nyu.edu",
   "nsf_id": "000496889",
   "pi_start_date": "2018-09-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Semiha",
   "pi_last_name": "Ergan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Semiha Ergan",
   "pi_email_addr": "semiha@nyu.edu",
   "nsf_id": "000588275",
   "pi_start_date": "2018-09-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1189",
   "pgm_ref_txt": "MAJOR RESEARCH INSTRUMENTATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 600000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this research project, we developed REIP, a novel Reconfigurable Environmental Intelligence Platform for fast sensor network prototyping. REIP consists of hardware and software components, its most central capability being an open-source software framework (SDK) with a flexible modular API for data collection and analysis using multiple sensing modalities. It was developed to be user-friendly, device-agnostic, and easily extensible, allowing for fast prototyping of heterogeneous sensor networks. REIP is implemented in Python to widen accessibility and encourage future contributions by lowering the learning curve.<br /><br />The potential and versatility of REIP have been validated through real-world deployments. One such instance involved acquiring the StreetAware dataset, a rich multimodal urban scene collection consisting of high-resolution audio, video, and LiDAR data from three Brooklyn intersections totaling approximately 7 unique hours. The audio and video, which come from multiple REIP devices, are accurately synchronized across the corresponding video and audio inputs, enabling novel applications, such as: (1) discovering and locating occluded objects, (2) associating audio events with their respective visual representations using both video and audio modes, (3) tracking the amount of each type of object in a scene over time, and (4) measuring pedestrian speed using multiple synchronized camera views.<br /><br />This data enables the study of data-driven solutions for urban problems, and the techniques we are developing can be incorporated into the future built environment to enhance accessibility and equity (e.g., traffic lights that adapt to pedestrians' needs).<br /><br />As part of our research efforts, we have developed techniques and systems for analyzing, processing, and visualizing large collections of city imagery. We developed Urban Mosaic, a tool for exploring the urban fabric through images that is capable of handling spatially and temporally dense datasets comprising millions of images.&nbsp; We have also designed CitySurfaces, an active learning-based framework that leverages computer vision techniques for classifying sidewalk materials using street-level images. Sidewalk material information has many practical uses but is seldom available for US cities. The final contribution that we would like to highlight is Tile2Net, an end-to-end open-source tool for extracting sidewalk, crosswalk, and footpath polygons from orthorectified aerial imagery using semantic segmentation.<br /><br />This project helped to establish the Visualization Lab at New York University, which has contributed to the education of PhD, MS, undergraduate, and even K-12 students. The lab's facilities will continue to serve generations of students to come. The REIP project has given rise to several open-source projects, some of which have already gained substantial external visibility and interest. The project has also produced significant data releases (e.g., StreetAware). Collectively, the REIP hardware and software along with the additional delivered software and data releases have already impacted data-driven urban science, and are likely to continue shaping this rapidly evolving research area.<br /><br /><br /></p><br>\n<p>\n Last Modified: 02/18/2024<br>\nModified by: Claudio&nbsp;T&nbsp;Silva</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1828576/1828576_10581939_1708318226774_streetaware--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/1828576/1828576_10581939_1708318226774_streetaware--rgov-800width.jpg\" title=\"StreetAware sensor positions and data types.\"><img src=\"/por/images/Reports/POR/2024/1828576/1828576_10581939_1708318226774_streetaware--rgov-66x44.jpg\" alt=\"StreetAware sensor positions and data types.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">StreetAware sensor positions and data types at the Commodore Barry Park intersection. Colors indicate the session, and numbers denote the sensor. This figure highlights all data modalities that are being captured during the collection process: audio, video, and LiDAR scans.</div>\n<div class=\"imageCredit\">Yurii Piadyk, New York University</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Claudio&nbsp;T&nbsp;Silva\n<div class=\"imageTitle\">StreetAware sensor positions and data types.</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1828576/1828576_10581939_1708318313867_happysensor--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/1828576/1828576_10581939_1708318313867_happysensor--rgov-800width.jpg\" title=\"REIP Happy Sensor\"><img src=\"/por/images/Reports/POR/2024/1828576/1828576_10581939_1708318313867_happysensor--rgov-66x44.jpg\" alt=\"REIP Happy Sensor\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">REIP Happy Sensor is a multimodal sensor that includes two 5 MP cameras, a 12 channel microphone array and a cellular modem. The sensor is waterproof for outdoor operation and powered by the NVIDIA Jetson Nano, which is thermally coupled to the aluminum enclosure for passive/silent cooling.</div>\n<div class=\"imageCredit\">Yurii Piadyk, New York University</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Claudio&nbsp;T&nbsp;Silva\n<div class=\"imageTitle\">REIP Happy Sensor</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn this research project, we developed REIP, a novel Reconfigurable Environmental Intelligence Platform for fast sensor network prototyping. REIP consists of hardware and software components, its most central capability being an open-source software framework (SDK) with a flexible modular API for data collection and analysis using multiple sensing modalities. It was developed to be user-friendly, device-agnostic, and easily extensible, allowing for fast prototyping of heterogeneous sensor networks. REIP is implemented in Python to widen accessibility and encourage future contributions by lowering the learning curve.\n\nThe potential and versatility of REIP have been validated through real-world deployments. One such instance involved acquiring the StreetAware dataset, a rich multimodal urban scene collection consisting of high-resolution audio, video, and LiDAR data from three Brooklyn intersections totaling approximately 7 unique hours. The audio and video, which come from multiple REIP devices, are accurately synchronized across the corresponding video and audio inputs, enabling novel applications, such as: (1) discovering and locating occluded objects, (2) associating audio events with their respective visual representations using both video and audio modes, (3) tracking the amount of each type of object in a scene over time, and (4) measuring pedestrian speed using multiple synchronized camera views.\n\nThis data enables the study of data-driven solutions for urban problems, and the techniques we are developing can be incorporated into the future built environment to enhance accessibility and equity (e.g., traffic lights that adapt to pedestrians' needs).\n\nAs part of our research efforts, we have developed techniques and systems for analyzing, processing, and visualizing large collections of city imagery. We developed Urban Mosaic, a tool for exploring the urban fabric through images that is capable of handling spatially and temporally dense datasets comprising millions of images. We have also designed CitySurfaces, an active learning-based framework that leverages computer vision techniques for classifying sidewalk materials using street-level images. Sidewalk material information has many practical uses but is seldom available for US cities. The final contribution that we would like to highlight is Tile2Net, an end-to-end open-source tool for extracting sidewalk, crosswalk, and footpath polygons from orthorectified aerial imagery using semantic segmentation.\n\nThis project helped to establish the Visualization Lab at New York University, which has contributed to the education of PhD, MS, undergraduate, and even K-12 students. The lab's facilities will continue to serve generations of students to come. The REIP project has given rise to several open-source projects, some of which have already gained substantial external visibility and interest. The project has also produced significant data releases (e.g., StreetAware). Collectively, the REIP hardware and software along with the additional delivered software and data releases have already impacted data-driven urban science, and are likely to continue shaping this rapidly evolving research area.\n\n\n\t\t\t\t\tLast Modified: 02/18/2024\n\n\t\t\t\t\tSubmitted by: ClaudioTSilva\n"
 }
}