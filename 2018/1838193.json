{
 "awd_id": "1838193",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: IA: Multiplatform, Multilingual, and Multimodal Tools for Analyzing Public Communication in over 100 Languages",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 1000000.0,
 "awd_amount": 1000000.0,
 "awd_min_amd_letter_date": "2018-09-07",
 "awd_max_amd_letter_date": "2018-09-07",
 "awd_abstract_narration": "In today's information age, understanding public communication flows around the world is important to United States policy and diplomacy. The challenge for research is to collect, analyze, and interpret information as it is presented worldwide, creating big data that is flowing at high velocity, in large volumes, with much variety in perspective, language, and platforms. Analytic methods for studying textual and visual public information worldwide are limited by language hurdles. This project aims to solve data analytics problems in the domain of international public information flows by developing methods that effectively leverage natural language processing, machine learning, and computer vision tools.\r\n    \r\nThis research will involve collecting multilingual, multiplatform, and multimodal corpora of text and images originating in the U.S. and reported worldwide, developing an interactive budget-efficient methodology for annotation by experts and crowdworkers that scales effectively, using machine learning and deep learning techniques that exploit multilingual and multimodal representations to develop data analytics tools for entity and frame recognition, sentiment analysis of entities and frames, and curating balanced real-time content collections for many languages. This project is expected to generate analytical tools for social scientists and others to better examine the international flow of public communications. The annotated data will provide training and benchmark datasets that can propel research in entity and frame recognition, sentiment analysis, and other related natural language processing tasks for many languages.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Margrit",
   "pi_last_name": "Betke",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Margrit Betke",
   "pi_email_addr": "betke@cs.bu.edu",
   "nsf_id": "000096058",
   "pi_start_date": "2018-09-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Prakash",
   "pi_last_name": "Ishwar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Prakash Ishwar",
   "pi_email_addr": "pi@bu.edu",
   "nsf_id": "000310021",
   "pi_start_date": "2018-09-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Lei",
   "pi_last_name": "Guo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lei Guo",
   "pi_email_addr": "guolei@bu.edu",
   "nsf_id": "000738195",
   "pi_start_date": "2018-09-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Derry",
   "pi_last_name": "Wijaya",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Derry Wijaya",
   "pi_email_addr": "derry.wijaya@gmail.com",
   "nsf_id": "000779252",
   "pi_start_date": "2018-09-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Trustees of Boston University",
  "inst_street_address": "1 SILBER WAY",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173534365",
  "inst_zip_code": "022151703",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "TRUSTEES OF BOSTON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "THL6A6JLE1S7"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of Boston University",
  "perf_str_addr": "881 Commonwealth Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "022151300",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  },
  {
   "pgm_ele_code": "829400",
   "pgm_ele_name": "Data Infrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 1000000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This award supported the </span><strong>Artificial Intelligence and Emerging Media (AIEM)&nbsp;</strong><span>research group at Boston University to conduct research and foster education in areas related to artificial intelligence and emerging media. The group explores and creates techniques from machine learning, natural language processing, and computer vision to interpret emerging media and their role in mass and interpersonal communication.&nbsp; AIEM studies the human and automated processes by which emerging media are developed, marketed, shaped and reshaped by users.</span></p>\n<p><span><span>Different news articles about the same topic often offer a variety of perspectives: an article written about gun violence might emphasize gun control, while another might promote 2nd Amendment rights, and yet a third might focus on mental health issues. In communication research, these different perspectives are known as \"<strong>frames</strong>\" which, when used in news media, will influence the opinion of their readers in multiple ways. AIEM developed an automated method for effectively detecting frames in<strong> news headlines in any language</strong> and applied it<span>&nbsp;in a large scale study of 88 thousand news headlines about the coverage of gun violence in the U.S.between 2016 and 2018 in English, German, Arabic, and Turkish.&nbsp; The analysis revealed that the U.S. media highly politicized the reporting of gun violence.&nbsp;</span></span></span>The research team also applied the frame detection approach to COVID-19 news reports in nine regions of the world in 2020.</p>\n<p><span>AIEM developed an interactive web-based tool called <strong>OpenFraming </strong>for automatically analyzing and classifying frames in text documents.&nbsp; The goal for providing this tool was to make automatic frame discovery and labeling based on topic modeling and deep learning widely accessible to researchers from a diverse array of disciplines. To this end, the team provided both state-of-the-art pre-trained frame classification models on various issues as well as a user-friendly pipeline for training novel classification models on user-provided corpora. Researchers can submit their documents and obtain frames of the documents.The degree of user involvement is flexible: a user can run models that have been pre-trained on select issues; submit labeled documents and train a new model for frame classification; or submit unlabeled documents and obtain potential frames of the documents. The code making up the OpenFraming tool is open-sourced and well documented, making the system transparent and expandable.&nbsp;</span></p>\n<p><span><span>AIEM developed AI-based methods to identify textual and visual news items that will trigger similar versus divergent <strong>emotional responses by news consumers</strong>. The group published a dataset that can serve as a&nbsp;<span>benchmark for AI methods predicting people's emotional reactions towards multi-modal news content (images and headlines).</span></span></span></p>\n<p><span><span><span>Most recently, the AIEM team explored&nbsp;</span></span></span>the affective responses and newsworthiness perceptions of <strong>generative AI for visual journalism</strong>. While generative AI offers advantages for newsrooms in terms of producing unique images and cutting costs, the potential misuse of AI-generated news images is a cause for concern. For the study, the team designed a 3-part news image codebook for affect-labeling news images based on journalism ethics and photography guidelines. They collected 200 news headlines and images retrieved from a variety of U.S. news sources on the topics of gun violence and climate change, generated corresponding news images from a commercial image-generating AI model, and asked study participants to annotate their emotional responses to the human-selected and AI-generated news images following the codebook. The team examined the impact of modality on emotions by measuring the effects of visual and textual modalities on emotional responses. The findings of this study provide insights into the quality and emotional impact of generative news images produced by people and AI. Further, results of this work can be useful in developing technical guidelines as well as policy measures for the ethical use of generative AI systems in journalistic production.</p>\n<p><span><br /></span></p><br>\n<p>\n Last Modified: 03/11/2024<br>\nModified by: Margrit&nbsp;Betke</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202327407_CommunicatingCOVD19_USNewsTopicsbyWeek--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202327407_CommunicatingCOVD19_USNewsTopicsbyWeek--rgov-800width.png\" title=\"Communicating COVID 19\"><img src=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202327407_CommunicatingCOVD19_USNewsTopicsbyWeek--rgov-66x44.png\" alt=\"Communicating COVID 19\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A combination of communication research methods and data science tools were used to identify main topics emphasized in the news U.S. coverage during 2020.</div>\n<div class=\"imageCredit\">AIEM research group, Boston University</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Margrit&nbsp;Betke\n<div class=\"imageTitle\">Communicating COVID 19</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202652396_OpenFraming--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202652396_OpenFraming--rgov-800width.png\" title=\"OpenFraming\"><img src=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202652396_OpenFraming--rgov-66x44.png\" alt=\"OpenFraming\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Interactive web-based machine learning tool for multilingual media frame analysis of user-provided data</div>\n<div class=\"imageCredit\">AIEM research group, Boston University</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Margrit&nbsp;Betke\n<div class=\"imageTitle\">OpenFraming</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202566583_gun_violence_emotional_responses--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202566583_gun_violence_emotional_responses--rgov-800width.png\" title=\"Emotional responses of news consumers to gun violence news content\"><img src=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202566583_gun_violence_emotional_responses--rgov-66x44.png\" alt=\"Emotional responses of news consumers to gun violence news content\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Distribution of emotional responses by news consumers to news images (I) and headline text (T) in the NEmo+ dataset.</div>\n<div class=\"imageCredit\">AIEM research group, Boston University</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Margrit&nbsp;Betke\n<div class=\"imageTitle\">Emotional responses of news consumers to gun violence news content</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710201837324_Screen_Shot_2020_04_02_at_6.51.16_PM--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710201837324_Screen_Shot_2020_04_02_at_6.51.16_PM--rgov-800width.png\" title=\"Gun Violence: U.S. Frame Trends for 2016 to 2018\"><img src=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710201837324_Screen_Shot_2020_04_02_at_6.51.16_PM--rgov-66x44.png\" alt=\"Gun Violence: U.S. Frame Trends for 2016 to 2018\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The number of times each frame is represented in new article headlines related to gun violence across the 3-year (per month) period. Some of the peaks represent the deadliest mass shootings in the U.S. since 1949.</div>\n<div class=\"imageCredit\">AIEM research group, Boston University</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Margrit&nbsp;Betke\n<div class=\"imageTitle\">Gun Violence: U.S. Frame Trends for 2016 to 2018</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202165979_gun_framing_US_Germany--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202165979_gun_framing_US_Germany--rgov-800width.png\" title=\"Comparison of frame association networks in the U.S. and German news\"><img src=\"/por/images/Reports/POR/2024/1838193/1838193_10580570_1710202165979_gun_framing_US_Germany--rgov-66x44.png\" alt=\"Comparison of frame association networks in the U.S. and German news\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Comparing the frame networks in the U.S. and Germany, it appears that U.S. media are highly politicized.  The frame \"politics\" is not only the most central node in the network but also closely connected with other frames, a pattern not found in German news.</div>\n<div class=\"imageCredit\">AIEM research group, Boston University</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Margrit&nbsp;Betke\n<div class=\"imageTitle\">Comparison of frame association networks in the U.S. and German news</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis award supported the Artificial Intelligence and Emerging Media (AIEM)research group at Boston University to conduct research and foster education in areas related to artificial intelligence and emerging media. The group explores and creates techniques from machine learning, natural language processing, and computer vision to interpret emerging media and their role in mass and interpersonal communication. AIEM studies the human and automated processes by which emerging media are developed, marketed, shaped and reshaped by users.\n\n\nDifferent news articles about the same topic often offer a variety of perspectives: an article written about gun violence might emphasize gun control, while another might promote 2nd Amendment rights, and yet a third might focus on mental health issues. In communication research, these different perspectives are known as \"frames\" which, when used in news media, will influence the opinion of their readers in multiple ways. AIEM developed an automated method for effectively detecting frames in news headlines in any language and applied itin a large scale study of 88 thousand news headlines about the coverage of gun violence in the U.S.between 2016 and 2018 in English, German, Arabic, and Turkish. The analysis revealed that the U.S. media highly politicized the reporting of gun violence.The research team also applied the frame detection approach to COVID-19 news reports in nine regions of the world in 2020.\n\n\nAIEM developed an interactive web-based tool called OpenFraming for automatically analyzing and classifying frames in text documents. The goal for providing this tool was to make automatic frame discovery and labeling based on topic modeling and deep learning widely accessible to researchers from a diverse array of disciplines. To this end, the team provided both state-of-the-art pre-trained frame classification models on various issues as well as a user-friendly pipeline for training novel classification models on user-provided corpora. Researchers can submit their documents and obtain frames of the documents.The degree of user involvement is flexible: a user can run models that have been pre-trained on select issues; submit labeled documents and train a new model for frame classification; or submit unlabeled documents and obtain potential frames of the documents. The code making up the OpenFraming tool is open-sourced and well documented, making the system transparent and expandable.\n\n\nAIEM developed AI-based methods to identify textual and visual news items that will trigger similar versus divergent emotional responses by news consumers. The group published a dataset that can serve as abenchmark for AI methods predicting people's emotional reactions towards multi-modal news content (images and headlines).\n\n\nMost recently, the AIEM team exploredthe affective responses and newsworthiness perceptions of generative AI for visual journalism. While generative AI offers advantages for newsrooms in terms of producing unique images and cutting costs, the potential misuse of AI-generated news images is a cause for concern. For the study, the team designed a 3-part news image codebook for affect-labeling news images based on journalism ethics and photography guidelines. They collected 200 news headlines and images retrieved from a variety of U.S. news sources on the topics of gun violence and climate change, generated corresponding news images from a commercial image-generating AI model, and asked study participants to annotate their emotional responses to the human-selected and AI-generated news images following the codebook. The team examined the impact of modality on emotions by measuring the effects of visual and textual modalities on emotional responses. The findings of this study provide insights into the quality and emotional impact of generative news images produced by people and AI. Further, results of this work can be useful in developing technical guidelines as well as policy measures for the ethical use of generative AI systems in journalistic production.\n\n\n\n\t\t\t\t\tLast Modified: 03/11/2024\n\n\t\t\t\t\tSubmitted by: MargritBetke\n"
 }
}