{
 "awd_id": "1811376",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "A Non-Asymptotic Theory of Robustness",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2018-07-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 120000.0,
 "awd_amount": 120000.0,
 "awd_min_amd_letter_date": "2018-05-11",
 "awd_max_amd_letter_date": "2020-05-03",
 "awd_abstract_narration": "Modern data acquisitions have facilitated the collection of large-scale data with complex structures, and meanwhile, have introduced a series of new challenges to data analysis both statistically and computationally. The heavy-tailed character of the distribution of empirical data has been repeatedly observed in many fields of research, including microarray studies in genomics, neuroimaging in medicine, and portfolio optimization and risk management in finance. In functional MRI studies, the parametric statistical methods often fail to produce valid cluster-wise inference, where the principal cause is that the spatial autocorrelation functions do not follow the assumed Gaussian shape; in finance, the power-law nature of the distribution of returns has been validated as a stylized fact over the years. The least squares method, albeit being most commonly used in practice due to its simplicity as a once-for-all solution, is sensitive to the tails of sample distributions and is proven to be suboptimal for heavy-tailed data from a non-asymptotic viewpoint. In this project, the PI will develop robust statistical procedures for various problems, ranging from mean estimation, linear regression, high-dimensional sparse regression to large covariance matrix estimation. The main goals of this research are to understand the finite-sample properties of robust learning, and to develop computationally efficient procedures that advance the practical use of robust methods.\r\n\r\nIn this project, the PI will study robust alternatives to the method of least squares for two fundamental problems: linear regression and covariance estimation. To achieve robustness against asymmetric and heavy-tailed data, the main idea is to use the adaptive Huber loss and its extension on the matrix space. From a non-asymptotic viewpoint, the accompanying scale parameter should adapt to the sample size, dimension and noise level for optimal tradeoff between the gain in stability and cost in bias. The work on the project aims to (i) develop new methods for robust estimation and inference under linear models, and investigate their mathematical underpinnings using techniques from concentration inequality in probability, finite-sample theory for M-estimation in statistics and convex analysis in optimization, and (ii) construct both general and structured large covariance matrix estimators under minimal assumptions on the data. The originality of the project resides in providing new perspectives on robustness, which not only represent useful complements to classical robust statistics but also make important contributions to modern statistical analysis, including high dimensional estimation and large-scale inference. The philosophy of the project echos John Tukey's principles for statistical practice by highlighting the importance of having methods of statistical analysis that are robust to violations of the assumptions underlying their use and allowing the possibility of data's influencing the choice of method by which they are analyzed.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Wenxin",
   "pi_last_name": "Zhou",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wenxin Zhou",
   "pi_email_addr": "wenxinz@uic.edu",
   "nsf_id": "000754197",
   "pi_start_date": "2018-05-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 Gilman Drive",
  "perf_city_name": "La Jolla",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930112",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 40000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 40000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 40000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Supported by this award from NSF, the PI and his collaborators have developed a series of user-friendly and computationally efficient robust statistical methods for heavy-tailed data. The &ldquo;heavy-tailed\" character of the distribution of empirical data has been repeatedly observed in various areas, including genomics, medical imaging and finance. Classical least squares type methods often behave poorly in deviations for heavy-tailed distributions. Inspired by the seminal work of Peter J. Huber in 1973, we develop tail-robust estimation and inference methods and theory for several fundamental statistical problems, including large structured covariance matrix estimation, linear (sparse) regression models and multi-factor models. The theoretical characterization and practical tuning of several key robustification parameters are carefully studied. We further develop scalable numerical algorithms for the proposed methods, implemented in both R and Python.</p>\n<p>The outcomes of this award include: (i) nine papers published in peer-reviewed journals, including the Annals of Statistics, Statistical Science, Journal of the American Statistical Association, Computational Statistics and Data Analysis, Electronic Journal of Statistics, and Statistica Sinica; and (ii) two R packages, FarmTest and adaHuber, that are available on The Comprehensive R Archvie Network. This award also helps the PI train two graduate students. One student graduated in May 2022, and the other is expected to graduate in early 2023.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/01/2022<br>\n\t\t\t\t\tModified by: Wenxin&nbsp;Zhou</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSupported by this award from NSF, the PI and his collaborators have developed a series of user-friendly and computationally efficient robust statistical methods for heavy-tailed data. The \"heavy-tailed\" character of the distribution of empirical data has been repeatedly observed in various areas, including genomics, medical imaging and finance. Classical least squares type methods often behave poorly in deviations for heavy-tailed distributions. Inspired by the seminal work of Peter J. Huber in 1973, we develop tail-robust estimation and inference methods and theory for several fundamental statistical problems, including large structured covariance matrix estimation, linear (sparse) regression models and multi-factor models. The theoretical characterization and practical tuning of several key robustification parameters are carefully studied. We further develop scalable numerical algorithms for the proposed methods, implemented in both R and Python.\n\nThe outcomes of this award include: (i) nine papers published in peer-reviewed journals, including the Annals of Statistics, Statistical Science, Journal of the American Statistical Association, Computational Statistics and Data Analysis, Electronic Journal of Statistics, and Statistica Sinica; and (ii) two R packages, FarmTest and adaHuber, that are available on The Comprehensive R Archvie Network. This award also helps the PI train two graduate students. One student graduated in May 2022, and the other is expected to graduate in early 2023.\n\n\t\t\t\t\tLast Modified: 07/01/2022\n\n\t\t\t\t\tSubmitted by: Wenxin Zhou"
 }
}