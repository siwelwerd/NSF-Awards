{
 "awd_id": "1830247",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ATD: Collaborative Research: Statistically Principled Real-Time Detection of Anomalies for Temporal Network Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leland Jameson",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 75000.0,
 "awd_amount": 75000.0,
 "awd_min_amd_letter_date": "2018-08-07",
 "awd_max_amd_letter_date": "2018-08-07",
 "awd_abstract_narration": "The detection of anomalous events in time-evolving networks of interconnected entities is gaining importance in our increasingly connected world. Example applications of anomaly detection in this setting include detecting terrorist cells or hate groups in a social network, identifying over-burdened power plants in a power grid, and uncovering illegal activity in financial markets. A major benefit of casting these problems as anomaly detection in networks is the ability to leverage the underlying network structure to significantly improve detection power. This research aims to develop a framework for anomaly detection in networks that guarantees good detection performance.\r\n\r\nThis research aims to develop a two-stage pipeline for statistically-principled detection of anomalous events in static and dynamic networks. The first stage uses the structure and temporal evolution of the network to generate continually evolving time-series data for each node on the network. These multivariate time-series will be built out of a range of features, potentially including global information such as that from the spectral embedding and local information such as a nodes participation in subgraph patterns, or so-called \"motifs\". Part of this research is therefore necessarily developing efficient means to compute and update these features as the network evolves. The second stage leverages recent developments in robust statistics, especially multivariate quantile regression, to integrate side information and flag potential anomalies for further investigation.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yuekai",
   "pi_last_name": "Sun",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yuekai Sun",
   "pi_email_addr": "yuekai@umich.edu",
   "nsf_id": "000758966",
   "pi_start_date": "2018-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "1085 South University Ave.",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091107",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "046Y00",
   "pgm_ele_name": "ATD-Algorithms for Threat Dete"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6877",
   "pgm_ref_txt": "ALGORITHMS IN THREAT DETECTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 75000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;</p>\n<div>\n<div>\n<div><span>The main outcome of this project was the development of a suite of mathematical tools for studying random graphs and, more generally, random matrices. Such objects arise in many applications in science and engineering. As a running example, consider a model of a social network among a group of people. The nodes in this network are individuals, while the edges in the network encode friendships between individuals. We often represent this network as an adjacency matrix, and it is the input to many algorithms for network analysis. In practice, we are often concerned with how small fluctuations in the adjacency matrix affects the outputs of downstream network analysis algorithms. A prominent class of such algorithms are spectral algorithms, which extract certain properties of the network encoded in the eigenvalues and eigenvectors of the adjacency matrix. Our suite of mathematical tools allows practitioners to derive bounds on the sensitivity of the eigenvalues and eigenvectors of adjacency matrices to small fluctuations in the entries of the matrix. This allows practitioners to guarantee the robustness of the outputs of downstream network analysis algorithms. To the best of our knowledge, our bounds are the sharpest available general bounds for the eigenvalues and eigenvectors of random matrices. In the accompanying figure, we plot the magnitude of changes in the eigenvectors of an adjacency matrix versus the size of changes of perturbations to its entries. We see that the bound provided by our theory is a sharp bound for the magnitude of the actual changes in the eigenvectors. This was a collaborative research project, and our collaborators leveraged this suite of tools to develop algorithms for studying time-varying networks.</span></div>\n</div>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/16/2022<br>\n\t\t\t\t\tModified by: Yuekai&nbsp;Sun</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1830247/1830247_10566771_1645060567163_twoboundsV2-1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1830247/1830247_10566771_1645060567163_twoboundsV2-1--rgov-800width.jpg\" title=\"Eigenvector error versus sample size\"><img src=\"/por/images/Reports/POR/2022/1830247/1830247_10566771_1645060567163_twoboundsV2-1--rgov-66x44.jpg\" alt=\"Eigenvector error versus sample size\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This plot shows the magnitude of changes in the eigenvectors of an adjacency matrix versus the size of changes of perturbations to its entries.</div>\n<div class=\"imageCredit\">Anil Damle, Yuekai Sun</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yuekai&nbsp;Sun</div>\n<div class=\"imageTitle\">Eigenvector error versus sample size</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \n\n\nThe main outcome of this project was the development of a suite of mathematical tools for studying random graphs and, more generally, random matrices. Such objects arise in many applications in science and engineering. As a running example, consider a model of a social network among a group of people. The nodes in this network are individuals, while the edges in the network encode friendships between individuals. We often represent this network as an adjacency matrix, and it is the input to many algorithms for network analysis. In practice, we are often concerned with how small fluctuations in the adjacency matrix affects the outputs of downstream network analysis algorithms. A prominent class of such algorithms are spectral algorithms, which extract certain properties of the network encoded in the eigenvalues and eigenvectors of the adjacency matrix. Our suite of mathematical tools allows practitioners to derive bounds on the sensitivity of the eigenvalues and eigenvectors of adjacency matrices to small fluctuations in the entries of the matrix. This allows practitioners to guarantee the robustness of the outputs of downstream network analysis algorithms. To the best of our knowledge, our bounds are the sharpest available general bounds for the eigenvalues and eigenvectors of random matrices. In the accompanying figure, we plot the magnitude of changes in the eigenvectors of an adjacency matrix versus the size of changes of perturbations to its entries. We see that the bound provided by our theory is a sharp bound for the magnitude of the actual changes in the eigenvectors. This was a collaborative research project, and our collaborators leveraged this suite of tools to develop algorithms for studying time-varying networks.\n\n\n\n\t\t\t\t\tLast Modified: 02/16/2022\n\n\t\t\t\t\tSubmitted by: Yuekai Sun"
 }
}