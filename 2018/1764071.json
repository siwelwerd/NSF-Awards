{
 "awd_id": "1764071",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Medium: Collaborative Research: Inverse Anatomical Modeling of the Face for Orthognathic Surgery",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922533",
 "po_email": "hshen@nsf.gov",
 "po_sign_block_name": "Han-Wei Shen",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 889173.0,
 "awd_amount": 889173.0,
 "awd_min_amd_letter_date": "2018-07-26",
 "awd_max_amd_letter_date": "2021-05-05",
 "awd_abstract_narration": "The face is the center of an individual's sense of identity and self-esteem, and plays a crucial role in interpersonal relationships. The current state of the art approaches computational modeling of human faces from two distinct angles. Computer graphics models feature high visual realism, as seen in the movies.  Whereas biomechanics focuses on physical realism, modeling the face as a sophisticated mechanical system that obeys the laws of physics. This project will bridge the gap between these two viewpoints and construct models of the face that offer both visual and physical realism. This is of the utmost importance in applications such as surgical prediction. Close to five percent of the population of the United States has a dentofacial anomaly that may require jaw surgery, which can have a profound effect on the appearance of the face. Virtually every patient asks, \"How will I look after the treatment?\" Even though this is an important and well-studied problem, there are currently no methods capable of predicting post-operative changes in facial expressions. By combining both visual and physical realism, this research will create the first system that can provide a natural, 3D visual answer to the patient's question by displaying a photorealistic facial animation after a simulated surgical procedure. Additional broad impact will derive from project outcomes because the new numerical techniques for the efficient simulation of biomaterials will provide a reusable foundation that can be leveraged for computational modeling of a variety of engineering materials that exhibit pronounced heterogeneity and anisotropy. The anatomical modeling framework developed in this work will also serve as a launchpad for future inquiry of interest to medical science (modeling of soft-tissue surgery, exploration of aging or pathology in the mechanics of facial expression, etc.).\r\n\r\nTo these ends, the project will create algorithms for the automated development of accurate patient-specific models of facial anatomy capable of representing realistic behavior of soft tissues, including the formation of facial expressions. The research aims at challenges which require coordinated efforts across various disciplines, including computer graphics, computer vision, biomechanics and craniofacial surgery. Novel computer vision methods will leverage information from 3D imaging (MRI/CT) to capture details of in-vivo human face deformations. The acquired data will serve as input to inverse finite element solvers, which will compute the unknown mechanical parameters of person-specific soft tissues, accounting for pre-strain and muscle activation units. This data-centric approach is a departure from established model-building methodologies, and has the potential to make a transformative impact on the anatomical modeling field. Furthermore, although the clinical application of orthognathic surgery is used as the motivation and key benchmark for the work, the algorithmic innovations produced in this activity transcend the specific scope of this task and deliver broader utility in the fields of visual computing and computational dynamics. Physics-based models of shape and deformation of elastic objects will be incorporated into visual acquisition systems as structural priors, enhancing the robustness and accuracy of the data collection.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cem",
   "pi_last_name": "Yuksel",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cem Yuksel",
   "pi_email_addr": "cem@cs.utah.edu",
   "nsf_id": "000636940",
   "pi_start_date": "2021-05-05",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Ladislav",
   "pi_last_name": "Kavan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ladislav Kavan",
   "pi_email_addr": "ladislav.kavan@gmail.com",
   "nsf_id": "000645156",
   "pi_start_date": "2018-07-26",
   "pi_end_date": "2021-05-05"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Srikumar",
   "pi_last_name": "Ramalingam",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Srikumar Ramalingam",
   "pi_email_addr": "srikumar.ramalingam@gmail.com",
   "nsf_id": "000735227",
   "pi_start_date": "2018-07-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jesse",
   "pi_last_name": "Goldstein",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jesse Goldstein",
   "pi_email_addr": "jag217@pitt.edu",
   "nsf_id": "000758863",
   "pi_start_date": "2018-07-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "50 South Central Campus Dr",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841129205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 889173.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aimed to study algorithms and fill technological gaps for automated development of accurate patient-specific models of facial anatomy which are capable of representing realistic behavior of soft tissues, including the formation of facial expressions. Thus, it targeted computational methods for capturing detailed 3D human body forms, extracting body pose and deformation data for machine learning, and physics simulations of deformable solids.</p>\r\n<p>Several new technologies have been developed as a part of this project. These include methods for acquiring 3D scans, capturing detailed human motion with a new kind of capture suit that is able to track subtle motions like breathing, muscle contracts, and flesh deformations, and a machine learning method for learning a small set of parameters from a training set of example poses of an active deformable object. In addition, a new method for compressing neural networks that preserves underlying functionality, a new method for 3D human shape and pose recovery from a single image, and a tractable heuristic for pruning excess parameters of neural networks were developed. Furthermore, an efficient computational method for solving polynomial equations, a computationally robust technique for handling self-intersections of deformable objects in physics-based simulations, and a new method for general physics-based simulations that can deliver improved computational performance and accuracy were developed.</p>\r\n<p>These new technologies were described in detail in scientific papers, their results were presented at scientific conferences, and open-source projects have been released to disseminate the information. Many of the technologies developed as a part of this project allow widespread uses beyond the scope of this project: the compression and pruning techniques for machine learning can be applied in various domains that employ neural networks, the capturing techniques can be used for extracting detailed human body motion, and the computational methods for polynomials and physics-based simulations can be used in various scientific domains for improving computational performance and accuracy.</p><br>\n<p>\n Last Modified: 12/29/2024<br>\nModified by: Cem&nbsp;Yuksel</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project aimed to study algorithms and fill technological gaps for automated development of accurate patient-specific models of facial anatomy which are capable of representing realistic behavior of soft tissues, including the formation of facial expressions. Thus, it targeted computational methods for capturing detailed 3D human body forms, extracting body pose and deformation data for machine learning, and physics simulations of deformable solids.\r\n\n\nSeveral new technologies have been developed as a part of this project. These include methods for acquiring 3D scans, capturing detailed human motion with a new kind of capture suit that is able to track subtle motions like breathing, muscle contracts, and flesh deformations, and a machine learning method for learning a small set of parameters from a training set of example poses of an active deformable object. In addition, a new method for compressing neural networks that preserves underlying functionality, a new method for 3D human shape and pose recovery from a single image, and a tractable heuristic for pruning excess parameters of neural networks were developed. Furthermore, an efficient computational method for solving polynomial equations, a computationally robust technique for handling self-intersections of deformable objects in physics-based simulations, and a new method for general physics-based simulations that can deliver improved computational performance and accuracy were developed.\r\n\n\nThese new technologies were described in detail in scientific papers, their results were presented at scientific conferences, and open-source projects have been released to disseminate the information. Many of the technologies developed as a part of this project allow widespread uses beyond the scope of this project: the compression and pruning techniques for machine learning can be applied in various domains that employ neural networks, the capturing techniques can be used for extracting detailed human body motion, and the computational methods for polynomials and physics-based simulations can be used in various scientific domains for improving computational performance and accuracy.\t\t\t\t\tLast Modified: 12/29/2024\n\n\t\t\t\t\tSubmitted by: CemYuksel\n"
 }
}