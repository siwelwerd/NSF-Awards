{
 "awd_id": "1832811",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Machine Learning-Based Approaches Toward Combatting Abusive Behavior in Online Communities",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Bainbridge",
 "awd_eff_date": "2017-08-16",
 "awd_exp_date": "2023-01-31",
 "tot_intn_awd_amt": 482075.0,
 "awd_amount": 482075.0,
 "awd_min_amd_letter_date": "2018-06-18",
 "awd_max_amd_letter_date": "2020-04-20",
 "awd_abstract_narration": "This research aims to computationally model abusive online behavior to build tools that help counter it, with the goal of making the Internet a more welcoming place.  Since its earliest days, flaming, trolling, harassment and abuse have plagued the Internet. This project will lay bare the structure of online abuse over many types of online conversations, a major step forward for the study of computer-mediated communication. This will result from modeling abuse with statistical machine learning algorithms as a function of theoretically inspired, sociolinguistic variables, and will entail new technical and methodological advances. This work will enable a transformative new class of automated and semi-automated applications that depend on computationally generated abuse predictions. The education and outreach plan is deeply tied to the research activities, and focuses on scaling-up the research's broader impacts.  A public application programming interface (API) will enable developers and online community managers around the world to integrate into their own sites the defenses against abuse developed by this research.\r\n\r\nThe work will consist of two major phases. In the first, the research will develop a deep understanding of abusive online behavior via statistical machine learning techniques. Specifically, the work will appropriate theories from social science and linguistics to inform the creation of features for robust statistical machine learning algorithms to predict abuse. These proposed abuse models will enable a brand new, transformative class of mixed-initiative artifacts capable of intervening in social media and online communities. In the second phase, this project will explore this newly enabled class of artifacts by building, deploying and evaluating sociotechnical tools for combatting abuse. Specifically, it will explore two classes of tools that use the abuse predictions: shields and moderator tools. The first, shields, will proactively block inbound abuse from reaching people. The second class of tools, moderator tools, will flag and triage abuse for community moderators.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Gilbert",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eric Gilbert",
   "pi_email_addr": "eegg@umich.edu",
   "nsf_id": "000573758",
   "pi_start_date": "2018-06-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091274",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 13217.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 111118.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 139482.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 95764.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 122494.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Abusive behavior presents a deep threat to today's Internet.  This project aimed to make significant advances on this problem using a  novel technical approach--with the long-term goal of making online  communities more welcoming places. In the project's first phase, we  developed a deep understanding of abusive online behavior via statistical  machine learning techniques. In the project's second phase, we used models to build, deploy and evaluate anti-abuse tools.<br /><br />In the first phase, we published a number of key papers studying abusive behavior on the internet via statistical and technical approaches. The papers led to significant intellectual and broader impact. The papers have become central in the social computing field, and also led to imapct on internet technologies for societal good. For example, this project substantially affected design and policy at Reddit, Twitter, Twitch, and Facebook, among others.<br /><br />In the second phase, we achiveved intellectual and broader impact by building systems: specifically, two new computational systems to prevent and deal with abusive behavior online. The first, Crossmod, is a new sociotechnical moderation system that  makes  decisions using cross-community learning--an approach that  leverages a  large corpus of previous moderator decisions via an ensemble  of  classifiers. Crossmod was deployed and evaluated on Reddit in a community of 10M people. The second, Sig, is an extensible Chrome framework  that computes and visualizes \"synthesized social signals.\" After a  formative study, we deployed and evaluated Sig on Twitter,  targeting two well-known problems on social media: toxic accounts and  misinformation.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/04/2023<br>\n\t\t\t\t\tModified by: Eric&nbsp;Gilbert</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1832811/1832811_10410420_1688494660747_crossmod--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1832811/1832811_10410420_1688494660747_crossmod--rgov-800width.jpg\" title=\"Crossmod, our tool for Reddit mods\"><img src=\"/por/images/Reports/POR/2023/1832811/1832811_10410420_1688494660747_crossmod--rgov-66x44.jpg\" alt=\"Crossmod, our tool for Reddit mods\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Crosssmod streams every comment written in a community, and applies models learned from other communities\ufffd mod decisions. Crossmod was deployed in a subreddit with 10m members.</div>\n<div class=\"imageCredit\">Eric Gilbert</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Eric&nbsp;Gilbert</div>\n<div class=\"imageTitle\">Crossmod, our tool for Reddit mods</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1832811/1832811_10410420_1688494568081_s3-3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1832811/1832811_10410420_1688494568081_s3-3--rgov-800width.jpg\" title=\"llustration of synthesized social signals\"><img src=\"/por/images/Reports/POR/2023/1832811/1832811_10410420_1688494568081_s3-3--rgov-66x44.jpg\" alt=\"llustration of synthesized social signals\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">@bob\ufffds account historyflows into algorithms to create signals that are rendered in the profile.</div>\n<div class=\"imageCredit\">Eric Gilbert</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Eric&nbsp;Gilbert</div>\n<div class=\"imageTitle\">llustration of synthesized social signals</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1832811/1832811_10410420_1688494738805_ct-timeseries--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1832811/1832811_10410420_1688494738805_ct-timeseries--rgov-800width.jpg\" title=\"Time series representing hate speech in a racist subreddit\"><img src=\"/por/images/Reports/POR/2023/1832811/1832811_10410420_1688494738805_ct-timeseries--rgov-66x44.jpg\" alt=\"Time series representing hate speech in a racist subreddit\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Time series representing hate speech in a racist subreddit that was banned by Reddit, at time=0 on the x-axis. We studied the ban via causal inference methods---finding that the ban worked for Reddit. This work led to the ban or quarantine of many hate groups across platforms.</div>\n<div class=\"imageCredit\">Eric Gilbert</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Eric&nbsp;Gilbert</div>\n<div class=\"imageTitle\">Time series representing hate speech in a racist subreddit</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nAbusive behavior presents a deep threat to today's Internet.  This project aimed to make significant advances on this problem using a  novel technical approach--with the long-term goal of making online  communities more welcoming places. In the project's first phase, we  developed a deep understanding of abusive online behavior via statistical  machine learning techniques. In the project's second phase, we used models to build, deploy and evaluate anti-abuse tools.\n\nIn the first phase, we published a number of key papers studying abusive behavior on the internet via statistical and technical approaches. The papers led to significant intellectual and broader impact. The papers have become central in the social computing field, and also led to imapct on internet technologies for societal good. For example, this project substantially affected design and policy at Reddit, Twitter, Twitch, and Facebook, among others.\n\nIn the second phase, we achiveved intellectual and broader impact by building systems: specifically, two new computational systems to prevent and deal with abusive behavior online. The first, Crossmod, is a new sociotechnical moderation system that  makes  decisions using cross-community learning--an approach that  leverages a  large corpus of previous moderator decisions via an ensemble  of  classifiers. Crossmod was deployed and evaluated on Reddit in a community of 10M people. The second, Sig, is an extensible Chrome framework  that computes and visualizes \"synthesized social signals.\" After a  formative study, we deployed and evaluated Sig on Twitter,  targeting two well-known problems on social media: toxic accounts and  misinformation.\n\n\t\t\t\t\tLast Modified: 07/04/2023\n\n\t\t\t\t\tSubmitted by: Eric Gilbert"
 }
}