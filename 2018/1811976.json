{
 "awd_id": "1811976",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Uncertainty Quantification in High-Dimensional Structured Regression Problems",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2018-06-01",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 179997.0,
 "awd_amount": 179997.0,
 "awd_min_amd_letter_date": "2018-05-11",
 "awd_max_amd_letter_date": "2018-05-11",
 "awd_abstract_narration": "Structured, high-dimensional regression problems is a current topic of major interest due recent applications in modern scientific fields. Such structured, high-dimensional data arise naturally in bioinformatics, signal processing, quantum mechanics and networks.  Handling this massive high-dimensional data is impossible unless the underlying parameter of interest has additional structure.  Examples of additional structure that arise in applications include sparsity or low-rankness and powerful estimation methods have been developed in the last decade to successfully recover the true parameter whenever such additional structure is present in the data. However, identifying whether such additional structure is present in the data is more challenging than the corresponding estimation problem. New phase transitions are seen and novel methods are needed. The goal of the current project is to develop statistical methodology aimed at identifying the existence of such additional structure, and to study the theoretical phase transitions of the problem.\r\n\r\n\r\nThe high-dimensional setting considers the situation where the number of unknown parameters outnumber the number of samples. Estimation procedures have successfully solves this high-dimensional setting under additional structural assumption on the problem: Common structural assumptions include sparsity or low-rankness, where the unknown parameter possesses some low-dimensional property.  In the so called sparse or low-rank regime, consistent estimation of the unknown parameter becomes possible even in the high-dimensional \"large p small n\" settings.  The proposed research will focus on uncertainty quantification in such structured, high-dimensional settings. Methodologies will be developed to construct confidence sets and confidence bands tailored to structured high-dimensional problems. A major challenge that will be studied both theoretically and empirically is identifying whether the sparse or low-rank regime actually occurs, or equivalently the construction of adaptive confidence sets. An adaptive confidence set captures the true parameter with high probability, and its size shrinks optimally with respect to the unknown sparsity or low-rankness of the problem.  The optimality properties of adaptive confidence sets will be studied, as well as the corresponding phase transitions with respect to the problem parameters.  The proposed research is motivated by and will be directly applicable to scientific fields where high-dimensional data arise.  An adaptive confidence set has major applications in practice as it provides a certificate that the sparse or low-rank regime actually occurs, and such certificate asserts that the high-dimensional estimation and inferential methods used in practice are actually accurate. Identifying whether the sparse regime actually occurs has direct applications in bioinformatics and signal processing, while identifying whether the low-rank regime occurs has direct applications in quantum tomography and matrix completion.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Pierre",
   "pi_last_name": "Bellec",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Pierre C Bellec",
   "pi_email_addr": "pcb71@stat.rutgers.edu",
   "nsf_id": "000734408",
   "pi_start_date": "2018-05-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University, SAS-Statistics",
  "perf_str_addr": "110 Frelinghuysen Road",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 179997.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The two decades have witnessed the arrival of large datasets, both by their sample size (how many individual subjects are present) and by their dimension (how many covariates or characterics of each individual is reported).&nbsp; Researchers and practitioners have tackled these problems with novel algorithms and estimators, often under structural assumption on the dataset such as sparsity or low-rankness (few covariates summarize major trends in the dataset).<br /><br />The award aimed at developing novel statistical methodologies to assess whether the structural assumption, be it sparsity or low-rankness, actually occurs. An alternate view of this problem is to assess from the data the performance of certain estimators specialised to tackle such sparse or low-rank datasets, as the estimated performance would reveal whether the assumed sparse or low-rank regime actually occurs.<br /><br />Researchers working on the award have produced significant contributions for this problem in different statistical settings:<br /><br />(a) In problems naturally endowed with a shape constraint, confidence sets were developed, and shown to be provably optimal, to capture the order of magnitude of the performance of natural estimators that leverage such shape constraint.<br /><br />(b) In problems naturally endowed with a sparse of low-rank structure, estimation of both the in-sample error (performance measured on the obseved individuals) and the out-of-sample error (performance measured on yet-to-be observed individuals), for estimators commonly used for such high-dimensional datasets.<br /><br />(c) Parameter tuning: In most problems of a high-dimensional nature, the estimators used in practice rely on the choice of tuning parameters, and different tuning parameters lead to variable performance. The criteria to estimate the in- and out-of-sample error mentioned previously were proved to enjoy theoretical guarantees that make them successful in parameter tuning.&nbsp; These guarantees make possible the automatic choice of tuning parameters that best reflect the underlying sparse or low-rank nature of the dataset.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/29/2022<br>\n\t\t\t\t\tModified by: Pierre&nbsp;Bellec</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe two decades have witnessed the arrival of large datasets, both by their sample size (how many individual subjects are present) and by their dimension (how many covariates or characterics of each individual is reported).  Researchers and practitioners have tackled these problems with novel algorithms and estimators, often under structural assumption on the dataset such as sparsity or low-rankness (few covariates summarize major trends in the dataset).\n\nThe award aimed at developing novel statistical methodologies to assess whether the structural assumption, be it sparsity or low-rankness, actually occurs. An alternate view of this problem is to assess from the data the performance of certain estimators specialised to tackle such sparse or low-rank datasets, as the estimated performance would reveal whether the assumed sparse or low-rank regime actually occurs.\n\nResearchers working on the award have produced significant contributions for this problem in different statistical settings:\n\n(a) In problems naturally endowed with a shape constraint, confidence sets were developed, and shown to be provably optimal, to capture the order of magnitude of the performance of natural estimators that leverage such shape constraint.\n\n(b) In problems naturally endowed with a sparse of low-rank structure, estimation of both the in-sample error (performance measured on the obseved individuals) and the out-of-sample error (performance measured on yet-to-be observed individuals), for estimators commonly used for such high-dimensional datasets.\n\n(c) Parameter tuning: In most problems of a high-dimensional nature, the estimators used in practice rely on the choice of tuning parameters, and different tuning parameters lead to variable performance. The criteria to estimate the in- and out-of-sample error mentioned previously were proved to enjoy theoretical guarantees that make them successful in parameter tuning.  These guarantees make possible the automatic choice of tuning parameters that best reflect the underlying sparse or low-rank nature of the dataset.\n\n\t\t\t\t\tLast Modified: 09/29/2022\n\n\t\t\t\t\tSubmitted by: Pierre Bellec"
 }
}