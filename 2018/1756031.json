{
 "awd_id": "1756031",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: CHS: Enabling Safe and Adaptive Robot-aided Gait Training through Biomechanical Characterization and Learning from Demonstration",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 191000.0,
 "awd_min_amd_letter_date": "2018-03-16",
 "awd_max_amd_letter_date": "2022-04-05",
 "awd_abstract_narration": "The unprecedented growth in the elderly population is generating a high demand for gait rehabilitation due to age-related neurological diseases.  To address this urgent need various assistive robots have been developed to improve gait training outcomes, and impedance control (controlling the force of resistance to external motions that are produced by the environment) has been widely employed in these robots to ensure safe human-robot interaction.  However, it is difficult to personalize the virtual impedance for such robots due to the complex nature of human neurological and musculoskeletal dynamics.  On the other hand, a physical therapist can provide adaptive assistance to a patient at the correct moment in a gait cycle based on real-time sensory feedback and clinical experience.  Inspired by this observation, one could imagine designing an assistive robot control system by learning from therapists' demonstrations, but such a purely data-driven approach could lead to significantly degraded performance with new gait patterns, which creates safety risks for users. This research will develop a hybrid assistive robot control approach, which integrates model-based impedance control with machine learning from therapists' behaviors so that the resultant robot assistance is safe yet adaptive.  Project outcomes will include a novel algorithm framework for physical human-robot collaboration that exhibits both performance guarantees due to the model-based control and intelligent adaptation resulting from robot learning.  The new technology will have a wide range of applications in many other safety-critical human-robot collaboration scenarios, including collaborative manufacturing, (semi) autonomous driving, and service robots.  The broader impacts of the work will be further enhanced by tight integration of the research with educational activities including new modules in existing robotics classes, research opportunities for undergraduate students from underrepresented groups, and internships for local high-school students.\r\n  \r\nThe scientific contribution of the work will include: 1) integration of heterogeneous wearable sensor data to build the robot learning model from therapists' demonstrations, and human knee impedance characterization to build the robot impedance control model; 2) a robot planning approach based on a fusion of learning from demonstration and impedance control, with the weights determined by the degree of confidence in the robot learning model; and 3) automatic requests for new demonstration data and incorporation of subject feedback to refine both the robot learning and impedance control models.  Performance of the approach will be assessed in biomechanical simulations, in lab tests with healthy subjects, and in a pilot study with stroke and Parkinson's disease patients.  It is envisioned that project outcomes will make assistive robots highly intelligent so that a therapist could work with multiple patients simultaneously and even remotely, which could significantly reduce both the therapists' labor intensity and cost of rehabilitation training for patients.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Wenlong",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wenlong Zhang",
   "pi_email_addr": "Wenlong.Zhang@asu.edu",
   "nsf_id": "000706436",
   "pi_start_date": "2018-03-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852816011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 175000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, the research team (\"we\" thereafter) studied model-based and learning-based control of robots for safe and efficient physical human-robot interaction, with a focus on knee exoskeleton for gait rehabilitation. The model-based control leveraged the offline biomechanical characterization and online human state estimation to personalize the robot assistance. The controller also learned from human demonstrations to understand a therapist's assistive strategies and adjust the robot assistance.</p>\n<p>For model-based control, we developed an automatic impedance tuning (AIT) approach for the knee exoskeleton. In this approach, we collected kinetic and kinematic data from each human subject without the exoskeleton to identify their knee&rsquo;s quasi-stiffness and damping in different tasks. With the exoskeleton, we applied an impedance controller where its virtual impedance was automatically adjusted based on the offline identified human impedance parameters and online probabilistic estimation of the current gait phase. The AIT controller was applied on the knee exoskeleton to assist stance phase of healthy subjects during walking. Experimental results showed lower muscle activities, higher cadence, and improved dynamic gait stability compared to the finite state machine controller.</p>\n<p>For the learning-based control, we collaborated with our clinical partner to collect data from therapists and patients. A custom-designed soft sensor was employed to measure the interaction kinetics and kinematics between the physical therapist and patient during gait therapy sessions. This sensor system collected the interaction force, patient's lower-limb joint kinematics and ground reaction forces. We used the data collected from two therapists and four stroke patients to characterize a therapist's strategies in response to unique gait behaviors found within a patient's gait. Analysis showed that knee extension and weight-shifting were the most important features that shaped a therapist's assistance strategies. These key features were then integrated into a virtual impedance model to predict the therapist's assistive torque. This model benefited from a goal-directed attractor and representative features that allowed intuitive characterization and estimation of a therapist's assistance strategies using Gaussian mixture regression. The resulting model can accurately capture high-level therapist behaviors over the course of a full training session while still explaining some of the more nuanced behaviors contained in individual strides.</p>\n<p>This project generated positive societal impacts for future wearable robots to personalize the assistance by incorporating a human user&rsquo;s biomechanics and learning from demonstrations given by medical professionals. The developed model-based and learning-based control can be applied to a wide range of human-robot interaction tasks, such as collaborative manufacturing, robotic surgery, and autonomous driving. The research outcomes of this project have been disseminated widely through various conference workshops, open-lab outreach events, and media coverage. All the publications resulting from this project have been made available in the NSF Public Access Repository. This project also created new resources for control and robotics curriculum. Four Ph.D. students, two M.S. thesis students, and eight undergraduate students were involved in this project, including four students trained as part of the Research Experience for Undergraduates (REU) program.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/10/2024<br>\nModified by: Wenlong&nbsp;Zhang</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn this project, the research team (\"we\" thereafter) studied model-based and learning-based control of robots for safe and efficient physical human-robot interaction, with a focus on knee exoskeleton for gait rehabilitation. The model-based control leveraged the offline biomechanical characterization and online human state estimation to personalize the robot assistance. The controller also learned from human demonstrations to understand a therapist's assistive strategies and adjust the robot assistance.\n\n\nFor model-based control, we developed an automatic impedance tuning (AIT) approach for the knee exoskeleton. In this approach, we collected kinetic and kinematic data from each human subject without the exoskeleton to identify their knees quasi-stiffness and damping in different tasks. With the exoskeleton, we applied an impedance controller where its virtual impedance was automatically adjusted based on the offline identified human impedance parameters and online probabilistic estimation of the current gait phase. The AIT controller was applied on the knee exoskeleton to assist stance phase of healthy subjects during walking. Experimental results showed lower muscle activities, higher cadence, and improved dynamic gait stability compared to the finite state machine controller.\n\n\nFor the learning-based control, we collaborated with our clinical partner to collect data from therapists and patients. A custom-designed soft sensor was employed to measure the interaction kinetics and kinematics between the physical therapist and patient during gait therapy sessions. This sensor system collected the interaction force, patient's lower-limb joint kinematics and ground reaction forces. We used the data collected from two therapists and four stroke patients to characterize a therapist's strategies in response to unique gait behaviors found within a patient's gait. Analysis showed that knee extension and weight-shifting were the most important features that shaped a therapist's assistance strategies. These key features were then integrated into a virtual impedance model to predict the therapist's assistive torque. This model benefited from a goal-directed attractor and representative features that allowed intuitive characterization and estimation of a therapist's assistance strategies using Gaussian mixture regression. The resulting model can accurately capture high-level therapist behaviors over the course of a full training session while still explaining some of the more nuanced behaviors contained in individual strides.\n\n\nThis project generated positive societal impacts for future wearable robots to personalize the assistance by incorporating a human users biomechanics and learning from demonstrations given by medical professionals. The developed model-based and learning-based control can be applied to a wide range of human-robot interaction tasks, such as collaborative manufacturing, robotic surgery, and autonomous driving. The research outcomes of this project have been disseminated widely through various conference workshops, open-lab outreach events, and media coverage. All the publications resulting from this project have been made available in the NSF Public Access Repository. This project also created new resources for control and robotics curriculum. Four Ph.D. students, two M.S. thesis students, and eight undergraduate students were involved in this project, including four students trained as part of the Research Experience for Undergraduates (REU) program.\n\n\n\t\t\t\t\tLast Modified: 03/10/2024\n\n\t\t\t\t\tSubmitted by: WenlongZhang\n"
 }
}