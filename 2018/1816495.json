{
 "awd_id": "1816495",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: Towards Robust Moving Target Defense: A Game Theoretic and Learning Approach",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 244189.0,
 "awd_amount": 260105.0,
 "awd_min_amd_letter_date": "2018-08-13",
 "awd_max_amd_letter_date": "2020-02-24",
 "awd_abstract_narration": "Malicious attacks are constantly evolving to inflict even more damage on the nation's infrastructure systems, corporate information technology (IT) systems, and our digital lives. A fundamental obstacle to achieving effective defense is information asymmetry, through which, under current static and passive defense schemes, the attacker has essentially limitless time to observe and learn about the defender, while the defender knows very little about the attacker. A promising approach to reverse information asymmetry is Moving Target Defense (MTD), whereby the defender dynamically updates system configurations to impede the attacker's learning process. Although MTD has been successfully applied in various domains, existing solutions typically assume an attacker with fixed capabilities and behavioral patterns that are known to the defender. The overarching goal of this project is to develop the foundations for the design and analysis of robust MTD mechanisms that can provide a guaranteed level of protection in the face of unknown and adaptive attacks. The proposed research contributes to the emerging field of the science of security via a cross-disciplinary approach that combines techniques from cybersecurity, game theory, and machine learning. The investigator will disseminate the research findings to industry to help impact real systems. Elements from this research are to be incorporated into new courses on cybersecurity at Tulane University. The project engages underrepresented students and K-12 students and provides rich research experience to undergraduate students.\r\n\r\nDeveloping robust MTD faces three major challenges induced by (1) the coupling of system dynamics and incentives; (2) the hidden behavior of stealthy attacks; (3) the necessity of coordinating multiple defenders in large systems. To tackle these challenges, the investigator will focus on three interrelated thrust areas. In the first thrust, a dynamic two-timescale MTD game that captures a variety of attack patterns and feedback structures is designed and techniques for handling games with large state spaces are investigated. In the second thrust, reinforcement learning-based MTD policies for thwarting unknown attacks are studied. The focus is on developing approximately optimal solutions with low complexity that can effectively exploit the delayed and noisy feedback during the game. In the third thrust, the MTD game and learning framework are extended to incorporate multiple attackers and defenders, and information sharing and mediation schemes for enabling coordinated MTD are investigated. The developed game models and defense strategies are validated via testbed implementations and trace-driven simulations. The research outcomes are expected to provide new insights and novel mechanisms that will significantly advance our understanding of how strategic thinking and learning can help achieve more adaptive cyber defense against advanced attacks.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zizhan",
   "pi_last_name": "Zheng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zizhan Zheng",
   "pi_email_addr": "zzheng3@tulane.edu",
   "nsf_id": "000749618",
   "pi_start_date": "2018-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Tulane University",
  "inst_street_address": "6823 SAINT CHARLES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "NEW ORLEANS",
  "inst_state_code": "LA",
  "inst_state_name": "Louisiana",
  "inst_phone_num": "5048654000",
  "inst_zip_code": "701185665",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "LA01",
  "org_lgl_bus_name": "THE ADMINISTRATORS OF TULANE EDUCATIONAL FUND",
  "org_prnt_uei_num": "XNY5ULPU8EN6",
  "org_uei_num": "XNY5ULPU8EN6"
 },
 "perf_inst": {
  "perf_inst_name": "Tulane University",
  "perf_str_addr": "6823 St Charles Avenue",
  "perf_city_name": "New Orleans",
  "perf_st_code": "LA",
  "perf_st_name": "Louisiana",
  "perf_zip_code": "701185698",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "LA01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "065Z",
   "pgm_ref_txt": "Human factors for security research"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 244189.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 15916.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Intellectual Merit:</strong></p>\n<p>To reverse the information asymmetry commonly found in cybersecurity, a promising approach is Moving Target Defense (MTD), where the defender constantly updates the system configuration to make it less predictable to the attacker. This high-level idea has been applied to multiple domains, from networks and runtime environments to software and data. However, prior work mainly focused on empirical studies of domain-specific dynamic configuration techniques, with very little research on quantifying the effectiveness of MTD. On the other hand, classic security game models for one-shot defenses, such as Bayesian Stackelberg Game (BSG) and its variants, are unsuitable for sequential MTD. To bridge the gap, this project developed the first MTD solution that is both robust and adaptive using tools from game theory, reinforcement learning, and meta-learning. The work goes beyond MTD and sheds light on the fundamental principles of robust sequential decision-making in the presence of unknown and strategic adversaries.&nbsp;</p>\n<p>Developing robust defenses in cybersecurity faces two important challenges. First, an advanced attacker can adapt its behavior dynamically in a secret way. Second, the type of an attacker (including its physical, cognitive, and computational abilities and constraints) is often uncertain or unknown to the defender a priori.</p>\n<p>To tackle the first challenge, the project modeled the sequential attacker-defender interactions in MTD as a two-player stochastic game and formulated the defender's problem as finding the Stackelberg equilibrium of the game with the defender as the leader and the attacker as the follower. This model departs from standard asymmetric stochastic games by incorporating both spatial (how to update system configuration) and temporal (when to update system configuration) decisions. Further, it was shown that when the attacker always learns the true system configuration at the end of each round (a worst-case scenario for the defender), the defender's problem can be reduced to solving a single-agent semi-Markov decision process (MDP). Built upon this key observation, a value iteration algorithm was developed to solve the problem, which was validated using real-world attack data obtained from the National Vulnerability Database (NVD).&nbsp;</p>\n<p>To address the second challenge, a typical approach is to consider a Bayesian setting by assuming that the defender has access to a distribution of attack types. However, targeting the average case leads to a suboptimal solution even when there is no distribution shift between when the MTD policy is trained and when it is applied. Alternatively, one can consider a fully online approach where the defender assumes zero prior knowledge of the attacker and continuously adapts its policy using feedback obtained on the fly. However, it requires collecting a large number of samples covering diverse attack scenarios, which is infeasible in most security-critical domains. The project developed a novel two-stage meta-reinforcement learning-based MTD framework to overcome both limitations.&nbsp;<span>By first training a meta-policy over a (possibly inaccurate) distribution of potential attack types and behavioral patterns and then adapting it online against the actual attack, this approach requires less prior knowledge while being able to adapt to unseen attacks&nbsp;quickly.</span></p>\n<p><strong>Broader Impacts:&nbsp;</strong></p>\n<p>The project has provided unique training experiences to two graduate students, four REU students (including one female student), and one high school student. They were exposed to diverse topics on cybersecurity, game theory, reinforcement learning, and meta-learning and obtained much-needed analytical and empirical skills at proper levels. The findings of the project were incorporated into the newly developed reinforcement learning course at Tulane and provided topics for student presentations and term projects. T<span>he outcomes of the project were disseminated via talks and posters at workshops and conferences.</span>&nbsp;All the code and datasets from the project are publicly available on GitHub.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/04/2022<br>\n\t\t\t\t\tModified by: Zizhan&nbsp;Zheng</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIntellectual Merit:\n\nTo reverse the information asymmetry commonly found in cybersecurity, a promising approach is Moving Target Defense (MTD), where the defender constantly updates the system configuration to make it less predictable to the attacker. This high-level idea has been applied to multiple domains, from networks and runtime environments to software and data. However, prior work mainly focused on empirical studies of domain-specific dynamic configuration techniques, with very little research on quantifying the effectiveness of MTD. On the other hand, classic security game models for one-shot defenses, such as Bayesian Stackelberg Game (BSG) and its variants, are unsuitable for sequential MTD. To bridge the gap, this project developed the first MTD solution that is both robust and adaptive using tools from game theory, reinforcement learning, and meta-learning. The work goes beyond MTD and sheds light on the fundamental principles of robust sequential decision-making in the presence of unknown and strategic adversaries. \n\nDeveloping robust defenses in cybersecurity faces two important challenges. First, an advanced attacker can adapt its behavior dynamically in a secret way. Second, the type of an attacker (including its physical, cognitive, and computational abilities and constraints) is often uncertain or unknown to the defender a priori.\n\nTo tackle the first challenge, the project modeled the sequential attacker-defender interactions in MTD as a two-player stochastic game and formulated the defender's problem as finding the Stackelberg equilibrium of the game with the defender as the leader and the attacker as the follower. This model departs from standard asymmetric stochastic games by incorporating both spatial (how to update system configuration) and temporal (when to update system configuration) decisions. Further, it was shown that when the attacker always learns the true system configuration at the end of each round (a worst-case scenario for the defender), the defender's problem can be reduced to solving a single-agent semi-Markov decision process (MDP). Built upon this key observation, a value iteration algorithm was developed to solve the problem, which was validated using real-world attack data obtained from the National Vulnerability Database (NVD). \n\nTo address the second challenge, a typical approach is to consider a Bayesian setting by assuming that the defender has access to a distribution of attack types. However, targeting the average case leads to a suboptimal solution even when there is no distribution shift between when the MTD policy is trained and when it is applied. Alternatively, one can consider a fully online approach where the defender assumes zero prior knowledge of the attacker and continuously adapts its policy using feedback obtained on the fly. However, it requires collecting a large number of samples covering diverse attack scenarios, which is infeasible in most security-critical domains. The project developed a novel two-stage meta-reinforcement learning-based MTD framework to overcome both limitations. By first training a meta-policy over a (possibly inaccurate) distribution of potential attack types and behavioral patterns and then adapting it online against the actual attack, this approach requires less prior knowledge while being able to adapt to unseen attacks quickly.\n\nBroader Impacts: \n\nThe project has provided unique training experiences to two graduate students, four REU students (including one female student), and one high school student. They were exposed to diverse topics on cybersecurity, game theory, reinforcement learning, and meta-learning and obtained much-needed analytical and empirical skills at proper levels. The findings of the project were incorporated into the newly developed reinforcement learning course at Tulane and provided topics for student presentations and term projects. The outcomes of the project were disseminated via talks and posters at workshops and conferences. All the code and datasets from the project are publicly available on GitHub. \n\n\t\t\t\t\tLast Modified: 12/04/2022\n\n\t\t\t\t\tSubmitted by: Zizhan Zheng"
 }
}