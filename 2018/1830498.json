{
 "awd_id": "1830498",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: FND: Rapid Operator Awareness via Mobile Robotics (ROAMR), Customizable Human Safety using Mobile and Wearable Co-Robots",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 489964.0,
 "awd_amount": 497946.0,
 "awd_min_amd_letter_date": "2018-08-08",
 "awd_max_amd_letter_date": "2020-04-22",
 "awd_abstract_narration": "Human operators in construction sites, disaster zones, and other rapidly changing environments risk injury from collisions with moving machinery and falling components.  The risk of collisions can reduce human performance by forcing them to work very slowly and keep track of multiple situations simultaneously.  This project aims to explore how teams of co-robots can improve human safety by detecting potential collisions that the humans may not be aware of, alerting them to the danger, and helping them move away from the danger.  The project will develop methods for communicating potential threats to human operators via a human-worn exoskeleton, which can also assist the people in moving to safety as rapidly as possible.\r\n\r\nThe approach will augment human awareness, performance, and safety in unstructured, outdoor, and varying environments, where dynamic objects pose threats of imminent, unnoticed collision.  Specifically, the project will develop a new safety architecture where mobile systems rapidly detect collisions and plan a safe response, a wearable exoskeleton communicates the situation to the human, and the exoskeleton helps to achieve a safe response.  The project will focus on 1) developing and characterizing a physical \"language\" for wearable co-robots to provide situational awareness based on visual displays, audio guidance, vibro-tactile sensations, and physical signals from the exoskeleton actuators; 2) investigating how wearable sensing can infer human motions using machine learning to predict human behavior by accounting for automated obstacle avoidance plans, human motion strategies, and measurements of joint kinematics, ground contact forces, and muscle activation; and 3) researching how a wearable exoskeleton can accelerate safe responses in real-time by using targeted exoskeleton torques to enhance propulsive forces and increase speed of response by reducing the apparent inertia of the limbs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anirban",
   "pi_last_name": "Mazumdar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anirban Mazumdar",
   "pi_email_addr": "anirban.mazumdar@me.gatech.edu",
   "nsf_id": "000770618",
   "pi_start_date": "2018-08-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Aaron",
   "pi_last_name": "Young",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Aaron J Young",
   "pi_email_addr": "aaron.young@me.gatech.edu",
   "nsf_id": "000718385",
   "pi_start_date": "2018-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Ave NW",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320420",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 489964.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 7982.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The objective of this project was to identify and quantify how wearable and mobile co-robots can improve human performance.&nbsp; This project aimed to use robots and robotic methodologies to augment human awareness, performance, and safety in unstructured, outdoor, and varying environments, where dynamic objects pose threats of imminent, unnoticed collision. Specifically, the project developed a new safety architecture where mobile systems rapidly detect collisions and plan a safe response, a wearable exoskeleton communicates the situation to the human, and the exoskeleton helps augment the human to achieve a safe response. The project focused on three core goals.</p>\n<p>Goal 1 focused on developing and characterizing a physical \"language\" for wearable co-robots to improve situational awareness through motion planning-based suggestions. These suggestions were communicated through visual displays, audio cues, vibro-tactile sensations, and physical signals from the exoskeleton actuators.</p>\n<p>Goal 2 investigated how wearable sensing can infer human motions using machine learning to predict human behavior by accounting for human motion strategies, and measurements of joint kinematics, ground contact forces, and muscle activation.</p>\n<p>Goal 3 examined how a wearable exoskeleton can accelerate safe responses in real-time by using targeted exoskeleton torques to enhance propulsive forces, increase speed of response and assist the operator in moving in the safest direction.&nbsp;</p>\n<p>&nbsp;Intellectual Merit (IM): This project achieved intellectual merit by creating new methods and data in the following ways.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IM1) Quantifying how humans react to situational awareness cues in the presence of simulated threats and visual distractions.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IM2) Developing human-centered motion planning algorithms and quantifying their performance using virtual reality studies.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IM3) Creating and quantifying a new human-robot teaming methodology that uses a wearable co-robot to guide humans through dangerous environments using variable device impedance.&nbsp;</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IM4) Quantifying an intention recognition algorithm for rapidly determining human escape behaviors.</p>\n<p>Broader Impacts (BI): This project contributed to broad impacts in three ways: 1) Research accomplishments with the potential for societal impact, 2) Dissemination of research results to society, 3) Training a diverse range of robotics engineers 4) Using research results to introduce high school students to robotics.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; BI1) The research results pertaining to human-centered algorithms and wearable co-robots have the potential to increase human safety.&nbsp; The techniques may become increasingly relevant as mobile robots and wearable systems become more prevalent.&nbsp;</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; BI2) To date, the research from this project has produced four journal publications.&nbsp; The research results have also been presented at several conferences.&nbsp;</p>\n<p>BI3) This project was the core part of 2 MS theses and 1 Ph.D. thesis.&nbsp; The project results will also be a large part of an additional Ph.D. thesis.&nbsp; This project has also helped support undergraduate research for credit and for pay.&nbsp; This project also supported an REU summer student who went on to join a top robotics Ph.D. program.</p>\n<p>BI4) This project supported a high school robotics summer camp.&nbsp; The latest event in 2023 involved 30 high school students.&nbsp; The camp utilized VR research from the project to teach students about using technology to improve human performance.&nbsp; The summer camp also introduced students to mobile robotics.&nbsp; This camp has the potential to impact the robotics community and workforce by enhancing knowledge and interest in the field.</p><br>\n<p>\n Last Modified: 01/26/2024<br>\nModified by: Anirban&nbsp;Mazumdar</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1830498/1830498_10567732_1706227993495_Human_Centered_Planning--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/1830498/1830498_10567732_1706227993495_Human_Centered_Planning--rgov-800width.jpg\" title=\"Human-centered motion planning.\"><img src=\"/por/images/Reports/POR/2024/1830498/1830498_10567732_1706227993495_Human_Centered_Planning--rgov-66x44.jpg\" alt=\"Human-centered motion planning.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Simulated mobile co-robots were shown to provide humans with situational awareness, and motion plans were used to inform safe human behaviors.</div>\n<div class=\"imageCredit\">Georgia Tech DART and EPIC Labs</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Anirban&nbsp;Mazumdar\n<div class=\"imageTitle\">Human-centered motion planning.</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1830498/1830498_10567732_1706226727994_ExoNavigation--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/1830498/1830498_10567732_1706226727994_ExoNavigation--rgov-800width.jpg\" title=\"Wearable Co-Robot Navigation\"><img src=\"/por/images/Reports/POR/2024/1830498/1830498_10567732_1706226727994_ExoNavigation--rgov-66x44.jpg\" alt=\"Wearable Co-Robot Navigation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A wearable co-robot can enhance human performance by communicating motion plans through varying physical interactions.</div>\n<div class=\"imageCredit\">Georgia Tech DART and EPIC Labs</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Anirban&nbsp;Mazumdar\n<div class=\"imageTitle\">Wearable Co-Robot Navigation</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe objective of this project was to identify and quantify how wearable and mobile co-robots can improve human performance. This project aimed to use robots and robotic methodologies to augment human awareness, performance, and safety in unstructured, outdoor, and varying environments, where dynamic objects pose threats of imminent, unnoticed collision. Specifically, the project developed a new safety architecture where mobile systems rapidly detect collisions and plan a safe response, a wearable exoskeleton communicates the situation to the human, and the exoskeleton helps augment the human to achieve a safe response. The project focused on three core goals.\n\n\nGoal 1 focused on developing and characterizing a physical \"language\" for wearable co-robots to improve situational awareness through motion planning-based suggestions. These suggestions were communicated through visual displays, audio cues, vibro-tactile sensations, and physical signals from the exoskeleton actuators.\n\n\nGoal 2 investigated how wearable sensing can infer human motions using machine learning to predict human behavior by accounting for human motion strategies, and measurements of joint kinematics, ground contact forces, and muscle activation.\n\n\nGoal 3 examined how a wearable exoskeleton can accelerate safe responses in real-time by using targeted exoskeleton torques to enhance propulsive forces, increase speed of response and assist the operator in moving in the safest direction.\n\n\nIntellectual Merit (IM): This project achieved intellectual merit by creating new methods and data in the following ways.\n\n\n IM1) Quantifying how humans react to situational awareness cues in the presence of simulated threats and visual distractions.\n\n\n IM2) Developing human-centered motion planning algorithms and quantifying their performance using virtual reality studies.\n\n\n IM3) Creating and quantifying a new human-robot teaming methodology that uses a wearable co-robot to guide humans through dangerous environments using variable device impedance.\n\n\n IM4) Quantifying an intention recognition algorithm for rapidly determining human escape behaviors.\n\n\nBroader Impacts (BI): This project contributed to broad impacts in three ways: 1) Research accomplishments with the potential for societal impact, 2) Dissemination of research results to society, 3) Training a diverse range of robotics engineers 4) Using research results to introduce high school students to robotics.\n\n\n BI1) The research results pertaining to human-centered algorithms and wearable co-robots have the potential to increase human safety. The techniques may become increasingly relevant as mobile robots and wearable systems become more prevalent.\n\n\n BI2) To date, the research from this project has produced four journal publications. The research results have also been presented at several conferences.\n\n\nBI3) This project was the core part of 2 MS theses and 1 Ph.D. thesis. The project results will also be a large part of an additional Ph.D. thesis. This project has also helped support undergraduate research for credit and for pay. This project also supported an REU summer student who went on to join a top robotics Ph.D. program.\n\n\nBI4) This project supported a high school robotics summer camp. The latest event in 2023 involved 30 high school students. The camp utilized VR research from the project to teach students about using technology to improve human performance. The summer camp also introduced students to mobile robotics. This camp has the potential to impact the robotics community and workforce by enhancing knowledge and interest in the field.\t\t\t\t\tLast Modified: 01/26/2024\n\n\t\t\t\t\tSubmitted by: AnirbanMazumdar\n"
 }
}