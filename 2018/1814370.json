{
 "awd_id": "1814370",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CDS&E: Reconstruction of universe's initial conditions with galaxies",
 "cfda_num": "47.049",
 "org_code": "03020000",
 "po_phone": "7032924905",
 "po_email": "nsharp@nsf.gov",
 "po_sign_block_name": "Nigel Sharp",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 520827.0,
 "awd_amount": 520827.0,
 "awd_min_amd_letter_date": "2018-08-26",
 "awd_max_amd_letter_date": "2018-08-26",
 "awd_abstract_narration": "The universe evolved from a simple state where matter was almost uniformly distributed in space. In the present day the matter is very strongly clustered into galaxies, clusters of galaxies, and even larger structures. This evolution is governed by gravity and by additional processes such as formation of stars in galaxies. There is enormous amount of information about the universe origins, content, and future evolution hidden in the galaxy distribution.  This information is difficult to access in the present-day form because it has been scrambled by gravity and other processes. The goal of this project is to use simulations to reconstruct the initial conditions of our universe. When these are evolved in time with known laws of physics, they give rise to our visible universe. Ultimately this will allow a movie to made of our universe starting from the initial smooth distribution and ending in images of actual galaxies such as the Hubble Deep Field. A major benefit of this method is that information about our universe can be simply extracted from the initial conditions.  More broadly, an aim of this project is to impact other communities where similar problems arise such as machine learning via the methods and tools developed   \r\n\r\nThe primary goal of this project is to develop and apply a new set of theoretical and computational instruments, including new statistical methods, algorithms, and computational implementations, to optimally reconstruct the initial condition of our universe from the spatial distribution of galaxies. Galaxies are a primary probe of the large scale structure of the universe that are or will be observed by surveys such as the Sloan Digital Sky Survey (SDSS), the Dark Energy Survey (DES), the Large Synoptic Survey Telescope (LSST), the Dark Energy Spectroscopic Instrument (DESI), EUCLID and the Wide Field Infrared Survey Telescope (WFIRST). This project will extend a hierarchical probabilistic generative model developed by the PI's team to the modelling of galaxies. The framework attempts to solve an exact probabilistic model for the initial conditions that is conditioned on the data with a process that combines elements of numerical optimization in high dimensions and analytic marginalization to find the best solution and their covariance matrix. The proposed research will apply this method to galaxy redshift catalogs and their surrounding dark matter information inferred from weak lensing. The method will be developed using realistic simulations of both dark matter and of galaxies populated in the dark matter and hydro simulations, before being applied to real data.  This research will explore best methods to achieve fast convergence in the search for local and global minimum and aims to have an impact more broadly to research areas (e.g. neural networks) outside astronomy in the tools developed for non-convex optimization in very high dimensions.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "AST",
 "org_div_long_name": "Division Of Astronomical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Uros",
   "pi_last_name": "Seljak",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Uros Seljak",
   "pi_email_addr": "useljak@berkeley.edu",
   "nsf_id": "000103999",
   "pi_start_date": "2018-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "The Regents of the University of California",
  "perf_str_addr": "359 Campbell",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947203411",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "121700",
   "pgm_ele_name": "EXTRAGALACTIC ASTRON & COSMOLO"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1206",
   "pgm_ref_txt": "THEORETICAL & COMPUTATIONAL ASTROPHYSICS"
  },
  {
   "pgm_ref_code": "8084",
   "pgm_ref_txt": "CDS&E"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 520827.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The purpose of this grant was&nbsp; to d<span>evelop methods to learn the likelihood of cosmology data as a function of cosmological parameters, and extract best possible cosmological information from it. This means to extract cosmological information from the Large Scale Structure data in the best possible way, prove this is the case, and provide correct covariance matrix or full posterior of the extracted cosmological parameters.&nbsp;<span>As a result of this proposal we can evaluate the optimal cosmology information content in Large Scale Structure data and compare them to other methods. Due to computational limitations this is for now limited to small surveys.&nbsp;</span></span></p>\n<p><span><span><span>The methods developed are unprecedented in that they attempt to extract information in cosmological observations optimally. As such every other method can and should be compared against this standard.&nbsp;</span><span>Some of the methods developed may have an impact on other disciplines. For example, CosmicRIM is an optimization method in very high dimensions that uses BFGS or ADAM proposals and learns a better proposal using Machine Learning method. This could be used for high dimensional optimization in many different domains.&nbsp;</span></span></span></p>\n<p><span><span><span>PI has been the main developer of a course in Bayesian Statistics and Machine Learning for Physical Sciences at UC Berkeley since 2017. The course is popular among both undergraduate and graduate students and has a large enrollment. Many of the research topics of this grant are also covered as homeworks or projects in the course. The course covers all the basics of Machine Learning, regression and classification, principal component and independent component analysis, density estimation, supervised and unsupervised learning, etc.&nbsp;</span><br /></span></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/21/2023<br>\n\t\t\t\t\tModified by: Uros&nbsp;Seljak</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe purpose of this grant was  to develop methods to learn the likelihood of cosmology data as a function of cosmological parameters, and extract best possible cosmological information from it. This means to extract cosmological information from the Large Scale Structure data in the best possible way, prove this is the case, and provide correct covariance matrix or full posterior of the extracted cosmological parameters. As a result of this proposal we can evaluate the optimal cosmology information content in Large Scale Structure data and compare them to other methods. Due to computational limitations this is for now limited to small surveys. \n\nThe methods developed are unprecedented in that they attempt to extract information in cosmological observations optimally. As such every other method can and should be compared against this standard. Some of the methods developed may have an impact on other disciplines. For example, CosmicRIM is an optimization method in very high dimensions that uses BFGS or ADAM proposals and learns a better proposal using Machine Learning method. This could be used for high dimensional optimization in many different domains. \n\nPI has been the main developer of a course in Bayesian Statistics and Machine Learning for Physical Sciences at UC Berkeley since 2017. The course is popular among both undergraduate and graduate students and has a large enrollment. Many of the research topics of this grant are also covered as homeworks or projects in the course. The course covers all the basics of Machine Learning, regression and classification, principal component and independent component analysis, density estimation, supervised and unsupervised learning, etc. \n\n\n\t\t\t\t\tLast Modified: 01/21/2023\n\n\t\t\t\t\tSubmitted by: Uros Seljak"
 }
}