{
 "awd_id": "1821833",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Multimodal Affective Pedagogical Agents for Different Types of Learners",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925126",
 "po_email": "abaylor@nsf.gov",
 "po_sign_block_name": "Amy Baylor",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2018-07-23",
 "awd_max_amd_letter_date": "2018-07-23",
 "awd_abstract_narration": "While most research on embodied pedagogical agents (adaptive virtual agents that guide and mentor learners) explores cognitive features, this project investigates the role of agent affect/emotion. This project examines how the agent's affective state (e.g., seeming interested or concerned) impacts different types of students (e.g., differing by knowledge level, gender, underrepresented group status, interest in STEM fields, and personality profile) when learning from online statistics lessons. The project integrates several areas of research: a) computer graphics research on life-like and believable representation of emotion in embodied agents, b) advanced methods and techniques from artificial intelligence and computer vision for real-time recognition of emotions, c) cognitive psychology research on learning from affective agents, and d) education research on the efficacy of affective agents for improving student learning of STEM concepts. Through experimental research the project will advance the state of the art in agent design and implementation by integrating findings on effective emotion regulation with algorithms that support life-like expression of emotions in embodied agents. \r\n\r\nTo investigate the multimodal design features of affective pedagogical agents, the project has two main objectives: (1) research and develop novel algorithms for emotion recognition and for life-like emotion representation in embodied animated agents, and (2) develop an empirically grounded research base to guide the design of affective pedagogical agents for different types of learners. In one series of experiments the project will determine evidence-based design principles to guide the development of agents that demonstrate emotion/affect, including which kinds of affective states are most effective for which kinds of learners. In a second series of experiments, the project will implement a web-camera system to detect the emotional state of the learner (e.g., confused, interested, content, or bored), adapting the emotional state displayed by the agent in response. Of interest is whether students learn the statistics lesson better when the pedagogical agent is sensitive to the learner's emotional state than when it is not. In addition to its scientific merit, the project will develop and make available a toolkit of affective animated pedagogical agents that adapt to learner characteristics to be used by learners of all ages, for education and training in a variety of subject matters and settings.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Mayer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Richard Mayer",
   "pi_email_addr": "mayer@psych.ucsb.edu",
   "nsf_id": "000274561",
   "pi_start_date": "2018-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Barbara",
  "inst_street_address": "3227 CHEADLE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA BARBARA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8058934188",
  "inst_zip_code": "931060001",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SANTA BARBARA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G9QBQDH39DF4"
 },
 "perf_inst": {
  "perf_inst_name": "University of California- Santa Barbara",
  "perf_str_addr": "Psychological and Brain Sciences",
  "perf_city_name": "Santa Barbara",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "931069660",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project examined how to design on-screen animated characters who help students learn new STEM content, such as a new statistical concept.&nbsp; In particular, the project focused on how to create on-screen animated characters who display human-like emotions that are conducive to learning.&nbsp; The project created video lessons on STEM topics in which the instructor taught exactly the same material but displayed either positive emotion (e.g., happy or content) or negative emotion (e.g., frustrated or bored) through their voice, gestures, facial expression, body stance, and eye gaze. &nbsp;Across a series of experiments, college students were able to recognize the emotion being displayed by the instructor, tended to feel the same emotion themselves, felt a stronger social connection with positive instructors than negative instructors, and in some cases performed better on tests covering what was taught.&nbsp; The results were similar for videos of real human instructors and for virtual instructors created through animation to convey the same gesture and voice as the human instructor.&nbsp; Overall, positive instructors produced better learning processes and outcomes than negative instructors, even when they were animated characters. The project shows that learning from online lessons involving onscreen animated instructors depends not only what information is presented but also the social and affective cues displayed by the animated instructor.&nbsp;</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2022<br>\n\t\t\t\t\tModified by: Richard&nbsp;Mayer</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project examined how to design on-screen animated characters who help students learn new STEM content, such as a new statistical concept.  In particular, the project focused on how to create on-screen animated characters who display human-like emotions that are conducive to learning.  The project created video lessons on STEM topics in which the instructor taught exactly the same material but displayed either positive emotion (e.g., happy or content) or negative emotion (e.g., frustrated or bored) through their voice, gestures, facial expression, body stance, and eye gaze.  Across a series of experiments, college students were able to recognize the emotion being displayed by the instructor, tended to feel the same emotion themselves, felt a stronger social connection with positive instructors than negative instructors, and in some cases performed better on tests covering what was taught.  The results were similar for videos of real human instructors and for virtual instructors created through animation to convey the same gesture and voice as the human instructor.  Overall, positive instructors produced better learning processes and outcomes than negative instructors, even when they were animated characters. The project shows that learning from online lessons involving onscreen animated instructors depends not only what information is presented but also the social and affective cues displayed by the animated instructor. \n\n\t\t\t\t\tLast Modified: 11/30/2022\n\n\t\t\t\t\tSubmitted by: Richard Mayer"
 }
}