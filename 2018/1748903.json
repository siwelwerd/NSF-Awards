{
 "awd_id": "1748903",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Global Digital Privacy Innovation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924420",
 "po_email": "cbethel@nsf.gov",
 "po_sign_block_name": "Cindy Bethel",
 "awd_eff_date": "2018-06-01",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 548450.0,
 "awd_amount": 548450.0,
 "awd_min_amd_letter_date": "2018-03-30",
 "awd_max_amd_letter_date": "2022-05-18",
 "awd_abstract_narration": "This research will drive global digital privacy innovation by developing a fundamental understanding of the privacy challenges faced by novice technology users in non-Western contexts and designing empirically-driven and theoretically-grounded technical interventions that transform existing knowledge of human-centered privacy. Although access to digital technologies offers great potential benefits, it also puts people at risk of digital security and privacy attacks, and novice technology users in non-Western contexts may lack the technological knowledge and experience required to understand the risks and protect their personal data. Moreover, a growing amount of evidence suggests that (1) these populations face a range of new and interesting digital privacy challenges that result from their different social, cultural, and religious contexts, and (2) the current design of mobile devices, and the privacy mechanisms that come with them, are primarily driven by Western values and do not adequately address the needs of these diverse populations.  This research will help US corporations to be more competitive in the global technology market and enable developers to create privacy-preserving systems that respect different cultures and values.\r\n\r\nThe research agenda has four primary aims. The first will collect empirical data through qualitative fieldwork that provides a deep understanding of people's usage patterns, privacy concerns, and priorities. The second will analyze this empirical data to generate privacy threat models and assess the relevance, severity, and likelihood of different privacy attacks. The third will use participatory design, software development, and field deployments to create and evaluate novel technical interventions that improve digital privacy by supporting alternative device usage models and increasing people's understanding and awareness of privacy threats. Finally, the fourth will integrate these research efforts into a broad set of education and outreach activities that amplify the project's impact on academia, industry, and society.  This human-centered research advances existing knowledge of digital privacy and technology use in non-Western societies, which will benefit researchers in computer science, security and privacy, human-computer interaction (HCI), global development, and others. The specific intellectual contributions include: (1) developing a fundamental understanding of the privacy challenges faced by novice users in non-Western contexts, (2) identifying new threat models and analyzing the privacy attack landscape, (3) designing and evaluating novel technical interventions that improve digital privacy for diverse populations, and (4) contributing empirical data and design ideas that initiate a new field of innovation at the intersection of HCI for development and computer security and privacy.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nicola",
   "pi_last_name": "Dell",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Nicola L Dell",
   "pi_email_addr": "nixdell@cornell.edu",
   "nsf_id": "000703800",
   "pi_start_date": "2018-03-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell Tech",
  "perf_str_addr": "2 West Loop Road",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100440052",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NY12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 102706.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 105419.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 111530.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 111209.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 117586.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This CAREER project aimed to </span><span>develop a fundamental </span><span>understanding of the digital privacy challenges faced by diverse communities in non-Western contexts and designed and tested novel interventions to improve digital privacy in these contexts. This project resulted in 11 conference and journal articles published in top human-computer interaction venues, constituting a body of new knowledge that dramatically expands the field&rsquo;s understanding of digital privacy and explainable AI in non-Western contexts and with low-literate communities.</span></p>\n<p><span>In one key line of research, we investigated how the concept of &ldquo;personal computing&rdquo; often does not fit the usage patterns of technology users in the Global South, where collective societal values and fewer economic resources often mean that several people share a single device. Moreover, social norms in these settings often demand that women share their personal data (e.g., messages, call history, browsing history) with their husbands and families, who monitor their activities. To explore how to enable personal privacy on devices that are shared by multiple users, we built an intervention that employs a &lsquo;tiered&rsquo; privacy model. Using this model, a person creates a &lsquo;shared&rsquo; account that contains data they are willing to share and that is assigned a password that will be shared. Simultaneously, they create a separate &lsquo;secret&rsquo; account that contains data they prefer to keep secret and that uses a password they do not share with anyone. We deployed our intervention with users in Bangladesh, showcasing how it might improve personal privacy within these communities.</span></p>\n<p><span>In another line of research, we empirically demonstrated how the concept of privacy differs across cultures and showed how social media platforms catalyze change in norms of information regulation. We discussed how the localization of transnational technology platforms provides a key site in which to investigate changing cultural ideas about privacy, and to discover misalignments between different expectations for information flow. We also explored ways that insufficient localization efforts by transnational technology companies puts some of the most marginalized users at disproportionate information disclosure risk when using new Internet tools and offered pragmatic suggestions for how such companies could improve privacy tools for users who are far (geographically or culturally) from where the tools are designed.</span></p>\n<p><span>In other research contributions we explored the digital privacy risks and challenges faced by small business owners in India, by refugees in Lebanon, Jordan, and Uganda, and by village officials in Cambodia. We further systematized existing knowledge of how online hate and harassment are being enacted across the globe, distilling key tactics for preventing and mitigating digital harms in a wide range of contexts and countries.</span></p>\n<p><span>In the later years of this project, emerging technological advances made it increasingly clear that artificial intelligence (AI) technologies are transforming notions of digital privacy, trust, and safety, raising an urgent need to consider how we might design privacy-preserving AI systems that are appropriate for people who will be expected to effectively operate these systems, but who currently possess very limited AI literacy. Thus, in the final stages of the award, we conducted qualitative research studies to characterize frontline workers knowledge, perceptions, and understandings of AI and the benefits and challenges that they anticipate as AI applications are integrated into their workflows, including security and privacy challenges, and questions concerning trust and safety. We discovered an alarming lack of AI literacy and potential for dangerous overreliance on AI. Thus, we conducted research that sought to expand current understanding of explainable AI to contexts in the Global South by designing explainable AI (XAI) interfaces that are more understandable to workers in these settings. In this project, we (1) identified how workers interpreted AI predictions and the associated explanations, (2) unpacked the benefits and pitfalls they perceived of the explanations, and (3) detailed how different design elements of the explanations impacted their AI understanding. Our findings demonstrate that while workers struggled to understand the AI explanations, they nevertheless expressed a strong preference for the explanations to be integrated into AI-driven tools and perceived several benefits of the explanations, such as helping CHWs learn new skills and improved patient trust in AI tools and in CHWs.</span></p>\n<p><span>The award provided numerous opportunities for training students to conduct community-engaged research, write and present research papers, and develop as intellectuals in computing. In particular, the award supported the PhD research of several women from underrepresented backgrounds in computing who have since gone on to successful careers in academia. These are excellent outcomes and examples of how engaging young researchers in societally impactful work can help to broaden the participation of women and underrepresented minorities in computing research.</span></p><br>\n<p>\n Last Modified: 08/14/2024<br>\nModified by: Nicola&nbsp;L&nbsp;Dell</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis CAREER project aimed to develop a fundamental understanding of the digital privacy challenges faced by diverse communities in non-Western contexts and designed and tested novel interventions to improve digital privacy in these contexts. This project resulted in 11 conference and journal articles published in top human-computer interaction venues, constituting a body of new knowledge that dramatically expands the fields understanding of digital privacy and explainable AI in non-Western contexts and with low-literate communities.\n\n\nIn one key line of research, we investigated how the concept of personal computing often does not fit the usage patterns of technology users in the Global South, where collective societal values and fewer economic resources often mean that several people share a single device. Moreover, social norms in these settings often demand that women share their personal data (e.g., messages, call history, browsing history) with their husbands and families, who monitor their activities. To explore how to enable personal privacy on devices that are shared by multiple users, we built an intervention that employs a tiered privacy model. Using this model, a person creates a shared account that contains data they are willing to share and that is assigned a password that will be shared. Simultaneously, they create a separate secret account that contains data they prefer to keep secret and that uses a password they do not share with anyone. We deployed our intervention with users in Bangladesh, showcasing how it might improve personal privacy within these communities.\n\n\nIn another line of research, we empirically demonstrated how the concept of privacy differs across cultures and showed how social media platforms catalyze change in norms of information regulation. We discussed how the localization of transnational technology platforms provides a key site in which to investigate changing cultural ideas about privacy, and to discover misalignments between different expectations for information flow. We also explored ways that insufficient localization efforts by transnational technology companies puts some of the most marginalized users at disproportionate information disclosure risk when using new Internet tools and offered pragmatic suggestions for how such companies could improve privacy tools for users who are far (geographically or culturally) from where the tools are designed.\n\n\nIn other research contributions we explored the digital privacy risks and challenges faced by small business owners in India, by refugees in Lebanon, Jordan, and Uganda, and by village officials in Cambodia. We further systematized existing knowledge of how online hate and harassment are being enacted across the globe, distilling key tactics for preventing and mitigating digital harms in a wide range of contexts and countries.\n\n\nIn the later years of this project, emerging technological advances made it increasingly clear that artificial intelligence (AI) technologies are transforming notions of digital privacy, trust, and safety, raising an urgent need to consider how we might design privacy-preserving AI systems that are appropriate for people who will be expected to effectively operate these systems, but who currently possess very limited AI literacy. Thus, in the final stages of the award, we conducted qualitative research studies to characterize frontline workers knowledge, perceptions, and understandings of AI and the benefits and challenges that they anticipate as AI applications are integrated into their workflows, including security and privacy challenges, and questions concerning trust and safety. We discovered an alarming lack of AI literacy and potential for dangerous overreliance on AI. Thus, we conducted research that sought to expand current understanding of explainable AI to contexts in the Global South by designing explainable AI (XAI) interfaces that are more understandable to workers in these settings. In this project, we (1) identified how workers interpreted AI predictions and the associated explanations, (2) unpacked the benefits and pitfalls they perceived of the explanations, and (3) detailed how different design elements of the explanations impacted their AI understanding. Our findings demonstrate that while workers struggled to understand the AI explanations, they nevertheless expressed a strong preference for the explanations to be integrated into AI-driven tools and perceived several benefits of the explanations, such as helping CHWs learn new skills and improved patient trust in AI tools and in CHWs.\n\n\nThe award provided numerous opportunities for training students to conduct community-engaged research, write and present research papers, and develop as intellectuals in computing. In particular, the award supported the PhD research of several women from underrepresented backgrounds in computing who have since gone on to successful careers in academia. These are excellent outcomes and examples of how engaging young researchers in societally impactful work can help to broaden the participation of women and underrepresented minorities in computing research.\t\t\t\t\tLast Modified: 08/14/2024\n\n\t\t\t\t\tSubmitted by: NicolaLDell\n"
 }
}