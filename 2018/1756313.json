{
 "awd_id": "1756313",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Architecture and plasticity of auditory lexical representations in the human brain",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032924502",
 "po_email": "dkravitz@nsf.gov",
 "po_sign_block_name": "Dwight Kravitz",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 651953.0,
 "awd_amount": 651953.0,
 "awd_min_amd_letter_date": "2018-07-05",
 "awd_max_amd_letter_date": "2018-07-05",
 "awd_abstract_narration": "Considering the diversity and richness of languages spoken around the globe, speech perception is arguably one of the main achievements of the human brain. While there is now broad support among cognitive neuroscientists for the concept of a hierarchy of cortical areas subserving auditory and speech processing, there is substantial disagreement about the roles different brain areas play in speech recognition, how the speech system learns and represents spoken words, and how learning words through one sense (e.g., through reading) can allow the brain to recognize the same words through another sense (e.g., through hearing). With support from the National Science Foundation, we will use advanced functional magnetic resonance imaging (fMRI) to investigate these questions. Specifically, the project is designed to resolve a major ongoing controversy regarding how and where words are represented in the brain by, for the first time, applying fMRI techniques to this field that have been used successfully to answer related questions in the domain of written words. A second study will probe how the brain learns new spoken words and adds them to the auditory lexicon.  In the final set of studies, the project will break new ground in our understanding of how the auditory and visual systems are linked in reading, and how this interaction is enabled by cross-sensory learning. Understanding the neural bases of speech processing and cross-sensory learning of language are areas of great interest not only for basic science but also other areas ranging from education and language learning to engineering (by elucidating effective learning algorithms for deep multisensory hierarchies, e.g., for automatic speech recognition) as well as biomedical fields (by building a foundation to study a range of disorders, including dyslexia and language comprehension deficits). The research project will form an opportunity to train the next generation of scientists, at the graduate, undergraduate, and high school levels. \r\n\r\nIn more scientific detail, the overarching goal of the proposed project is to study the existence and plasticity of auditory lexica in the human brain, and to understand coupling of written and auditory speech representations that permit cross-modal transfer of lexical learning. The project has three Aims: Aim 1 addresses the current controversy regarding the existence and location of auditory word representations in the brain. Translating techniques we previously developed to identify a \"visual lexicon\" in the \"Visual Word Form Area\", we will use sensitive fMRI rapid adaptation (fMRI-RA) and other advanced fMRI techniques to test the hypothesis of a (receptive) auditory lexicon within an analogous \"Auditory Word Form Area\" in left anterior superior temporal cortex. At the same time, we will test whether another lexicon exists in motor-related speech areas of the auditory dorsal stream representing articulatory word forms that are automatically activated by speech perception via an \"inverse model\". Aim 2 is designed to probe the plasticity invoked by the addition of novel words to the auditory lexicon. Aim 3 studies the interaction of written language with the auditory system. Prior studies have shown that reading activates phonological representations in proficient readers, and that this phonological recoding is crucial for reading acquisition. We will test the novel hypothesis that written words cause widespread activation of the auditory system and that training on novel written words can drive word-selective rewiring in the auditory lexical system.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maximilian",
   "pi_last_name": "Riesenhuber",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maximilian Riesenhuber",
   "pi_email_addr": "mr287@georgetown.edu",
   "nsf_id": "000106418",
   "pi_start_date": "2018-07-05",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Josef",
   "pi_last_name": "Rauschecker",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Josef P Rauschecker",
   "pi_email_addr": "rauschej@georgetown.edu",
   "nsf_id": "000233003",
   "pi_start_date": "2018-07-05",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Xiong",
   "pi_last_name": "Jiang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiong Jiang",
   "pi_email_addr": "Xiong.Jiang@georgetown.edu",
   "nsf_id": "000755271",
   "pi_start_date": "2018-07-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgetown University",
  "inst_street_address": "MAIN CAMPUS",
  "inst_street_address_2": "",
  "inst_city_name": "WASHINGTON",
  "inst_state_code": "DC",
  "inst_state_name": "District of Columbia",
  "inst_phone_num": "2026250100",
  "inst_zip_code": "20057",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DC00",
  "org_lgl_bus_name": "GEORGETOWN UNIVERSITY",
  "org_prnt_uei_num": "TF2CMKY1HMX9",
  "org_uei_num": "TF2CMKY1HMX9"
 },
 "perf_inst": {
  "perf_inst_name": "Georgetown University",
  "perf_str_addr": "37th & O St NW",
  "perf_city_name": "Washington",
  "perf_st_code": "DC",
  "perf_st_name": "District of Columbia",
  "perf_zip_code": "200571789",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DC00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169900",
   "pgm_ele_name": "Cognitive Neuroscience"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1699",
   "pgm_ref_txt": "COGNEURO"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 651953.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Considering the diversity and richness of languages spoken around the globe, speech perception is arguably one of the main achievements of the human brain. Yet, there has been substantial disagreement about the roles different brain areas play in speech recognition, how the speech system learns to recognize spoken words, and how the brain systems for spoken and written words interact. The present project used advanced functional magnetic resonance imaging (fMRI) in human participants to answer these questions.</p>\n<p>The main result of the project was the demonstration of the existence of an \"auditory lexicon\" for spoken words in a brain area in front of primary auditory cortex, in the so-called \"auditory word form area\" (AWFA). This finding upended a century-old model that had posited the existence of an auditory lexicon in a different brain area, <em>behind</em> primary auditory cortex, so-called \"Wernicke's area\". Yet, that model did not fit well with many observations from patients with speech recognition deficits, such as stroke patients. Project results not only showed neural selectivity in the AWFA for familiar words, but also showed that learning new spoken words sharpened neural selectivity for these words in the AWFA -- adding them to the brain?s auditory dictionary, as it were. These results were particularly intriguing as they perfectly paralleled our earlier results (likewise obtained with NSF funding) that had demonstrated the existence of a lexicon for written words in the brain?s visual system, in the so-called \"visual word form area\" (VWFA). Thus, the project has provided a convergent understanding of how the brain recognizes and learns words in different sensory modalities. In addition, we showed that auditory and written lexica in the brain are coupled, causing the written word lexicon to also respond to spoken words, but not vice-versa. This is thought to provide a mechanism for the brain to learn to recognize written words guided by input from spoken word representations (e.g., when reading aloud). Finally, the project demonstrated the existence of a lexicon for spoken words also in the brain?s speech production system, providing a candidate for a pathway for how individuals can learn to speak words (to be investigated in a future study). &nbsp;</p>\n<p>These results are of great interest not only for basic science but also for areas ranging from education and language learning to engineering as well as biomedical fields (by building a foundation to study a range of disorders, including dyslexia and language comprehension deficits and their remediation). The research project also served to advance the scientific training of future scientists at a number of levels, contributing to the PhD theses of several graduate students and providing research opportunities for a number of undergraduate and even high school students.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/25/2023<br>\n\t\t\t\t\tModified by: Maximilian&nbsp;Riesenhuber</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nConsidering the diversity and richness of languages spoken around the globe, speech perception is arguably one of the main achievements of the human brain. Yet, there has been substantial disagreement about the roles different brain areas play in speech recognition, how the speech system learns to recognize spoken words, and how the brain systems for spoken and written words interact. The present project used advanced functional magnetic resonance imaging (fMRI) in human participants to answer these questions.\n\nThe main result of the project was the demonstration of the existence of an \"auditory lexicon\" for spoken words in a brain area in front of primary auditory cortex, in the so-called \"auditory word form area\" (AWFA). This finding upended a century-old model that had posited the existence of an auditory lexicon in a different brain area, behind primary auditory cortex, so-called \"Wernicke's area\". Yet, that model did not fit well with many observations from patients with speech recognition deficits, such as stroke patients. Project results not only showed neural selectivity in the AWFA for familiar words, but also showed that learning new spoken words sharpened neural selectivity for these words in the AWFA -- adding them to the brain?s auditory dictionary, as it were. These results were particularly intriguing as they perfectly paralleled our earlier results (likewise obtained with NSF funding) that had demonstrated the existence of a lexicon for written words in the brain?s visual system, in the so-called \"visual word form area\" (VWFA). Thus, the project has provided a convergent understanding of how the brain recognizes and learns words in different sensory modalities. In addition, we showed that auditory and written lexica in the brain are coupled, causing the written word lexicon to also respond to spoken words, but not vice-versa. This is thought to provide a mechanism for the brain to learn to recognize written words guided by input from spoken word representations (e.g., when reading aloud). Finally, the project demonstrated the existence of a lexicon for spoken words also in the brain?s speech production system, providing a candidate for a pathway for how individuals can learn to speak words (to be investigated in a future study).  \n\nThese results are of great interest not only for basic science but also for areas ranging from education and language learning to engineering as well as biomedical fields (by building a foundation to study a range of disorders, including dyslexia and language comprehension deficits and their remediation). The research project also served to advance the scientific training of future scientists at a number of levels, contributing to the PhD theses of several graduate students and providing research opportunities for a number of undergraduate and even high school students.\n\n \n\n\t\t\t\t\tLast Modified: 10/25/2023\n\n\t\t\t\t\tSubmitted by: Maximilian Riesenhuber"
 }
}