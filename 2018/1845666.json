{
 "awd_id": "1845666",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Robust Large-Scale Data Mining for Knowledge Discovery in Depression Thought Records",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 487880.0,
 "awd_amount": 487880.0,
 "awd_min_amd_letter_date": "2018-08-23",
 "awd_max_amd_letter_date": "2021-07-20",
 "awd_abstract_narration": "This project investigates new robust large-scale data mining and machine learning algorithms to solve critical computational challenges in mining massive depression thought records for cognitive behavior therapy. Depression is rapidly emerging as one of the major problems in our society and is also related to many other health conditions, such as stroke, diabetes, hypertension, HIV/AIDS, etc. Cognitive behavior therapy is the most extensively researched form of psychotherapy for depression, and the depression thought records from patients is the key component of cognitive behavior therapy. However, the process of reviewing and analyzing the depression thought records is extremely time consuming, which inhibits both clinical interviews and the training of new therapists. This project builds a novel data mining system to automatically discover knowledge from depression thought records for assisting therapists in selecting potential interventions and aiding new therapists in their development of cognitive behavior therapy skills. This project will facilitate the development of novel educational tools to enable new courses and enhance current courses. This project engages minority students and under-served populations in research activities to give them a better exposure to cutting-edge science research.\r\n \r\nTo effectively and efficiently analyze large-scale depression thought records, this project explores the following research tasks. First, the project develops a robust semi-supervised learning model to categorize logical thinking errors of depression thought records. Second, the project investigates a joint multi-task method to simultaneously recognize the categories of thinking errors and emotions of depression thought records. Third, new multi-label and multi-instance learning is studied for identifying coping activities. Fourth, to analyze the multi-language depression thought records, robust transfer learning methods are developed for cross-language knowledge transfer. Meanwhile, parallel computational algorithms are designed and applied for large-scale depression thought record data mining. These novel data mining algorithms are designed to solve large-scale applications and automate the depression thought record data mining, which holds great promise for smart health.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Heng",
   "pi_last_name": "Huang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Heng Huang",
   "pi_email_addr": "heng@umd.edu",
   "nsf_id": "000086248",
   "pi_start_date": "2018-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pittsburgh",
  "inst_street_address": "4200 FIFTH AVENUE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4126247400",
  "inst_zip_code": "152600001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "UNIVERSITY OF PITTSBURGH - OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "MKAGLD59JRL1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pittsburgh",
  "perf_str_addr": "123 University Place",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152132303",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 487880.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our research findings in computational algorithm design and depression thought data analysis are highly relevant to the interdisciplinary research of data mining and biomedical data science. The investigation of this project produces several important outcomes.</p>\n<p>&nbsp;</p>\n<p>1. We developed new semi-supervised learning models to categorize the logical thinking errors of depression thought records (DTRs) using both labeled and unlabeled DTR data. Semi-Supervised Support Vector Machine (S3VM) is a powerful semi-supervised learning model. However, the high computational cost and non-convexity severely impede the S3VM method in large-scale applications. We proposed a new incremental learning algorithm to scale up S3VM based on the path following technique in the framework of difference of convex programming. Our new algorithm based on the path-following technique can directly update the solution of S3VM to converge to a local minimum within one outer loop so that the efficient incremental learning can be achieved. Our new algorithm is the first efficient path following algorithm for a non-convex problem with local minimum convergence guarantee. Experimental results show our new method has excellent performance on thinking error categorizations.</p>\n<p>&nbsp;</p>\n<p>2. We designed new sparse shrunk additive models to identify the depression thought markers with investigating the feature interactions. We target to identify the informative markers/features from depression thought records, which can help us understand the behavior of depression people better. In existing feature selection models, the interactions between features are often ignored or just discussed under prior structure information. To address this challenging issue, we consider the problem of sparse additive models for high-dimensional nonparametric regression with the allowance of the flexible interactions between features. We designed new sparse shrunk additive models to explore the structure information among features. This method bridges sparse kernel regression and sparse feature selection. We conducted experiments to validate the superior performance of our proposed methods.</p>\n<p>&nbsp;</p>\n<p>3. We studied transferable deep neural networks to simultaneously predict the logical thinking errors and emotions using electronic depression thought records. We formulated the thinking error prediction and emotion recognition problems as a multi-task learning problem. We proposed a new semi-supervised domain-adaptation method to integrate heterogeneous depression thought record data for thinking errors and emotions prediction with considering the prediction shares the same mechanism across different domains. We used a transferable batch normalization approach for deep neural networks to avoid problems related to domain shift in the data distributions. The altered network, referred to as transferable variational auto-encoder, avoids the need to introduce extra hyper-parameters or learnable parameters and is trainable end-to-end. The experimental results on DTRs show that our new algorithm has better performance than related methods.</p>\n<p>&nbsp;</p>\n<p>4. We introduced new dropout algorithm for deep learning model to improve the depression thought record data classification. Dropout is a popular technique to train large-scale deep neural networks to alleviate the overfitting problem. We explored it from a new perspective to provide new insight into this line of research. We disentangled the forward and backward pass of dropout and found that these two passes need different levels of noise to improve the generalization performance of deep neural networks. Based on this observation, we proposed the augmented dropout, which employs different dropping strategies in the forward and backward pass, to improve the standard dropout. Experimental results verified the effectiveness of our new method.</p>\n<p>&nbsp;</p>\n<p>5. We proposed a new deep large-scale multi-task learning network to classify the logical thinking errors of DTRs. We consider different thinking errors have interrelations, which could potentially help the prediction of each other, and formulate the thinking error prediction problem as a multi-task learning problem. We proposed a novel deep multi-task learning algorithm with automatically learning the interrelations among prediction tasks, i.e. thinking errors, and utilizing such information to enhance the prediction. In particular, we employed a multi-layer sub-network with low dimensional latent variables for learning the interrelations among thinking errors, and imposed a seamless and easy to implement regularization on deep models. The experimental results confirm the effectiveness of our new algorithm.</p>\n<p>&nbsp;</p>\n<p>6. We released the data mining software tools at the project website. To disseminate the project results, the investigators and students presented more than thirty full-length papers related to this project in peer-reviewed conference proceedings and journals.</p>\n<p>&nbsp;</p>\n<p>This project supported two Ph.D. students (one of them is female) at the University of Pittsburgh and the University of Texas at Arlington. Both of them have graduated.</p>\n<p>&nbsp;</p>\n<p>The proposed project makes great efforts to make the students be aware of the challenges in the future data mining and biomedical data science. The developed research outcomes have been seamlessly integrated into the course in ECE 3195 - Advanced Machine Learning and Deep Learning at the University of Pittsburgh and CSE 6389 - Advanced Topics in Data Science at the University of Texas at Arlington. Tutorial talks have been given in other courses for senior undergraduate students and graduate students.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/03/2023<br>\n\t\t\t\t\tModified by: Heng&nbsp;Huang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOur research findings in computational algorithm design and depression thought data analysis are highly relevant to the interdisciplinary research of data mining and biomedical data science. The investigation of this project produces several important outcomes.\n\n \n\n1. We developed new semi-supervised learning models to categorize the logical thinking errors of depression thought records (DTRs) using both labeled and unlabeled DTR data. Semi-Supervised Support Vector Machine (S3VM) is a powerful semi-supervised learning model. However, the high computational cost and non-convexity severely impede the S3VM method in large-scale applications. We proposed a new incremental learning algorithm to scale up S3VM based on the path following technique in the framework of difference of convex programming. Our new algorithm based on the path-following technique can directly update the solution of S3VM to converge to a local minimum within one outer loop so that the efficient incremental learning can be achieved. Our new algorithm is the first efficient path following algorithm for a non-convex problem with local minimum convergence guarantee. Experimental results show our new method has excellent performance on thinking error categorizations.\n\n \n\n2. We designed new sparse shrunk additive models to identify the depression thought markers with investigating the feature interactions. We target to identify the informative markers/features from depression thought records, which can help us understand the behavior of depression people better. In existing feature selection models, the interactions between features are often ignored or just discussed under prior structure information. To address this challenging issue, we consider the problem of sparse additive models for high-dimensional nonparametric regression with the allowance of the flexible interactions between features. We designed new sparse shrunk additive models to explore the structure information among features. This method bridges sparse kernel regression and sparse feature selection. We conducted experiments to validate the superior performance of our proposed methods.\n\n \n\n3. We studied transferable deep neural networks to simultaneously predict the logical thinking errors and emotions using electronic depression thought records. We formulated the thinking error prediction and emotion recognition problems as a multi-task learning problem. We proposed a new semi-supervised domain-adaptation method to integrate heterogeneous depression thought record data for thinking errors and emotions prediction with considering the prediction shares the same mechanism across different domains. We used a transferable batch normalization approach for deep neural networks to avoid problems related to domain shift in the data distributions. The altered network, referred to as transferable variational auto-encoder, avoids the need to introduce extra hyper-parameters or learnable parameters and is trainable end-to-end. The experimental results on DTRs show that our new algorithm has better performance than related methods.\n\n \n\n4. We introduced new dropout algorithm for deep learning model to improve the depression thought record data classification. Dropout is a popular technique to train large-scale deep neural networks to alleviate the overfitting problem. We explored it from a new perspective to provide new insight into this line of research. We disentangled the forward and backward pass of dropout and found that these two passes need different levels of noise to improve the generalization performance of deep neural networks. Based on this observation, we proposed the augmented dropout, which employs different dropping strategies in the forward and backward pass, to improve the standard dropout. Experimental results verified the effectiveness of our new method.\n\n \n\n5. We proposed a new deep large-scale multi-task learning network to classify the logical thinking errors of DTRs. We consider different thinking errors have interrelations, which could potentially help the prediction of each other, and formulate the thinking error prediction problem as a multi-task learning problem. We proposed a novel deep multi-task learning algorithm with automatically learning the interrelations among prediction tasks, i.e. thinking errors, and utilizing such information to enhance the prediction. In particular, we employed a multi-layer sub-network with low dimensional latent variables for learning the interrelations among thinking errors, and imposed a seamless and easy to implement regularization on deep models. The experimental results confirm the effectiveness of our new algorithm.\n\n \n\n6. We released the data mining software tools at the project website. To disseminate the project results, the investigators and students presented more than thirty full-length papers related to this project in peer-reviewed conference proceedings and journals.\n\n \n\nThis project supported two Ph.D. students (one of them is female) at the University of Pittsburgh and the University of Texas at Arlington. Both of them have graduated.\n\n \n\nThe proposed project makes great efforts to make the students be aware of the challenges in the future data mining and biomedical data science. The developed research outcomes have been seamlessly integrated into the course in ECE 3195 - Advanced Machine Learning and Deep Learning at the University of Pittsburgh and CSE 6389 - Advanced Topics in Data Science at the University of Texas at Arlington. Tutorial talks have been given in other courses for senior undergraduate students and graduate students.\n\n\t\t\t\t\tLast Modified: 04/03/2023\n\n\t\t\t\t\tSubmitted by: Heng Huang"
 }
}