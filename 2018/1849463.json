{
 "awd_id": "1849463",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Tensor500: A Streaming Analytics High Performance Computing Benchmark",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 99873.0,
 "awd_amount": 149748.0,
 "awd_min_amd_letter_date": "2018-08-20",
 "awd_max_amd_letter_date": "2020-06-30",
 "awd_abstract_narration": "Large-scale data analytics is essential to the National Strategic Computing Initiative (NSCI) and NSF's scientific discovery mission. Data-intensive supercomputing applications are increasingly important for handling high-performance computing workloads. However, current benchmarks and performance metrics do not provide useful information on suitability of computing systems for data-intensive applications.  This project will develop a new benchmark that can be used to assess the performance of new system implementations aimed at this important class of applications.\r\n \r\nThe research effort will produce a new Stream500 benchmark, complementary to Graph500, that replicates streaming analytics workload. The current benchmark capabilities will be expanded by enabling the exiting web-based infrastructure to accept submissions for multiple benchmarks.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tim",
   "pi_last_name": "Andersen",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Tim L Andersen",
   "pi_email_addr": "tim@cs.boisestate.edu",
   "nsf_id": "000425175",
   "pi_start_date": "2018-08-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Murphy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Richard Murphy",
   "pi_email_addr": "RichardMurphy620@boisestate.edu",
   "nsf_id": "000710981",
   "pi_start_date": "2018-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Boise State University",
  "inst_street_address": "1910 UNIVERSITY DR",
  "inst_street_address_2": "",
  "inst_city_name": "BOISE",
  "inst_state_code": "ID",
  "inst_state_name": "Idaho",
  "inst_phone_num": "2084261574",
  "inst_zip_code": "837250001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "ID02",
  "org_lgl_bus_name": "BOISE STATE UNIVERSITY",
  "org_prnt_uei_num": "HYWTVM5HNFM3",
  "org_uei_num": "HYWTVM5HNFM3"
 },
 "perf_inst": {
  "perf_inst_name": "Boise State University",
  "perf_str_addr": "",
  "perf_city_name": "Boise",
  "perf_st_code": "ID",
  "perf_st_name": "Idaho",
  "perf_zip_code": "837251135",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "ID02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "8237",
   "pgm_ref_txt": "CISE Interagency Agreements"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 99873.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 49875.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-daa6f468-7fff-c76b-8c56-8752a3fffacb\"> </span></p>\n<p dir=\"ltr\"><span>Tensors are a generalization of matrices to arbitrary dimension that naturally lend themselves to higher dimensional data (data that has multiple variables), and have recently seen a concurrent resurgent interest in computing, with companies such as Google and Amazon committing enormous resources to the development of software and hardware devoted to better and faster tensor-based data analytics pipelines.&nbsp; Tensors are algebraic objects and as such a large number of powerful mathematical methods have been developed to help us analyze and understand the data they contain and to derive meaning from that data.&nbsp; Consequently, the tensor is poised as a powerful point of entry facilitating exploration and discovery in engineering and the sciences.</span></p>\n<p dir=\"ltr\"><span>The over-arching goal of this project was to research and develop formal requirements for the creation of Tensor500, a set pf new machine learning-relevant, tensor-based High-Performance Computing (HPC) benchmarks in support of the National Strategic Computing Initiative (NSCI).&nbsp; Benchmarking HPC systems is not a trivial task, and the availability of accurate and relevant HPC benchmarks helps to drive hardware development, making hardware both more energy efficient for tasks of interest, and faster.&nbsp;</span></p>\n<p dir=\"ltr\"><span>In pursuing this goal, this project worked with the Graph500 Executive Committee, consisting of Dr. David Bader (Georgia Tech), Dr. Peter Kogge (University of Notre Dame), and Dr. Andrew Lumsdaine (Pacific Northwest National Laboratory), as well as Dr. Jon Berry of Sandia National Laboratory, and Dr. Tai-Ching Tuan from the Laboratory for Physical Sciences.&nbsp; In addition, </span><span>the project reviewed and summarized work from over 800 researchers in the field to determine the most promising research directions and state-of-the-art for tensor-based data analytics methods, in order to design the most accurate and relevant benchmark possible.&nbsp; &nbsp;</span></p>\n<p dir=\"ltr\"><span>The project identified 2 important criteria for the Tensor500 benchmarking suite. First, it is critical that Tensor500 provide mechanisms for generating artificial data that are robust and replicable, that can generate arbitrarily large amounts of data, and that produce data that is high-quality and accurately models real world scenarios.&nbsp; As an initial step to meet this criteria, the project supported the development of Kroenecker and power law based methods for generating data. Second, the project supported the development of five tensor kernels that are highly exercised in most machine learning workflows and other algorithms. The benchmark and data generation methods are publicly available at https://gitlab.com/tensorworld/pasta.</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/05/2022<br>\n\t\t\t\t\tModified by: Timothy&nbsp;L&nbsp;Andersen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nTensors are a generalization of matrices to arbitrary dimension that naturally lend themselves to higher dimensional data (data that has multiple variables), and have recently seen a concurrent resurgent interest in computing, with companies such as Google and Amazon committing enormous resources to the development of software and hardware devoted to better and faster tensor-based data analytics pipelines.  Tensors are algebraic objects and as such a large number of powerful mathematical methods have been developed to help us analyze and understand the data they contain and to derive meaning from that data.  Consequently, the tensor is poised as a powerful point of entry facilitating exploration and discovery in engineering and the sciences.\nThe over-arching goal of this project was to research and develop formal requirements for the creation of Tensor500, a set pf new machine learning-relevant, tensor-based High-Performance Computing (HPC) benchmarks in support of the National Strategic Computing Initiative (NSCI).  Benchmarking HPC systems is not a trivial task, and the availability of accurate and relevant HPC benchmarks helps to drive hardware development, making hardware both more energy efficient for tasks of interest, and faster. \nIn pursuing this goal, this project worked with the Graph500 Executive Committee, consisting of Dr. David Bader (Georgia Tech), Dr. Peter Kogge (University of Notre Dame), and Dr. Andrew Lumsdaine (Pacific Northwest National Laboratory), as well as Dr. Jon Berry of Sandia National Laboratory, and Dr. Tai-Ching Tuan from the Laboratory for Physical Sciences.  In addition, the project reviewed and summarized work from over 800 researchers in the field to determine the most promising research directions and state-of-the-art for tensor-based data analytics methods, in order to design the most accurate and relevant benchmark possible.   \nThe project identified 2 important criteria for the Tensor500 benchmarking suite. First, it is critical that Tensor500 provide mechanisms for generating artificial data that are robust and replicable, that can generate arbitrarily large amounts of data, and that produce data that is high-quality and accurately models real world scenarios.  As an initial step to meet this criteria, the project supported the development of Kroenecker and power law based methods for generating data. Second, the project supported the development of five tensor kernels that are highly exercised in most machine learning workflows and other algorithms. The benchmark and data generation methods are publicly available at https://gitlab.com/tensorworld/pasta.\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 01/05/2022\n\n\t\t\t\t\tSubmitted by: Timothy L Andersen"
 }
}