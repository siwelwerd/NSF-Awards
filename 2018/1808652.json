{
 "awd_id": "1808652",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CDS&E: Collaborative Research: Strategies for Managing Data in Uncertainty Quantification at Extreme Scales",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032927116",
 "po_email": "sghafoor@nsf.gov",
 "po_sign_block_name": "Sheikh Ghafoor",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 396066.0,
 "awd_amount": 396066.0,
 "awd_min_amd_letter_date": "2018-08-28",
 "awd_max_amd_letter_date": "2018-08-28",
 "awd_abstract_narration": "The exponential increase in the quantity of measurements and data holds tremendous promise for data-driven scientific discovery and decision making.  In many cases, data-driven scientific discovery is mathematically formulated as an inverse problem.  For inverse problems that serve as a basis for discovery and decision-making for complex problems, the uncertainty in its solutions must be quantified.  Though the past decades have seen tremendous advances in both theories and computational algorithms for inverse problems, quantifying the uncertainty (UQ) in their solutions taking big-data issues into account remains challenging.  This is largely due to computationally demanding nature of existing mathematical techniques that are unable to scale up to the amount of data being generated.  Consequently, much of the available data remains unused.  This project develops UQ algorithms that are both computationally scalable as well as datascalable for making scientific progresses in geosciences and medical imaging. In particular, the proposed methods are evaluated in the context of two challenging data-driven applications: (1) from large amount of seismograms (records of the ground motion) perform geophysical imaging to infer earth's interior structure to better understand earthquakes, and (2) from magnetic resonance (MR) cine images of patients estimate the heart's function (e.g. motion, contraction) to detect early onset of heart disease (cardiomyopathy).\r\n\r\n\r\nThe goal of this collaborative research project is to develop an integrated research program that addresses the data management and data analytics arising from both observations and scientific simulations, with applications from diverse domains at extreme scales. The project develops innovative statistical, mathematical, and parallel computational methods to manage the large amounts of simulation data as well as the ever increasing amounts of observation data required for extreme-scale UQ problems in general and Bayesian inverse problems in particular. These methods will be of immediate practical utility to scientists  and engineers dealing with big data and large-scale UQ problems in sensing-based disciplines, geosciences, climatology, medical imaging, etc. The successful completion of the project would  provide a first step towards the development of mathematical and computational methods for a wide range of data-driven  large-scale inverse and UQ challenges that can lead to original scientific discoveries and promote the progress of science.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hari",
   "pi_last_name": "Sundar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hari Sundar",
   "pi_email_addr": "hari.sundar@tufts.edu",
   "nsf_id": "000671836",
   "pi_start_date": "2018-08-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "50 S Central Campus Dr",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841129205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  },
  {
   "pgm_ele_code": "808400",
   "pgm_ele_name": "CDS&E"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "8084",
   "pgm_ref_txt": "CDS&E"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 396066.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The key impact of this work on inverse and UQ problems is the development and demonstration of algorithms for mitigating the effect<br />of big data problems within inverse and UQ problems. By developing scalable streaming and compression schemes, we have demonstrated that <br />checkpointing is not necessary and that streaming and compression are more efficient and scalable solutions. By packaging our codes as<br />easy to use C++ libraries, we hope more researchers working on similar problems will be able to utilize our methods and enable this research<br />to have a strong impact on the field. The key outcomes corresponding to the two major aims of this project are,<br /><br />Aim 1: We developed scalable algorithms for streaming and compression for managing large simulation data encountered in inverse and UQ problems<br />and demonstrated their efficiency and scalability compared to the use of checkpointing. We developed libraries for streaming and compression that <br />scale on large clusters and can redily be integrated with other codes for maximum impact. At the end of this project,<br />we reached the conclusion that recent developments in the quality, cost and longevity of SSDs had made streaming solutions <br />for inverse and UQ problems more attractive as compared to checkpointing, and that using compression schemes, especially<br />autoencoder based schemes that are tailored to the simulation data can significantly improve the performance and <br />scalability of these programs.<br /><br />Aim 2: We developed scalable strategies to tackle large observation data common in several large-scale UQ problems. Leveraging methods developed <br />under Aim 1 and integrating with methods developed from our collaborators at the University of Texas at Austin to use only a small subset of <br />available data, we improved overall scalability of UQ problems in the presence of large observational data. We demonstrated the efficacy of <br />our methods on a large-scale siesmic imaging problem using data from the USARRAY project.</p><br>\n<p>\n Last Modified: 05/24/2024<br>\nModified by: Hari&nbsp;Sundar</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe key impact of this work on inverse and UQ problems is the development and demonstration of algorithms for mitigating the effect\nof big data problems within inverse and UQ problems. By developing scalable streaming and compression schemes, we have demonstrated that \ncheckpointing is not necessary and that streaming and compression are more efficient and scalable solutions. By packaging our codes as\neasy to use C++ libraries, we hope more researchers working on similar problems will be able to utilize our methods and enable this research\nto have a strong impact on the field. The key outcomes corresponding to the two major aims of this project are,\n\nAim 1: We developed scalable algorithms for streaming and compression for managing large simulation data encountered in inverse and UQ problems\nand demonstrated their efficiency and scalability compared to the use of checkpointing. We developed libraries for streaming and compression that \nscale on large clusters and can redily be integrated with other codes for maximum impact. At the end of this project,\nwe reached the conclusion that recent developments in the quality, cost and longevity of SSDs had made streaming solutions \nfor inverse and UQ problems more attractive as compared to checkpointing, and that using compression schemes, especially\nautoencoder based schemes that are tailored to the simulation data can significantly improve the performance and \nscalability of these programs.\n\nAim 2: We developed scalable strategies to tackle large observation data common in several large-scale UQ problems. Leveraging methods developed \nunder Aim 1 and integrating with methods developed from our collaborators at the University of Texas at Austin to use only a small subset of \navailable data, we improved overall scalability of UQ problems in the presence of large observational data. We demonstrated the efficacy of \nour methods on a large-scale siesmic imaging problem using data from the USARRAY project.\t\t\t\t\tLast Modified: 05/24/2024\n\n\t\t\t\t\tSubmitted by: HariSundar\n"
 }
}