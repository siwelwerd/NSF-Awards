{
 "awd_id": "1816891",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small:Comp Cog: Broad-coverage semantic models of human sentence processing",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 490287.0,
 "awd_amount": 490287.0,
 "awd_min_amd_letter_date": "2018-08-09",
 "awd_max_amd_letter_date": "2023-04-06",
 "awd_abstract_narration": "Humans are a successful species in large part because they can pass knowledge about the world to one another using linguistic explanations.  These explanations can be quite complex, involving nested generalizations about multiple classes of objects and events.  Accurate models of how these relationships are decoded from natural language could further our understanding of how the brain works, and may allow non-programmer users to explain their desired products, goals and constraints to machines.  Sentence processing experiments may provide an important window into the mechanisms of idea formation in language comprehension, but the human mind is extraordinarily sensitive to the strangeness of constructed stimuli used in experimentally controlled research designs, yielding potentially confounding effects arising from unexpected words or sentence structures.  A common alternative is to use designs employing naturally-occurring stimuli with statistical controls, usually using one or more probabilistic measures of surprise during sentence processing.  Unfortunately, existing probabilistic measures of surprise are based on overly simple models of sentence processing that are not connected to the nested structure of generalizations that a linguistic explanation may describe, and thus have severe limits as predictors of these kinds of frequency effects.  This project will therefore develop a sentence processing model that decodes sentences into meanings using a human-like incremental probabilistic process.  This model will then be used to control for frequency effects in neural activation, blood oxygenation and reading time data in order to isolate effects that can be attributed to the mechanical process of constructing and storing complex ideas during language comprehension.\r\n\r\nThis project constructs a model of sentence processing that bases its processing decisions on mental representations of meanings rather than on words only.  This means that the model will be less surprised by repeated nouns or pronouns when these words refer to a common entity which is prominent in a discourse.  The project initially focuses on the development of a statistical sentence processing model which maintains several possible analyses of a sentence after each word is processed, each of which contains explicit representations of each discourse referent involved in a sentence meaning as a set of logical predicates adjacent to that referent in a graphical representation of the meaning.  A subsequent version of the model compresses these context sets into vectors, which are passed through a recurrent neural network.  The predictions of these models are compared against existing neural network language models used in natural language processing applications to ensure that their linguistic predictions are accurate.  Incremental probabilities generated by these models are then used to estimate probabilistic surprise as a frequency control in predicting functional magnetic resonance (fMRI), electroencephalographic (EEG), eye-tracking, and reading-time observations in existing datasets, in order to isolate effects due to memory usage and other mechanistic factors.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Schuler",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "William E Schuler",
   "pi_email_addr": "schuler.77@osu.edu",
   "nsf_id": "000326703",
   "pi_start_date": "2018-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio State University",
  "inst_street_address": "1960 KENNY RD",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBUS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "6146888735",
  "inst_zip_code": "432101016",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OH03",
  "org_lgl_bus_name": "OHIO STATE UNIVERSITY, THE",
  "org_prnt_uei_num": "MN4MDDMN8529",
  "org_uei_num": "DLWBSLWAJWR1"
 },
 "perf_inst": {
  "perf_inst_name": "Ohio State University",
  "perf_str_addr": "Oxley Hall",
  "perf_city_name": "Columbus",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "432101016",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OH03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 490287.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>In 2018, The Ohio State University received a $490,000 NSF Robust Intelligence award entitled \"RI: Small: Comp Cog: Broad-coverage semantic models of human sentence processing.\"&nbsp; This project developed several generations of a human-like sentence processing model and evaluated them against experimental reading time and brain imaging data.&nbsp; These evaluations used the probability the models assigned to each word in an input sentence given the preceding words as a predictor of the human response data.&nbsp; This measure of word probability has been shown to be a reliable predictor of reading times and brain imaging data in previous work, and is hypothesized to indicate that much of the cognitive work involved in human sentence processing is related to expectations about upcoming words.&nbsp; These structural models differ from currently popular transformer-based neural network language models, which have also been hypothesized as models of human sentence processing, in that they use an explicit representation of syntactic structure and information about the meanings of sentences, such as the antecedents of pronouns and other types of anaphora.</span></p>\r\n<p>Comparisons of these structural sentence processing models to large language models based on transformers and other types of artificial neural networks found the word probabilities estimated by these structural models obtained a better fit to reading times than other models, despite the fact that many of these other models estimated the correct words with a higher probability.&nbsp; Moreover, subsequent experiments showed that larger language models with more parameters (more artificial neurons) or trained on more text data produced poorer fits to reading time and brain imaging data than smaller models with fewer parameters or models trained on smaller amounts of text data.&nbsp; This suggests that large transformer-based neural network models with large amounts of training data may be predicting upcoming words in a way that is very different from human language users, and that this difference is magnified as large language models increase in size.</p><br>\n<p>\n Last Modified: 12/10/2024<br>\nModified by: William&nbsp;E&nbsp;Schuler</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn 2018, The Ohio State University received a $490,000 NSF Robust Intelligence award entitled \"RI: Small: Comp Cog: Broad-coverage semantic models of human sentence processing.\" This project developed several generations of a human-like sentence processing model and evaluated them against experimental reading time and brain imaging data. These evaluations used the probability the models assigned to each word in an input sentence given the preceding words as a predictor of the human response data. This measure of word probability has been shown to be a reliable predictor of reading times and brain imaging data in previous work, and is hypothesized to indicate that much of the cognitive work involved in human sentence processing is related to expectations about upcoming words. These structural models differ from currently popular transformer-based neural network language models, which have also been hypothesized as models of human sentence processing, in that they use an explicit representation of syntactic structure and information about the meanings of sentences, such as the antecedents of pronouns and other types of anaphora.\r\n\n\nComparisons of these structural sentence processing models to large language models based on transformers and other types of artificial neural networks found the word probabilities estimated by these structural models obtained a better fit to reading times than other models, despite the fact that many of these other models estimated the correct words with a higher probability. Moreover, subsequent experiments showed that larger language models with more parameters (more artificial neurons) or trained on more text data produced poorer fits to reading time and brain imaging data than smaller models with fewer parameters or models trained on smaller amounts of text data. This suggests that large transformer-based neural network models with large amounts of training data may be predicting upcoming words in a way that is very different from human language users, and that this difference is magnified as large language models increase in size.\t\t\t\t\tLast Modified: 12/10/2024\n\n\t\t\t\t\tSubmitted by: WilliamESchuler\n"
 }
}