{
 "awd_id": "1813470",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Collaborative Research: Building Subjective Knowledge Bases by Modeling Viewpoints",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 266000.0,
 "awd_min_amd_letter_date": "2018-08-03",
 "awd_max_amd_letter_date": "2019-02-11",
 "awd_abstract_narration": "This project will develop and empirically evaluate methods for creating subjective knowledge bases: databases of opinions and viewpoints as they are asserted by individuals in books, web forums, and social media. While most knowledge base research seeks to extract real-world truth from text, many factual assertions are either about inherently subjective propositions (such as \"apples are delicious\") or are non-subjective assertions that happen to contradict other belief holders or even consensus reality (such as \"the Earth is flat\"). This project pioneers new methods to automatically extract expressions of opinions and viewpoints from a textual corpus and use those assertions to build a subjective knowledge base that can accommodate contradictory and conflicting statements from different authors. Such a subjective knowledge base will help researchers answer a range of questions: What contradictory claims are being made in historical books, or contemporary social media? What propositions does a particular ideological community hold, and are they compatible with, or contradictory to, those held by other communities? This project lays the foundation for understanding a broad range of phenomena that can be seen as conflicts between coherent viewpoints.  The resulting computational models will lay the groundwork for intelligent systems that are robust with respect to the way in which propositions are used in the real world; as applications in artificial intelligence are being deployed more and more in social contexts, this research will inform these methods with more nuanced information about the diversity of human viewpoints.  This work will also include a substantial educational component, incorporating human context into algorithm design in undergraduate STEM education and broadening the use of natural language processing and machine learning across a range of disciplines.\r\n\r\nWhile previous work has focused on the primary task of identifying degrees of certainty (belief, viewpoints) in text, the primary contribution of this project will be modeling the structure of individual extracted viewpoints through the variables of the viewpoint holders and the viewpoint communities to which they belong. Models for building subjective knowledge bases accept subjective claims as fully semantic relational propositions, like recent research in open information extraction. However, instead of relying on the typical assumption of cross-document consensus, these models will embrace the simultaneous presence of contradictory claims across different author groups or even within the writings of the same individual. Major project components include: developing and refining broad-domain part-of-speech and syntactic parsing to be effective across both social media and historical books; using these tools to support author-centric latent-variable models of structured knowledge, which infers latent positions for both propositions and their viewpoint-holders; and improving the model with linguistic analysis of factuality and viewpoint (belief) commitment.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Bamman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Bamman",
   "pi_email_addr": "dbamman@berkeley.edu",
   "nsf_id": "000702889",
   "pi_start_date": "2018-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "Sponsored Projects Office",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947045940",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 250000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of the subjective knowledge base project was to develop and empirically evaluate methods for measuring the subjectivity of expressions (including opinions and viewpoints) as they asserted by individuals in books, web forums, and social media. While most knowledge base research seeks to extract real-world truth from text, many factual assertions are either about inherently subjective propositions (such as \"apples are delicious\") or are non-subjective assertions that happen to contradict other belief holders or even consensus reality (such as \"the Earth is flat\"). &nbsp;This project pioneered new methods to model the variation in meaning that arises in different communities; in addition to core progress improving natural language processing for several textual domains, this work has resulted in several tangible outcomes.</p>\n<p>First, it explores the degree to which the fundamental meanings of words are subject to variation by different communities that share a particular point of view. In this dimension of work, we have developed methods to measure this source of variation by inferring sociolects in online social media -- varieties of language that are used by specific communities. &nbsp;While past research has focused on measuring the variation in word choice that exists among groups online, we measure variation in the meanings of those words as well. &nbsp;In applying our method to a community of users on Reddit, we tie language use to community structure, finding that online community size has a direct connection to sociolect strength.&nbsp; &nbsp;&nbsp;</p>\n<p>Second, this project pioneered new methods to allow researchers across a wide range of disciplines (including computer science and the social sciences) to understand the source of that variation in meaning in interpretable ways by developing the construct of a \"contextual semantic axis\". &nbsp;This method builds on previous work defining a continuum between two opposing concepts (such as \"beautiful\"-\"ugly\", \"loveable\"-\"detestable\") and expands it to allow the representations of specific words in sentences to be situated on it. &nbsp;We apply this method to a collection of extremist men's communities across a number of forums online, and demonstrate that words describing women have become more \"detestable\" (along that semantic axis) over time, providing an additional example of how different communities encode their own subjective beliefs in language at the level of individual word senses.&nbsp;</p>\n<p>Third, we build models to explore how new word meanings propagate through different communities, identifying the documents that are most influential in the adoption of new senses. &nbsp;We focus on changing word meaning within academic publications, and develop a pipeline for identifying shifts in word meaning and measuring the influence of a document on later uses. &nbsp;We demonstrate that articles that have high linguistic influence tend to have more long-term citations that documents that do not; innovation at the level of coining new word senses is rewarded by citations, even when controlling for short-term citation counts, topics, and lexical features. &nbsp;This work helps shed light not only on the fundamental question of measuring how words have different meaning in different communities (including different time periods), but also how that new meaning becomes dominant in discourse.</p>\n<p>In addition to these core findings in research, this project also led to the development of publicly available course materials for incorporating human context into algorithm design in undergraduate STEM education and broadening the use of natural language processing and machine learning across a range of disciplines.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/20/2022<br>\n\t\t\t\t\tModified by: David&nbsp;Bamman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of the subjective knowledge base project was to develop and empirically evaluate methods for measuring the subjectivity of expressions (including opinions and viewpoints) as they asserted by individuals in books, web forums, and social media. While most knowledge base research seeks to extract real-world truth from text, many factual assertions are either about inherently subjective propositions (such as \"apples are delicious\") or are non-subjective assertions that happen to contradict other belief holders or even consensus reality (such as \"the Earth is flat\").  This project pioneered new methods to model the variation in meaning that arises in different communities; in addition to core progress improving natural language processing for several textual domains, this work has resulted in several tangible outcomes.\n\nFirst, it explores the degree to which the fundamental meanings of words are subject to variation by different communities that share a particular point of view. In this dimension of work, we have developed methods to measure this source of variation by inferring sociolects in online social media -- varieties of language that are used by specific communities.  While past research has focused on measuring the variation in word choice that exists among groups online, we measure variation in the meanings of those words as well.  In applying our method to a community of users on Reddit, we tie language use to community structure, finding that online community size has a direct connection to sociolect strength.    \n\nSecond, this project pioneered new methods to allow researchers across a wide range of disciplines (including computer science and the social sciences) to understand the source of that variation in meaning in interpretable ways by developing the construct of a \"contextual semantic axis\".  This method builds on previous work defining a continuum between two opposing concepts (such as \"beautiful\"-\"ugly\", \"loveable\"-\"detestable\") and expands it to allow the representations of specific words in sentences to be situated on it.  We apply this method to a collection of extremist men's communities across a number of forums online, and demonstrate that words describing women have become more \"detestable\" (along that semantic axis) over time, providing an additional example of how different communities encode their own subjective beliefs in language at the level of individual word senses. \n\nThird, we build models to explore how new word meanings propagate through different communities, identifying the documents that are most influential in the adoption of new senses.  We focus on changing word meaning within academic publications, and develop a pipeline for identifying shifts in word meaning and measuring the influence of a document on later uses.  We demonstrate that articles that have high linguistic influence tend to have more long-term citations that documents that do not; innovation at the level of coining new word senses is rewarded by citations, even when controlling for short-term citation counts, topics, and lexical features.  This work helps shed light not only on the fundamental question of measuring how words have different meaning in different communities (including different time periods), but also how that new meaning becomes dominant in discourse.\n\nIn addition to these core findings in research, this project also led to the development of publicly available course materials for incorporating human context into algorithm design in undergraduate STEM education and broadening the use of natural language processing and machine learning across a range of disciplines.\n\n\t\t\t\t\tLast Modified: 12/20/2022\n\n\t\t\t\t\tSubmitted by: David Bamman"
 }
}