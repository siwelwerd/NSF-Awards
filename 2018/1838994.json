{
 "awd_id": "1838994",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Crowdsourcing Metadata Enhancements to Improve the Discoverability and Reusability of Scientific Data: Experimental Evaluations",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Martin Halbert",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 298234.0,
 "awd_amount": 298234.0,
 "awd_min_amd_letter_date": "2018-08-15",
 "awd_max_amd_letter_date": "2018-08-15",
 "awd_abstract_narration": "This exploratory pilot project will undertake two experiments to determine what motivates people to contribute metadata enhancements to data that have been archived, but that are not sufficiently findable, accessible, interoperable, and reusable.  Current practice in data curation relies on the efforts of data producers and professional data curators to produce and provide metadata, including variable level data descriptors, study key words, and bibliographic citations to data-related publications. These efforts are expensive and, as a result, are often undersupplied, leaving data that has been archived and shared with the scientific community of limited value for reuse. The experiments in this project will directly inform potentially transformative efforts to engage the broader community in crowdsourcing enhancements to metadata so that tools and interfaces can be designed that will induce others to participate in this valuable activity, tapping into their knowledge of and interest in data in particular domains to increase data FAIRness. \r\n\r\nThis project is supported by the National Science Foundation Public Access Initiative which is managed by the NSF Office of Advanced Cyberinfrastructure on behalf of the Foundation.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Margaret",
   "pi_last_name": "Levenstein",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Margaret C Levenstein",
   "pi_email_addr": "maggiel@umich.edu",
   "nsf_id": "000104656",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "3003 South State St. Room 1062",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091274",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "741400",
   "pgm_ele_name": "NSF Public Access Initiative"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 298234.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-9b42ac9f-7fff-9954-08e6-8f9dd42d04d3\">&nbsp;</span></p>\n<p dir=\"ltr\"><span>In 2013, the U.S. Office of Science and Technology Policy established an explicit policy of data sharing from federally funded research projects. Data sharing is critical to the reproducibility of science and increases the efficiency of scientific research. Data re-use allows us to leverage prior investments to examine new questions and to approach old questions in new ways. Recognition of the importance of data sharing has led to the adoption of policies requiring data management plans and data sharing itself by funding agencies and journals, and has established data as a first class research object, comparable to articles, patents, and software. In most cases, however, researchers who produce valuable data have never been trained in data management or curation. As a result, this new emphasis creates a substantial burden on individual researchers and research projects and results in the \"sharing\" of data in ways that have limited value.&nbsp;</span></p>\n<p dir=\"ltr\"><span>For data sharing to be valuable, it must be FAIR: findable, accessible, interoperable, and re-usable. That is, the data must be organized and documented sufficiently for a third party to make sense of it without having to go back to the original data producer. The data must be discoverable, which requires metadata elements and a storage location accessible by common search strategies. It requires preservation, so that data can be re-used even when technology changes, as it surely will.&nbsp;</span></p>\n<p dir=\"ltr\"><span>This project designed and conducted a field experiment to investigate what motivates scholars to contribute metadata for their scholarly works. The experiment contacted authors of articles published in American Economics Association (AEA) journals whose data replication packages were available in openICPSR and asked them to contribute enhanced metadata for their data. Across all treatment conditions in this study, we collected a total of 3,149 metadata entries from 544 authors and completed missing metadata fields in a total of 522 studies. Overall, the rate of responding to our treatment emails was close to 40%. We attribute this high response rate to the fact that all emails were sent from an authoritative figure, namely, the AEA Data Editor. From a metadata collection perspective, this study demonstrates that the \"crowdsourcing approach\" can be an effective way to solicit metadata contribution from experts who have conducted the studies themselves. We demonstrate that collecting metadata contributions is both feasible and productive at scale and can serve as a low-cost way to address missing metadata issues in the future. We also did not find evidence that adding additional text mentioning the \"social benefit\" led to noticeable differences in the degree of willingness to contribute.</span></p>\n<p dir=\"ltr\"><span>The project also identified challenges to integrating the crowdsourced metadata into existing data archive workflows and created a prototype solution for applying the metadata changes at scale. Existing controls within the ICPSR deposit system make it difficult for external parties to make changes to deposits, and this led the project team to use a custom form outside of the openICPSR system to collect the enhanced metadata. To populate the metadata fields that were filled out on the external form, the project created a tool that partially automated metadata updates. This improvement is beneficial as ICPSR continues to archive increasingly more data and its associated metadata. We need creative and less manual processes for making these updates, which this tool achieves, and it will help enhance ICPSR's ability to make use of crowdsourced metadata enhancements in the future.</span></p>\n<p dir=\"ltr\"><span>This project contributed both to public economics, in its understanding of what incentivizes individuals to contribute public goods, and to information science, by improving the ability of data archives to make use of crowdsourced contributions to increase the FAIRness of data. This project improved ICPSR?s understanding of effective means for soliciting and integrating metadata improvements to existing archived materials. It has led to the creation of tools to facilitate use of crowdsourced metadata, in particular, solutions that scale creating and editing metadata records. ICPSR is a key institution for disseminating data produced by and to NSF researchers, and this project contributed to improvements in ICPSR's ability to produce FAIR data efficiently.&nbsp;</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/29/2023<br>\n\t\t\t\t\tModified by: Margaret&nbsp;Levenstein</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nIn 2013, the U.S. Office of Science and Technology Policy established an explicit policy of data sharing from federally funded research projects. Data sharing is critical to the reproducibility of science and increases the efficiency of scientific research. Data re-use allows us to leverage prior investments to examine new questions and to approach old questions in new ways. Recognition of the importance of data sharing has led to the adoption of policies requiring data management plans and data sharing itself by funding agencies and journals, and has established data as a first class research object, comparable to articles, patents, and software. In most cases, however, researchers who produce valuable data have never been trained in data management or curation. As a result, this new emphasis creates a substantial burden on individual researchers and research projects and results in the \"sharing\" of data in ways that have limited value. \nFor data sharing to be valuable, it must be FAIR: findable, accessible, interoperable, and re-usable. That is, the data must be organized and documented sufficiently for a third party to make sense of it without having to go back to the original data producer. The data must be discoverable, which requires metadata elements and a storage location accessible by common search strategies. It requires preservation, so that data can be re-used even when technology changes, as it surely will. \nThis project designed and conducted a field experiment to investigate what motivates scholars to contribute metadata for their scholarly works. The experiment contacted authors of articles published in American Economics Association (AEA) journals whose data replication packages were available in openICPSR and asked them to contribute enhanced metadata for their data. Across all treatment conditions in this study, we collected a total of 3,149 metadata entries from 544 authors and completed missing metadata fields in a total of 522 studies. Overall, the rate of responding to our treatment emails was close to 40%. We attribute this high response rate to the fact that all emails were sent from an authoritative figure, namely, the AEA Data Editor. From a metadata collection perspective, this study demonstrates that the \"crowdsourcing approach\" can be an effective way to solicit metadata contribution from experts who have conducted the studies themselves. We demonstrate that collecting metadata contributions is both feasible and productive at scale and can serve as a low-cost way to address missing metadata issues in the future. We also did not find evidence that adding additional text mentioning the \"social benefit\" led to noticeable differences in the degree of willingness to contribute.\nThe project also identified challenges to integrating the crowdsourced metadata into existing data archive workflows and created a prototype solution for applying the metadata changes at scale. Existing controls within the ICPSR deposit system make it difficult for external parties to make changes to deposits, and this led the project team to use a custom form outside of the openICPSR system to collect the enhanced metadata. To populate the metadata fields that were filled out on the external form, the project created a tool that partially automated metadata updates. This improvement is beneficial as ICPSR continues to archive increasingly more data and its associated metadata. We need creative and less manual processes for making these updates, which this tool achieves, and it will help enhance ICPSR's ability to make use of crowdsourced metadata enhancements in the future.\nThis project contributed both to public economics, in its understanding of what incentivizes individuals to contribute public goods, and to information science, by improving the ability of data archives to make use of crowdsourced contributions to increase the FAIRness of data. This project improved ICPSR?s understanding of effective means for soliciting and integrating metadata improvements to existing archived materials. It has led to the creation of tools to facilitate use of crowdsourced metadata, in particular, solutions that scale creating and editing metadata records. ICPSR is a key institution for disseminating data produced by and to NSF researchers, and this project contributed to improvements in ICPSR's ability to produce FAIR data efficiently. \n\n \n\n\t\t\t\t\tLast Modified: 01/29/2023\n\n\t\t\t\t\tSubmitted by: Margaret Levenstein"
 }
}