{
 "awd_id": "1837125",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: Small: Collaborative Research: Models and System-Level Coordination Algorithms for Power-in-the-Loop Autonomous Mobility-on-Demand Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032924926",
 "po_email": "mzivel@nsf.gov",
 "po_sign_block_name": "Michal Ziv-El",
 "awd_eff_date": "2019-01-01",
 "awd_exp_date": "2022-12-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2018-09-14",
 "awd_max_amd_letter_date": "2018-09-14",
 "awd_abstract_narration": "The goal of this project is to investigate how self-driving, electric vehicles transporting passengers on demand (a system referred to as autonomous mobility-on-demand, or AMoD) can enable optimized, coupled control of the power and transportation networks. The key observation is that the AMoD technology will give rise to complex couplings between the power and transportation networks, namely couplings between charging demand and electricity prices as people move around a city. The hypothesis is that by exploiting such couplings through control and optimization, AMoD systems will lead to lower electricity generation costs and higher integration levels of intermittent renewable energy resources such as wind and solar, while providing more convenient transportation. The results of this project will provide guidelines to transportation stakeholders and policy-makers regarding the deployment of autonomous vehicles on a societal scale, benefitting the U.S. economy by fostering clean and efficient future transportation systems.  \r\n\r\nThis project will devise theoretical models and optimization tools for the characterization of the aforementioned couplings and for the system-level control of AMoD with the power network in the loop. The key technical idea is to cast the coupled power and transportation networks in the formal framework of flow optimization, whereby city districts, charging stations, and roads are abstracted as nodes and edges of a graph, and the movements of customers, vehicles, and energy are abstracted as flows over such a graph. This project will then devise a control framework to optimize over the decision variables, e.g., vehicles' routes, charging decisions, and power generation schedules.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mahnoosh",
   "pi_last_name": "Alizadeh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mahnoosh Alizadeh",
   "pi_email_addr": "alizadeh@ece.ucsb.edu",
   "nsf_id": "000738962",
   "pi_start_date": "2018-09-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Barbara",
  "inst_street_address": "3227 CHEADLE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA BARBARA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8058934188",
  "inst_zip_code": "931060001",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SANTA BARBARA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G9QBQDH39DF4"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Barbara",
  "perf_str_addr": "ECE Department",
  "perf_city_name": "Santa Barbara",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "931069560",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "791800",
   "pgm_ele_name": "CPS-Cyber-Physical Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main goal of this project was to optimally dispatch and charge a fleet of autonomous electric vehicles (EVs) and set ride prices by considering the impact of such autonomous fleets on power transmission and distribution systems. The introduction of such autonomous vehicles for mobility-on-demand services provides an opportunity for better fleet management. Specifically, idle vehicles can be re-distributed (rebalanced) throughout the network to prevent accumulation of ride requests at busy locations. Autonomous vehicles allow for more effiicient rebalancing to be performed centrally by a platform operator who observes the state of all the vehicles and the demand, rather than locally by individual drivers. Furthermore, EVs provide opportunities for charging through cheap and environmentally-friendly energy resources (e.g., solar energy). As supply availability and prices differ across the network both geographically and temporally, this diversity can be exploited when the fleet is centrally operated by a platform operator that is aware of the electricity prices throughout the whole network. Moreover, coupling an optimal fleet management policy with a dynamic ride pricing scheme allows the revenues to be maximized while reducing the rebalancing cost and the waiting time of the customers by adjusting the induced demand.&nbsp;</p>\n<p>Among the several papers supported by this grant, we highlight two important results next.</p>\n<p>In [1], we defined the real-time dispatch and ride pricing policy for the fleet as a black box that takes the vehicle locations, energy levels, and customer queue lengths as inputs and outputs ride prices and vehicle routing/charging decisions. We optimized the dependence of this policy on the network state using reinforcement learning in a simulator.</p>\n<p>On real transportation networks of San Francisco and Manhattan, our real-time policy can successfully keep the queue lengths 400 times lower, decrease the charging costs by 25%, and earn higher profits compared to a static network-flow based policy. We compared our policy to heuristic modifications of the static policy such as surge pricing when the queues are long. We have shown that our policy is able to generate 24% more profits and results in 75% fewer queues than the best heuristic policy.</p>\n<p>In [2], we studied the effects of duopolistic competition in electric&nbsp;AMoD&nbsp;systems that are operated by profit-maximizing platform operators using a game-theoretic framework. We did so by characterizing the equilibrium strategies (pricing and fleet management strategies) of the platform operators in the monopolistic and duopolistic settings. We proved that identical competitors (i.e., operators with identical costs) can only have identical policies. We derived closed-form theoretical bounds quantifying the impacts of the competition on the ride prices, the profits of the firms, the aggregate demand served, and the consumer surplus as a function of a parameter that characterizes the correlation between customers&rsquo; preferences. We have shown that a higher correlation between customers&rsquo; preferences strengthens the competition and boosts the impacts of competition. We further empirically studied these effects using network and demand data of Manhattan.&nbsp;By quantifying&nbsp;the impacts of&nbsp;competition, we provide insights for&nbsp;investors to make informed policy decisions about competing&nbsp;AMoD&nbsp;platforms and investing in efficient&nbsp;AMoD&nbsp;technologies.</p>\n<p>The significance of this project is evident considering several facts.&nbsp;In 2017, the transportation sector became the largest emitter of greenhouse gases in the United States, overtaking emissions from the electric power industry. Therefore, transportation represents one of the primary challenges to achieving deep decarbonization of the U.S. economy. Furthermore, traffic congestion and gridlocks cost the population $124 billion in 2013 and are expected to increase by 50% to $186 billion by 2030. Besides pollution and congestion, the number of traffic-related fatalities due to car accidents in the United States were up 7% between 2019 and 2020. Given these challenges that the transportation sector needs to overcome, this project proposes deployment of fleets of shared autonomous electric vehicles to serve population&rsquo;s urban mobility needs as a promising remedy. By efficiently utilizing shared vehicles and optimally controlling this fleet, transportation needs can be satisfied with fewer vehicles on the road. Autonomous driving technology combined with vehicle-to-vehicle communication can help reduce car accidents in the United States. Furthermore, centrally operated electric vehicles can be charged optimally using renewable sources at the right times of the day and can be used to store energy, which can then provide electricity to the power grid when needed to increase grid reliability. All in all, through this project on control of autonomous fleets of electric vehicles, we can achieve&nbsp;less pollution, fewer accidents, and less congestion.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>[1]&nbsp;<span>Turan, Berkay and Pedarsani, Ramtin and Alizadeh, Mahnoosh.&nbsp;(2020).&nbsp;Dynamic pricing and fleet management for electric autonomous mobility on demand systems.&nbsp;&nbsp;</span><em>Transportation research Part C Emerging technologies</em><span>.</span></p>\n<p>[2]&nbsp;<span>Turan, Berkay and Alizadeh, Mahnoosh.&nbsp;(2021).&nbsp;Competition in Electric Autonomous Mobility on Demand Systems.&nbsp;&nbsp;</span><em>IEEE Transactions on Control of Network Systems</em><span>.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/02/2023<br>\n\t\t\t\t\tModified by: Mahnoosh&nbsp;Alizadeh</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe main goal of this project was to optimally dispatch and charge a fleet of autonomous electric vehicles (EVs) and set ride prices by considering the impact of such autonomous fleets on power transmission and distribution systems. The introduction of such autonomous vehicles for mobility-on-demand services provides an opportunity for better fleet management. Specifically, idle vehicles can be re-distributed (rebalanced) throughout the network to prevent accumulation of ride requests at busy locations. Autonomous vehicles allow for more effiicient rebalancing to be performed centrally by a platform operator who observes the state of all the vehicles and the demand, rather than locally by individual drivers. Furthermore, EVs provide opportunities for charging through cheap and environmentally-friendly energy resources (e.g., solar energy). As supply availability and prices differ across the network both geographically and temporally, this diversity can be exploited when the fleet is centrally operated by a platform operator that is aware of the electricity prices throughout the whole network. Moreover, coupling an optimal fleet management policy with a dynamic ride pricing scheme allows the revenues to be maximized while reducing the rebalancing cost and the waiting time of the customers by adjusting the induced demand. \n\nAmong the several papers supported by this grant, we highlight two important results next.\n\nIn [1], we defined the real-time dispatch and ride pricing policy for the fleet as a black box that takes the vehicle locations, energy levels, and customer queue lengths as inputs and outputs ride prices and vehicle routing/charging decisions. We optimized the dependence of this policy on the network state using reinforcement learning in a simulator.\n\nOn real transportation networks of San Francisco and Manhattan, our real-time policy can successfully keep the queue lengths 400 times lower, decrease the charging costs by 25%, and earn higher profits compared to a static network-flow based policy. We compared our policy to heuristic modifications of the static policy such as surge pricing when the queues are long. We have shown that our policy is able to generate 24% more profits and results in 75% fewer queues than the best heuristic policy.\n\nIn [2], we studied the effects of duopolistic competition in electric AMoD systems that are operated by profit-maximizing platform operators using a game-theoretic framework. We did so by characterizing the equilibrium strategies (pricing and fleet management strategies) of the platform operators in the monopolistic and duopolistic settings. We proved that identical competitors (i.e., operators with identical costs) can only have identical policies. We derived closed-form theoretical bounds quantifying the impacts of the competition on the ride prices, the profits of the firms, the aggregate demand served, and the consumer surplus as a function of a parameter that characterizes the correlation between customers\u2019 preferences. We have shown that a higher correlation between customers\u2019 preferences strengthens the competition and boosts the impacts of competition. We further empirically studied these effects using network and demand data of Manhattan. By quantifying the impacts of competition, we provide insights for investors to make informed policy decisions about competing AMoD platforms and investing in efficient AMoD technologies.\n\nThe significance of this project is evident considering several facts. In 2017, the transportation sector became the largest emitter of greenhouse gases in the United States, overtaking emissions from the electric power industry. Therefore, transportation represents one of the primary challenges to achieving deep decarbonization of the U.S. economy. Furthermore, traffic congestion and gridlocks cost the population $124 billion in 2013 and are expected to increase by 50% to $186 billion by 2030. Besides pollution and congestion, the number of traffic-related fatalities due to car accidents in the United States were up 7% between 2019 and 2020. Given these challenges that the transportation sector needs to overcome, this project proposes deployment of fleets of shared autonomous electric vehicles to serve population\u2019s urban mobility needs as a promising remedy. By efficiently utilizing shared vehicles and optimally controlling this fleet, transportation needs can be satisfied with fewer vehicles on the road. Autonomous driving technology combined with vehicle-to-vehicle communication can help reduce car accidents in the United States. Furthermore, centrally operated electric vehicles can be charged optimally using renewable sources at the right times of the day and can be used to store energy, which can then provide electricity to the power grid when needed to increase grid reliability. All in all, through this project on control of autonomous fleets of electric vehicles, we can achieve less pollution, fewer accidents, and less congestion.\n\n \n\n \n\n[1] Turan, Berkay and Pedarsani, Ramtin and Alizadeh, Mahnoosh. (2020). Dynamic pricing and fleet management for electric autonomous mobility on demand systems.  Transportation research Part C Emerging technologies.\n\n[2] Turan, Berkay and Alizadeh, Mahnoosh. (2021). Competition in Electric Autonomous Mobility on Demand Systems.  IEEE Transactions on Control of Network Systems.\n\n \n\n\t\t\t\t\tLast Modified: 05/02/2023\n\n\t\t\t\t\tSubmitted by: Mahnoosh Alizadeh"
 }
}