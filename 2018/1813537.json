{
 "awd_id": "1813537",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI:Small:Robust Performance Models",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 412000.0,
 "awd_amount": 476952.0,
 "awd_min_amd_letter_date": "2018-06-29",
 "awd_max_amd_letter_date": "2022-05-23",
 "awd_abstract_narration": "Algorithms are ubiquitous in modern society and integral to the economy. Whether finding optimal assignments of packages and operators to planes, trucks, and ships, or translating between different languages, the problems solved become larger and more challenging every day. Crucially enabling such developments are advances in artificial intelligence. There are often different approaches for solving the same type of problem, and they are often synergistic -- where one fails, another performs well.  AI techniques in this project allow the best approach for a given problem to be chosen automatically.  This research will allow for such choices to be made more robustly even in difficult circumstances, resulting in improved performance and reduced effort to deploy AI in practical systems. Ultimately, the project will make it easier for humans to develop high-performance AI systems.\r\n\r\nAlgorithm selection is the process of automatically matching synergistic algorithmic choices to the specific properties of a problem in order to achieve optimal performance.  Current methods for making such choices over available algorithms are often limited in applicability by the hardware on which the algorithms were benchmarked, the resource limits imposed on runs, and subject to bias caused by performance fluctuations in randomized algorithms.  In many cases, these issues are caused by reliance on brittle performance measures, limiting practical application in academia and industry.  This project aims to address these limitations in three ways. First, it will define a notion of robustness to guide algorithm selection, and identify properties of algorithms, experimental setups, and computational environments that affect robustness. Second, it will develop specific performance measures informed by this definition of robustness, and which are portable across different hardware platforms. Third, it will mitigate the impact of brittle performance measures through new approaches to building performance models based on machine learning.  The project will result in the dissemination of shared data and benchmarks to the broader AI community, for example through the Algorithm Selection Library (ASlib).\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lars",
   "pi_last_name": "Kotthoff",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lars Kotthoff",
   "pi_email_addr": "larsko@uwyo.edu",
   "nsf_id": "000761935",
   "pi_start_date": "2018-06-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wyoming",
  "inst_street_address": "1000 E UNIVERSITY AVE",
  "inst_street_address_2": "",
  "inst_city_name": "LARAMIE",
  "inst_state_code": "WY",
  "inst_state_name": "Wyoming",
  "inst_phone_num": "3077665320",
  "inst_zip_code": "820712000",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "WY00",
  "org_lgl_bus_name": "UNIVERSITY OF WYOMING",
  "org_prnt_uei_num": "FDR5YF2K32X5",
  "org_uei_num": "FDR5YF2K32X5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wyoming",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "WY",
  "perf_st_name": "Wyoming",
  "perf_zip_code": "820712000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "WY00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "054Y00",
   "pgm_ele_name": "GVF - Global Venture Fund"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5947",
   "pgm_ref_txt": "BELGIUM"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 412000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 14962.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 20440.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 14746.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 14804.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project developed several approaches and tools that make it easier to solve hard AI problems in practice. These approaches focus on more robust ways to run existing systems, leveraging their complementarity to improve overall performance. This includes being able to build better models of algorithmic performance through better machine learning approaches and tools.<br />Specifically, the supported researchers developed ways of leveraging parallelism in more intelligent ways to solve problems by running different solution approaches at the same time. We showed that doing this naively by running everything that is available in parallel actually slows things down, and developed an approach that selects a subset of the algorithms to run through predictions of their performance. Other research thrusts focused on making meta-algorithmic knowledge, used for modeling the behavior of algorithms, useable and useful in different contexts than where it was originally acquired. This is a crucial step to building more general and robust models of algorithmic behavior.<br />A further significant outcome of the funded project is a new paradigm for obtaining information for models of algorithmic performance. Before, such models treated the algorithms and approaches they modeled as black boxes about whose inner workings nothing is known. While this allows such methods to be broadly applicable, it ignores the main source of information about an algorithm -- the algorithm itself. We developed ways of automatically analyzing algorithms through their source code and binary executables and using this new information to build better models of algorithmic behavior.<br />Machine learning is at the core of the supported research and critically enables it. This award supported contributions to these fundamental techniques, in particular for the mlr machine learning framework and ecosystem, which the PI is a core contributor to. The mlr framework is not specific to the research supported through this award, and the advancements enabled by this award will support researchers and practitioners who are interested in applying machine learning in general.<br />More broadly, the supported research enables the more efficient use of computational infrastructure through better guidance on when to use what algorithms and approaches and how. While we focused on hard AI problems, our results are not specific to this application. Results of the performed research were disseminated in the form of research publications, but also in the form of software and datasets that interested researchers can use in their own investigations.<br />In addition, this award supported the training of 13 undergraduate and six graduate students, who gained proficiency in running and evaluating state-of-the-art AI algorithms, using Machine Learning to model their behavior, and running large-scale computational experiments.</p><br>\n<p>\n Last Modified: 11/23/2023<br>\nModified by: Lars&nbsp;Kotthoff</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe project developed several approaches and tools that make it easier to solve hard AI problems in practice. These approaches focus on more robust ways to run existing systems, leveraging their complementarity to improve overall performance. This includes being able to build better models of algorithmic performance through better machine learning approaches and tools.\nSpecifically, the supported researchers developed ways of leveraging parallelism in more intelligent ways to solve problems by running different solution approaches at the same time. We showed that doing this naively by running everything that is available in parallel actually slows things down, and developed an approach that selects a subset of the algorithms to run through predictions of their performance. Other research thrusts focused on making meta-algorithmic knowledge, used for modeling the behavior of algorithms, useable and useful in different contexts than where it was originally acquired. This is a crucial step to building more general and robust models of algorithmic behavior.\nA further significant outcome of the funded project is a new paradigm for obtaining information for models of algorithmic performance. Before, such models treated the algorithms and approaches they modeled as black boxes about whose inner workings nothing is known. While this allows such methods to be broadly applicable, it ignores the main source of information about an algorithm -- the algorithm itself. We developed ways of automatically analyzing algorithms through their source code and binary executables and using this new information to build better models of algorithmic behavior.\nMachine learning is at the core of the supported research and critically enables it. This award supported contributions to these fundamental techniques, in particular for the mlr machine learning framework and ecosystem, which the PI is a core contributor to. The mlr framework is not specific to the research supported through this award, and the advancements enabled by this award will support researchers and practitioners who are interested in applying machine learning in general.\nMore broadly, the supported research enables the more efficient use of computational infrastructure through better guidance on when to use what algorithms and approaches and how. While we focused on hard AI problems, our results are not specific to this application. Results of the performed research were disseminated in the form of research publications, but also in the form of software and datasets that interested researchers can use in their own investigations.\nIn addition, this award supported the training of 13 undergraduate and six graduate students, who gained proficiency in running and evaluating state-of-the-art AI algorithms, using Machine Learning to model their behavior, and running large-scale computational experiments.\t\t\t\t\tLast Modified: 11/23/2023\n\n\t\t\t\t\tSubmitted by: LarsKotthoff\n"
 }
}