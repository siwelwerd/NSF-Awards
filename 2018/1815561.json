{
 "awd_id": "1815561",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: A Unified Compositional Model for Explainable Video-based Human Activity Parsing",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 449000.0,
 "awd_amount": 449000.0,
 "awd_min_amd_letter_date": "2018-08-15",
 "awd_max_amd_letter_date": "2018-08-15",
 "awd_abstract_narration": "An ultimate goal of computer vision is understanding scene and activities from images and video. This task involves many perceptual and cognitive processes at various semantic levels. A next step beyond visual classification is visual interpretation, that is, to explain the relations among visual entities through visual inference and reasoning. Due to the enormous variability across instances of this problem, semantic parsing for explaining a visual scene and activities is highly challenging. This project studies how the structural composition of visual entities can be used to overcome the diversity in the visual scene and activities. It advances and enrich the basic research of computer vision, and brings significant impact on many merging applications, including autonomous or assisted driving, intelligent robots, and intelligent video surveillance. This research also contributes to education through curriculum development, student training, and knowledge dissemination. It includes interactions with K-12 students for participation and research opportunities.  \r\n\r\nThis research is to develop a unified visual compositional model that can effectively learn complex semantic concepts in a scalable end-to-end fashion, while achieving good generalizability and providing explainable parsing of the visual data. The project is focused on: (1) a principled model and its theoretical foundation, by designing a stochastic grammar based on the probabilistic And/Or-Graph to model the structural composition; (2) an effective computational approach for learning and parsing, by exploiting data-driven pattern mining to discover structural components and by exploring how the patterns may be self-formed; (3) a solid case study on video human activity parsing and interpretation, by inferring the complex compositions of human actions, body movements, and interaction with the environment; and (4) tools and prototype systems for human articulated body pose estimation, contextual object discovery, and video-based human activity analysis and interpretation.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ying",
   "pi_last_name": "Wu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ying Wu",
   "pi_email_addr": "yingwu@northwestern.edu",
   "nsf_id": "000299558",
   "pi_start_date": "2018-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "2145 Sheridan Road, Northwestern",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602083118",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 449000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The key issue in visual modeling is to cope with the uncertainty in visual patterns that generally exhibit enormous variations. Deep net-based methods have recently demonstrated impressive results on many visual recognition tasks. They forcefully learn a highly non-linear mapping from the visual space to the ?label? space. Generally, they don?t explicitly exploit the visual space structure, but rather depend on the coverage of the huge amount of training data. In practice, however, it is not always possible to collect ?sufficient? training data so as to well cover the complicated visual diversity. Many reasons cause the diversity of visual appearances. An important one is the variation in structural composition. A larger visual pattern can be decomposed into smaller component patterns. The possibly endless structural compositions produce enormous visual complexity and diversity. This is not well investigated and understood and thus deserves more studies.</p>\n<p>This project develops a novel unified visual compositional model that is able to effectively learn complex semantic concepts in a scalable end-to-end fashion while achieving good generalizability and providing explainable parsing of the visual data. It produces (1) a principled model and its theoretical foundation. This model addresses the two critical issues for visual composition, including structure and appearance modeling, through a unified approach in an end-to-end fashion. It designs a stochastic grammar based on the probabilistic And/Or-Graph to model the structural composition. In addition, this structural decomposition is grounded to images via deep networks to handle the visual appearance uncertainty; (2) an effective computational approach for effective learning and parsing. This new model exploits data-driven pattern mining to discover significant structural components and explore how the patterns may be self-formed; (3) a solid case study on video human activity parsing. Human activities are complex compositions of human actions, body movements, and interactions with the environment. This incurs almost limitless variations. This research aims to more generalizable and explainable analysis of video human activities; and (4) tools and prototype systems. Effective and efficient tools are developed for human detection, articulated body pose estimation, and contextual object discovery that many computer vision tasks can use. Prototype systems are developed for video-based human activity analysis and interpretation.</p>\n<p>Exploiting the structural composition of the visual patterns, this new model is able to cope with the enormous visual variability by recursively dividing and conquering the uncertainties of its components, so that the learning can be achieved via smaller data. In addition, the inference based on such a compositional model produces semantic parsing of visual data, thus providing explainable interpretation and leading to understanding. Moreover, this new model is expected to largely alleviate over-fitting in learning, achieve much more robust generalizability, and realize scalable learning.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/22/2023<br>\n\t\t\t\t\tModified by: Ying&nbsp;Wu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe key issue in visual modeling is to cope with the uncertainty in visual patterns that generally exhibit enormous variations. Deep net-based methods have recently demonstrated impressive results on many visual recognition tasks. They forcefully learn a highly non-linear mapping from the visual space to the ?label? space. Generally, they don?t explicitly exploit the visual space structure, but rather depend on the coverage of the huge amount of training data. In practice, however, it is not always possible to collect ?sufficient? training data so as to well cover the complicated visual diversity. Many reasons cause the diversity of visual appearances. An important one is the variation in structural composition. A larger visual pattern can be decomposed into smaller component patterns. The possibly endless structural compositions produce enormous visual complexity and diversity. This is not well investigated and understood and thus deserves more studies.\n\nThis project develops a novel unified visual compositional model that is able to effectively learn complex semantic concepts in a scalable end-to-end fashion while achieving good generalizability and providing explainable parsing of the visual data. It produces (1) a principled model and its theoretical foundation. This model addresses the two critical issues for visual composition, including structure and appearance modeling, through a unified approach in an end-to-end fashion. It designs a stochastic grammar based on the probabilistic And/Or-Graph to model the structural composition. In addition, this structural decomposition is grounded to images via deep networks to handle the visual appearance uncertainty; (2) an effective computational approach for effective learning and parsing. This new model exploits data-driven pattern mining to discover significant structural components and explore how the patterns may be self-formed; (3) a solid case study on video human activity parsing. Human activities are complex compositions of human actions, body movements, and interactions with the environment. This incurs almost limitless variations. This research aims to more generalizable and explainable analysis of video human activities; and (4) tools and prototype systems. Effective and efficient tools are developed for human detection, articulated body pose estimation, and contextual object discovery that many computer vision tasks can use. Prototype systems are developed for video-based human activity analysis and interpretation.\n\nExploiting the structural composition of the visual patterns, this new model is able to cope with the enormous visual variability by recursively dividing and conquering the uncertainties of its components, so that the learning can be achieved via smaller data. In addition, the inference based on such a compositional model produces semantic parsing of visual data, thus providing explainable interpretation and leading to understanding. Moreover, this new model is expected to largely alleviate over-fitting in learning, achieve much more robust generalizability, and realize scalable learning.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 09/22/2023\n\n\t\t\t\t\tSubmitted by: Ying Wu"
 }
}