{
 "awd_id": "1840857",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Medium: Collaborative Research: Next-Generation Statistical Optimization Methods for Big Data Computing",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2020-12-31",
 "tot_intn_awd_amt": 237718.0,
 "awd_amount": 237718.0,
 "awd_min_amd_letter_date": "2018-09-19",
 "awd_max_amd_letter_date": "2018-09-19",
 "awd_abstract_narration": "This project develops a new generation of optimization methods to address data mining and knowledge discovery challenges in large-scale scientific data analysis. The project is constructed in the context that modern computing architectures are enabling us to fit complex statistical models (Big Models) on large and complex datasets (Big Data).  However, despite significant progress in each subfield of Big Data, Big Model, and modern computing architecture, we are still lacking  powerful optimization  techniques to effectively integrate these key components.\r\n\r\nOne important bottleneck is that many general-purpose optimization  methods are not specifically designed for statistical learning problems. Even some of them are tailored to utilize specific problem structures, they have not actually incorporated sophisticated statistical thinking into algorithm design and analysis. To tackle this bottleneck, the project extends traditional theory to open new possibilities for nontraditional optimization  problems, such as nonconvex and infinite-dimensional examples.  The project develops deeper theoretical understanding of several challenging  issues in optimization (such as nonconvexity), develops new algorithms that will lead to better practical methods in the big data era, and demonstrates the new methods on challenging bio-informatics problems.\r\n\r\nThe project is closely related to NSF's mission to promote Big Data research, and will have broad impacts. In the Big Data era, we see an urgent need for powerful optimization methods to handle the increasing complexity of modern datasets.  However, we still lack adequate methods, theory, and computational techniques.  By simultaneously addressing these aspects, this project will deliver novel and useful statistical optimization methods that benefit all relevant scientific areas. The project will deliver easy-to-use software packages which directly help scientists to explore and analyze complex datasets.  Both PIs will also design and develop new classes to teach modern techniques in handling big data optimization problems. All the course materials - including lecture notes, problem sets, source code, solutions and working  examples - will be freely  accessed online.  Moreover, both PIs will write tutorial  papers and disseminate the results of this research through the internet, academic conferences, workshops,  and journals.  Through senior theses and potentially the REU (Research Experiences for Undergraduates) program, the proposed project will also actively include undergraduates and engage under-represented minority groups.\r\n\r\nTo achieve these goals, this project develops (i) a new research area named statistical optimization, which incorporates sophisticated statistical thinking into modern optimization, and will effectively bridge machine learning, statistics, optimization,  and stochastic analysis; (ii) new theoretical frameworks and computational methods for nonconvex and infinite-dimensional optimization, which will motivate effective optimization methods with theoretical  guarantees that are applicable to a wide variety of prominent statistical models; (iii) new scalable optimization methods, which aim at fully harnessing the horsepower of modern large-scale distributed computing infrastructure.  The project will shed new theoretical light on large-scale optimization, advance practice through novel algorithms and software, and demonstrate the methods on challenging bio-informatics problems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Han",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Han Liu",
   "pi_email_addr": "hanliu@northwestern.edu",
   "nsf_id": "000582220",
   "pi_start_date": "2018-09-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "1801 Maple Ave.",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602013149",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 72103.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 165615.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research developed a new theory of nonconvex statistical optimization, which &nbsp;incorporates sophisticated model-based statistical theory into the design and analysis of optimization algorithms. This new theory has several key advantages over the previous optimization theory: first, it focuses on the average-case instead of the highly improbable worst-case performance; second, it leverages the rich information from the underlying statistical model.</p>\n<p>As for intellectual merit, the developed theory has great practical relevance. As an example, it has been applied to analyze the popular pathwise coordinate ascent algorithm. The previous optimization theory could not explain why the algorithm has strong empirical performance in spite of its poor worst-case performance. &nbsp;Our new results showed that this algorithm in fact guarantee the linear convergence to a desirable local optimum, thus providing the first statistical/computational analysis of pathwise coordinate ascent. We have also applied this new framework to successfully analyze other commonly used procedures such as alternating gradient descent, establishing global convergence rates and creating improved update rules.&nbsp;To better disseminate these research results, the PI and his students has developed and are maintaining one high quality statistical software package named PICASSO, it is freely available on CRAN. &nbsp;This &nbsp;supported research has contributed significantly to a new academic area named model-based statistical optimization.&nbsp;</p>\n<p>As for broader impact, &nbsp;this research exceeds fundamental theory and directly impacts the society. For example, this research considers the problem of&nbsp;deciphering the language of non-coding DNA. Gene regulatory code is highly complex due to the existence of polysemy and distant semantic relationship, which previous informatics methods often fail to capture especially in data-scarce scenarios. To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, which forms a global and transferrable understanding of genomic DNA sequences based on up and downstream nucleotide contexts. We show that the single pre-trained transformers model can simultaneously achieve state-of-the-art performance on many sequence prediction tasks, after easy fine-tuning using small task-specific data. Further, DNABERT enables direct visualization of nucleotide-level importance and semantic relationship within input sequences for better interpretability and accurate identification of conserved sequence motifs and functional genetic variants. We also demonstrate that pre-trained DNABERT with the human genome can even be readily applied to other organisms with exceptional performance.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/20/2021<br>\n\t\t\t\t\tModified by: Han&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis research developed a new theory of nonconvex statistical optimization, which  incorporates sophisticated model-based statistical theory into the design and analysis of optimization algorithms. This new theory has several key advantages over the previous optimization theory: first, it focuses on the average-case instead of the highly improbable worst-case performance; second, it leverages the rich information from the underlying statistical model.\n\nAs for intellectual merit, the developed theory has great practical relevance. As an example, it has been applied to analyze the popular pathwise coordinate ascent algorithm. The previous optimization theory could not explain why the algorithm has strong empirical performance in spite of its poor worst-case performance.  Our new results showed that this algorithm in fact guarantee the linear convergence to a desirable local optimum, thus providing the first statistical/computational analysis of pathwise coordinate ascent. We have also applied this new framework to successfully analyze other commonly used procedures such as alternating gradient descent, establishing global convergence rates and creating improved update rules. To better disseminate these research results, the PI and his students has developed and are maintaining one high quality statistical software package named PICASSO, it is freely available on CRAN.  This  supported research has contributed significantly to a new academic area named model-based statistical optimization. \n\nAs for broader impact,  this research exceeds fundamental theory and directly impacts the society. For example, this research considers the problem of deciphering the language of non-coding DNA. Gene regulatory code is highly complex due to the existence of polysemy and distant semantic relationship, which previous informatics methods often fail to capture especially in data-scarce scenarios. To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, which forms a global and transferrable understanding of genomic DNA sequences based on up and downstream nucleotide contexts. We show that the single pre-trained transformers model can simultaneously achieve state-of-the-art performance on many sequence prediction tasks, after easy fine-tuning using small task-specific data. Further, DNABERT enables direct visualization of nucleotide-level importance and semantic relationship within input sequences for better interpretability and accurate identification of conserved sequence motifs and functional genetic variants. We also demonstrate that pre-trained DNABERT with the human genome can even be readily applied to other organisms with exceptional performance.\n\n\t\t\t\t\tLast Modified: 05/20/2021\n\n\t\t\t\t\tSubmitted by: Han Liu"
 }
}