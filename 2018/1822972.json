{
 "awd_id": "1822972",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SPX: Collaborative Research: Memory Fabric: Data Management for Large-scale Hybrid Memory Systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yuanyuan Yang",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2018-07-27",
 "awd_max_amd_letter_date": "2018-07-27",
 "awd_abstract_narration": "New large-scale high performance computing systems being developed for the national labs and by US industry, combine heterogeneous memory components, accelerators and accelerator-near memory, and programmable high-performance interconnects. These memory-rich designs are attractive as they provide the compute-near-data capacity needed for improving the time to scientific discovery, and for supporting new classes of latency-sensitive data-intensive applications. However, existing software stacks are not equipped to deal with the heterogeneity and complexity of these machine designs, which impacts application performance and machine efficiency. The Memory Fabric (MF) solution developed in this project provides new abstractions and mechanisms that permit the systems software stacks to gain deeper insight into applications' data usage patterns and requirements, and to coordinate the decisions concerning how data should be distributed across different memories, or exchanged along different interconnection paths. \r\n\r\nThe Memory Fabric (MF) architecture introduces new data-centric abstractions, memory object and memory object flow, and accompanying memory and communications management methods. The higher-level information captured in the new abstractions empowers the MF runtime to better guide the underlying memory and interconnect management, and to mask the complexities of the underlying memory substrate. Additional benefits are derived from use of near-memory-fabric computation, including via dynamically inserted application-specific codes, which further specialize and accelerate the operations carried out by MF. MF is evaluated using several important application domains, including big data learning and analytics, and traditional high-performance scientific simulations. Its benefits include gains in application performance and resource efficiency, while shielding applications and application developers from the underlying machine details.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ada",
   "pi_last_name": "Gavrilovska",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ada Gavrilovska",
   "pi_email_addr": "ada@cc.gatech.edu",
   "nsf_id": "000494213",
   "pi_start_date": "2018-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Greg",
   "pi_last_name": "Eisenhauer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Greg Eisenhauer",
   "pi_email_addr": "eisen@cc.gatech.edu",
   "nsf_id": "000313459",
   "pi_start_date": "2018-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Tech Research Corporation",
  "perf_str_addr": "255 North Avenue",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320420",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 1\">\n<div class=\"section\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>The new large-scale systems being developed for the national labs and by US industry, combine heterogeneous memory components, accelerators, and accelerator-near memory, and programmable high-performance interconnects. These memory-rich designs are attractive as they provide the compute-near data capacity needed for improving the time to scientific discovery, and for supporting new classes of latency-sensitive data-intensive applications. However, existing software stacks are not equipped to deal with the heterogeneity and complexity of these machine designs, which impacts application performance and machine efficiency. </span></p>\n</div>\n</div>\n</div>\n</div>\n<p>The intellectual merit of this project lies in its contribution of a new suite of technologies, forming a solution called Memory Fabric (MF), that provides new abstractions and mechanisms that permit the systems software stacks to gain deeper insight into applications' data usage patterns and requirements and to coordinate the decisions concerning how data should be distributed across different memories, or exchanged along different interconnection paths. The specific contributions of the project include (1) new intelligent methods for managing complex, heterogeneous memory fabrics resources, that lead to order of improvement in application performance and system efficiency; (2) new mechanisms for native data structures and domain-specific runtimes that make it possible to more effectively program the underlying memory fabric resources and achieve performance and efficiency gains; (3) characterization of the impact that the emerging hardware and software stack complexity can have on real-world data-intensive and HPC workloads; and (4) new insights into the opportunities that can be achieved by leveraging new technologies for in-fabric programmability for complex application workflows and by adopting computer vision methods in system-level management of complex resources, which lead to promising new directions for future research.&nbsp;</p>\n<p>Broader impacts of this project are achieved through dissemination of the results via publications and presentations at premier international conferences, workshops and many invited industry talks, and by open-sourcing many of the software artifacts and experimental data that resulted from this research. The project supported several PhD dissertations, including of students from under-represented groups in computing. Additional visibility of the outcomes of the projects was achieved via multiple awards and recognitions, including the EECS Rising Star award for one of the project's lead PhD student participants. The project also seeded new collaborations with industry and the National Labs, thereby facilitated technology transfer and further increasing the impact of the completed research.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/01/2022<br>\n\t\t\t\t\tModified by: Ada&nbsp;Gavrilovska</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\n\n\nThe new large-scale systems being developed for the national labs and by US industry, combine heterogeneous memory components, accelerators, and accelerator-near memory, and programmable high-performance interconnects. These memory-rich designs are attractive as they provide the compute-near data capacity needed for improving the time to scientific discovery, and for supporting new classes of latency-sensitive data-intensive applications. However, existing software stacks are not equipped to deal with the heterogeneity and complexity of these machine designs, which impacts application performance and machine efficiency. \n\n\n\n\n\nThe intellectual merit of this project lies in its contribution of a new suite of technologies, forming a solution called Memory Fabric (MF), that provides new abstractions and mechanisms that permit the systems software stacks to gain deeper insight into applications' data usage patterns and requirements and to coordinate the decisions concerning how data should be distributed across different memories, or exchanged along different interconnection paths. The specific contributions of the project include (1) new intelligent methods for managing complex, heterogeneous memory fabrics resources, that lead to order of improvement in application performance and system efficiency; (2) new mechanisms for native data structures and domain-specific runtimes that make it possible to more effectively program the underlying memory fabric resources and achieve performance and efficiency gains; (3) characterization of the impact that the emerging hardware and software stack complexity can have on real-world data-intensive and HPC workloads; and (4) new insights into the opportunities that can be achieved by leveraging new technologies for in-fabric programmability for complex application workflows and by adopting computer vision methods in system-level management of complex resources, which lead to promising new directions for future research. \n\nBroader impacts of this project are achieved through dissemination of the results via publications and presentations at premier international conferences, workshops and many invited industry talks, and by open-sourcing many of the software artifacts and experimental data that resulted from this research. The project supported several PhD dissertations, including of students from under-represented groups in computing. Additional visibility of the outcomes of the projects was achieved via multiple awards and recognitions, including the EECS Rising Star award for one of the project's lead PhD student participants. The project also seeded new collaborations with industry and the National Labs, thereby facilitated technology transfer and further increasing the impact of the completed research. \n\n\t\t\t\t\tLast Modified: 02/01/2022\n\n\t\t\t\t\tSubmitted by: Ada Gavrilovska"
 }
}