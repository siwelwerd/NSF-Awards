{
 "awd_id": "1816019",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: Collaborative: ForensicExaminer: Testbed for Benchmarking Digital Audio Forensic Algorithms",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2023-01-31",
 "tot_intn_awd_amt": 291471.0,
 "awd_amount": 331471.0,
 "awd_min_amd_letter_date": "2018-09-04",
 "awd_max_amd_letter_date": "2022-07-12",
 "awd_abstract_narration": "The proliferation of powerful smart-computing devices (e.g., smartphones, surveillance systems) capable of production, editing, analysis, and sharing of multimedia files and associated technological advances have affected almost every aspect of our lives. The use of digital multimedia (images, audio, and video) as evidence is rapidly growing in multiple applications, including legal proceedings and law enforcement. However, forensic audio examiners are facing a new challenge of analyzing evidence containing audio from social networking websites, because audio editing and manipulation tools are both sophisticated and easy to use, increasing the risk of audio forgery. The goal of this project is to develop a framework and methods to support audio forensics examiners in detecting and localizing tampering in audio files, including developing novel algorithms to associate files to specific recording devices; creating methods to detect and estimate the risks of attempts to evade existing forgery detectors; evaluating speaker recognition systems in the presence of audio replay attacks; and collecting a large and diverse dataset of recordings that can be used for benchmarking of existing and future audio forensic analysis tools and techniques. The project also has a significant educational component, consisting of a set of hands-on activities involving media generation, manipulation, and analysis aimed at outreach and broadening participation in science, technology, engineering and mathematics (STEM) disciplines including forensic science, digital signal processing, and statistical data analysis and digital forensics.\r\n\r\nThe project is has four main research thrusts. The first will involve designing effective microphone fingerprint modeling and extraction algorithms tailored for audio forensic applications. The team will leverage microphone calibration methods, statistical signal processing techniques for blind microphone fingerprint estimation, and system identification methods for linking an audio recording to a specific recording device. The second thrust aims to investigate the impact of anti-forensic attacks on existing forgery detectors and replay attacks on speaker recognition systems. The research team will design attack models to perturb the underlying forgery detection feature space and analyze performance of existing and new algorithms under these anti-forensics attacks. The third research effort will be focused on designing new audio forensic analysis algorithms robust to these and other emerging anti-forensic attacks. The team will use manipulation methods for anti-forensic attacks and a game-theory-based framework for attack-aware tamper detection and design new forensic methods based on findings of these activities. The fourth research thrust will aim at developing a first-of-its-kind research commons for audio forensics consisting of benchmarking datasets, algorithms, and tools. The team will collect audio from both controlled settings and crowdsourcing in the wild, and use known audio manipulation, editing, and anti-forensic techniques to generate tampered datasets. The team will design and deploy the benchmarking testbed, ForensicExaminer, using a micro services architecture.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hafiz",
   "pi_last_name": "Malik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hafiz Malik",
   "pi_email_addr": "hafiz@umich.edu",
   "nsf_id": "000504526",
   "pi_start_date": "2018-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan - Dearborn",
  "perf_str_addr": "4901 Evergreen Rd.",
  "perf_city_name": "Dearborn",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481282406",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "MI12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 291471.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Wide spread adpontion of high-powered smart-computing devices, like smartphones, has profoundly impacted various aspects of our lives, including law enforcement and legal proceedings. These devices enable us to create, edit, analyze, and share multimedia files, driving significant technological advancements. Nowadays, digital multimedia, such as audio, video, and images, has become the standard form of evidence in litigation and criminal justice cases. However, ensuring the authenticity and integrity of this media poses significant challenges. To be admissible as evidence, digital media must be proven authentic, meaning it provides a complete record of events since its creation. Additionally, its integrity must be verified, involving the detection of any disruptions or intentional manipulations in the recording, such as insertions or compressions. This verification process becomes even more difficult when there is a lack of supporting data, like digital watermarks, and when the media has been altered with anti-forensic intent. Furthermore, the availability of powerful and user-friendly digital editing, open-source availability of generative AI algorithms and manipulation tools has further complicated the authentication and integrity verification of digital audio files.</p>\n<p>The goal of this project is to investigate microphone and acoustic environment signatures in the evidentiary recording, to investigate the impact of anti-forensic attacks on existing methods, to design robust attack-aware algorithms against anti-forensic attacks, and to develop a common platform for benchmarking audio forensics algorithms and tools. These objectives have been achieved through the creation and implementation of a following diverse range of methodologies, tools, and collaborative research platforms:&nbsp;</p>\n<ol>\n<li>In this project, we have developed several novel methods to improve the capture of microphone signatures from voice replay, voice cloning, and the algorithms used for their synthesis. We have also focused on understanding the dynamic speech variations in genuine signals and distinguishing them from spoofed samples.&nbsp;</li>\n<li>Additionally, our research has shed light on the vulnerabilities of automated speaker verification systems to AI-cloned voices and multi-order replay spoofing. Furthermore, we have explored the impact of deepfake, and recorded audio injected through LASER into MEMS microphones, and we have devised countermeasures to detect such attacks.</li>\n<li>Moreover, we have specifically crafted liveness detection techniques tailored for the purpose of speaker verification.&nbsp;</li>\n<li>Unlike other single attack-specific countermeasures, we have developed two novel unified anti-spoofing methods that can handle various attacks on automated speaker verification using a single descriptor.</li>\n<li>The existing countermeasures against AI-generated voices are unable to reliably detect unseen samples or audio generated by new AI algorithms. Therefore, we have developed a novel spoofing transformer network called SpotNet.&nbsp;</li>\n<li>Furthermore, we have developed a secure and lightweight automated speaker verification system that not only reliably authenticates speakers/users but also demonstrates resistance against multiple audio spoofing attacks. Moreover, this system possesses the capability to capture the signature of voice cloning algorithms.&nbsp;</li>\n<li>In addition, we have developed deep learning-based methods for detecting both audio and video deepfakes by capturing temporal, spatial, and inter-domain inconsistencies. Furthermore, we have created the first-ever neuro-symbolic deepfake detection framework that leverages the observation that deepfakes often exhibit inter- or intra-modality inconsistencies in the emotional expressions of the manipulated individuals.&nbsp;</li>\n<li>We have also developed a framework for securing voice-controlled devices/services, e.g., Amazon Alexa, Google Home, Apple Siri, etc., against emerging threat vectors including LASER injection&nbsp; attacks.</li>\n<li>We have created a publicly available voice spoofing detection corpus (VSDC) that includes bonafide samples as well as first-order and second-order replay samples.</li>\n<li>We have developed a research commons platform that facilitates apple-to-apple comparative analysis of state-of-the-art voice spoofing countermeasures.&nbsp;</li>\n<li>We have also investigated the impact of anti-forensic attacks on automatic speaker verification (ASV) and voice countermeasures. This investigation involved using voice samples obtained through facemasks and compressed audio samples, among other techniques.</li>\n<li>Additionally, we investigated the impact of adversarial attacks, including mole or other perturbation-based attacks, on audio-visual deepfake detection systems, and&nbsp;</li>\n<li>We have developed an approach based on game theory to enhance the security of audio-visual deepfake detection systems</li>\n</ol>\n<p>The intellectual merit of this project is its interdisciplinary approach that spans multiple domains, including cybersecurity, audio/speech processing, digital forensics, applied probability theory, and large-scale experimentation with audio data. At its core, this project involves the development of novel algorithms capable of accurately modeling and extracting the unique characteristics of acquisition devices, effectively addressing anti-forensic attacks, assessing system performance in the face of such attacks, designing forensic detectors that are resilient to these attacks, and curating comprehensive datasets for benchmarking and platform development purposes.</p>\n<p>This project has made substantial contributions with broader impacts spanning multiple domains including multimedia forensics, content integrity verificaion, civil and criminal proceedings, national security, the fintech industry, law enforcement, cyberspace, voice-activated services, and the entertainment industry.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/21/2023<br>\n\t\t\t\t\tModified by: Hafiz&nbsp;Malik</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWide spread adpontion of high-powered smart-computing devices, like smartphones, has profoundly impacted various aspects of our lives, including law enforcement and legal proceedings. These devices enable us to create, edit, analyze, and share multimedia files, driving significant technological advancements. Nowadays, digital multimedia, such as audio, video, and images, has become the standard form of evidence in litigation and criminal justice cases. However, ensuring the authenticity and integrity of this media poses significant challenges. To be admissible as evidence, digital media must be proven authentic, meaning it provides a complete record of events since its creation. Additionally, its integrity must be verified, involving the detection of any disruptions or intentional manipulations in the recording, such as insertions or compressions. This verification process becomes even more difficult when there is a lack of supporting data, like digital watermarks, and when the media has been altered with anti-forensic intent. Furthermore, the availability of powerful and user-friendly digital editing, open-source availability of generative AI algorithms and manipulation tools has further complicated the authentication and integrity verification of digital audio files.\n\nThe goal of this project is to investigate microphone and acoustic environment signatures in the evidentiary recording, to investigate the impact of anti-forensic attacks on existing methods, to design robust attack-aware algorithms against anti-forensic attacks, and to develop a common platform for benchmarking audio forensics algorithms and tools. These objectives have been achieved through the creation and implementation of a following diverse range of methodologies, tools, and collaborative research platforms: \n\nIn this project, we have developed several novel methods to improve the capture of microphone signatures from voice replay, voice cloning, and the algorithms used for their synthesis. We have also focused on understanding the dynamic speech variations in genuine signals and distinguishing them from spoofed samples. \nAdditionally, our research has shed light on the vulnerabilities of automated speaker verification systems to AI-cloned voices and multi-order replay spoofing. Furthermore, we have explored the impact of deepfake, and recorded audio injected through LASER into MEMS microphones, and we have devised countermeasures to detect such attacks.\nMoreover, we have specifically crafted liveness detection techniques tailored for the purpose of speaker verification. \nUnlike other single attack-specific countermeasures, we have developed two novel unified anti-spoofing methods that can handle various attacks on automated speaker verification using a single descriptor.\nThe existing countermeasures against AI-generated voices are unable to reliably detect unseen samples or audio generated by new AI algorithms. Therefore, we have developed a novel spoofing transformer network called SpotNet. \nFurthermore, we have developed a secure and lightweight automated speaker verification system that not only reliably authenticates speakers/users but also demonstrates resistance against multiple audio spoofing attacks. Moreover, this system possesses the capability to capture the signature of voice cloning algorithms. \nIn addition, we have developed deep learning-based methods for detecting both audio and video deepfakes by capturing temporal, spatial, and inter-domain inconsistencies. Furthermore, we have created the first-ever neuro-symbolic deepfake detection framework that leverages the observation that deepfakes often exhibit inter- or intra-modality inconsistencies in the emotional expressions of the manipulated individuals. \nWe have also developed a framework for securing voice-controlled devices/services, e.g., Amazon Alexa, Google Home, Apple Siri, etc., against emerging threat vectors including LASER injection  attacks.\nWe have created a publicly available voice spoofing detection corpus (VSDC) that includes bonafide samples as well as first-order and second-order replay samples.\nWe have developed a research commons platform that facilitates apple-to-apple comparative analysis of state-of-the-art voice spoofing countermeasures. \nWe have also investigated the impact of anti-forensic attacks on automatic speaker verification (ASV) and voice countermeasures. This investigation involved using voice samples obtained through facemasks and compressed audio samples, among other techniques.\nAdditionally, we investigated the impact of adversarial attacks, including mole or other perturbation-based attacks, on audio-visual deepfake detection systems, and \nWe have developed an approach based on game theory to enhance the security of audio-visual deepfake detection systems\n\n\nThe intellectual merit of this project is its interdisciplinary approach that spans multiple domains, including cybersecurity, audio/speech processing, digital forensics, applied probability theory, and large-scale experimentation with audio data. At its core, this project involves the development of novel algorithms capable of accurately modeling and extracting the unique characteristics of acquisition devices, effectively addressing anti-forensic attacks, assessing system performance in the face of such attacks, designing forensic detectors that are resilient to these attacks, and curating comprehensive datasets for benchmarking and platform development purposes.\n\nThis project has made substantial contributions with broader impacts spanning multiple domains including multimedia forensics, content integrity verificaion, civil and criminal proceedings, national security, the fintech industry, law enforcement, cyberspace, voice-activated services, and the entertainment industry.\n\n\t\t\t\t\tLast Modified: 06/21/2023\n\n\t\t\t\t\tSubmitted by: Hafiz Malik"
 }
}