{
 "awd_id": "1817183",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Modeling Multiple Modalities for Knowledge-Base Construction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 448001.0,
 "awd_amount": 448001.0,
 "awd_min_amd_letter_date": "2018-06-25",
 "awd_max_amd_letter_date": "2018-06-25",
 "awd_abstract_narration": "Information-rich documents are prevalent in many domains such as news articles, social media posts, online retail pages, healthcare records, financial reports, and scientific papers. Automatically extracting knowledge from such documents is useful in many applications, such as for answering questions, searching the web, automated dialogs, and analyzing trends. Existing machine learning methods focus only on the text in the documents, and ignore other information sources such as images, tables, and numbers. Thus, much of the information is not extracted, leading to incomplete knowledge and incorrect conclusions. This research advances research in machine learning and natural language processing to address these problems. With support for accurate extraction and reasoning, this project will pave the way for novel applications to domains with unstructured, multimodal documents.\r\n\r\nThe specific aim of the project is to investigate a novel construction pipeline for knowledge bases, taking the first steps in combining textual and relational evidence with numerical, image, and tabular data. To address the many interconnected challenges therein, the project focuses on two sub-tasks. First, the team will extract new facts about an entity from a document, such as its attributes, by combining the different parts (text, images, and tables). Second, the team will develop models to identify missing relations in graphs that contain multimodal facts. For each task, the project includes plans to introduce new datasets, propose benchmark evaluations, and develop appropriate baselines. Further, the team will build upon recent advances in deep neural encoders to investigate machine learning approaches that learn unified, semantic embeddings to model multimodal data. With these contributions, the project will initiate a body of research in machine learning and natural language processing that uses unstructured multimodal data in all its forms for accurate knowledge extraction.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sameer",
   "pi_last_name": "Singh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sameer Singh",
   "pi_email_addr": "sameer@uci.edu",
   "nsf_id": "000727594",
   "pi_start_date": "2018-06-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Irvine",
  "inst_street_address": "160 ALDRICH HALL",
  "inst_street_address_2": "",
  "inst_city_name": "IRVINE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9498247295",
  "inst_zip_code": "926970001",
  "inst_country_name": "United States",
  "cong_dist_code": "47",
  "st_cong_dist_code": "CA47",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA IRVINE",
  "org_prnt_uei_num": "MJC5FCYQTPE6",
  "org_uei_num": "MJC5FCYQTPE6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Irvine",
  "perf_str_addr": "4204 Donald Bren School of ICS",
  "perf_city_name": "Irvine",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "926973425",
  "perf_ctry_code": "US",
  "perf_cong_dist": "47",
  "perf_st_cong_dist": "CA47",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 448001.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-5392e36f-7fff-09ef-ab2e-a99c2bcb9668\">\n<p dir=\"ltr\"><span>Constructing a complete, accurate knowledge base is an important machine learning task due to its various applications, such as question answering, web search, intelligent agents, opinion mining, and for trend analysis. The evidence and information for constructing such knowledge bases can come from various modalities of evidence that we regularly encounter, such as textual documents,&nbsp; images, semi-structured tables, video, and audio. Without the support of reasoning over these rich sources of information, we cannot build accurate and complete models of knowledge. This project focused on contributions around research areas relevant to modeling and reasoning with text, images, and knowledge.</span></p>\n<br />\n<p dir=\"ltr\"><span>First, the team introduced several techniques focusing on link prediction when representing knowledge as graphs, with connections to multiple modalities. We proposed joint embedding models for link prediction that combine image, text, and relational structure to predict the links in the graph. We proposed novel benchmarks by extending two existing datasets, and presented the first benchmarks for this setup. We also focused on the appropriate evaluation of embeddings for entities and relations in existing KG completion benchmarks. We identified the critical shortcomings of these evaluation metrics as lack of calibration, incorrect assumptions about the data, and simple baselines that outperform recently introduced models. We gathered a semi-complete KG referred to that enables us to compute accurate triple classification accuracy on this data. Conducting thorough experiments on existing models, we provide new insights and directions for the KG completion research.</span></p>\n<br />\n<p dir=\"ltr\"><span>The team also focused on modeling the interaction between relational structure and text, i.e. how factual information from knowledge graphs is rendered in the text. Language models are increasingly becoming more effective at generating text that sounds natural; however, they could be much better at generating factual content. We introduce a unique latent-variable language model (KGLM) that uses information from knowledge bases, ensuring the generated text mirrors the facts. Another significant contribution was the development of KnowBert, an enhancement to the renowned BERT model, by infusing it with structured data from multiple knowledge bases. KnowBert, trained in an innovative multitask setting, exhibited proficiency in various tasks, from relationship extraction to word sense clarification. One of the key aspects of text and knowledge is to determine which entities appear in the text. We developed a streaming cross-document entity coreference (CDC) system that offers a robust solution for entity disambiguation in real-time data flows. Lastly, the team ventured into question-answering, pinpointing the interplay between linguistic expressions and factual knowledge. Here, the endeavor was to unearth discrepancies between language and facts, refining the process of question decomposition and response.</span></p>\n<br />\n<p dir=\"ltr\"><span>Our third set of contributions is focused on images and their interactions with text and knowledge. We introduced neural models that employ structured representations to adeptly model textual queries and extract relevant information from images. This weakly supervised semantic parsing approach, although susceptible to inaccuracies due to spurious programs, was improved upon by emphasizing output consistency for related inputs. In related work, we focused on grounded and embodied learning with a specific emphasis on natural language instruction. By segregating language, action, and vision into discrete modules in the Language, Action, and Vision (LAV) framework, we made training more efficient and demonstrated strong results on the ALFRED task for interactive instruction following. Moreover, the team also worked on the integration of text and images particularly in scientific contexts, with datasets like MedICaT that link medical images to their textual counterparts (captions). Concurrently, we introduced novel models for zero-shot localizing textual information in images, a task known as referring expression comprehension. Collectively, these contributions provide various aspects of the synergy between text and images.</span></p>\n<br />\n<p dir=\"ltr\"><span>Lastly, we focused on social media that provides a different form of text (short and noisy) but also is an increasingly relevant source of up-to-date information. Our first project in this direction focused on Tweeki, a dataset and model for linking entities mentioned in tweets to their canonical entities in knowledge sources (such as Wikipedia). With COVID disrupting our work, we also saw a rise in new forms of misinformation on social media. To address this, we also focused on developing benchmarks for misinformation detection and rumor verification. For this task, there&rsquo;s a significant need for language models to refer to canonical information and facts and use them in their detection. We develop datasets and models that refer to such ever-evolving knowledge bases (as new scientific discoveries are made) and change their predictions accordingly. Our contributions include the COVID-Lies and the COVID-RV datasets that contain annotations for rumor and misinformation for social media posts, in the context of a canonical knowledge source (collected via a collaboration with medical experts).</span></p>\n<br />\n<p dir=\"ltr\"><span>Altogether, these contributions provide several relevant benchmarks, models, and insights around reasoning and relationships in unstructured text, knowledge, and images.</span></p>\n</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/20/2023<br>\n\t\t\t\t\tModified by: Sameer&nbsp;Singh</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nConstructing a complete, accurate knowledge base is an important machine learning task due to its various applications, such as question answering, web search, intelligent agents, opinion mining, and for trend analysis. The evidence and information for constructing such knowledge bases can come from various modalities of evidence that we regularly encounter, such as textual documents,  images, semi-structured tables, video, and audio. Without the support of reasoning over these rich sources of information, we cannot build accurate and complete models of knowledge. This project focused on contributions around research areas relevant to modeling and reasoning with text, images, and knowledge.\n\n\nFirst, the team introduced several techniques focusing on link prediction when representing knowledge as graphs, with connections to multiple modalities. We proposed joint embedding models for link prediction that combine image, text, and relational structure to predict the links in the graph. We proposed novel benchmarks by extending two existing datasets, and presented the first benchmarks for this setup. We also focused on the appropriate evaluation of embeddings for entities and relations in existing KG completion benchmarks. We identified the critical shortcomings of these evaluation metrics as lack of calibration, incorrect assumptions about the data, and simple baselines that outperform recently introduced models. We gathered a semi-complete KG referred to that enables us to compute accurate triple classification accuracy on this data. Conducting thorough experiments on existing models, we provide new insights and directions for the KG completion research.\n\n\nThe team also focused on modeling the interaction between relational structure and text, i.e. how factual information from knowledge graphs is rendered in the text. Language models are increasingly becoming more effective at generating text that sounds natural; however, they could be much better at generating factual content. We introduce a unique latent-variable language model (KGLM) that uses information from knowledge bases, ensuring the generated text mirrors the facts. Another significant contribution was the development of KnowBert, an enhancement to the renowned BERT model, by infusing it with structured data from multiple knowledge bases. KnowBert, trained in an innovative multitask setting, exhibited proficiency in various tasks, from relationship extraction to word sense clarification. One of the key aspects of text and knowledge is to determine which entities appear in the text. We developed a streaming cross-document entity coreference (CDC) system that offers a robust solution for entity disambiguation in real-time data flows. Lastly, the team ventured into question-answering, pinpointing the interplay between linguistic expressions and factual knowledge. Here, the endeavor was to unearth discrepancies between language and facts, refining the process of question decomposition and response.\n\n\nOur third set of contributions is focused on images and their interactions with text and knowledge. We introduced neural models that employ structured representations to adeptly model textual queries and extract relevant information from images. This weakly supervised semantic parsing approach, although susceptible to inaccuracies due to spurious programs, was improved upon by emphasizing output consistency for related inputs. In related work, we focused on grounded and embodied learning with a specific emphasis on natural language instruction. By segregating language, action, and vision into discrete modules in the Language, Action, and Vision (LAV) framework, we made training more efficient and demonstrated strong results on the ALFRED task for interactive instruction following. Moreover, the team also worked on the integration of text and images particularly in scientific contexts, with datasets like MedICaT that link medical images to their textual counterparts (captions). Concurrently, we introduced novel models for zero-shot localizing textual information in images, a task known as referring expression comprehension. Collectively, these contributions provide various aspects of the synergy between text and images.\n\n\nLastly, we focused on social media that provides a different form of text (short and noisy) but also is an increasingly relevant source of up-to-date information. Our first project in this direction focused on Tweeki, a dataset and model for linking entities mentioned in tweets to their canonical entities in knowledge sources (such as Wikipedia). With COVID disrupting our work, we also saw a rise in new forms of misinformation on social media. To address this, we also focused on developing benchmarks for misinformation detection and rumor verification. For this task, there\u2019s a significant need for language models to refer to canonical information and facts and use them in their detection. We develop datasets and models that refer to such ever-evolving knowledge bases (as new scientific discoveries are made) and change their predictions accordingly. Our contributions include the COVID-Lies and the COVID-RV datasets that contain annotations for rumor and misinformation for social media posts, in the context of a canonical knowledge source (collected via a collaboration with medical experts).\n\n\nAltogether, these contributions provide several relevant benchmarks, models, and insights around reasoning and relationships in unstructured text, knowledge, and images.\n\n\n\t\t\t\t\tLast Modified: 09/20/2023\n\n\t\t\t\t\tSubmitted by: Sameer Singh"
 }
}