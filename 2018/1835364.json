{
 "awd_id": "1835364",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: NCS-FO: Discovering Dynamics in Massive-Scale Neural Datasets Using Machine Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 621897.0,
 "awd_amount": 621897.0,
 "awd_min_amd_letter_date": "2018-08-28",
 "awd_max_amd_letter_date": "2019-10-17",
 "awd_abstract_narration": "For decades, neuroscientists have recorded from single brain cells (neurons) to understand how the brain senses, makes decisions, and controls movements. We can now record from hundreds of neurons simultaneously but are still at an early stage in developing tools for determining how networks of neurons work together to perceive the world and to generate the control signals needed to produce coordinated movement. Focusing on movement, this project brings to bear the power of deep learning --- powerful new machine learning algorithms --- on the problem of understanding neural activity. Because deep learning thrives on big data, the investigators can leverage massive-scale brain recordings.  These include month-long recordings chronicling the activity of 100 neurons as a monkey goes about its daily business, or recording from thousands of neurons for hours in the mouse, each identified with an exact location in the brain and tied to the mouse's on-going behaviors. These approaches will open new windows on how neurons act together moment-by-moment to produce movement. The investigators will develop simple descriptions of the underlying processes to be shared with the public through venues including online tutorials, a new open course that will be developed at Emory University and Georgia Tech, the Atlanta Science Festival, and Atlanta's Brain Awareness Month. They will also make their data sets publicly available, and host data tutorial and modeling competitions at key scientific meetings, to accelerate progress by engaging the broader scientific community.\r\n\r\nIn the fifty years since Ed Evarts first recorded single neurons in M1 of behaving monkeys, great effort has been devoted to understanding the relation between these individual signals and movement-related signals collected during highly constrained motor behaviors performed by over-trained monkeys. In parallel, theoreticians posited that the computations performed in the brain depend critically on network-level phenomena: dynamical laws in brain circuits that constrain the activity and dictate how it evolves over time. The goal of this project is to develop a powerful new suite of tools, based on deep learning, to analyze these dynamics at unprecedented temporal and spatial scales. The investigators will leverage recordings with month-long M1 electrophysiology, EMG, and behavioral data during natural behaviors from monkeys, and vast numbers of neurons recorded with two-photon imaging from behaving mice. Novel machine learning techniques using sequential auto-encoders will enable the investigators to learn the dynamics underlying these data. This combination will provide windows into the brain's control of motor behavior that have never before been possible. The novel analytical framework developed here will be extensible from motor behaviors to higher level problems of error processing, decision making, and learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chethan",
   "pi_last_name": "Pandarinath",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chethan Pandarinath",
   "pi_email_addr": "chethan.pandarinath@emory.edu",
   "nsf_id": "000770862",
   "pi_start_date": "2018-08-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Emory University",
  "inst_street_address": "201 DOWMAN DR NE",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4047272503",
  "inst_zip_code": "303221061",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "EMORY UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "S352L5PJLMP8"
 },
 "perf_inst": {
  "perf_inst_name": "Emory University",
  "perf_str_addr": "1760 Haygood Dr Suite E104",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303221000",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "GA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "8551",
   "pgm_ref_txt": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 621897.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-a746bf4e-7fff-0b1e-744e-7e40cb8efce5\"><span>For decades, neuroscientists have recorded from single brain cells (neurons) to understand how the brain senses, makes decisions, and controls movements. We can now record from hundreds of neurons simultaneously but are still at an early stage in developing tools for determining how these neurons work together in networks to perceive the world and to generate the control signals needed to produce coordinated movement. This award supported the development of powerful new machine learning techniques to massive-scale neuroscience data. In particular, we made three major advances. First, we improved experimental techniques, by advancing our ability to record from both the brain and the muscles as a monkey moved within an unconstrained environment. This is a challenging technological problem requiring coordination of multiple sophisticated electronic systems for recording brain and muscle data, together with video recorded from cameras positioned around the environment. Second, we built upon a powerful, recent machine learning technique, to be able to apply it to an experimental technique called two-photon calcium imaging. Calcium imaging allows for recording the activity of thousands of neurons simultaneously, and is compatible with other biological techniques to identify the cell types or connection patterns of the recorded neurons. The tradeoff of this technique is that data is acquired with poorer time resolution than some other methods. Our new advances in machine learning have allowed us to push back the tradeoff between recording more neurons or recording more accurate timing data. Instead, we can now use whichever neurons we are recording at a given moment to help reconstruct the activity of the neurons we are not recording at that moment. Finally, we improved the machine learning technique itself. Previously, this technique required a great deal of care and expertise to apply it to new datasets. Here, we added the capability for the algorithm to tune itself, making it much easier to use and therefore broadening the community who can use it. In designing methods to evaluate our machine learning approaches, we produced a set of benchmarks that we hope will be adopted by the community and used widely. To this end, we are hosting a competition using these benchmarks so that the many new techniques produced by different researchers can be efficiently compared and evaluated, further speeding progress in the field.</span></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/21/2022<br>\n\t\t\t\t\tModified by: Chethan&nbsp;Pandarinath</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nFor decades, neuroscientists have recorded from single brain cells (neurons) to understand how the brain senses, makes decisions, and controls movements. We can now record from hundreds of neurons simultaneously but are still at an early stage in developing tools for determining how these neurons work together in networks to perceive the world and to generate the control signals needed to produce coordinated movement. This award supported the development of powerful new machine learning techniques to massive-scale neuroscience data. In particular, we made three major advances. First, we improved experimental techniques, by advancing our ability to record from both the brain and the muscles as a monkey moved within an unconstrained environment. This is a challenging technological problem requiring coordination of multiple sophisticated electronic systems for recording brain and muscle data, together with video recorded from cameras positioned around the environment. Second, we built upon a powerful, recent machine learning technique, to be able to apply it to an experimental technique called two-photon calcium imaging. Calcium imaging allows for recording the activity of thousands of neurons simultaneously, and is compatible with other biological techniques to identify the cell types or connection patterns of the recorded neurons. The tradeoff of this technique is that data is acquired with poorer time resolution than some other methods. Our new advances in machine learning have allowed us to push back the tradeoff between recording more neurons or recording more accurate timing data. Instead, we can now use whichever neurons we are recording at a given moment to help reconstruct the activity of the neurons we are not recording at that moment. Finally, we improved the machine learning technique itself. Previously, this technique required a great deal of care and expertise to apply it to new datasets. Here, we added the capability for the algorithm to tune itself, making it much easier to use and therefore broadening the community who can use it. In designing methods to evaluate our machine learning approaches, we produced a set of benchmarks that we hope will be adopted by the community and used widely. To this end, we are hosting a competition using these benchmarks so that the many new techniques produced by different researchers can be efficiently compared and evaluated, further speeding progress in the field.\n\n\t\t\t\t\tLast Modified: 12/21/2022\n\n\t\t\t\t\tSubmitted by: Chethan Pandarinath"
 }
}