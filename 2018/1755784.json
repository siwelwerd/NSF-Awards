{
 "awd_id": "1755784",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: CPS: Cognitive Trust in Human-Autonomous Vehicle Interactions",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928950",
 "po_email": "rwachter@nsf.gov",
 "po_sign_block_name": "Ralph Wachter",
 "awd_eff_date": "2018-04-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2018-03-07",
 "awd_max_amd_letter_date": "2021-12-14",
 "awd_abstract_narration": "This goal of this research is to create new techniques for advancing our understanding of the role of trust within human-autonomous vehicle interactions and assisting in the design of safe and trustworthy autonomy into future vehicles. We are witnessing accelerating technological advances in autonomous vehicles. As the degree of autonomy of vehicles increases and the nature of human-autonomy interactions becomes more complex, key questions that need to be asked are how to ensure safety and trust in human-autonomous vehicle interactions. On the one hand, high-profile incidents make clear the risks from \"overtrust\" or over-reliance on autonomous vehicles. On the other hand, \"undertrust\" may cause the neglect or under-utilization of automation. This work will be integrated into the graduate and undergraduate education on cyber-physical systems, as well as various Science, Technology, Engineering and Mathematics (STEM) outreach programs for K-12 students.\r\n\r\nThe approach is to develop languages and algorithms for formally expressing and reasoning about trust in human-autonomous vehicle interactions. This includes new models that can represent a human's trust in autonomous vehicles, together with new formal methods that can use these models in a tractable manner to verify trust requirements. The key innovations include new methods to measure trust based on multi-modal sensing of human cognitive and physiological states, new methods to express and verify trust-based specifications, and new methods to explain trust-based decisions in human-autonomy interactions. If successful, this research will allow the formalization of trust in human-autonomous vehicle interactions and the design of autonomous vehicles that establish appropriate levels of trust.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lu",
   "pi_last_name": "Feng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lu Feng",
   "pi_email_addr": "lf9u@virginia.edu",
   "nsf_id": "000724241",
   "pi_start_date": "2018-03-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Virginia Main Campus",
  "inst_street_address": "1001 EMMET ST N",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTESVILLE",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "4349244270",
  "inst_zip_code": "229034833",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "VA05",
  "org_lgl_bus_name": "RECTOR & VISITORS OF THE UNIVERSITY OF VIRGINIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJG6HU8PA4S5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Virginia",
  "perf_str_addr": "85 Engineer's Way",
  "perf_city_name": "Charlottesville",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "229044740",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "VA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "026y00",
   "pgm_ele_name": "CRII CISE Research Initiation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Recent years have witnessed significant advances in the development of automated vehicles, which have already been tested over millions of miles on public roads. However, fully autonomous vehicles that do not require human intervention are still decades away due to technology, infrastructure, and regulation limitations. Most automated vehicles available to the general public nowadays are Levels 2 and 3 of automation, which allow the driver to turn attention away from the primary task of driving, but the driver must still be prepared to take over control of the vehicle when necessary. The human&rsquo;s decision on whether to rely on the automation is guided by trust. Prior studies have found that distrust is the main barrier to the adoption of automated vehicles; in addition, users with lower trust levels take over control of the vehicle more frequently. However, overtrust in automation can lead to catastrophic outcomes such as fatal vehicle crashes. Thus, it is important to consider the influence of human trust when developing automated vehicles. The goal of this project is to design methodologies for capturing the social, trust-based decisions within human-autonomy partnerships.</p>\n<p>&nbsp;</p>\n<p><strong>Intellectual Merits.</strong>&nbsp;As a subjective mental state, human trust is difficult to measure and model. Existing methods mostly use post-experiment surveys to measure trust levels and cannot capture their dynamic changes in real-time, which is imperative for the design of automated vehicles (e.g., to decide timely intervention actions). We conducted user studies to investigate the feasibility of measuring human trust in real-time, which showed that human trust is influenced by many factors and changes over time during the human-automation interaction. Drawing on these insights, we developed the first trust-based route planning method for automated vehicles. The key innovation is that we built a data-driven trust dynamics model with user study data and incorporated it into a partially observable Markov decision process (POMDP) modeling the driver-vehicle interaction. We further extended this work to analyze the trade-offs between multiple planning objectives (e.g., trust, distance, energy consumption) via multi-objective optimization of the POMDP. In addition, one way to improve users&rsquo; trust is to increase the system transparency by providing explanations about the automation. To this end, we developed novel methods to generate contrastive explanations (e.g., why one action is taken instead of another) to help users understand vehicle planning results. Furthermore, we developed personalized driver models and context-aware advisory warnings to improve the safety and trust of semi-autonomous driving.&nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>Broad Impacts.</strong>&nbsp;The result of this project has the potential to contribute to safer and more trustworthy design of automated vehicles. We have disseminated the project findings through publications and presentations at various conferences and journals, as well as via collaboration with our industry partners at Toyota North America. Additionally, this project has provided research opportunities for multiple PhD students and undergraduate students. The results of this project have been integrated in the PI's course \"CPS: Formal Methods, Safety and Security&rdquo; at the University of Virginia, which has inspired lots of interesting classroom discussions.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/15/2022<br>\n\t\t\t\t\tModified by: Lu&nbsp;Feng</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nRecent years have witnessed significant advances in the development of automated vehicles, which have already been tested over millions of miles on public roads. However, fully autonomous vehicles that do not require human intervention are still decades away due to technology, infrastructure, and regulation limitations. Most automated vehicles available to the general public nowadays are Levels 2 and 3 of automation, which allow the driver to turn attention away from the primary task of driving, but the driver must still be prepared to take over control of the vehicle when necessary. The human\u2019s decision on whether to rely on the automation is guided by trust. Prior studies have found that distrust is the main barrier to the adoption of automated vehicles; in addition, users with lower trust levels take over control of the vehicle more frequently. However, overtrust in automation can lead to catastrophic outcomes such as fatal vehicle crashes. Thus, it is important to consider the influence of human trust when developing automated vehicles. The goal of this project is to design methodologies for capturing the social, trust-based decisions within human-autonomy partnerships.\n\n \n\nIntellectual Merits. As a subjective mental state, human trust is difficult to measure and model. Existing methods mostly use post-experiment surveys to measure trust levels and cannot capture their dynamic changes in real-time, which is imperative for the design of automated vehicles (e.g., to decide timely intervention actions). We conducted user studies to investigate the feasibility of measuring human trust in real-time, which showed that human trust is influenced by many factors and changes over time during the human-automation interaction. Drawing on these insights, we developed the first trust-based route planning method for automated vehicles. The key innovation is that we built a data-driven trust dynamics model with user study data and incorporated it into a partially observable Markov decision process (POMDP) modeling the driver-vehicle interaction. We further extended this work to analyze the trade-offs between multiple planning objectives (e.g., trust, distance, energy consumption) via multi-objective optimization of the POMDP. In addition, one way to improve users\u2019 trust is to increase the system transparency by providing explanations about the automation. To this end, we developed novel methods to generate contrastive explanations (e.g., why one action is taken instead of another) to help users understand vehicle planning results. Furthermore, we developed personalized driver models and context-aware advisory warnings to improve the safety and trust of semi-autonomous driving. \n\n \n\nBroad Impacts. The result of this project has the potential to contribute to safer and more trustworthy design of automated vehicles. We have disseminated the project findings through publications and presentations at various conferences and journals, as well as via collaboration with our industry partners at Toyota North America. Additionally, this project has provided research opportunities for multiple PhD students and undergraduate students. The results of this project have been integrated in the PI's course \"CPS: Formal Methods, Safety and Security\" at the University of Virginia, which has inspired lots of interesting classroom discussions. \n\n\t\t\t\t\tLast Modified: 12/15/2022\n\n\t\t\t\t\tSubmitted by: Lu Feng"
 }
}