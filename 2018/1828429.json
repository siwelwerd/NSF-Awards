{
 "awd_id": "1828429",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MRI: Development of an Interactive Immersive Environment that Senses and Responds to Humans",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922935",
 "po_email": "dmedhi@nsf.gov",
 "po_sign_block_name": "Deepankar Medhi",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 298783.0,
 "awd_amount": 298783.0,
 "awd_min_amd_letter_date": "2018-08-23",
 "awd_max_amd_letter_date": "2022-09-07",
 "awd_abstract_narration": "This project seeks to create a prototype immersive human-in-the loop system for sensing and responding to human emotions and behaviors. It aims to develop a prototype system that utilizes human-body based measures like heart, skin temperature, and galvanic skin response aiming to understand how a person is feeling and behaving.\r\n \r\nImmersive environments are used in various settings including physical therapy for missing limbs, storytelling for children, and design of interactive building displays for architecture professionals. Affective computing researchers have utilized immersive worlds and physiological data to interpret, understand and respond to human emotion related to healthcare decision-making, teaching programming to kids, and hostile negotiation training. This effort utilizes mixed/virtual reality headsets, interactive computing displays, and audio systems with the specific aims of increasing understanding about gestures, words, facial expressions, and other behaviors involved in design-thinking when using an immersive environment, and improving undergraduate and graduate knowledge on use of an immersive human-in-the-loop system.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gloria",
   "pi_last_name": "Washington",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Gloria J Washington",
   "pi_email_addr": "gwashington@scs.howard.edu",
   "nsf_id": "000702577",
   "pi_start_date": "2018-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Howard University",
  "inst_street_address": "2400 6TH ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "WASHINGTON",
  "inst_state_code": "DC",
  "inst_state_name": "District of Columbia",
  "inst_phone_num": "2028064759",
  "inst_zip_code": "200590002",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DC00",
  "org_lgl_bus_name": "HOWARD UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "DYZNJGLTHMR9"
 },
 "perf_inst": {
  "perf_inst_name": "Howard University",
  "perf_str_addr": "",
  "perf_city_name": "Washington",
  "perf_st_code": "DC",
  "perf_st_name": "District of Columbia",
  "perf_zip_code": "200591000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DC00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "118900",
   "pgm_ele_name": "Major Research Instrumentation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1189",
   "pgm_ref_txt": "MAJOR RESEARCH INSTRUMENTATION"
  },
  {
   "pgm_ref_code": "1594",
   "pgm_ref_txt": "HIST BLACK COLLEGES AND UNIV"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 298783.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In 2018, Howard University received a major instrumentation award #1828429 for $298,783 for the proposal entitled, &ldquo;<em>MRI: Development of an Interactive Environment that Senses and Responds to Humans</em>&rdquo; to create a physical space that utilized artificial intelligence techniques to recognize and respond to human conversations and emotions to improve productivity. The initiative focused on 1) understanding behaviors, emotions, and short-term effects of persons involved in conversations containing microaggressions in the workplace for diversity, equity, and inclusion training; 2) design-thinking for creating and sustaining innovative teams; and 3) user engagement and experience within virtual architectural structures. This project due to COVID and the constraints of in-person meetings, pivoted to creating machine learning techniques that could leverage audio and text-based techniques gathered from virtual conferencing technologies. Most notable technique that originated from this project was a creation of deep-learning techniques for capturing and tracking microaggressions<a href=\"#_ftn1\">[1]</a> and a dataset called ABL-MICRO<a href=\"#_ftn2\">[2]</a> that was created from open-source video snippets of American television shows like &ldquo;The Office&rdquo;, &ldquo;All in the Family&rdquo;, and &ldquo;The Golden Girls&rdquo;. This dataset, made available to the public, includes annotated examples of racial and sexual microaggressions for scientific researchers to leverage in their models for future identification of spoken or gesture-based microaggressions that may occur in the workplace. Additionally, this Development-focused MRI project led to comprehensive research surrounding automatic speech recognition from audio and video and the complications of this technology to accurately pick up the words of women, African, and African-American speakers<a href=\"#_ftn3\">[3]</a>. This research led to collaborations with industry to investigate smarter techniques for diversity, equity, inclusion training, improving voice assistant technologies for African-Americans, and collaborations with other academic institutions studying similar problems pertaining to uncomfortable speech. Finally, this MRI led to collaborations of use of virtual reality software for improving patient-doctor communications and for making psychiatric professionals more empathetic and understanding of their patients<a href=\"#_ftn4\">[4]</a>. Although the project experienced challenges, pivoting during the COVID-19 pandemic towards leveraging the video and audio in conferencing software led towards the success of the project.</p>\n<p>This MRI Development project also created various opportunities for Black and Brown students to learn about computing research, contribute to posters, and author their own research papers<a href=\"#_ftn5\">[5]</a>. This MRI contributed to graduating two PhD students that work at the intersection of data science and academia. &nbsp;Undergraduate and grad researchers working on the project were awarded Best Research at the CCSC Eastern Regional Conference 2021. Finally, two undergradaute students that were funded by this research received a NSF Graduate Research Fellowship and went on to pursue their PhD degrees at University of Colorado &ndash; Colorado Springs and Carnegie Mellon University. Finally two differnt undergradaute students went on to pursue their PhD degrees at the University of Washington in the<span>&nbsp;Human Centered Design &amp; Engineering Department.</span></p>\n<div><br /> \n<hr size=\"1\" />\n<div>\n<p><a href=\"#_ftnref1\">[1]</a> Ngueajio, M. K., Hernandez, I., Cornett, K., &amp; Washington, G. (2022). Towards Identification of Microaggressions in real-life and Scripted conversations, using Context-Aware Machine Learning Techniques.</p>\n</div>\n<div>\n<p><a href=\"#_ftnref2\">[2]</a> Washington, G. J., Mance, G., Aryal, S. K., &amp; Kengni, M. (2021). ABL-MICRO: Opportunities for Affective AI Built Using a Multimodal Microaggression Dataset. In&nbsp;<em>AffCon@ AAAI</em>&nbsp;(pp. 23-29).</p>\n</div>\n<div>\n<p><a href=\"#_ftnref3\">[3]</a> Ngueajio, M. K., &amp; Washington, G. (2022, June). Hey ASR system! Why aren&rsquo;t you more inclusive? Automatic speech recognition systems&rsquo; bias and proposed bias mitigation techniques. A literature review. In International Conference on Human-Computer Interaction (pp. 421-440). Cham: Springer Nature Switzerland.</p>\n</div>\n<div>\n<p><a href=\"#_ftnref4\">[4]</a> Corriette, B., Parsons, D., Alim, C., Barrett, T., Cranston, T., &amp; Washington, G. (2023, March). Using VR to Elicit Empathy in Current and Future Psychiatrists for their Patients of Color. In 2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW) (pp. 187-190). IEEE.</p>\n</div>\n<div>\n<p><a href=\"#_ftnref5\">[5]</a> Barett, T., Thompson, K., &amp; Alim, C. (2022). The Visibility Project: Virtual Reality Experience for Racial Bias Training in Psychiatry.&nbsp;<em>Journal of Computing Sciences in Colleges</em>,&nbsp;<em>38</em>(3), 214-214.</p>\n</div>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/17/2023<br>\n\t\t\t\t\tModified by: Gloria&nbsp;Washington</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn 2018, Howard University received a major instrumentation award #1828429 for $298,783 for the proposal entitled, \"MRI: Development of an Interactive Environment that Senses and Responds to Humans\" to create a physical space that utilized artificial intelligence techniques to recognize and respond to human conversations and emotions to improve productivity. The initiative focused on 1) understanding behaviors, emotions, and short-term effects of persons involved in conversations containing microaggressions in the workplace for diversity, equity, and inclusion training; 2) design-thinking for creating and sustaining innovative teams; and 3) user engagement and experience within virtual architectural structures. This project due to COVID and the constraints of in-person meetings, pivoted to creating machine learning techniques that could leverage audio and text-based techniques gathered from virtual conferencing technologies. Most notable technique that originated from this project was a creation of deep-learning techniques for capturing and tracking microaggressions[1] and a dataset called ABL-MICRO[2] that was created from open-source video snippets of American television shows like \"The Office\", \"All in the Family\", and \"The Golden Girls\". This dataset, made available to the public, includes annotated examples of racial and sexual microaggressions for scientific researchers to leverage in their models for future identification of spoken or gesture-based microaggressions that may occur in the workplace. Additionally, this Development-focused MRI project led to comprehensive research surrounding automatic speech recognition from audio and video and the complications of this technology to accurately pick up the words of women, African, and African-American speakers[3]. This research led to collaborations with industry to investigate smarter techniques for diversity, equity, inclusion training, improving voice assistant technologies for African-Americans, and collaborations with other academic institutions studying similar problems pertaining to uncomfortable speech. Finally, this MRI led to collaborations of use of virtual reality software for improving patient-doctor communications and for making psychiatric professionals more empathetic and understanding of their patients[4]. Although the project experienced challenges, pivoting during the COVID-19 pandemic towards leveraging the video and audio in conferencing software led towards the success of the project.\n\nThis MRI Development project also created various opportunities for Black and Brown students to learn about computing research, contribute to posters, and author their own research papers[5]. This MRI contributed to graduating two PhD students that work at the intersection of data science and academia.  Undergraduate and grad researchers working on the project were awarded Best Research at the CCSC Eastern Regional Conference 2021. Finally, two undergradaute students that were funded by this research received a NSF Graduate Research Fellowship and went on to pursue their PhD degrees at University of Colorado &ndash; Colorado Springs and Carnegie Mellon University. Finally two differnt undergradaute students went on to pursue their PhD degrees at the University of Washington in the Human Centered Design &amp; Engineering Department.\n\n \n\n\n\n[1] Ngueajio, M. K., Hernandez, I., Cornett, K., &amp; Washington, G. (2022). Towards Identification of Microaggressions in real-life and Scripted conversations, using Context-Aware Machine Learning Techniques.\n\n\n\n[2] Washington, G. J., Mance, G., Aryal, S. K., &amp; Kengni, M. (2021). ABL-MICRO: Opportunities for Affective AI Built Using a Multimodal Microaggression Dataset. In AffCon@ AAAI (pp. 23-29).\n\n\n\n[3] Ngueajio, M. K., &amp; Washington, G. (2022, June). Hey ASR system! Why aren\u2019t you more inclusive? Automatic speech recognition systems\u2019 bias and proposed bias mitigation techniques. A literature review. In International Conference on Human-Computer Interaction (pp. 421-440). Cham: Springer Nature Switzerland.\n\n\n\n[4] Corriette, B., Parsons, D., Alim, C., Barrett, T., Cranston, T., &amp; Washington, G. (2023, March). Using VR to Elicit Empathy in Current and Future Psychiatrists for their Patients of Color. In 2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW) (pp. 187-190). IEEE.\n\n\n\n[5] Barett, T., Thompson, K., &amp; Alim, C. (2022). The Visibility Project: Virtual Reality Experience for Racial Bias Training in Psychiatry. Journal of Computing Sciences in Colleges, 38(3), 214-214.\n\n\n\n\t\t\t\t\tLast Modified: 08/17/2023\n\n\t\t\t\t\tSubmitted by: Gloria Washington"
 }
}