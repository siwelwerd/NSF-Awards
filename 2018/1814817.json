{
 "awd_id": "1814817",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: Toward Fully Automated Data-Driven Analysis of Web Censorship",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 499995.0,
 "awd_amount": 499995.0,
 "awd_min_amd_letter_date": "2018-09-06",
 "awd_max_amd_letter_date": "2018-09-06",
 "awd_abstract_narration": "Different countries have very different positions concerning freedom of expression, and may be increasingly using online filtering tools for web censorship. While the research community has devoted significant attention to the problem of anonymous communication, many other aspects of censorship and anonymization have not yet been studied in detail. We do not know, for instance, whether it is possible to automatically infer which techniques censors use and which topics censors are after. Grounded in empirical measurements, this project first aims to produce quantitative models of the techniques used in practice for actual web censorship on a global scale, and of the suspected targets of censorship. Informed by these measurements, a secondary goal is to devise novel techniques to perform automated censorship data collection with minimal human involvement.  The team will integrate project findings and techniques into coursework, and, by making measurement data publicly available, will provide a useful resource to researchers in fields beyond the realm of computer security (for example, sociology or political science), as well as non-governmental organizations and policy-makers interested in freedom of speech issues. \r\n\r\nAt a technical level, the project will identify and construct reliable and representative corpora of web pages to test for censorship, and gather measurements of censorship occurrences on a global scale and over long intervals of time. A key objective will be to minimize human involvement during data collection to reduce risk to the individuals, while still seeking to collect data from a wide mix of vantage points representing a variety countries and organizations.  This will involve developing techniques for improving geolocation of requests, combining domain name service-based measurement techniques with the use of virtual private networks and servers to increase coverage, avoiding detection by censors while taking these measurements, developing techniques to distinguish network or server errors from acts of censorship, addressing issues of cross-language access and censorship, and accounting for changes in censors' behavior over time.  The team will analyze this data to determine whether one can automatically detect the occurrence of censorship with minimal assumptions about the form censorship may take, and whether one can automatically extract the probable topic of the censored material.  Informed by these inferences around censored topics, the team will investigate the extent of keyword-based censorship in the wild, and how actual censoring practice aligns with published accounts of censor behavior from both censors themselves and from other organizations that monitor censorship.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nicolas",
   "pi_last_name": "Christin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nicolas Christin",
   "pi_email_addr": "nicolasc@andrew.cmu.edu",
   "nsf_id": "000508103",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 Forbes Ave",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 499995.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Can we design a worldwide, fully automated measurement infrastructure for Internet censorship?This is the simple, yet extremely ambitious question that this project started from.Back when we started the project, most Internet censorship measurement platforms either relied on volunteers in countries of interest, which led to strong ethical quandaries given that these volunteers could put themselves in harm's way by running afoul of local censorship laws; or used inferences from remote signals (e.g., DNS queries or BGP probes), that provided a more limited view than what the monitoring of actual connections could help discover.<br />The intellectual merit of this proposal was to attempt to see how far one could go without resorting to volunteers, while, at the same time retaining a very fine-grained (e.g., flow level) view of censorship. Our research showed that we could deploy a comprehensive measurement platform, minimizing the risk of harm to humans, by extensively resorting to virtual private servers (and virtual private networks). Our work culminated in the development of the ICLab (Internet Controls Lab) platform, and featured a number of innovations: automated validation of advertised VPN/VPS location, automatic generation of probe lists of web URLs to test for possible censorship, and automated detection of block pages, among others. Thanks to our fine-grained view of censorship, we were able to discover certain censorship techniques, and evidence inconsistencies among censorship activities within a single countries. From a dissemination standpoint, this work resulted in three major publications, with a fourth paper currently under submission.<br />The broader impacts of this work are numerous. At an immediate level, the many challenges we faced led us to use this research as an example in a graduate-level seminar on the research process. Beyond the classroom, the availability of our ICLab platform has proven of interest to many stakeholders outside the realm of computer science -- e.g., activists, journalists, political scientists, etc -- and has planted the seed for future collaborations.</p><br>\n<p>\n Last Modified: 01/30/2024<br>\nModified by: Nicolas&nbsp;Christin</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nCan we design a worldwide, fully automated measurement infrastructure for Internet censorship?This is the simple, yet extremely ambitious question that this project started from.Back when we started the project, most Internet censorship measurement platforms either relied on volunteers in countries of interest, which led to strong ethical quandaries given that these volunteers could put themselves in harm's way by running afoul of local censorship laws; or used inferences from remote signals (e.g., DNS queries or BGP probes), that provided a more limited view than what the monitoring of actual connections could help discover.\nThe intellectual merit of this proposal was to attempt to see how far one could go without resorting to volunteers, while, at the same time retaining a very fine-grained (e.g., flow level) view of censorship. Our research showed that we could deploy a comprehensive measurement platform, minimizing the risk of harm to humans, by extensively resorting to virtual private servers (and virtual private networks). Our work culminated in the development of the ICLab (Internet Controls Lab) platform, and featured a number of innovations: automated validation of advertised VPN/VPS location, automatic generation of probe lists of web URLs to test for possible censorship, and automated detection of block pages, among others. Thanks to our fine-grained view of censorship, we were able to discover certain censorship techniques, and evidence inconsistencies among censorship activities within a single countries. From a dissemination standpoint, this work resulted in three major publications, with a fourth paper currently under submission.\nThe broader impacts of this work are numerous. At an immediate level, the many challenges we faced led us to use this research as an example in a graduate-level seminar on the research process. Beyond the classroom, the availability of our ICLab platform has proven of interest to many stakeholders outside the realm of computer science -- e.g., activists, journalists, political scientists, etc -- and has planted the seed for future collaborations.\t\t\t\t\tLast Modified: 01/30/2024\n\n\t\t\t\t\tSubmitted by: NicolasChristin\n"
 }
}