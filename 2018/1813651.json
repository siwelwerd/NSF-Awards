{
 "awd_id": "1813651",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Watch One, Do One, Teach One: An Integrated Robot Architecture for Skill Transfer",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2018-08-08",
 "awd_max_amd_letter_date": "2018-08-08",
 "awd_abstract_narration": "In the last several years, robotics research has transitioned from being concerned exclusively with building fully autonomous and capable robots to include building partially-capable robots that collaborate with human partners, allowing the robot to do what robots do best and the human to do what humans do best.  This transition has been fueled by a renaissance of safe, interactive systems designed to enhance the efforts of small- and medium-scale manufacturing, and has been accompanied by a change in the way we think robots should be trained.   Learning mechanisms in which the robot operates in isolation, learning from passive observation of people performing tasks, are being replaced by mechanisms where the robot learns through collaboration with a human partner as they accomplish tasks together.  This project will seek to develop a robot architecture that allows for new skills to be taught to a robot by an expert human instructor, for the robot to then become a skilled collaborator that operates side-by-side with a human partner, and finally for the robot to teach that learned skill to a novice human student.  To achieve this goal, popular but opaque learning mechanisms will need to be abandoned in favor of novel representations that allow for rapid learning while remaining transparent to explanation during collaboration and teaching, in conjunction with a serious consideration of the mental state (the knowledge, goals, and intentions) of the human partner.  A fundamental outcome of this work will be a unified representation linking the existing literature in learning from demonstration to collaborative scenarios and scenarios involving the robot as an instructor. Thus, project outcomes will have broad impact in application domains such as collaborative manufacturing, while also enhancing our substantial investment in education and training (especially research offerings for graduate and undergraduate investigators), and will furthermore enrich the efforts to broaden participation in computing.\r\n\r\nThis effort will build upon research in three subfields and extend the state-of-the-art to address deficiencies in each:\r\n\r\n1 - Robot as Student.  Building on work from Learning from Demonstration, the team will construct robots that learn task models from humans.   However, to be useful to the other thrust areas, these models must not be opaque as many current learning techniques are.   Instead, a transparent model will allow the robot to provide and ask feedback about its performance, explain what it has learned, and to proactively ask questions that speed up learning.\r\n\r\n2 - Robot as Collaborator.  The relatively new field of Human-Robot Collaboration struggles with synchronizing task execution between human and robot partners.   By linking to models of learned task behavior and models of user intention and understanding, the team will construct systems that become proficient in negotiating task allocation, accommodating user preferences, and restoring/updating internal representations in case of errors or change of plans.\r\n\r\n3 - Robot as Teacher.  Fields including Intelligent Tutoring Systems build models of user knowledge, typically modeled using Bayesian knowledge tracing.  These models, however, simply show knowledge as known, unknown, or forgotten, and only for factual knowledge.   By linking with concrete representations of task and intent, the team will create robots that can detect, extend, or repair the mental model of a student for real-world tasks.\r\n\r\nA set of milestones across three years will culminate in a demonstration of a robot that can learn a new task, collaborate on that task, and then teach that task to others.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Brian",
   "pi_last_name": "Scassellati",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Brian M Scassellati",
   "pi_email_addr": "brian.scassellati@yale.edu",
   "nsf_id": "000197372",
   "pi_start_date": "2018-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Yale University",
  "inst_street_address": "150 MUNSON ST",
  "inst_street_address_2": "",
  "inst_city_name": "NEW HAVEN",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "2037854689",
  "inst_zip_code": "065113572",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "CT03",
  "org_lgl_bus_name": "YALE UNIV",
  "org_prnt_uei_num": "FL6GV84CKN57",
  "org_uei_num": "FL6GV84CKN57"
 },
 "perf_inst": {
  "perf_inst_name": "Yale University",
  "perf_str_addr": "AKWatson Hall",
  "perf_city_name": "New Haven",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "065208285",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "CT03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>CHS: Small: Watch One, Do One, Teach One: An Integrated Robot Architecture for Skill Transfer</p>\n<p>Brian Scassellati, Yale University</p>\n<p>The last decade of robotics research has shown remarkable progress in building both robots that learn from humans and robots that teach or tutor human students.&nbsp; However, because the technology driving these systems are fundamentally different, there has not been a system that is capable of both learning a skill from a person and then teaching that skill to another person.&nbsp; Learning systems tend to use statistics-based machine learning techniques like deep learning, which use large amounts of data and computing power to learn remarkable skills.&nbsp; However, the capabilities of these systems are hidden inside of complex data structures and cannot be easily explained or summarized to a student.&nbsp; Teaching systems tend to use rule-based methods to memorize specific statements but learning these rules from interactions with people can be challenging.&nbsp; Our project focused on building a robot architecture that allows for new skills to be taught to a robot by an expert human instructor, for the robot to then become a skilled collaborator who operates side-by-side with a human partner, and finally for the robot to teach that learned skill to a novice human student. Our holistic, end-to-end proposition requires that we abandon popular but opaque learning mechanisms in favor of novel representations that allow for rapid learning while remaining transparent to explanation during collaboration and teaching. This architecture also requires a serious consideration of the mental state (the knowledge, goals, and intentions) of the human partner.</p>\n<p>In human learning, the method of having a student teach others has been shown to deepen their understanding of the material, improve later recall, and to speed up the learning process.&nbsp; Surgeons are trained using this technique under the adage of ?See One, Do One, Teach One,? and requires medical students to learn, perform, and teach a procedure to be considered proficient.</p>\n<p>We succeeded in developing a novel learning system that focused on teaching musical concepts using a glockenspiel.&nbsp; An expert human instructor taught the robot to play three-note musical harmonies by watching the instructor demonstrate these chords.&nbsp; Once the robot had learned to produce these harmonies, it could play alongside with a human percussionist to complete harmonies.&nbsp; The robot then was able to teach a novice human, who had no understanding of music theory, the rules underlying the harmonic scale.&nbsp; We demonstrated this robot with dozens of expert and novice pairs.&nbsp;</p>\n<p>Our project also has been instrumental in training a new generation of computer science students, including four doctoral students and more than 15 undergraduate students.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/10/2023<br>\n\t\t\t\t\tModified by: Brian&nbsp;M&nbsp;Scassellati</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nCHS: Small: Watch One, Do One, Teach One: An Integrated Robot Architecture for Skill Transfer\n\nBrian Scassellati, Yale University\n\nThe last decade of robotics research has shown remarkable progress in building both robots that learn from humans and robots that teach or tutor human students.  However, because the technology driving these systems are fundamentally different, there has not been a system that is capable of both learning a skill from a person and then teaching that skill to another person.  Learning systems tend to use statistics-based machine learning techniques like deep learning, which use large amounts of data and computing power to learn remarkable skills.  However, the capabilities of these systems are hidden inside of complex data structures and cannot be easily explained or summarized to a student.  Teaching systems tend to use rule-based methods to memorize specific statements but learning these rules from interactions with people can be challenging.  Our project focused on building a robot architecture that allows for new skills to be taught to a robot by an expert human instructor, for the robot to then become a skilled collaborator who operates side-by-side with a human partner, and finally for the robot to teach that learned skill to a novice human student. Our holistic, end-to-end proposition requires that we abandon popular but opaque learning mechanisms in favor of novel representations that allow for rapid learning while remaining transparent to explanation during collaboration and teaching. This architecture also requires a serious consideration of the mental state (the knowledge, goals, and intentions) of the human partner.\n\nIn human learning, the method of having a student teach others has been shown to deepen their understanding of the material, improve later recall, and to speed up the learning process.  Surgeons are trained using this technique under the adage of ?See One, Do One, Teach One,? and requires medical students to learn, perform, and teach a procedure to be considered proficient.\n\nWe succeeded in developing a novel learning system that focused on teaching musical concepts using a glockenspiel.  An expert human instructor taught the robot to play three-note musical harmonies by watching the instructor demonstrate these chords.  Once the robot had learned to produce these harmonies, it could play alongside with a human percussionist to complete harmonies.  The robot then was able to teach a novice human, who had no understanding of music theory, the rules underlying the harmonic scale.  We demonstrated this robot with dozens of expert and novice pairs. \n\nOur project also has been instrumental in training a new generation of computer science students, including four doctoral students and more than 15 undergraduate students.\n\n \n\n\t\t\t\t\tLast Modified: 07/10/2023\n\n\t\t\t\t\tSubmitted by: Brian M Scassellati"
 }
}