{
 "awd_id": "1812197",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Decision Theoretic Bayesian Computation",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2018-08-03",
 "awd_max_amd_letter_date": "2020-07-29",
 "awd_abstract_narration": "Decision-makers, whether in business, policy-making, or engineering systems, face the problem of taking action without complete knowledge of the state of the world. Examples of such situations include controlling industrial plants, maneuvering autonomous vehicles, developing new drugs, making investment decisions or staffing decisions in service systems. Modern decision-makers typically use sophisticated probabilistic models to capture uncertainty, and take optimal actions within the framework of such models. In general, the models themselves involve unknown parameters which must be estimated from data. While large datasets improve the estimation of the parameters, leading to more accurate decisions, these big-data settings also raise computational challenges that call for approximations in the estimation. Current methodology typically proceeds in two steps: (1) use the vast statistical and machine learning literature to approximately estimate model parameters, and (2) use the resulting approximations to compute the best possible action. This two-stage procedure can result in sub-optimality of actions, as the approximations computed in the first stage are not tailored to the decision-making problem in the second stage. The objective of this project is to develop and study a methodological framework for approximate computation that puts decision-making at its center, recognizing that the ultimate goal of most big-data analyses is to help decide among actions in the face of uncertainty. The project will provide tools and theory to accurately account for trade-offs between statistical accuracy, decision-theoretic utility and computational complexity, and will integrate decision-making into the computational revolution that has driven much of modern data-science. The tools and theory potentially impact a large range of data-driven decision-making problems. \r\n\r\nThis project works in the overarching framework of Bayesian statistics, where the primary object of interest is the posterior distribution over the unknown parameters and variables. The research focuses on theoretical and methodological challenges arising from approximate computation for Bayesian decision theory. The investigators consider two complementary problems, (a) Decision-theoretic variational Bayes, and (b) Robust decision-making. The former task analyzes and extends variational methods, developed in the machine learning community to approximate intractable Bayesian posterior distributions, from a decision-theoretic viewpoint. The investigators will theoretically study the optimality of such algorithms with respect to decision-making rather than prediction, and develop novel `loss-calibrated' algorithms that search for approximations using decision-theoretic, rather than inferential criteria. Task (b) recognizes that a model is always an approximation to reality, and is therefore misspecified. As a consequence, a Bayesian posterior distribution, even if calculated exactly, might not actually characterize the distribution over future observations. The investigators explore connections with approximations from the first task, and move from uncertainty about parameters and variables under a specified model, to uncertainty about the choice of model itself. They develop and analyze methodology that allows robust and principled decisions in the face of such `Knightian' uncertainty.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Vinayak",
   "pi_last_name": "Rao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Vinayak Rao",
   "pi_email_addr": "varao@purdue.edu",
   "nsf_id": "000703280",
   "pi_start_date": "2018-08-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Harsha",
   "pi_last_name": "Honnappa",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Harsha Honnappa",
   "pi_email_addr": "honnappa@purdue.edu",
   "nsf_id": "000678148",
   "pi_start_date": "2018-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "150 N University Street",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072067",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 48082.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 50263.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 51655.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project focuses largely on computational challenges with Bayesian statistics, specifically, the computation of tractable approximations to instractable Bayesian posterior distributions. The outcome of this project is a theoretical and methodological framework that incorporates decision-making into the pipeline, with the resulting \"loss-calibrated\" approximations constructed with some ultimate decision-making task in mind. This integrates decision-making into the computational revolution that has driven much of modern data-science.&nbsp;</p>\n<p>A major outcome of this work is a framework that generalizes current approaches through connections with the Donsker-Varadhan variational principle. This general framework subsumes a range of methods, including&nbsp; naive methods where the posterior is approximated first and then used in a decision-making problem, or where the optimal decisions are computed using a loss-calibrated posterior in a one-shot manner. This work also established finite sample regret bounds on decisions made in such loss-calibrated settings. The project also provided conditions for asymptotic consistency of such methods, giving conditions on the loss-function, approximating family and underlying model. This work was later extended from independent to Markovian data.</p>\n<p>A second outcome was the extension of variational methods to optimization problems with stochastic constraints on the solution. These stochastic constraints were allowed to evolve in a data-driven fashion, with the stochasticity itself approximated using variational methods. The project then provided conditions to converge on the true constraints as more data is collected, and also to converge on the true solution to the constrained optimization problem.</p>\n<p>The final outcome of this project focused on non-i.i.d. data. In addition to the work mentioned two paragraphs up, this line of work developed probably approximately correct (PAC)-style minimax sample complexity results for the offline estimation of transition kernels of discrete-time, finite-state controlled Markov chains. This work was motivated by the need for rigorous statistical inference in offline reinforcement learning (RL) and system identification problems. This is natural in the setting of learning to manage operations and service systems, and decision-making in mission-critical settings, where it is either too risky and/or uneconomical to use online RL. The work develop statistical bounds on a nonparametric estimator of the transition kernels of the controlled Markov chain, with the dependence of the bounds on the logging policy coming in the form of a natural mixing coefficient. In line with the goals of this proposal, we use the properties of the estimated transition matrix to the problem of offline policy evaluation, providing sample complexity results on the estimation of the value function of the overall system.&nbsp;<br />Work under this project with carried out with two PhD students, one from Industrial Engineering, and one from the Statistics department. The former has graduated and is currently a postdoctoral research assistant, while the latter is close to graduations and intends to remain in academia. Material from this projet has been incorporated into courses taught by both PIs, whether on computational statistics, Bayesian statistics or queuing systems. Overall, the project has formed a successful synthesis of methodology and problems from statistics and industrial engineering.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/11/2023<br>\n\t\t\t\t\tModified by: Vinayak&nbsp;Rao</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project focuses largely on computational challenges with Bayesian statistics, specifically, the computation of tractable approximations to instractable Bayesian posterior distributions. The outcome of this project is a theoretical and methodological framework that incorporates decision-making into the pipeline, with the resulting \"loss-calibrated\" approximations constructed with some ultimate decision-making task in mind. This integrates decision-making into the computational revolution that has driven much of modern data-science. \n\nA major outcome of this work is a framework that generalizes current approaches through connections with the Donsker-Varadhan variational principle. This general framework subsumes a range of methods, including  naive methods where the posterior is approximated first and then used in a decision-making problem, or where the optimal decisions are computed using a loss-calibrated posterior in a one-shot manner. This work also established finite sample regret bounds on decisions made in such loss-calibrated settings. The project also provided conditions for asymptotic consistency of such methods, giving conditions on the loss-function, approximating family and underlying model. This work was later extended from independent to Markovian data.\n\nA second outcome was the extension of variational methods to optimization problems with stochastic constraints on the solution. These stochastic constraints were allowed to evolve in a data-driven fashion, with the stochasticity itself approximated using variational methods. The project then provided conditions to converge on the true constraints as more data is collected, and also to converge on the true solution to the constrained optimization problem.\n\nThe final outcome of this project focused on non-i.i.d. data. In addition to the work mentioned two paragraphs up, this line of work developed probably approximately correct (PAC)-style minimax sample complexity results for the offline estimation of transition kernels of discrete-time, finite-state controlled Markov chains. This work was motivated by the need for rigorous statistical inference in offline reinforcement learning (RL) and system identification problems. This is natural in the setting of learning to manage operations and service systems, and decision-making in mission-critical settings, where it is either too risky and/or uneconomical to use online RL. The work develop statistical bounds on a nonparametric estimator of the transition kernels of the controlled Markov chain, with the dependence of the bounds on the logging policy coming in the form of a natural mixing coefficient. In line with the goals of this proposal, we use the properties of the estimated transition matrix to the problem of offline policy evaluation, providing sample complexity results on the estimation of the value function of the overall system. \nWork under this project with carried out with two PhD students, one from Industrial Engineering, and one from the Statistics department. The former has graduated and is currently a postdoctoral research assistant, while the latter is close to graduations and intends to remain in academia. Material from this projet has been incorporated into courses taught by both PIs, whether on computational statistics, Bayesian statistics or queuing systems. Overall, the project has formed a successful synthesis of methodology and problems from statistics and industrial engineering.\n\n\t\t\t\t\tLast Modified: 01/11/2023\n\n\t\t\t\t\tSubmitted by: Vinayak Rao"
 }
}