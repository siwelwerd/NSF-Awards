{
 "awd_id": "1837992",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: F: Collaborative Research: Moment Methods for Big Data: Modern Theory, Algorithms, and Applications",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 1000000.0,
 "awd_amount": 1000000.0,
 "awd_min_amd_letter_date": "2018-09-07",
 "awd_max_amd_letter_date": "2018-09-07",
 "awd_abstract_narration": "Modern scientific disciplines are increasingly faced with datasets of ever larger size and complexity. Experimental observations may be marred by inaccurate measurements and missing values, and the sheer volume of the output of modern high-throughput experimental procedures in the life sciences makes data processing an increasing challenge. Drawing accurate scientific inferences from such data requires developing new tools that are both theoretically sound and computationally efficient. This project aims to develop statistical methodologies for uncovering the intrinsic structure in large, complex data. The planned methods have the potential to become the default data science techniques used in many scientific and engineering disciplines. Fast, user-friendly software will be made publicly available, both for general purpose big data analysis and specific scientific applications.\r\n\r\nThe first pillar of the planned methodology is principal component analysis (PCA). The investigators are extending the use of PCA to the setting of high-dimensional observations with corrupted observations, non-Gaussian noise, and low signal-to-noise ratios. These kinds of datasets arise in problems such as cryo-electron microscopy and X-ray free electron laser imaging. This work will provide robust tools for exploratory data analysis for these problems. The second pillar of the research program is the method of moments, a classical technique for parameter estimation that the investigators have repurposed for new problems. The investigators will extend the range of applicability of the method of moments to many big data problems that exhibit certain algebraic structure. For these problems, the method of moments enables scalable and near-optimal statistical inference. Finally, the novel extensions of PCA and the method of moments will be combined to derive new near-optimal and scalable statistical inference procedures for high-dimensional problems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Amit",
   "pi_last_name": "Singer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Amit Singer",
   "pi_email_addr": "amits@math.princeton.edu",
   "nsf_id": "000312743",
   "pi_start_date": "2018-09-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442020",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 1000000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-2b770e2e-7fff-078d-33a3-e4bebaf3bfc8\"><span>Modern scientific and engineering applications are increasingly faced with massive high dimensional datasets. Principal Component Analysis (PCA) is the most widely used method for dimension reduction, enabling other downstream tasks such as classification, clustering, denoising, and modeling. PCA is used in thousands of scientific papers every year, and has played a fundamental role in many scientific breakthroughs in genomics and neuroscience. In this project we extended PCA in several important ways. Specifically, we developed new techniques and supporting theory that extend the application of PCA to handle data with missing values, non-Gaussian noise, and data transformations. In addition, we developed new denoising schemes and proved their optimality for various noise models, and provided new theoretical analysis of randomized sketching algorithms that are essential for the application of PCA to extremely large datasets. We also introduced new and improved techniques with sound theoretical guarantees for selecting the number of principal components in high dimensions with heteroscedastic noise. We have demonstrated and validated<span id=\"docs-internal-guid-4a1b68ce-7fff-60ab-a49a-49e5df340356\"><span>&nbsp;the utility and of our new methodologies on a wide range of both synthetic and experimental datasets. We were also able to provide accurate theoretical predictions for the amount of data required for certain statistical estimation problems, using the method of moments framework. The project has been extremely productive overall, resulting in over<span id=\"docs-internal-guid-a8f42bb0-7fff-c466-0952-b0d53c6a61d2\"><span>&nbsp;30 publications in peer reviewed journals and conferences, including the leading venues in statistics, applied mathematics, and signal processing.&nbsp;</span></span></span></span></span></span></p>\n<p><span id=\"docs-internal-guid-2b770e2e-7fff-078d-33a3-e4bebaf3bfc8\"><span><span id=\"docs-internal-guid-4a1b68ce-7fff-60ab-a49a-49e5df340356\"><span><span id=\"docs-internal-guid-a8f42bb0-7fff-c466-0952-b0d53c6a61d2\"><span> </span></span> </span></span></span></span></p>\n<p><span id=\"docs-internal-guid-c9497da1-7fff-98ea-786d-efeacd90d2fe\"> </span></p>\n<p dir=\"ltr\"><span>The impact of the project lies in the development of novel mathematical, statistical, and computational methods for the analysis of massive datasets. By extending existing techniques for data processing, such as PCA to the new setting of massive datasets, we significantly advance our understanding and methodology for processing large datasets. We also introduce powerful new mathematical techniques such as those based on random matrix theory for deriving statistical methods, techniques that have not been used a great deal so far, which constitutes a technical innovation.</span></p>\n<p><span id=\"docs-internal-guid-f9a529c1-7fff-c59c-4537-f0933740221a\"> </span></p>\n<p dir=\"ltr\"><span>The impact on other disciplines lies in the development of methods for processing large datasets, and the development of publicly available open source software implementations, which can be used by researchers in other areas, such as computational chemistry, neuroscience and genomics.</span></p>\n<p>The impact on the development of human resources includes the development and dissemination of skills related to the analysis of massive datasets, including their preprocessing, visualization and analysis. These skills were primarily&nbsp;developed in the students and postdocs funded, and disseminated in papers and seminars, as well as in some lectures in courses for undergraduate and graduate students.</p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p><span id=\"docs-internal-guid-c9497da1-7fff-98ea-786d-efeacd90d2fe\"><span id=\"docs-internal-guid-f9a529c1-7fff-c59c-4537-f0933740221a\">&nbsp;</span></span></p>\n<div><span><br /></span></div>\n<p dir=\"ltr\"><span><br /></span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p><span id=\"docs-internal-guid-2b770e2e-7fff-078d-33a3-e4bebaf3bfc8\"><span>&nbsp;</span></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/28/2023<br>\n\t\t\t\t\tModified by: Amit&nbsp;Singer</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nModern scientific and engineering applications are increasingly faced with massive high dimensional datasets. Principal Component Analysis (PCA) is the most widely used method for dimension reduction, enabling other downstream tasks such as classification, clustering, denoising, and modeling. PCA is used in thousands of scientific papers every year, and has played a fundamental role in many scientific breakthroughs in genomics and neuroscience. In this project we extended PCA in several important ways. Specifically, we developed new techniques and supporting theory that extend the application of PCA to handle data with missing values, non-Gaussian noise, and data transformations. In addition, we developed new denoising schemes and proved their optimality for various noise models, and provided new theoretical analysis of randomized sketching algorithms that are essential for the application of PCA to extremely large datasets. We also introduced new and improved techniques with sound theoretical guarantees for selecting the number of principal components in high dimensions with heteroscedastic noise. We have demonstrated and validated the utility and of our new methodologies on a wide range of both synthetic and experimental datasets. We were also able to provide accurate theoretical predictions for the amount of data required for certain statistical estimation problems, using the method of moments framework. The project has been extremely productive overall, resulting in over 30 publications in peer reviewed journals and conferences, including the leading venues in statistics, applied mathematics, and signal processing. \n\n  \n\n \nThe impact of the project lies in the development of novel mathematical, statistical, and computational methods for the analysis of massive datasets. By extending existing techniques for data processing, such as PCA to the new setting of massive datasets, we significantly advance our understanding and methodology for processing large datasets. We also introduce powerful new mathematical techniques such as those based on random matrix theory for deriving statistical methods, techniques that have not been used a great deal so far, which constitutes a technical innovation.\n\n \nThe impact on other disciplines lies in the development of methods for processing large datasets, and the development of publicly available open source software implementations, which can be used by researchers in other areas, such as computational chemistry, neuroscience and genomics.\n\nThe impact on the development of human resources includes the development and dissemination of skills related to the analysis of massive datasets, including their preprocessing, visualization and analysis. These skills were primarily developed in the students and postdocs funded, and disseminated in papers and seminars, as well as in some lectures in courses for undergraduate and graduate students.\n\n\n\n \n\n \n\n\n\n\n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 01/28/2023\n\n\t\t\t\t\tSubmitted by: Amit Singer"
 }
}