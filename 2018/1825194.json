{
 "awd_id": "1825194",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Video Communication Technologies in Survey Data Collection",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927269",
 "po_email": "ceavey@nsf.gov",
 "po_sign_block_name": "Cheryl Eavey",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 120805.0,
 "awd_amount": 120805.0,
 "awd_min_amd_letter_date": "2018-08-17",
 "awd_max_amd_letter_date": "2018-08-17",
 "awd_abstract_narration": "This research project will examine data quality, participation, respondent experience, and costs in two promising but not yet widely deployed survey modes that use off-the-shelf video technology and are less costly than face to face (FTF) interviews: video-mediated (VM) interviews (live two-way communication via platforms like Skype) and video self-administered (VS) interviews, in which video-recorded interviewers ask the questions and respondents answer by typing or clicking. This project will compare these measures of data quality and costs in VM and VS interviews carried out by the same professional interviewers and in conventional online (textual) self-administered questionnaires, asking the same survey questions to members of a representative sample who are randomly assigned to one of these three modes. Because VM is synchronous and \"live\" like face-to-face (FTF) interviewing, and VS is asynchronous and recorded but still projects a human face, the project's comparisons will provide new insights regarding how these decomposable aspects of human contact affect behavior and experience in surveys. The project's results will reveal the extent to which, and for whom, less costly interaction (live but remote vs. recorded) with an interviewer promotes engagement and data quality comparable to what is found in similar FTF interviews. More generally, the findings will address when and in what ways modern communication modes that reduce social presence and are less personal might be equal to or even more effective than FTF interaction. Findings from this project will provide valuable information relevant to the future of survey measurement and will be of interest to survey researchers in the Federal statistical system and other survey organizations.\r\n\r\nEven as survey data continue to be central to public policy and decision-making, survey measurement is challenged by declining response rates, increasing costs, declining trust in survey organizations, and rapidly changing communication habits among the public.  Understanding how video technologies could fit into the future of survey data collection is important both because it may meet potential respondents \"where they live\" and because it may provide a significantly lower cost alternative to FTF interviewing. There is even the potential to reach some members of the public whose location makes FTF interviewing difficult or expensive, but who may well be able to participate in a video interview (e.g., people who live in remote rural areas or members of the military deployed overseas).  In comparing data quality across these three survey modes, the project will quantify participation rates, connectivity problems, respondent compliance with the video interviewing protocol, conscientious responding (giving precise answers to numerical questions, thoughtfully differentiating answers), and disclosure of sensitive information. The project will measure the potential impact of individual interviewers, feelings of engagement with the interview, rapport with the interviewer, and respondent satisfaction. The project also will allow assessment of data collection costs across these modes.  Access to and use of video technologies are not universal, and even among those with access some are willing to engage in video interaction while others are reluctant. The project will begin to address whether and how the effects of video technologies on survey data collection differ for participants with different levels of prior experience and preference for using the technologies.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Schober",
   "pi_mid_init": "F",
   "pi_sufx_name": "",
   "pi_full_name": "Michael F Schober",
   "pi_email_addr": "schober@newschool.edu",
   "nsf_id": "000440887",
   "pi_start_date": "2018-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "The New School",
  "inst_street_address": "66 W 12TH ST",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2122295600",
  "inst_zip_code": "100118603",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "THE NEW SCHOOL",
  "org_prnt_uei_num": "YNL2H7YNMFP9",
  "org_uei_num": "YNL2H7YNMFP9"
 },
 "perf_inst": {
  "perf_inst_name": "The New School",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100118603",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "133300",
   "pgm_ele_name": "Methodology, Measuremt & Stats"
  },
  {
   "pgm_ele_code": "880000",
   "pgm_ele_name": "SCIENCE RESOURCES STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 120805.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-f4bc85e1-7fff-f494-8362-890af6451cfb\"> </span></p>\n<p dir=\"ltr\"><span>This project examined data quality, participation, respondent experience and costs in two promising but not yet widely deployed survey modes that use off-the-shelf video technology and are less costly than in-person interviews: live video interviews (live two-way communication via platforms like Zoom) and prerecorded-video interviews, in which respondents play video recordings of interviewers asking survey questions and respondents answer by typing or clicking. The primary study compared three measures of data quality, costs, and respondent experience in live video and prerecorded-video interviews carried out by the same professional interviewers and in web surveys (conventional online textual self-administered questionnaires) asking the same survey questions. 1067 participants from online panels, selected to match US population demographics (gender, race, education) and oversampled for adults older than 65, were randomly assigned to one of these three modes. A secondary goal was to explore interviewer variance (interviewer-related error) in live video vs. prerecorded-video interviews, which the assignment of respondents to interviewers in the study was designed to allow. Based on what was learned from the results and in response to changing interviewing practices resulting from COVID-19, a second study was carried out online examining factors affecting people?s reported willingness to participate in interviews conducted via live video vs. other modes.&nbsp;</span></p>\n<p>A major finding from the project is that there can be clear data quality benefits for both video modes: respondents disclosed more sensitive information and rounded less often in prerecorded video ?interviews? than in the other modes, and respondents in live video interviews straightlined less than in the other modes. These patterns are attributable to respondents younger than 65 years of age, who seemed to exploit the absence of an interviewer in the self-administered modes by answering less carefully. Irrespective of age, respondents reported significantly greater satisfaction with live video interviews than with the other modes. Contrary to potential concerns about adopting either live video mode, we saw no evidence for ?interviewer effects? (differential responding for different live or prerecorded interviewers). At least as implemented here and with these particular participants, both video modes seem viable for production survey data collection, which may be of particular value when in-person interviews are not feasible.&nbsp;&nbsp;</p>\n<p dir=\"ltr\"><span>Another major finding is that recruitment for live video interviews was particularly challenging, but once sample members agreed to participate they completed the interview at high rates and they had few technical problems. Respondents were easier to recruit for prerecorded video interviews than for live video interviews, but they broke off at high levels compared to the web survey respondents and especially compared to live video interview respondents. Evidence from respondent debriefing suggests that live video interviewing may increase people?s sense of privacy beyond in-person interviewing (mediation might provide a ?protective barrier?), and that prerecorded interviewers seem to elicit a social response akin to rapport experienced in-person.&nbsp;</span>How our findings on participation will generalize to members of a representative sample, e.g., a probability panel such as Amerispeaks or the American Trends Panel, is not yet known, and experience with and expectations about using video continue to evolve, but it is clear that continued study and focus on emerging norms will be essential as these methods are deployed.</p>\n<p dir=\"ltr\"><span>A third set of findings is that people who report enjoying live video more and finding live video more useful in other contexts are more likely to be willing to participate in a live video survey interview. This effect is moderated by the extent to which they report greater discomfort responding to a particular sensitive survey question in video than in four other modes (in person, telephone, prerecorded video, or web survey). Members of our online sample, whose usual participation is in textual web surveys, were more likely to report being willing to participate in the self-administered modes (web, prerecorded video) than interviewer-administered modes (in person, phone, live video), but the majority of respondents were at least somewhat willing to participate in a live video interview, with a few respondents preferring live video to other modes but others quite unwilling. The range of reasons for these preferences are likely to be informative about when and how video technologies are likely to be successfully deployed for survey data collection.</span></p>\n<p dir=\"ltr\"><span>During the project period, which coincided with the emerging pandemic, the team provided guidance on live video interviewing to researchers who carry out large-scale in-person surveys and who needed to consider quickly pivoting to live video interviewing for their upcoming waves of data collection (e.g., American National Election Study, European Social Survey, American Community Survey, and Panel Study of Income Dynamics Child Development Supplement). These conversations raised the team?s awareness of the need for more general guidance based on our work and to our publishing a first paper summarizing general design considerations for live video survey interviews.</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/30/2021<br>\n\t\t\t\t\tModified by: Michael&nbsp;F&nbsp;Schober</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThis project examined data quality, participation, respondent experience and costs in two promising but not yet widely deployed survey modes that use off-the-shelf video technology and are less costly than in-person interviews: live video interviews (live two-way communication via platforms like Zoom) and prerecorded-video interviews, in which respondents play video recordings of interviewers asking survey questions and respondents answer by typing or clicking. The primary study compared three measures of data quality, costs, and respondent experience in live video and prerecorded-video interviews carried out by the same professional interviewers and in web surveys (conventional online textual self-administered questionnaires) asking the same survey questions. 1067 participants from online panels, selected to match US population demographics (gender, race, education) and oversampled for adults older than 65, were randomly assigned to one of these three modes. A secondary goal was to explore interviewer variance (interviewer-related error) in live video vs. prerecorded-video interviews, which the assignment of respondents to interviewers in the study was designed to allow. Based on what was learned from the results and in response to changing interviewing practices resulting from COVID-19, a second study was carried out online examining factors affecting people?s reported willingness to participate in interviews conducted via live video vs. other modes. \n\nA major finding from the project is that there can be clear data quality benefits for both video modes: respondents disclosed more sensitive information and rounded less often in prerecorded video ?interviews? than in the other modes, and respondents in live video interviews straightlined less than in the other modes. These patterns are attributable to respondents younger than 65 years of age, who seemed to exploit the absence of an interviewer in the self-administered modes by answering less carefully. Irrespective of age, respondents reported significantly greater satisfaction with live video interviews than with the other modes. Contrary to potential concerns about adopting either live video mode, we saw no evidence for ?interviewer effects? (differential responding for different live or prerecorded interviewers). At least as implemented here and with these particular participants, both video modes seem viable for production survey data collection, which may be of particular value when in-person interviews are not feasible.  \nAnother major finding is that recruitment for live video interviews was particularly challenging, but once sample members agreed to participate they completed the interview at high rates and they had few technical problems. Respondents were easier to recruit for prerecorded video interviews than for live video interviews, but they broke off at high levels compared to the web survey respondents and especially compared to live video interview respondents. Evidence from respondent debriefing suggests that live video interviewing may increase people?s sense of privacy beyond in-person interviewing (mediation might provide a ?protective barrier?), and that prerecorded interviewers seem to elicit a social response akin to rapport experienced in-person. How our findings on participation will generalize to members of a representative sample, e.g., a probability panel such as Amerispeaks or the American Trends Panel, is not yet known, and experience with and expectations about using video continue to evolve, but it is clear that continued study and focus on emerging norms will be essential as these methods are deployed.\nA third set of findings is that people who report enjoying live video more and finding live video more useful in other contexts are more likely to be willing to participate in a live video survey interview. This effect is moderated by the extent to which they report greater discomfort responding to a particular sensitive survey question in video than in four other modes (in person, telephone, prerecorded video, or web survey). Members of our online sample, whose usual participation is in textual web surveys, were more likely to report being willing to participate in the self-administered modes (web, prerecorded video) than interviewer-administered modes (in person, phone, live video), but the majority of respondents were at least somewhat willing to participate in a live video interview, with a few respondents preferring live video to other modes but others quite unwilling. The range of reasons for these preferences are likely to be informative about when and how video technologies are likely to be successfully deployed for survey data collection.\nDuring the project period, which coincided with the emerging pandemic, the team provided guidance on live video interviewing to researchers who carry out large-scale in-person surveys and who needed to consider quickly pivoting to live video interviewing for their upcoming waves of data collection (e.g., American National Election Study, European Social Survey, American Community Survey, and Panel Study of Income Dynamics Child Development Supplement). These conversations raised the team?s awareness of the need for more general guidance based on our work and to our publishing a first paper summarizing general design considerations for live video survey interviews.\n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/30/2021\n\n\t\t\t\t\tSubmitted by: Michael F Schober"
 }
}