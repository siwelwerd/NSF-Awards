{
 "awd_id": "1813490",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Adaptive Metareasoning for Bounded Rational Agents",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928074",
 "po_email": "jdonlon@nsf.gov",
 "po_sign_block_name": "James Donlon",
 "awd_eff_date": "2018-08-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 404722.0,
 "awd_amount": 404722.0,
 "awd_min_amd_letter_date": "2018-07-23",
 "awd_max_amd_letter_date": "2018-07-23",
 "awd_abstract_narration": "Metareasoning is the process by which an intelligent agent monitors and controls its own thought processes so as to produce effective action in a timely manner.  Just as people must decide when to stop thinking and take action, AI systems also need to be able to interrupt their decision-making process and commit to an action or plan.  While people often use heuristic methods to determine the interruption time, this project offers metareasoning techniques that optimize the value of computation and stop planning when the urgency to take action outweighs the anticipated benefit of continued computation.  The project transforms the ability of researchers and practitioners to create responsive planning systems by offering easy-to-use, off-the-shelf adaptive metareasoning techniques to control them.  Additional areas of broader impact include mentoring of student researchers with special attention to underrepresented groups, a range of outreach activities to local schools, targeted activities to increase diversity in computer science, and industrial collaborations.\r\n\r\nThe approach uses planning algorithms that can be interrupted at any time, offering a tradeoff between runtime and quality of results.  To take advantage of this tradeoff, novel metareasoning techniques are developed that overcome the drawbacks of existing methods.  The key idea is to replace the reliance on extensive offline experiments by creating new ways to predict performance and adapt the prediction quickly to the specific problem instance at hand.  The project answers fundamental questions about the feasibility, efficiency, and scalability of optimizing meta-level control with minimal computational overhead.  The main contributions are: (1) online performance prediction methods for efficient meta-level control of anytime algorithms that outperform state-of-the-art methods; (2) a novel approach to create and adapt meta-level control policies online using reinforcement learning techniques; (3) extensions of the above methods to control a portfolio of anytime algorithms, allowing transitions from one algorithm to another using shared intermediate solution representations; and (4) extensions of the above methods to control the internal operation of adjustable anytime algorithms.  The team evaluates the new metareasoning techniques on complex computational tasks using a range of anytime algorithms based on different programming paradigms and demonstrates ease of use and significant performance gains relative to existing metareasoning techniques.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shlomo",
   "pi_last_name": "Zilberstein",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shlomo Zilberstein",
   "pi_email_addr": "shlomo@cs.umass.edu",
   "nsf_id": "000460242",
   "pi_start_date": "2018-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "140 Governors Drive",
  "perf_city_name": "Amherst",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010039264",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 404722.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Metareasoning is the process by which an intelligent agent monitors and controls its own \"thought processes\" so as to produce effective actions in a timely manner.</span>&nbsp;Just as people must decide when to stop thinking and take action, AI systems also need to be able to interrupt their decision-making process and commit to an action or plan. While people often use heuristic methods to determine the interruption time, this project produced<strong>&nbsp;</strong>metareasoning techniques that optimize the value of computation and stop planning when the urgency to take action outweighs the anticipated benefit of continued computation. The project transformed the ability of researchers and practitioners to create responsive planning systems by offering easy-to-use, adaptive metareasoning techniques to control them. &nbsp;</p>\n<p>To address the high computational complexity of planning under uncertainty, it is widely recognized that AI systems cannot produce perfect actions instantly, but must instead exhibit some form of&nbsp;bounded rationality&nbsp;that produces good enough results while factoring the cost of decision making into the agent's deliberation process. Such agents often rely on \"anytime algorithms\" that offer a tradeoff between runtime and quality of results. However, to exploit this tradeoff, it is necessary to develop effective&nbsp;metareasoning capabilities&nbsp;that can manage the anytime algorithm in real time. The project uncovered several drawbacks of existing metareasoning techniques and produced a comprehensive approach to overcome them. Specific outcomes include:</p>\n<ol>\n<li>An <span>efficient online performance prediction method for anytime algorithms that replaces the need to construct performance profiles via extensive offline experimentation, and thereby makes anytime algorithms more easily used in practice.</span></li>\n<li><span>A novel approach to&nbsp;create and adapt meta-level control policies&nbsp;online using model-free reinforcement learning techniques such as temporal-difference learning.</span></li>\n<li><span>An approach to use metareasoning to improve not only the performance, but also the safety of autonomous systems.</span></li>\n<li><span>A metareasoning approach using deep reinforcement learning for tuning the hyperparameters of anytime planning algorithms to optimize the time/quality tradeoff they offer, showing along the way the surprising benefits of randomly adjusting anytime weighted A*, a commonly used heuristic search algorithm.&nbsp;</span></li>\n<li><span>A metareasoning approach using deep reinforcement learning for adjusting the state abstractions of Markov Decision Processes ( MDP), using metareasoning over different abstractions in order to optimize the trade-off between MDP policy quality and computation time.</span></li>\n<li><span>An approach for ethically compliant planning to support moral autonomous systems.</span></li>\n</ol>\n<p>Overall, these results extended the scope and applicability of metareasoning in AI. Additional outcomes include training and mentoring of graduate and undergraduate students with special attention to underrepresented groups (two students involved in this project earned prestigious NSF graduate fellowships), college-level initiatives led by the PI to increase undergraduate student participation in research, and industrial collaborations that helped transition the aformentioned outcomes into practical applications.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/08/2023<br>\n\t\t\t\t\tModified by: Shlomo&nbsp;Zilberstein</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMetareasoning is the process by which an intelligent agent monitors and controls its own \"thought processes\" so as to produce effective actions in a timely manner. Just as people must decide when to stop thinking and take action, AI systems also need to be able to interrupt their decision-making process and commit to an action or plan. While people often use heuristic methods to determine the interruption time, this project produced metareasoning techniques that optimize the value of computation and stop planning when the urgency to take action outweighs the anticipated benefit of continued computation. The project transformed the ability of researchers and practitioners to create responsive planning systems by offering easy-to-use, adaptive metareasoning techniques to control them.  \n\nTo address the high computational complexity of planning under uncertainty, it is widely recognized that AI systems cannot produce perfect actions instantly, but must instead exhibit some form of bounded rationality that produces good enough results while factoring the cost of decision making into the agent's deliberation process. Such agents often rely on \"anytime algorithms\" that offer a tradeoff between runtime and quality of results. However, to exploit this tradeoff, it is necessary to develop effective metareasoning capabilities that can manage the anytime algorithm in real time. The project uncovered several drawbacks of existing metareasoning techniques and produced a comprehensive approach to overcome them. Specific outcomes include:\n\nAn efficient online performance prediction method for anytime algorithms that replaces the need to construct performance profiles via extensive offline experimentation, and thereby makes anytime algorithms more easily used in practice.\nA novel approach to create and adapt meta-level control policies online using model-free reinforcement learning techniques such as temporal-difference learning.\nAn approach to use metareasoning to improve not only the performance, but also the safety of autonomous systems.\nA metareasoning approach using deep reinforcement learning for tuning the hyperparameters of anytime planning algorithms to optimize the time/quality tradeoff they offer, showing along the way the surprising benefits of randomly adjusting anytime weighted A*, a commonly used heuristic search algorithm. \nA metareasoning approach using deep reinforcement learning for adjusting the state abstractions of Markov Decision Processes ( MDP), using metareasoning over different abstractions in order to optimize the trade-off between MDP policy quality and computation time.\nAn approach for ethically compliant planning to support moral autonomous systems.\n\n\nOverall, these results extended the scope and applicability of metareasoning in AI. Additional outcomes include training and mentoring of graduate and undergraduate students with special attention to underrepresented groups (two students involved in this project earned prestigious NSF graduate fellowships), college-level initiatives led by the PI to increase undergraduate student participation in research, and industrial collaborations that helped transition the aformentioned outcomes into practical applications.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 09/08/2023\n\n\t\t\t\t\tSubmitted by: Shlomo Zilberstein"
 }
}