{
 "awd_id": "1749376",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Multimethod Investigation of Articulatory and Perceptual Constraints on Natural Language Evolution",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032924770",
 "po_email": "rtheodor@nsf.gov",
 "po_sign_block_name": "Rachel M. Theodore",
 "awd_eff_date": "2018-05-15",
 "awd_exp_date": "2023-10-31",
 "tot_intn_awd_amt": 343977.0,
 "awd_amount": 349882.0,
 "awd_min_amd_letter_date": "2018-05-17",
 "awd_max_amd_letter_date": "2019-07-23",
 "awd_abstract_narration": "Languages change over time, such that the way we speak English now is very different than the speech patterns of elder generations and our distant ancestors. This project will exploit the visual nature of sign languages--where the body parts producing language are highly visible--to determine whether languages change so that they are easier to produce or so that they are easier to understand. In doing so, the project will address fundamental theoretical questions about language change that cannot be addressed by analyzing historical samples of spoken languages. To this end, the researchers will develop computational tools that allow 3D human body poses to be automatically extracted from 2D video. Such tools will be useful for the development of automated sign language recognition, promoting accessibility for deaf and hard-of-hearing people, and for developing automated systems for recognizing and classifying human gestures. The research will involve deaf and hard-of-hearing students, helping to increase diversity in the nation's scientific workforce.\r\n\r\nIt is well documented that sign languages change over time, and it is a commonly held belief that those changes have resulted from successive generations making language easier to perceive. However, most of this evidence has been anecdotal and descriptive and has not quantified changes in the ease of perception and production of ASL over time. The research team will take advantage of the fully visible articulators of sign languages to develop novel pose estimation algorithms that are able to automatically extract information contained in 2D video to create accurate 3D models of articulator movement during language production. The recent birth and rapid evolution of Nicaraguan Sign Language (NSL) has allowed researchers to study language change, from the beginning, on a compressed time-scale. By leveraging an existing NSL database--comprised of 2D videos from four generations of Nicaraguan signers--and utilizing these novel pose estimation algorithms, the researchers will be able to empirically assess the extent to which linguistic changes are driven by perceptual constraints imposed by the human visual system and/or articulatory constraints imposed by the musculoskeletal system. The researchers will also query lexical databases of American Sign Language to test predictions about the perceptual form of modern day ASL, and conduct behavioral studies with deaf and hearing users of ASL to test hypotheses regarding the allocation of visual attention as a result of both deafness and acquisition of a sign language. In doing so, the research will provide valuable information about how the human brain changes the tools we use (in this case, language) and the way that those tools in turn shape the function of the human brain. This will provide a more complex understanding of language change that illuminates the complex interaction between languages and the human beings that use them.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Dye",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew W Dye",
   "pi_email_addr": "mwddls@rit.edu",
   "nsf_id": "000562649",
   "pi_start_date": "2018-05-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andreas",
   "pi_last_name": "Savakis",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Andreas E Savakis",
   "pi_email_addr": "andreas.savakis@rit.edu",
   "nsf_id": "000239740",
   "pi_start_date": "2018-05-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Matt",
   "pi_last_name": "Huenerfauth",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matt Huenerfauth",
   "pi_email_addr": "matt.huenerfauth@rit.edu",
   "nsf_id": "000220138",
   "pi_start_date": "2018-05-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Corrine",
   "pi_last_name": "Occhino",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Corrine Occhino",
   "pi_email_addr": "cokccl@rit.edu",
   "nsf_id": "000753403",
   "pi_start_date": "2018-05-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rochester Institute of Tech",
  "inst_street_address": "1 LOMB MEMORIAL DR",
  "inst_street_address_2": "",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5854757987",
  "inst_zip_code": "146235603",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "ROCHESTER INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "J6TWTRKC1X14"
 },
 "perf_inst": {
  "perf_inst_name": "Rochester Institute of Tech",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146235603",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 343977.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 5905.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Languages change over time, such that the way we speak English now is very different to the speech patterns of elder generations and our distant ancestors. In this project we sought to exploit the visual nature of sign languages &ndash; where the body parts producing language are highly visible &ndash; to determine whether languages change so that they are easier to produce or so that they are easier to understand. In doing so, we aimed to address fundamental theoretical questions about language change that cannot be addressed by analyzing historical samples of spoken languages.</p>\n<p>To do so, we developed computational tools that permitted the creation 3D human body poses from 2D video recordings of American Sign Language (ASL) and Nicaraguan Sign Language (NSL). This meant that we did not have to reply upon collecting new data using motion capture technology. Rather, we were able to take advantage of existing ASL and NSL databases. Furthermore, by collaborating with computer scientists interested in computer animation of the human body, we used the 3D pose estimations to create models of signers' human skeletons and muscle mass. This allowed us to derive measurements of the effort required to produce signs.</p>\n<p>To date, we have used these new computational tools to look at individual signs. This work has allowed us to conclude that sign languages change over time in order to bring hard-to-perceive signs - those with complex hand configurations - closer to the center fo the visual field. This allows the human visual system to more easily recognize the signs. Our parallel work looking at the perceptual-attentional systems of individuals who use sign languages has suggested that using a sign language also results in more attention to the part of the visual field where signs are typically located. In other words, the language and the language user both adapt in order to increase communicative efficiency.&nbsp;</p>\n<p>Moving forward, we plan to continue to apply these computational tools to NSL narratives that have been recorded over the past few decades. This will allow us to explore the forces that change languages as they are passed along from one generation to the next. Such tools will also be necessary for the development of automated sign language recognition, promoting accessibility for deaf and hard-of-hearing people, and for developing automated systems for recognizing and classifying human gestures. In this way, the results of the work funded under this award will continue to have an impact on the ways in which researchers understand the structure, function and development of human language.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/04/2024<br>\nModified by: Matthew&nbsp;W&nbsp;Dye</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nLanguages change over time, such that the way we speak English now is very different to the speech patterns of elder generations and our distant ancestors. In this project we sought to exploit the visual nature of sign languages  where the body parts producing language are highly visible  to determine whether languages change so that they are easier to produce or so that they are easier to understand. In doing so, we aimed to address fundamental theoretical questions about language change that cannot be addressed by analyzing historical samples of spoken languages.\n\n\nTo do so, we developed computational tools that permitted the creation 3D human body poses from 2D video recordings of American Sign Language (ASL) and Nicaraguan Sign Language (NSL). This meant that we did not have to reply upon collecting new data using motion capture technology. Rather, we were able to take advantage of existing ASL and NSL databases. Furthermore, by collaborating with computer scientists interested in computer animation of the human body, we used the 3D pose estimations to create models of signers' human skeletons and muscle mass. This allowed us to derive measurements of the effort required to produce signs.\n\n\nTo date, we have used these new computational tools to look at individual signs. This work has allowed us to conclude that sign languages change over time in order to bring hard-to-perceive signs - those with complex hand configurations - closer to the center fo the visual field. This allows the human visual system to more easily recognize the signs. Our parallel work looking at the perceptual-attentional systems of individuals who use sign languages has suggested that using a sign language also results in more attention to the part of the visual field where signs are typically located. In other words, the language and the language user both adapt in order to increase communicative efficiency.\n\n\nMoving forward, we plan to continue to apply these computational tools to NSL narratives that have been recorded over the past few decades. This will allow us to explore the forces that change languages as they are passed along from one generation to the next. Such tools will also be necessary for the development of automated sign language recognition, promoting accessibility for deaf and hard-of-hearing people, and for developing automated systems for recognizing and classifying human gestures. In this way, the results of the work funded under this award will continue to have an impact on the ways in which researchers understand the structure, function and development of human language.\n\n\n\t\t\t\t\tLast Modified: 01/04/2024\n\n\t\t\t\t\tSubmitted by: MatthewWDye\n"
 }
}