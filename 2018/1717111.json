{
 "awd_id": "1717111",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III:  Small:  Creating Natural Data Visualization and Analysis Environments",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2017-11-15",
 "awd_exp_date": "2021-10-31",
 "tot_intn_awd_amt": 493752.0,
 "awd_amount": 493752.0,
 "awd_min_amd_letter_date": "2017-11-09",
 "awd_max_amd_letter_date": "2017-11-09",
 "awd_abstract_narration": "In the current data-rich era, data visualization and exploration capabilities are becoming more widely used in a variety of disciplines including business, health, education, and public policy, among others. Currently, people use visualization systems on desktop and laptop computers and typically interact via keyboard and mouse. Such interactions, while useful, pale in comparison to the natural, fluid interactions presented in futuristic feature films such as \"Minority Report\" and \"Iron Man\" where characters interact with large, projected wall displays through speech, gaze, and gesture. To move towards such futuristic interfaces, we must develop new forms of Natural User Interfaces (NUIs) employing multimodal interactions such as speech, pen, touch, gestures, gaze, and head and body movements. While no specific interaction modality may provide all desired capabilities, combinations of modalities (e.g., speech, gaze, and pen) could ideally provide a more natural, intuitive, and integrated interface experience. This project will explore, design, develop, and evaluate NUIs for data visualization and visual analytics. Developing techniques and systems that provide natural, expressive, multimodal input and interaction for multiple representations of data has the potential to broadly impact a virtually unlimited number of disciplines and areas of society. Additionally, the project will provide educational experience and research training for graduate and undergraduate students to help assist them in their careers. \r\n\r\nDrawing upon prior research on natural language and multi-touch interfaces for visualization, the research seeks to enable a next generation of powerful, expressive, and natural systems that facilitate fluid interaction with visual representations of data. While these interaction modalities harbor great potential, many research challenges exist and must be addressed. For instance, how should a system handle speech input that is ill-formed, incomplete, or ambiguous? What if an intention is misinterpreted or misunderstood? Regarding multi-touch gesture input, what are the \"best\" touch gestures to use in these interfaces? Do those gestures map well to different types of visualizations and to different display types and sizes and types? How do we make these gestures easier to discover and learn? Combining multiple input modalities may allow systems to counterbalance the weaknesses of one modality with the strengths of another (e.g., ambiguity in selection via speech can be balanced by the preciseness of touch), facilitating a naturalistic user experience. Project objectives include the design, implementation, and evaluation of multimodal interfaces to data visualization systems. In particular, the research will investigate how different interaction methods affect and enable data analysis and exploration. The project will create applications for particular data domains as well as open-source toolkits for other researchers to use in their own work. User studies will identify if and how different types of interaction (speech, touch, gesture, etc.) make analysis faster, easier to learn, and more powerful. The project website (http://www.cc.gatech.edu/gvu/ii/naturalvis) will include project information, links to resulting publications, videos, and open-source software that is produced.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Stasko",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "John T Stasko",
   "pi_email_addr": "stasko@cc.gatech.edu",
   "nsf_id": "000268564",
   "pi_start_date": "2017-11-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Ave., NW",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 493752.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Data visualizations can help people better understand, explore, and learn from data sets. By representing a data set in a visual form that is more comprehensible than a table of numbers, one can better help people take away insights and knowledge about the domain(s) of the data set.</p>\n<p>Many data visualization systems have now been built, some even with commercial success such as Tableau and PowerBI. Almost all these systems still provide a very traditional desktop computer-focused interface using a keyboard and mouse for interaction. Recent advancements in other computer form factors (small, large, and mobile) suggest trying other forms of interaction as well.</p>\n<p>In this project, we explored new types of visualization interfaces that provide a more \"natural\" style of interaction. In particular, we examined the use of touch (finger), pen, and natural language (typed and spoken) input. Our goal was to create new styles of visualization systems that would support a more fluid and efficient interaction methodology, one that would seem more natural to people and perhaps even more enjoyable to use.</p>\n<p>Our research began by studying how these new types of interaction might work and how people would react to them. We used these findings to design and implement prototype systems that embodied the new ideas. One was called Orko and it allowed people to analyze and explore network visualizations through an interface providing touch and speech. A subsequent system called DataBreeze ran on a large display and provided an interface supporting touch, pen, and speech interactions. We also ran user studies in which we evaluated how well people could use these systems and their perceptions of the interactions. Finally, we created a software toolkit to help visualization developers add natural language input capabilities to their systems.</p>\n<p>We hope that the pioneering research in this project illustrates new styles and forms of interfaces that other researchers and developers can try in their future systems. We believe that some of these ideas might make the visualization interfaces easier to use or might allow people to use them more effectively.</p>\n<p>The project has produced scientific results documented through journal articles and conference papers, as well as multiple software systems in the domains described above. The project also has trained both graduate and undergraduate students in research and teaching. Some of the students already have graduated and gone on to careers in academia and industry.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/06/2022<br>\n\t\t\t\t\tModified by: John&nbsp;T&nbsp;Stasko</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1717111/1717111_10524282_1641508684494_teaser--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1717111/1717111_10524282_1641508684494_teaser--rgov-800width.jpg\" title=\"DataBreeze\"><img src=\"/por/images/Reports/POR/2022/1717111/1717111_10524282_1641508684494_teaser--rgov-66x44.jpg\" alt=\"DataBreeze\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Interface for the DataBreeze data visualization system that allows touch, pen, and speech input to configure and control the display. Here, a user is exploring data about U.S. colleges represented through a unit visualization technique.</div>\n<div class=\"imageCredit\">John Stasko</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">John&nbsp;T&nbsp;Stasko</div>\n<div class=\"imageTitle\">DataBreeze</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nData visualizations can help people better understand, explore, and learn from data sets. By representing a data set in a visual form that is more comprehensible than a table of numbers, one can better help people take away insights and knowledge about the domain(s) of the data set.\n\nMany data visualization systems have now been built, some even with commercial success such as Tableau and PowerBI. Almost all these systems still provide a very traditional desktop computer-focused interface using a keyboard and mouse for interaction. Recent advancements in other computer form factors (small, large, and mobile) suggest trying other forms of interaction as well.\n\nIn this project, we explored new types of visualization interfaces that provide a more \"natural\" style of interaction. In particular, we examined the use of touch (finger), pen, and natural language (typed and spoken) input. Our goal was to create new styles of visualization systems that would support a more fluid and efficient interaction methodology, one that would seem more natural to people and perhaps even more enjoyable to use.\n\nOur research began by studying how these new types of interaction might work and how people would react to them. We used these findings to design and implement prototype systems that embodied the new ideas. One was called Orko and it allowed people to analyze and explore network visualizations through an interface providing touch and speech. A subsequent system called DataBreeze ran on a large display and provided an interface supporting touch, pen, and speech interactions. We also ran user studies in which we evaluated how well people could use these systems and their perceptions of the interactions. Finally, we created a software toolkit to help visualization developers add natural language input capabilities to their systems.\n\nWe hope that the pioneering research in this project illustrates new styles and forms of interfaces that other researchers and developers can try in their future systems. We believe that some of these ideas might make the visualization interfaces easier to use or might allow people to use them more effectively.\n\nThe project has produced scientific results documented through journal articles and conference papers, as well as multiple software systems in the domains described above. The project also has trained both graduate and undergraduate students in research and teaching. Some of the students already have graduated and gone on to careers in academia and industry.\n\n\t\t\t\t\tLast Modified: 01/06/2022\n\n\t\t\t\t\tSubmitted by: John T Stasko"
 }
}