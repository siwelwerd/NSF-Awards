{
 "awd_id": "1758678",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "STTR Phase II:  Autonomous Landing of Small Unmanned Aircraft Systems onto Moving Platforms",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Muralidharan Nair",
 "awd_eff_date": "2018-03-15",
 "awd_exp_date": "2021-02-28",
 "tot_intn_awd_amt": 748706.0,
 "awd_amount": 1420912.0,
 "awd_min_amd_letter_date": "2018-03-15",
 "awd_max_amd_letter_date": "2021-03-26",
 "awd_abstract_narration": "The broader impact/commercial potential of this project will enable Unmanned Aerial Systems\r\n(UAS or drones) to safely and reliably operate from moving vehicles and moving vessels at sea.\r\nThere is an immediate need for this capability in many industries. In commercial fishing, drones\r\nwill replace manned aircraft for fish-finding operations, radically reducing cost and risk. In maritime\r\nsecurity, drones will provide surveillance around ships, including locating a ?man-overboard? in\r\ntime to save the person?s life. In the oil and gas industry, drones will provide rapid-response to oil\r\nspills by mapping the location and extent of the oil slick, limiting the environmental and economic\r\ndamage. In hydrographic surveying, drones will identify and geo-locate navigation aids, at a\r\nfraction of the time and cost of current survey methods. In commercial shipping, drones will\r\ninspect and protect shipping vessels while they are underway. In the transport industry, drones\r\nwill delivery packages the ?last mile? from a delivery truck to a customer?s door. In law enforcement\r\nand border security, drones will operate from moving patrol vehicles while officers remain safe\r\nand mobile in the vehicle. These applications are currently difficult or impossible, but will become\r\nradically safer and easier with the proposed technology.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase 2 project will advance the current state\r\nof the art in UAS/drone autonomy, to enable reliable drone operations from moving vehicles and\r\nmoving vessels at sea. Shipboard landing is extremely difficult, due to the heaving and rolling of\r\nthe ship deck, potential high winds, and the high precision control required during landing. Current\r\ndrone technology does not facilitate landing on moving platforms; this prevents their use in\r\nmaritime operations, and has become the main barrier to commercialization in this sector. The\r\nproposed research will develop a vision-aided relative navigation system that combines precise\r\nair-to-ship observations with onboard sensor measurements to accurately estimate the relative\r\nstate between the drone and the ship. These relative state estimates will be used to dynamically\r\nroute and control the drone safely on to the ship deck. Technical feasibility of this approach has\r\nbeen demonstrated during the Phase I project, which included demonstration of the technology\r\nin a relevant environment. The primary goals of the Phase 2 project are to improve system\r\nreliability, expand the operational envelope, and productize our system. The plan to achieve these\r\ngoals includes scientific development paired with extensive testing, validation, and demonstration.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Gaemus",
   "pi_last_name": "Collins",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gaemus Collins",
   "pi_email_addr": "gaemus@planckaero.com",
   "nsf_id": "000704129",
   "pi_start_date": "2018-03-15",
   "pi_end_date": "2020-07-13"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Oliver",
   "pi_last_name": "Martin",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Oliver B Martin",
   "pi_email_addr": "oliver@planckaero.com",
   "nsf_id": "000832315",
   "pi_start_date": "2020-07-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "McLain",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy W McLain",
   "pi_email_addr": "mclain@byu.edu",
   "nsf_id": "000365157",
   "pi_start_date": "2018-03-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Planck Aerosystems Inc",
  "inst_street_address": "2065 KURTZ ST",
  "inst_street_address_2": "",
  "inst_city_name": "SAN DIEGO",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6192305049",
  "inst_zip_code": "921102014",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "PLANCK AEROSYSTEMS INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "FNMEBP6YMYL7"
 },
 "perf_inst": {
  "perf_inst_name": "Office of Research and Creative Activities, BYU",
  "perf_str_addr": "A-285 ASB, BYU",
  "perf_city_name": "Provo",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "846021043",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "UT03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "150500",
   "pgm_ele_name": "STTR Phase I"
  },
  {
   "pgm_ele_code": "159100",
   "pgm_ele_name": "STTR Phase II"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "019Z",
   "pgm_ref_txt": "Grad Prep APG:Enhan. Experience"
  },
  {
   "pgm_ref_code": "1591",
   "pgm_ref_txt": "STTR PHASE II"
  },
  {
   "pgm_ref_code": "165E",
   "pgm_ref_txt": "SBIR Phase IIB"
  },
  {
   "pgm_ref_code": "169E",
   "pgm_ref_txt": "SBIR Tech Enhan Partner (TECP)"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  },
  {
   "pgm_ref_code": "8034",
   "pgm_ref_txt": "Hardware Components"
  },
  {
   "pgm_ref_code": "8035",
   "pgm_ref_txt": "Hardware Devices"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 898447.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 522465.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Autonomous landing of small unmanned aircraft systems (sUAS) onto moving platforms is a deceptively difficult problem for many reasons. The difficulty of the challenge becomes more apparent when one considers manned aviation and the additional training that pilots require to land a fixed wing or rotorcraft on a ship. Doing so requires approximately three times the amount of training compared to operating the same aircraft from fixed, stationary locations. As many pilots will attest, landing on a moving platform is a mentally taxing process. A sUAS, on the other hand, cannot rely on the cognitive load of a skilled and highly training pilot. The landing must be autonomous, which means the system must be robust and intelligent. On a moving platform, no two landings are the same. The system must be able to detection conditions, predict a future state, and adjust immediately. The sUAS must quickly make decisions about what actions to take based on available information. Plus, there is very little room for error, since a mistake could result in not only a hard landing, but the aircraft ending up in the sea for a total loss. Furthermore, the autonomous landing system must be portable to a wide range of different unmanned aircraft, each of which has its own control system and dynamics. Finally, for the solution to be scalable, it must be capable of operating sUAS from vessels without certified flight decks.&nbsp;</p>\n<p><br />Despite the challenge, there is a massive value derived from an autonomous landing system for sUAS on moving platforms. It enables sUAS mission sets that are not possible without it. Missions include many areas of oceanographic research, emergency response such as search &amp; rescue and oil spill mapping, defense &amp; security operations, and logistics. The logistics application is particularly impactful, as it includes shore-to-ship and ship-to-ship transportation of cargo, documents, essential tools and equipment, and medicines that would otherwise require an arduous and costly deployment of a small boat at sea.&nbsp;</p>\n<p><br />Planck employed a vision-based localization scheme, coupled with advanced control system and artificial intelligence to address the challenge with great success. The vision-based approach has proven very reliable, and operates without GPS or other interferences. The primary focus was on performance improvements, including the ability to work at night and in fog without the need for GPS or RF beacons. Usability and interface improvements were also a major undertaking, which allowed for the technology to accommodate many different sUAS types. The project supported maturation, adaptation, testing, and integration of the technology into several products and unmanned aircraft. The integration process has been streamlined for repeatable, reliable deployment.&nbsp;</p>\n<p><br />Commercialization efforts have also proven quite successful. The technology has been used on multiple embedded products, complete sUAS, and third-party systems. End users cover many sectors: Science &amp; Research, Energy, Defense &amp; Security, and Logistics. The commercialization under this project has fostered relationships with unmanned systems and sensor manufacturers, including technology integration and demonstration opportunities for future deployment opportunities.&nbsp;</p>\n<p><br />The project?s success has broader impacts; it will contribute to the future proliferation of unmanned systems performing valuable tasks in all environments. For example, a new era of unmanned teaming is emerging, where aircraft are deployed from unmanned ground vehicles (UGV) and unmanned surface vehicles (USV). The technology provides a safe and reliable foundation for future vision-based aerial navigation, which is important for autonomous air mobility. GPS or external infrastructure will not always be available or reliable, yet air mobility platforms must be able to continue operations. This is especially true in disaster response scenarios. Autonomous docking for in-orbit refueling or servicing of geosynchronous satellites may be commonplace in the future, and this technology may pave the way. All told, the vision-based navigation technologies that were matured, adapted, and commercialized in this project will have a lasting impact across many sectors.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/31/2021<br>\n\t\t\t\t\tModified by: Oliver&nbsp;B&nbsp;Martin</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233865997_USV_UAS_Team--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233865997_USV_UAS_Team--rgov-800width.jpg\" title=\"UAS-UAV Teaming\"><img src=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233865997_USV_UAS_Team--rgov-66x44.jpg\" alt=\"UAS-UAV Teaming\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Unmanned aircraft cooperatively teamed with a unmanned vessel for port security application.</div>\n<div class=\"imageCredit\">David Twining</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Oliver&nbsp;B&nbsp;Martin</div>\n<div class=\"imageTitle\">UAS-UAV Teaming</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233940711_TetheredsUASonBoat--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233940711_TetheredsUASonBoat--rgov-800width.jpg\" title=\"Tethered UAS on a vessel\"><img src=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233940711_TetheredsUASonBoat--rgov-66x44.jpg\" alt=\"Tethered UAS on a vessel\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Tethered aircraft deployed from a moving vessel providing a persistent mobile sensor platform</div>\n<div class=\"imageCredit\">Allan Matthew</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Oliver&nbsp;B&nbsp;Martin</div>\n<div class=\"imageTitle\">Tethered UAS on a vessel</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234059824_Vision-basednavigation--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234059824_Vision-basednavigation--rgov-800width.jpg\" title=\"Vision-based navigation for UAS\"><img src=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234059824_Vision-basednavigation--rgov-66x44.jpg\" alt=\"Vision-based navigation for UAS\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Perspective from unmanned aircraft preparing to land on a small vessel at sea</div>\n<div class=\"imageCredit\">Josh Wells</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Oliver&nbsp;B&nbsp;Martin</div>\n<div class=\"imageTitle\">Vision-based navigation for UAS</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234309659_QGCformovingplatforms--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234309659_QGCformovingplatforms--rgov-800width.jpg\" title=\"User interface for mobile operations\"><img src=\"/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234309659_QGCformovingplatforms--rgov-66x44.jpg\" alt=\"User interface for mobile operations\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A graphical user interface can run on any computer or tablet device and provides vehicle-relative tools necessary for operating from moving platforms.</div>\n<div class=\"imageCredit\">Allan Matthew</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Oliver&nbsp;B&nbsp;Martin</div>\n<div class=\"imageTitle\">User interface for mobile operations</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nAutonomous landing of small unmanned aircraft systems (sUAS) onto moving platforms is a deceptively difficult problem for many reasons. The difficulty of the challenge becomes more apparent when one considers manned aviation and the additional training that pilots require to land a fixed wing or rotorcraft on a ship. Doing so requires approximately three times the amount of training compared to operating the same aircraft from fixed, stationary locations. As many pilots will attest, landing on a moving platform is a mentally taxing process. A sUAS, on the other hand, cannot rely on the cognitive load of a skilled and highly training pilot. The landing must be autonomous, which means the system must be robust and intelligent. On a moving platform, no two landings are the same. The system must be able to detection conditions, predict a future state, and adjust immediately. The sUAS must quickly make decisions about what actions to take based on available information. Plus, there is very little room for error, since a mistake could result in not only a hard landing, but the aircraft ending up in the sea for a total loss. Furthermore, the autonomous landing system must be portable to a wide range of different unmanned aircraft, each of which has its own control system and dynamics. Finally, for the solution to be scalable, it must be capable of operating sUAS from vessels without certified flight decks. \n\n\nDespite the challenge, there is a massive value derived from an autonomous landing system for sUAS on moving platforms. It enables sUAS mission sets that are not possible without it. Missions include many areas of oceanographic research, emergency response such as search &amp; rescue and oil spill mapping, defense &amp; security operations, and logistics. The logistics application is particularly impactful, as it includes shore-to-ship and ship-to-ship transportation of cargo, documents, essential tools and equipment, and medicines that would otherwise require an arduous and costly deployment of a small boat at sea. \n\n\nPlanck employed a vision-based localization scheme, coupled with advanced control system and artificial intelligence to address the challenge with great success. The vision-based approach has proven very reliable, and operates without GPS or other interferences. The primary focus was on performance improvements, including the ability to work at night and in fog without the need for GPS or RF beacons. Usability and interface improvements were also a major undertaking, which allowed for the technology to accommodate many different sUAS types. The project supported maturation, adaptation, testing, and integration of the technology into several products and unmanned aircraft. The integration process has been streamlined for repeatable, reliable deployment. \n\n\nCommercialization efforts have also proven quite successful. The technology has been used on multiple embedded products, complete sUAS, and third-party systems. End users cover many sectors: Science &amp; Research, Energy, Defense &amp; Security, and Logistics. The commercialization under this project has fostered relationships with unmanned systems and sensor manufacturers, including technology integration and demonstration opportunities for future deployment opportunities. \n\n\nThe project?s success has broader impacts; it will contribute to the future proliferation of unmanned systems performing valuable tasks in all environments. For example, a new era of unmanned teaming is emerging, where aircraft are deployed from unmanned ground vehicles (UGV) and unmanned surface vehicles (USV). The technology provides a safe and reliable foundation for future vision-based aerial navigation, which is important for autonomous air mobility. GPS or external infrastructure will not always be available or reliable, yet air mobility platforms must be able to continue operations. This is especially true in disaster response scenarios. Autonomous docking for in-orbit refueling or servicing of geosynchronous satellites may be commonplace in the future, and this technology may pave the way. All told, the vision-based navigation technologies that were matured, adapted, and commercialized in this project will have a lasting impact across many sectors. \n\n\t\t\t\t\tLast Modified: 03/31/2021\n\n\t\t\t\t\tSubmitted by: Oliver B Martin"
 }
}