{
 "awd_id": "1838017",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: F: Optimization in Federated Networks of Devices",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-01-01",
 "awd_exp_date": "2023-12-31",
 "tot_intn_awd_amt": 999391.0,
 "awd_amount": 999391.0,
 "awd_min_amd_letter_date": "2018-09-07",
 "awd_max_amd_letter_date": "2018-09-07",
 "awd_abstract_narration": "Modern networks of remote devices, such as mobile phones, wearable devices, and autonomous vehicles, generate massive amounts of data each day. This rich data has the potential to power a wide range of statistical machine learning-based applications, such as learning the activities of mobile phone users, adapting to pedestrian behavior in autonomous vehicles, predicting health events like low blood sugar from wearable devices, or detecting burglaries within smart homes. Due to the growing storage and computational power of remote devices, as well as privacy concerns associated with personal data, it is increasingly attractive to store and process data directly on each device. In the burgeoning field of \"federated learning,\" the aim is to use a central server to learn statistical models from data stored across these remote devices, while relying on substantial computation from each device. Federated learning can be naturally cast through the lens of mathematical optimization, a key component in formulating and training most machine learning models. This project focuses on tackling several of the unique statistical and systems challenges associated with federated optimization. As part of this project, a novel open-source benchmarking framework is also being developed to concretely define the research challenges in federated learning and promote reproducibility in empirical evaluations. This project involves participation from students from underrepresented populations.\r\n\t\t\t\t\r\nThe focus of this project is to develop a novel suite of optimization methods to tackle the unique challenges of learning on remote devices, including (a) expensive communication between remote devices and a central server; (b) high variability in data, computational resources, and communication bandwidth across devices; and (c) a very small fraction of remote devices participating in the training process at any one time. While numerous optimization methods in the data center setting have been proposed to tackle (a), none allow significant flexibility in terms of (b) and (c). Further, the limited number of recently introduced federated methods either lack theoretical convergence guarantees or do not adequately address these three challenges. This project aims to develop a suite of federated optimization methods to tackle these issues, specifically developing and understanding techniques for: convex optimization, non-convex optimization, and network-aware optimization. These methods will unleash the computational power of federated networks to train highly-accurate predictive models while adhering to strict systems, network, and privacy constraints. This project leverages ideas from optimization, statistics, machine learning, distributed computing, and sensor networks.  In addition to developing foundational federated optimization methods, the broader impact of this project includes the creation of a novel open-source benchmarking framework.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ameet",
   "pi_last_name": "Talwalkar",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Ameet S Talwalkar",
   "pi_email_addr": "talwalkar@cmu.edu",
   "nsf_id": "000585693",
   "pi_start_date": "2018-09-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Virginia",
   "pi_last_name": "Smith",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Virginia Smith",
   "pi_email_addr": "smithv@andrew.cmu.edu",
   "nsf_id": "000756862",
   "pi_start_date": "2018-09-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 999391.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Modern networks of remote devices, such as mobile phones, wearable devices, and smart homes, generate massive amounts of data each day. Federated learning involves training statistical models directly on these devices, and introduces statistical and systems challenges that require a fundamental departure from standard methods designed for distributed optimization in data center environments. As a result of this project, we&nbsp;</span><span>developed a suite of fundamental methods and analyses for federated optimization, tackling unique challenges of federated learning related to (a) expensive communication; (b) high variability; and (c) low participation. Our work proposed novel techniques for problems including communication-efficient federated optimization, client selection, federated hyperparameter tuning, meta-learning, and federated clustering.</span></p>\n<div title=\"Page 1\">\n<p><strong>Intellectual Merit.&nbsp;&nbsp;</strong><span>E</span><span>xploring the diverse statistical and systems challenges of federated learning necessitated the development of novel algorithms and analyses. Our work combined classical concepts from convex and non-convex optimization with distributed computing principles, and considered unique challenges that marked a departure from standard data center-centric optimization techniques. We also developed an open-source benchmarking framework, LEAF, to&nbsp;</span><span>rigorously study the</span><span>&nbsp;statistical accuracy, scalability, and on-device efficiency of our proposed methods, and popularized this benchmark with the broader community. Educationally, we identified core ideas from the research and disseminated them via undergraduate and graduate courses, as well as through seminars,&nbsp;workshops, and speaking engagements.</span></p>\n<p><strong>Broader Impact.&nbsp;&nbsp;</strong><span>The work completed via this grant developed foundational optimization primitives for federated learning, enabling new data-driven applications in heterogeneous distributed networks. The research itself is relevant to the optimization, machine learning, and distributed systems communities. Our benchmarking framework and surveys of the field are crucial assets for the broader research community to concretely define the challenges in federated learning and to promote reproducibility in empirical evaluations. The project enabled interaction between machine learning and optimization researchers, not only within the Schools of Engineering and Computer Science at CMU, but also in the global research community through&nbsp;a series of conferences, workshops, and seminars organized by the PIs. Finally, our courses have helped&nbsp;educate the next generation of students to work at the intersection of machine learning and optimization generally, and federated learning more specifically.</span></p>\n</div><br>\n<p>\n Last Modified: 02/29/2024<br>\nModified by: Virginia&nbsp;Smith</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nModern networks of remote devices, such as mobile phones, wearable devices, and smart homes, generate massive amounts of data each day. Federated learning involves training statistical models directly on these devices, and introduces statistical and systems challenges that require a fundamental departure from standard methods designed for distributed optimization in data center environments. As a result of this project, wedeveloped a suite of fundamental methods and analyses for federated optimization, tackling unique challenges of federated learning related to (a) expensive communication; (b) high variability; and (c) low participation. Our work proposed novel techniques for problems including communication-efficient federated optimization, client selection, federated hyperparameter tuning, meta-learning, and federated clustering.\n\n\n\nIntellectual Merit.Exploring the diverse statistical and systems challenges of federated learning necessitated the development of novel algorithms and analyses. Our work combined classical concepts from convex and non-convex optimization with distributed computing principles, and considered unique challenges that marked a departure from standard data center-centric optimization techniques. We also developed an open-source benchmarking framework, LEAF, torigorously study thestatistical accuracy, scalability, and on-device efficiency of our proposed methods, and popularized this benchmark with the broader community. Educationally, we identified core ideas from the research and disseminated them via undergraduate and graduate courses, as well as through seminars,workshops, and speaking engagements.\n\n\nBroader Impact.The work completed via this grant developed foundational optimization primitives for federated learning, enabling new data-driven applications in heterogeneous distributed networks. The research itself is relevant to the optimization, machine learning, and distributed systems communities. Our benchmarking framework and surveys of the field are crucial assets for the broader research community to concretely define the challenges in federated learning and to promote reproducibility in empirical evaluations. The project enabled interaction between machine learning and optimization researchers, not only within the Schools of Engineering and Computer Science at CMU, but also in the global research community througha series of conferences, workshops, and seminars organized by the PIs. Finally, our courses have helpededucate the next generation of students to work at the intersection of machine learning and optimization generally, and federated learning more specifically.\n\t\t\t\t\tLast Modified: 02/29/2024\n\n\t\t\t\t\tSubmitted by: VirginiaSmith\n"
 }
}