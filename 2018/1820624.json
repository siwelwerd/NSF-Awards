{
 "awd_id": "1820624",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: Collaborative: Exploiting Physical Properties in Wireless Networks for Implicit Authentication",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 339950.0,
 "awd_amount": 339950.0,
 "awd_min_amd_letter_date": "2017-12-18",
 "awd_max_amd_letter_date": "2017-12-18",
 "awd_abstract_narration": "The rapid development of information technology not only leads to great convenience in our daily lives, but also raises significant concerns in the field of security and privacy. Particularly, the authentication process, which serves as the first line of information security by verifying the identity of a person or device, has become increasingly critical. An unauthorized access could result in detrimental impact on both corporation and individual in both secrecy loss and privacy leakage. Unlike many existing studies on user/device authentication, which either employ specialized or expensive hardware that needs experts for installation and calibration or require users' active involvement, the emerging low-cost and unobtrusive authentication solution without the users' participation is particularly attractive to effectively complement conventional security approaches. Due to the rich wireless connectivity and unique signal characteristics in pervasive wireless environments, this project takes a different view point by exploiting unique physical properties in wireless networks to facilitate implicit authentication for both human and mobile devices. The proposed research could advance our knowledge in exploiting the physical layer information in wireless networks to capture unique physiological and behavioral characteristics from human during their daily activities. It could also enhance our understanding in developing deep learning techniques to authenticate people based on their activities in the physical environments. Additionally, the educational efforts include curriculum development, K-12 and undergraduate involvement, and underrepresented student engagement in research.\r\n\r\nThis project focuses on building a holistic framework that leverages fine-grained radio signals available from the commercial wireless networks to perform implicit user/device authentication. The proposed framework aims to advance the foundation of integrating fine-grained physical properties in wireless networks to enhance wireless security. The research reveals that the fine-grained signal properties in wireless networks are capable to capture unique physiological and behavioral characteristics from human in both stationary and mobile daily activities. The proposed framework develops smart segmentation on the wireless signals and extract unique features that enable the capability of distinguishing individual. It further develops deep learning techniques to authenticate people based on their daily activities in the physical environments. The authentication process does not require active user involvement nor require the user to wear any device. This project also develops efficient techniques to detect the presence of user spoofing and localize attackers to facilitate the employment of a broad array of defending strategies.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yingying",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yingying Chen",
   "pi_email_addr": "yingche@scarletmail.rutgers.edu",
   "nsf_id": "000080615",
   "pi_start_date": "2017-12-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers",
  "perf_str_addr": "94 Brett Road",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088543925",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "065Z",
   "pgm_ref_txt": "Human factors for security research"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 339950.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project focuses on building a holistic framework that leverages fine-grained radio signals available from the commercial wireless networks to perform implicit user/device authentication. The proposed framework aims to advance the foundation of integrating fine-grained physical properties in wireless networks to enhance wireless security. The research reveals that the fine-grained signal properties in wireless networks are capable to capture unique physiological and behavioral characteristics from human in both stationary and mobile daily activities. The proposed framework develops smart segmentation on the wireless signals and extract unique features that enable the capability of distinguishing individual. Particularly, we accomplished the following aspects. (1) PPG-based Continuous Authentication on Wrist-worn Wearable Devices. (2) Enabling Fine-Grained Finger Gesture Recognition on Commodity WiFi Devices. (3) Inferring Live Speech and Speaker Identity via Subtle Facial Dynamics Captured by AR/VR Motion.&nbsp;</p>\n<p>(1) PPG-based Continuous Authentication on Wrist-worn Wearable Devices. Traditional one-time user authentication is vulnerable to attacks when an adversary can obtain unauthorized privileges after a user&rsquo;s initial login. Continuous user authentication (CA) has recently shown its great potential by enabling seamless user authentication with few users&rsquo; participation. We devise a low-cost system that can exploit users&rsquo; pulsatile signals from photoplethysmography (PPG) sensors in commodity wearable devices to perform CA. Our system requires zero user effort and applies to practical scenarios that have non-clinical PPG measurements with human motion artifacts (MA). We explore the uniqueness of the human cardiac system and develop adaptive MA filtering methods to mitigate the impacts of transient and continuous activities from daily life. Furthermore, we identify general fiducial features and develop an adaptive classifier that can authenticate users continuously based on their cardiac characteristics with little additional training effort. Experiments with our wrist-worn PPG sensing platform on 20 participants under practical scenarios demonstrate that our system can achieve a high CA accuracy of over 90% and a low false detection rate of 4% in detecting random attacks.</p>\n<p>(2) Enabling Fine-Grained Finger Gesture Recognition on Commodity WiFi Devices. Gesture recognition has become increasingly important in human-computer interaction and can support different applications such as smart home, VR, and gaming. Traditional approaches usually rely on dedicated sensors that are worn by the user or cameras that require line of sight. In this work, we present a &#64257;ne-grained &#64257;nger gesture recognition system by using commodity WiFi without requiring user to wear any sensors. Our system takes advantages of the &#64257;ne-grained Channel State Information available from commodity WiFi devices and the prevalence of WiFi network infrastructures. It senses and identi&#64257;es subtle movements of &#64257;nger gestures by examining the unique patterns exhibited in the detailed CSI. We devise environmental noise removal mechanism to mitigate the effect of signal dynamic due to the environment changes. Moreover, we propose to capture the intrinsic gesture behavior to deal with individual diversity and gesture inconsistency. Lastly, we utilize multiple WiFi links and larger bandwidth at 5GHz to achieve &#64257;nger gesture recognition under multi-user scenario.&nbsp;</p>\n<p>(3) Inferring Live Speech and Speaker Identity via Subtle Facial Dynamics Captured by AR/VR Motion Sensors.<strong> </strong>In this project, we show a serious privacy risk of using voice interfaces while the user is wearing the face-mounted AR/VR devices. Specifically, we design an eavesdropping attack, Face-Mic, which leverages speech-associated subtle facial dynamics captured by zero-permission motion sensors in AR/VR headsets to infer highly sensitive information from live human speech, including speaker gender, identity, and speech content. Face-Mic is grounded on a key insight that AR/VR headsets are closely mounted on the user&rsquo;s face, allowing a potentially malicious app on the headset to capture underlying facial dynamics as the wearer speaks, including movements of facial muscles and bone-borne vibrations, which encode private biometrics and speech characteristics. To mitigate the impacts of body movements, we develop a signal source separation technique to identify and separate the speech-associated facial dynamics from other types of body movements. We further extract representative features with respect to the two types of facial dynamics. We successfully demonstrate privacy leakage through AR/VR headsets by deriving the user&rsquo;s gender/identity and extracting speech information via the development of a deep learning-based framework. Extensive experiments using four mainstream VR headsets validate the generalizability, effectiveness, and high accuracy of Face-Mic.</p>\n<p>The proposed research can advance our knowledge in exploiting the physical layer information in wireless networks to capture unique physiological and behavioral characteristics from human during their daily activities. It can also enhance our understanding in developing deep learning techniques to authenticate people based on their activities in the physical environments. Moreover, during the project period the PIs not only trained graduate students to conduct the research but also actively included undergraduates and high school students through research internship programs. Results are disseminated through scholarly publications, active outreach to the wireless and mobile industry through WINLAB's industry events and connections.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/29/2022<br>\n\t\t\t\t\tModified by: Yingying&nbsp;Chen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project focuses on building a holistic framework that leverages fine-grained radio signals available from the commercial wireless networks to perform implicit user/device authentication. The proposed framework aims to advance the foundation of integrating fine-grained physical properties in wireless networks to enhance wireless security. The research reveals that the fine-grained signal properties in wireless networks are capable to capture unique physiological and behavioral characteristics from human in both stationary and mobile daily activities. The proposed framework develops smart segmentation on the wireless signals and extract unique features that enable the capability of distinguishing individual. Particularly, we accomplished the following aspects. (1) PPG-based Continuous Authentication on Wrist-worn Wearable Devices. (2) Enabling Fine-Grained Finger Gesture Recognition on Commodity WiFi Devices. (3) Inferring Live Speech and Speaker Identity via Subtle Facial Dynamics Captured by AR/VR Motion. \n\n(1) PPG-based Continuous Authentication on Wrist-worn Wearable Devices. Traditional one-time user authentication is vulnerable to attacks when an adversary can obtain unauthorized privileges after a user\u2019s initial login. Continuous user authentication (CA) has recently shown its great potential by enabling seamless user authentication with few users\u2019 participation. We devise a low-cost system that can exploit users\u2019 pulsatile signals from photoplethysmography (PPG) sensors in commodity wearable devices to perform CA. Our system requires zero user effort and applies to practical scenarios that have non-clinical PPG measurements with human motion artifacts (MA). We explore the uniqueness of the human cardiac system and develop adaptive MA filtering methods to mitigate the impacts of transient and continuous activities from daily life. Furthermore, we identify general fiducial features and develop an adaptive classifier that can authenticate users continuously based on their cardiac characteristics with little additional training effort. Experiments with our wrist-worn PPG sensing platform on 20 participants under practical scenarios demonstrate that our system can achieve a high CA accuracy of over 90% and a low false detection rate of 4% in detecting random attacks.\n\n(2) Enabling Fine-Grained Finger Gesture Recognition on Commodity WiFi Devices. Gesture recognition has become increasingly important in human-computer interaction and can support different applications such as smart home, VR, and gaming. Traditional approaches usually rely on dedicated sensors that are worn by the user or cameras that require line of sight. In this work, we present a &#64257;ne-grained &#64257;nger gesture recognition system by using commodity WiFi without requiring user to wear any sensors. Our system takes advantages of the &#64257;ne-grained Channel State Information available from commodity WiFi devices and the prevalence of WiFi network infrastructures. It senses and identi&#64257;es subtle movements of &#64257;nger gestures by examining the unique patterns exhibited in the detailed CSI. We devise environmental noise removal mechanism to mitigate the effect of signal dynamic due to the environment changes. Moreover, we propose to capture the intrinsic gesture behavior to deal with individual diversity and gesture inconsistency. Lastly, we utilize multiple WiFi links and larger bandwidth at 5GHz to achieve &#64257;nger gesture recognition under multi-user scenario. \n\n(3) Inferring Live Speech and Speaker Identity via Subtle Facial Dynamics Captured by AR/VR Motion Sensors. In this project, we show a serious privacy risk of using voice interfaces while the user is wearing the face-mounted AR/VR devices. Specifically, we design an eavesdropping attack, Face-Mic, which leverages speech-associated subtle facial dynamics captured by zero-permission motion sensors in AR/VR headsets to infer highly sensitive information from live human speech, including speaker gender, identity, and speech content. Face-Mic is grounded on a key insight that AR/VR headsets are closely mounted on the user\u2019s face, allowing a potentially malicious app on the headset to capture underlying facial dynamics as the wearer speaks, including movements of facial muscles and bone-borne vibrations, which encode private biometrics and speech characteristics. To mitigate the impacts of body movements, we develop a signal source separation technique to identify and separate the speech-associated facial dynamics from other types of body movements. We further extract representative features with respect to the two types of facial dynamics. We successfully demonstrate privacy leakage through AR/VR headsets by deriving the user\u2019s gender/identity and extracting speech information via the development of a deep learning-based framework. Extensive experiments using four mainstream VR headsets validate the generalizability, effectiveness, and high accuracy of Face-Mic.\n\nThe proposed research can advance our knowledge in exploiting the physical layer information in wireless networks to capture unique physiological and behavioral characteristics from human during their daily activities. It can also enhance our understanding in developing deep learning techniques to authenticate people based on their activities in the physical environments. Moreover, during the project period the PIs not only trained graduate students to conduct the research but also actively included undergraduates and high school students through research internship programs. Results are disseminated through scholarly publications, active outreach to the wireless and mobile industry through WINLAB's industry events and connections.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/29/2022\n\n\t\t\t\t\tSubmitted by: Yingying Chen"
 }
}