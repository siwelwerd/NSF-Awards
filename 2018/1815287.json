{
 "awd_id": "1815287",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Open-domain, Data-driven Code Synthesis from Natural Language",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 499726.0,
 "awd_amount": 507726.0,
 "awd_min_amd_letter_date": "2018-05-22",
 "awd_max_amd_letter_date": "2021-05-19",
 "awd_abstract_narration": "One of the major hurdles in programming is turning ideas into code; all programmers, even experts, frequently reach points in a program where they know what they want to do but cannot easily turn it into a concrete implementation. In this case, it is common to turn to the web, e.g. enter a natural language query, search, browse results, copy-and-paste appropriate code, and modify it to the desired shape. However, this process is still time-consuming. This research aims to automate and enhance this process, by creating new data-driven methods for code synthesis from natural language, which allow developers to go directly from natural language description to code. Specifically, this project's goal is to bring code synthesis to the open domain, moving from highly engineered methods that work on only a single programming language or task, to methods that have the flexibility and scalability to answer most of the questions asked by programmers, in many different programming languages. The intellectual merit of this cross-disciplinary project lies in its potential to contribute to software engineering through the examination of developer's interaction with natural language productivity tools, and its potential to contribute to natural language processing through new models to understand procedural texts. This project will have broader impact through the development of tools and data linking together programs and natural language, potential to improve STEM education by lowering the barriers to programming, and training of graduate and undergraduate research assistants who will be able to straddle and act as bridges between the fields of natural language processing and software engineering.\r\n\r\nThere are three technical pillars to the work. First, it will focus on methods to mine data consisting of natural language and corresponding code at scale, necessary for training. The mining will be performed over existing online data sources, such as community question answering sites (Stack Overflow) and open-source software repositories (GitHub), using machine learning models that consider both content matches and available meta-data, and crowd-sourcing-based verification of the extracted data. Second, the project will develop code synthesis methods that have the flexibility to handle the wide variety of expressions expected across a variety of software projects and developer needs. This will be done by developing models using neural networks, which have recently shown impressive ability to interpret a wide variety of expressions in other natural language processing tasks. We will expand these models to condition on project context, which will ensure handling of the various constraints necessary to create well-formed programs and allow for adaptation to project-specific conventions and needs. Third, the project will develop methods for learning and improving the models from developer behavior, by feeding back corrections to the generated code into the system and learning from the differences between the pre- and post-correction code. These methods will all be integrated into developer support tools that can be used in a development environment, or through an online API. The utility of these methods will be examined in both controlled and in-the-wild studies. Controlled studies will examine the subjective accuracy of the mined data and generated code, as well as the effect of the tools on the efficiency and ease of development, for programmers from novice to expert level. This project will also create and release tools for general consumption, solicit feedback from a wide variety of developers, and examine how developers use the proposed tools.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Graham",
   "pi_last_name": "Neubig",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Graham Neubig",
   "pi_email_addr": "gneubig@andrew.cmu.edu",
   "nsf_id": "000732016",
   "pi_start_date": "2018-05-22",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Bogdan",
   "pi_last_name": "Vasilescu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bogdan Vasilescu",
   "pi_email_addr": "vasilescu@cmu.edu",
   "nsf_id": "000692194",
   "pi_start_date": "2018-05-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 499726.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>One of the major hurdles in programming is turning ideas into code; all programmers, even experts, frequently reach points in a program where they know what they want to do but cannot easily turn it into a concrete implementation. In this case, it is common to turn to the web, e.g. enter a natural language query, search, browse results, copy-and-paste appropriate code, and modify it to the desired shape. However, this process is still time-consuming.</p>\n<p>In this research project, we developed methods to automate and enhance this process, by creating new data-driven methods for code synthesis from natural language, which allow developers to go directly from natural language description to code. Specifically, this project's goal was to bring code synthesis to the open domain, moving from highly engineered methods that work on only a single programming language or task, to methods that have the flexibility and scalability to answer most of the questions asked by programmers, in many different programming languages.</p>\n<p>Within this general goal, we developed datasets, devised methods, and performed user studies of the efficacy of such code generation methods with developers. Specific outcomes include:</p>\n<p>1. Development of methodology for syntax-based code generation, which was implemented in practice in the TranX code generation software. TranX or similar methodology was used by a number of companies such as Amazon and Microsoft in their code generation systems, and the resulting papers have been cited over 700 times in aggregate.</p>\n<p>2. Development of datasets for training and testing of code generation models. In particular, the CoNaLa code-generation corpus was scraped from stack overflow and then human-curated, and has been widely used as a testbed for code generation. This dataset has further been expanded to cover other natural languages such as Japanese, Spanish, and Russian, and been augmented with unit tests for execution-based evaluation. The resulting paper has been cited over 150 times.</p>\n<p>3. Experiments with these tools incorporated into the software development process through an IDE plugin. These experiments demonstrated both the promise of such tools, and highlighted some challenges such as the importance of using broader context or providing information about where the code came from.</p>\n<p>4. A series of papers on retrieval-based methods for code generation. These methods are not only more accurate, but also provide information about the provenance of the generated code, increasing the reliability of the code for developers who want to consume it downstream.</p>\n<p>The broader impact of this project has been large, with applications across the industry. In particular, the resulting work was referenced in development of the now Codex tool that powers Github CoPilot, a tool that has now permeated the software development industry.</p>\n<p>In addition, this project has supported the professional development of several PhD and Master's students, one of whom is now putting the research work developed from this project in practice in Google's internal code recommendation systems.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/22/2023<br>\n\t\t\t\t\tModified by: Graham&nbsp;Neubig</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOne of the major hurdles in programming is turning ideas into code; all programmers, even experts, frequently reach points in a program where they know what they want to do but cannot easily turn it into a concrete implementation. In this case, it is common to turn to the web, e.g. enter a natural language query, search, browse results, copy-and-paste appropriate code, and modify it to the desired shape. However, this process is still time-consuming.\n\nIn this research project, we developed methods to automate and enhance this process, by creating new data-driven methods for code synthesis from natural language, which allow developers to go directly from natural language description to code. Specifically, this project's goal was to bring code synthesis to the open domain, moving from highly engineered methods that work on only a single programming language or task, to methods that have the flexibility and scalability to answer most of the questions asked by programmers, in many different programming languages.\n\nWithin this general goal, we developed datasets, devised methods, and performed user studies of the efficacy of such code generation methods with developers. Specific outcomes include:\n\n1. Development of methodology for syntax-based code generation, which was implemented in practice in the TranX code generation software. TranX or similar methodology was used by a number of companies such as Amazon and Microsoft in their code generation systems, and the resulting papers have been cited over 700 times in aggregate.\n\n2. Development of datasets for training and testing of code generation models. In particular, the CoNaLa code-generation corpus was scraped from stack overflow and then human-curated, and has been widely used as a testbed for code generation. This dataset has further been expanded to cover other natural languages such as Japanese, Spanish, and Russian, and been augmented with unit tests for execution-based evaluation. The resulting paper has been cited over 150 times.\n\n3. Experiments with these tools incorporated into the software development process through an IDE plugin. These experiments demonstrated both the promise of such tools, and highlighted some challenges such as the importance of using broader context or providing information about where the code came from.\n\n4. A series of papers on retrieval-based methods for code generation. These methods are not only more accurate, but also provide information about the provenance of the generated code, increasing the reliability of the code for developers who want to consume it downstream.\n\nThe broader impact of this project has been large, with applications across the industry. In particular, the resulting work was referenced in development of the now Codex tool that powers Github CoPilot, a tool that has now permeated the software development industry.\n\nIn addition, this project has supported the professional development of several PhD and Master's students, one of whom is now putting the research work developed from this project in practice in Google's internal code recommendation systems.\n\n \n\n\t\t\t\t\tLast Modified: 02/22/2023\n\n\t\t\t\t\tSubmitted by: Graham Neubig"
 }
}