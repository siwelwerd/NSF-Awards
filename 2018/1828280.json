{
 "awd_id": "1828280",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MRI: Development of a System for High-Resolution Uninterrupted Capture of Complex Animal Motions",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Wendy C. Crone",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 249666.0,
 "awd_amount": 265666.0,
 "awd_min_amd_letter_date": "2018-09-19",
 "awd_max_amd_letter_date": "2022-09-07",
 "awd_abstract_narration": "This major research instrumentation award supports the development of an integrated camera array that will be customized to meet the challenges of capturing fast and highly complex animal motions--providing an enabling tool for fundamental research to understand and model the dynamics of motion. The instrument will permit uninterrupted motion tracking for hundreds of points on an animal as it executes even the most complex motions, such as midair somersaults that bats perform in pursuit of prey. The unprecedented detail, quality, and quantity of the data to be generated will provide the basis for new fundamental research into how animals use freedom of movement to attain unmatched levels of performance in maneuverability and energy efficiency. The large volume of quantitative data produced by the instrument will bring data-intensive methods--from non-linear dynamics and machine learning-- to bear on the field of animal motion. A deeper understanding of the principles behind animal motion will be key to the development of next-generation mobile robots that can handle unconstrained, natural environments. These highly dexterous, mobile robots will enhance productivity in applications such as manufacturing, health care, disaster response, precision agriculture, forestry and environmental monitoring and clean-up. This instrument will also enable fundamental research on the motion of man-made structures, such as the complex dynamic motions inherent in flutter in aerodynamic systems. Knowledge gleaned from this instrument will also help veterinarians to diagnose disease and pain from animals' motion patterns. Graduate and undergraduate students will be involved in instrumentation development and the instrumentation will enable interdisciplinary research training opportunities in engineering and biology. \r\n\r\n\r\n\r\nThe instrument will combine high spatial and temporal resolution with the ability to view a moving animal from many different angles at the same time. It will consist of 48 high-speed video cameras that can deliver a 1280x1024-pixel image resolution at 1057-Hz frame rate. High-quality illumination will be provided by 8 specialized lights so that no part of a moving animal will ever be hidden from view. All cameras in the array will be synchronized (precision < 10 nanoseconds) and operated automatically to allow for efficient capture of large motion data sets. A recording of 5 seconds, for example, will result in over 250,000 images with 332 Gigabytes of raw data. The project team's automated image processing methods will allow reliable tracking of several hundred landmark points across such large image sets. The instrument and its accompanying suite of software tools will be used for the study of previously unexplained animal motion capabilities such as the highly articulated flight of bats, gliding of snakes, and lizards running on vertical substrates.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rolf",
   "pi_last_name": "Mueller",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rolf Mueller",
   "pi_email_addr": "rolf.mueller@vt.edu",
   "nsf_id": "000514733",
   "pi_start_date": "2018-09-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Amos",
   "pi_last_name": "Abbott",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Amos L Abbott",
   "pi_email_addr": "abbott@vt.edu",
   "nsf_id": "000348621",
   "pi_start_date": "2018-09-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Alexander",
   "pi_last_name": "Leonessa",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alexander Leonessa",
   "pi_email_addr": "leonessa@vt.edu",
   "nsf_id": "000261361",
   "pi_start_date": "2018-09-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Socha",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "John Socha",
   "pi_email_addr": "jjsocha@vt.edu",
   "nsf_id": "000515275",
   "pi_start_date": "2018-09-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Hongxiao",
   "pi_last_name": "Zhu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hongxiao Zhu",
   "pi_email_addr": "hongxiao@vt.edu",
   "nsf_id": "000655793",
   "pi_start_date": "2018-09-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Polytechnic Institute and State University",
  "inst_street_address": "300 TURNER ST NW",
  "inst_street_address_2": "STE 4200",
  "inst_city_name": "BLACKSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "5402315281",
  "inst_zip_code": "240603359",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "VA09",
  "org_lgl_bus_name": "VIRGINIA POLYTECHNIC INSTITUTE & STATE UNIVERSITY",
  "org_prnt_uei_num": "X6KEFGLHSJX7",
  "org_uei_num": "QDE5UHE5XD16"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Polytechnic Institute and State University",
  "perf_str_addr": "1075 Life Science Cir",
  "perf_city_name": "Blacksburg",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "240611016",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "VA09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "118900",
   "pgm_ele_name": "Major Research Instrumentation"
  },
  {
   "pgm_ele_code": "756900",
   "pgm_ele_name": "Dynamics, Control and System D"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "030E",
   "pgm_ref_txt": "CONTROL SYSTEMS"
  },
  {
   "pgm_ref_code": "034E",
   "pgm_ref_txt": "Dynamical systems"
  },
  {
   "pgm_ref_code": "116E",
   "pgm_ref_txt": "RESEARCH EXP FOR UNDERGRADS"
  },
  {
   "pgm_ref_code": "1189",
   "pgm_ref_txt": "MAJOR RESEARCH INSTRUMENTATION"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9231",
   "pgm_ref_txt": "SUPPL FOR UNDERGRAD RES ASSIST"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 249666.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><pre>Many animal species are capable of a wide range of extremely dexterous\nmotions that have yet to be replicated by man-made systems such as\nrobots. If the performance gap between biological and man-made\nmobility could be closed, this could enable robots and drones that are\nmuch better suited for accomplishing tasks in complex natural\nenvironments than what is currently available. Such systems could then\nhave a transformative impact on the automation of vital outdoor tasks\nrelated to areas such as agriculture, forestry, environmental\nsurveillance, and national security. Critical to accomplishing this\ngoal are large amounts of quantitative data that can accurately\ncapture how animals move. The project has created an instrument that\nis capable of delivering this data. It consists of an array of 50\nhigh-speed video cameras that each capture slightly more than 1000\nimages in every second, i.e., over 50,000 images per second in\ntotal. Furthermore, the acquisition of the images is synchronized in\ntime across cameras, so that all cameras acquire each of their images\nat exactly the same time. The cameras are distributed to capture a\nmoving animal from many different directions, which allows a\nthree-dimensional reconstruction of the geometry of the animal as it\nmoves. The many different direction also help to prevent loss of\ninformation in situation where one part of an animal's body occludes\nanother part. In addition, the cameras can also capture a fairly large\nvolume (a cylinder with 6 meters length a diameter of 2.7 meters)\nwhich allows to capture motions that play out over such a space in\ntheir entirety. To insure that this volume is also well let, the array\nis also equipped with 40 camera lights. The array is networked with\nservers for data storage that can capture the large volumes of image\ndata. In the first months of operation, the array has been used\nsuccessfully to capture flying bats. The flight motions of these\nanimals pose a worthy challenge for the instrument, because the wings\nundergo large deformations within the wingbeat cycle that also change\nwith the respective flight maneuvers. The data obtained from the array\nare currently being used for the development of AI tools that can\nautomatically sift through large amount of camera images and\nreconstruct the three-dimensional geometry of the animal without\nrequiring any user intervention. In this way, it will be possible to\nprocess data from many different flights and hence make comparisons of\nhow the animals adapt their flight maneuvers to different situations.</pre>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/29/2023<br>\n\t\t\t\t\tModified by: Rolf&nbsp;Mueller</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1828280/1828280_10583776_1675046766306_flight_tunnel--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1828280/1828280_10583776_1675046766306_flight_tunnel--rgov-800width.jpg\" title=\"Flight tunnel construction\"><img src=\"/por/images/Reports/POR/2023/1828280/1828280_10583776_1675046766306_flight_tunnel--rgov-66x44.jpg\" alt=\"Flight tunnel construction\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Images of the flight tunnel during construction</div>\n<div class=\"imageCredit\">Benjamin Beiter, Rolf Mueller</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Rolf&nbsp;Mueller</div>\n<div class=\"imageTitle\">Flight tunnel construction</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "Many animal species are capable of a wide range of extremely dexterous\nmotions that have yet to be replicated by man-made systems such as\nrobots. If the performance gap between biological and man-made\nmobility could be closed, this could enable robots and drones that are\nmuch better suited for accomplishing tasks in complex natural\nenvironments than what is currently available. Such systems could then\nhave a transformative impact on the automation of vital outdoor tasks\nrelated to areas such as agriculture, forestry, environmental\nsurveillance, and national security. Critical to accomplishing this\ngoal are large amounts of quantitative data that can accurately\ncapture how animals move. The project has created an instrument that\nis capable of delivering this data. It consists of an array of 50\nhigh-speed video cameras that each capture slightly more than 1000\nimages in every second, i.e., over 50,000 images per second in\ntotal. Furthermore, the acquisition of the images is synchronized in\ntime across cameras, so that all cameras acquire each of their images\nat exactly the same time. The cameras are distributed to capture a\nmoving animal from many different directions, which allows a\nthree-dimensional reconstruction of the geometry of the animal as it\nmoves. The many different direction also help to prevent loss of\ninformation in situation where one part of an animal's body occludes\nanother part. In addition, the cameras can also capture a fairly large\nvolume (a cylinder with 6 meters length a diameter of 2.7 meters)\nwhich allows to capture motions that play out over such a space in\ntheir entirety. To insure that this volume is also well let, the array\nis also equipped with 40 camera lights. The array is networked with\nservers for data storage that can capture the large volumes of image\ndata. In the first months of operation, the array has been used\nsuccessfully to capture flying bats. The flight motions of these\nanimals pose a worthy challenge for the instrument, because the wings\nundergo large deformations within the wingbeat cycle that also change\nwith the respective flight maneuvers. The data obtained from the array\nare currently being used for the development of AI tools that can\nautomatically sift through large amount of camera images and\nreconstruct the three-dimensional geometry of the animal without\nrequiring any user intervention. In this way, it will be possible to\nprocess data from many different flights and hence make comparisons of\nhow the animals adapt their flight maneuvers to different situations.\n\n \n\n\t\t\t\t\tLast Modified: 01/29/2023\n\n\t\t\t\t\tSubmitted by: Rolf Mueller"
 }
}