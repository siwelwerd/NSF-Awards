{
 "awd_id": "1839201",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Towards the Web of Biodiversity Knowledge: Understanding Data Connectedness to Improve Identifier Practices",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Martin Halbert",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 299973.0,
 "awd_amount": 299973.0,
 "awd_min_amd_letter_date": "2018-07-31",
 "awd_max_amd_letter_date": "2018-07-31",
 "awd_abstract_narration": "Biodiversity research investigates the variety and variability of life on Earth. This field of science crosses many research disciplines such as genetics, studies of organisms, plants and animals, habitats and ecosystems, and their interactions. A long-standing challenge for biodiversity researchers is to find, access, \"mine\", and integrate complex and diverse information from those disciplines. New approaches have now become possible with the increasing availability of \"big data\" techniques and infrastructure. This project will explore and employ such advanced techniques for retrieval and mining of a wide range of available open biodiversity data sources, with the aim of generating an improved holistic picture or \"knowledge graph\" of Earth's biodiversity. The project will also identify the data practices and discovered relationships that were needed to accomplish this graph-building task, with the aim of informing the development of future data systems and training on these techniques. \r\n\r\nMany attempts have been made to link together biodiversity knowledge using linked identifiers coupled with data standards and taxonomies, but satisfactory results with such \"exact matching\" approaches have been elusive. This project aims to develop new methods of relating records across datasets that do not rely on matching identifiers but instead employ inferred rather than explicit relationships between data records. This is an experimental approach that has not yet been attempted at scale.  Linkages between publicly available biodiversity, genetic, literature, and other data will be explored; and software infrastructure will be developed to combine and link multiple biodiversity datasets. Another goal is to quantify the relationship between identifier practices and the ability to construct links between available biodiversity, genetic, literature, and other data. This project will draw on and complement other large ongoing collaborative efforts that contribute to broad integration of biodiversity knowledge, data science, and infrastructure such as the Encyclopedia of Life (EOL) and the NSF-supported iDigBio project. The ultimate aim is to understand which data practices provide the most value to the biodiversity community and thereby inform policy, standards, and training on identifiers. This, in turn, can enable the exploration of new fundamental and cross-disciplinary research questions, and potentially improve practices of a wide range of US and international data aggregators and data producers. \r\n\r\nThis project is supported by the National Science Foundation's Public Access Initiative which is managed by the NSF Office of Advanced Cyberinfrastructure on behalf of the Foundation.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jose",
   "pi_last_name": "Fortes",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Jose A Fortes",
   "pi_email_addr": "fortes@ufl.edu",
   "nsf_id": "000415025",
   "pi_start_date": "2018-07-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1 University Drive",
  "perf_city_name": "Gainesville",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326112001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "741400",
   "pgm_ele_name": "NSF Public Access Initiative"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 299973.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-9ec658af-7fff-d2eb-27a7-73ca48073c52\">&nbsp;</span></p>\n<p dir=\"ltr\"><span>The monitoring, understanding and preservation of Earth&rsquo;s biodiversity rely on our ability to gather data, to link related data and to analyze them repeatedly over long periods of time. Biodiversity scientists leverage the existence of data aggregation networks to select data relevant to their work, generating custom datasets needed to answer specific research questions. For their scientific work to be reproducible and repeatable it is necessary to make sure that the datasets are uniquely and persistently identified so that their names always refer to the same data and different data are never retrieved using the same name in the foreseeable future. Also necessary is the ability to track the provenance of the data so that scientists can retrace and update data sources. The linkage of persistently identified datasets that include their provenance yields biodiversity data graphs that connect datasets obtained over time from the same source.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>The intellectual outcomes of this project include techniques (and their implementations) for both generating persistent unique identifiers for datasets and tracking the provenance of datasets. In particular, the use of content-based identifiers was proposed for the first time for biocollections data. A content-based identifier of a dataset is a fixed-size string of characters that uniquely encodes the contents of the dataset. In other words, the identifier of a dataset will change if and only its content changes. This project showed that currently used identifiers that are not based on dataset content are inadequate and, as an alternative, showed that content-based identifiers are better suited for unique identification, re-use, linking, and preservation of biodiversity datasets. It also demonstrated that provenance information containing content-based dataset identifiers could also be encoded to identify datasets that include provenance information about themselves. A software tool called Preston implementing these techniques for dataset identification and provenance tracking was developed and used to deploy data observatories that track datasets of different types (text or media) provided to biodiversity data aggregators in the USA and abroad. Preston was used to demonstrate that evolving and disappearing datasets from unreliable web locations (i.e. accessible via URLs) can be versioned, reliably referenced, and preserved by leveraging provenance records describing the collection of datasets (with content-based identifiers) from URLs.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>The broader impact outcomes of this project include software and scripts all of which are publicly available, including the code for the tool Preston. </span><span>As of October 2021, Preston observatories have collected over 1.5TB of versioned biodiversity data and provenance for 1,249,376 unique dataset versions (including several hundred provenance datasets) spread over 822,932 different Internet locations. </span><span>All datasets created by tools developed in the project are deposited redundantly across existing Internet repositories (namely, Internet Archive and Zenodo). Two PhD students and two undergraduate students participated in this project.</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/02/2021<br>\n\t\t\t\t\tModified by: Jose&nbsp;A&nbsp;Fortes</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThe monitoring, understanding and preservation of Earth\u2019s biodiversity rely on our ability to gather data, to link related data and to analyze them repeatedly over long periods of time. Biodiversity scientists leverage the existence of data aggregation networks to select data relevant to their work, generating custom datasets needed to answer specific research questions. For their scientific work to be reproducible and repeatable it is necessary to make sure that the datasets are uniquely and persistently identified so that their names always refer to the same data and different data are never retrieved using the same name in the foreseeable future. Also necessary is the ability to track the provenance of the data so that scientists can retrace and update data sources. The linkage of persistently identified datasets that include their provenance yields biodiversity data graphs that connect datasets obtained over time from the same source.\n\n \nThe intellectual outcomes of this project include techniques (and their implementations) for both generating persistent unique identifiers for datasets and tracking the provenance of datasets. In particular, the use of content-based identifiers was proposed for the first time for biocollections data. A content-based identifier of a dataset is a fixed-size string of characters that uniquely encodes the contents of the dataset. In other words, the identifier of a dataset will change if and only its content changes. This project showed that currently used identifiers that are not based on dataset content are inadequate and, as an alternative, showed that content-based identifiers are better suited for unique identification, re-use, linking, and preservation of biodiversity datasets. It also demonstrated that provenance information containing content-based dataset identifiers could also be encoded to identify datasets that include provenance information about themselves. A software tool called Preston implementing these techniques for dataset identification and provenance tracking was developed and used to deploy data observatories that track datasets of different types (text or media) provided to biodiversity data aggregators in the USA and abroad. Preston was used to demonstrate that evolving and disappearing datasets from unreliable web locations (i.e. accessible via URLs) can be versioned, reliably referenced, and preserved by leveraging provenance records describing the collection of datasets (with content-based identifiers) from URLs.\n\n \nThe broader impact outcomes of this project include software and scripts all of which are publicly available, including the code for the tool Preston. As of October 2021, Preston observatories have collected over 1.5TB of versioned biodiversity data and provenance for 1,249,376 unique dataset versions (including several hundred provenance datasets) spread over 822,932 different Internet locations. All datasets created by tools developed in the project are deposited redundantly across existing Internet repositories (namely, Internet Archive and Zenodo). Two PhD students and two undergraduate students participated in this project.\n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/02/2021\n\n\t\t\t\t\tSubmitted by: Jose A Fortes"
 }
}