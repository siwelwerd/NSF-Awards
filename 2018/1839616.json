{
 "awd_id": "1839616",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Real-Time: Precision Reserves from Flexible Loads: An Online Reinforcement Learning Approach",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Donald Wunsch",
 "awd_eff_date": "2018-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 248799.0,
 "awd_amount": 248799.0,
 "awd_min_amd_letter_date": "2018-09-19",
 "awd_max_amd_letter_date": "2018-09-19",
 "awd_abstract_narration": "This proposal explores an online reinforcement learning framework that can provide high capacity rating and scheduling of many end user-level flexible resources such as swimming pools. In sharp contrast with conventional approaches of statically and uniformly treating end user loads with small capacity rating and scheduling them via heuristics based algorithms, the proposed framework will provide a theoretically rigorous and practically scalable approach for learning the unknown parameters of end user loads and adaptively controlling them with provable guarantees.\r\n\r\nIntellectual Merit:\r\n\r\n (i) This proposal will illustrate the possibility of substantial increasing of capacity credit from end user demand response in provision of spinning reserves via scalable real-time estimation and control as opposed to the conventional heuristic based scheduling algorithms. (ii) This proposal will introduce a learning and adaptive control algorithm using the framework of online reinforcement learning to address the operational problems when the consumer specific parameters are unknown. (iii) This proposal will introduce an index-based learning and scheduling algorithm that scales only linearly with the number of end users. (iv) This proposal will test a data-driven optimal scheduling that jointly maximize the profit for the aggregator and track the required reserve provision trajectory from the collection of even a small number of flexible users.  The proposed research is generalizable towards many resource scheduling problems with uncertainty that arise in the context of transportation, communication, and other engineering dynamical systems.\r\n\r\nBroader Impacts:\r\n\r\nOnce successful, this project will provide a systematic approach for obtaining spinning reserve at much\r\nless cost from flexible end user resources in a provably reliable and environmentally sustainable way.\r\nThis team will introduce new course modules on the topic of data-driven online learning in dynamical systems, which closely integrates reinforcement learning, dynamical control, and optimization for more than 200 undergraduate and graduate students currently enrolled in related areas courses at Texas A&M. \r\nThis team will continue the strong track record of engaging undergraduate students for research, in particular the under-representative groups.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Le",
   "pi_last_name": "Xie",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Le Xie",
   "pi_email_addr": "le.xie@tamu.edu",
   "nsf_id": "000557004",
   "pi_start_date": "2018-09-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Dileep",
   "pi_last_name": "Kalathil",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dileep Kalathil",
   "pi_email_addr": "dileep.kalathil@tamu.edu",
   "nsf_id": "000760025",
   "pi_start_date": "2018-09-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M Engineering Experiment Station",
  "perf_str_addr": "3128 tamu",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433128",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760700",
   "pgm_ele_name": "EPCN-Energy-Power-Ctrl-Netwrks"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "155E",
   "pgm_ref_txt": "Electric power networks"
  },
  {
   "pgm_ref_code": "1653",
   "pgm_ref_txt": "Adaptive & intelligent systems"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 248799.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project explored a robust reinforcement learning framework that can provide effective energy system applications in the electric distribution networks.&nbsp;</p>\n<p>Intellectual Merit:</p>\n<p>Three key results have been reported as the outcome of this project.&nbsp;</p>\n<p>(1) Reinforcement Learning Algorithm for end user Voltage Regulation: We proposed a reinforcement learning-based voltage control strategy withjoint provision of real and reactive power support for distribution grids with deep photovoltaic penetration. Thevoltage regulation problem is posed as a Markov Decision Process with rewards parametrized to balance betweenvoltage deviation minimization and solar production maximization. We also developed a fully decentralized(communication-free) approach for this voltage control, which can be implemented on existing physicalinfrastructure, helping to alleviate problems related to communication failure or cyber-attacks.</p>\n<p>(2) Reinforcement Learning Algorithm for end user-level&nbsp;protection: We proposed a novel nested reinforcementlearning algorithm for optimal relay protection control for a network of relays in a power distribution network. Wedon&rsquo;t assume any explicit communication between the relays. We formulates the relay protection control as a multi-agent RL problem where each relay acts as an agent, observes only its local measurements and takes controlactions based on this observation. We argued that the radial structure imposes only a one directional influencepattern among the agents, starting from the end of the line to the feeder. Using this structure, we developed a nestedtraining procedure for the network of relays. Our nested RL algorithm converges fast in simulations. The converged&nbsp;operation conditions, and speed in responses.</p>\n<p>(3) Robust Reinforcement Learning: We proposed an online model-free reinforcement learning algorithm to learncontrol policies that are robust against parameter uncertainties of the model. We first developed a model-free robustpolicy evaluation algorithm called Robust least Squares Policy Evaluation (RLSPE) and rigorously proved itsconvergence. We then developed a robust policy iteration algorithm called RLSPI algorithm with provableguarantees on the performance. The performance of the proposed algorithms are evaluated on benchmarkproblems.</p>\n<p>&nbsp;</p>\n<p>Broader Impacts:</p>\n<p>This project has involved multipled graduate students (including 2 females) in different aspects of the research. The findings have been broadly disseminated through scientific papers and webinars such as the Texas A&amp;M Energy Institute Webinar series. Much of the research have been disseminated through the courses offered by Dr. Xie and Dr. Kalathil on data sciences for modern power systems. Dr. Xie and Dr. Kalathil have offered twice short courses tailored for power industry engieers on \"Data Sciences for Modern Power Systems,\" with more than 50 engineers registered cumulatively.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/06/2022<br>\n\t\t\t\t\tModified by: Le&nbsp;Xie</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project explored a robust reinforcement learning framework that can provide effective energy system applications in the electric distribution networks. \n\nIntellectual Merit:\n\nThree key results have been reported as the outcome of this project. \n\n(1) Reinforcement Learning Algorithm for end user Voltage Regulation: We proposed a reinforcement learning-based voltage control strategy withjoint provision of real and reactive power support for distribution grids with deep photovoltaic penetration. Thevoltage regulation problem is posed as a Markov Decision Process with rewards parametrized to balance betweenvoltage deviation minimization and solar production maximization. We also developed a fully decentralized(communication-free) approach for this voltage control, which can be implemented on existing physicalinfrastructure, helping to alleviate problems related to communication failure or cyber-attacks.\n\n(2) Reinforcement Learning Algorithm for end user-level protection: We proposed a novel nested reinforcementlearning algorithm for optimal relay protection control for a network of relays in a power distribution network. Wedon\u2019t assume any explicit communication between the relays. We formulates the relay protection control as a multi-agent RL problem where each relay acts as an agent, observes only its local measurements and takes controlactions based on this observation. We argued that the radial structure imposes only a one directional influencepattern among the agents, starting from the end of the line to the feeder. Using this structure, we developed a nestedtraining procedure for the network of relays. Our nested RL algorithm converges fast in simulations. The converged operation conditions, and speed in responses.\n\n(3) Robust Reinforcement Learning: We proposed an online model-free reinforcement learning algorithm to learncontrol policies that are robust against parameter uncertainties of the model. We first developed a model-free robustpolicy evaluation algorithm called Robust least Squares Policy Evaluation (RLSPE) and rigorously proved itsconvergence. We then developed a robust policy iteration algorithm called RLSPI algorithm with provableguarantees on the performance. The performance of the proposed algorithms are evaluated on benchmarkproblems.\n\n \n\nBroader Impacts:\n\nThis project has involved multipled graduate students (including 2 females) in different aspects of the research. The findings have been broadly disseminated through scientific papers and webinars such as the Texas A&amp;M Energy Institute Webinar series. Much of the research have been disseminated through the courses offered by Dr. Xie and Dr. Kalathil on data sciences for modern power systems. Dr. Xie and Dr. Kalathil have offered twice short courses tailored for power industry engieers on \"Data Sciences for Modern Power Systems,\" with more than 50 engineers registered cumulatively. \n\n \n\n\t\t\t\t\tLast Modified: 02/06/2022\n\n\t\t\t\t\tSubmitted by: Le Xie"
 }
}