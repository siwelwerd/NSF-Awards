{
 "awd_id": "1753968",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER: Efficient Learning of Personalized Strategies",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Roger Mailler",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2020-05-31",
 "tot_intn_awd_amt": 287196.0,
 "awd_amount": 295195.0,
 "awd_min_amd_letter_date": "2017-11-01",
 "awd_max_amd_letter_date": "2017-11-01",
 "awd_abstract_narration": "Online retailers frequently provide tailored product or movie recommendations. But the power of automated personalization, driven by data and statistics, could be far greater: imagine the impact on poverty reduction if all children had a personalized, self-improving tutoring system as part of their education. To realize this vision requires personalization systems that reason about both the immediate impact of a recommended item (e.g. will a learner immediately learn from a video lecture) as well as its longer term impact. For example, a recommended item or intervention may cause a user to change his/her preferences, state of knowledge, or reveal information about the user that was previously unknown. This requires methods for creating personalized strategies: adaptive rules about what decisions to make (whether or which ad to show, which pedagogical activity to provide) in which circumstances to maximize for long term outcomes. \r\n\r\nThis research involves developing new data-driven, machine learning approaches to construct such personalized strategies for related individuals, and using them towards improving the effectiveness of online mathematics educational systems.  The project frames personalized strategy creation as sequential decision making under uncertainty research. Though there have been many advances in sequential decision making under uncertainty, existing approaches have focused primarily on other application areas, like robotics, and fail to account or leverage for some of the special features that arise when interacting with people. These include that accurate simulation of people is difficult but prior data is often available, and that individuals are often related. This project contributes algorithms for mining existing datasets to create and precisely bound the expected performance of new high-quality strategies and for online policy learning across a series of similar sequential decision making tasks.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Emma",
   "pi_last_name": "Brunskill",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Emma Brunskill",
   "pi_email_addr": "ebrun@cs.stanford.edu",
   "nsf_id": "000514969",
   "pi_start_date": "2017-11-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943041212",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 287194.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-970a5391-7fff-1eba-0a7d-2a2cab783c43\"> </span></p>\n<p dir=\"ltr\"><span>A key aspect of machine learning and artificial intelligence is the topic of reinforcement learning&nbsp; which involves learning from data and experience to automatically make good decisions. This project focused on advancing how to do this in domains that involve interacting with people, like healthcare or education. This grant supported many scientific advances including</span></p>\n<p>&nbsp;</p>\n<ol>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>&ldquo;What if?&rdquo; reasoning with reinforcement learning and historical data. In particular, this project resulted in new algorithms that can take an existing dataset about past decisions and their outcomes and can use it to evaluate the performance of a different decision policy before it is deployed, or to search to find better performing decision policies. The resulting algorithms were tried on multiple simulators, including a highly accurate blood glucose simulator designed to model insulin dosage strategies.&nbsp;</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Strong theoretical bounds that characterize the amount of interaction data needed for any algorithm to learn to perform well in certain decision processes, and approaches that can provably leverage domain structure when present to achieve tighter theoretical bounds.&nbsp;</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Approaches that move beyond expected outcomes to efficiently learn decision policies sensitive to risk, or satisfy constraints (such as safety or fairness) in addition to other performance characteristics.&nbsp;</span></p>\n</li>\n</ol>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>These results were shared with the broader community through publications in highly competitive machine learning and artificial intelligence conferences, as well as in a </span><span>Science</span><span> article.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>To increase the accessibility of this field to the broader community, the PI developed a new reinforcement learning class and included specific sections to focus on the technical challenges arising when creating reinforcement learning algorithms targeted to support people. The PI made the videos, slides and homeworks publically accessible, and the resulting videos have been viewed tens of thousands of times. </span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/25/2020<br>\n\t\t\t\t\tModified by: Emma&nbsp;Brunskill</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nA key aspect of machine learning and artificial intelligence is the topic of reinforcement learning  which involves learning from data and experience to automatically make good decisions. This project focused on advancing how to do this in domains that involve interacting with people, like healthcare or education. This grant supported many scientific advances including\n\n \n\n\n\"What if?\" reasoning with reinforcement learning and historical data. In particular, this project resulted in new algorithms that can take an existing dataset about past decisions and their outcomes and can use it to evaluate the performance of a different decision policy before it is deployed, or to search to find better performing decision policies. The resulting algorithms were tried on multiple simulators, including a highly accurate blood glucose simulator designed to model insulin dosage strategies. \n\n\nStrong theoretical bounds that characterize the amount of interaction data needed for any algorithm to learn to perform well in certain decision processes, and approaches that can provably leverage domain structure when present to achieve tighter theoretical bounds. \n\n\nApproaches that move beyond expected outcomes to efficiently learn decision policies sensitive to risk, or satisfy constraints (such as safety or fairness) in addition to other performance characteristics. \n\n\n\n \nThese results were shared with the broader community through publications in highly competitive machine learning and artificial intelligence conferences, as well as in a Science article. \n\n \nTo increase the accessibility of this field to the broader community, the PI developed a new reinforcement learning class and included specific sections to focus on the technical challenges arising when creating reinforcement learning algorithms targeted to support people. The PI made the videos, slides and homeworks publically accessible, and the resulting videos have been viewed tens of thousands of times. \n\n \n\n \n\n\t\t\t\t\tLast Modified: 11/25/2020\n\n\t\t\t\t\tSubmitted by: Emma Brunskill"
 }
}