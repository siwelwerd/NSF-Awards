{
 "awd_id": "1837515",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: Medium: Information based Control of Cyber-Physical Systems operating in uncertain environments",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Anthony Kuh",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 896030.0,
 "awd_amount": 896030.0,
 "awd_min_amd_letter_date": "2018-09-06",
 "awd_max_amd_letter_date": "2018-09-06",
 "awd_abstract_narration": "Most cyber-physical systems have operated in comparatively benign environments, often engineered to meet the needs of the system.  For instance, in many settings robots operate in closed-off environments in manufacturing.  However, as these systems are deployed in increasingly isolated environments (such as search and rescue efforts, automation in surgical devices, collaborative manufacturing) these robots will need to operate while reasoning about substantial uncertainty.  Moreover, actions taken by the system impact that uncertainty.  The proposed work will develop algorithms that enable a cyber-physical system to reason about what actions it must take to manage its uncertainty.  A simple example of this is understanding that one must look behind and under things when searching for an object. The goal of this project is to automate the process of managing that uncertainty, however it arises.  For instance, interacting with humans (such as physically interacting with a person while assisting her motion, or tracking a person during a search effort) involves uncertainty about what the person is going to do.  Enabling a robotic system to actively test a person's intent, and then act according to her subsequent behavior, is key to the robot's ability to be an effective partner.  This essential point, that action on the part of a cyber-physical system can be used to explicitly manage its understanding of the world, is the core purpose of the proposed work.\r\n\r\nThe proposed work will leverage recent results in information-based real-time nonlinear control. Specifically, ergodic control (controlling the ergodicity of a trajectory relative to some reference distribution) enables one to specify an objective using a density function to describe the desired spatial characteristics for a trajectory. In the context of Hidden Markov Models (HMMs) and Partially Observable Markov Decision Processes (POMDPs), this allows a system to actively probe multiple states, simultaneously considering process uncertainty, measurement uncertainty, and uncertainty associated with the Markov process itself, even when the HMM is changing over time because of new states or processes being introduced into the ambient environment. The apparent reason for the effectiveness of ergodic control in the context of reactive planning under uncertainty is that it always computes plans in the continuum, avoiding the combinatoric complexity associated with POMDPs. Moreover, the needs of the dynamic system and the cyber system are inter-related during physical motion, so the work will additionally develop methods that maintain stability with respect to both state and information. This inter-dependence creates a trade-off between the physical ability to act and the computational load on the cyber system, enabling a cyber-physical system to reduce the load on its cyber system through physical action.  The research will develop algorithms capable of real-time information-based control in response to constantly changing data. One of the motivating examples will be aerial vehicles tracking unknown numbers of targets on the ground in a highly occluded environment such as a forest or an urban setting. Additionally, a robotic arm, already used for assistive device research, will be used to implement and assess the proposed methods.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Todd",
   "pi_last_name": "Murphey",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Todd D Murphey",
   "pi_email_addr": "t-murphey@northwestern.edu",
   "nsf_id": "000485210",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Brenna",
   "pi_last_name": "Argall",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Brenna Argall",
   "pi_email_addr": "brenna.argall@northwestern.edu",
   "nsf_id": "000602007",
   "pi_start_date": "2018-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "2145 Sheridan Road",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602080834",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "791800",
   "pgm_ele_name": "CPS-Cyber-Physical Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 896030.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project \"CPS: Medium: Information based Control of Cyber-Physical Systems operating in uncertain environments\" (Award 1837515) developed algorithms that enable machines that learn from their environment to make decisions about how and when to collect data. Animals are remarkable at this, able to reason about what information they need to learn something novel. Identifying novel objects and behaviors can be a safety-critical skill, and machines will sometimes not have offline data to learn from. For instance, a vehicle may become damaged during operation in a way that cannot be modeled from first principles, leading to a requirement that the vehicle quickly relearns how to operate. People are a source of uncertainty, since their skills, deficits, and intent are individualized; a robotic system supporting a human may need to learn from interaction. Despite these needs to reason over what data is needed and how to obtain it, most machine learning focuses on passively acquired data. This project created algorithms that enable a robot to explore an environment to build perceptual and dynamic models and then use those models for future decision making.&nbsp; The work included development of real-time algorithms for identifying general environmental models and deployment of these techniques in hardware. Many of the application areas focused on human-robot interaction, where human decision-making is assisted by, or regulated by, an autonomous system. Some of these applications were very concrete, such as a driverless car system that assists with keeping a person safe while not interfering with the person?s intent. Some of the more far-reaching results include a human-machine interaction that leads to an emergent language that allows them to communicate. &nbsp;<br /><br />The work is important because robots routinely encounter novel situations for which no model exists and possibly no model can exist. In an era of Large Language Models and other AI techniques, this is a new frontier. Instead of focusing on regressing the entire internet, this work enables learning from specific instances of physically residing in a particular environment. This will enable health application (e.g., personalized physical therapy that adapts to the particular state of a person on a given day), security (e.g., identifying and collecting data about unprecedented signatures in an environment, and other learning tasks where response to environmental novelty is essential to task success. <br /><br />Both simulated and physical systems were tested as part of the work, including autonomy interacting with people.&nbsp; Physical experiments included robotic learning in complex terrain, robot ensembles searching an outdoor complex environment, and human machine interfaces. Simulated systems included quickly learning visual perception of novel objects, with no models of the objects or even the sensor. Software was implemented in a general manner, with all of it available as open source code.<br /><br />During the period of the award, important broader impact goals were accomplished.&nbsp; Outreach at the Museum of Science and Industry, Chicago occurred in each year of the award, except the pandemic years when the museum was closed, reaching thousands of students.&nbsp;&nbsp; All of the robotic experiments and non-clinical human-machine interfaces were used in the museum outreach.&nbsp; Moreover, a class was developed at Northwestern University on active learning, the primary topic of this project. The class incorporates some of the results in lectures and in exercises. Algorithms developed as part of this effort have been applied at Northwestern University?s Feinberg School of Medicine using physical assistance robots.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/31/2023<br>\n\t\t\t\t\tModified by: Todd&nbsp;D&nbsp;Murphey</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project \"CPS: Medium: Information based Control of Cyber-Physical Systems operating in uncertain environments\" (Award 1837515) developed algorithms that enable machines that learn from their environment to make decisions about how and when to collect data. Animals are remarkable at this, able to reason about what information they need to learn something novel. Identifying novel objects and behaviors can be a safety-critical skill, and machines will sometimes not have offline data to learn from. For instance, a vehicle may become damaged during operation in a way that cannot be modeled from first principles, leading to a requirement that the vehicle quickly relearns how to operate. People are a source of uncertainty, since their skills, deficits, and intent are individualized; a robotic system supporting a human may need to learn from interaction. Despite these needs to reason over what data is needed and how to obtain it, most machine learning focuses on passively acquired data. This project created algorithms that enable a robot to explore an environment to build perceptual and dynamic models and then use those models for future decision making.  The work included development of real-time algorithms for identifying general environmental models and deployment of these techniques in hardware. Many of the application areas focused on human-robot interaction, where human decision-making is assisted by, or regulated by, an autonomous system. Some of these applications were very concrete, such as a driverless car system that assists with keeping a person safe while not interfering with the person?s intent. Some of the more far-reaching results include a human-machine interaction that leads to an emergent language that allows them to communicate.  \n\nThe work is important because robots routinely encounter novel situations for which no model exists and possibly no model can exist. In an era of Large Language Models and other AI techniques, this is a new frontier. Instead of focusing on regressing the entire internet, this work enables learning from specific instances of physically residing in a particular environment. This will enable health application (e.g., personalized physical therapy that adapts to the particular state of a person on a given day), security (e.g., identifying and collecting data about unprecedented signatures in an environment, and other learning tasks where response to environmental novelty is essential to task success. \n\nBoth simulated and physical systems were tested as part of the work, including autonomy interacting with people.  Physical experiments included robotic learning in complex terrain, robot ensembles searching an outdoor complex environment, and human machine interfaces. Simulated systems included quickly learning visual perception of novel objects, with no models of the objects or even the sensor. Software was implemented in a general manner, with all of it available as open source code.\n\nDuring the period of the award, important broader impact goals were accomplished.  Outreach at the Museum of Science and Industry, Chicago occurred in each year of the award, except the pandemic years when the museum was closed, reaching thousands of students.   All of the robotic experiments and non-clinical human-machine interfaces were used in the museum outreach.  Moreover, a class was developed at Northwestern University on active learning, the primary topic of this project. The class incorporates some of the results in lectures and in exercises. Algorithms developed as part of this effort have been applied at Northwestern University?s Feinberg School of Medicine using physical assistance robots. \n\n\t\t\t\t\tLast Modified: 10/31/2023\n\n\t\t\t\t\tSubmitted by: Todd D Murphey"
 }
}