{
 "awd_id": "1836819",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: Medium: Collaborative Research: Certifiable reinforcement learning for cyber-physical systems",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": "7032925394",
 "po_email": "rnash@nsf.gov",
 "po_sign_block_name": "Richard Nash",
 "awd_eff_date": "2018-09-15",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 666254.0,
 "awd_amount": 682254.0,
 "awd_min_amd_letter_date": "2018-08-29",
 "awd_max_amd_letter_date": "2021-07-20",
 "awd_abstract_narration": "We propose to generalize and certify the performance of reinforcement learning algorithms for control of cyber-physical systems (CPS). Broadly speaking, reinforcement learning applied to physical systems is concerned with making predictions from data to control the system to extremize a performance criterion. The project will particularly focus on developing theory and algorithms applicable to hybrid and multi-agent control systems, that is, systems with continuous and discrete elements and systems with multiple decision-making agents, which are ubiquitous in CPS across spatiotemporal scales and application domains. Reinforcement learning algorithms are not yet mature enough to guarantee performance when applied to control of CPS. In light of these limitations, this project aims to lay the theoretical and computational foundation to certify reinforcement learning algorithms so that they may be deployed in society with high confidence.\r\n\r\nThis project will certify reinforcement learning algorithms that compute optimal control policies in systems with non-classical dynamics and non-classical costs. To achieve this goal, we will generalize convergent algorithms originally designed for purely continuous systems to apply in hybrid control systems whose states undergo a mixture of discrete and continuous transitions. Moreover, we specifically aim to ensure this approach is applicable to societal-scale CPS in which multiple agents, some of which may be humans, interact directly with the CPS. These algorithms will be experimentally validated on three testbeds that represent a range of hybrid and multi-agent phenomena that arise in CPS. The first testbed will test the performance of our algorithms on societal-scale traffic flow networks via simulation. The second testbed will consider heterogeneous teams of aerial and terrestrial mobile robots collaborating with human partners to perform construction, inspection, and maintenance tasks on scale facsimiles of infrastructure like bridges, and tunnels. The third testbed will study the closed-loop interaction between individual humans and remote, teleoperated robots that perform dynamic locomotion and manipulation behaviors. This project will also co-organize an interdisciplinary workshop with technology policy experts, the results of which will form the basis for an interdisciplinary multi-campus graduate-level seminar run by the PIs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sam",
   "pi_last_name": "Burden",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sam Burden",
   "pi_email_addr": "sburden@uw.edu",
   "nsf_id": "000704018",
   "pi_start_date": "2018-08-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Lillian",
   "pi_last_name": "Ratliff",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lillian Ratliff",
   "pi_email_addr": "ratliffl@uw.edu",
   "nsf_id": "000717231",
   "pi_start_date": "2018-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "4333 Brooklyn Ave NE",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981950001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760700",
   "pgm_ele_name": "EPCN-Energy-Power-Ctrl-Netwrks"
  },
  {
   "pgm_ele_code": "791800",
   "pgm_ele_name": "CPS-Cyber-Physical Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "102Z",
   "pgm_ref_txt": "COVID-Disproportionate Impcts Inst-Indiv"
  },
  {
   "pgm_ref_code": "1653",
   "pgm_ref_txt": "Adaptive & intelligent systems"
  },
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 666254.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aimed to generalize and certify the performance of reinforcementlearning algorithms for control of cyber-physical systems (CPS). In particular,outcomes of the project including&nbsp;new theory, metrics, and methods for certifying algorithms that compute optimal control policies in systems with non-classical dynamics and non-classical costs.&nbsp; Broadly speaking, reinforcement learning applied to physical systems is concerned with making predictions from data to control the system to extremize a performance criterion. In this context, this project&nbsp; particularly focused on developing theory and algorithms applicable to hybrid and multi-agent control systems, that is, systems with continuous and discrete elements and systems with multiple decision-making agents, which are ubiquitous in CPS acrosss patio-temporal scales and application domains. While arguably reinforcement learning algorithms are not yet mature enough to guarantee performance when applied to control of complex CPS with learning enable components, this project made great strides in laying the theoretical and computational foundation to certify reinforcement learning algorithms so that they may be deployed in society with high confidence.</p>\n<p><br />&nbsp;To achieve this goal, the research team generalized convergent algorithms originally designed for purely continuous systems to apply in hybrid controlsystems whose states undergo a mixture of discrete and continuous transitions. Computationally efficient methods for ensuring additional desiderata such as saftey were developed. Moreover, the team developed techniques that targeted&nbsp; societal-scale CPS inwhich multiple agents, some of which may be humans, interact directly with the CPS. The developed algorithms and theoretical models were experimentally validated on three testbeds that represent a range of hybrid and multi-agent phenomena arising in CPS. The first testbed focuses on the performance of ouralgorithms on societal-scale traffic flow networks via simulation. The second testbed concerns heterogeneous teams of aerial and terrestrial mobile robots collaborating with human partners to perform construction, inspection, and maintenance tasks on scale facsimiles of infrastructure like bridges, andtunnels. The third testbed comprises both simulation and real-world experimental studies focused on the closed-loop interaction between individual humans and learning based systems. The latter test bed is motivated by CPS suchas teleoperated robots that perform dynamic locomotion and manipulation behaviors, human-in-the-loop societal scale CPS such as intelligent transportation, and multi-agent reinforcement learning broadly. Overall the project resulted in a wide range of results from fundamental new theory on non-smooth dynamical systems and multi-agent interactions to practically implementable algorithms to experimental validation in a variety of CPS context.&nbsp;</p>\n<p>The research team included not just the PIs and graduate students, but a numberof undergraduate researchers funded through REUs who contributed significantlyto the project, especially the simulation-based test beds which are now publiclyavailable for the community to use. Finally, the team disseminated the results to a range of different communities including industry, policy makers, governing bodies, and academia.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/14/2023<br>\n\t\t\t\t\tModified by: Lillian&nbsp;Ratliff</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project aimed to generalize and certify the performance of reinforcementlearning algorithms for control of cyber-physical systems (CPS). In particular,outcomes of the project including new theory, metrics, and methods for certifying algorithms that compute optimal control policies in systems with non-classical dynamics and non-classical costs.  Broadly speaking, reinforcement learning applied to physical systems is concerned with making predictions from data to control the system to extremize a performance criterion. In this context, this project  particularly focused on developing theory and algorithms applicable to hybrid and multi-agent control systems, that is, systems with continuous and discrete elements and systems with multiple decision-making agents, which are ubiquitous in CPS acrosss patio-temporal scales and application domains. While arguably reinforcement learning algorithms are not yet mature enough to guarantee performance when applied to control of complex CPS with learning enable components, this project made great strides in laying the theoretical and computational foundation to certify reinforcement learning algorithms so that they may be deployed in society with high confidence.\n\n\n To achieve this goal, the research team generalized convergent algorithms originally designed for purely continuous systems to apply in hybrid controlsystems whose states undergo a mixture of discrete and continuous transitions. Computationally efficient methods for ensuring additional desiderata such as saftey were developed. Moreover, the team developed techniques that targeted  societal-scale CPS inwhich multiple agents, some of which may be humans, interact directly with the CPS. The developed algorithms and theoretical models were experimentally validated on three testbeds that represent a range of hybrid and multi-agent phenomena arising in CPS. The first testbed focuses on the performance of ouralgorithms on societal-scale traffic flow networks via simulation. The second testbed concerns heterogeneous teams of aerial and terrestrial mobile robots collaborating with human partners to perform construction, inspection, and maintenance tasks on scale facsimiles of infrastructure like bridges, andtunnels. The third testbed comprises both simulation and real-world experimental studies focused on the closed-loop interaction between individual humans and learning based systems. The latter test bed is motivated by CPS suchas teleoperated robots that perform dynamic locomotion and manipulation behaviors, human-in-the-loop societal scale CPS such as intelligent transportation, and multi-agent reinforcement learning broadly. Overall the project resulted in a wide range of results from fundamental new theory on non-smooth dynamical systems and multi-agent interactions to practically implementable algorithms to experimental validation in a variety of CPS context. \n\nThe research team included not just the PIs and graduate students, but a numberof undergraduate researchers funded through REUs who contributed significantlyto the project, especially the simulation-based test beds which are now publiclyavailable for the community to use. Finally, the team disseminated the results to a range of different communities including industry, policy makers, governing bodies, and academia. \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 01/14/2023\n\n\t\t\t\t\tSubmitted by: Lillian Ratliff"
 }
}