{
 "awd_id": "1815821",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF:  Small:  An Information Theoretic Framework for Web Privacy",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 487080.0,
 "awd_amount": 487080.0,
 "awd_min_amd_letter_date": "2018-05-30",
 "awd_max_amd_letter_date": "2021-11-08",
 "awd_abstract_narration": "Internet users reasonably expect their online identities and web browsing activities to remain private. Unfortunately, this is far from the case in practice; in reality, users are constantly tracked on the internet. As web tracking technologies become more sophisticated and pervasive, there is a critical need to understand and quantify web users' privacy risk, that is, what is the likelihood that users on the internet can be uniquely identified from their online activities?\r\n\r\nThis project addresses web privacy from an information theoretic perspective.  Based on statistical models for online activity and social network connections, the project develops a unified information theoretic framework to quantify the privacy risk that web users face from online attacks. The proposed research addresses internet privacy through three interrelated thrusts focusing on fingerprinting, social network de-anonymization and synergistic attacks, and provides an evaluation plan to experiment with real-world networks.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Elza",
   "pi_last_name": "Erkip",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Elza Erkip",
   "pi_email_addr": "elza@nyu.edu",
   "nsf_id": "000488052",
   "pi_start_date": "2018-05-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Siddharth",
   "pi_last_name": "Garg",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Siddharth Garg",
   "pi_email_addr": "sg175@nyu.edu",
   "nsf_id": "000680915",
   "pi_start_date": "2018-05-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Farhad",
   "pi_last_name": "Shirani Chaharsooghi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Farhad Shirani Chaharsooghi",
   "pi_email_addr": "fshirani@fiu.edu",
   "nsf_id": "000758124",
   "pi_start_date": "2018-05-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 487080.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Internet and social media users frequently post content with the expectation of anonymity, for instance, via anonymous socual media accounts or by uploading health data that they expect will be anonymized. Unfortunately, by correlating data sources from across the internet, attackers can deanonymize personal details of users, creating significant privacy risk. Previous attacks have identified patient health records, user browsing history, shopping habits and anonymously posted movie ratings. An important first step in safeguarding users' privacy risk is quantifying it and understand the extent to which attackers can (and perhaps cannot) breach user privacy.</p>\n<p>In this project, we undertook a fresh approach to quantifying user privacy risk using tools from the discipline of information theory that seeks to understand the mathematical principles of how information is stored and communicated. Using tools from this discipline, in this project we have captured several fundamental \"bounds\" on the attacker's capabilities, essentially revealing mathematically what an attacker can and cannot under various circumstances. These include privacy attacks on social networks where attackers can track users over their many social media profiles even when they are linked to each other, and for databases, for instance, patient health records.&nbsp;</p>\n<p>Instances of settings for which we were able to demonstrate new bounds include social network deanonymization attacks where attackers have access to \"seeds\" --- a subset of users who have already been deanonymized. We studied the impact of the size of the seed set on the ability of attackers to deanonymize the remaining users. For databases, we studied settings where database entries might be deleted or corrupted; how do these deletion and corruptions impact the attacker success?</p>\n<p>A fundamental understanding of attacker's capabilities in deanonymizing users will lead to new defenses that protect user privacy on the internet. However, the problems we studied also arise in other domains unrelated to privacy, for instance, in computer vision and genetics. Thus, our results can have a positive impact in these areas as well. We have disseminated our results to communities of interest include academia and industry via publications, talks at conferences and other venues, and individual meetings. Undergraduate and graduate classes at the PIs' institutions have been enirched with new material on privacy risks in the digital age.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 04/08/2024<br>\nModified by: Siddharth&nbsp;Garg</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nInternet and social media users frequently post content with the expectation of anonymity, for instance, via anonymous socual media accounts or by uploading health data that they expect will be anonymized. Unfortunately, by correlating data sources from across the internet, attackers can deanonymize personal details of users, creating significant privacy risk. Previous attacks have identified patient health records, user browsing history, shopping habits and anonymously posted movie ratings. An important first step in safeguarding users' privacy risk is quantifying it and understand the extent to which attackers can (and perhaps cannot) breach user privacy.\n\n\nIn this project, we undertook a fresh approach to quantifying user privacy risk using tools from the discipline of information theory that seeks to understand the mathematical principles of how information is stored and communicated. Using tools from this discipline, in this project we have captured several fundamental \"bounds\" on the attacker's capabilities, essentially revealing mathematically what an attacker can and cannot under various circumstances. These include privacy attacks on social networks where attackers can track users over their many social media profiles even when they are linked to each other, and for databases, for instance, patient health records.\n\n\nInstances of settings for which we were able to demonstrate new bounds include social network deanonymization attacks where attackers have access to \"seeds\" --- a subset of users who have already been deanonymized. We studied the impact of the size of the seed set on the ability of attackers to deanonymize the remaining users. For databases, we studied settings where database entries might be deleted or corrupted; how do these deletion and corruptions impact the attacker success?\n\n\nA fundamental understanding of attacker's capabilities in deanonymizing users will lead to new defenses that protect user privacy on the internet. However, the problems we studied also arise in other domains unrelated to privacy, for instance, in computer vision and genetics. Thus, our results can have a positive impact in these areas as well. We have disseminated our results to communities of interest include academia and industry via publications, talks at conferences and other venues, and individual meetings. Undergraduate and graduate classes at the PIs' institutions have been enirched with new material on privacy risks in the digital age.\n\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 04/08/2024\n\n\t\t\t\t\tSubmitted by: SiddharthGarg\n"
 }
}