{
 "awd_id": "2039653",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Live Reality: Sustainable and Up-to-Date Information Quality in Live Social Media through Continuous Evidence-Based Knowledge Acquisition",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2020-09-01",
 "awd_max_amd_letter_date": "2023-08-28",
 "awd_abstract_narration": "Social media have complemented traditional press with immediate reports and worldwide coverage. However, they also receive and propagate significant amounts of misinformation and disinformation such as fake news. A skillful mixture of verifiable facts and outrageous fiction, fake news aim to attract reader attention, make an immediate initial impact, and then quickly forgotten. Even as disposable novelty, fake news have had significant impact on real world events such as elections. For human readers and machine learning (ML) classifiers, distinguishing fake news from real news has been challenging due to their sophisticated construction, camouflaging fiction with facts, as well as continuously evolving by incorporating the newest and hottest topics as they mutate. The Live Reality project will track the evolution of fake news through continuous import of reliable, verified facts from authoritative sources, and separate the facts from fiction, to catch fake news in the act. The automated real-time tracking capability is a significant innovation compared to traditional ML classifiers generated from manually labeled training data, which are constrained to finding historical fake news, long after the fact.\r\n\r\nGiven the short lifespan of disposable novelty (days or hours), catching fake news in the act requires significant innovation in two dimensions. First, the ML classifier must be continuously updated to recognize true novelty that have never been seen before. Second, the update must be sufficiently timely to catch disposable novelty before they expire, e.g., within hours of their initial dissemination. Continuous collection of live social media and authoritative sources will generate novel fake news and associated ground truth, which are integrated through the Evidence-Based Knowledge Acquisition (EBKA) approach, which adds reliable information from authoritative sources into a continuously adaptive teamed classifier to distinguish the verifiable facts from the fiction in fake news. As news topics evolve, fake news are expected to follow, and EBKA will generate and integrate new sub-models into the live teamed classifier to recognize the new topics. The EBKA approach will be demonstrated on live data containing fake news on a variety of topics, specifically disaster management such as the COVID-19 pandemic. Due to the disposable novelty nature of fake news, EBKA will be evaluated in two dimensions: classifier performance in terms of accuracy and precision, and timeliness of classifier identifying truly new fake news soon after their appearance in the real world.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Calton",
   "pi_last_name": "Pu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Calton Pu",
   "pi_email_addr": "calton@cc.gatech.edu",
   "nsf_id": "000432066",
   "pi_start_date": "2020-09-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Title of Project: EAGER: Live Reality: Sustainable and Up-to-Date Information Quality in Live Social Media through Continuous Evidence-Based Knowledge Acquisition</p>\r\n<p>Award Number: 2039653</p>\r\n<p>&nbsp;</p>\r\n<p>The project explored the challenges in the monitoring, collection, and analysis of rapidly changing knowledge about the real world. Examples of evolving knowledge include human-generated information such as social media and news, physical events such as natural disasters, and scientific discoveries such as new COVID-19 virus variants. Traditional deep learning models trained on closed datasets are limited to past knowledge. On their own, these classic machine learning models have difficulties recognizing never-seen-before novelty such as fake news, result of a process called Knowledge Obsolescence. To counter Knowledge Obsolescence, we have developed the Evidence-Based Knowledge Acquisition (EBKA) approach to augment static past knowledge with new up-to-date information from trusted sources, for example, new COVID discoveries reported by the Centers for Disease Control and Prevention (CDC). Through EBKA, we were able to automate the process of incorporating trusted new knowledge on fake news to overcome the Knowledge Obsolescence of previously trained models. Continuously updated teamed classifiers with new members trained through EBKA gained the ability to detect fresh fake news with higher accuracy and perhaps more importantly, at a timeframe (in a few days) much earlier than previously feasible using manual labeling (typically after a few months).</p>\r\n<p>As Large Language Models (LLMs) of significant capabilities (hundreds of billions of parameters and larger) became available in recent years, they still suffered Knowledge Obsolescence due to their static training datasets, even though LLMs have a much larger scale (by several orders of magnitude) than traditional manually labeled datasets for deep learning. Update techniques similar to EBKA have been developed to supplement LLMs with new information, including model refinements and RAG (retrieval-augmented generation), capable of adding knowledge generally. In this project, we have integrated EBKA with LLMs to demonstrate the feasibility of augmenting LLM with new knowledge acquired through EBKA. This line of research will continue in the LIKE (Live Information and Knowledge Evolution) project.</p>\r\n<p>In research, the project provided partial support for the publication of several papers on Live Knowledge, including 2 ACM journal articles, 5 IEEE conference papers, plus several arXiv reports and repositories of public data and accompanying software tools. In education and training, these datasets and software tools have been used by more than 100 project students at all levels in their training on evolving knowledge-related technologies. The project supported 3 PhD students and more than 10 MS students as TA/managers of the student projects.</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/24/2025<br>\nModified by: Calton&nbsp;Pu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nTitle of Project: EAGER: Live Reality: Sustainable and Up-to-Date Information Quality in Live Social Media through Continuous Evidence-Based Knowledge Acquisition\r\n\n\nAward Number: 2039653\r\n\n\n\r\n\n\nThe project explored the challenges in the monitoring, collection, and analysis of rapidly changing knowledge about the real world. Examples of evolving knowledge include human-generated information such as social media and news, physical events such as natural disasters, and scientific discoveries such as new COVID-19 virus variants. Traditional deep learning models trained on closed datasets are limited to past knowledge. On their own, these classic machine learning models have difficulties recognizing never-seen-before novelty such as fake news, result of a process called Knowledge Obsolescence. To counter Knowledge Obsolescence, we have developed the Evidence-Based Knowledge Acquisition (EBKA) approach to augment static past knowledge with new up-to-date information from trusted sources, for example, new COVID discoveries reported by the Centers for Disease Control and Prevention (CDC). Through EBKA, we were able to automate the process of incorporating trusted new knowledge on fake news to overcome the Knowledge Obsolescence of previously trained models. Continuously updated teamed classifiers with new members trained through EBKA gained the ability to detect fresh fake news with higher accuracy and perhaps more importantly, at a timeframe (in a few days) much earlier than previously feasible using manual labeling (typically after a few months).\r\n\n\nAs Large Language Models (LLMs) of significant capabilities (hundreds of billions of parameters and larger) became available in recent years, they still suffered Knowledge Obsolescence due to their static training datasets, even though LLMs have a much larger scale (by several orders of magnitude) than traditional manually labeled datasets for deep learning. Update techniques similar to EBKA have been developed to supplement LLMs with new information, including model refinements and RAG (retrieval-augmented generation), capable of adding knowledge generally. In this project, we have integrated EBKA with LLMs to demonstrate the feasibility of augmenting LLM with new knowledge acquired through EBKA. This line of research will continue in the LIKE (Live Information and Knowledge Evolution) project.\r\n\n\nIn research, the project provided partial support for the publication of several papers on Live Knowledge, including 2 ACM journal articles, 5 IEEE conference papers, plus several arXiv reports and repositories of public data and accompanying software tools. In education and training, these datasets and software tools have been used by more than 100 project students at all levels in their training on evolving knowledge-related technologies. The project supported 3 PhD students and more than 10 MS students as TA/managers of the student projects.\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 02/24/2025\n\n\t\t\t\t\tSubmitted by: CaltonPu\n"
 }
}