{
 "awd_id": "1954830",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research:SHF:Medium:Bringing Python Up to Speed",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 377053.0,
 "awd_amount": 377053.0,
 "awd_min_amd_letter_date": "2020-06-17",
 "awd_max_amd_letter_date": "2020-06-17",
 "awd_abstract_narration": "The Python programming language is among today's most popular computer programming languages and is used to write software in a wide variety of domains, from web services to data analysis to machine learning. Unfortunately, Python\u2019s lightweight and flexible nature -- a major source of its appeal -- can cause significant performance and correctness problems - Python programs can suffer slowdowns as high as 60,000x over optimized code written in traditional programming languages like C and C++, and can require an order-of-magnitude more memory.  Python's flexible, \u201cdynamic\u201d features also make its programs error-prone, with many coding errors only being discovered late in development or after deployment. Python\u2019s frequent use as a \"glue language\" -- to integrate and interact with different components written in C or C++ -- exposes many Python programs to the unique dangers of those languages, including susceptibility to memory corruption-based security vulnerabilities. This project aims to remedy these problems by developing new technology for Python in the form of novel performance analysis tools, memory-reduction and speed-improving optimizations (including support for multi-core execution), automated software testing frameworks, and common benchmarks to drive their evaluation.\r\n\r\nThis project will develop (1) performance analysis tools that help Python programmers accurately identify the sources of slowdowns; (2) techniques for automatically identifying code that can be replaced by calls to C/C++ libraries; (3) an approach to unlocking parallelism in Python threads, which currently must execute sequentially due to a global interpreter lock; and (4) automatic techniques to drastically reduce the memory footprints of Python applications. To improve the correctness of Python applications, the project will develop novel automated testing techniques that (1) augment property-based random testing with coverage-guided fuzzing; (2) employ concolic execution for smarter test generation and input minimization; (3) synthesize property-specific generator functions; (4) leverage statistical clustering techniques to reduce duplicated failure-inducing inputs; and (5) leverage parallelism and adaptive scheduling algorithms to increase testing throughput. The project will develop a set of \"bug benchmarks\" -- indeed, a novel benchmark-producing methodology -- to evaluate these techniques. The twin threads of performance and correctness are synergistic and complementary: automatic testing drives performance analysis, while performance optimizations (like parallelism) speed automatic testing.\r\n\r\nThis award is co-funded by the Software & Hardware Foundations Program in the Division of Computer & Computing Foundations, and the NSF Office of Advanced Cyberinfrastructure.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Emery",
   "pi_last_name": "Berger",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Emery D Berger",
   "pi_email_addr": "emery@cs.umass.edu",
   "nsf_id": "000483414",
   "pi_start_date": "2020-06-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "100 Venture Way, Suite 201",
  "perf_city_name": "Hadley",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010359450",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "689200",
   "pgm_ele_name": "CI REUSE"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "077Z",
   "pgm_ref_txt": "CSSI-1: Cyberinfr for Sustained Scientif"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  },
  {
   "pgm_ref_code": "8004",
   "pgm_ref_txt": "Software Institutes"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 377053.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-2b85b829-7fff-0169-1c41-8c22f164eea0\">\n<h1 dir=\"ltr\"><span style=\"color: #000000; font-size: 12px; font-weight: normal;\">The aim of this project was to dramatically increase the performance and correctness of applications written in Python by developing novel performance analysis tools, novel optimizations, and novel automatic testing frameworks. These are mostly tailored to and implemented for Python, but applicable in other similar languages.&nbsp;&nbsp;</span></h1>\n<p dir=\"ltr\"><span>The project's major outcomes related to performance are (1) development of a new Python performance profiler, called Scalene, which has been released to the community to rapid uptake (downloaded almost 750,000 times already), (2) designing and integrating a new metric tracked by Scalene, called copy volume, that identifies costly copying within and across library boundaries, (3) designing a novel low-cost approach to memory tracking, letting Scalene produce line-level memory profiles at real-time, running orders of magnitude than previous work, (4) designing and integrating an algorithm to tease apart Python, native, and I/O time, all at a line granularity, (5) developing a novel on-the-fly, low cost and high precision automatic memory leak detection for Python, and (6) incorporating GPU profiling, at line granularity.</span></p>\n<p dir=\"ltr\"><span>The major outcomes related to correctness are (1) developing a manual mutation testing framework for Python that integrates with two popular testing frameworks (Hypothesis and pytest), (2) developing methods for symbolic execution of multilingual programs that contain both Python code and low-level C++ code, (3) exploring the minimization behavior of Hypothesis with particular emphasis on bug slippage, (4) showing how random test-case generation can be improved using ideas from the combinatorial testing literature, (5) building&nbsp; a publicly available evaluation platform for property based testing generators, called ETNA, that offers cross-language and cross-tool support for evaluating the efficiency and effectiveness of property-based testing generators and enumerators, (6) developing Slipcover, a fast code coverage tool that dramatically reduces the overhead of collecting the line coverage information needed by coverage-guided fuzzers, (7) generalizing targeted property-based testing on top of Hypothesis to take advantage of Slipcover and perform coverage-guided fuzzing efficiently, (8) deriving automatic targeting functions from Hypothesis preconditions that facilitate more effective test generation in the presence of assume statements, and (9) conducting a large user study with software developers at Jane Street Capital, with the goal of identifying both challenges (places where people are having difficulty applying PBT tools and methods) and opportunities (places where PBT could be applied to real-world problems, perhaps with improved tooling and/or better education).</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/09/2023<br>\n\t\t\t\t\tModified by: Emery&nbsp;Berger</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThe aim of this project was to dramatically increase the performance and correctness of applications written in Python by developing novel performance analysis tools, novel optimizations, and novel automatic testing frameworks. These are mostly tailored to and implemented for Python, but applicable in other similar languages.  \nThe project's major outcomes related to performance are (1) development of a new Python performance profiler, called Scalene, which has been released to the community to rapid uptake (downloaded almost 750,000 times already), (2) designing and integrating a new metric tracked by Scalene, called copy volume, that identifies costly copying within and across library boundaries, (3) designing a novel low-cost approach to memory tracking, letting Scalene produce line-level memory profiles at real-time, running orders of magnitude than previous work, (4) designing and integrating an algorithm to tease apart Python, native, and I/O time, all at a line granularity, (5) developing a novel on-the-fly, low cost and high precision automatic memory leak detection for Python, and (6) incorporating GPU profiling, at line granularity.\nThe major outcomes related to correctness are (1) developing a manual mutation testing framework for Python that integrates with two popular testing frameworks (Hypothesis and pytest), (2) developing methods for symbolic execution of multilingual programs that contain both Python code and low-level C++ code, (3) exploring the minimization behavior of Hypothesis with particular emphasis on bug slippage, (4) showing how random test-case generation can be improved using ideas from the combinatorial testing literature, (5) building  a publicly available evaluation platform for property based testing generators, called ETNA, that offers cross-language and cross-tool support for evaluating the efficiency and effectiveness of property-based testing generators and enumerators, (6) developing Slipcover, a fast code coverage tool that dramatically reduces the overhead of collecting the line coverage information needed by coverage-guided fuzzers, (7) generalizing targeted property-based testing on top of Hypothesis to take advantage of Slipcover and perform coverage-guided fuzzing efficiently, (8) deriving automatic targeting functions from Hypothesis preconditions that facilitate more effective test generation in the presence of assume statements, and (9) conducting a large user study with software developers at Jane Street Capital, with the goal of identifying both challenges (places where people are having difficulty applying PBT tools and methods) and opportunities (places where PBT could be applied to real-world problems, perhaps with improved tooling and/or better education).\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 08/09/2023\n\n\t\t\t\t\tSubmitted by: Emery Berger"
 }
}