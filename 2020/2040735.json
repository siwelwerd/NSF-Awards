{
 "awd_id": "2040735",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NSF Convergence Accelerator Track D: Rapid Development of Intelligent, Built Environment Geo-Databases Using AI and Data-Driven Models",
 "cfda_num": "47.084",
 "org_code": "15020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Mike Pozmantier",
 "awd_eff_date": "2020-09-15",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 920000.0,
 "awd_amount": 920000.0,
 "awd_min_amd_letter_date": "2020-09-04",
 "awd_max_amd_letter_date": "2020-11-24",
 "awd_abstract_narration": "The NSF Convergence Accelerator supports use-inspired, team-based, multidisciplinary efforts that address challenges of national importance and will produce deliverables of value to society in the near future. The broader impact and potential societal benefit of this Convergence Accelerator Phase I project is to achieve what is seen as the Holy Grail by the Built Environment research community and industry. Infrastructure designers and planners increasingly require detailed three dimensional (3D) geospatial databases of the Built Environment, in order to consider human scale perceptions, which today are often overlooked but critical to improving cities in order to better meet the needs of its citizens and other emerging technologies, such as autonomous vehicles. The impact on society of applying Artificial Intelligence (AI) to rapidly create secure and intelligent 3D models of the Built Environment, including horizontal (e.g., highway, bridges) and vertical (e.g., buildings, plants) facilities, by turning raw data into actionable information cannot be overstated. However, to-date, assembling and maintaining those databases has been too expensive for even the most progressive cities due in large part to the cost of manual feature extraction. Built Environment data that is accurate and reliable is critical for the well-being of communities as such data is used for a variety of purposes including emergency preparedness, asset operations, maintenance, public safety, and more. A convergent, innovative team will be formed with industry partners to ensure that the knowledge developed through this research effectively transitions into many aspects of practice.  From the outset, and through both phases of the project, the team is taking steps through team building and intentional engagement with a variety of stakeholders to broaden the scope of potential impacts of the proposed innovation. Specifically, the research and implementation activities will be designed to consistently include dialogue and invite input from a broad range of interests, intentionally seeking involvement with segments of the public that are traditionally left out or neglected in technology implementation endeavors. This research also implements activities for workforce development in computer vision and geomatics, which currently has a large gap between employment needs and a workforce of appropriately skilled personnel, particularly from underrepresented backgrounds. \r\n\r\n\r\nCurrent workflows and procedures to develop 3D models of the Built Environment require substantial manual effort. Those processes that are automated are limited to small datasets that are not representative of the current point clouds and other data being acquired or needed for Building Information Modeling (BIM). They are also limited in the types of objects that can be modeled. To this end, the interdisciplinary research team will work with stakeholders to develop a more holistic Scan-to-BIM process. Phase I of this project  has two primary goals: (1) provide a scan-to-BIM validation tool by compiling a sizable collection of benchmark datasets with annotated point cloud scans and corresponding BIM models, creating a prototype validation server with metrics related to parameters of interest to stakeholders (e.g., evaluate the accuracy of modeled door widths, which are important to ADA compliance assessment, or evaluate these models for urban renewal, redevelopment projects), and create and host a Scan-to-BIM challenge for researchers all over the world to participate, and (2) develop a prototype tool to implement a holistic Scan-to-BIM framework to rapidly and reliably generate BIM models from scan data that can be used not only to facilitate the development of the benchmark datasets but also used by stakeholders. Based on the research resulting from these challenges, the project team plans to build a comprehensive cloud-based service for Scan-to-BIM, which will be deployed to serve the Architectural/Engineering/Construction (AEC) community, and ultimately the public in general as these models can decrease construction or renovation project costs of public infrastructure funded with taxpayer\u2019s money. Users would be able to select desired algorithms for key stages of the Scan-to-BIM framework based on their performance for specific applications and use cases.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "ITE",
 "org_div_long_name": "Innovation and Technology Ecosystems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yelda",
   "pi_last_name": "Turkan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yelda Turkan",
   "pi_email_addr": "yelda.turkan@oregonstate.edu",
   "nsf_id": "000692641",
   "pi_start_date": "2020-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yong",
   "pi_last_name": "Cho",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Yong K Cho",
   "pi_email_addr": "yong.cho@ce.gatech.edu",
   "nsf_id": "000492865",
   "pi_start_date": "2020-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Olsen",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Michael J Olsen",
   "pi_email_addr": "michael.olsen@oregonstate.edu",
   "nsf_id": "000560441",
   "pi_start_date": "2020-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Fuxin",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Fuxin Li",
   "pi_email_addr": "lif@eecs.oregonstate.edu",
   "nsf_id": "000637562",
   "pi_start_date": "2020-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Roger",
   "pi_last_name": "Chen",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Roger B Chen",
   "pi_email_addr": "rbchen@hawaii.edu",
   "nsf_id": "000809806",
   "pi_start_date": "2020-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Oregon State University",
  "inst_street_address": "1500 SW JEFFERSON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CORVALLIS",
  "inst_state_code": "OR",
  "inst_state_name": "Oregon",
  "inst_phone_num": "5417374933",
  "inst_zip_code": "973318655",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "OR04",
  "org_lgl_bus_name": "OREGON STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "MZ4DYXE1SL98"
 },
 "perf_inst": {
  "perf_inst_name": "Oregon State University",
  "perf_str_addr": "",
  "perf_city_name": "Corvallis",
  "perf_st_code": "OR",
  "perf_st_name": "Oregon",
  "perf_zip_code": "973312140",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "OR04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131Y00",
   "pgm_ele_name": "Convergence Accelerator Resrch"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 920000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"BasicParagraph\">Architects, Engineers, Contractors, and Owners need reliable 3D digital models of the physical world to render informed decisions regarding the planning, design, construction, and management of the Built Environment. The rise in 3D sensor technologies such as lidar and 360 cameras have enabled the rapid collection of rich 3D data but transforming this data into useful 3D models is tedious, time-consuming, and expensive. Our prototype AI-based InstaTwin technology developed through the Convergence Accelerator Program automatically segments, classifies, and extracts real-world features from 3D data to create digital representations of reality to address the barriers of creating 3D models.&nbsp;&nbsp;Furthermore, the AI components of InstaTwin have broad applicability and far-reaching impact on equity, energy, and sustainability.&nbsp;</p>\n<p class=\"BasicParagraph\">Buildings account for 40% of the world?s energy consumption primarily because older buildings are not efficient. Transitioning old building stock to energy-efficient buildings is an essential component of reaching global ecological sustainability. To achieve this transition, we need better ways to assess, analyze, monitor, renovate, and alter the behavior of buildings in real-time to optimize and reduce the use of fuels for heating, lighting, and cooling. Fundamental to this idea is having a digital representation of a building.</p>\n<p class=\"BasicParagraph\">The InstaTwin platform we developed during this project enables 3D models of the Built Environment to be created through a digitization process of the physical world. The process consists of collecting 3D data from sensors such as laser scanners (i.e., lidar) and 360 cameras and the converting these data into 3D objects. The resulting 3D model is sometimes called a ?digital twin? or building information model (i.e., BIM).</p>\n<p class=\"BasicParagraph\">To better understand this digitization process, consider the process of flatbed scanning, where a flatbed scanner captures a pixelized image of a physical document. The captured image is helpful as a digital record; however, the true value of the scan is the words contained within the image. Transcribing these words manually is a time-consuming process, and technologies such as Optical Character Recognition (OCR) significantly increased the accessibility to and utility of the information in the scanned document. &nbsp;</p>\n<p class=\"BasicParagraph\">Similarly, scanning a building is analogous to scanning a document. Instead of a flatbed, however, a 3D laser scanner spins around on a tripod and measure the contents of a building. The resulting scan data, called a ?point cloud,? is useful as a digital record, but the true value is the objects and building elements contained within the scan. Transcribing these objects is considerably more time-consuming than the transcription of words and, as of today, there exists no equivalent to OCR for the creation of BIM.</p>\n<p class=\"BasicParagraph\">InstaTwin is a prototype platform that automatically generates 3D building models from scans. This conversion is an incredibly difficult problem since buildings can be very complex, but with the power of AI, InstaTwin empowers asset owners, architects, engineers, and facility managers to make better, faster, and more efficient decisions about the Built Environment. Fundamentally, InstaTwin is a data repository and processing framework that can be accessed online. Collaborators and users submit data, test algorithms, process data into 3D models, view results, and download BIMs. Implicit in our design is a framework that can provide immediate industry benefit and thus incentivizing users to supply data, train models, and support its continued development.</p>\n<p class=\"BasicParagraph\">To develop the prototype Insta-Twin platform, the team participated in the extensive NSF accelerator training course to learn effective strategies for convergent research and ideation. They also conducted several interviews of industry professionals to identify key bottlenecks as well as determine how it would integrate within their workflows.&nbsp;&nbsp;Several of these professionals attended ideation workshops and provided feedback on the prototype.&nbsp;&nbsp;In parallel to developing the prototype platform, the research team compiled a vast database of point cloud data with corresponding building information models and CAD floorplans. These data were shared for a challenge competition at two workshops focused on converging the computer vision, architecture, engineering, and construction communities.&nbsp;&nbsp;</p>\n<p class=\"BasicParagraph\">&nbsp;</p>\n<p class=\"BasicParagraph\">&nbsp;</p>\n<p class=\"BasicParagraph\">&nbsp;</p>\n<p class=\"BasicParagraph\">&nbsp;</p>\n<p class=\"BasicParagraph\">&nbsp;</p>\n<p class=\"BasicParagraph\">&nbsp;</p>\n<p class=\"BasicParagraph\">&nbsp;</p>\n<p class=\"BasicParagraph\">&nbsp;</p>\n<p class=\"BasicParagraph\">&nbsp;</p>\n<p class=\"BasicParagraph\">&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/06/2022<br>\n\t\t\t\t\tModified by: Yelda&nbsp;Turkan</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/2040735/2040735_10705267_1659824554629_InstaTwin--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/2040735/2040735_10705267_1659824554629_InstaTwin--rgov-800width.jpg\" title=\"InstaTwin Interface\"><img src=\"/por/images/Reports/POR/2022/2040735/2040735_10705267_1659824554629_InstaTwin--rgov-66x44.jpg\" alt=\"InstaTwin Interface\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">InstaTwin - convert lidar point clouds into 3D models</div>\n<div class=\"imageCredit\">Luisa Parker</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yelda&nbsp;Turkan</div>\n<div class=\"imageTitle\">InstaTwin Interface</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "Architects, Engineers, Contractors, and Owners need reliable 3D digital models of the physical world to render informed decisions regarding the planning, design, construction, and management of the Built Environment. The rise in 3D sensor technologies such as lidar and 360 cameras have enabled the rapid collection of rich 3D data but transforming this data into useful 3D models is tedious, time-consuming, and expensive. Our prototype AI-based InstaTwin technology developed through the Convergence Accelerator Program automatically segments, classifies, and extracts real-world features from 3D data to create digital representations of reality to address the barriers of creating 3D models.  Furthermore, the AI components of InstaTwin have broad applicability and far-reaching impact on equity, energy, and sustainability. \nBuildings account for 40% of the world?s energy consumption primarily because older buildings are not efficient. Transitioning old building stock to energy-efficient buildings is an essential component of reaching global ecological sustainability. To achieve this transition, we need better ways to assess, analyze, monitor, renovate, and alter the behavior of buildings in real-time to optimize and reduce the use of fuels for heating, lighting, and cooling. Fundamental to this idea is having a digital representation of a building.\nThe InstaTwin platform we developed during this project enables 3D models of the Built Environment to be created through a digitization process of the physical world. The process consists of collecting 3D data from sensors such as laser scanners (i.e., lidar) and 360 cameras and the converting these data into 3D objects. The resulting 3D model is sometimes called a ?digital twin? or building information model (i.e., BIM).\nTo better understand this digitization process, consider the process of flatbed scanning, where a flatbed scanner captures a pixelized image of a physical document. The captured image is helpful as a digital record; however, the true value of the scan is the words contained within the image. Transcribing these words manually is a time-consuming process, and technologies such as Optical Character Recognition (OCR) significantly increased the accessibility to and utility of the information in the scanned document.  \nSimilarly, scanning a building is analogous to scanning a document. Instead of a flatbed, however, a 3D laser scanner spins around on a tripod and measure the contents of a building. The resulting scan data, called a ?point cloud,? is useful as a digital record, but the true value is the objects and building elements contained within the scan. Transcribing these objects is considerably more time-consuming than the transcription of words and, as of today, there exists no equivalent to OCR for the creation of BIM.\nInstaTwin is a prototype platform that automatically generates 3D building models from scans. This conversion is an incredibly difficult problem since buildings can be very complex, but with the power of AI, InstaTwin empowers asset owners, architects, engineers, and facility managers to make better, faster, and more efficient decisions about the Built Environment. Fundamentally, InstaTwin is a data repository and processing framework that can be accessed online. Collaborators and users submit data, test algorithms, process data into 3D models, view results, and download BIMs. Implicit in our design is a framework that can provide immediate industry benefit and thus incentivizing users to supply data, train models, and support its continued development.\nTo develop the prototype Insta-Twin platform, the team participated in the extensive NSF accelerator training course to learn effective strategies for convergent research and ideation. They also conducted several interviews of industry professionals to identify key bottlenecks as well as determine how it would integrate within their workflows.  Several of these professionals attended ideation workshops and provided feedback on the prototype.  In parallel to developing the prototype platform, the research team compiled a vast database of point cloud data with corresponding building information models and CAD floorplans. These data were shared for a challenge competition at two workshops focused on converging the computer vision, architecture, engineering, and construction communities.  \n \n \n \n \n \n \n \n \n \n \n\n \n\n\t\t\t\t\tLast Modified: 08/06/2022\n\n\t\t\t\t\tSubmitted by: Yelda Turkan"
 }
}