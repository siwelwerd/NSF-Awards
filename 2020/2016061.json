{
 "awd_id": "2016061",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: SaTC: CORE: Medium: Threat Intelligence for Targets of Coordinated Harassment",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 808000.0,
 "awd_amount": 824000.0,
 "awd_min_amd_letter_date": "2020-08-26",
 "awd_max_amd_letter_date": "2023-02-27",
 "awd_abstract_narration": "Coordinated online harassment by collections of individuals and groups is a scourge of the modern Internet. It has upended and cost lives, silenced voices, and is making our public discourse more cruel and less representative. The phenomenon creates challenges for those who seek an equitable, secure and trustworthy internet to reduce the threat of coordinated attacks and handle attacks swiftly and effectively. Using the research team's past experiences with a clinical model that has been useful in helping victims of intimate partner violence, and new understandings of how to handle coordinated harassment to reduce harms and provide active assistance to targets of harassment, this project pilots an advice clinic. To ensure that the work has practical, real world impact, the project is also developing materials and working with platforms, threat intelligence companies, and non-profit organizations that help targets of online harassment .\r\n\r\nThe project uses a comprehensive set of technical and human-centered methods to advance  our understanding of coordinated harassment threats and mitigation techniques. The coordination of harassment allows harassers to scale their attacks, but also provides defenders with an opportunity to monitor attackers. This project will study how threat intelligence---an emerging area of cybersecurity that has enabled the blocking, detecting, and remediation of cyberattacks---can be used to monitor channels where coordinated harassment and doxing campaigns happen, understand escalation processes, identify pain points, and prioritize courses of action for platforms, law enforcement, and targeted individuals. The multidisciplinary team and mixed methods approach will enable the project to not only build sophisticated tools, but also build scientific knowledge in multiple fields and to understand whether and how the proposed tools can contribute solutions to a complex societal problem.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rachel",
   "pi_last_name": "Greenstadt",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rachel Greenstadt",
   "pi_email_addr": "greenstadt@nyu.edu",
   "nsf_id": "000514368",
   "pi_start_date": "2020-08-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Damon",
   "pi_last_name": "McCoy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Damon McCoy",
   "pi_email_addr": "dm181@nyu.edu",
   "nsf_id": "000616444",
   "pi_start_date": "2020-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "370 Jay Street",
  "perf_city_name": "Brooklyn",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "112013828",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "NY07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "065Z",
   "pgm_ref_txt": "Human factors for security research"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 808000.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-a01c4ce0-7fff-a75d-0fb6-42fdd2d97dd5\"> </span></p>\r\n<p dir=\"ltr\"><span>Our project created a comprehensive set of technical and human-centered methods to advance our understanding of coordinated harassment threats and mitigation techniques.&nbsp; The coordination of harassment allows harassers to scale their attacks but also provides defenders with an opportunity to monitor attackers. We studied how threat intelligence&mdash;an emerging area of security that has enabled the blocking, detecting, and remediation of cyberattacks&mdash;can be used to monitor channels where coordinated harassment and doxing campaigns happen, understand escalation processes, identify pain points, and prioritize courses of action for platforms, law enforcement, and targeted individuals. We built scalable data collection frameworks and automated processing techniques that scale and commoditize the creation of low-cost valuable threat intelligence.</span></p>\r\n<p dir=\"ltr\"><span>We collaborated on a study with academics and industry which demonstrated that existing security, privacy, and antiabuse protections fail to address the growing threat of online hate and harassment. To understand and address this gap, we proposed a taxonomy for reasoning about online hate and harassment. Our taxonomy identified seven classes of attacks, such as toxic content and surveillance, that each stems from different attacker capabilities and intents. We found that hate and harassment are a pervasive, growing experience for online users, particularly for at-risk communities like young adults, based on our longitudinal three-year survey. In addition to scaling harassment through incitement and coordination, online communities that commonly engage in harassment are likely a source of innovation for harassment attack strategies. We created a large-scale open-source data analysis pipeline and machine learning model to discover incitements to harassment that span multiple platforms. Our approach and open-source tools can be used to generate threat intelligence about ongoing coordinated harassment threats and tactics.</span></p>\r\n<p dir=\"ltr\"><span>We studied how some communities sustain long-term harassment campaigns. </span><span>&nbsp;</span><span>We found that internet service providers can unwittingly worsen harassment campaigns by passing along PII to harassers.</span><span> Deepfake technology is often used to create non-consensual pornographic videos in concert with other coordinated harassment methods. We studied how difficult it was for non-experts to create convincing deepfakes and also the ways in which the deepfake creation community organizes online to learn, discuss, sell, and distribute deepfake videos. We also studied the robustness of several deepfake detection techniques.</span></p>\r\n<p dir=\"ltr\"><span>People Search Websites, a category of data brokers, collect, catalog, monetize and often publicly display individuals' personally identifiable information (PII). We studied user privacy rights in 20 such websites assessing the usability of data access and data removal mechanisms. We combined insights from these two processes to determine connections between sites, such as shared access mechanisms or removal effects. We find that data access requests are mostly unsuccessful. Instead, sites cite a variety of legal exceptions or misinterpret the nature of the requests. By purchasing reports, we found that only one set of connected sites provided access to the same report they sell to customers.&nbsp;</span></p>\r\n<p dir=\"ltr\"><span>This project significantly contributed to the education of nine PhD students, six of which have graduated into positions in academia and industry, one postdoctoral scholar who is now a faculty member, and two undergraduate REUs who successfully published their work and are now pursuing further study.</span></p>\r\n<p dir=\"ltr\"><span>We have affirmed the thesis of this project that large scale data analysis and human center approaches can generate useful threat intelligence for mitigating coordinated harassment. The detection and mitigation approaches that we created have been released as open source so that they can be adopted by social media networks and other independent third-parties such as researchers.</span></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/14/2025<br>\nModified by: Rachel&nbsp;Greenstadt</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \r\n\n\nOur project created a comprehensive set of technical and human-centered methods to advance our understanding of coordinated harassment threats and mitigation techniques. The coordination of harassment allows harassers to scale their attacks but also provides defenders with an opportunity to monitor attackers. We studied how threat intelligencean emerging area of security that has enabled the blocking, detecting, and remediation of cyberattackscan be used to monitor channels where coordinated harassment and doxing campaigns happen, understand escalation processes, identify pain points, and prioritize courses of action for platforms, law enforcement, and targeted individuals. We built scalable data collection frameworks and automated processing techniques that scale and commoditize the creation of low-cost valuable threat intelligence.\r\n\n\nWe collaborated on a study with academics and industry which demonstrated that existing security, privacy, and antiabuse protections fail to address the growing threat of online hate and harassment. To understand and address this gap, we proposed a taxonomy for reasoning about online hate and harassment. Our taxonomy identified seven classes of attacks, such as toxic content and surveillance, that each stems from different attacker capabilities and intents. We found that hate and harassment are a pervasive, growing experience for online users, particularly for at-risk communities like young adults, based on our longitudinal three-year survey. In addition to scaling harassment through incitement and coordination, online communities that commonly engage in harassment are likely a source of innovation for harassment attack strategies. We created a large-scale open-source data analysis pipeline and machine learning model to discover incitements to harassment that span multiple platforms. Our approach and open-source tools can be used to generate threat intelligence about ongoing coordinated harassment threats and tactics.\r\n\n\nWe studied how some communities sustain long-term harassment campaigns. We found that internet service providers can unwittingly worsen harassment campaigns by passing along PII to harassers. Deepfake technology is often used to create non-consensual pornographic videos in concert with other coordinated harassment methods. We studied how difficult it was for non-experts to create convincing deepfakes and also the ways in which the deepfake creation community organizes online to learn, discuss, sell, and distribute deepfake videos. We also studied the robustness of several deepfake detection techniques.\r\n\n\nPeople Search Websites, a category of data brokers, collect, catalog, monetize and often publicly display individuals' personally identifiable information (PII). We studied user privacy rights in 20 such websites assessing the usability of data access and data removal mechanisms. We combined insights from these two processes to determine connections between sites, such as shared access mechanisms or removal effects. We find that data access requests are mostly unsuccessful. Instead, sites cite a variety of legal exceptions or misinterpret the nature of the requests. By purchasing reports, we found that only one set of connected sites provided access to the same report they sell to customers.\r\n\n\nThis project significantly contributed to the education of nine PhD students, six of which have graduated into positions in academia and industry, one postdoctoral scholar who is now a faculty member, and two undergraduate REUs who successfully published their work and are now pursuing further study.\r\n\n\nWe have affirmed the thesis of this project that large scale data analysis and human center approaches can generate useful threat intelligence for mitigating coordinated harassment. The detection and mitigation approaches that we created have been released as open source so that they can be adopted by social media networks and other independent third-parties such as researchers.\r\n\n\n\t\t\t\t\tLast Modified: 01/14/2025\n\n\t\t\t\t\tSubmitted by: RachelGreenstadt\n"
 }
}