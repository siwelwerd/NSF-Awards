{
 "awd_id": "2038479",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps: Creating data sets that are distilled into collections of information that may be used to answer questions in real-time",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922160",
 "po_email": "rshuman@nsf.gov",
 "po_sign_block_name": "Ruth Shuman",
 "awd_eff_date": "2020-07-15",
 "awd_exp_date": "2021-12-31",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2020-07-22",
 "awd_max_amd_letter_date": "2020-07-22",
 "awd_abstract_narration": "The broader impact/commercial potential of this I-Corps project is the development of low-cost, industry agnostic, artificial intelligence resources. Presently, data analysts and data science teams face one primary problem: data cleanliness. Data cleanliness is a measure of corrupt or inaccurate records from a record set or table.  To clean a database one must identify incomplete or incorrect parts of the data and then replace, modify, or delete the bad data. Machine learning models often perform well in lab conditions but fail in the real world due to dirty data. Artificial intelligence solutions are inhibited in real world applications due to too little signaling data amidst the noise. The proposed technology solves the problems that face many data scientists who dependent on the dirty data at hand. There is a demand for faster, better decision making across virtually every industry. The goal is to strategically solve the data cleanliness problem, with protectable intellectual property and processes, for various industries after refining internal processes, user interface, and value propositions for the initial technology target: financial institutions.\r\n\r\nThis I-Corps project is based on the development of novel artificial intelligence resources to automate data preparation, augmentation, and governance processes. These resources include proprietary machine learning algorithms, unique data librarying processes, dynamic training sets, next generation database technology, and intelligent rules engines to reimagine the expensive, high-effort, and highly technical space of data science. The novel approach of this project will automate over 60% of a data scientists\u2019 workload, reduce cost, minimize internal IT resource demands, and increase information access.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anita",
   "pi_last_name": "Bell",
   "pi_mid_init": "I",
   "pi_sufx_name": "",
   "pi_full_name": "Anita I Bell",
   "pi_email_addr": "anitab@email.arizona.edu",
   "nsf_id": "000785337",
   "pi_start_date": "2020-07-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Arizona",
  "inst_street_address": "845 N PARK AVE RM 538",
  "inst_street_address_2": "",
  "inst_city_name": "TUCSON",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "5206266000",
  "inst_zip_code": "85721",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "AZ07",
  "org_lgl_bus_name": "UNIVERSITY OF ARIZONA",
  "org_prnt_uei_num": "",
  "org_uei_num": "ED44Y3W6P7B9"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona Board of Regents, University of Arizona",
  "perf_str_addr": "9040 S. Rita Road 1270",
  "perf_city_name": "Tucson",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "857479192",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "AZ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project of assessing the need, delivery mechanisms, and explicit use cases surrounding data distillation for real-time analysis, that does not require highly technical interfaces, was successfully completed. The project delivered five primary outcomes that were in line with the original intellectual merit objectives and the broader industry and general data science impacts of the project proposal. In addition, the project provided the necessary foundation from which to begin production of a novel solution to architecting the next generation of data storage, processing, and analysis. This project was led with an applied focus on the community-centric retail financial centers, economic empowerment programs, digital banking, corporate banking, small-business banking, and community-chartered credit unions. The most notable project outcomes included:</p>\n<p>Mapping of industry use cases, under the umbrella of broader impacts, this project discovered the tangible ways in which access to clean, functional, and responsive data would impact not only day-to-day operations of community banking programs but the communities themselves. The project identified both generalized use cases and specific, immediate applications. Generalized applications included measuring fiscal project impacts, reducing institutional risk, protecting member or shareholder funds from fraud, securing sensitive information, and better identifying underserved communities.</p>\n<p>The project also notated a repeated urgency of need adding detail to the original project hypothesis surrounding broader impacts. Repeated one-on-one interviews, group presentation feedback sessions, and story capture activities associated with this project consistently ranked the need for clean, precise data as a top need. With 62% of interviewees putting data as a top 3 problem that needs to be solved in the next 24-months and 87% of interviewees listing data as a top 5 problem to solve.</p>\n<p>In addition to defining repeated use cases through the project's interview phase, and the expedited timeline for a solution to these use cases, the project also delivered on the \"how\". The preferable access channels and major roadblocks that prevented the use cases, this project discovered, from being solved with conventional or existing measures.</p>\n<p>The next phase of the project, after uncovering practical applications and the existing hurdles and limitations, was to draft a novel solution and revisit the use cases. The approach, speaking to the intellectual merit of the project, was found to be through using custom, novel machine learning methods and new elastic training libraries, to automate the alleviation or removal most common data governance roadblocks.</p>\n<p>Final feedback and interview processes uncovered the final unique piece of the puzzle. A unique approach to data distillation, enrichment, and relational characterization further supported the intellectual merit of the project. This would require data handling and backend processing that would increase the accessibility and flexibility of the solution. An approach to data science and data augmentation that was not currently available in any of the solutions currently serving over 19,000 institutions.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/09/2022<br>\n\t\t\t\t\tModified by: Anita&nbsp;I&nbsp;Bell</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project of assessing the need, delivery mechanisms, and explicit use cases surrounding data distillation for real-time analysis, that does not require highly technical interfaces, was successfully completed. The project delivered five primary outcomes that were in line with the original intellectual merit objectives and the broader industry and general data science impacts of the project proposal. In addition, the project provided the necessary foundation from which to begin production of a novel solution to architecting the next generation of data storage, processing, and analysis. This project was led with an applied focus on the community-centric retail financial centers, economic empowerment programs, digital banking, corporate banking, small-business banking, and community-chartered credit unions. The most notable project outcomes included:\n\nMapping of industry use cases, under the umbrella of broader impacts, this project discovered the tangible ways in which access to clean, functional, and responsive data would impact not only day-to-day operations of community banking programs but the communities themselves. The project identified both generalized use cases and specific, immediate applications. Generalized applications included measuring fiscal project impacts, reducing institutional risk, protecting member or shareholder funds from fraud, securing sensitive information, and better identifying underserved communities.\n\nThe project also notated a repeated urgency of need adding detail to the original project hypothesis surrounding broader impacts. Repeated one-on-one interviews, group presentation feedback sessions, and story capture activities associated with this project consistently ranked the need for clean, precise data as a top need. With 62% of interviewees putting data as a top 3 problem that needs to be solved in the next 24-months and 87% of interviewees listing data as a top 5 problem to solve.\n\nIn addition to defining repeated use cases through the project's interview phase, and the expedited timeline for a solution to these use cases, the project also delivered on the \"how\". The preferable access channels and major roadblocks that prevented the use cases, this project discovered, from being solved with conventional or existing measures.\n\nThe next phase of the project, after uncovering practical applications and the existing hurdles and limitations, was to draft a novel solution and revisit the use cases. The approach, speaking to the intellectual merit of the project, was found to be through using custom, novel machine learning methods and new elastic training libraries, to automate the alleviation or removal most common data governance roadblocks.\n\nFinal feedback and interview processes uncovered the final unique piece of the puzzle. A unique approach to data distillation, enrichment, and relational characterization further supported the intellectual merit of the project. This would require data handling and backend processing that would increase the accessibility and flexibility of the solution. An approach to data science and data augmentation that was not currently available in any of the solutions currently serving over 19,000 institutions.\n\n\t\t\t\t\tLast Modified: 12/09/2022\n\n\t\t\t\t\tSubmitted by: Anita I Bell"
 }
}