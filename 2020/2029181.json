{
 "awd_id": "2029181",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Robots Teaching Robots: Real-time Optimal Control of Complex Engineering Systems",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032924588",
 "po_email": "yuewang@nsf.gov",
 "po_sign_block_name": "Yue Wang",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 479868.0,
 "awd_amount": 479868.0,
 "awd_min_amd_letter_date": "2020-08-17",
 "awd_max_amd_letter_date": "2020-10-14",
 "awd_abstract_narration": "This project introduces learner-helper robot pairs to enable the learner robot to use physical experimentation to improve its performance on repetitive task, without accurate analytical or numerical models. The specific challenge is that these tasks -- for example walking on two legs or riding a bicycle -- require a minimal necessary level of performance, below which the robot is unable to function. In the examples, this minimal level of ability corresponds to not falling over. The helper satisfies these minimal requirements while the learner uses repeated trials to improve its performance. For example, the helper might suspend the two-legged walker from a traveling harness or move alongside the bicycle robot providing an additional point of support. As the learner-helper team masters the task, the amount of assistance that the helper can apply is gradually reduced, until the learner is performing at a high level on its own. An analogy is a child learning to ride a bike with the help of an adult moving alongside. The new control technique will enable robots to teach robots in training lines of future factories similar to robots currently used in assembly lines of manufacturing companies. Therefore, the results of this research will benefit the U.S. economy and society. This research also involves several disciplines including mechanical, electrical, computer, and control engineering. The multi-disciplinary approach is expected to broaden the participation of underrepresented groups in research and positively impact engineering education.\r\n\r\nOptimal control is a branch of control theory that has the potential to revolutionize the creation of intelligent engineering systems, industrial robots, surgical robots, and assistive robots that can improve by repeated experience, somewhat similar to humans. There are many optimal control techniques to control engineering systems. However, almost all currently available techniques require high-fidelity models or a large amount of measured data to mitigate the so-called simulation-reality gap; the gap between the optimal performance predicted by computer simulations and the non-optimal performance observed in real engineering applications. This award supports fundamental research to close the simulation-reality gap when optimal control is applied to engineering systems. Model-based optimal control techniques enable efficient computation but they are subject to conservative control performance. Data-driven optimal control techniques mitigate the detrimental effect of uncertain models, but to do so, they require a large amount of training data. Therefore, scientific barriers must be overcome to realize the full application potential of optimal control techniques. This research will address the knowledge gap that limits the potential and theoretical promise of optimal control theory when applied to complex engineering systems. The new technique promotes optimization of system performance via real-time experiments guided by dedicated teacher robots, instead of optimizing system performance guided only by uncertain model-based predictions and measured data. The technique delivers a transformative approach to control the class of complex, underactuated, and unstable robots, for which obtaining high-fidelity models is challenging, while gathering training data is time-consuming. The research outcomes could potentially provide mainstream paradigms in creating next-generation intelligent machines.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Braun",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Braun",
   "pi_email_addr": "david.braun.robotics@gmail.com",
   "nsf_id": "000806588",
   "pi_start_date": "2020-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Vanderbilt University",
  "inst_street_address": "110 21ST AVE S",
  "inst_street_address_2": "",
  "inst_city_name": "NASHVILLE",
  "inst_state_code": "TN",
  "inst_state_name": "Tennessee",
  "inst_phone_num": "6153222631",
  "inst_zip_code": "372032416",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "TN05",
  "org_lgl_bus_name": "VANDERBILT UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "GTNBNWXJ12D5"
 },
 "perf_inst": {
  "perf_inst_name": "Vanderbilt University",
  "perf_str_addr": "2301 Vanderbilt Place",
  "perf_city_name": "Nashville",
  "perf_st_code": "TN",
  "perf_st_name": "Tennessee",
  "perf_zip_code": "372350002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "TN07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "756900",
   "pgm_ele_name": "Dynamics, Control and System D"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "030E",
   "pgm_ref_txt": "CONTROL SYSTEMS"
  },
  {
   "pgm_ref_code": "034E",
   "pgm_ref_txt": "Dynamical systems"
  },
  {
   "pgm_ref_code": "8024",
   "pgm_ref_txt": "Complex Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 479868.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Intellectual Merit</strong><br /> The project has developed real-time optimal control techniques for systems exhibiting both continuous and discrete behaviors. These systems, such as walking robots and others that interact with their surroundings, must learn and adapt to complex tasks without requiring detailed models or extensive training data. The proposed methods empower robots to operate effectively in uncertain and dynamic environments, bridging the gap between theoretical control methods and practical applications. By combining traditional model-based and contemporary data-driven control approaches, the project addresses the \"simulation-reality gap,\" which has historically hindered optimal control implementation. Additionally, the research explored learner-helper robots and expanded the toolkit of control methods by formalizing iterative, half-model-based, and model-free techniques applicable to engineering systems. Through numerical experimentation and validation, these methods have demonstrated improved performance over feedback control, model-based reinforcement learning, and model-predictive control techniques, particularly for under-actuated and unstable robots. This work has broadened the knowledge base for translating theoretical optimal control concepts into practical applications.</p>\n<p><strong>Broader Impacts</strong><br /> The control methods developed in this project have broad implications across multiple fields, including robotics, healthcare, and manufacturing. These methods enable robots to learn complex tasks and adapt in real-time, reducing the reliance on precise models and extensive data. This adaptability is crucial in applications such as assistive and surgical robotics, where precision and safety are paramount. The advancements in the helper-learner robot concept can also be applied to fall prevention and rehabilitation devices, providing societal benefits beyond traditional robotics. The integration of model-based and data-driven methods ensures that these robots can function effectively in environments where existing control techniques may fall short, offering significant improvements in efficiency, adaptability, and safety. The project has also contributed to the education of graduate and undergraduate students in engineering, fostering future innovation in robotics. Students gained valuable experience working with advanced techniques in applied optimal control, preparing them to address complex challenges in various industries. Ultimately, this research has the potential to significantly advance the development of intelligent, self-learning robotic systems across a broad spectrum of applications, from industrial automation to healthcare, paving the way for impactful future technologies.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 09/12/2024<br>\nModified by: David&nbsp;Braun</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIntellectual Merit\n The project has developed real-time optimal control techniques for systems exhibiting both continuous and discrete behaviors. These systems, such as walking robots and others that interact with their surroundings, must learn and adapt to complex tasks without requiring detailed models or extensive training data. The proposed methods empower robots to operate effectively in uncertain and dynamic environments, bridging the gap between theoretical control methods and practical applications. By combining traditional model-based and contemporary data-driven control approaches, the project addresses the \"simulation-reality gap,\" which has historically hindered optimal control implementation. Additionally, the research explored learner-helper robots and expanded the toolkit of control methods by formalizing iterative, half-model-based, and model-free techniques applicable to engineering systems. Through numerical experimentation and validation, these methods have demonstrated improved performance over feedback control, model-based reinforcement learning, and model-predictive control techniques, particularly for under-actuated and unstable robots. This work has broadened the knowledge base for translating theoretical optimal control concepts into practical applications.\n\n\nBroader Impacts\n The control methods developed in this project have broad implications across multiple fields, including robotics, healthcare, and manufacturing. These methods enable robots to learn complex tasks and adapt in real-time, reducing the reliance on precise models and extensive data. This adaptability is crucial in applications such as assistive and surgical robotics, where precision and safety are paramount. The advancements in the helper-learner robot concept can also be applied to fall prevention and rehabilitation devices, providing societal benefits beyond traditional robotics. The integration of model-based and data-driven methods ensures that these robots can function effectively in environments where existing control techniques may fall short, offering significant improvements in efficiency, adaptability, and safety. The project has also contributed to the education of graduate and undergraduate students in engineering, fostering future innovation in robotics. Students gained valuable experience working with advanced techniques in applied optimal control, preparing them to address complex challenges in various industries. Ultimately, this research has the potential to significantly advance the development of intelligent, self-learning robotic systems across a broad spectrum of applications, from industrial automation to healthcare, paving the way for impactful future technologies.\n\n\n\t\t\t\t\tLast Modified: 09/12/2024\n\n\t\t\t\t\tSubmitted by: DavidBraun\n"
 }
}