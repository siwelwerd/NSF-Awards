{
 "awd_id": "2006765",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: RUI: Scalable and Iterative Statistical Testing of Multiple Hypotheses on Massive Datasets",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927978",
 "po_email": "racharya@nsf.gov",
 "po_sign_block_name": "Raj Acharya",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 373381.0,
 "awd_amount": 373381.0,
 "awd_min_amd_letter_date": "2020-08-19",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "Modern scientific practice is rooted on statistical testing of hypotheses on data. To limit the risk of false discoveries, the tests must offer strict statistical guarantees. The task is very challenging due to the sheer amount of rich data available today, and to the ever-increasing number of complex hypotheses that scientists want to test on the same data. In order for science to advance, and therefore advance society and human well-being, it is of the foremost importance that scientists are given tools that overcome these challenges. This project will design novel computational methods for statistical hypothesis testing that tackle all the above challenges by combining modern statistical results with recent approaches from the area of knowledge discovery and data mining, a field of computer science dealing with the efficient analysis of data. As part of the educational activities, this project will develop materials for college-level courses to ensure that the next generation of scientists and computer scientists posses the intellectual and practical knowledge to ensure a statistically-sound analysis of data and testing of hypotheses by using and extending the methods developed in the project. A diverse cohort of undergraduate students will be involved in the research and educational components of the project.\r\n\r\nThe team of researchers in this project will design and mathematically analyze algorithms to make statistical hypothesis testing iterative and scalable along multiple dimensions. Many existing statistical procedures are already computationally expensive when testing a single hypothesis on moderate-size datasets, and become even more inefficient as the amount of data or the number of hypotheses grows. Along the dimension of data complexity, available tests often lack scalability because limited to simple types of data (e.g., binary tables), while fewer methods are available for rich data such as attributed graphs or panel time-series. The lack of scalable methods may be due in part to the requirement that hypothesis tests satisfy stringent statistical guarantees (e.g., the Family-Wise Error Rate (FWER) and the False Discovery Rate (FDR)) to ensure that the successive inference is sound. Additionally, the iterative aspect of the practice of data analysis has been ignored for statistical tests, but considering it is crucial in order to ensure that these guarantees are satisfied. This project will develop algorithms for the scalable and iterative statistical testing of multiple complex hypotheses on massive rich datasets, while imposing only weak assumptions on the data generation process, and controlling the FWER and the FDR. These results will be achieved by bringing together two areas of computer science research that had, until now, only very limited points of contact: statistical learning theory and data mining. The novel methods developed in this project will use concepts from the former, such as (local) Rademacher averages, covering numbers, and pseudodimension, to exploit the structure of the class of hypotheses being tested and achieve better sample complexity bounds, which translate to higher statistical power and improved control of the FWER/FDR, even in an iterative data analysis setting. These concepts will be adapted to statistical hypothesis testing and strengthen to fully exploit their practical usefulness, especially on rich datasets and in the presence of dependencies between the data points. The project team will use techniques from the knowledge discovery task of pattern mining to efficiently explore the space of hypotheses to filter out those that are definitively not significant. To reach this goal, the project team will develop novel bounds for the p-value functions of different tests and adapt these techniques to rich datasets such as attributed graphs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matteo",
   "pi_last_name": "Riondato",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matteo Riondato",
   "pi_email_addr": "mriondato@amherst.edu",
   "nsf_id": "000792606",
   "pi_start_date": "2020-08-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Amherst College",
  "inst_street_address": "155 S PLEASANT ST",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135422804",
  "inst_zip_code": "010022234",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "AMHERST COLLEGE, TRUSTEES OF",
  "org_prnt_uei_num": "",
  "org_uei_num": "KDRLUT71AFM5"
 },
 "perf_inst": {
  "perf_inst_name": "Amherst College",
  "perf_str_addr": "155 S. Pleasant Street",
  "perf_city_name": "Amherst",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010025000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9229",
   "pgm_ref_txt": "RES IN UNDERGRAD INST-RESEARCH"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 373381.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project developed novel computational methods for data analysis.</p>\r\n<p>During the first part of the project, methods based on random sampling were developed: rather than analyzing the whole dataset, what kind of results can be obtained from only analyzing a small subset of the dataset chosen at random? How good is the quality of such results? How can subset be chosen? Different methods were developed, for a wide range of data analytics tasks, to answer these and other questions.</p>\r\n<p>In the second part of the project, the work focused on developing new methods to make statistical hypothesis testing scalable. Testing hypotheses is a cornerstone of the scientific methods, but many available approaches become inefficient as the dataset size, or the number of hypotheses to be tested, grow. The project developed new methods that solve some of these challenges.</p>\r\n<p>Many papers were published at top conferences in data mining and machine  learning. All methods have been implemented and open source  implementations are available.</p>\r\n<p>During the whole project, tens of undergraduate students were trained in the craft of research, from learning how to read scientific papers, to writing new scientific papers. Many of the published works related to the project have undergraduate coauthors. These students will form the next generation of scientists, who will be well versed in the statistical and computational challenges of data analysis.</p><br>\n<p>\n Last Modified: 02/14/2025<br>\nModified by: Matteo&nbsp;Riondato</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project developed novel computational methods for data analysis.\r\n\n\nDuring the first part of the project, methods based on random sampling were developed: rather than analyzing the whole dataset, what kind of results can be obtained from only analyzing a small subset of the dataset chosen at random? How good is the quality of such results? How can subset be chosen? Different methods were developed, for a wide range of data analytics tasks, to answer these and other questions.\r\n\n\nIn the second part of the project, the work focused on developing new methods to make statistical hypothesis testing scalable. Testing hypotheses is a cornerstone of the scientific methods, but many available approaches become inefficient as the dataset size, or the number of hypotheses to be tested, grow. The project developed new methods that solve some of these challenges.\r\n\n\nMany papers were published at top conferences in data mining and machine  learning. All methods have been implemented and open source  implementations are available.\r\n\n\nDuring the whole project, tens of undergraduate students were trained in the craft of research, from learning how to read scientific papers, to writing new scientific papers. Many of the published works related to the project have undergraduate coauthors. These students will form the next generation of scientists, who will be well versed in the statistical and computational challenges of data analysis.\t\t\t\t\tLast Modified: 02/14/2025\n\n\t\t\t\t\tSubmitted by: MatteoRiondato\n"
 }
}