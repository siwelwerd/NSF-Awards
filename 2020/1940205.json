{
 "awd_id": "1940205",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER:Reducibility among high-dimensional statistics problems: information preserving mappings, algorithms, and complexity.",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032928910",
 "po_email": "jafowler@nsf.gov",
 "po_sign_block_name": "James Fowler",
 "awd_eff_date": "2020-02-01",
 "awd_exp_date": "2025-01-31",
 "tot_intn_awd_amt": 650000.0,
 "awd_amount": 650000.0,
 "awd_min_amd_letter_date": "2020-01-24",
 "awd_max_amd_letter_date": "2024-05-07",
 "awd_abstract_narration": "Large-scale data collection and analysis is transforming science, engineering, and industry. At their core, applications rely on statistical inference whereby meaning is extracted from noisy data. This is challenging due not only to the sheer scale, but also the complex underlying structure that must often be exploited. The two basic resources for carrying out an inference task are (1) data, which can vary in quality and quantity; and (2) computation. There appears to be a trade-off: The minimum amount of data needed by computationally infeasible algorithms is often far less than what is required by all known computationally efficient algorithms. As this trade-off is poorly understood, the objective of the project is to create the mathematical foundations for reasoning about the optimal computational and statistical efficiency of algorithms for structured inference problems. Significant societal impact may be possible via new fundamental insights relevant to basic procedures and methods used across business, economics, medical technology, social network analysis, genetics, neuroscience, and many other domains. Furthermore, as part of a synergistic research and education plan, the project will take a multi-faceted approach to STEM education, including: (1) mentorship of both undergraduate and graduate students in research; (2) outreach to both high school and undergraduate groups; (3) creation of a collaborative research experience for undergraduate students on topics related to the project; and (4) development of new courses at MIT, both at the advanced undergraduate and PhD levels.\r\n \r\nThe project aims to develop a comprehensive average-case complexity theory of statistical inference, analogous to the classical P versus NP theory for combinatorial problems, characterizing when inference is or is not efficiently solvable and showing strong equivalences between problems. The bulk of the technical approach is based on developing new techniques for average-case reductions that yield precise relationships between different problems. Average-case reductions transform one problem into another, implying a comparison between the data and computation resources required by each. In addition to characterizing fundamental limits, the approach pursued in this project will result in algorithms and insights. By creating a web of reductions between problems, it will be possible to translate algorithms for one problem into algorithms for other problems. Furthermore, strong equivalences obtained via such two-way reductions will show that the same phenomenon appears in seemingly different problems because they are at their core the same problem. The project has the potential to change the basic methodology for studying statistical inference problems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Guy",
   "pi_last_name": "Bresler",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Guy Bresler",
   "pi_email_addr": "guy@MIT.EDU",
   "nsf_id": "000704719",
   "pi_start_date": "2020-01-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7797",
   "pgm_ref_txt": "COMM & INFORMATION FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 121776.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 389622.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 138602.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Statistical inference is the process of extracting useful information from data. Modern large-scale statistical inference is costly both in terms of data requirement and computational requirement. The focus of this project was on understanding how much of each of these resources is needed to solve a wide variety of statistical inference problems. In other words, what is the best algorithm for a given situation, how much data does it need, and how long will it need to run on the computer? The basic approach of the project was to relate different problems to one another in a certain strong sense. This is the method that has been used since the beginning of computer science to investigate algorithmic feasibility; however, the applicability of the approach to statistics and machine learning problems, which have data as their input, was limited before initiation of this project. By showing that two seemingly very different problems are actually at their core essentially the same problem, one may conclude that algorithms for one problem transfer to algorithms for the other. Similarly, if one problem is infeasible, because it requires too much computational resource with a given amount of data, one may conclude the same for the other problem. These types of connections clarify and simplify the complicated landscape of statistical problems, greatly reducing effort needed to study each problem individually and in isolation.&nbsp;</span></p>\r\n<p><span>The project successfully carried out its main objectives and developed a web of connections between a wide variety of differently structured statistics problems. This elucidated for the first time the computational limits for a number of statistics problems, which will help guide the development of optimal algorithms that efficiently use of both data and computation. Additionally, numerous new techniques for comparison of complex data were developed, and these are likely to be useful for studying a range of statistics and machine learning problems in the upcoming years. &nbsp;&nbsp;</span></p>\r\n<p><span>Future societal impact may be possible via the newly obtained fundamental insights due to their relevance to basic procedures and methods used across business, economics, medical technology, social network analysis, genetics, neuroscience, and many other domains. The project&rsquo;s educational component included: (1) mentorship of both undergraduate and graduate students in research; (2) creation of a highly popular winter course for undergraduate students on probability topics related to the project; and (3) inclusion of material into multiple courses at MIT, both at the advanced undergraduate and PhD levels.</span></p>\r\n<div><span><br /></span></div>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/04/2025<br>\nModified by: Guy&nbsp;Bresler</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nStatistical inference is the process of extracting useful information from data. Modern large-scale statistical inference is costly both in terms of data requirement and computational requirement. The focus of this project was on understanding how much of each of these resources is needed to solve a wide variety of statistical inference problems. In other words, what is the best algorithm for a given situation, how much data does it need, and how long will it need to run on the computer? The basic approach of the project was to relate different problems to one another in a certain strong sense. This is the method that has been used since the beginning of computer science to investigate algorithmic feasibility; however, the applicability of the approach to statistics and machine learning problems, which have data as their input, was limited before initiation of this project. By showing that two seemingly very different problems are actually at their core essentially the same problem, one may conclude that algorithms for one problem transfer to algorithms for the other. Similarly, if one problem is infeasible, because it requires too much computational resource with a given amount of data, one may conclude the same for the other problem. These types of connections clarify and simplify the complicated landscape of statistical problems, greatly reducing effort needed to study each problem individually and in isolation.\r\n\n\nThe project successfully carried out its main objectives and developed a web of connections between a wide variety of differently structured statistics problems. This elucidated for the first time the computational limits for a number of statistics problems, which will help guide the development of optimal algorithms that efficiently use of both data and computation. Additionally, numerous new techniques for comparison of complex data were developed, and these are likely to be useful for studying a range of statistics and machine learning problems in the upcoming years. \r\n\n\nFuture societal impact may be possible via the newly obtained fundamental insights due to their relevance to basic procedures and methods used across business, economics, medical technology, social network analysis, genetics, neuroscience, and many other domains. The projects educational component included: (1) mentorship of both undergraduate and graduate students in research; (2) creation of a highly popular winter course for undergraduate students on probability topics related to the project; and (3) inclusion of material into multiple courses at MIT, both at the advanced undergraduate and PhD levels.\r\n\n\r\n\n\n\t\t\t\t\tLast Modified: 02/04/2025\n\n\t\t\t\t\tSubmitted by: GuyBresler\n"
 }
}