{
 "awd_id": "1948517",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: CHS: RUI: Gaze Sharing to Support Remote Collaboration",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2020-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 105572.0,
 "awd_amount": 121572.0,
 "awd_min_amd_letter_date": "2020-04-10",
 "awd_max_amd_letter_date": "2020-05-27",
 "awd_abstract_narration": "Remote collaboration is becoming a common practice in virtually all employment sectors as it enables flexibility, accommodates different lifestyles, combines resources, and reduces expenses. Despite its numerous advantages and the many technological advancements to support it, there remain numerous challenges. Remote collaborators struggle to maintain shared awareness, mutual understanding, and coordination, leading to frustration and time and monetary loss. Recently, dual eye tracking technology has been explored as a novel way of enhancing remote synchronous collaboration. Through gaze sharing, the process where two collaborators can see each other's point of gaze visualized on their individual screens in real time, remote collaborators in diverse settings have seen improvements in the quality and outcome of their interactions. This project will explore previously overlooked dimensions of remote collaboration and how it is affected by gaze sharing. In particular, it will investigate the communication channel that is used in conjunction with gaze sharing and will explore how gaze awareness affects multi-party groups that go beyond the traditionally studied pairs. This project will be a first step toward understanding how contextual gaze sharing can intelligently support remote collaboration in realistic scenarios that include multiple collaborators.\r\n\r\nResearch on real-time gaze sharing has shown that it is a promising way to alleviate some of the limitations of lack of collocation by increasing shared awareness. However, prior gaze sharing studies have not considered the medium of communication and have only studied its effect on communication during audio calls. With the prevalence of text-based communication, it is important to systematically examine the combined effect of the communication medium and shared gaze on collaboration. The first phase of this project will explore gaze sharing as an additional signal to instant messaging and will contrast it to audio-based communication. Using existing communication theories, it will examine the joint effect of gaze sharing and primary channel of communication on collaboration through metrics that include gaze overlap, efficiency, effectiveness, and cognitive workload. The second phase of this project will focus on the group size of remote teams. Gaze sharing has been shown to be particularly effective in studies that include pairs, but it is unclear whether these positive effects would persist in multi-party groups. This project will explore the effect of gaze sharing on multiple collaborators through the development and release of a free and open-source writing platform that will allow multi-party gaze sharing. A user study on writing with groups of varying sizes will follow to uncover whether visualizing multiple gaze locations will be detrimental rather than beneficial to the quality of the collaboration and its outcome. The findings of this project will offer recommendations for future technologies that support multi-party collaborations through the use of different communication media and gaze sharing.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alexandra",
   "pi_last_name": "Papoutsaki",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alexandra Papoutsaki",
   "pi_email_addr": "apaa2017@pomona.edu",
   "nsf_id": "000786713",
   "pi_start_date": "2020-04-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pomona College",
  "inst_street_address": "550 N COLLEGE AVE # 244",
  "inst_street_address_2": "",
  "inst_city_name": "CLAREMONT",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9096218328",
  "inst_zip_code": "917114434",
  "inst_country_name": "United States",
  "cong_dist_code": "28",
  "st_cong_dist_code": "CA28",
  "org_lgl_bus_name": "POMONA COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "Q9VBQSV2CBY5"
 },
 "perf_inst": {
  "perf_inst_name": "Pomona College",
  "perf_str_addr": "550 North College",
  "perf_city_name": "Claremont",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "917114434",
  "perf_ctry_code": "US",
  "perf_cong_dist": "28",
  "perf_st_cong_dist": "CA28",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 121572.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Eye tracking is a methodology used in many settings due to its ability to determine where someone is looking. One example of the insights it can lead to is a project that was pursued with this award. The researchers investigated how professional comedians create humor differently from non-comedians. Using eye-tracking technology, the researchers recruited professional comedians and people with no comedic experience and observed them when trying to generate funny captions for cartoons. They found that comedians naturally focus more on the most eye-catching parts of an image than non-comedians. This type of attention is tied to bottom-up thinking, which is driven by what is seen or directly experienced. Comedians use this way of thinking more, allowing spontaneous ideas to flow more freely. In contrast, non-comedians often use top-down thinking, which is more goal-oriented and deliberate but is less effective for humor creation as it is less tied to salient features. This work has theoretical implications for our understanding of humor creation, but it also offers practical lessons for anyone who wants to be able to come up with funny lines based on an image. The key is to pay attention to the &ldquo;elephant in the room,&rdquo; which is the most obvious part of the scene, and address it unexpectedly to build surprise rather than excessively plan or search for humor outside the presented situation.</p>\r\n<p>Traditionally, eye tracking has been deployed for studying individuals, but recently, a new technique, shared gaze, has emerged to bring eye tracking to remote collaborative settings. With shared gaze, collaborators working on a shared project, for example, editing a shared document synchronously, can see each other&rsquo;s point of gaze projected and visualized on their own screen in real-time. Shared gaze has been shown to lead to higher mutual awareness, which is a common obstacle among people who work together remotely. With remote work becoming increasingly popular, shared gaze has the potential to make it more efficient and lead to higher satisfaction among co-workers.</p>\r\n<p>In the past, shared gaze had been studied when combined with voice-based communication. That left questions about its effect when it is combined with&nbsp; text-based communication. This award led to a project that investigated how shared gaze affects teamwork when people use voice communication or text messaging to collaborate. The researchers found that adding shared gaze to chat improved collaboration in terms of correctness and led collaborators to talk about and look more often at shared content. In addition, collaborators reported higher levels of awareness of their partner&rsquo;s activity, as well as increased perceived performance, joint attention, and smooth flow of communication. However, shared gaze negatively impacted the effort and mental demand required from participants, who overall preferred gaze-augmented voice-based communication. Contrary to text-based communication, collaboration over audio additionally benefited from shared gaze by reducing how long it takes to complete joint tasks and the cognitive workload required. This work offers insights to developers of collaboration tools who are interested in incorporating shared gaze in settings that accommodate different ways of communicating between collaborators.</p>\r\n<p>Shared gaze has been commonly used for structured tasks, such as co-writing or problem-solving. With this award, the researchers also investigated its effects on open-ended, creative tasks, such as collaborative drawing. Collaborative drawing is a popular way for people to meet and work on the same artwork for recreation and artistic growth. The researchers first surveyed users of online collaborative platforms. The users reported the importance of communication but also of maintaining individual agency. The researchers next designed a study investigating how remote collaborators perceive the effect of shared gaze on creativity and teamwork when drawing together. They found that combining voice-based communication with shared gaze was perceived to strike the best balance between providing a sense of a tight collaboration while retaining one&rsquo;s ability to operate as an individual. Shared gaze led to collaborators being more aware of each other&rsquo;s activity, which in turn led to fewer interruptions as collaborators did not have to wait for each other before they acted. Surprisingly, many participants found that when could only communicate using the shared canvas, they were the freest to pursue creative and unusual ideas. This project provides guidelines for new creativity tools that adapt based on individual preferences among collaborators and take into account the nature of the joint task.</p>\r\n<p>Overall, this award advances our knowledge of human behavior in creative settings and furthers our understanding of how the novel interaction technique of shared gaze affects remote collaboration under various ways of communicating when working with others.</p>\r\n<p>The award has led to three publications and two conference talks. It has also had an impact on undergraduate and high-school students, many from underrerpesented backgrounds. Six undergraduate students in these projects have continued their studies by pursuing a Ph.D. in Human-Computer Interaction.</p><br>\n<p>\n Last Modified: 12/17/2024<br>\nModified by: Alexandra&nbsp;Papoutsaki</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1948517/1948517_10663926_1734475292816_interface--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1948517/1948517_10663926_1734475292816_interface--rgov-800width.png\" title=\"A collaborative drawing platform that supports shared gaze\"><img src=\"/por/images/Reports/POR/2024/1948517/1948517_10663926_1734475292816_interface--rgov-66x44.png\" alt=\"A collaborative drawing platform that supports shared gaze\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Two users drawing on a shared synchronous canvas. A gray circle shows the collaborator's gaze, but here, since both users are looking at the astronaut, it turned green.</div>\n<div class=\"imageCredit\">Tongyu Zhou</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Alexandra&nbsp;Papoutsaki\n<div class=\"imageTitle\">A collaborative drawing platform that supports shared gaze</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1948517/1948517_10663926_1734475550328_satisfaction--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1948517/1948517_10663926_1734475550328_satisfaction--rgov-800width.png\" title=\"The five dimensions on the quality of collaboration that were asked at the end of each task along with the mean rank scores\"><img src=\"/por/images/Reports/POR/2024/1948517/1948517_10663926_1734475550328_satisfaction--rgov-66x44.png\" alt=\"The five dimensions on the quality of collaboration that were asked at the end of each task along with the mean rank scores\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Voice generally led to higher scores on perceived quality. Shared gaze had a positive effect on joint attention, flow of communication, and awareness of partner's activity for text communication.</div>\n<div class=\"imageCredit\">Alexandra Papoutsaki</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Alexandra&nbsp;Papoutsaki\n<div class=\"imageTitle\">The five dimensions on the quality of collaboration that were asked at the end of each task along with the mean rank scores</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nEye tracking is a methodology used in many settings due to its ability to determine where someone is looking. One example of the insights it can lead to is a project that was pursued with this award. The researchers investigated how professional comedians create humor differently from non-comedians. Using eye-tracking technology, the researchers recruited professional comedians and people with no comedic experience and observed them when trying to generate funny captions for cartoons. They found that comedians naturally focus more on the most eye-catching parts of an image than non-comedians. This type of attention is tied to bottom-up thinking, which is driven by what is seen or directly experienced. Comedians use this way of thinking more, allowing spontaneous ideas to flow more freely. In contrast, non-comedians often use top-down thinking, which is more goal-oriented and deliberate but is less effective for humor creation as it is less tied to salient features. This work has theoretical implications for our understanding of humor creation, but it also offers practical lessons for anyone who wants to be able to come up with funny lines based on an image. The key is to pay attention to the elephant in the room, which is the most obvious part of the scene, and address it unexpectedly to build surprise rather than excessively plan or search for humor outside the presented situation.\r\n\n\nTraditionally, eye tracking has been deployed for studying individuals, but recently, a new technique, shared gaze, has emerged to bring eye tracking to remote collaborative settings. With shared gaze, collaborators working on a shared project, for example, editing a shared document synchronously, can see each others point of gaze projected and visualized on their own screen in real-time. Shared gaze has been shown to lead to higher mutual awareness, which is a common obstacle among people who work together remotely. With remote work becoming increasingly popular, shared gaze has the potential to make it more efficient and lead to higher satisfaction among co-workers.\r\n\n\nIn the past, shared gaze had been studied when combined with voice-based communication. That left questions about its effect when it is combined with text-based communication. This award led to a project that investigated how shared gaze affects teamwork when people use voice communication or text messaging to collaborate. The researchers found that adding shared gaze to chat improved collaboration in terms of correctness and led collaborators to talk about and look more often at shared content. In addition, collaborators reported higher levels of awareness of their partners activity, as well as increased perceived performance, joint attention, and smooth flow of communication. However, shared gaze negatively impacted the effort and mental demand required from participants, who overall preferred gaze-augmented voice-based communication. Contrary to text-based communication, collaboration over audio additionally benefited from shared gaze by reducing how long it takes to complete joint tasks and the cognitive workload required. This work offers insights to developers of collaboration tools who are interested in incorporating shared gaze in settings that accommodate different ways of communicating between collaborators.\r\n\n\nShared gaze has been commonly used for structured tasks, such as co-writing or problem-solving. With this award, the researchers also investigated its effects on open-ended, creative tasks, such as collaborative drawing. Collaborative drawing is a popular way for people to meet and work on the same artwork for recreation and artistic growth. The researchers first surveyed users of online collaborative platforms. The users reported the importance of communication but also of maintaining individual agency. The researchers next designed a study investigating how remote collaborators perceive the effect of shared gaze on creativity and teamwork when drawing together. They found that combining voice-based communication with shared gaze was perceived to strike the best balance between providing a sense of a tight collaboration while retaining ones ability to operate as an individual. Shared gaze led to collaborators being more aware of each others activity, which in turn led to fewer interruptions as collaborators did not have to wait for each other before they acted. Surprisingly, many participants found that when could only communicate using the shared canvas, they were the freest to pursue creative and unusual ideas. This project provides guidelines for new creativity tools that adapt based on individual preferences among collaborators and take into account the nature of the joint task.\r\n\n\nOverall, this award advances our knowledge of human behavior in creative settings and furthers our understanding of how the novel interaction technique of shared gaze affects remote collaboration under various ways of communicating when working with others.\r\n\n\nThe award has led to three publications and two conference talks. It has also had an impact on undergraduate and high-school students, many from underrerpesented backgrounds. Six undergraduate students in these projects have continued their studies by pursuing a Ph.D. in Human-Computer Interaction.\t\t\t\t\tLast Modified: 12/17/2024\n\n\t\t\t\t\tSubmitted by: AlexandraPapoutsaki\n"
 }
}