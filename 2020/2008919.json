{
 "awd_id": "2008919",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps:  The Smartphone-Based Interactive Fit Detection Mirror",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922160",
 "po_email": "rshuman@nsf.gov",
 "po_sign_block_name": "Ruth Shuman",
 "awd_eff_date": "2020-02-15",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2020-02-03",
 "awd_max_amd_letter_date": "2021-12-08",
 "awd_abstract_narration": "The broader impact/commercial potential of this I-Corps project is in the development of a novel smartphone-based detection technology to assist in physical analysis of the human body, with applications for the medical, retail, or athletic sectors. Currently, fit-related problems are addressed primarily in a manual, labor-intensive process.  Our innovation provides a small, portable, affordable, and sustainable solution in finding the optimal fit in a timely and cost-effective manner. \r\n\r\nThis I-Corps project will develop an integrated system to estimate the human body shape for medical and retail applications. This innovation has a unique combination of a sensor technology, image processing techniques, and machine learning algorithms to integrate fit-related data with merchandise information. The proposed device measures a subject\u2019s fit using a smartphone camera, detects the body shape from the measurement using image processing techniques, and presents a subject with the merchandise that fits using machine learning techniques. Moreover, the innovation also integrates a subject\u2019s biomedical information to personalize fit.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jo Woon",
   "pi_last_name": "Chong",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jo Woon Chong",
   "pi_email_addr": "j.chong@ttu.edu",
   "nsf_id": "000739360",
   "pi_start_date": "2020-02-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas Tech University",
  "inst_street_address": "2500 BROADWAY",
  "inst_street_address_2": "",
  "inst_city_name": "LUBBOCK",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "8067423884",
  "inst_zip_code": "79409",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "TX19",
  "org_lgl_bus_name": "TEXAS TECH UNIVERSITY SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "EGLKRQ5JBCZ7"
 },
 "perf_inst": {
  "perf_inst_name": "Texas Tech University",
  "perf_str_addr": "Box 43102, Department of Electri",
  "perf_city_name": "Lubbock",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "794093102",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "TX19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This I-Corps project has explored the commercial potential of a new fit detection technology using a smart device and has made it broadly available for scientific discovery and fashion and retail applications. The project has further developed a smart device-based fit detection solution using image processing and machine learning.&nbsp;We had developed a smartphone-based interactive fit detection solution which suggests personalized selection of garments based on a subject&rsquo;s body measurement, body shape, and physiological response to garments obtained from the subject&rsquo;s personal smartphone. The novelty of this innovation includes smartphone-based 1) &ldquo;accurate&rdquo; body size measurement, 2) &ldquo;novel&rdquo; body shape detection, 3) &ldquo;novel&rdquo; physiological response measurement, and 4) &ldquo;novel&rdquo; personalized garment suggestion methods.&nbsp;The technology has advantages of being as accurate as currently available commercial products and more convenient compared to the current products. The proposed smart device-based fit detection technology has made use of body size and fit-related information.&nbsp;This novel interactive fit detection solution using a smartphone demonstrates. Intellectual Merit by advancing scientific knowledge with regards to integrating multiple functions related to fit detection using the sensors or components embedded in a smartphone.</p>\n<p>&nbsp;</p>\n<p>This project has societal broader impact by minimizing time and expense due to imprecise decisions of fit and size for garments since this solution can provide precise and personalized garment suggestion. In the aspect of economic broader impact, this project impacts on reducing huge costs involved in garment returns due to misfit. The commercial impacts of this project are to provide a key solution to solve fit issues in apparel industry and increasing economic competitiveness of this industry with necessary technology advancement. The educational impact for this project is to engage underrepresented student group to learn in the lab and research for this project.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/31/2022<br>\n\t\t\t\t\tModified by: Jo Woon&nbsp;Chong</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis I-Corps project has explored the commercial potential of a new fit detection technology using a smart device and has made it broadly available for scientific discovery and fashion and retail applications. The project has further developed a smart device-based fit detection solution using image processing and machine learning. We had developed a smartphone-based interactive fit detection solution which suggests personalized selection of garments based on a subject\u2019s body measurement, body shape, and physiological response to garments obtained from the subject\u2019s personal smartphone. The novelty of this innovation includes smartphone-based 1) \"accurate\" body size measurement, 2) \"novel\" body shape detection, 3) \"novel\" physiological response measurement, and 4) \"novel\" personalized garment suggestion methods. The technology has advantages of being as accurate as currently available commercial products and more convenient compared to the current products. The proposed smart device-based fit detection technology has made use of body size and fit-related information. This novel interactive fit detection solution using a smartphone demonstrates. Intellectual Merit by advancing scientific knowledge with regards to integrating multiple functions related to fit detection using the sensors or components embedded in a smartphone.\n\n \n\nThis project has societal broader impact by minimizing time and expense due to imprecise decisions of fit and size for garments since this solution can provide precise and personalized garment suggestion. In the aspect of economic broader impact, this project impacts on reducing huge costs involved in garment returns due to misfit. The commercial impacts of this project are to provide a key solution to solve fit issues in apparel industry and increasing economic competitiveness of this industry with necessary technology advancement. The educational impact for this project is to engage underrepresented student group to learn in the lab and research for this project.\n\n\t\t\t\t\tLast Modified: 08/31/2022\n\n\t\t\t\t\tSubmitted by: Jo Woon Chong"
 }
}