{
 "awd_id": "2008501",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Evaluating and Optimizing Wayfinding in Healthcare Settings through Biometric Data and Virtual Response Testing",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2020-08-15",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 415657.0,
 "awd_amount": 415657.0,
 "awd_min_amd_letter_date": "2020-08-04",
 "awd_max_amd_letter_date": "2020-08-04",
 "awd_abstract_narration": "Wayfinding systems are the signs, color-schemes, and other features of large, complex buildings that serve as aids in navigation. Unfortunately, wayfinding is often treated as an \"afterthought\" rather than as an integral part of the architectural design process. In healthcare facilities, difficulties in wayfinding have been shown to be a major source of stress for patients and visitors, as well as a significant burden on hospital staff members and an obstacle to operational efficiency. Testing and evaluating wayfinding systems is difficult, because each facility is unique and trying out many different wayfinding options in the same building to see which one works best would be financially and logistically implausible. Thus, there is currently no good method to rigorously compare the success of different wayfinding design strategies. To help solve this problem, the researchers will develop a new platform to evaluate and optimize wayfinding design in specific healthcare facilities before those wayfinding features are physically constructed. Virtual-reality (VR) testing will be used to accomplish this purpose. Participants in the study will don VR headsets, along with various biometric sensors to help evaluate their stress levels. They will then be asked to complete common navigational tasks in a virtual replica of a hospital building, such as finding their way from the main entrance to a specific patient room. Using a virtual replica of the building allows the researchers to easily swap out different wayfinding features, thereby determining what types of navigational aids are most effective for improving wayfinding and reducing stress. The study will contribute to the development of a new type of research platform that can be used to conduct human-response testing for many different environmental design variables, even beyond wayfinding. It will promote greater attention to the needs of building users, including minority experiences (such as those of disabled users) that have been historically overlooked in design. The ultimate goal of the project is to streamline the virtual design-testing process so that other designers and researchers can easily implement this approach and benefit from rigorous pre-construction testing.\r\n\r\nThe VR testing platform designed and developed as part of this project will use actual design information for planned hospital complexes, importing the data directly from commonly used designed-industry software. Study participants will experience different versions of the facilities that integrate different combinations of possible wayfinding designs. As the participants complete wayfinding tasks in the virtual buildings, the researchers will collect biometric data including electroencephalography (EEG) and electrocardiography (EKG) signals to serve as objective measures of stress and confusion, as well as behavioral data about the participants\u2019 actions in the environment and their navigational success. Self-reported data about conscious evaluations and reactions to the environment will also be collected from the participants. Two pilot studies will be conducted in the context of a healthcare facility that is currently under contract by the research team\u2019s industry partners, testing actual wayfinding designs that may be used in the final constructed facility. The first pilot study will focus on different types and combinations of color patterns, pictograms, and architectural features for wayfinding. The second pilot study will focus on the wayfinding impact of different external view conditions (the placement of windows and various exterior landmarks). As part of the research, the team will investigate and confirm brain activity (EEG) classifiers, i.e., neural signatures, for wayfinding success, by triangulating this data with the behavioral and self-reported findings. By using these neural signatures and other biometric interpretations, the project will provide specific findings to improve the facility being investigated in the pilot tests. These results will be incorporated in a platform that will be made available to other researchers as a generalized software tool to support VR-based design testing with integrated biometric sensor data. In future work, the research platform can be extended to study other implementations of wayfinding design in different types of facilities, and potentially to examine human responses to a broad range of additional design variables. Rigorous virtual testing of architectural designs has the potential to greatly expand the evidence-based design paradigm, promoting responsible, data-driven innovation in the field and leading to more effective and healthy built environments.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Saleh",
   "pi_last_name": "Kalantari",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Saleh Kalantari",
   "pi_email_addr": "sk3268@cornell.edu",
   "nsf_id": "000780547",
   "pi_start_date": "2020-08-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mahsa",
   "pi_last_name": "Shoaran",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mahsa Shoaran",
   "pi_email_addr": "shoaran@cornell.edu",
   "nsf_id": "000760794",
   "pi_start_date": "2020-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "373 Pine Tree Road",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148502820",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 415657.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Effective navigation in complex facilities like hospitals is crucial for reducing stress and improving operational efficiency. Our multidisciplinary project aimed to enhance wayfinding design in healthcare by leveraging immersive Virtual Reality (VR) environments and neurophysiological data collection. By simulating hospital environments before construction, we sought to rigorously test and optimize architectural design variables influencing navigation efficiency.</p>\n<p>Our goal was to develop a platform for immersive VR testing of wayfinding designs, integrating subjective feedback with biometric data like electroencephalography (EEG) and heart rate measurements. We pursued three primary aims: Aim 1&mdash;utilize VR and biometric data to compare the effectiveness of interior design variables (specifically color patterns, graphics, and architectural features) on wayfinding performance in a healthcare facility; Aim 2&mdash;assess the ecological validity of VR in wayfinding research by comparing human responses in real-world environments with those in identical VR replicas; and Aim 3&mdash;develop a Brain&ndash;Computer Interface (BCI) software tool that enables designers to access neurological data, create interaction prototypes, and evaluate designs based on neurophysiological feedback.</p>\n<p>In the first study, collaborating with Parkin Architects, we recreated the Corner Brook Acute Care Hospital in VR. We manipulated design variables to create three distinct conditions: (1) standard signage with minimal environmental contrast; (2) added color to highlight destinations and increase contrast; and (3) enhanced color, graphics, architectural features, and textures to further aid navigation. Participants were randomly assigned to one of the three conditions and completed wayfinding tasks while we collected behavioral data and neurophysiological measurements. We analyzed self-reported stress, fatigue, confusion levels, task completion times, orientation behaviors, and EEG data focusing on brain regions associated with spatial awareness and navigational processing.</p>\n<p>Our findings indicated that participants navigating the comprehensively enhanced environment exhibited significantly improved orientation behaviors. They spent more time viewing navigational signs, were more likely to proceed in the correct direction after viewing a sign, and demonstrated greater neural activation in parietal and occipital regions, evidenced by desynchronization in beta (25&ndash;35 Hz) and theta (3&ndash;7 Hz) EEG frequency bands. These neural patterns suggest heightened cognitive engagement and effective integration of environmental information during navigation. Interestingly, despite improved orientation behaviors and neural activations, there were no significant differences in self-reported stress or confusion levels across the different design conditions. This implies that enhanced design elements can facilitate navigation without necessarily altering subjective perceptions of difficulty or stress.</p>\n<p>To assess the generalizability of VR findings to real-world settings, we conducted another experiment comparing human responses in a real multi-level educational facility and its identical VR replica. We measured various metrics, including distance covered, mistakes made, task completion time, spatial memory, backtracking, sign observation, perceived uncertainty, cognitive workload, and task difficulty, observing significant discrepancies in all measures. We also analyzed potential age-related effects to look for heightened VR/real-world response discrepancies among older adults (+55) compared to younger adults (18&ndash;30), finding no significant age-by-condition interaction effects. Examining the spatial distribution of self-reported wayfinding uncertainty revealed similar areas of pronounced uncertainty in both settings. Overall, these findings indicate that while VR is a useful design research tool, caution is needed when interpreting and generalizing its results.</p>\n<p>We also developed NEURON, a BCI plugin for Rhino/Grasshopper, enabling designers to access neurological data and integrate it into the design process. NEURON allows for the creation of BCI interaction prototypes and the evaluation of designs based on neurophysiological feedback. Through three case studies, we demonstrated the tool's potential to support design generation and evaluation, highlighting its stability, usability, and effectiveness for designers with limited neuroscience experience.</p>\n<p>Our project resulted in multiple peer-reviewed publications and conference presentations, advancing knowledge at the intersection of design, neuroscience, and technology. We developed innovative tools such as the Continuous Uncertainty Annotation method and the Wayfind App, facilitating real-time tracking of behavior and self-reported responses during wayfinding tasks. These tools enhance the granularity and accuracy of data collection in navigation studies. The project provided substantial training opportunities for students across educational levels, involving them in research techniques, data analysis, and academic writing, thereby fostering interdisciplinary skills and promoting diversity in research participation.</p>\n<p>Our findings have significant implications for evidence-based design practices, particularly in healthcare settings where efficient navigation is critical. By demonstrating that specific architectural features and environmental affordances can enhance navigational cognition, we provide empirical support for design strategies that improve user experiences. The collaboration with Parkin Architects exemplifies the practical applicability of our research, influencing the final design of the Corner Brook Hospital and contributing to its recognition with the Touchstone Gold Medal Award for excellence in evidence-based design. Moreover, the methodological framework and tools developed in this project have the potential to impact multiple disciplines, including environmental psychology, brain&ndash;computer interfaces, and spatial cognition research. By making these resources available, we encourage other researchers and designers to adopt and build upon our approaches, ultimately contributing to improved design processes and built environments.</p><br>\n<p>\n Last Modified: 09/26/2024<br>\nModified by: Saleh&nbsp;Kalantari</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373698274_VR_vs_Real_2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373698274_VR_vs_Real_2--rgov-800width.jpg\" title=\"Comparing spatial navigation in a virtual environment vs. an identical real environment across the adult lifespan\"><img src=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373698274_VR_vs_Real_2--rgov-66x44.jpg\" alt=\"Comparing spatial navigation in a virtual environment vs. an identical real environment across the adult lifespan\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Spatial distribution of uncertainty (RE = real environment; VE = virtual environment; DIFF = difference between RE and VE).</div>\n<div class=\"imageCredit\">Design + Augmented Intelligence Lab</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Saleh&nbsp;Kalantari\n<div class=\"imageTitle\">Comparing spatial navigation in a virtual environment vs. an identical real environment across the adult lifespan</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373430356_NSF_Report--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373430356_NSF_Report--rgov-800width.jpg\" title=\"Wayfinding in Virtual Hospital\"><img src=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373430356_NSF_Report--rgov-66x44.jpg\" alt=\"Wayfinding in Virtual Hospital\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Screenshots from the participants' view in the virtual environment and a study participant wearing the physiological sensors and VR display helmet.</div>\n<div class=\"imageCredit\">Design + Augmented Intelligence Lab</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Saleh&nbsp;Kalantari\n<div class=\"imageTitle\">Wayfinding in Virtual Hospital</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373807538_Uncertainty_--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373807538_Uncertainty_--rgov-800width.jpg\" title=\"Identifying uncertainty states during wayfinding in indoor environments: An EEG classification study\"><img src=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373807538_Uncertainty_--rgov-66x44.jpg\" alt=\"Identifying uncertainty states during wayfinding in indoor environments: An EEG classification study\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">(a) Screenshot of a video clip in which the participant performed decisive movement. The uncertainty score from the raters for this clip was 1 (indicating very low levels of wayfinding uncertainty). (b) Model prediction and interpretation of the EEG data using Shapley Additive Explanations. The Rand</div>\n<div class=\"imageCredit\">Design + Augmented Intelligence Lab</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Saleh&nbsp;Kalantari\n<div class=\"imageTitle\">Identifying uncertainty states during wayfinding in indoor environments: An EEG classification study</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373891897_Uncertainty_2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373891897_Uncertainty_2--rgov-800width.jpg\" title=\"Identifying uncertainty states during wayfinding in indoor environments: An EEG classification study\"><img src=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373891897_Uncertainty_2--rgov-66x44.jpg\" alt=\"Identifying uncertainty states during wayfinding in indoor environments: An EEG classification study\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Schematic overview of decoding uncertainty during the wayfinding tasks.</div>\n<div class=\"imageCredit\">Design + Augmented Intelligence Lab</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Saleh&nbsp;Kalantari\n<div class=\"imageTitle\">Identifying uncertainty states during wayfinding in indoor environments: An EEG classification study</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373577917_VR_vs_Real--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373577917_VR_vs_Real--rgov-800width.jpg\" title=\"Comparing spatial navigation in a virtual environment vs. an identical real environment across the adult lifespan\"><img src=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373577917_VR_vs_Real--rgov-66x44.jpg\" alt=\"Comparing spatial navigation in a virtual environment vs. an identical real environment across the adult lifespan\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Top: Correspondence between the real-world facility and the virtual environment. Bottom: Participants in the real-world facility and the virtual environment.</div>\n<div class=\"imageCredit\">Design + Augmented Intelligence Lab</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Saleh&nbsp;Kalantari\n<div class=\"imageTitle\">Comparing spatial navigation in a virtual environment vs. an identical real environment across the adult lifespan</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373749171_Neuron--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373749171_Neuron--rgov-800width.jpg\" title=\"Visual flow-based programming plugin for brain\ufffdcomputer Interface in computer-aided design\"><img src=\"/por/images/Reports/POR/2024/2008501/2008501_10692402_1727373749171_Neuron--rgov-66x44.jpg\" alt=\"Visual flow-based programming plugin for brain\ufffdcomputer Interface in computer-aided design\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Neuron Components.</div>\n<div class=\"imageCredit\">Design + Augmented Intelligence Lab</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Saleh&nbsp;Kalantari\n<div class=\"imageTitle\">Visual flow-based programming plugin for brain\ufffdcomputer Interface in computer-aided design</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nEffective navigation in complex facilities like hospitals is crucial for reducing stress and improving operational efficiency. Our multidisciplinary project aimed to enhance wayfinding design in healthcare by leveraging immersive Virtual Reality (VR) environments and neurophysiological data collection. By simulating hospital environments before construction, we sought to rigorously test and optimize architectural design variables influencing navigation efficiency.\n\n\nOur goal was to develop a platform for immersive VR testing of wayfinding designs, integrating subjective feedback with biometric data like electroencephalography (EEG) and heart rate measurements. We pursued three primary aims: Aim 1utilize VR and biometric data to compare the effectiveness of interior design variables (specifically color patterns, graphics, and architectural features) on wayfinding performance in a healthcare facility; Aim 2assess the ecological validity of VR in wayfinding research by comparing human responses in real-world environments with those in identical VR replicas; and Aim 3develop a BrainComputer Interface (BCI) software tool that enables designers to access neurological data, create interaction prototypes, and evaluate designs based on neurophysiological feedback.\n\n\nIn the first study, collaborating with Parkin Architects, we recreated the Corner Brook Acute Care Hospital in VR. We manipulated design variables to create three distinct conditions: (1) standard signage with minimal environmental contrast; (2) added color to highlight destinations and increase contrast; and (3) enhanced color, graphics, architectural features, and textures to further aid navigation. Participants were randomly assigned to one of the three conditions and completed wayfinding tasks while we collected behavioral data and neurophysiological measurements. We analyzed self-reported stress, fatigue, confusion levels, task completion times, orientation behaviors, and EEG data focusing on brain regions associated with spatial awareness and navigational processing.\n\n\nOur findings indicated that participants navigating the comprehensively enhanced environment exhibited significantly improved orientation behaviors. They spent more time viewing navigational signs, were more likely to proceed in the correct direction after viewing a sign, and demonstrated greater neural activation in parietal and occipital regions, evidenced by desynchronization in beta (2535 Hz) and theta (37 Hz) EEG frequency bands. These neural patterns suggest heightened cognitive engagement and effective integration of environmental information during navigation. Interestingly, despite improved orientation behaviors and neural activations, there were no significant differences in self-reported stress or confusion levels across the different design conditions. This implies that enhanced design elements can facilitate navigation without necessarily altering subjective perceptions of difficulty or stress.\n\n\nTo assess the generalizability of VR findings to real-world settings, we conducted another experiment comparing human responses in a real multi-level educational facility and its identical VR replica. We measured various metrics, including distance covered, mistakes made, task completion time, spatial memory, backtracking, sign observation, perceived uncertainty, cognitive workload, and task difficulty, observing significant discrepancies in all measures. We also analyzed potential age-related effects to look for heightened VR/real-world response discrepancies among older adults (+55) compared to younger adults (1830), finding no significant age-by-condition interaction effects. Examining the spatial distribution of self-reported wayfinding uncertainty revealed similar areas of pronounced uncertainty in both settings. Overall, these findings indicate that while VR is a useful design research tool, caution is needed when interpreting and generalizing its results.\n\n\nWe also developed NEURON, a BCI plugin for Rhino/Grasshopper, enabling designers to access neurological data and integrate it into the design process. NEURON allows for the creation of BCI interaction prototypes and the evaluation of designs based on neurophysiological feedback. Through three case studies, we demonstrated the tool's potential to support design generation and evaluation, highlighting its stability, usability, and effectiveness for designers with limited neuroscience experience.\n\n\nOur project resulted in multiple peer-reviewed publications and conference presentations, advancing knowledge at the intersection of design, neuroscience, and technology. We developed innovative tools such as the Continuous Uncertainty Annotation method and the Wayfind App, facilitating real-time tracking of behavior and self-reported responses during wayfinding tasks. These tools enhance the granularity and accuracy of data collection in navigation studies. The project provided substantial training opportunities for students across educational levels, involving them in research techniques, data analysis, and academic writing, thereby fostering interdisciplinary skills and promoting diversity in research participation.\n\n\nOur findings have significant implications for evidence-based design practices, particularly in healthcare settings where efficient navigation is critical. By demonstrating that specific architectural features and environmental affordances can enhance navigational cognition, we provide empirical support for design strategies that improve user experiences. The collaboration with Parkin Architects exemplifies the practical applicability of our research, influencing the final design of the Corner Brook Hospital and contributing to its recognition with the Touchstone Gold Medal Award for excellence in evidence-based design. Moreover, the methodological framework and tools developed in this project have the potential to impact multiple disciplines, including environmental psychology, braincomputer interfaces, and spatial cognition research. By making these resources available, we encourage other researchers and designers to adopt and build upon our approaches, ultimately contributing to improved design processes and built environments.\t\t\t\t\tLast Modified: 09/26/2024\n\n\t\t\t\t\tSubmitted by: SalehKalantari\n"
 }
}