{
 "awd_id": "1956200",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: Dictionary Attacks on Biometrics",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925177",
 "po_email": "asquicci@nsf.gov",
 "po_sign_block_name": "Anna Squicciarini",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 483437.0,
 "awd_amount": 483437.0,
 "awd_min_amd_letter_date": "2020-06-23",
 "awd_max_amd_letter_date": "2020-06-23",
 "awd_abstract_narration": "Biometric authentication, that lets you identify yourself with for example your fingerprint, your voice, or your face, is a very common authentication mechanism these days. Most smartphones and a growing number of other devices and systems feature some form of biometrics. This is partly because they are seen as faster, easier and sometimes more secure alternatives to passwords. However, recent studies suggest that the machine learning methods at the core of biometric authentication systems have serious vulnerabilities. In particular, it is sometimes possible to use what's called a \"dictionary attack\", where a set of existing tokens can be found which together have a high probability of bypassing the authentication system. In this project, the researchers will study such attacks on various biometric systems, and also find effective defenses for them. The project builds on work where the investigators used modern machine learning approaches to find vulnerabilities in fingerprint and voice authentication. The methods developed will improve the overall security and reliability of biometric authentication mechanisms.\r\n\r\nIn contrast to well-known spoofing, dictionary attacks do not rely on biometric samples of a targeted individual, e.g., voice recordings or latent prints, but instead exploit weaknessess of the specific biometric modality (or its deployment). They allow targeting of entire populations, and rely on fortuitous matches of common biometric features. Recent advances in machine learning, and in particular in generative models such as Generative Adversarial Networks, have made such attacks possible for biometrics. The goal of this project is to systematically study the security of biometrics in commonly used unsupervised and mobile deployments, e.g., in smartphones, home assistants, IoT devices, or voice calls. The researchers will focus on the newly discovered dictionary attacks on the fingerprint, voice and face modalities. Investigators will study practical threat models and propose attack detection and mitigation strategies. The project will address questions which are focused on understanding this type of vulnerability and its associated attacks, and how they can best be defended against:\r\n\r\n- What are the most practical threat models and what are the capabilities the attackers need to posess?\r\n- Do the attack strategies generalize between the modalities?\r\n- Are the identified \"master-examples\" universal? Do they transfer between user populations and authentication systems?\r\n- What is the optimal mitigation strategy? Is it possible to reliably detect the presented synthetic content?\r\n- Is it possible to improve the enrollment policy to maximize security and/or warn the user about higher vulnerability of the enrolled examples?\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Julian",
   "pi_last_name": "Togelius",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Julian Togelius",
   "pi_email_addr": "julian.togelius@nyu.edu",
   "nsf_id": "000686152",
   "pi_start_date": "2020-06-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Nasir",
   "pi_last_name": "Memon",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Nasir D Memon",
   "pi_email_addr": "Nm1214@nyu.edu",
   "nsf_id": "000403287",
   "pi_start_date": "2020-06-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Pawel",
   "pi_last_name": "Korus",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pawel Korus",
   "pi_email_addr": "pkorus@nyu.edu",
   "nsf_id": "000792560",
   "pi_start_date": "2020-06-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "70 Washington Square S",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 483437.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Biometric recognition relies on physical characteristics and behavioral patterns to authenticate an individual. The widespread use of biometric recognition in personalized devices such as smartphones and laptops, as well as for law enforcement, company site access control, and immigration control, requires detailed security analysis. This project explores a specific type of vulnerability in biometric recognition systems known as dictionary attacks, which can impersonate multiple individuals in a single attempt using a synthetic attack vector.</span></p>\r\n<p>We've had the most success with attacks on fingerprint recognition, followed by attacks on speaker recognition, and comparatively lesser success with attacks on iris recognition. Given that we used similar methods, this outcome most likely reflects that iris recognition is an inherently more robus modality.</p>\r\n<p>We demonstrated the feasibility of dictionary attacks on fingerprint, speaker, and iris recognition systems. Our work used evolutionary algorithms and generative adversarial networks to design dictionary attacks effective on templates (minutiae) and images (fingerprint).</p>\r\n<p>The published work exposed the vulnerability of partial fingerprint-based recognition systems. The work resulted in \"DeepMasterPrints\" which received public attention and won the Best Paper Award at BTAS.</p>\r\n<p>Speaker recognition systems use waveform or template (spectrogram) representation for verification. Dictionary attacks spoofed multiple users on state-of-the-art speaker verification systems that use raw signals and encoded representations. The project observed maximal success using black-box voice cloning attacks.</p>\r\n<p>Iris recognition systems are known to be resilient against various attacks. We leveraged underlying domain information, specifically, biometric menagerie, to generate synthetic IrisCodes as dictionary attacks. This was moderately successful, but not at the level of the other modalities. At the end of the project, we had not yet been able to produce an attack method for full iris images (as opposed to in the iris code domain), though work is ongoing to try to do this.</p>\r\n<p>In sum, the work done in this project helps us better characterize and understand the security profile of three important modalities of biometric authentication. The attack methods discovered and refined within the project can inform future iterations of biometric recognition protocols, and eventually make all of us safer.</p><br>\n<p>\n Last Modified: 02/13/2025<br>\nModified by: Julian&nbsp;Togelius</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nBiometric recognition relies on physical characteristics and behavioral patterns to authenticate an individual. The widespread use of biometric recognition in personalized devices such as smartphones and laptops, as well as for law enforcement, company site access control, and immigration control, requires detailed security analysis. This project explores a specific type of vulnerability in biometric recognition systems known as dictionary attacks, which can impersonate multiple individuals in a single attempt using a synthetic attack vector.\r\n\n\nWe've had the most success with attacks on fingerprint recognition, followed by attacks on speaker recognition, and comparatively lesser success with attacks on iris recognition. Given that we used similar methods, this outcome most likely reflects that iris recognition is an inherently more robus modality.\r\n\n\nWe demonstrated the feasibility of dictionary attacks on fingerprint, speaker, and iris recognition systems. Our work used evolutionary algorithms and generative adversarial networks to design dictionary attacks effective on templates (minutiae) and images (fingerprint).\r\n\n\nThe published work exposed the vulnerability of partial fingerprint-based recognition systems. The work resulted in \"DeepMasterPrints\" which received public attention and won the Best Paper Award at BTAS.\r\n\n\nSpeaker recognition systems use waveform or template (spectrogram) representation for verification. Dictionary attacks spoofed multiple users on state-of-the-art speaker verification systems that use raw signals and encoded representations. The project observed maximal success using black-box voice cloning attacks.\r\n\n\nIris recognition systems are known to be resilient against various attacks. We leveraged underlying domain information, specifically, biometric menagerie, to generate synthetic IrisCodes as dictionary attacks. This was moderately successful, but not at the level of the other modalities. At the end of the project, we had not yet been able to produce an attack method for full iris images (as opposed to in the iris code domain), though work is ongoing to try to do this.\r\n\n\nIn sum, the work done in this project helps us better characterize and understand the security profile of three important modalities of biometric authentication. The attack methods discovered and refined within the project can inform future iterations of biometric recognition protocols, and eventually make all of us safer.\t\t\t\t\tLast Modified: 02/13/2025\n\n\t\t\t\t\tSubmitted by: JulianTogelius\n"
 }
}