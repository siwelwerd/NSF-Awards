{
 "awd_id": "2003131",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: MLWiNS: Dino-RL: A Domain Knowledge Enriched Reinforcement Learning Framework for Wireless Network Optimization",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2020-06-01",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 181571.0,
 "awd_amount": 208240.0,
 "awd_min_amd_letter_date": "2020-05-27",
 "awd_max_amd_letter_date": "2021-07-26",
 "awd_abstract_narration": "Reinforcement learning (RL) methods have met with renewed interest in recent years for adaptively configuring wireless networks. Despite the promising early results and the conceptual match, many existing approaches do not develop and tailor the RL methods to fit the unique characteristics of wireless networking. The goal of this project is to develop a novel domain knowledge enriched RL framework, or Dino-RL, to address this problem. The Dino-RL framework aims to seamlessly integrate the physical-law based modeling and an abstract episodic memory into the RL process, and has the potential to revamp the operation and management of future wireless networks. Developing this novel technology would also help maintain the nation's continued leadership in wireless technologies and its pipeline of highly qualified engineers. \r\n\r\nThe project pursues synergistic activities for the successful design and implementation of Dino-RL, followed by a comprehensive, real-world data driven evaluation. Episodic RL is first studied with the objective to incorporate domain knowledge into building an efficient episodic memory. In addition, a hierarchical hidden variable model is built to enable meta-reinforcement learning for knowledge transfer and efficient exploration. Lastly, the conflict between enhancing the physical-law based modeling and reinforcement learning is balanced via novel sample-efficient model selection algorithms.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jing",
   "pi_last_name": "Yang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jing Yang",
   "pi_email_addr": "akz2wg@virginia.edu",
   "nsf_id": "000627186",
   "pi_start_date": "2020-05-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "13A EE West",
  "perf_city_name": "University Park",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168021503",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "PA15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8585",
   "pgm_ref_txt": "NSF/Intel Partnership Projects"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "021Z",
   "pgm_ref_txt": "Industry Partnerships"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 181571.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 26669.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aims to build a new paradigm of reinforcement learning (RL) based network optimization schemes for wireless networks operating in a highly dynamic and even non-stationary environment. The objective is to tightly incorporate the domain knowledge of wireless network operations to the design and analysis of RL algorithms, and demonstrate performance improvement over state of the art.</p>\n<p>Throughout the duration of this project, the team mainly focuses on two research directions: On one side, it focuses on the theoretical side of RL, and strives to unveil the theoretical underpinnings of modern RL algorithms.&nbsp;&nbsp;On the one side, with the insights obtained from the theoretical study, it develops practical RL algorithms that efficiently solve various important wireless network optimizations. The results obtained from this project significantly advance the understanding of RL in the research community, and provide an efficient solution for wireless network optimization, especially for networks operating in a highly dynamic and even non-stationary environment.&nbsp;</p>\n<p>The reinforcement learning models and algorithms improve the state of the art in machine learning and sequential decision making, and can be applied to a variety of disciplines, such as autonomous driving, smart cities, recommender systems, etc. This research has the potential to transform the way how next generation wireless networks operate, enabling more intelligent, adaptive, and context-aware network management solutions.</p>\n<p>Three Ph.D. students have been trained through this project. They learned how to use the analytical tools and computer simulations to study both wireless communication networks and machine learning. The project promotes their creativity and independent problem-solving abilities. Results obtained from this project have been presented during the monthly meetings with Intel researchers and the annual workshop organized by Intel, and published in top venues in machine learning, information theory, signal processing, and communications. The research results have also been incorporated into EE597: Selected Topics on Reinforcement Learning, a graduate level course developed by the PI at PSU.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 09/03/2024<br>\nModified by: Jing&nbsp;Yang</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project aims to build a new paradigm of reinforcement learning (RL) based network optimization schemes for wireless networks operating in a highly dynamic and even non-stationary environment. The objective is to tightly incorporate the domain knowledge of wireless network operations to the design and analysis of RL algorithms, and demonstrate performance improvement over state of the art.\n\n\nThroughout the duration of this project, the team mainly focuses on two research directions: On one side, it focuses on the theoretical side of RL, and strives to unveil the theoretical underpinnings of modern RL algorithms.On the one side, with the insights obtained from the theoretical study, it develops practical RL algorithms that efficiently solve various important wireless network optimizations. The results obtained from this project significantly advance the understanding of RL in the research community, and provide an efficient solution for wireless network optimization, especially for networks operating in a highly dynamic and even non-stationary environment.\n\n\nThe reinforcement learning models and algorithms improve the state of the art in machine learning and sequential decision making, and can be applied to a variety of disciplines, such as autonomous driving, smart cities, recommender systems, etc. This research has the potential to transform the way how next generation wireless networks operate, enabling more intelligent, adaptive, and context-aware network management solutions.\n\n\nThree Ph.D. students have been trained through this project. They learned how to use the analytical tools and computer simulations to study both wireless communication networks and machine learning. The project promotes their creativity and independent problem-solving abilities. Results obtained from this project have been presented during the monthly meetings with Intel researchers and the annual workshop organized by Intel, and published in top venues in machine learning, information theory, signal processing, and communications. The research results have also been incorporated into EE597: Selected Topics on Reinforcement Learning, a graduate level course developed by the PI at PSU.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 09/03/2024\n\n\t\t\t\t\tSubmitted by: JingYang\n"
 }
}