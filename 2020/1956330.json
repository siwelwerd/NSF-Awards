{
 "awd_id": "1956330",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: RI: Medium: A Rigorous, General Framework for Tractable Learning of Large-Scale DAGs from Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2020-06-15",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 392866.0,
 "awd_amount": 398866.0,
 "awd_min_amd_letter_date": "2020-06-10",
 "awd_max_amd_letter_date": "2022-06-06",
 "awd_abstract_narration": "Recent advances in machine learning and artificial intelligence owe much of their success to the development of algorithms that learn complicated relationships and understanding complex phenomena from massive datasets. These algorithms have been successfully applied on a diverse array of applications, including medicine, genetics, robotics, marketing, finance, and, increasingly, in societal applications. Despite their many successes, however, these applications continue to suffer from security, transparency, fairness, and interpretability problems. Many of these practical challenges can be traced back to well-known limitations with respect to interpretability, causality, and false discoveries. At the same time, substantial progress has been made in recent years in our understanding of these practical challenges in relatively simple settings with only a few factors and comparatively simple models. This research seeks to integrate these efforts, in order to provide a flexible framework for flexible, interpretable, causal modeling from high-dimensional, complex datasets. The investigated approach specifically seeks to avoid spurious correlations that commonly appear in complex datasets, while retaining the flexibility of modern machine learning algorithms with an eye towards applications in medicine, biology, and finance.\r\n\r\nWhile many applications of machine learning have been driven by impressive advances in complex predictive models, at the same time a need has emerged for models that can extract causal information from massive, unlabeled datasets. Graphical models provide a principled and effective way to uncover this type knowledge from unlabeled data. Although the problem of learning undirected graphs has witnessed a series of remarkable advances over the past decade, directed acyclic graphs (DAGs) that encode directed, potentially causal information, have not benefited from these advances. As a result, there is a pressing need for novel and theoretically sound methods for learning DAGs that can capture complex, asymmetric relationships, reduce model complexity, and most importantly, learn causal relationships for human decision-makers and stakeholders. This project explores a new approach for learning DAGs from data that provides the basis for a general statistical and computational framework, which has been lacking thus far. The technical aims can be divided along three major axes: 1) Developing novel continuous relaxations of the combinatorial optimization problems that arise in structure learning problems, 2) Developing new tools for analyzing the behavior of optimization schemes in highly nonconvex settings, and 3) Theoretical advances in nonparametric causal modeling and its statistical properties.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nikhyl",
   "pi_last_name": "Aragam",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Nikhyl B Aragam",
   "pi_email_addr": "bryon@chicagobooth.edu",
   "nsf_id": "000810540",
   "pi_start_date": "2020-06-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "5807 South Woodlawn Avenue",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606371610",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 127280.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 130917.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 140669.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Recent years have seen significant interest in bridging causality and modern machine learning, which has necessitated new approaches to learning causal relationships from data. Inspired by the success of differentiable models such as deep neural networks, this project focuses on re-formulating the problem of learning causal models as a differentiable optimization problem. <br /><br />We pursued this goal by blending ideas from graphical models, optimization, and statistical machine learning. Graphical models provide a general mathematical framework for representing and learning multivariate dependencies in complex datasets via graphs. Such graphs have also proven crucial to representing causality, algorithmically and computationally. However, when the causal graph is unknown, a significant practical challenge is learning this graph from data. By framing the learning problem as an optimization problem, a host of tools from the optimization literature become available: Gradient-based optimization, Karush-Kuhn-Tucker theory, bilevel and stochastic optimization, and homotopy methods, for example.<br /><br />Over the course of this project, we developed a unified, general framework for learning causal models as a nonconvex optimization problem. Our goals were both algorithmic and statistical. Algorithmically, we showed how to decompose the general problem into three differentiable components that align nicely with standard approaches in ML: The objective, the constraint, and the optimizer. Achieving this was a major breakthrough for learning causal models: Most ML problems have standard decompositions of this form, however, causal learning has notoriously resisted this approach. One of the first key practical steps was to carefully study the constraints (in the form of acyclicity), and to propose a new, fast constraint function based on M-matrices and a log-barrier function. We next investigated the resulting optimization problem, and developed novel algorithms for finding both local and global minimizers, with substantial improvements in accuracy. We also investigated the use of new objectives that lead to more robust identifiability and invariance properties. We also explored models with latent variables, including the application of deep generative models. We established some of the first identifiability results for deep causal models with nonparametric latent structure. This has provided foundational in the burgeoning field of causal representation learning.<br /><br />Statistically, we advanced the field in several directions. We developed a detailed nonparametric theory for learning graphical models as well as the first minimax theory for causal models, which allowed us to characterize optimal algorithms for learning causal graphs. This led directly to a new method for variable selection in causal models and showed that it provably improves over state-of-the-art approaches such as the Lasso and subset selection. This is an important subroutine that every causal learning method must implement, and thus has broad implications for the field.<br /><br />Finally, on the software front, we delivered two main advances: A detailed comparison of existing methods and the release of a new Python library for learning causal models. This library contains implementations of all the algorithms produced over the course of this project, implemented as a general-purpose framework in Torch.<br /><br />Overall, the developments from this project have significantly advanced both the foundations and practice of learning of causal models with strong guarantees, which is essential given the growing adoption of ML and AI tools in high-stakes settings such as healthcare and law and broader consumer-facing settings where causality is essential.</p><br>\n<p>\n Last Modified: 09/18/2024<br>\nModified by: Nikhyl&nbsp;B&nbsp;Aragam</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nRecent years have seen significant interest in bridging causality and modern machine learning, which has necessitated new approaches to learning causal relationships from data. Inspired by the success of differentiable models such as deep neural networks, this project focuses on re-formulating the problem of learning causal models as a differentiable optimization problem. \n\nWe pursued this goal by blending ideas from graphical models, optimization, and statistical machine learning. Graphical models provide a general mathematical framework for representing and learning multivariate dependencies in complex datasets via graphs. Such graphs have also proven crucial to representing causality, algorithmically and computationally. However, when the causal graph is unknown, a significant practical challenge is learning this graph from data. By framing the learning problem as an optimization problem, a host of tools from the optimization literature become available: Gradient-based optimization, Karush-Kuhn-Tucker theory, bilevel and stochastic optimization, and homotopy methods, for example.\n\nOver the course of this project, we developed a unified, general framework for learning causal models as a nonconvex optimization problem. Our goals were both algorithmic and statistical. Algorithmically, we showed how to decompose the general problem into three differentiable components that align nicely with standard approaches in ML: The objective, the constraint, and the optimizer. Achieving this was a major breakthrough for learning causal models: Most ML problems have standard decompositions of this form, however, causal learning has notoriously resisted this approach. One of the first key practical steps was to carefully study the constraints (in the form of acyclicity), and to propose a new, fast constraint function based on M-matrices and a log-barrier function. We next investigated the resulting optimization problem, and developed novel algorithms for finding both local and global minimizers, with substantial improvements in accuracy. We also investigated the use of new objectives that lead to more robust identifiability and invariance properties. We also explored models with latent variables, including the application of deep generative models. We established some of the first identifiability results for deep causal models with nonparametric latent structure. This has provided foundational in the burgeoning field of causal representation learning.\n\nStatistically, we advanced the field in several directions. We developed a detailed nonparametric theory for learning graphical models as well as the first minimax theory for causal models, which allowed us to characterize optimal algorithms for learning causal graphs. This led directly to a new method for variable selection in causal models and showed that it provably improves over state-of-the-art approaches such as the Lasso and subset selection. This is an important subroutine that every causal learning method must implement, and thus has broad implications for the field.\n\nFinally, on the software front, we delivered two main advances: A detailed comparison of existing methods and the release of a new Python library for learning causal models. This library contains implementations of all the algorithms produced over the course of this project, implemented as a general-purpose framework in Torch.\n\nOverall, the developments from this project have significantly advanced both the foundations and practice of learning of causal models with strong guarantees, which is essential given the growing adoption of ML and AI tools in high-stakes settings such as healthcare and law and broader consumer-facing settings where causality is essential.\t\t\t\t\tLast Modified: 09/18/2024\n\n\t\t\t\t\tSubmitted by: NikhylBAragam\n"
 }
}