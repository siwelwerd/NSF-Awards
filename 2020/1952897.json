{
 "awd_id": "1952897",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Variational Inference Approach to Computer Model Calibration, Uncertainty Quantification, Scalability, and Robustness",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922595",
 "po_email": "mbocea@nsf.gov",
 "po_sign_block_name": "Marian Bocea",
 "awd_eff_date": "2020-08-15",
 "awd_exp_date": "2023-10-31",
 "tot_intn_awd_amt": 110000.0,
 "awd_amount": 64705.0,
 "awd_min_amd_letter_date": "2020-06-16",
 "awd_max_amd_letter_date": "2024-03-21",
 "awd_abstract_narration": "Computer models are found to be effective in many applications such as climate modeling, human organ modeling, and nuclear physics problems. There is an increasing interest how the computer output could be coupled with locally available data for quick inference that accounts for the myriad of uncertainty sources. This project focuses on developing new computational techniques and flexible model building in addition to associated software development. The project will impact science and society because of the interdisciplinary research between nuclear physics, computer modeling, and statistical theory. This research will uncover statistical properties and computational techniques to transform the next generation computational scientists and practitioners. The fast and scalable computation will enhance the use of computer models in real world problem solving.\r\n\r\n\r\nThis project develops statistically valid techniques that are both computationally inexpensive and practical to facilitate the use of computer model outputs together with local data accounting model and parameter uncertainty. The approach extends to a robust modeling approach in case of model failures that can occur when covering a large study domain. In particular, the research team will develop Gaussian process-based emulator that models both the sparsely observed computer model and the unknown discrepancy that explains the gap between the model and reality. The approach is Bayesian which provides for the natural quantification of uncertainties. The key tool for statistical inference is to replace the standard practice of Markov Chain Monte Carlo (MCMC) with a novel usage of variational Bayes (VB) inference. While the variational Bayes is popular in machine learning literature, the technique is not as popular in statistics as MCMC based sampling techniques. The slow uptake the VB framework seems to be due to the additional complexities it adds to modeling and the relatively uncharted theoretical properties. This project develops an innovative VB algorithm to resolve the present issues in computer model calibration with the aim of improving the computation scalability and extendibility in a robust modeling approach. We plan to build software for translational research to reach the desired applications for maximum impact. The research will provide transformative research that impacts statistical computation, Bayesian statistics, computer modeling and calibration, and related applications.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Stefan",
   "pi_last_name": "Wild",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Stefan M Wild",
   "pi_email_addr": "wild@anl.gov",
   "nsf_id": "000609143",
   "pi_start_date": "2020-06-16",
   "pi_end_date": "2022-12-08"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Plumlee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew Plumlee",
   "pi_email_addr": "mplumlee.data@gmail.com",
   "nsf_id": "000710716",
   "pi_start_date": "2022-12-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Stefan",
   "pi_last_name": "Wild",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Stefan M Wild",
   "pi_email_addr": "wild@anl.gov",
   "nsf_id": "000609143",
   "pi_start_date": "2022-12-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Plumlee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew Plumlee",
   "pi_email_addr": "mplumlee.data@gmail.com",
   "nsf_id": "000710716",
   "pi_start_date": "2020-06-16",
   "pi_end_date": "2022-12-08"
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "2205 Tech Drive",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602083112",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  },
  {
   "pgm_ele_code": "808400",
   "pgm_ele_name": "CDS&E"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "8084",
   "pgm_ref_txt": "CDS&E"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 64704.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research project has significantly advanced the way we use computer  simulations to solve complex problems across various scientific fields  by developing sophisticated methods that effectively handle incomplete  data. These advancements have bridged the gap more accurately between  theoretical models and real-world observations. The project has yielded a  set of innovative computational tools for emulation that assist  scientists and engineers in calibrating their models, quantifying  uncertainties, and conducting sensitivity analyses with greater  reliability and precision. A pivotal innovation of this project is a  novel method that simplifies the management of simulation outputs with  missing data by intelligently imputing these gaps and adjusting the  uncertainty quantification processes, thereby enhancing the reliability  and accuracy of the simulations. Additionally, the project has developed  techniques to predict when simulations might fail due to the complexity  of the model or the vastness of the data being analyzed, employing  advanced statistical methods to understand and forecast potential  failures&mdash;a crucial step for improving the robustness and accuracy of  simulations in practical scenarios. Moreover, the project introduced a  groundbreaking technique that manages noisy, high-dimensional  data&mdash;common in sophisticated simulations&mdash;without the heavy computational  costs typically involved. This technique allows scientists to make  faster and more precise predictions after computer experiments, which is especially beneficial in  fields where timely and accurate results are critical. Through these  developments, the project has not only enhanced the toolset available  for statistical computation but also deepened our understanding of how  to manage uncertainties in simulation outputs. These advancements have  been integrated into a widely accessible software package. With one  article published and others under refinement, the project continues to  shape the future of how simulations are used to understand and solve  complex issues, demonstrating the powerful impact of combining  statistical science with computer modeling of complex systems.</p><br>\n<p>\n Last Modified: 05/12/2024<br>\nModified by: Matthew&nbsp;Plumlee</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis research project has significantly advanced the way we use computer  simulations to solve complex problems across various scientific fields  by developing sophisticated methods that effectively handle incomplete  data. These advancements have bridged the gap more accurately between  theoretical models and real-world observations. The project has yielded a  set of innovative computational tools for emulation that assist  scientists and engineers in calibrating their models, quantifying  uncertainties, and conducting sensitivity analyses with greater  reliability and precision. A pivotal innovation of this project is a  novel method that simplifies the management of simulation outputs with  missing data by intelligently imputing these gaps and adjusting the  uncertainty quantification processes, thereby enhancing the reliability  and accuracy of the simulations. Additionally, the project has developed  techniques to predict when simulations might fail due to the complexity  of the model or the vastness of the data being analyzed, employing  advanced statistical methods to understand and forecast potential  failuresa crucial step for improving the robustness and accuracy of  simulations in practical scenarios. Moreover, the project introduced a  groundbreaking technique that manages noisy, high-dimensional  datacommon in sophisticated simulationswithout the heavy computational  costs typically involved. This technique allows scientists to make  faster and more precise predictions after computer experiments, which is especially beneficial in  fields where timely and accurate results are critical. Through these  developments, the project has not only enhanced the toolset available  for statistical computation but also deepened our understanding of how  to manage uncertainties in simulation outputs. These advancements have  been integrated into a widely accessible software package. With one  article published and others under refinement, the project continues to  shape the future of how simulations are used to understand and solve  complex issues, demonstrating the powerful impact of combining  statistical science with computer modeling of complex systems.\t\t\t\t\tLast Modified: 05/12/2024\n\n\t\t\t\t\tSubmitted by: MatthewPlumlee\n"
 }
}