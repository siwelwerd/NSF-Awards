{
 "awd_id": "1952236",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SCC-PG: Fostering Aging-in-Place and Autonomy in Elderly Persons through Intelligent Tracking",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2020-08-17",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "As people age they begin to need assistance with activities of daily life (ADLs). Losing the ability to perform ADLs requires that these individuals receive care from family members, move to senior living communities or experience a significant drop in their quality of life. Given the projected rise in the number of older adults over the coming decades, the resources available to care for this population will be spread thin, potentially leaving some with lower quality of care or even without any form of care. One means of addressing this is developing systems that allow older adults to live independently while maintaining their quality of life for longer. Such systems would not only meet a well-documented desire to live independently, but also reduce the burden of care on caregivers and/or the need for more expensive forms of long-term care. This project will lay the groundwork for the development of a scalable gerontechnological system consisting of sensors and novel algorithms designed to recognize ADL performance in real-world settings. Through tracking of resident performance of ADLs we aim to facilitate more timely and relevant care and interventions.\r\n\r\nThe project works with multiple senior living communities to develop a gerontechnological system that allows for a quantified daily health profile to enable meaningful care for those who wish to age-in-place. This planning grant attempts to answer the following research questions through interviews and observational studies with each collaborating senior living community and determination of preliminary technological details: (1) What are the specific needs of both caregivers and residents from a gerontechnological system built on the recognition of ADLs and resident location? (2) What are the requirements of the indoor positioning system (IPS)? (3) What are the privacy needs and concerns of the caretakers and residents and how can the system address them? The information gained from the planning grant will allow us to submit a multi-year Integrative Research Grant that will attempt to answer the following research questions: (1) Can common ADLs be accurately recognized using a combination of wearable devices and novel machine learning algorithms and methodologies? (2) How does the recognition of activity patterns, feedback to residents and caregivers, and individually-tailored interventions support and/or impact the lives of senior living  community residents? (3) How does the recognition of activity patterns, feedback to residents and caregivers, and individually-tailored ADL support and/or impact the workload and ease the burden of care on the caregivers within the senior living facilities? Successful completion of this work has the potential to transform the current paradigm of elderly healthcare from reactive to proactive by monitoring and supporting the health of the elderly population.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tracy",
   "pi_last_name": "Hammond",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Tracy A Hammond",
   "pi_email_addr": "hammond@tamu.edu",
   "nsf_id": "000118785",
   "pi_start_date": "2020-08-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Goldberg",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel Goldberg",
   "pi_email_addr": "daniel.goldberg@tamu.edu",
   "nsf_id": "000627978",
   "pi_start_date": "2020-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M University",
  "perf_str_addr": "Dept. of Comp. Sci. & Eng.",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433112",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "033Y00",
   "pgm_ele_name": "S&CC: Smart & Connected Commun"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "042Z",
   "pgm_ref_txt": "S&CC: Smart and Connected Communities"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-1b31e4d9-7fff-17f9-4de7-06e8fbd9a2bb\"> </span></p><p dir=\"ltr\"><span>As wearable technologies become capable of recognizing our daily activities, there is an increasing opportunity to utilize these devices and algorithms to improve the state of elderly care.&nbsp;</span></p><p dir=\"ltr\"><span>To that end this work had two parallel goals:</span></p><ol><li dir=\"ltr\"><p dir=\"ltr\"><span>Understand the needs of caregivers and residents in senior living communities and how the recognition of Activities of Daily Living (ADLs) could increase resident independence, reduce the caregiver burden of care, and ultimately improve the quality of care.</span></p></li><li dir=\"ltr\"><p dir=\"ltr\"><span>Develop novel activity recognition algorithms capable of recognizing a wider array of Activities of Daily Living in real-world scenarios.</span></p></li></ol><p dir=\"ltr\"><span>In terms of the first goal, we worked with two senior living communities where we interviewed both caregivers and residents to understand what activities they would like to see monitored, how that information would be presented, and how the resident?s privacy and well-being could be maintained. Based on these interviews we developed AutoRounds, a prototype interface which allows caregivers to view resident ADL performance, vital signs, and locations, communicate via a notes system with other caregivers, and get notifications when an adverse event (e.g., a fall) occurs. In terms of the second goal, we have developed an algorithm that is able to recognize when individuals take medication in a fully in-the-wild scenario, which is challenging given that it occurs infrequently over the course of a day. We have also developed a generalized algorithm to recognize a handful of ADLs (e.g., brushing teeth, washing hands, drinking, walking) in fully in-the-wild scenarios.</span></p><div><span><br /></span></div><p>&nbsp;</p><p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/16/2022<br>\n\t\t\t\t\tModified by: Tracy&nbsp;A&nbsp;Hammond</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209217199_residents_view--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209217199_residents_view--rgov-800width.jpg\" title=\"Residents view\"><img src=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209217199_residents_view--rgov-66x44.jpg\" alt=\"Residents view\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Residents view</div>\n<div class=\"imageCredit\">Josh Cherian & Tracy Hammond</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tracy&nbsp;A&nbsp;Hammond</div>\n<div class=\"imageTitle\">Residents view</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209320615_resident_vitals--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209320615_resident_vitals--rgov-800width.jpg\" title=\"Vitals\"><img src=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209320615_resident_vitals--rgov-66x44.jpg\" alt=\"Vitals\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Resident Vitals</div>\n<div class=\"imageCredit\">Josh Cherian & Tracy Hammond</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tracy&nbsp;A&nbsp;Hammond</div>\n<div class=\"imageTitle\">Vitals</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209374254_resident_summary--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209374254_resident_summary--rgov-800width.jpg\" title=\"Summary\"><img src=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209374254_resident_summary--rgov-66x44.jpg\" alt=\"Summary\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Resident summary</div>\n<div class=\"imageCredit\">Josh Cherian & Tracy Hammond</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tracy&nbsp;A&nbsp;Hammond</div>\n<div class=\"imageTitle\">Summary</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209793709_map_view--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209793709_map_view--rgov-800width.jpg\" title=\"Map\"><img src=\"/por/images/Reports/POR/2022/1952236/1952236_10698493_1671209793709_map_view--rgov-66x44.jpg\" alt=\"Map\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Map of the facility</div>\n<div class=\"imageCredit\">Josh Cherian & Tracy Hammond</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tracy&nbsp;A&nbsp;Hammond</div>\n<div class=\"imageTitle\">Map</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"porColContainerHR\">\n<div class=\"porContentCol\">\n<h2>Addendum # 1</h2><p dir=\"ltr\"><span>As wearable technologies become capable of recognizing our daily activities, there is an increasing opportunity to utilize these devices and algorithms to improve the state of elderly care.&nbsp;</span></p>\n<p dir=\"ltr\"><span>To that end this work had two parallel goals:</span></p>\n<ol>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Understand the needs of caregivers and residents in senior living communities and how the recognition of Activities of Daily Living (ADLs) could increase resident independence, reduce the caregiver burden of care, and ultimately improve the quality of care.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Develop novel activity recognition algorithms capable of recognizing a wider array of Activities of Daily Living in real-world scenarios.</span></p>\n</li>\n</ol>\n<p dir=\"ltr\"><span>In terms of the first goal, we worked with two senior living communities where we interviewed both caregivers and residents to understand what activities they would like to see monitored, how that information would be presented, and how the resident?s privacy and well-being could be maintained. Based on these interviews we developed AutoRounds, a prototype interface which allows caregivers to view resident ADL performance, vital signs, and locations, communicate via a notes system with other caregivers, and get notifications when an adverse event (e.g., a fall) occurs. In terms of the second goal, we have developed an algorithm that is able to recognize when individuals take medication in a fully in-the-wild scenario, which is challenging given that it occurs infrequently over the course of a day. We have also developed a generalized algorithm to recognize a handful of ADLs (e.g., brushing teeth, washing hands, drinking, walking) in fully in-the-wild scenarios.</span></p>\n<p>&nbsp;</p><br>\n<p>Added: 02/09/2023<br>Submitted by: Tracy&nbsp;A&nbsp;Hammond</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery1\">\n<div class=\"photoCount\" id=\"photoCount1\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto1\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls1\"></div>\n<div class=\"galSlideshow\" id=\"slideshow1\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation1\">\n<ul class=\"thumbs\" id=\"thumbs1\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1952236/1952236_10698493_1675968556813_resident_summary(1)--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1952236/1952236_10698493_1675968556813_resident_summary(1)--rgov-800width.jpg\" title=\"Resident summary\"><img src=\"/por/images/Reports/POR/2023/1952236/1952236_10698493_1675968556813_resident_summary(1)--rgov-66x44.jpg\" alt=\"Resident summary\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Resident summary</div>\n<div class=\"imageCredit\">Tracy Hammond</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tracy&nbsp;A&nbsp;Hammond</div>\n<div class=\"imageTitle\">Resident summary</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1952236/1952236_10698493_1675968488744_resident_vitals(1)--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1952236/1952236_10698493_1675968488744_resident_vitals(1)--rgov-800width.jpg\" title=\"Resident vitals\"><img src=\"/por/images/Reports/POR/2023/1952236/1952236_10698493_1675968488744_resident_vitals(1)--rgov-66x44.jpg\" alt=\"Resident vitals\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Resident vitals</div>\n<div class=\"imageCredit\">Tracy Hammond</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tracy&nbsp;A&nbsp;Hammond</div>\n<div class=\"imageTitle\">Resident vitals</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1952236/1952236_10698493_1675968612073_map_view(1)--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1952236/1952236_10698493_1675968612073_map_view(1)--rgov-800width.jpg\" title=\"Map of the facility\"><img src=\"/por/images/Reports/POR/2023/1952236/1952236_10698493_1675968612073_map_view(1)--rgov-66x44.jpg\" alt=\"Map of the facility\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Map of the facility</div>\n<div class=\"imageCredit\">Tracy Hammond</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tracy&nbsp;A&nbsp;Hammond</div>\n<div class=\"imageTitle\">Map of the facility</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n As wearable technologies become capable of recognizing our daily activities, there is an increasing opportunity to utilize these devices and algorithms to improve the state of elderly care. To that end this work had two parallel goals:Understand the needs of caregivers and residents in senior living communities and how the recognition of Activities of Daily Living (ADLs) could increase resident independence, reduce the caregiver burden of care, and ultimately improve the quality of care.Develop novel activity recognition algorithms capable of recognizing a wider array of Activities of Daily Living in real-world scenarios.In terms of the first goal, we worked with two senior living communities where we interviewed both caregivers and residents to understand what activities they would like to see monitored, how that information would be presented, and how the resident?s privacy and well-being could be maintained. Based on these interviews we developed AutoRounds, a prototype interface which allows caregivers to view resident ADL performance, vital signs, and locations, communicate via a notes system with other caregivers, and get notifications when an adverse event (e.g., a fall) occurs. In terms of the second goal, we have developed an algorithm that is able to recognize when individuals take medication in a fully in-the-wild scenario, which is challenging given that it occurs infrequently over the course of a day. We have also developed a generalized algorithm to recognize a handful of ADLs (e.g., brushing teeth, washing hands, drinking, walking) in fully in-the-wild scenarios.\n\n \n \n\n\t\t\t\t\tLast Modified: 12/16/2022\n\n\t\t\t\t\tSubmitted by: Tracy A HammondAs wearable technologies become capable of recognizing our daily activities, there is an increasing opportunity to utilize these devices and algorithms to improve the state of elderly care. \nTo that end this work had two parallel goals:\n\n\nUnderstand the needs of caregivers and residents in senior living communities and how the recognition of Activities of Daily Living (ADLs) could increase resident independence, reduce the caregiver burden of care, and ultimately improve the quality of care.\n\n\nDevelop novel activity recognition algorithms capable of recognizing a wider array of Activities of Daily Living in real-world scenarios.\n\n\nIn terms of the first goal, we worked with two senior living communities where we interviewed both caregivers and residents to understand what activities they would like to see monitored, how that information would be presented, and how the resident?s privacy and well-being could be maintained. Based on these interviews we developed AutoRounds, a prototype interface which allows caregivers to view resident ADL performance, vital signs, and locations, communicate via a notes system with other caregivers, and get notifications when an adverse event (e.g., a fall) occurs. In terms of the second goal, we have developed an algorithm that is able to recognize when individuals take medication in a fully in-the-wild scenario, which is challenging given that it occurs infrequently over the course of a day. We have also developed a generalized algorithm to recognize a handful of ADLs (e.g., brushing teeth, washing hands, drinking, walking) in fully in-the-wild scenarios.\n\n \nLast Modified: 02/09/2023\nSubmitted by: Tracy A Hammond"
 }
}