{
 "awd_id": "2003709",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CDS&E: Collaborative Research: HyLoC: Objective-driven Adaptive Hybrid Lossy Compression Framework for Extreme-Scale Scientific Applications",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032927116",
 "po_email": "sghafoor@nsf.gov",
 "po_sign_block_name": "Sheikh Ghafoor",
 "awd_eff_date": "2020-08-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 256761.0,
 "awd_amount": 256761.0,
 "awd_min_amd_letter_date": "2020-07-22",
 "awd_max_amd_letter_date": "2020-07-22",
 "awd_abstract_narration": "Today's extreme-scale scientific simulations and instruments are producing huge amounts of data that cannot be transmitted or stored effectively. Lossy compression, a data compression approach leading to certain data distortion, has been considered as a promising solution, because it can significantly reduce the data size while maintaining high data fidelity. However, the existing lossy compression methods may not always work effectively on all datasets used in specific applications because of their distinct and diverse characteristics. Moreover, the user objectives in compression quality and performance may vary with applications, datasets or circumstances. This project aims to develop a hybrid lossy compression framework to automatically construct the best-fit compression for diverse user objectives in data-intensive scientific research. Educational and engagement activities are provided to develop new curriculum related to scientific data compression and promote research collaborations with national laboratories.\r\n\r\nDesigning an efficient, adaptive, hybrid framework that can always choose the best-fit compression strategy is nontrivial, since existing state-of-the-art lossy compression methods are developed with distinct principles. The project has a three-stage research plan. First, the project decouples the state-of-the-art error-bounded lossy compression approaches into multiple stages and effectively models the working efficiency (e.g., compression ratio, error, speed) of particular approaches in each stage. Second, the project develops a loosely-coupled framework to aggregate the decoupled compression stages together and also explores as many compression pipelines composed of different stages as possible, to optimize the classic compression efficiency, including compression quality and performance. Third, the project optimizes the synthetic data-movement performance regarding the external devices and resources, such as I/O performance. The team evaluates the proposed framework on multiple extreme-scale scientific applications, including cosmological simulations, light source instrument data analytics, quantum circuit simulations, and climate simulations. The project may create technologies that can increase the storage availability and improve the performance for extreme-scale scientific applications, opening opportunities for new discoveries.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sheng",
   "pi_last_name": "Di",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sheng Di",
   "pi_email_addr": "sdi@uchicago.edu",
   "nsf_id": "000796586",
   "pi_start_date": "2020-07-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "5801 South Ellis Avenue",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606373210",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808400",
   "pgm_ele_name": "CDS&E"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "8084",
   "pgm_ref_txt": "CDS&E"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 256761.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>With one-year no-cost-extension, we have completed all the tasks planned in the proposal very well.&nbsp;</p>\n<p><br />This project plans to develop an efficient, adaptive, hybrid lossy compression (HyLoC) framework with optimized external-device related performance in regard of users' diverse objectives. Our work has significantly improved compression quality, speed, and overall data-movement performance related to external environments such as I/O and wide area network (WAN), because of brand-new compression methods and optimized techniques considering the external devices. The key final outcomes are three-fold. (1) We have successfully decoupled the state-of-the-art error-bounded lossy compression approaches into multiple stages and effectively models the working efficiency (e.g., compression ratio, error, speed) for the lossy compressors. We developed a series of compression ratio and quality estimation methods/algorithms such as FXRZ Libpressio-predict. (2) We developed a loosely-coupled framework to aggregate the decoupled compression stages together and also explored different compression pipelines to optimized compression ratio, speed and quality for different devices. For example, we developed a dynamic error-bounded lossy compressor that can adapt to user's diverse constraints such as multi-range-error-bound and ranges of interest. We also developed cuSZp/cuSZp, which can get the compression/decompression throughput up to 300-500 GB/s on GPU A100. We also developed multiple algorithms based on our loosely-coupled framework to optimize compression quality for various scientific applications, including climate application, molecular dynamics simulations, seismic imaging, and so on. (3) We optimized the synthetic data-movement performance regarding the external devices and resources, such as I/O and wide area network (WAN). For example, we developed GlobaZip, which integrates error-bounded lossy compression into Globus system. With GlobaZip, the users can lauch a remote task to transfer one or multiple data files from one Globus endpoint to another one on WAN. GlobaZip can estimate the compression ratio based on the user-specific error bound and compression quality, such as PSNR and performance. GlobaZip also supports a GUI allowing users to visualize the decompressed data and tune the error-bounds interactively.</p>\n<p><br />In addition to research, the PI is committed to educational activities. The research findings have been integrated into the 'compression for scientific datasets' tutorial in the top conference -- SC21-24. The project has involved at least six PhD students, and has contributed to the graduation of two PhD students.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 09/09/2024<br>\nModified by: Sheng&nbsp;Di</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nWith one-year no-cost-extension, we have completed all the tasks planned in the proposal very well.\n\n\n\nThis project plans to develop an efficient, adaptive, hybrid lossy compression (HyLoC) framework with optimized external-device related performance in regard of users' diverse objectives. Our work has significantly improved compression quality, speed, and overall data-movement performance related to external environments such as I/O and wide area network (WAN), because of brand-new compression methods and optimized techniques considering the external devices. The key final outcomes are three-fold. (1) We have successfully decoupled the state-of-the-art error-bounded lossy compression approaches into multiple stages and effectively models the working efficiency (e.g., compression ratio, error, speed) for the lossy compressors. We developed a series of compression ratio and quality estimation methods/algorithms such as FXRZ Libpressio-predict. (2) We developed a loosely-coupled framework to aggregate the decoupled compression stages together and also explored different compression pipelines to optimized compression ratio, speed and quality for different devices. For example, we developed a dynamic error-bounded lossy compressor that can adapt to user's diverse constraints such as multi-range-error-bound and ranges of interest. We also developed cuSZp/cuSZp, which can get the compression/decompression throughput up to 300-500 GB/s on GPU A100. We also developed multiple algorithms based on our loosely-coupled framework to optimize compression quality for various scientific applications, including climate application, molecular dynamics simulations, seismic imaging, and so on. (3) We optimized the synthetic data-movement performance regarding the external devices and resources, such as I/O and wide area network (WAN). For example, we developed GlobaZip, which integrates error-bounded lossy compression into Globus system. With GlobaZip, the users can lauch a remote task to transfer one or multiple data files from one Globus endpoint to another one on WAN. GlobaZip can estimate the compression ratio based on the user-specific error bound and compression quality, such as PSNR and performance. GlobaZip also supports a GUI allowing users to visualize the decompressed data and tune the error-bounds interactively.\n\n\n\nIn addition to research, the PI is committed to educational activities. The research findings have been integrated into the 'compression for scientific datasets' tutorial in the top conference -- SC21-24. The project has involved at least six PhD students, and has contributed to the graduation of two PhD students.\n\n\n\t\t\t\t\tLast Modified: 09/09/2024\n\n\t\t\t\t\tSubmitted by: ShengDi\n"
 }
}