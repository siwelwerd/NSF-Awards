{
 "awd_id": "2015397",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Generative Models for Complex Data: Inference, Sensing, and Repair",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2020-06-15",
 "awd_max_amd_letter_date": "2020-06-15",
 "awd_abstract_narration": "The research in this project lies at the boundary of statistics and machine learning, and is focused on studying new families of statistical models. A generative model is an algorithm that transforms random inputs into synthesized data to mimic data found in a naturally occurring dataset, such as a database of images. The research will explore theory, algorithms, and applications of generative models to gain insight into phenomena observed in practice but poorly understood in terms of mathematical principles. The work will also pursue new applications of generative models in computational neuroscience, at scales from the cellular level to the macro level of human cognition. Anticipated outcomes of the research include development of software that implements new methodology, training of graduate students across traditional disciplines, and the introduction of modern statistics and machine learning to undergraduates through research projects based on this work.\r\n\r\nThe technical objectives of the project include four interrelated aims. First is to investigate the statistical properties of variational programs that are widely used in deep learning, and to develop new approaches to building generative models for novel data types. The second aim is to explore new algorithms to solve inverse problems based on generative models. Third, a new form of robust estimation will be studied where a model is corrupted after it has been constructed on data. Model repair is motivated from the fact that increasingly large statistical models, including neural networks, are being embedded in systems that may be subject to failure. Finally, the project will develop applications of generative modeling and inversion algorithms for modeling brain imaging data, including the use of simultaneous recordings in different modalities.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Lafferty",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "John D Lafferty",
   "pi_email_addr": "john.lafferty@yale.edu",
   "nsf_id": "000092106",
   "pi_start_date": "2020-06-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Yale University",
  "inst_street_address": "150 MUNSON ST",
  "inst_street_address_2": "",
  "inst_city_name": "NEW HAVEN",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "2037854689",
  "inst_zip_code": "065113572",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "CT03",
  "org_lgl_bus_name": "YALE UNIV",
  "org_prnt_uei_num": "FL6GV84CKN57",
  "org_uei_num": "FL6GV84CKN57"
 },
 "perf_inst": {
  "perf_inst_name": "Yale University",
  "perf_str_addr": "24 Hillhouse Avenue",
  "perf_city_name": "New Haven",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "065208290",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "CT03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The research in this project focused on studying new families of generative models, including theory, algorithms, and applications to gain insight into modeling complex data. The project also studied new applications of generative models in computational neuroscience, at scales from the cellular level to the macro level of human cognition. A framework of model repair was introduced, with the goal of recovering a statistical model that has been corrupted after it has been estimated from data. The theory revealed that estimators based on stochastic gradient descent are well suited to model repair, while sparse models are not. Several generative models were developed for neuroscience data, including the visual system of the fly, imaging with multiple modalities such as Calcium and fMRI, and behavioral data. Computational models of the fly visual system were trained to reveal possible principles required to carry out efficient inference tasks. New AI frameworks for generative relational learning were introduced, combining the flexibility and efficiency of symbolic and neural systems, motivated by principles cognitive neuroscience. Abilities for abstraction and creative thinking are central to human intelligence, but largely separate from our ability to acquire semantic and procedural knowledge through sensory tasks, such as image and audio processing. Modern deep learning systems can often capture this latter type of intelligence through efficient function approximation, but have had limited success with relational and abstract reasoning, which requires identifying novel associations from limited data and generalizing to new domains. A new computational framework was proposed to endow transformers, used in large language models, with greater abstract reasoning abilities. Four PhD students received advanced training under this research project.</p><br>\n<p>\n Last Modified: 02/14/2024<br>\nModified by: John&nbsp;D&nbsp;Lafferty</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe research in this project focused on studying new families of generative models, including theory, algorithms, and applications to gain insight into modeling complex data. The project also studied new applications of generative models in computational neuroscience, at scales from the cellular level to the macro level of human cognition. A framework of model repair was introduced, with the goal of recovering a statistical model that has been corrupted after it has been estimated from data. The theory revealed that estimators based on stochastic gradient descent are well suited to model repair, while sparse models are not. Several generative models were developed for neuroscience data, including the visual system of the fly, imaging with multiple modalities such as Calcium and fMRI, and behavioral data. Computational models of the fly visual system were trained to reveal possible principles required to carry out efficient inference tasks. New AI frameworks for generative relational learning were introduced, combining the flexibility and efficiency of symbolic and neural systems, motivated by principles cognitive neuroscience. Abilities for abstraction and creative thinking are central to human intelligence, but largely separate from our ability to acquire semantic and procedural knowledge through sensory tasks, such as image and audio processing. Modern deep learning systems can often capture this latter type of intelligence through efficient function approximation, but have had limited success with relational and abstract reasoning, which requires identifying novel associations from limited data and generalizing to new domains. A new computational framework was proposed to endow transformers, used in large language models, with greater abstract reasoning abilities. Four PhD students received advanced training under this research project.\t\t\t\t\tLast Modified: 02/14/2024\n\n\t\t\t\t\tSubmitted by: JohnDLafferty\n"
 }
}