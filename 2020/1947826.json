{
 "awd_id": "1947826",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: SHF: Efficiency-Aware Robust Implementation of Neural Networks with Algorithm-Hardware Co-design",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2020-04-01",
 "awd_exp_date": "2023-03-31",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2020-01-24",
 "awd_max_amd_letter_date": "2020-01-24",
 "awd_abstract_narration": "With the advent of Internet-of-Things and the necessity to enable intelligence in embedded devices like mobile phones, wearables etc., low-power and secure hardware implementation of neural networks is vital. Despite achieving high performance and unprecedented classification accuracies on a variety of perception tasks, Deep Neural Networks (DNNs) have been shown to be adversarially vulnerable. For example, a DNN can be easily fooled into mis-classifying an input with slight changes of image-pixel intensities. This vulnerability severely limits the deployment and its use in safety-critical real-world tasks such as self-driving cars, malware detection, healthcare monitoring systems etc. This project investigates hardware aware techniques to resolve or resist software vulnerabilities (specifically, adversarial attacks) by exploring the design space of energy-accuracy-robustness trade-off cohesively with algorithm-hardware co-design to create functional intelligent systems. Thus, the project seeks to develop robustness-aware algorithms broadly applicable to the energy-efficient and secure implementation of DNN engines on both current CMOS accelerator platforms and emerging memory technologies. Furthermore, the research will support the interdisciplinary development of a diverse cohort of PhD and undergraduate students, and the development of a graduate-level course at Yale University on neural network architectures and learning algorithms tied with robustness from circuit and system design perspective.\r\n\r\nThe technical aims of this project are divided into two thrusts. The first thrust develops robustness centred algorithms in DNNs where techniques such as quantization, pruning among others are used to improve the adversarial resilience of models while yielding energy-efficiency benefits. This part also identifies a new form of noise stability for DNNs, i.e., the sensitivity of each layer\u2019s computation to adversarial noise. This allows for a principled way of applying layer-specific algorithmic modifications that incurs adversarial robustness as well as energy-efficiency with minimal loss in accuracy. The second thrust benchmarks and implements the proposed robust computing models on emerging technology-based memristor crossbar-array platforms to investigate the hardware-level benefits (while comparing with standard CMOS accelerator baselines). In particular, design issues and complexities for implementing variable precision, stochastic and combined stochastic-deterministic neuronal activity will be investigated. The two thrusts offer a fundamental co-design infrastructure where algorithmic innovations will be used to optimize robust and efficient hardware implementations for neural networks.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Priyadarshini",
   "pi_last_name": "Panda",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Priyadarshini Panda",
   "pi_email_addr": "priya.panda@yale.edu",
   "nsf_id": "000807705",
   "pi_start_date": "2020-01-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Yale University",
  "inst_street_address": "150 MUNSON ST",
  "inst_street_address_2": "",
  "inst_city_name": "NEW HAVEN",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "2037854689",
  "inst_zip_code": "065113572",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "CT03",
  "org_lgl_bus_name": "YALE UNIV",
  "org_prnt_uei_num": "FL6GV84CKN57",
  "org_uei_num": "FL6GV84CKN57"
 },
 "perf_inst": {
  "perf_inst_name": "Yale University",
  "perf_str_addr": "10 Hillhouse Avenue",
  "perf_city_name": "New Haven",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "065208284",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "CT03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we developed robustness centred algorithms in Deep Neural Networks where techniques such as quantization, pruning among others are used to improve the adversarial resilience of models while yielding energy-efficiency benefits. We also implemented the proposed robust computing models on emerging technology-based memristive crossbar array (MCA) platforms to investigate the hardware-level benefits (while comparing with standard CMOS accelerator baselines).&nbsp;</p>\n<p>The outcome from the above thrusts have been integrated into a graduate and senior undergraduate level course for Electrical Engineering- EENG 439 Neural Networks and Learning Systems - taught by PI Panda at Yale University.</p>\n<p>Three undergraduate (two female) and one graduate PhD student were involved in the completion of this project. All three undergraduates went on to publish first-authored papers [R1, R2, R3].</p>\n<p>All code and platforms developed in this project have been made available for public use on github.</p>\n<p>[R1] <span>Sterneck, Rachel, Abhishek Moitra, and Priyadarshini Panda. \"Noise sensitivity-based energy efficient and robust adversary detection in neural networks.\"&nbsp;</span><em>IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</em><span>&nbsp;41, no. 5 (2021): 1423-1435.</span></p>\n<p>[R2]&nbsp;Foldy-Porto T, Venkatesha Y, Panda P. Activation Density driven Energy-Efficient Pruning in Training. arXiv preprint arXiv:2002.02949. 2020 Feb 7 (<a href=\"https://www.micc.unifi.it/icpr2020/index.php/papers-and-authors/\">ICPR 2020</a>).</p>\n<p>[R3]&nbsp;Vasquez K, Venkatesha Y, Bhattacharjee A, Moitra A, Panda P. Activation Density based Mixed-Precision Quantization for Energy Efficient Neural Networks. arXiv preprint arXiv:2101.04354. 2021 Jan. (<a href=\"https://www.date-conference.com/accepted\">DATE 2021</a>)</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/30/2023<br>\n\t\t\t\t\tModified by: Priyadarshini&nbsp;Panda</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this project, we developed robustness centred algorithms in Deep Neural Networks where techniques such as quantization, pruning among others are used to improve the adversarial resilience of models while yielding energy-efficiency benefits. We also implemented the proposed robust computing models on emerging technology-based memristive crossbar array (MCA) platforms to investigate the hardware-level benefits (while comparing with standard CMOS accelerator baselines). \n\nThe outcome from the above thrusts have been integrated into a graduate and senior undergraduate level course for Electrical Engineering- EENG 439 Neural Networks and Learning Systems - taught by PI Panda at Yale University.\n\nThree undergraduate (two female) and one graduate PhD student were involved in the completion of this project. All three undergraduates went on to publish first-authored papers [R1, R2, R3].\n\nAll code and platforms developed in this project have been made available for public use on github.\n\n[R1] Sterneck, Rachel, Abhishek Moitra, and Priyadarshini Panda. \"Noise sensitivity-based energy efficient and robust adversary detection in neural networks.\" IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 41, no. 5 (2021): 1423-1435.\n\n[R2] Foldy-Porto T, Venkatesha Y, Panda P. Activation Density driven Energy-Efficient Pruning in Training. arXiv preprint arXiv:2002.02949. 2020 Feb 7 (ICPR 2020).\n\n[R3] Vasquez K, Venkatesha Y, Bhattacharjee A, Moitra A, Panda P. Activation Density based Mixed-Precision Quantization for Energy Efficient Neural Networks. arXiv preprint arXiv:2101.04354. 2021 Jan. (DATE 2021)\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 04/30/2023\n\n\t\t\t\t\tSubmitted by: Priyadarshini Panda"
 }
}