{
 "awd_id": "2040521",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NSF Convergence Accelerator-Track D: Application of Sequential Inductive Transfer Learning for Experimental Metadata Normalization to Enable Rapid Integrative Analysis",
 "cfda_num": "47.084",
 "org_code": "15020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Mike Pozmantier",
 "awd_eff_date": "2020-09-15",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 999951.0,
 "awd_amount": 999951.0,
 "awd_min_amd_letter_date": "2020-09-08",
 "awd_max_amd_letter_date": "2020-10-14",
 "awd_abstract_narration": "The NSF Convergence Accelerator supports use-inspired, team-based, multidisciplinary efforts that address challenges of national importance and will produce deliverables of value to society in the near future. \r\n\r\nThis project, NSF Convergence Accelerator-Track D: Application of sequential inductive transfer learning for experimental metadata normalization to enable rapid integrative analysis, develops tools to support integrative analyses and meta analyses across multiple, distinct research databases. With the explosion in data-driven research, researchers even in a single domain of study are confronted with many different databases that use different terminologies and measurement schemes. Thus, data become siloed\u2014collected via different processes and described by different metadata schemes with no central index of databases, metadata, or variables, making it difficult for a researcher to identify data of the appropriate type for use in integrative analyses or meta analyses. In Phase I of this effort, a multidisciplinary team of researchers and experts in statistics, epidemiology, data harmonization, machine leaning, ethics, databases, imaging, and software engineering will develop tools to link metadata across four biomedical database, as a proof of concept. The linked information will be available via the MetaMatchMaker (3M) portal to be developed by the project.\r\n\r\nWhile traditional neural network approaches could be used to link experimental metadata, that approach can be time consuming, requiring the construction of large training datasets. This project employs an alternative approach based on Pretrained Learning Models (PLMs), combining methods used in Natural Language Processing (NLP) and transfer learning, to allow for the application of data-driven models built in one domain to be applied to another, without the time and expense of developing large training datasets. In Phase I of the effort, a PLM will be developed from a large existing manually trained dataset of PhenX\u2013dbGAP metadata linkage, which will then be used to link metadata from four diverse biomedical databases. The results from Phase I would enable rapid and broader identification of experimental data in less time and with fewer resources devoted to data normalization; second, the PLM approach is expected to provide significant savings in linking experimental metadata across databases by eliminating, or greatly reducing, the need for development of training data. Phase II of this effort will expand the number and variety of linked databases, and also make 3M compliant with developing federated data access procedures for biomedical data, such as Global Alliance for Genomics and Health (GA4GH)\u2019s Authentication and Authorization Infrastructure. The metrics for success of this approach include increased speed and reduced cost of conducting integrative analyses; increased reuse of linked data. While, the proof of concept in Phase I is based on the linkage of biomedical data, if successful, this approach would be applicable to databases frp, many other domains including, for example, national security, weather, environmental research, geosciences, astronomy, forensic analysis, and law enforcement.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "ITE",
 "org_div_long_name": "Innovation and Technology Ecosystems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Grier",
   "pi_last_name": "Page",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Grier Page",
   "pi_email_addr": "gpage@rti.org",
   "nsf_id": "000276286",
   "pi_start_date": "2020-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Xiangqin",
   "pi_last_name": "Cui",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiangqin Cui",
   "pi_email_addr": "xiangqin.cui@emory.edu",
   "nsf_id": "000389707",
   "pi_start_date": "2020-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "YUN",
   "pi_last_name": "WANG",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "YUN WANG",
   "pi_email_addr": "yun.wang2@emory.edu",
   "nsf_id": "000827101",
   "pi_start_date": "2020-09-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Research Triangle Institute",
  "inst_street_address": "3040 CORNWALLIS RD",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195416000",
  "inst_zip_code": "277090155",
  "inst_country_name": "United States",
  "cong_dist_code": null,
  "st_cong_dist_code": "NC",
  "org_lgl_bus_name": "RESEARCH TRIANGLE INSTITUTE",
  "org_prnt_uei_num": "JJHCMK4NT5N3",
  "org_uei_num": "JJHCMK4NT5N3"
 },
 "perf_inst": {
  "perf_inst_name": "Research Triangle Institute",
  "perf_str_addr": "3040 East Cornwallis Road",
  "perf_city_name": "Research Triangle Park",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277092194",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131Y00",
   "pgm_ele_name": "Convergence Accelerator Resrch"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 999951.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We are fundamentally handicapped in the way we do science. We spend a huge amount of time and budget assembling datasets before any insights can occur. This goal of this project was in part to address this barrier by reducing this time, effort, and money needed to identify, assemble, and harmonize data for scientific studies. Secondarily the goal was to train the study staff in user centric design and development principles in order to develop tools that better meet the needs of the scientific community.</p>\n<p>The result of this study is a clear example of the utility of user centric design principles. As proposed the study was proposed to use general Artificial Intelligence methods to make it easier to find study data across the many public data repositories. However, during the user central design training, the investigators conducted two fundamental actions, which changed the course of the study. First was a deeper dive into the rapidly developing artificial intelligence methods causing the central AI methods being to move from conventional sematic linking methods to using large language models often called generative AI methods, which allowed far more robust training of the linking functions, which improved the performance of the model. Which resulted in the tools increasing the savings in labor and budget for data discovery and the second ideas that was identified from the user centric design. One aspect of user centric design is detailed interviews with potential user to identify what they think is needed from the tools or processes being studies. During these interviews we identified that the data harmonization issues as much harder and more important than data discovery. The is best exemplified through a quote from an interview, &ldquo;I wish I had a magic data harmonization button&rsquo;. Due to our knowledge of AI we were able to realize that the same AI model that could be used for data discovery could be turned to the question of data harmonization. This the team ended up developing two research tools: MetaMatchMaker: Find (available at <a href=\"http://www.metamatchmaker.com/\">www.metamatchmaker.com</a>) which enables easy data discovery across multiple public data repositories with a robust AI based search function. The second tool MetaMatchMaker:Link enables the metadata, usually study variables, across two of more data sets to be linked across studies with high accuracy and low effort. Thus, this study was able to utilize the training of the convergence accelerator training to enable the team to develop several powerful tools that will reduce the time and effort to conduct scientific studies.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/19/2023<br>\n\t\t\t\t\tModified by: Grier&nbsp;Page</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWe are fundamentally handicapped in the way we do science. We spend a huge amount of time and budget assembling datasets before any insights can occur. This goal of this project was in part to address this barrier by reducing this time, effort, and money needed to identify, assemble, and harmonize data for scientific studies. Secondarily the goal was to train the study staff in user centric design and development principles in order to develop tools that better meet the needs of the scientific community.\n\nThe result of this study is a clear example of the utility of user centric design principles. As proposed the study was proposed to use general Artificial Intelligence methods to make it easier to find study data across the many public data repositories. However, during the user central design training, the investigators conducted two fundamental actions, which changed the course of the study. First was a deeper dive into the rapidly developing artificial intelligence methods causing the central AI methods being to move from conventional sematic linking methods to using large language models often called generative AI methods, which allowed far more robust training of the linking functions, which improved the performance of the model. Which resulted in the tools increasing the savings in labor and budget for data discovery and the second ideas that was identified from the user centric design. One aspect of user centric design is detailed interviews with potential user to identify what they think is needed from the tools or processes being studies. During these interviews we identified that the data harmonization issues as much harder and more important than data discovery. The is best exemplified through a quote from an interview, \"I wish I had a magic data harmonization button\u2019. Due to our knowledge of AI we were able to realize that the same AI model that could be used for data discovery could be turned to the question of data harmonization. This the team ended up developing two research tools: MetaMatchMaker: Find (available at www.metamatchmaker.com) which enables easy data discovery across multiple public data repositories with a robust AI based search function. The second tool MetaMatchMaker:Link enables the metadata, usually study variables, across two of more data sets to be linked across studies with high accuracy and low effort. Thus, this study was able to utilize the training of the convergence accelerator training to enable the team to develop several powerful tools that will reduce the time and effort to conduct scientific studies.\n\n \n\n\t\t\t\t\tLast Modified: 06/19/2023\n\n\t\t\t\t\tSubmitted by: Grier Page"
 }
}