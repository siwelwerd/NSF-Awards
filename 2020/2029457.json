{
 "awd_id": "2029457",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RAPID: Collecting Reliable COVID-19 Datasets in Crisis Conditions",
 "cfda_num": "47.084",
 "org_code": "15020000",
 "po_phone": "7032924596",
 "po_email": "cbaru@nsf.gov",
 "po_sign_block_name": "Chaitanya Baru",
 "awd_eff_date": "2020-05-01",
 "awd_exp_date": "2020-10-31",
 "tot_intn_awd_amt": 69998.0,
 "awd_amount": 69998.0,
 "awd_min_amd_letter_date": "2020-05-01",
 "awd_max_amd_letter_date": "2020-05-01",
 "awd_abstract_narration": "This RAPID project enables approaches to mitigate the negative impacts of COVID-19 on public health, society, and the economy by deploying technologies to enable collecting reliable COVID-19-related data sets under crisis conditions. \r\n\r\nIn the midst of a crisis, such as the COVID-19 pandemic, generators of critical new data, such as hospitals and critical health organizations, lack the time and resources to make this important data readily available for use by others. One cannot expect the already overburdened primary data providers to do the extra work needed to make the data more accessible for others to use. Even those who already publish data on their websites often do not have the time to edit/modify the data, for example to apply newly introduced tags, such as Schema.org\u2019s new tags related to coronavirus. Yet, these data are critical in a crisis in order to inform the public; improve emergency response; and aid the scientific community in its efforts to find solutions. Currently, the teams that are engaged in dataset collection are employing slow, tedious, and painstaking manual techniques.  The interactive dataset collection tools to be developed by this project will provide an alternative approach, empowering a community of volunteers to help with data collection efforts. The data collection tools developed can be used with only an internet connection, a web browser, and brief training, thereby putting the effort well within reach of a large population of potential volunteers. \r\n\r\nExisting automatic data extractors assume that (i) webpages in a single website are structured uniformly, because they were produced from the same template and (ii) relevant webpages originate from a single website.  As a result, much of the prior work in the area of web data extraction and ingestion focuses on \u2018syntactic\u2019 extraction.  Currently, dedicated data collection teams are collecting data with a combination of expertise and time-consuming and painstaking manual effort.  Other teams are hiring call centers to call hospitals in each state to collect their capacities. Such high-cost, high-effort approaches do not scale well to all the datasets that one would like to be able to access and analyze. Many COVID-19-related datasets are scattered over thousands of websites with similar information but no structural similarities--e.g., each hospital\u2019s website may look different but may contain very similar and related data. The technical challenge that this project will tackle will be to build a \u2018semantic\u2019 data extractor that locates the information of interest despite divergent website structures. The software tools that will be created for data ingestion can be used by the many individuals who are keen to contribute their time and effort to help combat COVID-19, without compromising their physical distancing efforts.\r\n\r\nThis RAPID award is made by the Convergence Accelerator program in the Office of Integrative Activities and is associated with the Convergence Accelerator Track A: Open Knowledge Network.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "ITE",
 "org_div_long_name": "Innovation and Technology Ecosystems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rastislav",
   "pi_last_name": "Bodik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rastislav Bodik",
   "pi_email_addr": "bodik@uw.edu",
   "nsf_id": "000207383",
   "pi_start_date": "2020-05-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "4333 Brooklyn Ave NE",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981950001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "095Y00",
   "pgm_ele_name": "CA-HDR: Convergence Accelerato"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "096Z",
   "pgm_ref_txt": "COVID-19 Research"
  },
  {
   "pgm_ref_code": "7914",
   "pgm_ref_txt": "RAPID"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 69998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-298cacf9-7fff-7884-789b-ae7ff4f6a54c\">\n<p dir=\"ltr\"><span>In the midst of a crisis, important sources of COVID-19 data, such as hospitals and critical health organizations, lack the time and resources to make their data readily available to other users.&nbsp; Even when they manage to present the data on their websites, they often cannot take the time to apply the appropriate schema.org markup. As a result, web datasets lack the annotation with the valuable schema.org&rsquo;s Coronavirus schema, which prevents search engines and other webpage-consuming products from taking advantage of the data. Current approaches for collecting these datasets are resource expensive: Dedicated research teams like the Johns Hopkins COVID-19 data team collect critical datasets with a combination of expertise and time-consuming, painful manual effort.&nbsp; Other teams hire call centers to call hospitals in each state to collect their capacities.&nbsp; This high-cost, high-effort approach does not scale to all the datasets we need.&nbsp;&nbsp;</span></p>\n<br />\n<p dir=\"ltr\"><span>This work is based on the observation that many individuals are keen to contribute to combating COVID-19 and are happy to devote their time in ways that do not compromise their social distancing efforts.&nbsp; We developed an interactive dataset collection tool that empowers volunteers to do the dataset creation work that we cannot expect from the already overburdened data providers.&nbsp; Since this work can be done with only an internet connection, a browser, and a brief training, we expect this is well within reach for a large population of potential volunteers.</span></p>\n<br />\n<p dir=\"ltr\"><span>We focused on meeting this need by offering lightweight web data ingestion tooling.&nbsp; In particular, this work developed a prototype tool that lets low-programming users like volunteers use a standard browser to indicate data of interest on a webpage.&nbsp; The ingestion tool offers a visual interface that users can manipulate to transform their extracted data into an OKN-compliant set of triples.&nbsp; In keeping with the spirit of knowledge graph flexibility, users can include different properties for a given entity based on the different data available across websites.&nbsp; In follow-on work, later versions of this technique are being developed in a C-Accel proposal led by Mike Cafarella on the Knowledge Network Programming System (KNPS).&nbsp; The next generation of our RAPID prototype is now being integrated into the KNPS. The first applications of the KNPS prototype are in the areas of COVID-19 research and Economics.&nbsp; The work on integrating lightweight ingestion tooling into KNPS is ongoing.</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/10/2021<br>\n\t\t\t\t\tModified by: Rastislav&nbsp;Bodik</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nIn the midst of a crisis, important sources of COVID-19 data, such as hospitals and critical health organizations, lack the time and resources to make their data readily available to other users.  Even when they manage to present the data on their websites, they often cannot take the time to apply the appropriate schema.org markup. As a result, web datasets lack the annotation with the valuable schema.org\u2019s Coronavirus schema, which prevents search engines and other webpage-consuming products from taking advantage of the data. Current approaches for collecting these datasets are resource expensive: Dedicated research teams like the Johns Hopkins COVID-19 data team collect critical datasets with a combination of expertise and time-consuming, painful manual effort.  Other teams hire call centers to call hospitals in each state to collect their capacities.  This high-cost, high-effort approach does not scale to all the datasets we need.  \n\n\nThis work is based on the observation that many individuals are keen to contribute to combating COVID-19 and are happy to devote their time in ways that do not compromise their social distancing efforts.  We developed an interactive dataset collection tool that empowers volunteers to do the dataset creation work that we cannot expect from the already overburdened data providers.  Since this work can be done with only an internet connection, a browser, and a brief training, we expect this is well within reach for a large population of potential volunteers.\n\n\nWe focused on meeting this need by offering lightweight web data ingestion tooling.  In particular, this work developed a prototype tool that lets low-programming users like volunteers use a standard browser to indicate data of interest on a webpage.  The ingestion tool offers a visual interface that users can manipulate to transform their extracted data into an OKN-compliant set of triples.  In keeping with the spirit of knowledge graph flexibility, users can include different properties for a given entity based on the different data available across websites.  In follow-on work, later versions of this technique are being developed in a C-Accel proposal led by Mike Cafarella on the Knowledge Network Programming System (KNPS).  The next generation of our RAPID prototype is now being integrated into the KNPS. The first applications of the KNPS prototype are in the areas of COVID-19 research and Economics.  The work on integrating lightweight ingestion tooling into KNPS is ongoing.\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 05/10/2021\n\n\t\t\t\t\tSubmitted by: Rastislav Bodik"
 }
}