{
 "awd_id": "2041960",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: SaTC-EDU: Teaching Security in Undergraduate Artificial Intelligence Courses Using Transparency and Contextualization",
 "cfda_num": "47.076",
 "org_code": "11010000",
 "po_phone": "7032928182",
 "po_email": "asiraj@nsf.gov",
 "po_sign_block_name": "Ambareen Siraj",
 "awd_eff_date": "2020-09-01",
 "awd_exp_date": "2023-12-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 316000.0,
 "awd_min_amd_letter_date": "2020-07-29",
 "awd_max_amd_letter_date": "2021-05-20",
 "awd_abstract_narration": "This project will explore how to teach undergraduate computer science students about security in systems that use artificial intelligence (AI). This is important for educating a workforce that is knowledgeable about robust and trustworthy AI. The aim is to design an AI curriculum that will foster a security mindset for identifying vulnerabilities that could cause harm, whether through attacks by a malicious actor, or through perpetuating or amplifying social biases. The educational approach will focus on transparency and contextualization. Transparency involves making the inner workings of a system accessible to students, so they can understand which aspects of the system\u2019s construction lead to its vulnerabilities. Contextualization involves situating AI techniques in real-world environments to understand their specific security implications. Contextualization is fundamental for teaching conventional security topics. For instance, accessing personal location data can serve a legitimate purpose in Google Maps, but is typically suspicious behavior in a game. The same piece of code may be used in each case, but its legitimacy is determined by its broader context. The team will conduct research on, and develop instructional materials and assessment tools for, integrating transparency and contextualization into the undergraduate AI curriculum. Since security in AI is a new area within computer science education research, the main goal is to develop initial designs for instruction and assessment that integrate transparency and contextualization at a level appropriate for undergraduates.\r\n \r\nThe goal is to develop proof-of-concept instructional materials and techniques, and assessments for security concepts and skills in undergraduate AI courses. Instruction will be designed for four kinds of learning objectives. Students should: (1) know that AI systems can cause harms and are not immune to attacks; (2) be able to explain sources of vulnerabilities; (3) be able to identify vulnerabilities in a specific system, which could include attacking it; and (4) be able to defend an AI system by modifying it to mitigate threats. The team will identify AI topics in existing curricula that have security implications. The team will create tasks that illustrate the concrete security issues and conduct cognitive task analyses with experts in AI and security to see how they approach those problems. This process will yield the initial learning goals. The team will conduct an assessment survey on those goals with students who have taken the undergraduate AI course, to establish a baseline level of knowledge and elicit potential misconceptions. Based on the foundation that students have and the learning goals, the team will design initial instruction, iterating on the design through one-on-one think-alouds and small-group tutoring sessions with student participants. The team will test the instruction in a controlled experiment, comparing the AI plus security materials to AI-only materials, using pre- and post-tests to measure learning. Finally, a study using the designed instruction in an undergraduate course will illustrate how it works in a typical setting.  \r\n\r\nThis project is supported by a special initiative of the Secure and Trustworthy Cyberspace (SaTC) program to foster new, previously unexplored, collaborations between the fields of cybersecurity, artificial intelligence, and education. The SaTC program aligns with the Federal Cybersecurity Research and Development Strategic Plan and the National Privacy Research Strategy to protect and preserve the growing social and economic benefits of cyber systems while ensuring security and privacy.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DGE",
 "org_div_long_name": "Division Of Graduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eliane",
   "pi_last_name": "Wiese",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Eliane S Wiese",
   "pi_email_addr": "eliane.wiese@utah.edu",
   "nsf_id": "000782420",
   "pi_start_date": "2020-07-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Suresh",
   "pi_last_name": "Venkatasubramanian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Suresh Venkatasubramanian",
   "pi_email_addr": "suresh_venkatasubramanian@brown.edu",
   "nsf_id": "000074075",
   "pi_start_date": "2020-07-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mu",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mu Zhang",
   "pi_email_addr": "muzhang@cs.utah.edu",
   "nsf_id": "000814070",
   "pi_start_date": "2020-07-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "50 CENTRAL CAMPUS DR",
  "perf_city_name": "SALT LAKE CITY",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841120090",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "093Z",
   "pgm_ref_txt": "AI Education/Workforce Develop"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0421",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002122DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0420",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002021DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 300000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Technology doesn't operate in a vacuum. Considering how the context of use should affect a technical implementation is part of professional ethics, and is a duty of computing professionals. Yet, computing concepts are often practiced with abstract, decontextualized assignments. This project set out to explore how to teach students to consider context while also deepening the rigor of the technical learning. Through creating an assignment for an undergraduate course on Artificial Intelligence, we found that the human concerns arising from the problem context helped us identify technical issues that students needed to understand. Further, using the assignment in the course helped the instructor identify gaps in students' technical knowledge that previous assignments hadn't. Additionally, while the vast majority of students tried to address the human needs in the problem situation, many lacked the technical skills to correctly evaluate if their proposed solution met its goals, emphasizing the importance of technical skills for verifying the appropriateness of a solution.</p>\n<p>The process of creating this assignment was not simple. A key outcome from the project was identifying a set of specific instructional design challenges in creating assignments where human concerns are integrated with technical ones. After identifying these challenges, we created an instructional design process to mitigate them, and tested the process on ourselves by using it to create instruction and assessment for a different computing topic. The new design process was helpful for identifying technical learning goals that are important when considering the context of use, but are likely to be overlooked when only considering abstract problems.</p>\n<p>To examine if attention to the broader context distracts students from learning the technical material, we conducted a randomized experiment that compared two forms of instruction: technical-only (with numerical, abstract examples and problems), and integrated (with the technical problems situated in human contexts). We did not find differences in learning between the two forms of instruction, indicating that considerations of human issues did not distract from technical learning. This finding lays the groundwork for future studies to examine how much an instructor can incorporate human concerns before there is a tradeoff with technical learning.</p>\n<p>This project also supported a literature review of all the research pertaining to teaching ethics in undergraduate computing that has been published by the Association of Computing Machinery (100 papers). A key finding in the review is that computing education researchers have conceptualized \"ethics\" in many different ways. Recommendations based on this finding are that researchers make explicit their conceptualization of ethics, explore partnerships with ethics experts, examine which strategies are best suited to teaching different conceptions of ethics, develop robust assessments, and consider how recommendations and challenges for incorporating ethics into computing curricula relate to different conceptualizations of ethics. The literature review further demonstrated the need for instructional design processes for ethics instruction and for comparison studies to examine possible tradeoffs between ethics-integrated and technical-only instruction.</p>\n<p>This project included many broader impacts: over 100 undergraduate students per year in an Artificial Intelligence course engaged with human concerns within a technical assignment. Over 80 undergraduate students learned about k-means and practiced applying human concerns to its implementation (through participating in the randomized experiment). Four undergraduate students gained research experience working on the project (one wrote an undergraduate thesis on it). This project also supported one Ph.D. student, including professional development from presenting this work at conferences. Finally, this project deepened engagement with ethics and human concerns among the computing faculty at the University of Utah.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 04/10/2024<br>\nModified by: Eliane&nbsp;S&nbsp;Wiese</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nTechnology doesn't operate in a vacuum. Considering how the context of use should affect a technical implementation is part of professional ethics, and is a duty of computing professionals. Yet, computing concepts are often practiced with abstract, decontextualized assignments. This project set out to explore how to teach students to consider context while also deepening the rigor of the technical learning. Through creating an assignment for an undergraduate course on Artificial Intelligence, we found that the human concerns arising from the problem context helped us identify technical issues that students needed to understand. Further, using the assignment in the course helped the instructor identify gaps in students' technical knowledge that previous assignments hadn't. Additionally, while the vast majority of students tried to address the human needs in the problem situation, many lacked the technical skills to correctly evaluate if their proposed solution met its goals, emphasizing the importance of technical skills for verifying the appropriateness of a solution.\n\n\nThe process of creating this assignment was not simple. A key outcome from the project was identifying a set of specific instructional design challenges in creating assignments where human concerns are integrated with technical ones. After identifying these challenges, we created an instructional design process to mitigate them, and tested the process on ourselves by using it to create instruction and assessment for a different computing topic. The new design process was helpful for identifying technical learning goals that are important when considering the context of use, but are likely to be overlooked when only considering abstract problems.\n\n\nTo examine if attention to the broader context distracts students from learning the technical material, we conducted a randomized experiment that compared two forms of instruction: technical-only (with numerical, abstract examples and problems), and integrated (with the technical problems situated in human contexts). We did not find differences in learning between the two forms of instruction, indicating that considerations of human issues did not distract from technical learning. This finding lays the groundwork for future studies to examine how much an instructor can incorporate human concerns before there is a tradeoff with technical learning.\n\n\nThis project also supported a literature review of all the research pertaining to teaching ethics in undergraduate computing that has been published by the Association of Computing Machinery (100 papers). A key finding in the review is that computing education researchers have conceptualized \"ethics\" in many different ways. Recommendations based on this finding are that researchers make explicit their conceptualization of ethics, explore partnerships with ethics experts, examine which strategies are best suited to teaching different conceptions of ethics, develop robust assessments, and consider how recommendations and challenges for incorporating ethics into computing curricula relate to different conceptualizations of ethics. The literature review further demonstrated the need for instructional design processes for ethics instruction and for comparison studies to examine possible tradeoffs between ethics-integrated and technical-only instruction.\n\n\nThis project included many broader impacts: over 100 undergraduate students per year in an Artificial Intelligence course engaged with human concerns within a technical assignment. Over 80 undergraduate students learned about k-means and practiced applying human concerns to its implementation (through participating in the randomized experiment). Four undergraduate students gained research experience working on the project (one wrote an undergraduate thesis on it). This project also supported one Ph.D. student, including professional development from presenting this work at conferences. Finally, this project deepened engagement with ethics and human concerns among the computing faculty at the University of Utah.\n\n\n\t\t\t\t\tLast Modified: 04/10/2024\n\n\t\t\t\t\tSubmitted by: ElianeSWiese\n"
 }
}