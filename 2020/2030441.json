{
 "awd_id": "2030441",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Cyberlearning with Co-Robotic Teachable Agents",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927593",
 "po_email": "wuhe@nsf.gov",
 "po_sign_block_name": "Wu He",
 "awd_eff_date": "2019-08-19",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 299851.0,
 "awd_amount": 299851.0,
 "awd_min_amd_letter_date": "2020-05-20",
 "awd_max_amd_letter_date": "2023-04-18",
 "awd_abstract_narration": "Cyberlearning technologies that incorporate robust personalized support and motivational engagement with co-robotic teachable agents present compelling high risk-high payoff opportunities for advancement and broad dissemination of collaborative-robotics STEM education. The project will create robotic teachable agent technologies that provide personalized social, affective, and cognitive support to improve students' STEM learning and motivation. The project will engage at least 10 teachers and 250 middle school students including many underrepresented minority middle school students in the study of collaborative robotics and STEM cyberlearning. The researchers will involve students and teachers in the design and integration of ChalkTalk (a Mixed Reality gesture-based storytelling and simulation tool-kit) with Robotic-Teachable Agents for middle school Geometry (R-TAG) to create an open-source tool-kit for formal and informal STEM learning. The researchers will conduct empirical studies to develop rich models of student cognitive and social interactions, and improve understanding of how to design personalized cognitive, social, and affective support using physical and virtual teachable robotic agents. The project will create a low-cost opportunity for students and teachers to engage in collaborative robotics and STEM cyberlearning. The project will contribute to development and testing of education strategies for broadening participation of students from groups underrepresented in education pathways to careers in robotics. \r\n\r\nThis research will advance the state-of-the-art of co-robotic cyberlearning, engaging hundreds of underrepresented minority middle school students in personalized Ubiquitous Cyberlearning with Collaborative Robotic Experiences (UCCRE). The project will (1) investigate how UCCRE can develop perceptual and cognitive support through collaborative embodied personalized interaction that generates exploratory insight, adaptive feedback, and self-explanation - going beyond typical tutoring support (offering hints, instructional explanations); (2) investigate how UCCRE can develop social support, through embodied personalized interaction with robotic teachable agents that engage and motivate students and (3) evaluate UCCRE through a series of pilot studies using design-based research methods, affective and physiological measures, and Natural Language Processing (NLP) tools. The researchers will use these methods, measures, and tools to sense and adapt to learners' affective states in ways that promote learning and creativity. Students and teachers will iteratively advance the capacity of UCCRE to provide personalized adaptive cognitive and social support, and facilitate collaborative embodied interactions between robotic teachable agents, students and teachers, within formal classroom and informal after-school settings. The findings on participatory design of ubiquitous co-robotics will likely generalize across domains and improve students' interest and motivation in learning robotics.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Winslow",
   "pi_last_name": "Burleson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Winslow Burleson",
   "pi_email_addr": "win@arizona.edu",
   "nsf_id": "000249639",
   "pi_start_date": "2020-05-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Arizona",
  "inst_street_address": "845 N PARK AVE RM 538",
  "inst_street_address_2": "",
  "inst_city_name": "TUCSON",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "5206266000",
  "inst_zip_code": "85721",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "AZ07",
  "org_lgl_bus_name": "UNIVERSITY OF ARIZONA",
  "org_prnt_uei_num": "",
  "org_uei_num": "ED44Y3W6P7B9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Arizona",
  "perf_str_addr": "",
  "perf_city_name": "TUCSON",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "857194824",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "AZ07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  },
  {
   "pgm_ele_code": "722700",
   "pgm_ele_name": "ITEST-Inov Tech Exp Stu & Teac"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "13XX",
   "app_name": "H-1B FUND, EHR, NSF",
   "app_symb_id": "045176",
   "fund_code": "1300XXXXDB",
   "fund_name": "H-1B FUND, EDU, NSF",
   "fund_symb_id": "045176"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 299851.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-a0e55d2b-7fff-5935-a8da-1e1f2c22b6d1\">\n<p dir=\"ltr\"><span>This project has advanced the state-of-the-art of co-robotic cyberlearning, engaging middle school students in Ubiquitous Cyberlearning with Collaborative Robotic Experiences (UCCRE). We integrated a Mixed Reality (MR) gesture-based storytelling and simulation tool-kit, ChalkTalk with the R-TAG (Robotic-Teachable Agents for middle school Geometry) cyberlearning research platform.&nbsp; These technologies are designed to provide personalized adaptive cognitive and social support, and facilitate collaborative embodied interactions between robotic teachable agents, students and teachers, within formal classroom and informal after-school settings.&nbsp;</span></p>\n<p dir=\"ltr\"><span>To combine these technologies we used a module called&nbsp; &ldquo;corelink&rdquo; that incorporates and expands interactive authoring and AR/VR capabilities that can be experienced by students in real-time. Corelink has also enabled us to integrate University of Arizona Sensor Lab multimodal sensors into the suite of technologies, thereby expanding the affective and contextual sensing capabilities of the system.&nbsp; We have conducted studies on the feasibility of using these sensors and hardware in conjunction with the interactive robot.</span></p>\n<p dir=\"ltr\"><span>Collectively these integrated systems provide the foundational infrastructure to integrate signals and experiences across locations, with multiple users, and technologies. We have successfully implemented and tested interactive collaborative features across several modalities, with low latency, between NYU and UA, as part of the expansion of the NSF MRI Holodeck Project.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Corelink handles sending, receiving, recording, and replaying of data throughout the collocated and distributed holodeck node servers and constituent technologies, to provide seamless cross-modality integration that drive real-time interactive Mixed Reality (MR) collaborative experiences. These studies and infrastructure advancements demonstrate the capacity to extend the Ubiquitous Cyberlearning with Collaborative Robotic Experiences (UCCRE) system into classrooms in multiple states.</span></p>\n<p dir=\"ltr\"><span>At NYU, prior to transitioning the award to University of Arizona (UA), and here at UA, we have engaged undergraduate and graduate students from NYU Tandon School of Engineering and UA School of Information in the advancement of the project. Students gained project-related research experience in software and hardware development. Students working on this project have also been interacting with collaborators on the NSF MRI Holodeck project to facilitate the integration of the Holodeck&rsquo;s multi-modal affective sensing and visualization capabilities with the supportive feedback presentation from the teachable agent platform research.&nbsp;&nbsp;</span></p>\n<br />\n<p dir=\"ltr\"><span>Broader Impacts:&nbsp;</span></p>\n<p dir=\"ltr\"><span>With respect to the principal discipline of cyberlearning, this project is advancing a better understanding of how co-robots in classrooms can improve STEM Cyberlearning outcomes. In addition, we are focusing on areas of importance in K-12 computing education: Computational Thinking, Computing and Robotics, and novel educational interactions relating to integrated cognitive, social, and emotional support.&nbsp; A potential broader societal impact from this project is that the UCCRE framework and research methodologies can inform and be re-configured to support learning in a broad array of domains. A better understanding of the impact of co-robots will pave the way for these technologies to be adopted in a manner that leverages principles of learning and contributes to closing achievement gaps.&nbsp;&nbsp;</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/07/2024<br>\nModified by: Winslow&nbsp;Burleson</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\nThis project has advanced the state-of-the-art of co-robotic cyberlearning, engaging middle school students in Ubiquitous Cyberlearning with Collaborative Robotic Experiences (UCCRE). We integrated a Mixed Reality (MR) gesture-based storytelling and simulation tool-kit, ChalkTalk with the R-TAG (Robotic-Teachable Agents for middle school Geometry) cyberlearning research platform. These technologies are designed to provide personalized adaptive cognitive and social support, and facilitate collaborative embodied interactions between robotic teachable agents, students and teachers, within formal classroom and informal after-school settings.\n\n\nTo combine these technologies we used a module called corelink that incorporates and expands interactive authoring and AR/VR capabilities that can be experienced by students in real-time. Corelink has also enabled us to integrate University of Arizona Sensor Lab multimodal sensors into the suite of technologies, thereby expanding the affective and contextual sensing capabilities of the system. We have conducted studies on the feasibility of using these sensors and hardware in conjunction with the interactive robot.\n\n\nCollectively these integrated systems provide the foundational infrastructure to integrate signals and experiences across locations, with multiple users, and technologies. We have successfully implemented and tested interactive collaborative features across several modalities, with low latency, between NYU and UA, as part of the expansion of the NSF MRI Holodeck Project.\n\n\nCorelink handles sending, receiving, recording, and replaying of data throughout the collocated and distributed holodeck node servers and constituent technologies, to provide seamless cross-modality integration that drive real-time interactive Mixed Reality (MR) collaborative experiences. These studies and infrastructure advancements demonstrate the capacity to extend the Ubiquitous Cyberlearning with Collaborative Robotic Experiences (UCCRE) system into classrooms in multiple states.\n\n\nAt NYU, prior to transitioning the award to University of Arizona (UA), and here at UA, we have engaged undergraduate and graduate students from NYU Tandon School of Engineering and UA School of Information in the advancement of the project. Students gained project-related research experience in software and hardware development. Students working on this project have also been interacting with collaborators on the NSF MRI Holodeck project to facilitate the integration of the Holodecks multi-modal affective sensing and visualization capabilities with the supportive feedback presentation from the teachable agent platform research.\n\n\n\n\nBroader Impacts:\n\n\nWith respect to the principal discipline of cyberlearning, this project is advancing a better understanding of how co-robots in classrooms can improve STEM Cyberlearning outcomes. In addition, we are focusing on areas of importance in K-12 computing education: Computational Thinking, Computing and Robotics, and novel educational interactions relating to integrated cognitive, social, and emotional support. A potential broader societal impact from this project is that the UCCRE framework and research methodologies can inform and be re-configured to support learning in a broad array of domains. A better understanding of the impact of co-robots will pave the way for these technologies to be adopted in a manner that leverages principles of learning and contributes to closing achievement gaps.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 02/07/2024\n\n\t\t\t\t\tSubmitted by: WinslowBurleson\n"
 }
}