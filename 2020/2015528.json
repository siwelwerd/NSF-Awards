{
 "awd_id": "2015528",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Bayesian and Semi-Bayesian Methods for Detecting Relationships in High Dimensions",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-08-15",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 99562.0,
 "awd_amount": 99562.0,
 "awd_min_amd_letter_date": "2020-08-04",
 "awd_max_amd_letter_date": "2022-05-24",
 "awd_abstract_narration": "In this big-data era, massive data sets are being generated routinely and we are seeing a growing need for powerful, reliable, and interpretable statistical learning tools to help understand these data.  The main ideas and approaches in this projectl focus on developing effective statistical learning tools to learn about complex and heterogeneous structures, such as those changing in time or varying among different groups of individuals, in high-dimensions. The activities will have a significant impact on high dimensional Bayesian analysis and modeling of nonlinear relationships. While most current efforts for high-dimensional Bayesian analyses have been focused on linear models, this project focuses on two ways of generalizing standard linear models to meet certain practical challenges: one is a generalized form of mixture modeling, termed as individualized variable selection, which enables each individual observation to have its own set of dependent variables through the employment of neuronized priors. Another extension is the Bayesian inference of index models that form a mixture structure. The project will lead to useful tools (or customized software) for discovering interpretable nonlinear and interactive patterns among a large number of potential variables. Various aspects of statistical modeling, design, and learning strategies integrated in our algorithms are  broadly applicable to problems involving  signal discovery in complex systems and high-dimensional data.  The project will also provide both educational and interdisciplinary research opportunities for graduate students, and will result in software useful to biomedical researchers, economists, social scientists, and many other practitioners. \r\n\r\nIn a vast number of regression problems, especially under high-dimensional settings, the structure of the association between covariates in hand and the target quantity of interest might be heterogeneous over observations, which calls for effective methods to detect such non-trivial structures. Standard procedures, including traditional variable selections, commonly overlook the existence of interplays of these heterogeneous factors. This research project aims to develop statistical procedures that identify the complicated relationship between response Y and a set of covariates X in flexible and computationally efficient ways.  Project 1 focuses on Bayesian individualized variable selection (BIVS), which generalizes standard linear regression models to quantify  heterogeneous effects among individual observations that differ in their  dependent variables with different magnitudes. The PIs will investigate its theoretical properties, including model selection consistency and its robustness when the model assumption is violated. Project 2 is devoted to the development of an efficient Bayesian method to infer the semi-parametric relationship between the response and covariates through general index models. The PIs will explore its computational feasibility and theoretical properties such as the posterior contraction rate on the estimation of the sufficient dimension reduction space. Project 3 focuses on a fast tuning parameter selection procedure by employing a generative process via neural networks. By using this procedure,  the cross-validation can be efficiently implemented for general models, such as the BIVS and Bayesian index models,  regularized variable selection, and nonparametric function estimation.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Minsuk",
   "pi_last_name": "Shin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Minsuk Shin",
   "pi_email_addr": "mshin@mailbox.sc.edu",
   "nsf_id": "000814792",
   "pi_start_date": "2020-08-04",
   "pi_end_date": "2022-05-24"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ray",
   "pi_last_name": "Bai",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ray Bai",
   "pi_email_addr": "rbai@mailbox.sc.edu",
   "nsf_id": "000880453",
   "pi_start_date": "2022-05-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of South Carolina at Columbia",
  "inst_street_address": "1600 HAMPTON ST",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBIA",
  "inst_state_code": "SC",
  "inst_state_name": "South Carolina",
  "inst_phone_num": "8037777093",
  "inst_zip_code": "292083403",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "SC06",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTH CAROLINA",
  "org_prnt_uei_num": "Q93ZDA59ZAR5",
  "org_uei_num": "J22LNTMEDP73"
 },
 "perf_inst": {
  "perf_inst_name": "University of South Carolina",
  "perf_str_addr": "1526 Greene Street, 215A",
  "perf_city_name": "Columbia",
  "perf_st_code": "SC",
  "perf_st_name": "South Carolina",
  "perf_zip_code": "292080001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "SC06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 99562.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has advanced Bayesian methodologies for detecting relationships in complex, high-dimensional data. The project produced new methods and scalable optimization and Markov chain Monte Carlo (MCMC) algorithms for Bayesian varying coefficient models when the number of covariates is large and possibly larger than the sample size. In addition, a framework for Bayesian modal regression was introduced which allows for Bayesian inference of the conditional mode. Modal regression is very robust to outliers and skewness, allowing one to detect interesting covariate effects missed by mean or quantile regression. In addition to Bayesian inference of the mode, procedures for model selection and prediction in Bayesian modal regression were also introduced.</p>\n<p>The second major contribution of the project was novel advancements in deep generative models. A deep generative framework for weighted M-estimation was proposed, which covers a variety of procedures such as bootstrapping, cross-validation, and quantile regression. Whereas traditional weighted M-estimation (e.g. bootstrapping) requires solving repeated optimizations, this framework requires solving only a single optimization. Then it is inexpensive to generate novel samples from an implicit probability distribution. This generative framework was also extended to mixing density estimation in latent variable models. Finally, the problem of conditional density estimation (CDE) was considered by connecting CDE with joint quantile regression. A generative framework for generating samples from many random quantile levels was proposed, and a new family of partial monotonic neural networks (PMNNs) was introduced to resolve the problem of crossing quantile curves. Finally, a novel vanishing variability penalty on the generator function was introduced to mitigate the well-known issue of training data memorization in deep generative models.</p>\n<p>These contributions may be impactful inside and outside of statistics, especially in engineering, physical sciences, and other disciplines where uncertainty quantification is a high priority. By inducing a probability distribution over the model parameters through appropriate priors, our Bayesian varying coefficient and modal regression models are useful for quantifying uncertainty in a principled manner. Further, our deep generative framework enables scalable uncertainty quantification and density estimation through deep generative procedures. Finally, our vanishing variability penalty construction may have an impact on generative artificial intelligence (AI), where training data memorization is a well-known problem.</p>\n<p>To date, this project has produced six peer-reviewed papers that have been published in reputable journals or conferences and two more that have been accepted, with further papers in development. Software packages written in Python and R to implement the methods have been made publicly available. One PhD student was trained in deep learning and deep generative models, and this student recently graduated with his PhD in Statistics. Other graduate students were trained in deep learning and deep generative models through a special topics graduate course on high-dimensional data that incorporated research from this project. The PI presented work funded by this grant at conferences (e.g. the Joint Statistical Meetings and EcoSta) and department colloquia.</p><br>\n<p>\n Last Modified: 09/28/2024<br>\nModified by: Ray&nbsp;Bai</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project has advanced Bayesian methodologies for detecting relationships in complex, high-dimensional data. The project produced new methods and scalable optimization and Markov chain Monte Carlo (MCMC) algorithms for Bayesian varying coefficient models when the number of covariates is large and possibly larger than the sample size. In addition, a framework for Bayesian modal regression was introduced which allows for Bayesian inference of the conditional mode. Modal regression is very robust to outliers and skewness, allowing one to detect interesting covariate effects missed by mean or quantile regression. In addition to Bayesian inference of the mode, procedures for model selection and prediction in Bayesian modal regression were also introduced.\n\n\nThe second major contribution of the project was novel advancements in deep generative models. A deep generative framework for weighted M-estimation was proposed, which covers a variety of procedures such as bootstrapping, cross-validation, and quantile regression. Whereas traditional weighted M-estimation (e.g. bootstrapping) requires solving repeated optimizations, this framework requires solving only a single optimization. Then it is inexpensive to generate novel samples from an implicit probability distribution. This generative framework was also extended to mixing density estimation in latent variable models. Finally, the problem of conditional density estimation (CDE) was considered by connecting CDE with joint quantile regression. A generative framework for generating samples from many random quantile levels was proposed, and a new family of partial monotonic neural networks (PMNNs) was introduced to resolve the problem of crossing quantile curves. Finally, a novel vanishing variability penalty on the generator function was introduced to mitigate the well-known issue of training data memorization in deep generative models.\n\n\nThese contributions may be impactful inside and outside of statistics, especially in engineering, physical sciences, and other disciplines where uncertainty quantification is a high priority. By inducing a probability distribution over the model parameters through appropriate priors, our Bayesian varying coefficient and modal regression models are useful for quantifying uncertainty in a principled manner. Further, our deep generative framework enables scalable uncertainty quantification and density estimation through deep generative procedures. Finally, our vanishing variability penalty construction may have an impact on generative artificial intelligence (AI), where training data memorization is a well-known problem.\n\n\nTo date, this project has produced six peer-reviewed papers that have been published in reputable journals or conferences and two more that have been accepted, with further papers in development. Software packages written in Python and R to implement the methods have been made publicly available. One PhD student was trained in deep learning and deep generative models, and this student recently graduated with his PhD in Statistics. Other graduate students were trained in deep learning and deep generative models through a special topics graduate course on high-dimensional data that incorporated research from this project. The PI presented work funded by this grant at conferences (e.g. the Joint Statistical Meetings and EcoSta) and department colloquia.\t\t\t\t\tLast Modified: 09/28/2024\n\n\t\t\t\t\tSubmitted by: RayBai\n"
 }
}