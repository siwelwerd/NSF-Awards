{
 "awd_id": "1952339",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FRG: Collaborative Research: Robust, Efficient, and Private Deep Learning Algorithms",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922113",
 "po_email": "ygorb@nsf.gov",
 "po_sign_block_name": "Yuliya Gorb",
 "awd_eff_date": "2020-08-15",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 434750.0,
 "awd_amount": 434750.0,
 "awd_min_amd_letter_date": "2020-08-13",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "This project develops robust, accurate, and efficient next-generation deep learning algorithms with data privacy and theoretical guarantees for solving challenging artificial intelligence (AI) problems. The methods will have robustness to adversarial attacks with theoretical guarantees.  The project will push artificial intelligence gains in performance and privacy to mobile devices. A broad range of applications includes autonomous driving, drug and material discovery, medical treatment planning, national defense, privacy-preserving machine learning at the edge, federated learning, and also blockchain. Moreover, the developed tools will significantly scale the existing scientific simulations to ultra-large scale and high-dimensional scenarios. This project will partially support one graduate student per year at each campus.\r\n\r\nOur approach toward trustworthy deep learning is theoretically principled by modern partial differential equations and optimization algorithms and theories.  The project involves new algorithmic and theoretical techniques to tackle graph representation in high-dimensional non-convex, non-smooth AI settings. In particular, the project will study (1) developing adversarial robust deep learning algorithms and their theoretical foundations; (2) improving the accuracy of deep learning leveraging new stochastic optimization and principled neural network unit design assisted neural architecture search; (3) advancing deep neural networks compression with algorithms and hardware co-design; (4) designing new data privacy mechanisms to optimally tradeoff between utility and privacy; (5) inventing new quantitative analysis tools to decipher the mysteries of deep learning theoretical challenges; (6) quantifying uncertainties of sophisticated deep learning algorithms. The project trains a diverse body of graduate and undergraduate students at UC Irvine, UCLA, and University of Utah through collaborative education and research activities in applied mathematics, computer science, data science, and general biological, physical, and sociological disciplines.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Andrea",
   "pi_last_name": "Bertozzi",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Andrea L Bertozzi",
   "pi_email_addr": "bertozzi@math.ucla.edu",
   "nsf_id": "000107633",
   "pi_start_date": "2020-08-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Stanley",
   "pi_last_name": "Osher",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Stanley J Osher",
   "pi_email_addr": "sjo@math.ucla.edu",
   "nsf_id": "000165369",
   "pi_start_date": "2020-08-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Bao",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bao Wang",
   "pi_email_addr": "bwang@math.utah.edu",
   "nsf_id": "000797442",
   "pi_start_date": "2020-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900951555",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "1616",
   "pgm_ref_txt": "FOCUSED RESEARCH GROUPS IN MATH SCIENCES"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 434750.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Intellectual Merit: This project develops robust, accurate, and efficient next-generation machine learning and deep learning algorithms with data privacy and theoretical guarantees for solving challenging artificial intelligence (AI) problems.&nbsp; One example is Privacy-Preserving Federated Multi-Task Linear Regression, where we investigate multi-task learning (MTL), where multiple learning tasks are performed jointly rather than separately to leverage their similarities and improve performance. Another example are Graph Laplacian (GL)-based semi-supervised learning is one of the most used approaches for classifying nodes in a graph. Understanding and certifying the adversarial robustness of machine learning algorithms has attracted large amounts of attention from different research communities due to its crucial importance in many security-critical applied domains. We provide the first adversarial robust certification for the GL classifier. More precisely we quantitatively bound the difference in the classification accuracy of the GL classifier before and after an adversarial attack.&nbsp; We have many new methods developed for deep learning and machine learning.&nbsp; These include Glassoformer: a query-sparse transformer for post-fault power grid voltage prediction; GRAND++: Graph Neural Diffusion with A Source Term; Active learning methods, heavy ball neural ODE methods; equivariant graph neural network methods; and MomentumRNN - &nbsp;Integrating Momentum into Recurrent Neural Networks.</p>\n<p>Broader Impacts: This project has trained undergraduate researchers,&nbsp; PhD students, and postdocs at the University of Utah and UCLA.&nbsp; The Project also included a collaboration with the Univ. of California Irvine (Jack Xin).&nbsp; Success outcomes for these junior researchers are shown by the many publications coauthored by students and postdocs and the job placement of these people.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/17/2024<br>\nModified by: Andrea&nbsp;L&nbsp;Bertozzi</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIntellectual Merit: This project develops robust, accurate, and efficient next-generation machine learning and deep learning algorithms with data privacy and theoretical guarantees for solving challenging artificial intelligence (AI) problems. One example is Privacy-Preserving Federated Multi-Task Linear Regression, where we investigate multi-task learning (MTL), where multiple learning tasks are performed jointly rather than separately to leverage their similarities and improve performance. Another example are Graph Laplacian (GL)-based semi-supervised learning is one of the most used approaches for classifying nodes in a graph. Understanding and certifying the adversarial robustness of machine learning algorithms has attracted large amounts of attention from different research communities due to its crucial importance in many security-critical applied domains. We provide the first adversarial robust certification for the GL classifier. More precisely we quantitatively bound the difference in the classification accuracy of the GL classifier before and after an adversarial attack. We have many new methods developed for deep learning and machine learning. These include Glassoformer: a query-sparse transformer for post-fault power grid voltage prediction; GRAND++: Graph Neural Diffusion with A Source Term; Active learning methods, heavy ball neural ODE methods; equivariant graph neural network methods; and MomentumRNN - Integrating Momentum into Recurrent Neural Networks.\n\n\nBroader Impacts: This project has trained undergraduate researchers, PhD students, and postdocs at the University of Utah and UCLA. The Project also included a collaboration with the Univ. of California Irvine (Jack Xin). Success outcomes for these junior researchers are shown by the many publications coauthored by students and postdocs and the job placement of these people.\n\n\n\t\t\t\t\tLast Modified: 11/17/2024\n\n\t\t\t\t\tSubmitted by: AndreaLBertozzi\n"
 }
}