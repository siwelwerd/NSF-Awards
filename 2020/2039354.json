{
 "awd_id": "2039354",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: SaTC-EDU: Instilling a Mindset of Adversarial Thinking into Computer Science Courses Early and Often",
 "cfda_num": "47.076",
 "org_code": "11010000",
 "po_phone": "7032928182",
 "po_email": "asiraj@nsf.gov",
 "po_sign_block_name": "Ambareen Siraj",
 "awd_eff_date": "2020-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 297881.0,
 "awd_amount": 313881.0,
 "awd_min_amd_letter_date": "2020-07-27",
 "awd_max_amd_letter_date": "2021-05-03",
 "awd_abstract_narration": "Security and design flaws in artificial intelligence (AI) algorithms and computer systems can leave our personal information, including sensitive data such as medical records, dangerously exposed, or can give rise to biases that disadvantage or threaten parts of the population. The ability to successfully find these security and design flaws before they cause harm depends on qualified engineers, researchers, and policymakers who understand threats to computer systems and algorithms.  However, threat-modeling is typically taught only in advanced Computer Science courses, which come late in the curriculum and which not all students elect to take. This project investigates whether earlier and continued exposure to material on threat modeling and a mindset called \"adversarial thinking\" improves students' ability to recognize and address challenges in privacy, cybersecurity, and new AI technologies. Adversarial thinking refers to adopting the perspective of an adversary who seeks to exploit weaknesses in a system, algorithm, or model. The resulting course materials and findings will be disseminated, and the findings are expected to motivate changes in the approach to computer science curricula.\r\n\r\nThe project proposes to develop material on adversarial thinking and integrate it into courses at the introductory, intermediate, and advanced level of Brown University\u2019s computer science curriculum. The project team will measure students' performance and progression within each course as well as across courses. The data collected will help answer the project\u2019s central research question: do students who encounter adversarial thinking early in and repeatedly throughout their computer science education show improved ability to recognize and address threats and flaws in computer systems security and AI models? The project will impact academic computer science education through pedagogical methods, skills, and recommendations for curricular structures that help prepare students for the complexities, risks, and opportunities of new technologies.\r\n\r\nThis project is supported by a special initiative of the Secure and Trustworthy Cyberspace (SaTC) program to foster new, previously unexplored, collaborations between the fields of cybersecurity, artificial intelligence, and education. The SaTC program aligns with the Federal Cybersecurity Research and Development Strategic Plan and the National Privacy Research Strategy to protect and preserve the growing social and economic benefits of cyber systems while ensuring security and privacy.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DGE",
 "org_div_long_name": "Division Of Graduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "Nelson",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy B Nelson",
   "pi_email_addr": "timothy_nelson@brown.edu",
   "nsf_id": "000738605",
   "pi_start_date": "2020-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Stephen",
   "pi_last_name": "Bach",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Stephen H Bach",
   "pi_email_addr": "stephen_bach@brown.edu",
   "nsf_id": "000799726",
   "pi_start_date": "2020-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Malte",
   "pi_last_name": "Schwarzkopf",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Malte Schwarzkopf",
   "pi_email_addr": "malte_schwarzkopf@brown.edu",
   "nsf_id": "000806141",
   "pi_start_date": "2020-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kathryn",
   "pi_last_name": "Fisler",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kathryn Fisler",
   "pi_email_addr": "kathryn_fisler@brown.edu",
   "nsf_id": "000131380",
   "pi_start_date": "2020-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Shriram",
   "pi_last_name": "Krishnamurthi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shriram Krishnamurthi",
   "pi_email_addr": "sk+17@cs.brown.edu",
   "nsf_id": "000280993",
   "pi_start_date": "2020-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "",
  "perf_city_name": "Providence",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029129002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "093Z",
   "pgm_ref_txt": "AI Education/Workforce Develop"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0420",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002021DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0421",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002122DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 297881.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Computer security is critically important especially in today's increasingly AI-based applications. However, it is notoriously difficult to teach students to look for and find security flaws in computer systems. This project investigated whether the mindset of \"adversarial thinking\" (AT), where students put themselves into the attacker's (i.e., the adversary's) position and try to find weaknesses in a computer system, can help increase students'&nbsp;<span>ability to see and address challenges in privacy and cybersecurity, particularly around new AI technologies.</span></p>\n<p>The project developed pedagogic techniques, computer systems, and curricular materials to investigate this hypothesis, and performed empirical studies to measure students' ability to engage in adversarial thinking activities. We deployed these activities in introductory, intermediate, and advanced undergraduate courses at Brown CS, including cybersecurity and AI courses.</p>\n<p>In our empirical work, we found that students are capable of sophisticated AT analysis of systems in and outside an explicit cybersecurity context, and well before they fully understand well the key technologies under evaluation. This suggests that adversarial thinking is a promising technique that can be introduced early in computer science education.</p>\n<p>We applied these insights in two concrete examples. First, we developed a data science system, Tuplex, that helps with tasks such as pre-processing data for training an AI model. Tuplex is based around the idea of separating data that fits the developer's common (expected) case from exception-case data that does not (i.e., adversarial, non-conforming examples). Tuplex lets data scientists iteratively process their data sets by writing a program that handles common-case data, then inspecting the data that fails to fit their assumptions, and specifying how this data ought to be handled. Post-hoc focus on the collected exception case data helps the user make progress without having to deal with unexpected inputs one at a time when the analysis runs. Tuplex also leverages the split into common-case and exception-case data to speed up processing, since it can generate faster program code by focusing on the common case only.</p>\n<p>Second, in a deep-dive case study, we find that the pedagogical benefits of adversarial thinking also apply in specific domain: model finding using solvers. Solvers are tools used in formal methods to check the consistency of formal models of a system or computer program. Formal models help find bugs and ensure that important properties of an algorithm or system also hold. Finding correct models is challenging, and solvers seek to aid the process by showing the user examples that fit the current model --- i.e., concrete instances of a system that fit the specified constraints. Our work shows that it is helpful to show users multiple such instances, as well as negative (adversarial) examples of instances that fail to meet the constraints.&nbsp;<span>This format, known as \"contrasting cases\", is based on findings from perceptual psychology that information is more salient when presented in contrast across two or more examples.</span></p>\n<p>Building on these insights, we developed a series of assignments focused on socially-responsible computing, some of which embed adversarial thinking principles. We deployed these assignments across courses with the help of socially-responsible computing teaching assistants (STAs). We report on this effort and on the broader socially-responsible computing program that grew out of it.</p>\n<p>All curricular materials produced are freely available.</p><br>\n<p>\n Last Modified: 01/08/2024<br>\nModified by: Malte&nbsp;Schwarzkopf</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nComputer security is critically important especially in today's increasingly AI-based applications. However, it is notoriously difficult to teach students to look for and find security flaws in computer systems. This project investigated whether the mindset of \"adversarial thinking\" (AT), where students put themselves into the attacker's (i.e., the adversary's) position and try to find weaknesses in a computer system, can help increase students'ability to see and address challenges in privacy and cybersecurity, particularly around new AI technologies.\n\n\nThe project developed pedagogic techniques, computer systems, and curricular materials to investigate this hypothesis, and performed empirical studies to measure students' ability to engage in adversarial thinking activities. We deployed these activities in introductory, intermediate, and advanced undergraduate courses at Brown CS, including cybersecurity and AI courses.\n\n\nIn our empirical work, we found that students are capable of sophisticated AT analysis of systems in and outside an explicit cybersecurity context, and well before they fully understand well the key technologies under evaluation. This suggests that adversarial thinking is a promising technique that can be introduced early in computer science education.\n\n\nWe applied these insights in two concrete examples. First, we developed a data science system, Tuplex, that helps with tasks such as pre-processing data for training an AI model. Tuplex is based around the idea of separating data that fits the developer's common (expected) case from exception-case data that does not (i.e., adversarial, non-conforming examples). Tuplex lets data scientists iteratively process their data sets by writing a program that handles common-case data, then inspecting the data that fails to fit their assumptions, and specifying how this data ought to be handled. Post-hoc focus on the collected exception case data helps the user make progress without having to deal with unexpected inputs one at a time when the analysis runs. Tuplex also leverages the split into common-case and exception-case data to speed up processing, since it can generate faster program code by focusing on the common case only.\n\n\nSecond, in a deep-dive case study, we find that the pedagogical benefits of adversarial thinking also apply in specific domain: model finding using solvers. Solvers are tools used in formal methods to check the consistency of formal models of a system or computer program. Formal models help find bugs and ensure that important properties of an algorithm or system also hold. Finding correct models is challenging, and solvers seek to aid the process by showing the user examples that fit the current model --- i.e., concrete instances of a system that fit the specified constraints. Our work shows that it is helpful to show users multiple such instances, as well as negative (adversarial) examples of instances that fail to meet the constraints.This format, known as \"contrasting cases\", is based on findings from perceptual psychology that information is more salient when presented in contrast across two or more examples.\n\n\nBuilding on these insights, we developed a series of assignments focused on socially-responsible computing, some of which embed adversarial thinking principles. We deployed these assignments across courses with the help of socially-responsible computing teaching assistants (STAs). We report on this effort and on the broader socially-responsible computing program that grew out of it.\n\n\nAll curricular materials produced are freely available.\t\t\t\t\tLast Modified: 01/08/2024\n\n\t\t\t\t\tSubmitted by: MalteSchwarzkopf\n"
 }
}