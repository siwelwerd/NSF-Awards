{
 "awd_id": "2007036",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Online Learning and Optimal Experiment Design with a Budget",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032920000",
 "po_email": "ahero@nsf.gov",
 "po_sign_block_name": "Alfred Hero",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 500225.0,
 "awd_amount": 500225.0,
 "awd_min_amd_letter_date": "2020-07-28",
 "awd_max_amd_letter_date": "2020-07-28",
 "awd_abstract_narration": "Machine learning is routinely used in science and industry to make inferences about a phenomenon that cannot be observed directly, but can be probed through a series of experiments. For instance, the chief metric when optimizing a chemical reaction may be the yield of the desired output, but many experimental conditions such as pH and ambient temperature may affect the yield. Adaptive experimental design provides a framework to exploit observed measurements of the past to plan measurements in the future in a closed loop. It has been shown to require far fewer overall measurements to achieve the same inference goals compared to any fixed plan chosen in advance. However, a limitation is the implicit assumption that every possible measurement is available at all times. In practice this is rarely true - for example chemical reagents can run out and restrict the possible experiments. This forces a tradeoff on practitioners: if only a subset of measurements are possible at the current time and you have a fixed budget of experiments, is it worth it to take one of the available experiments, or abstain in the hope of better opportunities in the future? The focus of this research is to formalize such questions and develop a framework for addressing online adaptive experimental design in the sequential setting of unpredictable measurement availability. The project also includes a plan to vertically integrate robust data collection techniques across the university touching all levels and disciplines, as well as outreach that starts with K-12 students and extends to the community at large.\r\n\r\nThis project amalgamates insights from adaptive experimental design, multi-armed bandits, and online algorithms. Current adaptive experimental design methods, for instance in stochastic optimization and best-arm identification, assume access to a fixed batch of experiments to choose from at each time, and explicitly plan to evolve the allocation of measurements over this batch using optimal design techniques such as G-optimal design. However, if the measurement set is changing at each time, potentially adversarially, such planning is extremely difficult. Motivated by progress in specific cases that leverage advances in convex optimization, the project seeks to provide a general framework for experimental design including optimization and multiple testing in online settings.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kevin",
   "pi_last_name": "Jamieson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kevin Jamieson",
   "pi_email_addr": "jamieson@cs.washington.edu",
   "nsf_id": "000776726",
   "pi_start_date": "2020-07-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Maryam",
   "pi_last_name": "Fazel",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maryam Fazel",
   "pi_email_addr": "mfazel@uw.edu",
   "nsf_id": "000488519",
   "pi_start_date": "2020-07-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "185 Stevens Way",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981950001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 500225.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-4e0301c4-7fff-4963-154a-b0d83ed4a2fb\"><span>Over the life of this award, our team has developed a broad suite of new algorithms and theoretical insights that improve how machines learn from data in real time. At its core, our work has focused on adaptive experimental design&mdash;the process of deciding which measurements or actions to take next in order to learn as efficiently as possible&mdash;and applying these ideas to a wide range of practical problems from robotics to online decision making. One research thrust advanced our understanding of online experimental design by rigorously exploring the trade-offs between taking an immediate, possibly imperfect measurement and waiting for a higher-quality measurement later. At the heart of that study was the challenge of best-arm identification for linear bandits under selective sampling&mdash;a problem that naturally arises when measurements come at a cost of time or resources. In contrast to this static measurement setting, another major thrust extended our work to reinforcement learning and control where an agent&rsquo;s actions influence the state of the environment and the agent must optimize over state-dependent policies. Building on classical active learning and optimal experimental design, our work developed new algorithms and theoretical insights that provide instance-dependent guarantees, enabling our methods to be adaptive to the specific characteristics of the data and environment. We achieved significant progress in diverse areas including active learning under safety and fairness constraints, instance-dependent reinforcement learning for both linear and non-linear dynamical systems, and resource allocation strategies in time-varying environments. These advancements refined our understanding of the information and adaptability requirements for algorithms, yielding practical methods that are computationally efficient and sample-optimal. While our research is primarily theoretical, it lays a solid foundation for potential applications in areas such as robotics, adaptive experimentation, and data-driven decision-making. In addition to our theoretical work, we actively engaged in outreach and mentoring to broaden public understanding of AI. Jamieson and Fazel gave a talk on &ldquo;The History of AI and Its Influence Today&rdquo; for a local retirement home, sparking extensive discussion. Jamieson went on to give similar introductory AI talks at different community centers so that all told, the events reached several hundred people. Fazel co-organized industry panels featuring female professionals at the UW ECE Women&rsquo;s Research Event in 2022 and 2023, and co-led a mentoring session on effective research communication through the Learning Theory Alliance. Jamieson also contributed to the effort by mentoring students applying to graduate school. </span></span></p><br>\n<p>\n Last Modified: 02/06/2025<br>\nModified by: Kevin&nbsp;Jamieson</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nOver the life of this award, our team has developed a broad suite of new algorithms and theoretical insights that improve how machines learn from data in real time. At its core, our work has focused on adaptive experimental designthe process of deciding which measurements or actions to take next in order to learn as efficiently as possibleand applying these ideas to a wide range of practical problems from robotics to online decision making. One research thrust advanced our understanding of online experimental design by rigorously exploring the trade-offs between taking an immediate, possibly imperfect measurement and waiting for a higher-quality measurement later. At the heart of that study was the challenge of best-arm identification for linear bandits under selective samplinga problem that naturally arises when measurements come at a cost of time or resources. In contrast to this static measurement setting, another major thrust extended our work to reinforcement learning and control where an agents actions influence the state of the environment and the agent must optimize over state-dependent policies. Building on classical active learning and optimal experimental design, our work developed new algorithms and theoretical insights that provide instance-dependent guarantees, enabling our methods to be adaptive to the specific characteristics of the data and environment. We achieved significant progress in diverse areas including active learning under safety and fairness constraints, instance-dependent reinforcement learning for both linear and non-linear dynamical systems, and resource allocation strategies in time-varying environments. These advancements refined our understanding of the information and adaptability requirements for algorithms, yielding practical methods that are computationally efficient and sample-optimal. While our research is primarily theoretical, it lays a solid foundation for potential applications in areas such as robotics, adaptive experimentation, and data-driven decision-making. In addition to our theoretical work, we actively engaged in outreach and mentoring to broaden public understanding of AI. Jamieson and Fazel gave a talk on The History of AI and Its Influence Today for a local retirement home, sparking extensive discussion. Jamieson went on to give similar introductory AI talks at different community centers so that all told, the events reached several hundred people. Fazel co-organized industry panels featuring female professionals at the UW ECE Womens Research Event in 2022 and 2023, and co-led a mentoring session on effective research communication through the Learning Theory Alliance. Jamieson also contributed to the effort by mentoring students applying to graduate school. \t\t\t\t\tLast Modified: 02/06/2025\n\n\t\t\t\t\tSubmitted by: KevinJamieson\n"
 }
}