{
 "awd_id": "2006827",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CNS Core: Small: Understanding Per-Hop Flow Control",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922935",
 "po_email": "dmedhi@nsf.gov",
 "po_sign_block_name": "Deepankar Medhi",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2020-08-19",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "This research concerns how best to manage contention for data center network resources. Data centers are among the fastest growing segment of the computer industry, and networks connect the computers in a data center to allow them to communicate. Just as roads can become congested when too many people try to use them at the same time, data center networks can become congested when too many applications try to send data at the same time. Most networks today use an end to end control mechanism - as the network becomes congested, it sends signals back to the computers to slow down. It might seem that faster networks would help, but the opposite is true - the amount of network communication is also rapidly increasing, and more data can be sent before the feedback mechanism can kick in to control traffic. This project (a collaborative project between investigators at the University of Washington and Massachusetts Institute of Technology) is to explore a different approach, where feedback occurs within the network, hop-by-hop between network switches, and just for those applications that are sending too fast.\r\n\r\nThe challenges for congestion control for data centers include rapidly increasing workload demand, ever faster links, small average transfer sizes, extremely bursty traffic, and limited switch buffer capacity. Existing end-to-end congestion control systems are far from optimal in these settings, and this is particularly noticeable for latency-sensitive applications. Many data center operators compensate by using priorities and/or running their networks at very low average utilization, but this raises costs without fully solving the problem. This research attempts to understand the benefits and limits of an alternative approach to congestion control for data center networks, based on per-hop flow control. The research will (i) develop a theoretical framework to quantify the difference between the two different approaches, (ii) demonstrate a practical implementation on modern programmable data center network switches, and (iii) understand and develop solutions for the engineering challenges of using per-hop flow control in data centers.\r\n\r\nIf successful, the research will help enable an emerging class of latency-sensitive applications to be deployed within and across data centers and at lower cost, for bursty traffic patterns and emerging very high bandwidth networks being developed in industry. Data center network technologies are rapidly evolving, and so a key aspect of this research is to develop materials to help train undergraduate and graduate students for the challenges that latency-sensitive applications pose for data center networks.\r\n\r\nThe project website, https://www.cs.washington.edu/homes/tom/backpressure/, contains copies of all project papers, presentations, source code, simulations, experimental results, and teaching materials. Additional material will be placed there as the project progresses, and will be maintained for a minimum of ten years after the completion of the project.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mohammad",
   "pi_last_name": "Alizadeh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mohammad Alizadeh",
   "pi_email_addr": "alizadeh@csail.mit.edu",
   "nsf_id": "000703497",
   "pi_start_date": "2020-08-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Effective congestion control in data centers is becoming increasingly challenging with rapidly increasing workload demand, faster links, extremely bursty traffic, limited switch buffer capacity, and the increasing prevalence of latency-sensitive applications. Addressing these challenges with traditional end-to-end congestion control methods is proving to be inadequate. With increasing link speeds, most data transfers are completed within less than a single round-trip delay; therefore, end-to-end schemes struggle to form an effective response that avoids compounding the problem. This project explores an alternative: per-hop per-flow flow control, which aims to significantly speed up the response to congestion, limited only by the delay between adjacent switches.</span><span><br /><br /><strong>Intellectual merit:</strong><br /><br /><strong>Backpressure Flow Control (BFC):</strong> This project introduced a practical hop-by-hop, per-flow flow control scheme suitable for data center networks. Unlike traditional schemes that demand impractical switch resources (e.g., per-connection queues and extensive buffers), BFC offers a scalable design compatible with commercially available programmable switches. It operates by maintaining state only for the \"active flows\"&mdash;those with packets at a switch at any moment&mdash;and dynamically assigns these flows to available queues. This dynamic approach, a stark contrast to the fixed flow-to-queue mappings typical in existing networks, aims to minimize flow collisions and thereby enhance performance under hop-by-hop flow control.<br /><br /><strong>Optimal congestion control for time-varying links:</strong> Modern networks exhibit a high degree of variability in link rates -- from the fluctuating bandwidth of cellular networks to the capacity variability caused by traffic scheduling in data centers. This project developed a formal model for congestion control over such links. It provides a theoretical framework for identifying an optimal control law that balances link utilization and queuing delay under stochastic link conditions, offering insights into designing more efficient congestion control protocols.<br /><br /><strong>Parsimon:</strong> Network tail latency is a crucial metric for cloud application performance that can be affected by a wide variety of factors, including network load, inter-rack traffic skew, traffic burstiness, flow size distributions, oversubscription, topology asymmetry, and congestion control protocols. Estimating the impact of different design decisions on tail latency is difficult. Network simulators such as NS-3 can provide accurate answers, but they can take hours or days to answer what-if questions for a single configuration even at a moderate scale. The Parsimon project addressed this gap by developing a set of techniques to provide a speedup of more than a factor of 500 relative to NS-3 when estimating the tail latency experienced on large-scale networks with general traffic workloads and topologies.<br /><br /><strong>Broader impact:</strong><br /><br />Data centers are vital to the current digital ecosystem, supporting a wide array of computing needs for individuals, businesses, and large organizations alike. Enhancements in network efficiency, such as those developed by this project, have the potential to significantly reduce operational costs and environmental impact of data centers. As is true for reducing highway congestion, reducing the length and spread of data center network congestion events allows for all other resources, such as servers and disks, to be used more efficiently and ultimately allow applications to provide more timely response to end users. Improving resource utilization also allows data center operators to achieve more with existing infrastructure, delay upgrading existing equipment or adding new data centers, lowering energy use for ongoing operations.<br /><br />Furthermore, this project contributed to the academic and professional development of two Ph.D. students from MIT and the University of Washington, with one now working as a researcher in the technology industry.</span></p><br>\n<p>\n Last Modified: 03/15/2024<br>\nModified by: Mohammad&nbsp;Alizadeh</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nEffective congestion control in data centers is becoming increasingly challenging with rapidly increasing workload demand, faster links, extremely bursty traffic, limited switch buffer capacity, and the increasing prevalence of latency-sensitive applications. Addressing these challenges with traditional end-to-end congestion control methods is proving to be inadequate. With increasing link speeds, most data transfers are completed within less than a single round-trip delay; therefore, end-to-end schemes struggle to form an effective response that avoids compounding the problem. This project explores an alternative: per-hop per-flow flow control, which aims to significantly speed up the response to congestion, limited only by the delay between adjacent switches.\n\nIntellectual merit:\n\nBackpressure Flow Control (BFC): This project introduced a practical hop-by-hop, per-flow flow control scheme suitable for data center networks. Unlike traditional schemes that demand impractical switch resources (e.g., per-connection queues and extensive buffers), BFC offers a scalable design compatible with commercially available programmable switches. It operates by maintaining state only for the \"active flows\"those with packets at a switch at any momentand dynamically assigns these flows to available queues. This dynamic approach, a stark contrast to the fixed flow-to-queue mappings typical in existing networks, aims to minimize flow collisions and thereby enhance performance under hop-by-hop flow control.\n\nOptimal congestion control for time-varying links: Modern networks exhibit a high degree of variability in link rates -- from the fluctuating bandwidth of cellular networks to the capacity variability caused by traffic scheduling in data centers. This project developed a formal model for congestion control over such links. It provides a theoretical framework for identifying an optimal control law that balances link utilization and queuing delay under stochastic link conditions, offering insights into designing more efficient congestion control protocols.\n\nParsimon: Network tail latency is a crucial metric for cloud application performance that can be affected by a wide variety of factors, including network load, inter-rack traffic skew, traffic burstiness, flow size distributions, oversubscription, topology asymmetry, and congestion control protocols. Estimating the impact of different design decisions on tail latency is difficult. Network simulators such as NS-3 can provide accurate answers, but they can take hours or days to answer what-if questions for a single configuration even at a moderate scale. The Parsimon project addressed this gap by developing a set of techniques to provide a speedup of more than a factor of 500 relative to NS-3 when estimating the tail latency experienced on large-scale networks with general traffic workloads and topologies.\n\nBroader impact:\n\nData centers are vital to the current digital ecosystem, supporting a wide array of computing needs for individuals, businesses, and large organizations alike. Enhancements in network efficiency, such as those developed by this project, have the potential to significantly reduce operational costs and environmental impact of data centers. As is true for reducing highway congestion, reducing the length and spread of data center network congestion events allows for all other resources, such as servers and disks, to be used more efficiently and ultimately allow applications to provide more timely response to end users. Improving resource utilization also allows data center operators to achieve more with existing infrastructure, delay upgrading existing equipment or adding new data centers, lowering energy use for ongoing operations.\n\nFurthermore, this project contributed to the academic and professional development of two Ph.D. students from MIT and the University of Washington, with one now working as a researcher in the technology industry.\t\t\t\t\tLast Modified: 03/15/2024\n\n\t\t\t\t\tSubmitted by: MohammadAlizadeh\n"
 }
}