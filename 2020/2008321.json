{
 "awd_id": "2008321",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS Core: Small: Operating Systems Abstractions for Serverless Computing",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jason Hallstrom",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 499986.0,
 "awd_amount": 499986.0,
 "awd_min_amd_letter_date": "2020-07-10",
 "awd_max_amd_letter_date": "2020-07-10",
 "awd_abstract_narration": "Serverless functions, or Functions as a Service (FaaS), are a cloud computing feature whose popularity has been increasing in recent years. This project will improve serverless functions with a sophisticated runtime system that will allow users to run code efficiently while keeping serverless functions economically viable to providers.  While keeping the programming model simple, a more sophisticated runtime will provide features such as efficient caching of intermediate results and fault tolerance.  Meanwhile hardware acceleration (e.g., graphical processing units (GPUs)) will be transparently enabled.  As a consequence, serverless functions will be made efficient for new classes of workloads such as video processing and machine learning inference.\r\n\r\nAchieving efficient execution with a simple programming model requires a technically sophisticated runtime system.  Organizing the computation as a data flow graph allows the user to provide only simple data dependencies while the runtime simultaneously schedules local storage and computational accelerators along with more traditional resources such as the Central Processing Unit (CPU) cores and memory.  Serverless workloads require high parallelism and short run times to make the platform worthwhile.  However, maintaining high levels of parallelism can be difficult because of input-dependent processing requirements and GPU acceleration.  Load imbalance arises when the stages specified in a data flow graph have data-dependent processing requirements.  This is common in some machine learning (ML) related tasks, e.g., face recognition. GPUs may make the problem worse because a data flow graph that is balanced for CPU execution might become unbalanced when some stages are executed on a GPU where execution is much faster.\r\n\r\nThis project will provide the necessary tools, techniques, and infrastructure to bring serverless functions to new workloads with unprecedented levels of performance.  This allows the continued exponential evolution and innovation for systems that rely on machine learning and other compute-intensive computations. This project will also provide an opportunity for doctoral students to work as graduate research assistants while gaining broad exposure to interdisciplinary research that draws from multiple areas of computer science, including operating systems, virtualization and GPUs.\r\n\r\nResults from this project will be made public where they can be archived.  All published material from the project will be distributed for free from the authors' web site.  Research artifacts are likely to include modified source code and workloads.  Research publications will be available at https://www.cs.utexas.edu/users/witchel/.  Source code, workloads, and other artifacts will be available at https://github.com/ut-osa/.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Emmett",
   "pi_last_name": "Witchel",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Emmett Witchel",
   "pi_email_addr": "witchel@cs.utexas.edu",
   "nsf_id": "000164959",
   "pi_start_date": "2020-07-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "The University of Texas at Austin",
  "perf_str_addr": "3925 W Braker Lane, Suite 3340",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787595316",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "TX37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 499986.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our goal is to provide better performance and better price/performance with a reasonable programming cost for serverless computing as compared with current cloud virtual machines.&nbsp; Our progress toward this goal came from solving the following problems: making GPUs available to serverless workloads, adapting scalable, distributed, shared, fault-tolerant, append-only logs to enable stateful serverless workloads, and finally, we showed how streaming workloads, an important stateful workload, can run effectively on serverless.&nbsp; These technical accomplishments establish the intellectual merit of the project.</p>\n<p>We built and published DGSF, a platform that enables serverless applications to access virtualized GPUs by disaggregating resources.&nbsp; DGSF uses a small pool of remote physical GPUs to serve many serverless applications concurrently.&nbsp; This approach makes cost-efficient use of GPUs, incentivizing cloud providers to make them available to serverless workloads.</p>\n<p>For stateful serverless workloads, we observe that distributed, shared, fault-tolerant logs have emerged as a powerful tool in distributed systems to solve several difficult problems with a single, elegant abstraction. Logs provide persistent and fault-tolerant storage, but they also provide fine-grained state machine replication, which forms the basis for important distributed services like consensus and transactional data management. A fault-tolerant distributed log enables distributed services to be built quickly and correctly, while also providing a single target for low level, system optimizations.</p>\n<p>We built and published Boki which uses shared logs to enable efficient stateful services built on the serverless paradigm.&nbsp; For serverless applications, the total order provided by the shared log enables serverless functions to agree on the order of state updates, eliminating the need for complex coordination protocols. Moreover, the shared log acts as a reliable and durable storage layer, ensuring that state updates are persisted even in the presence of failures.</p>\n<p>Boki is the first system that allows stateful serverless functions to manage state using distributed shared logs.&nbsp; Boki's shared log abstraction supports diverse serverless use cases, including fault-tolerant workflows, durable object storage, and message queues.&nbsp; Boki's shared logs achieve elasticity, data locality, and resource efficiency.&nbsp; Our evaluation of Boki re\\veals promising performance.&nbsp; It provides significantly lower latency and higher throughput for a variety of tasks when compared with current alternatives like MongoDB, Amazon SQS, and Apache Pulsar.</p>\n<p>Stream processing is a paradigm for continuously transforming and analyzing data as it arrives.&nbsp; To handle high data rates, stream processing systems distribute the workload across multiple nodes.&nbsp; However, unlike simple data-parallel batch jobs, streaming computations are long-running and stateful -- they maintain and update intermediate results over time as new data arrives. Fault tolerance is crucial for stream processing systems to ensure results remain correct in the presence of failures. The key challenge is providing exactly-once semantics -- ensuring each input record is reflected in the processing results exactly one time, even if failures occur.</p>\n<p>Fault-tolerant distributed shared logs (such as Boki) have emerged as a storage substrate well suited for streaming workloads.&nbsp; Shared log systems have nodes dedicated to storage and ordering, which provide fault-tolerant storage whose bandwidth capacity scales with increasing resources.&nbsp; Boki supports string tags for selective reads, and string tags can implement an efficient atomic multi-stream append by a specific encoding of metadata on a single data record append.&nbsp; Compared to current systems that send messages to coordinate the atomic logging, using the advanced features of modern shared logs significantly reduces the cost of maintaining exactly-once semantics and subsequently the median and tail latencies for a range of workloads.</p>\n<p>We built and submitted a streaming system that uses Boki and is mature enough that we can port the complete NEXMark benchmark suite. We compare the performance of it with Kafka Streams, which is an industry-leading distributed stream processing engine that uses logging for fault tolerance.&nbsp; Evaluation results show that our system achieves 1.3x to 5.4x lower median latency, or 1.3x to 5.0x higher saturation throughput than Kafka Streams on NEXMark workloads.</p>\n<p>For the broader impact of our work, every day billions of people use applications that run in data centers.&nbsp; Cloud computing and the services it has enabled have transformed computing and life over the past decade.&nbsp; By bringing new workloads to serverless platforms, we provide necessary tools, techniques, and infrastructure to enable the continued exponential evolution and innovation for systems that rely on ML and other compute-intensive computations.&nbsp; All of our software is open source.&nbsp; Also, the work has contributed to student development and has been integrated into our teaching curriculum.</p><br>\n<p>\n Last Modified: 09/22/2024<br>\nModified by: Emmett&nbsp;Witchel</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nOur goal is to provide better performance and better price/performance with a reasonable programming cost for serverless computing as compared with current cloud virtual machines. Our progress toward this goal came from solving the following problems: making GPUs available to serverless workloads, adapting scalable, distributed, shared, fault-tolerant, append-only logs to enable stateful serverless workloads, and finally, we showed how streaming workloads, an important stateful workload, can run effectively on serverless. These technical accomplishments establish the intellectual merit of the project.\n\n\nWe built and published DGSF, a platform that enables serverless applications to access virtualized GPUs by disaggregating resources. DGSF uses a small pool of remote physical GPUs to serve many serverless applications concurrently. This approach makes cost-efficient use of GPUs, incentivizing cloud providers to make them available to serverless workloads.\n\n\nFor stateful serverless workloads, we observe that distributed, shared, fault-tolerant logs have emerged as a powerful tool in distributed systems to solve several difficult problems with a single, elegant abstraction. Logs provide persistent and fault-tolerant storage, but they also provide fine-grained state machine replication, which forms the basis for important distributed services like consensus and transactional data management. A fault-tolerant distributed log enables distributed services to be built quickly and correctly, while also providing a single target for low level, system optimizations.\n\n\nWe built and published Boki which uses shared logs to enable efficient stateful services built on the serverless paradigm. For serverless applications, the total order provided by the shared log enables serverless functions to agree on the order of state updates, eliminating the need for complex coordination protocols. Moreover, the shared log acts as a reliable and durable storage layer, ensuring that state updates are persisted even in the presence of failures.\n\n\nBoki is the first system that allows stateful serverless functions to manage state using distributed shared logs. Boki's shared log abstraction supports diverse serverless use cases, including fault-tolerant workflows, durable object storage, and message queues. Boki's shared logs achieve elasticity, data locality, and resource efficiency. Our evaluation of Boki re\\veals promising performance. It provides significantly lower latency and higher throughput for a variety of tasks when compared with current alternatives like MongoDB, Amazon SQS, and Apache Pulsar.\n\n\nStream processing is a paradigm for continuously transforming and analyzing data as it arrives. To handle high data rates, stream processing systems distribute the workload across multiple nodes. However, unlike simple data-parallel batch jobs, streaming computations are long-running and stateful -- they maintain and update intermediate results over time as new data arrives. Fault tolerance is crucial for stream processing systems to ensure results remain correct in the presence of failures. The key challenge is providing exactly-once semantics -- ensuring each input record is reflected in the processing results exactly one time, even if failures occur.\n\n\nFault-tolerant distributed shared logs (such as Boki) have emerged as a storage substrate well suited for streaming workloads. Shared log systems have nodes dedicated to storage and ordering, which provide fault-tolerant storage whose bandwidth capacity scales with increasing resources. Boki supports string tags for selective reads, and string tags can implement an efficient atomic multi-stream append by a specific encoding of metadata on a single data record append. Compared to current systems that send messages to coordinate the atomic logging, using the advanced features of modern shared logs significantly reduces the cost of maintaining exactly-once semantics and subsequently the median and tail latencies for a range of workloads.\n\n\nWe built and submitted a streaming system that uses Boki and is mature enough that we can port the complete NEXMark benchmark suite. We compare the performance of it with Kafka Streams, which is an industry-leading distributed stream processing engine that uses logging for fault tolerance. Evaluation results show that our system achieves 1.3x to 5.4x lower median latency, or 1.3x to 5.0x higher saturation throughput than Kafka Streams on NEXMark workloads.\n\n\nFor the broader impact of our work, every day billions of people use applications that run in data centers. Cloud computing and the services it has enabled have transformed computing and life over the past decade. By bringing new workloads to serverless platforms, we provide necessary tools, techniques, and infrastructure to enable the continued exponential evolution and innovation for systems that rely on ML and other compute-intensive computations. All of our software is open source. Also, the work has contributed to student development and has been integrated into our teaching curriculum.\t\t\t\t\tLast Modified: 09/22/2024\n\n\t\t\t\t\tSubmitted by: EmmettWitchel\n"
 }
}