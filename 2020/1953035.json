{
 "awd_id": "1953035",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Machine Learning Theory and Algorithms for Differential Games, with Applications in Economics",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2020-08-12",
 "awd_max_amd_letter_date": "2020-08-12",
 "awd_abstract_narration": "Artificial intelligence (AI) has been applied in many scientific fields, including imaging, computer vision, and materials science. However, the study of the application of AI to differential games and economics is still in its infancy. Differential games, as an offspring of game theory and optimal control, provide the modeling and analysis of conflicts in the context of a dynamical systems. Domains of applications include management science, economics, social science, biology, and national security. One of the core objectives is to compute Nash equilibria that refer to strategies by which no player has an incentive to deviate. The research aims to break the tractability barrier in computing these Nash equilibria by using, developing, and studying appropriate Machine Learning algorithms. The project also provides research training opportunities for graduate students. \r\n\r\nA major bottleneck comes from the notorious intractability of finite-player games, which makes the direct computation of Nash equilibria extremely time-consuming and memory demanding, especially for a large number of players. The problem of efficiently and accurately computing Nash equilibria for stochastic differential games with a finite number of heterogeneous players is addressed by developing play-based Deep Neural Networks algorithms. Infinite-player games will be solved by new Reinforcement Learning algorithms developed in the context of Mean Field Game theory for competitive games and Mean Field Control theory for cooperative games. Applications to economics and finance problems such as Systemic Risk and Investment/Consumption are considered.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ruimeng",
   "pi_last_name": "Hu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ruimeng Hu",
   "pi_email_addr": "rhu@ucsb.edu",
   "nsf_id": "000791214",
   "pi_start_date": "2020-08-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jean-Pierre",
   "pi_last_name": "Fouque",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jean-Pierre Fouque",
   "pi_email_addr": "fouque@pstat.ucsb.edu",
   "nsf_id": "000281989",
   "pi_start_date": "2020-08-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Barbara",
  "inst_street_address": "3227 CHEADLE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA BARBARA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8058934188",
  "inst_zip_code": "931060001",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SANTA BARBARA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G9QBQDH39DF4"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Barbara",
  "perf_str_addr": "Rm3227 Cheadle Hall",
  "perf_city_name": "Santa Barbara",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "931063110",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project consisted of two parts:</p>\n<p>(1) Developing deep learning methods and theories for stochastic differential games with a moderate to large number of players.</p>\n<p>(2) Designing reinforcement learning algorithms in the context of Mean Field Game theory for competitive games and Mean Field Control theory for cooperative games with an infinite number of players.</p>\n<p>Applications to economic and financial problems, such as systemic risk and investment/consumption, were considered.</p>\n<p>&nbsp;</p>\n<p>Intellectual Merit:</p>\n<p>Stochastic differential games study players' strategical decision-making under uncertainty and often exhibit high dimensional features and, as a result, suffer from the curse of dimensionality (CoD). For the first part, we have succeeded in developing accurate and efficient deep-learning algorithms to mitigate the CoD when solving games when solving games involving numerous players or incorporating realistic features like delay. On the theoretical side, theoretical guarantees for the proposed methods have been provided, and novel viewpoints on why existing generative methods can perform well in high-dimensional settings have been established. So far, the team has developed machine learning theory and algorithms for stochastic control and games, mean-field games, generative models, and PDE solvers.</p>\n<p>Reinforcement Learning (RL) is a classical machine learning model-free technique where an agent interacts with an environment, and by trial-and-error improves her strategy in order to maximize the collected reward. In the second part,&nbsp; we brought the Mean Field aspect to RL to model an agent interacting with a large population of agents who tries to learn Nash equilibria in the case of competitive agents or central planner equilibria in the case of collaborating agents. We have introduced an original two-timescale RL algorithm which solves one of these two problems depending on the ratio of two learning rates, one for the action function and the other for the population distributions. Applications to finance in finite time horizon such as the trader?s liquidation problem have been studied. Subsequently, we extended our algorithm to three timescales to solve Mean Field Control Games which models competitive games between a large number of large groups of collaborative agents. The continuous space version of these algorithms led us to build actor-critic neural network algorithms.</p>\n<p><br />Broader Impacts:</p>\n<p>Games between a large number of interacting agents is a central paradigm in various research domains, ranging from finance to social networks. In the first part, the developed algorithm has been applied to controlling epidemics, resulting in an article published in the Notice of the AMS, which targets a general audience and is intended for junior Ph.D. students for educational purposes. The developed generative models can successfully address the data scarcity in financial data and privacy issues in health data, potentially advancing research in those areas. Three undergraduate students have been involved in this research project, resulting in a paper published in a top mathematical finance journal. Four graduate students have been trained, two of whom are supported by the grant. A new graduate course has been developed based on the project's outcomes.</p>\n<p>In the second part, we proposed reinforcement learning algorithms to solve these problems in model-free contexts. Several graduate students (4) have been trained in machine learning and game theory. Our research topic was a project titled 'Multiscale Reinforcement Learning Algorithms for Mean Field Control Games,' proposed by the CFMAR Undergraduate Lab, a new initiative of the Center for Financial Mathematics and Actuarial Research at UCSB, involving teams of undergraduate students mentored by graduate students and faculty. This initiative has been a valuable opportunity to train undergraduate students as well.</p>\n<p>Our results have been widely disseminated through top journal articles and machine learning conferences, and numerous talks given in seminars, workshops, or conferences.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/21/2023<br>\n\t\t\t\t\tModified by: Ruimeng&nbsp;Hu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project consisted of two parts:\n\n(1) Developing deep learning methods and theories for stochastic differential games with a moderate to large number of players.\n\n(2) Designing reinforcement learning algorithms in the context of Mean Field Game theory for competitive games and Mean Field Control theory for cooperative games with an infinite number of players.\n\nApplications to economic and financial problems, such as systemic risk and investment/consumption, were considered.\n\n \n\nIntellectual Merit:\n\nStochastic differential games study players' strategical decision-making under uncertainty and often exhibit high dimensional features and, as a result, suffer from the curse of dimensionality (CoD). For the first part, we have succeeded in developing accurate and efficient deep-learning algorithms to mitigate the CoD when solving games when solving games involving numerous players or incorporating realistic features like delay. On the theoretical side, theoretical guarantees for the proposed methods have been provided, and novel viewpoints on why existing generative methods can perform well in high-dimensional settings have been established. So far, the team has developed machine learning theory and algorithms for stochastic control and games, mean-field games, generative models, and PDE solvers.\n\nReinforcement Learning (RL) is a classical machine learning model-free technique where an agent interacts with an environment, and by trial-and-error improves her strategy in order to maximize the collected reward. In the second part,  we brought the Mean Field aspect to RL to model an agent interacting with a large population of agents who tries to learn Nash equilibria in the case of competitive agents or central planner equilibria in the case of collaborating agents. We have introduced an original two-timescale RL algorithm which solves one of these two problems depending on the ratio of two learning rates, one for the action function and the other for the population distributions. Applications to finance in finite time horizon such as the trader?s liquidation problem have been studied. Subsequently, we extended our algorithm to three timescales to solve Mean Field Control Games which models competitive games between a large number of large groups of collaborative agents. The continuous space version of these algorithms led us to build actor-critic neural network algorithms.\n\n\nBroader Impacts:\n\nGames between a large number of interacting agents is a central paradigm in various research domains, ranging from finance to social networks. In the first part, the developed algorithm has been applied to controlling epidemics, resulting in an article published in the Notice of the AMS, which targets a general audience and is intended for junior Ph.D. students for educational purposes. The developed generative models can successfully address the data scarcity in financial data and privacy issues in health data, potentially advancing research in those areas. Three undergraduate students have been involved in this research project, resulting in a paper published in a top mathematical finance journal. Four graduate students have been trained, two of whom are supported by the grant. A new graduate course has been developed based on the project's outcomes.\n\nIn the second part, we proposed reinforcement learning algorithms to solve these problems in model-free contexts. Several graduate students (4) have been trained in machine learning and game theory. Our research topic was a project titled 'Multiscale Reinforcement Learning Algorithms for Mean Field Control Games,' proposed by the CFMAR Undergraduate Lab, a new initiative of the Center for Financial Mathematics and Actuarial Research at UCSB, involving teams of undergraduate students mentored by graduate students and faculty. This initiative has been a valuable opportunity to train undergraduate students as well.\n\nOur results have been widely disseminated through top journal articles and machine learning conferences, and numerous talks given in seminars, workshops, or conferences.\n\n\t\t\t\t\tLast Modified: 09/21/2023\n\n\t\t\t\t\tSubmitted by: Ruimeng Hu"
 }
}