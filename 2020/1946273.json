{
 "awd_id": "1946273",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: Detecting Vulnerabilities and Remediations in Software Dependencies",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 499928.0,
 "awd_amount": 499928.0,
 "awd_min_amd_letter_date": "2020-08-27",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "Software is at the very center of today's society, permeating commerce, transportation, information exchange, and entertainment. Today's software is rarely written from scratch and is frequently dependent on a large ecosystem of open source libraries and tools. As a result, a single vulnerability in a library often has a cascading effect, resulting in corresponding vulnerabilities in the many software systems and applications that depend on it. The goal of this project is to aid software developers in identifying and updating vulnerable dependencies through the creation of methods that detect, measure, and remediate a software project's use of external, open source software with security flaws. As part of achieving this goal, the investigators will develop the first global vulnerable-dependency graph to characterize the problem within the broader open source ecosystem.\r\n\r\nThe creation of this global vulnerable-dependency graph depends on addressing two key research challenges. First, software dependencies exist in many forms, ranging from clear listings in package manifests to copies of external libraries added to a software project's code repository. Second, not all vulnerability fixes are announced. Developers often discover and fix vulnerabilities without issuing an announcement (or perhaps even without knowing a vulnerability was fixed). This project will address these challenges through novel application of static program analysis and text analytics. These techniques will scalably recover software dependencies, mapping both publicly known vulnerabilities as well as discovered silent vulnerability fixes to individual versions of software libraries and tools.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Enck",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "William H Enck",
   "pi_email_addr": "whenck@ncsu.edu",
   "nsf_id": "000593699",
   "pi_start_date": "2020-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Bradley",
   "pi_last_name": "Reaves",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bradley Reaves",
   "pi_email_addr": "bgreaves@ncsu.edu",
   "nsf_id": "000760088",
   "pi_start_date": "2020-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "890 Oval Dr",
  "perf_city_name": "Raleigh",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276958206",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 499928.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Intellectual Merit: </strong>The focus of this award was to aid software developers in identifying and updating <em>vulnerable dependencies</em> through the creation of methods that detect, measure, and remediate a project&rsquo;s user of external, open source software with security flaws.<br /><br />Modern software relies on dozens of packages and modules for functionality, ranging from trivial (e.g., leftpad.js) to essential (e.g., OpenSSL). External dependencies save significant development time and (in theory) reduce software flaws by establishing canonical, well-reviewed implementations of algorithms (e.g., cryptography). However, nearly all software has vulnerabilities, and when a vulnerability in an external dependency is discovered and fixed, the fix needs to be propagated to all software projects that use that dependency.<br /><br />The first thrust of this work considered the challenge of silent vulnerability fixes. When a security researcher external to a project discovers a vulnerability, a security advisory (e.g., CVE) is typically issued. However, this is not always the case when the developer of a project discovers a vulnerability. The developer may simply fix the vulnerability and move on with other changes. Our work discovered two novel methods of detecting silent fixes. The first approach, called Differential Alert Analysis (DAA), leverages the knowledge encoded by experts into static application security testing (SAST) tools to determine when a silent vulnerability fix occurs. Conceptually, the SAST tool is run on consecutive versions (or commits) of a software project, and when an alert disappears, a security fix is likely. Our work also highlights a new utility for SAST tools, which are infamous for producing a high number of false positives. Since the false positive alerts appear in both reports, DAA easily eliminates them from the results. The second approach leverages state-of-the-art machine learning techniques to discover vulnerability fixes. Specifically, we fine-tuned the CodeBERT programming language (PL) - natural language (NL) model to classify code commits to a project as a vulnerability fix or not. We showed that this technique generalizes across nine popular programming languages.<br /><br />The second thrust of this work focused on enhancing information in vulnerability databases to enable automated triage of vulnerability reports for external dependencies. State-of-the-art source composition analysis (SCA) tools are beginning to use a technique called \"reachability analysis\" to determine if the code in a given software project \"reaches\" the vulnerable code in an external dependency. This optimization has potential to significantly decrease the effort required by project maintainers when managing vulnerabilities. Unfortunately, security advisories often lack critical information needed to perform reachability analysis. We enhanced vulnerability information in two ways.<br /><br />First, most security advisories lack information about a vulnerability fixing commit (VFC), also known as a \"patch link.\" A VFC shows what parts of the code were fixed in the process of fixing a vulnerability. We proposed a novel approach called VFCFinder, which takes as input a security advisory and provides a ranked list of five possible VFCs. VFCFinder builds upon our fine-tuned CodeBERT model for classifying vulnerability fixes and extends it with other code and security advisory artifacts. VFCFinder ranks VFCs as the top candidate 80.0% of the time and within the top-5 candidates 96.6% of the time. This ranking drastically reduces human effort to identify VFCs.<br /><br />Second, even with the VFC, SCA tools performing reachability analysis need to know which functions in the code of the old version were vulnerable. There are two widely used approaches: (1) manual curation and (2) a naive automated approach that considers all changed functions in a security patch as vulnerable. The naive automated approach is widely used. Unfortunately, it is significantly flawed. Using manual annotations from the Go Vulnerability Database, we found that the naive automated approach is only correct 22% of the time.&nbsp; We then systematically evaluated how the naive approach can be augmented using generative artificial intelligence (GenAI). We systematically evaluated different models and prompting techniques, showing that GenAI techniques can surpass the naive automated approach precision by 173% (0.22 to 0.60) with only a 18% decrease in recall (0.90 to 0.74).<br /><br /><strong>Broader Impact:</strong> Our work has directly contributed to vulnerability databases. We ran DAA on Python and Java projects, discovering 237 silent vulnerabilities fixes. We contributed this vulnerability information to the Cloud Security Alliance's Global Security Database (GSD). We ran VFCFinder on security advisories in GitHub&rsquo;s Security Advisory (GHSA) database that were missing VFC information. We used VFCFinder to backfill over 300 missing VFCs, which were accepted by GitHub. Both of these data contributions aid vulnerability management by practitioners and lead to more secure software for consumers. We also publicly released our source code, datasets, and fine-tuned models for use by industry and government practitioners.</p><br>\n<p>\n Last Modified: 01/06/2025<br>\nModified by: William&nbsp;H&nbsp;Enck</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIntellectual Merit: The focus of this award was to aid software developers in identifying and updating vulnerable dependencies through the creation of methods that detect, measure, and remediate a projects user of external, open source software with security flaws.\n\nModern software relies on dozens of packages and modules for functionality, ranging from trivial (e.g., leftpad.js) to essential (e.g., OpenSSL). External dependencies save significant development time and (in theory) reduce software flaws by establishing canonical, well-reviewed implementations of algorithms (e.g., cryptography). However, nearly all software has vulnerabilities, and when a vulnerability in an external dependency is discovered and fixed, the fix needs to be propagated to all software projects that use that dependency.\n\nThe first thrust of this work considered the challenge of silent vulnerability fixes. When a security researcher external to a project discovers a vulnerability, a security advisory (e.g., CVE) is typically issued. However, this is not always the case when the developer of a project discovers a vulnerability. The developer may simply fix the vulnerability and move on with other changes. Our work discovered two novel methods of detecting silent fixes. The first approach, called Differential Alert Analysis (DAA), leverages the knowledge encoded by experts into static application security testing (SAST) tools to determine when a silent vulnerability fix occurs. Conceptually, the SAST tool is run on consecutive versions (or commits) of a software project, and when an alert disappears, a security fix is likely. Our work also highlights a new utility for SAST tools, which are infamous for producing a high number of false positives. Since the false positive alerts appear in both reports, DAA easily eliminates them from the results. The second approach leverages state-of-the-art machine learning techniques to discover vulnerability fixes. Specifically, we fine-tuned the CodeBERT programming language (PL) - natural language (NL) model to classify code commits to a project as a vulnerability fix or not. We showed that this technique generalizes across nine popular programming languages.\n\nThe second thrust of this work focused on enhancing information in vulnerability databases to enable automated triage of vulnerability reports for external dependencies. State-of-the-art source composition analysis (SCA) tools are beginning to use a technique called \"reachability analysis\" to determine if the code in a given software project \"reaches\" the vulnerable code in an external dependency. This optimization has potential to significantly decrease the effort required by project maintainers when managing vulnerabilities. Unfortunately, security advisories often lack critical information needed to perform reachability analysis. We enhanced vulnerability information in two ways.\n\nFirst, most security advisories lack information about a vulnerability fixing commit (VFC), also known as a \"patch link.\" A VFC shows what parts of the code were fixed in the process of fixing a vulnerability. We proposed a novel approach called VFCFinder, which takes as input a security advisory and provides a ranked list of five possible VFCs. VFCFinder builds upon our fine-tuned CodeBERT model for classifying vulnerability fixes and extends it with other code and security advisory artifacts. VFCFinder ranks VFCs as the top candidate 80.0% of the time and within the top-5 candidates 96.6% of the time. This ranking drastically reduces human effort to identify VFCs.\n\nSecond, even with the VFC, SCA tools performing reachability analysis need to know which functions in the code of the old version were vulnerable. There are two widely used approaches: (1) manual curation and (2) a naive automated approach that considers all changed functions in a security patch as vulnerable. The naive automated approach is widely used. Unfortunately, it is significantly flawed. Using manual annotations from the Go Vulnerability Database, we found that the naive automated approach is only correct 22% of the time. We then systematically evaluated how the naive approach can be augmented using generative artificial intelligence (GenAI). We systematically evaluated different models and prompting techniques, showing that GenAI techniques can surpass the naive automated approach precision by 173% (0.22 to 0.60) with only a 18% decrease in recall (0.90 to 0.74).\n\nBroader Impact: Our work has directly contributed to vulnerability databases. We ran DAA on Python and Java projects, discovering 237 silent vulnerabilities fixes. We contributed this vulnerability information to the Cloud Security Alliance's Global Security Database (GSD). We ran VFCFinder on security advisories in GitHubs Security Advisory (GHSA) database that were missing VFC information. We used VFCFinder to backfill over 300 missing VFCs, which were accepted by GitHub. Both of these data contributions aid vulnerability management by practitioners and lead to more secure software for consumers. We also publicly released our source code, datasets, and fine-tuned models for use by industry and government practitioners.\t\t\t\t\tLast Modified: 01/06/2025\n\n\t\t\t\t\tSubmitted by: WilliamHEnck\n"
 }
}