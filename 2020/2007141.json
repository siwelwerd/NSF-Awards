{
 "awd_id": "2007141",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Small: Representation Learning for Semantic Mapping and Safe Robot Navigation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 448515.0,
 "awd_amount": 448515.0,
 "awd_min_amd_letter_date": "2020-08-24",
 "awd_max_amd_letter_date": "2021-07-26",
 "awd_abstract_narration": "Autonomous robot systems offer tremendous potential for transforming various industry sectors, including transportation, construction, mining, and agriculture. The operational conditions in these domains, however, are unstructured and dynamically changing. This poses a major challenge for current robot system designs as they depend on static offline environment models and rigid dynamics models that do not improve with operational experience. The impact of autonomous systems in these domains is also limited by hand-designed safety rules that fail to account for the complexity and uncertainty of real-world operation. This project will develop new theoretical and algorithmic tools for advancing the ability of autonomous systems to comprehend their surroundings online from sensory observations and adapt their operation safely in response to changing conditions. On the educational front, the project aims to increase the participation of underrepresented undergraduate students in education and research activites related to robot autonomy in human environments and develop new talent in the STEM fields, which will be critical for the future of the U.S. economy.\r\n\r\nThe key innovations of the project include techniques for online inference of object shapes and robot dynamics models from sensory observations as well as control design for the learned robot dynamics, subject to safety constraints from the observed objects. First, an implicit surface model of object shape, compactly encoded with a latent feature vector is proposed. An online optimization algorithm to estimate the object poses, shapes, and robot motion jointly is developed. This algorithm enables semantic environment understanding and specification of safety constraints for autonomous navigation. Second, the spectral properties of the Koopman operator and the versatility of Bayesian neural networks are leveraged to design self-supervised robot dynamics learning algorithms. These algorithms provide an adaptive way of estimating robot dynamics from online data, while relying on approximation error bounds to guarantee that the control design satisfies the safety constraints provided by the perceptual system. These innovations will enable autonomous robot operation in unknown environments that is adaptable, due to the use of learned robot and object models, and safe, due to the use of perception- and uncertainty-aware constraints in the control design.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nikolay",
   "pi_last_name": "Atanasov",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Nikolay A Atanasov",
   "pi_email_addr": "natanasov@ucsd.edu",
   "nsf_id": "000739678",
   "pi_start_date": "2020-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jorge",
   "pi_last_name": "Cortes",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jorge Cortes",
   "pi_email_addr": "cortes@ucsd.edu",
   "nsf_id": "000302793",
   "pi_start_date": "2020-08-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 Gilman Drive",
  "perf_city_name": "La Jolla",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930403",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 161787.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 286728.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-f46e2f5d-7fff-4da9-d2b1-e9ff82271b76\"> </span></p>\r\n<p dir=\"ltr\"><span>There is enormous visibility surrounding robot autonomy as unmanned mobile robots hold the potential to shape the future of transportation, agriculture, mining, construction, security, and environmental sustainability. The impact of autonomous systems in these domains, however, depends critically on their ability to understand their environment and adapt safely to changing operational conditions. This project considered three important elements for achieving safe resilient robot autonomy:&nbsp; (1) understanding environments based on onboard sensing, (2) learning robot motion capabilities from data, and (3) synthesising safe robot actions, taking uncertainty in the environment and robot models into account.</span></p>\r\n<p dir=\"ltr\"><span>Related to environment understanding, a major achievement of the project is the development of signed distance functions (SDF) and signed directional distance function (SDDF) representations for modeling object shape and environment geometry. These functions return the distance to an object surface from a desired position or position and direction. Once learned from sensor data, such models allow fast collision detection and fast prediction of occlusion in partially known environments, which are critical aspects for imposing safety and visibility constraints in autonomous robot navigation.&nbsp;</span></p>\r\n<p dir=\"ltr\"><span>Related to robot modeling, a major achievement of the project is the development of Koopman operator techniques for analyzing the behavior of nonlinear dynamical systems and for synthesizing control strategies for autonomous robot navigation. </span><span>The Koopman operator is a characterization of the behavior of a dynamical system in the space of system output (e.g., robot positions). Regardless whether the system model is linear or nonlinear, the associated Koopman operator is always linear, which enables the use of simple and computationally efficient analysis and design tools from linear systems theory. The project developed techniques for constructing Koopman-operator-based system models from sensor data and for quantifying the accuracy and expressiveness of the resulting model.&nbsp;</span></p>\r\n<p dir=\"ltr\"><span>Related to synthesizing safe robot actions, </span><span>the project introduced a novel combination of Reference Governor (RG) techniques and Control Barrier Functions (CBFs) to guarantee joint safety and stability in robotic systems. Traditional control approaches often struggle to balance these two objectives, particularly in the presence of dynamic obstacles. The RG method ensures that the robot maintains stability while adaptively adjusting its reference trajectory to remain within a safe region. By integrating CBF-based constraints into the RG framework, the control synthesis method ensures real-time responsiveness to environmental changes, enabling robots to safely navigate in complex and unstructured environments.</span></p>\r\n<p dir=\"ltr\"><span>A significant challenge in deploying safe control policies in real-world scenarios is the presence of uncertainty due to sensor noise, model inaccuracies, and external disturbances. To address this, the project developed a distributionally robust formulation of safety and stability constraints, which accounts for these uncertainties explicitly. The developed Distributionally Robust Control Barrier Function (DR-CBF) approach ensures that safety constraints remain valid even under uncertain state estimations, thereby improving the robustness of autonomous robot navigation in real-world conditions. This formulation enables the robot to make safety-critical decisions with quantifiable confidence, significantly enhancing reliability in dynamic and unpredictable environments.</span></p>\r\n<p dir=\"ltr\"><span>The project provided theoretical analysis of the feasibility, regularity, and boundedness properties of distributionally robust safe stabilizing controllers. The research established necessary and sufficient conditions for the solvability of control synthesis problems with distributionally robust constraints, contributing to a deeper understanding of their computational complexity and stability guarantees. Additionally, the project characterized the conditions under which discontinuities in CBF-based controllers arise and provided methods to ensure bounded control inputs. These insights are crucial for designing controllers that are both effective and computationally efficient, making them suitable for real-time deployment in robotic applications.</span></p>\r\n<p dir=\"ltr\"><span>To validate these theoretical developments, the project successfully demonstrated safe mobile robot autonomous navigation in unstructured environments with dynamic obstacles. Real-world experiments showcased the effectiveness of the developed algorithms in navigating cluttered spaces, avoiding pedestrians, and adapting to unexpected environmental changes. The experimental results not only confirmed the practicality of the proposed approaches but also provided valuable insights for future improvements and real-world deployments.</span></p>\r\n<p dir=\"ltr\"><span>Beyond research contributions, the project also had a significant impact on education and outreach. It provided hands-on research experiences to PhD, MS, and undergraduate students, fostering the development of future experts in robotics, control, and AI. Additionally, it engaged underrepresented students through structured mentoring programs, ensuring broader participation in STEM research.</span></p>\r\n<p dir=\"ltr\"><span>In conclusion, this project has advanced the state of the art in safe autonomous robot navigation by developing novel shape representation models, novel robot dynamics identification techniques, and novel robust control techniques with safety guarantees. The combination of theoretical insights, algorithmic innovations, and real-world demonstrations has laid a strong foundation for the deployment of safe and intelligent autonomous robot systems in dynamic and unstructured environments.</span></p>\r\n<p dir=\"ltr\"><span><br /></span></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/03/2025<br>\nModified by: Nikolay&nbsp;A&nbsp;Atanasov</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738572012603_Figure1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738572012603_Figure1--rgov-800width.jpg\" title=\"Object shape reconstruction\"><img src=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738572012603_Figure1--rgov-66x44.jpg\" alt=\"Object shape reconstruction\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Object shape reconstruction from point cloud data. a) Point cloud observations obtained from depth camera images b) Reconstructed object meshes using signed distance function prediction</div>\n<div class=\"imageCredit\">Mo Shan and Nikolay Atanasov</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Nikolay&nbsp;A&nbsp;Atanasov\n<div class=\"imageTitle\">Object shape reconstruction</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738574138425_Figure3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738574138425_Figure3--rgov-800width.jpg\" title=\"Control barrier function\"><img src=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738574138425_Figure3--rgov-66x44.jpg\" alt=\"Control barrier function\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A simulated robot (cyan triangle) navigates an environment with three elliptical obstacles (orange, blue, green) using a control barrier function to impose safety constraints.</div>\n<div class=\"imageCredit\">Kehan Long and Nikolay Atanasov</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Nikolay&nbsp;A&nbsp;Atanasov\n<div class=\"imageTitle\">Control barrier function</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738573091293_Figure2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738573091293_Figure2--rgov-800width.jpg\" title=\"Simultaneous robot localization and object mapping\"><img src=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738573091293_Figure2--rgov-66x44.jpg\" alt=\"Simultaneous robot localization and object mapping\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Simultaneous robot localization and object mapping in a lab environment. A racecar robot (right) tracks chair semantic keypoints (colored dots on the top left) to estimate its trajectory (localization) and recover the chair positions and orientations (blue ellipsoids in middle plot).</div>\n<div class=\"imageCredit\">Mo Shan and Nikolay Atanasov</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Nikolay&nbsp;A&nbsp;Atanasov\n<div class=\"imageTitle\">Simultaneous robot localization and object mapping</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738573445305_Figure4--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738573445305_Figure4--rgov-800width.png\" title=\"Safe mobile robot navigation in unknown environments\"><img src=\"/por/images/Reports/POR/2025/2007141/2007141_10701149_1738573445305_Figure4--rgov-66x44.png\" alt=\"Safe mobile robot navigation in unknown environments\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Real-world safe mobile robot navigation in unknown environments containing both static and dynamic obstacles. A Jackal robot uses onboard camera and LiDAR measurements to formulate control barrier function constrains for synthesizing safe control actions.</div>\n<div class=\"imageCredit\">Zhichao Li, Kehan Long, Yinzhuang Yi, Jorge Cortes, Nikolay Atanasov</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Nikolay&nbsp;A&nbsp;Atanasov\n<div class=\"imageTitle\">Safe mobile robot navigation in unknown environments</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\n \r\n\n\nThere is enormous visibility surrounding robot autonomy as unmanned mobile robots hold the potential to shape the future of transportation, agriculture, mining, construction, security, and environmental sustainability. The impact of autonomous systems in these domains, however, depends critically on their ability to understand their environment and adapt safely to changing operational conditions. This project considered three important elements for achieving safe resilient robot autonomy: (1) understanding environments based on onboard sensing, (2) learning robot motion capabilities from data, and (3) synthesising safe robot actions, taking uncertainty in the environment and robot models into account.\r\n\n\nRelated to environment understanding, a major achievement of the project is the development of signed distance functions (SDF) and signed directional distance function (SDDF) representations for modeling object shape and environment geometry. These functions return the distance to an object surface from a desired position or position and direction. Once learned from sensor data, such models allow fast collision detection and fast prediction of occlusion in partially known environments, which are critical aspects for imposing safety and visibility constraints in autonomous robot navigation.\r\n\n\nRelated to robot modeling, a major achievement of the project is the development of Koopman operator techniques for analyzing the behavior of nonlinear dynamical systems and for synthesizing control strategies for autonomous robot navigation. The Koopman operator is a characterization of the behavior of a dynamical system in the space of system output (e.g., robot positions). Regardless whether the system model is linear or nonlinear, the associated Koopman operator is always linear, which enables the use of simple and computationally efficient analysis and design tools from linear systems theory. The project developed techniques for constructing Koopman-operator-based system models from sensor data and for quantifying the accuracy and expressiveness of the resulting model.\r\n\n\nRelated to synthesizing safe robot actions, the project introduced a novel combination of Reference Governor (RG) techniques and Control Barrier Functions (CBFs) to guarantee joint safety and stability in robotic systems. Traditional control approaches often struggle to balance these two objectives, particularly in the presence of dynamic obstacles. The RG method ensures that the robot maintains stability while adaptively adjusting its reference trajectory to remain within a safe region. By integrating CBF-based constraints into the RG framework, the control synthesis method ensures real-time responsiveness to environmental changes, enabling robots to safely navigate in complex and unstructured environments.\r\n\n\nA significant challenge in deploying safe control policies in real-world scenarios is the presence of uncertainty due to sensor noise, model inaccuracies, and external disturbances. To address this, the project developed a distributionally robust formulation of safety and stability constraints, which accounts for these uncertainties explicitly. The developed Distributionally Robust Control Barrier Function (DR-CBF) approach ensures that safety constraints remain valid even under uncertain state estimations, thereby improving the robustness of autonomous robot navigation in real-world conditions. This formulation enables the robot to make safety-critical decisions with quantifiable confidence, significantly enhancing reliability in dynamic and unpredictable environments.\r\n\n\nThe project provided theoretical analysis of the feasibility, regularity, and boundedness properties of distributionally robust safe stabilizing controllers. The research established necessary and sufficient conditions for the solvability of control synthesis problems with distributionally robust constraints, contributing to a deeper understanding of their computational complexity and stability guarantees. Additionally, the project characterized the conditions under which discontinuities in CBF-based controllers arise and provided methods to ensure bounded control inputs. These insights are crucial for designing controllers that are both effective and computationally efficient, making them suitable for real-time deployment in robotic applications.\r\n\n\nTo validate these theoretical developments, the project successfully demonstrated safe mobile robot autonomous navigation in unstructured environments with dynamic obstacles. Real-world experiments showcased the effectiveness of the developed algorithms in navigating cluttered spaces, avoiding pedestrians, and adapting to unexpected environmental changes. The experimental results not only confirmed the practicality of the proposed approaches but also provided valuable insights for future improvements and real-world deployments.\r\n\n\nBeyond research contributions, the project also had a significant impact on education and outreach. It provided hands-on research experiences to PhD, MS, and undergraduate students, fostering the development of future experts in robotics, control, and AI. Additionally, it engaged underrepresented students through structured mentoring programs, ensuring broader participation in STEM research.\r\n\n\nIn conclusion, this project has advanced the state of the art in safe autonomous robot navigation by developing novel shape representation models, novel robot dynamics identification techniques, and novel robust control techniques with safety guarantees. The combination of theoretical insights, algorithmic innovations, and real-world demonstrations has laid a strong foundation for the deployment of safe and intelligent autonomous robot systems in dynamic and unstructured environments.\r\n\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 02/03/2025\n\n\t\t\t\t\tSubmitted by: NikolayAAtanasov\n"
 }
}