{
 "awd_id": "1948244",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: SaTC: Automatic Generation of API to Natural Language Data Type Mappings for Developer and End User Privacy Risk Mitigation",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2020-03-15",
 "awd_exp_date": "2024-02-29",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 183000.0,
 "awd_min_amd_letter_date": "2020-03-25",
 "awd_max_amd_letter_date": "2021-05-19",
 "awd_abstract_narration": "Since the advent of the smart phone, an increasing amount of the population has gained access to Internet-accessible software applications (apps). This, coupled with the various sensors available on mobile devices, make the general public highly susceptible to privacy risks as sensitive information (e.g., location, camera images, biometrics) may be leaked to the Internet. To help users make informed decisions about the potential privacy risks in using apps, regulators increasingly require app developers to include privacy policies communicating what information is collected or shared and how that information is used. However, even when such privacy policies are present, trust must be put in the app developers to adhere to the promises therein. Furthermore, developers are accountable for their adherence to their policies and must be confident that their privacy policies accurately represent their practices. This project aims to assist both developers and general app users in verifying the alignment of privacy policies and the apps they represent by producing an automated process for linking the semantics of language used in privacy policies with the code used to produce the apps themselves. Furthermore, the project will use this framework to generate tools for end users and developers to directly benefit from this work.\r\n\r\nThe research project aims to produce an automated process for generating mappings between code-level APIs and natural language data types using machine learning. The resulting mappings will be utilized in developer and end user tools to identify and help mitigate potential privacy leakage during development and app usage. The current state of misalignment detection between privacy policies and app code requires the manual generation of mappings from code-level Application Program Interface (API) methods to privacy-oriented natural language data types. Even for small app categories, this process can require a human to review thousands of methods and hundreds of annotations resulting in potential for inaccuracies due to fatigue and incomplete domain knowledge. APIs also change as methods are introduced and deprecated resulting in outdated mappings. These problems make it difficult to apply the framework practically as the environment continually evolves. This project will address these challenges through two contributions. First, machine learning will be applied to the mapping generation process to produce an automated, scalable method for generating code-phrase mappings for APIs as needed. This will allow for misalignment detection for API levels, methods, and app categories beyond those build in previous contributions. This automated approach will make use of a state-of-the-art pre-trained language models to detect semantic similarity between API documentation and natural language data types used in privacy policies. Second, the resulting mappings from the automated model will be applied to practical developer and end user tools to enable informed decision for privacy risk mitigation. The PoliDroid tool suite will be developed including a developer-oriented integrated developer environment plugin which detects potential unintended privacy leaks based on a privacy policy and a real-time misalignment detection tool for end users.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rocky",
   "pi_last_name": "Slavin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rocky Slavin",
   "pi_email_addr": "rocky.slavin@utsa.edu",
   "nsf_id": "000808090",
   "pi_start_date": "2020-03-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at San Antonio",
  "inst_street_address": "1 UTSA CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SAN ANTONIO",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "2104584340",
  "inst_zip_code": "782491644",
  "inst_country_name": "United States",
  "cong_dist_code": "20",
  "st_cong_dist_code": "TX20",
  "org_lgl_bus_name": "THE UNIVERSITY OF TEXAS AT SAN ANTONIO",
  "org_prnt_uei_num": "U44ZMVYU52U6",
  "org_uei_num": "U44ZMVYU52U6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at San Antonio",
  "perf_str_addr": "One UTSA Circle",
  "perf_city_name": "San Antonio",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "782491644",
  "perf_ctry_code": "US",
  "perf_cong_dist": "20",
  "perf_st_cong_dist": "TX20",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 175000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aimed to close the gap between what mobile apps say in their privacy policies and what they actually do with user data, especially focusing on Android apps. The overarching aim was to develop automated methods for mapping domain-specific natural language data types used in privacy policies to Android API methods used in application source code. This endeavor was motivated by the need to verify the consistency and truthfulness of privacy policies regarding the data practices of mobile applications.</p>\n<p><strong>Year 1: Laying the Foundation</strong></p>\n<p>Initially, the project focused on identifying specific parts of app code known as API sources and sinks. These are essentially points where data can enter (source) or leave (sink) the app. Identifying these points helps in pinpointing where data might be collected or shared without clear disclosure in the app's privacy policy. &nbsp;The creation of two source/sink annotations was a major activity, aiming to train a machine learning classifier for automatic mapping generation. This effort resulted in the development of tools and models that significantly improved the accuracy of source and sink classification over existing state-of-the-art solutions. The success of these developments promised to simplify the application of natural-language-based privacy analysis tools across various API versions, potentially increasing their adoption outside research contexts.</p>\n<p><strong>Subsequent Years: Refinement and Expansion</strong></p>\n<p>Over the next two years, the project evolved to include the development of a refined approach for identifying app API leaks and their alignment with privacy policies, leveraging large language models (LLMs). A notable advancement was the creation of a policy-app dataset consisting of 200 Android apps and their corresponding policies. This dataset facilitated several experiments aimed at evaluating the effectiveness of LLMs in extracting data practices from privacy policies. The project's focus on leveraging LLMs for mapping API methods to privacy policy language represented a novel approach to bridging the semantic gap between the technical functionalities of apps and their described data practices.</p>\n<p><strong>Final Year: Breakthroughs and Achievements</strong></p>\n<p>In the final year, the project achieved significant milestones, including the development of an automated method for identifying consistency between policy and code, which was not the initial specific objective but a highly desired outcome. This success underscored the project's ability to adapt and leverage recent advancements in LLMs and other methodologies to directly address the problem of policy misalignment.&nbsp;</p>\n<p><strong>Intellectual Merit and Broader Impacts</strong></p>\n<p>The intellectual merit of this project lies in its innovative approach to addressing the complex challenge of aligning privacy policies with the actual data practices of mobile applications. By leveraging LLMs and developing automated methods for mapping domain-specific natural language data types to Android API methods, the project has significantly advanced the state of the art in privacy analysis tools. This work not only enhances the accuracy and efficiency of identifying privacy policy and app code misalignments but also contributes to the generalizability of privacy analysis across various API versions. Such advancements deepen our understanding of the semantic gap between natural language and application code, paving the way for future research in privacy protection technologies.&nbsp;</p>\n<p>The project's impact extends beyond academic contributions, aiming to facilitate the adoption of privacy risk mitigation frameworks from research to industry. The development of tools and methods for privacy policy and code alignment has the potential to reduce privacy risks and increase trust among end users.The broader impacts of the project are manifold, extending its benefits beyond the academic domain to societal welfare. By developing tools and methodologies that can be adopted by the industry, the project contributes to the reduction of privacy risks and the enhancement of trust among end users of mobile applications. Furthermore, the project's emphasis on training and professional development has fostered a new generation of researchers equipped with the skills and knowledge to tackle privacy-related challenges. The dissemination of research findings through conferences and publications, combined with the direct application of project outcomes in industry practices, exemplifies the project's commitment to advancing both science and society through innovation in privacy protection.</p>\n<p>This comprehensive four-year project not only advanced the technical understanding and methodologies for assessing privacy policy and app code alignment but also contributed to the training and development of new researchers in the field. Its outcomes are poised to influence both academic research and industry practices, underlining the project's significance in the broader context of privacy protection in the digital age.<strong>&nbsp;</strong></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/29/2024<br>\nModified by: Rocky&nbsp;Slavin</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project aimed to close the gap between what mobile apps say in their privacy policies and what they actually do with user data, especially focusing on Android apps. The overarching aim was to develop automated methods for mapping domain-specific natural language data types used in privacy policies to Android API methods used in application source code. This endeavor was motivated by the need to verify the consistency and truthfulness of privacy policies regarding the data practices of mobile applications.\n\n\nYear 1: Laying the Foundation\n\n\nInitially, the project focused on identifying specific parts of app code known as API sources and sinks. These are essentially points where data can enter (source) or leave (sink) the app. Identifying these points helps in pinpointing where data might be collected or shared without clear disclosure in the app's privacy policy. The creation of two source/sink annotations was a major activity, aiming to train a machine learning classifier for automatic mapping generation. This effort resulted in the development of tools and models that significantly improved the accuracy of source and sink classification over existing state-of-the-art solutions. The success of these developments promised to simplify the application of natural-language-based privacy analysis tools across various API versions, potentially increasing their adoption outside research contexts.\n\n\nSubsequent Years: Refinement and Expansion\n\n\nOver the next two years, the project evolved to include the development of a refined approach for identifying app API leaks and their alignment with privacy policies, leveraging large language models (LLMs). A notable advancement was the creation of a policy-app dataset consisting of 200 Android apps and their corresponding policies. This dataset facilitated several experiments aimed at evaluating the effectiveness of LLMs in extracting data practices from privacy policies. The project's focus on leveraging LLMs for mapping API methods to privacy policy language represented a novel approach to bridging the semantic gap between the technical functionalities of apps and their described data practices.\n\n\nFinal Year: Breakthroughs and Achievements\n\n\nIn the final year, the project achieved significant milestones, including the development of an automated method for identifying consistency between policy and code, which was not the initial specific objective but a highly desired outcome. This success underscored the project's ability to adapt and leverage recent advancements in LLMs and other methodologies to directly address the problem of policy misalignment.\n\n\nIntellectual Merit and Broader Impacts\n\n\nThe intellectual merit of this project lies in its innovative approach to addressing the complex challenge of aligning privacy policies with the actual data practices of mobile applications. By leveraging LLMs and developing automated methods for mapping domain-specific natural language data types to Android API methods, the project has significantly advanced the state of the art in privacy analysis tools. This work not only enhances the accuracy and efficiency of identifying privacy policy and app code misalignments but also contributes to the generalizability of privacy analysis across various API versions. Such advancements deepen our understanding of the semantic gap between natural language and application code, paving the way for future research in privacy protection technologies.\n\n\nThe project's impact extends beyond academic contributions, aiming to facilitate the adoption of privacy risk mitigation frameworks from research to industry. The development of tools and methods for privacy policy and code alignment has the potential to reduce privacy risks and increase trust among end users.The broader impacts of the project are manifold, extending its benefits beyond the academic domain to societal welfare. By developing tools and methodologies that can be adopted by the industry, the project contributes to the reduction of privacy risks and the enhancement of trust among end users of mobile applications. Furthermore, the project's emphasis on training and professional development has fostered a new generation of researchers equipped with the skills and knowledge to tackle privacy-related challenges. The dissemination of research findings through conferences and publications, combined with the direct application of project outcomes in industry practices, exemplifies the project's commitment to advancing both science and society through innovation in privacy protection.\n\n\nThis comprehensive four-year project not only advanced the technical understanding and methodologies for assessing privacy policy and app code alignment but also contributed to the training and development of new researchers in the field. Its outcomes are poised to influence both academic research and industry practices, underlining the project's significance in the broader context of privacy protection in the digital age.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 03/29/2024\n\n\t\t\t\t\tSubmitted by: RockySlavin\n"
 }
}