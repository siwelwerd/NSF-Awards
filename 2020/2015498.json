{
 "awd_id": "2015498",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Scalable Algorithms for Bayesian On-Line Learning with Large-Scale Dynamic Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-08-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2020-06-20",
 "awd_max_amd_letter_date": "2020-06-20",
 "awd_abstract_narration": "Bayesian methods provide a principled way for assessing model uncertainty in machine learning of big data, which is critical to the development of trustworthy artificial intelligence (AI). However, the lack of efficient Monte Carlo algorithms has drastically hindered applications of Bayesian methods in the big data era. Compared to frequentist methods, Bayesian methods are often much slower. To tackle this difficulty, a variety of scalable Monte Carlo algorithms have been developed in the recent literature. However, these algorithms can only be applied to static data; none of them can be directly applied to dynamic data.  Many of the problems centering data science, such as natural language processing, autonomous car driving and weather forecasting, are facing challenges of dynamic data. The traditional particle filters or sequential Monte Carlo algorithms lack the scalability necessary for dealing with large-scale dynamic data. By reformulating the ensemble Kalman filter (EnKF) under the framework of Langevin dynamics, this project proposes Langevinized EnKF as a general and scalable stochastic gradient sequential Monte Carlo algorithm for Bayesian on-line learning with large-scale dynamic data. The Langevinized EnKF improves uncertainty quantification for a wide class of data assimilation problems, advancing the development of trustworthy AI. Successful completion of this project will generate a set of scalable and theoretically rigorous algorithms for Bayesian on-line learning, which can provide significant benefits to the development of data driven technologies. The research results will be disseminated to communities of interest via collaborations, publications, and conference presentations. The project will also have significant impacts on education through direct involvement of graduate students and incorporation of the research results into undergraduate and graduate courses. \r\n\r\nAlthough the EnKF has been extremely successful in dealing with complex dynamic data encountered in  oceanography, reservoir modeling and weather forecasting, it does not converge to the right filtering distribution except for linear systems in the large ensemble limit. The Langevinized EnKF resolves this issue; it converges to the right filtering distribution in data assimilation and is thus able to quantify uncertainty of the underlying dynamic system. The Langevinized EnKF can also be used for Bayesian learning with large-scale statistic data by reformulating the Bayesian inverse problem as a state-space model with Langevin dynamics and the subsampling technique. Different variants of the Langevinized EnKF will be developed to extend its applications to non-Gaussian data and incomplete data. As the whole, this project will provide a complete treatment for Bayesian analysis of big data. The Langevinized EnKF can be applied to big data problems in various data scenarios: dynamic data and static data, Gaussian data and non-Gaussian data, and complete data and incomplete data,  provided the data is classified in different ways. Statistical theory underlying the Langevinized EnKF will be rigorously studied. Exciting scientific applications, including language modeling and dynamic network analysis, will be conducted.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Faming",
   "pi_last_name": "Liang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Faming Liang",
   "pi_email_addr": "fmliang@purdue.edu",
   "nsf_id": "000490214",
   "pi_start_date": "2020-06-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "PURDUE UNIVERSITY",
  "perf_str_addr": "250 N. University St.",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072114",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "059Z",
   "pgm_ref_txt": "Science of Learning"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Bayesian analysis provides a principled approach to assessing model uncertainty, which is essential for developing safe and trustworthy artificial intelligence (AI) in machine learning for big data. In recent years, many scalable Bayesian algorithms, such as those based on stochastic gradients and split-and-merge strategies, have been developed. However, these algorithms primarily address static data and are challenging to adapt for dynamic data. Dynamic systems, on the other hand, are a significant source of big data in modern data science. Many important applications, such as autonomous driving and weather forecasting, generate large-scale dynamic data. Traditional particle filtering algorithms lack the scalability needed to handle such data effectively. Developing scalable Bayesian online learning algorithms for dynamic data presents a significant challenge to the statistical community. <br /><br /><br />In this project, the PI and students reformulate the ensemble Kalman filter (EnKF) within the framework of Langevin dynamics, resulting in a new particle filtering algorithm --- Langevinized EnKF (LEnKF). The LEnKF algorithm has been shown to converge to the correct filtering distribution in data assimilation, while achieving accelerated execution through its adoption of the forecast-analysis procedure from the EnKF algorithm and the mini-batch strategy from stochastic gradient Markov chain Monte Carlo algorithms. The LEnKF algorithm is not only scalable with respect to state dimension and sample size but also tends to resist sample degeneracy for long-series dynamic data, making it highly effective for uncertainty quantification of dynamic systems with large-scale data. The LEnKF algorithm has been extended to various scenarios, including those where the dynamic system is non-Gaussian, non-linear, and involves unknown parameters. As practical applications, the LEnKF algorithm has been successfully used in dynamic network embedding and identifying factors that impact on the transmission and mortality of COVID-19. Recently, the LEnKF algorithm has also been adapted to reinforcement learning, allowing users to quantify uncertainties associated with the value function and model parameters and to monitor these uncertainties during policy updates throughout the training phase. This paves the way for more robust and adaptable reinforcement learning.<br /><br />This project has developed a set of scalable and theoretically rigorous tools for modeling large-scale dynamic data, with significant potential to advance data-driven technologies. Specifically, the LEnKF algorithm improves uncertainty quantification for underlying dynamic systems in Bayesian online learning, supporting the development of safe and trustworthy artificial intelligence (AI). Research findings have been disseminated to relevant communities through collaborations, publications, and conference presentations.</p><br>\n<p>\n Last Modified: 10/31/2024<br>\nModified by: Faming&nbsp;Liang</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nBayesian analysis provides a principled approach to assessing model uncertainty, which is essential for developing safe and trustworthy artificial intelligence (AI) in machine learning for big data. In recent years, many scalable Bayesian algorithms, such as those based on stochastic gradients and split-and-merge strategies, have been developed. However, these algorithms primarily address static data and are challenging to adapt for dynamic data. Dynamic systems, on the other hand, are a significant source of big data in modern data science. Many important applications, such as autonomous driving and weather forecasting, generate large-scale dynamic data. Traditional particle filtering algorithms lack the scalability needed to handle such data effectively. Developing scalable Bayesian online learning algorithms for dynamic data presents a significant challenge to the statistical community. \n\n\nIn this project, the PI and students reformulate the ensemble Kalman filter (EnKF) within the framework of Langevin dynamics, resulting in a new particle filtering algorithm --- Langevinized EnKF (LEnKF). The LEnKF algorithm has been shown to converge to the correct filtering distribution in data assimilation, while achieving accelerated execution through its adoption of the forecast-analysis procedure from the EnKF algorithm and the mini-batch strategy from stochastic gradient Markov chain Monte Carlo algorithms. The LEnKF algorithm is not only scalable with respect to state dimension and sample size but also tends to resist sample degeneracy for long-series dynamic data, making it highly effective for uncertainty quantification of dynamic systems with large-scale data. The LEnKF algorithm has been extended to various scenarios, including those where the dynamic system is non-Gaussian, non-linear, and involves unknown parameters. As practical applications, the LEnKF algorithm has been successfully used in dynamic network embedding and identifying factors that impact on the transmission and mortality of COVID-19. Recently, the LEnKF algorithm has also been adapted to reinforcement learning, allowing users to quantify uncertainties associated with the value function and model parameters and to monitor these uncertainties during policy updates throughout the training phase. This paves the way for more robust and adaptable reinforcement learning.\n\nThis project has developed a set of scalable and theoretically rigorous tools for modeling large-scale dynamic data, with significant potential to advance data-driven technologies. Specifically, the LEnKF algorithm improves uncertainty quantification for underlying dynamic systems in Bayesian online learning, supporting the development of safe and trustworthy artificial intelligence (AI). Research findings have been disseminated to relevant communities through collaborations, publications, and conference presentations.\t\t\t\t\tLast Modified: 10/31/2024\n\n\t\t\t\t\tSubmitted by: FamingLiang\n"
 }
}