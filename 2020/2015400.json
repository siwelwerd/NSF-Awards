{
 "awd_id": "2015400",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Black-Box Science:  Ideas and Insights for Learning-Based Statistical Inference",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 160000.0,
 "awd_amount": 160000.0,
 "awd_min_amd_letter_date": "2020-06-26",
 "awd_max_amd_letter_date": "2022-06-27",
 "awd_abstract_narration": "This project seeks to develop essential tools that will allow scientists to better harness the full power of machine learning in practical scientific settings. In the current era of big data, machine learning algorithms have set themselves apart as excellent, accurate tools for modeling complex systems and predicting future outcomes. Determining why those particular algorithms actually work and how those predictions are generated has proven to be a much greater challenge, yet understanding these aspects is crucial for practical scientific use. For example, if an algorithm predicts that you are at risk for a particular disease, you will instinctively care less about the exact percentage chance you have of getting it and much more about why you are more likely to get it and whether there is something you could do to prevent getting it. This work will develop tools that allow scientists to more easily determine which variables most affect an algorithm's performance and whether some other collection of variables might offer an alternative but equally accurate explanation for the outcomes predicted. Various components of these algorithms will also be explored mathematically to determine whether some of them can be borrowed and inserted into simpler models in order to obtain predictions that are not only more accurate, but are also more easily explainable.\r\n\r\nThis project seeks to develop efficient means of statistical inference within a machine learning context with an emphasis on random forests in particular. Specifically, a computationally efficient hypothesis test will be developed that allows for p-values for feature importance to be calculated with similar effort to the original algorithm. In addition to these tests, a framework for characterizing the uncertainty in the model selection process itself will be developed to provide insights into not just the optimal model obtained, but also to illustrate how many alternative models may exist with similar predictive power. Finally, an in-depth study on the fundamental role of randomness in supervised learning ensembles will be undertaken. Lessons learned about the helpful effects of such randomness will be utilized to boost performance of more traditional models in appropriate settings.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lucas",
   "pi_last_name": "Mentch",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Lucas K Mentch",
   "pi_email_addr": "lkm31@pitt.edu",
   "nsf_id": "000710108",
   "pi_start_date": "2020-06-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pittsburgh",
  "inst_street_address": "4200 FIFTH AVENUE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4126247400",
  "inst_zip_code": "152600001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "UNIVERSITY OF PITTSBURGH - OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "MKAGLD59JRL1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pittsburgh",
  "perf_str_addr": "University Club",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152132303",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 57536.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 59066.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 43398.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The high-level goal of this project was to develop tools to help bridge the gap between machine learning and classical statistical analyses.&nbsp; Two of the three aims focused on a particular learning algorithm &ndash; random forests &ndash; and sought to both better understand the inner workings of these procedures as well as to develop analytical tools for analyzing their performance.&nbsp; Understanding the role of randomness in random forests provided insight into when these methods might work well and also suggested alternative methods that had not been proposed.&nbsp; Learning methods like random forests are traditionally seen as &ldquo;black boxes&rdquo; &ndash; algorithms that may produce accurate predictions but are often very difficult to audit and examine how those predictions were generated.&nbsp; Our work in the first two aims mitigates this issue. The third aim in this project focused on the idea of model set selection &ndash; finding entire sets of good models rather than only a single optimal model.&nbsp; This will help to give scientists a broader perspective on their findings as each model can be seen as an alternative explanation of the underlying phenomena.&nbsp; In total, our work produced a total of six scientific publications appearing in top-tier journals and was presented at numerous conferences both in the United States, as well as in the United Kingdom and Italy.&nbsp; Four different graduate students were involved in various aspects of the work and each had an opportunity to contribute to publications and present at conferences.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 08/26/2024<br>\nModified by: Lucas&nbsp;K&nbsp;Mentch</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe high-level goal of this project was to develop tools to help bridge the gap between machine learning and classical statistical analyses. Two of the three aims focused on a particular learning algorithm  random forests  and sought to both better understand the inner workings of these procedures as well as to develop analytical tools for analyzing their performance. Understanding the role of randomness in random forests provided insight into when these methods might work well and also suggested alternative methods that had not been proposed. Learning methods like random forests are traditionally seen as black boxes  algorithms that may produce accurate predictions but are often very difficult to audit and examine how those predictions were generated. Our work in the first two aims mitigates this issue. The third aim in this project focused on the idea of model set selection  finding entire sets of good models rather than only a single optimal model. This will help to give scientists a broader perspective on their findings as each model can be seen as an alternative explanation of the underlying phenomena. In total, our work produced a total of six scientific publications appearing in top-tier journals and was presented at numerous conferences both in the United States, as well as in the United Kingdom and Italy. Four different graduate students were involved in various aspects of the work and each had an opportunity to contribute to publications and present at conferences.\n\n\n\t\t\t\t\tLast Modified: 08/26/2024\n\n\t\t\t\t\tSubmitted by: LucasKMentch\n"
 }
}