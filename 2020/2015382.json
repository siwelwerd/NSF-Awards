{
 "awd_id": "2015382",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Capturing Salient Features in Point Process Models via Stochastic Process Discrepancies",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 104215.0,
 "awd_amount": 104215.0,
 "awd_min_amd_letter_date": "2020-06-25",
 "awd_max_amd_letter_date": "2020-06-25",
 "awd_abstract_narration": "In the 21st century, mathematical modeling has emerged as a primary tool for scientific investigation.  Scientists construct mathematical and computer models intended to capture the important features of a complex physical phenomenon, and learn more about the phenomenon by exploring what values of any uncertain model parameters lead to model predictions that mimic closely what is observed in nature.  Still, at best the models typically cannot capture all of nature's complexity \u2013 or, as George Box famously put it, \"All models are wrong, but some are useful.\"  This is really a good thing for discovery \u2013 often scientists can get new insights and develop deeper understanding by studying precisely why their models fail to match reality.  In this research the PIs will develop a new approach to quantifying this \"discrepancy\" between mathematical models and observations, intended specifically for problems in which the data are numerical counts of events or objects.  Examples arise in nearly every scientific field \u2013 counts of volcanoes or earthquakes or disease cases; of galaxies or stars or exoplanets; of photons or gamma ray burst pulses or neutrinos.  This project will specifically address two classes of problems in astronomy.  One class concerns how astronomers can convert raw data measuring light from astrophysical objects (such as stars and galaxies) into estimates of properties of the sources (such as brightness and color) with accurately quantified uncertainties, even when the precise shapes of the objects are not known, and their images overlap.  A second class concerns using astronomical survey catalogs to learn the dominant demographic properties of stars, galaxies, or minor planets (such as asteroids), such as the distribution of their luminosities or masses. The NSF-funded Vera Rubin Observatory will produce data for both types of problems. The research will include developing fast, open-source\r\ncomputational algorithms implementing the new approaches.\r\n\r\nThe project is motivated by application areas in which salient feature discovery is threatened by model misspecification.  In applications with real-valued magnitude data with additive Gaussian errors, statisticians have addressed misspecification by introducing additive discrepancy processes into models, often using Gaussian processes.  The two problem areas addressed here require analysis of discrete count or point process data: photon counting data comprising images and time series from cosmic sources, or demographic data in astronomical survey catalogs.  Both areas rely on Poisson point process models, with an intensity function describing, say, the photon arrival rate (per unit area) as a function of direction and time, or the density of galaxies as a function of spatial location and luminosity.  Additive discrepancy models are not applicable to such discrete-data settings.  The team will develop new semiparametric methods that supplement parametric salient feature models with nonparametric discrepancy processes that flexibly model the departure of salient models from the true data generating process.  An approach serving as a starting point represents the true underlying intensity function as the product of the salient feature model and a stochastic multiplicative discrepancy process.  The salient feature model will be a parametricintensity function (e.g., with location, amplitude, scale, and shape parameters), sometimes in a superposition of multiple components (e.g., stars in an image, pulses in a transient burst, or population components). To model discrepancy from the salient model, a natural choice with appealing theoretical properties is a multiplicative gamma discrepancy process; composition with the Poisson point process leads to an overall negative binomial point process for the observations.  The team will implement this approach, and generalize it in several directions. For demographic models, the discrepancy models will be embedded in a hierarchical model that accounts for measurement error and selection effects.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Wolpert",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Robert L Wolpert",
   "pi_email_addr": "rlw@duke.edu",
   "nsf_id": "000444377",
   "pi_start_date": "2020-06-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "2200 W. Main St. Ste 710",
  "perf_city_name": "DURHAM",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277054010",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 104215.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><em>Model building</em> is widely recognized as a core activity of science. But what is a model? A model is a<em> surrogate object.</em> It stands in for some real target object or system, aiming to capture aspects of it to fulfill a particular purpose. Necessarily, a <em>surrogate</em>&nbsp;model will not resemble the object or system it is standing in for with complete fidelity. For example, a <em>medical model</em> (an animal or cell culture) is meant to stand in for humans in the early evaluation of a potential medical treatment. A rodent serving as a medical model bears little similarity to humans in many obvious respects, but has biological systems resembling human counterparts closely enough to offer explanatory and predictive capability in the context of medical research. A medical model is an example of a scientific model-- a stand-in for a physical system that enables scientists to learn about the system, for explanatory and predictive purposes.</p>\n<p>In quantitative sciences,<em> mathematical models</em> play a preeminent role, enabling quantitative prediction of real-world measurements. In many scientific settings, sources of noise and other forms of randomness impact measurements, and predictions are necessarily uncertain. <em>Statistical models</em> use probability theory to quantify uncertainty in predictions and conclusions.</p>\n<p>Statistician George Box famously said, <em>\"All models are wrong, but some are useful.</em>\" Box's remark recognizes that models necessarily overlook details, some unnecessary to consider for the purpose at hand, others perhaps necessary but not yet recognized. Probability theorist Mark Kac put it more colorfully, calling models \"caricatures of reality\" that \"portray, though perhaps in distorted manner, some of the features of the real world.\"</p>\n<p>This project developed a framework for building statistical models that aim to capture the <em>salient features</em> of a process, explicitly recognizing that the predictions of the salient feature model should not be expected to match reality with high fidelity. Statisticians have developed such capability in the context of comparing the predictions of complex computer models to real-world measurements, such as climate predictions and predictions of patterns observed the cosmic background radiation, the relic microwave radiation from the Big Bang. In these settings, scientists measure continuous (real-number-valued) quantities like temperature across the globe, or the strength of microwave radiation across the sky. Even the most complex computer models are incapable of modeling every detail; phenomena like the effects of leaf canopies and clouds on climate, or turbulence on the formation of galaxies and their dark matter halos, are not understood well enough to model accurately with current resources. So analysts incorporate a<em> discrepancy process</em> into their predictions--- extra controlled randomness that gets added to model predictions. The discrepancy process isn't merely a \"fudge factor\" included to make the predictions look better. It recognizes incompleteness in a model---<em>model misspecification</em> in statistics parlance---and propagates the extra uncertainty due to incompleteness backward through the model, so that scientists do not assign unjustified levels of confidence to estimates, predictions, and explanations.</p>\n<p>This project developed new, similar capability for treating model misspecification for measurements that are<em> discrete</em> rather than continuous, focusing on data analysis problems in astronomy. As an example, many astronomical instruments count photons (light quanta) from a source, as a function of time or energy; some instruments even measure properties of every individual photon (\"event data\"). The models for such data use an <em>intensity function</em> to predict the rate at which events may be counted. Rates have to be non-negative, so additive <em>discrepancy processes</em> are inapplicable. This project developed multiplicative discrepancy processes tailored to such data. The salient model rate is multiplied by a small random positive factor, near one, at each point, making the predictions slightly \"fuzzy.\"</p>\n<p>The figures show an example: counting the number and sizes of pulses in a <em>gamma ray burst</em> (GRB), a burst of high-energy photons produced by the collapse of a massive star into a black hole. The first figure shows a GRB \"light curve\" showing photon counts in small time bins through the course of a burst. Astronomers would like to know the number and properties of pulses. Visually, it appears there are two or perhaps three pulses. To count them in a formal, statistical way, astronomers use a simple pulse model (the thin curves, with three plausible fits shown). The bar plot shows the probability for there being different numbers of pulses in the burst based on the model; four is most likely, which seems unjustified. The simple model does not exactly describe real pulses, so the model ends up inserting small pulses to make up for the misfit. The second figure shows results incorporating multiplicative discrepancy, recognizing the pulse model is approximate. This model favors two or three pulses, better describing reality.</p>\n<p>The team also engaged in training young astronomers in advanced statistical methods, lecturing annually at the Summer School in Statistics for Astronomers hosted by Penn State University.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/27/2023<br>\n\t\t\t\t\tModified by: Robert&nbsp;L&nbsp;Wolpert</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/2015382/2015382_10680499_1698437955197_2-GRBFit-WithDiscrepancy--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2015382/2015382_10680499_1698437955197_2-GRBFit-WithDiscrepancy--rgov-800width.jpg\" title=\"Counting pulses in a gamma-ray burst (with multiplicative discrepancy)\"><img src=\"/por/images/Reports/POR/2023/2015382/2015382_10680499_1698437955197_2-GRBFit-WithDiscrepancy--rgov-66x44.jpg\" alt=\"Counting pulses in a gamma-ray burst (with multiplicative discrepancy)\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Counting the pulses in a gamma-ray burst with a simple salient feature pulse model, here incorporating a multiplicative discrepancy process to accountfor minor inaccuracy in the pulse model. The discrepancy process leads to reliable counting of pulses.</div>\n<div class=\"imageCredit\">Thomas Loredo, Robert Wolpert, and Mary Beth Broadbent</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Robert&nbsp;L&nbsp;Wolpert</div>\n<div class=\"imageTitle\">Counting pulses in a gamma-ray burst (with multiplicative discrepancy)</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nModel building is widely recognized as a core activity of science. But what is a model? A model is a surrogate object. It stands in for some real target object or system, aiming to capture aspects of it to fulfill a particular purpose. Necessarily, a surrogate model will not resemble the object or system it is standing in for with complete fidelity. For example, a medical model (an animal or cell culture) is meant to stand in for humans in the early evaluation of a potential medical treatment. A rodent serving as a medical model bears little similarity to humans in many obvious respects, but has biological systems resembling human counterparts closely enough to offer explanatory and predictive capability in the context of medical research. A medical model is an example of a scientific model-- a stand-in for a physical system that enables scientists to learn about the system, for explanatory and predictive purposes.\n\nIn quantitative sciences, mathematical models play a preeminent role, enabling quantitative prediction of real-world measurements. In many scientific settings, sources of noise and other forms of randomness impact measurements, and predictions are necessarily uncertain. Statistical models use probability theory to quantify uncertainty in predictions and conclusions.\n\nStatistician George Box famously said, \"All models are wrong, but some are useful.\" Box's remark recognizes that models necessarily overlook details, some unnecessary to consider for the purpose at hand, others perhaps necessary but not yet recognized. Probability theorist Mark Kac put it more colorfully, calling models \"caricatures of reality\" that \"portray, though perhaps in distorted manner, some of the features of the real world.\"\n\nThis project developed a framework for building statistical models that aim to capture the salient features of a process, explicitly recognizing that the predictions of the salient feature model should not be expected to match reality with high fidelity. Statisticians have developed such capability in the context of comparing the predictions of complex computer models to real-world measurements, such as climate predictions and predictions of patterns observed the cosmic background radiation, the relic microwave radiation from the Big Bang. In these settings, scientists measure continuous (real-number-valued) quantities like temperature across the globe, or the strength of microwave radiation across the sky. Even the most complex computer models are incapable of modeling every detail; phenomena like the effects of leaf canopies and clouds on climate, or turbulence on the formation of galaxies and their dark matter halos, are not understood well enough to model accurately with current resources. So analysts incorporate a discrepancy process into their predictions--- extra controlled randomness that gets added to model predictions. The discrepancy process isn't merely a \"fudge factor\" included to make the predictions look better. It recognizes incompleteness in a model---model misspecification in statistics parlance---and propagates the extra uncertainty due to incompleteness backward through the model, so that scientists do not assign unjustified levels of confidence to estimates, predictions, and explanations.\n\nThis project developed new, similar capability for treating model misspecification for measurements that are discrete rather than continuous, focusing on data analysis problems in astronomy. As an example, many astronomical instruments count photons (light quanta) from a source, as a function of time or energy; some instruments even measure properties of every individual photon (\"event data\"). The models for such data use an intensity function to predict the rate at which events may be counted. Rates have to be non-negative, so additive discrepancy processes are inapplicable. This project developed multiplicative discrepancy processes tailored to such data. The salient model rate is multiplied by a small random positive factor, near one, at each point, making the predictions slightly \"fuzzy.\"\n\nThe figures show an example: counting the number and sizes of pulses in a gamma ray burst (GRB), a burst of high-energy photons produced by the collapse of a massive star into a black hole. The first figure shows a GRB \"light curve\" showing photon counts in small time bins through the course of a burst. Astronomers would like to know the number and properties of pulses. Visually, it appears there are two or perhaps three pulses. To count them in a formal, statistical way, astronomers use a simple pulse model (the thin curves, with three plausible fits shown). The bar plot shows the probability for there being different numbers of pulses in the burst based on the model; four is most likely, which seems unjustified. The simple model does not exactly describe real pulses, so the model ends up inserting small pulses to make up for the misfit. The second figure shows results incorporating multiplicative discrepancy, recognizing the pulse model is approximate. This model favors two or three pulses, better describing reality.\n\nThe team also engaged in training young astronomers in advanced statistical methods, lecturing annually at the Summer School in Statistics for Astronomers hosted by Penn State University.\n\n\t\t\t\t\tLast Modified: 10/27/2023\n\n\t\t\t\t\tSubmitted by: Robert L Wolpert"
 }
}