{
 "awd_id": "2015379",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Extremes in High Dimensions: Causality, Sparsity, Classification, Clustering, Learning",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 299999.0,
 "awd_amount": 299999.0,
 "awd_min_amd_letter_date": "2020-06-18",
 "awd_max_amd_letter_date": "2020-06-18",
 "awd_abstract_narration": "In recent years, through news reports and first-hand experience, the general public has become keenly aware of extreme events, in particular, of extreme weather conditions such as extended heat waves, periods of extreme cold, an increase in the number and intensity of tornadoes and hurricanes, or periods of record precipitation resulting in unprecedented floods.  Just in the past few years, the insurance claims from extreme climatic events have been staggering, which include the Missouri River flood in April 2019 ($10.8B), Hurricane Michael in October 2018  ($25B), the California wildfires in December 2017 ($18.7B), the US drought/heatwave in 2012 ($33.9B), and Hurricane Sandy in October 2012 ($73.4B).  This list does not include non-climatic extreme events such as the financial crisis from 2008 nor the current covid-19 pandemic. Many of the extreme events experienced today that are weather, environmental, industrial, epidemiological, economic, or social media related are occurring at a more frequent rate, which often result in huge losses to our society in a variety of ways from financial to human life to our way of life. While the occurrence of extreme events is reasonably well understood in steady state situations, it has become clear that the preponderance of extremes events suggest that the steady-state assumption is no longer valid.  The key objective of this research is to try to understand causal impacts of various factors from a potentially large array of variables including changing environmental conditions, demographic movements within the US, changing landscapes, and changing economic conditions, on the frequency and magnitude of extreme events.  From many variables, we hope to produce methodology to extract the important features in the data that have a direct impact on describing and predicting extremes.  This research is potentially of use to policymakers who need to anticipate and plan for extreme events leading to sensible strategies for mitigating their impact on society. The graduate student support will be used for interdisciplinary research.\r\n\r\nThe principal goal of this research project is to design new tools for analyzing and modeling extremes in a myriad of situations that go well beyond the boundaries of classical extreme value theory. These include detection of often nonlinear sets of much smaller dimension that can provide an adequate description of extremes in high dimensions, for which we hope to apply the powerful modern learning techniques (such as graph-based learning methods) that allow us to determine this extremal support from the data. In general, detecting sparsity in the exponent measure describing high-dimensional extremes, i.e., locating (often numerous) low-dimensional regions which carry most of the support of exponent measure will be a key focus of this research. A second main thrust of this research centers on the issue of causality in both small and large dimensional problems. In the most basic form, a set of variables X is said to be tail causal to a dependent vector Y if certain changes in X (sometimes themselves extreme but not always so) impact the tail behavior of Y. An important setting of this type is the potential outcomes framework for causality of extreme events, which will be a major focus in this project's research agenda.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Davis",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Richard A Davis",
   "pi_email_addr": "rdavis@stat.columbia.edu",
   "nsf_id": "000320452",
   "pi_start_date": "2020-06-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Marco",
   "pi_last_name": "Avella Medina",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Marco Avella Medina",
   "pi_email_addr": "marco.avella@columbia.edu",
   "nsf_id": "000817126",
   "pi_start_date": "2020-06-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "1255 Amsterdam Ave",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100276902",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 299999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>One of the overarching goals of this research project was to develop new tools for analyzing and modeling extremes in a myriad of situations that go well beyond the boundaries of classical extreme value theory.&nbsp; For example, if the data is of large dimension such as temperature or rainfall recorded at a large number of monitoring stations, one might want to associate the impact of extreme temperature or rainfall at one location on the other locations.&nbsp; In other words extremes from the entire set of data can often be reduced to a much smaller and manageable subset of the data without much loss in information.&nbsp;&nbsp; To this end, the research produced in this project related to two specific methodologies: one was to discover clustering of extreme observations and the second was to find condensed regions in the data that can provide adequate description of the extremes.&nbsp;</p>\n<p>&nbsp;</p>\n<p>For finding clusters, we used an approach from machine learning based on spectral clustering.&nbsp; The idea is to consider the angular components of each data value when that particular data value is large.&nbsp; These angular components tend to cluster in certain directions.&nbsp; For each two angular components we define a distance from which a graphical model is formed.&nbsp; That is, two angular components are linked by an edge in the graph if the distance between them is sufficiently small.&nbsp; After forming this graph, then a graphical Laplacian is defined which allows one to optimally locate clusters of highly concentrated angular components.&nbsp; One big advantage of this method is that it was able to effectively separate signal from noise.</p>\n<p>&nbsp;</p>\n<p>We used kernel principal component analysis (PCA) to find nonlinear regions of high concentration of extremes. &nbsp;Here the main idea is that the data are&nbsp; mapped into a high-dimensional space, called a reproducing kernel Hilbert space (RKHS), via a kernel function map.&nbsp; On this larger space, one performs PCA in the typical manner; i.e., the number of significant eigenvalues and corresponding eigenfunctions are identified.&nbsp; At this stage the dimension of the problem has been substantially reduced.&nbsp; The pre-images under this mapping are then calculated under the under the smaller subspace found on the RKHS. &nbsp;It was discovered that the procedure was particularly effective for the case when the data is contaminated with noise.&nbsp;</p>\n<p>On the broad impacts side, Professor Davis has advised one PhD student, Leon Fernandes, during the duration of this grant.&nbsp; He has been working on problems that are tangentially related to this grant and expects to defend in December 2023.&nbsp; Davis taught a topics in probability course to PhD students in the Statistics Department at Columbia in spring 2022.&nbsp; A main component of this course included topics in heavy-tailed time series modeling and extremal dependence, which are directly related to this grant.&nbsp; Davis also delivered a PhD summer course (May 2023) for students at Bocconi University which included topics in extreme value theory.&nbsp; He has also been a member of Columbia&rsquo;s STEM DEI committee for the past 3 years.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/30/2023<br>\n\t\t\t\t\tModified by: Richard&nbsp;A&nbsp;Davis</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOne of the overarching goals of this research project was to develop new tools for analyzing and modeling extremes in a myriad of situations that go well beyond the boundaries of classical extreme value theory.  For example, if the data is of large dimension such as temperature or rainfall recorded at a large number of monitoring stations, one might want to associate the impact of extreme temperature or rainfall at one location on the other locations.  In other words extremes from the entire set of data can often be reduced to a much smaller and manageable subset of the data without much loss in information.   To this end, the research produced in this project related to two specific methodologies: one was to discover clustering of extreme observations and the second was to find condensed regions in the data that can provide adequate description of the extremes. \n\n \n\nFor finding clusters, we used an approach from machine learning based on spectral clustering.  The idea is to consider the angular components of each data value when that particular data value is large.  These angular components tend to cluster in certain directions.  For each two angular components we define a distance from which a graphical model is formed.  That is, two angular components are linked by an edge in the graph if the distance between them is sufficiently small.  After forming this graph, then a graphical Laplacian is defined which allows one to optimally locate clusters of highly concentrated angular components.  One big advantage of this method is that it was able to effectively separate signal from noise.\n\n \n\nWe used kernel principal component analysis (PCA) to find nonlinear regions of high concentration of extremes.  Here the main idea is that the data are  mapped into a high-dimensional space, called a reproducing kernel Hilbert space (RKHS), via a kernel function map.  On this larger space, one performs PCA in the typical manner; i.e., the number of significant eigenvalues and corresponding eigenfunctions are identified.  At this stage the dimension of the problem has been substantially reduced.  The pre-images under this mapping are then calculated under the under the smaller subspace found on the RKHS.  It was discovered that the procedure was particularly effective for the case when the data is contaminated with noise. \n\nOn the broad impacts side, Professor Davis has advised one PhD student, Leon Fernandes, during the duration of this grant.  He has been working on problems that are tangentially related to this grant and expects to defend in December 2023.  Davis taught a topics in probability course to PhD students in the Statistics Department at Columbia in spring 2022.  A main component of this course included topics in heavy-tailed time series modeling and extremal dependence, which are directly related to this grant.  Davis also delivered a PhD summer course (May 2023) for students at Bocconi University which included topics in extreme value theory.  He has also been a member of Columbia\u2019s STEM DEI committee for the past 3 years.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 07/30/2023\n\n\t\t\t\t\tSubmitted by: Richard A Davis"
 }
}