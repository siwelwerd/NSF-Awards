{
 "awd_id": "1955361",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Medium: Learning Task-Specific Representations for Broadly Capable Reinforcement Learning Agents",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924286",
 "po_email": "yduan@nsf.gov",
 "po_sign_block_name": "Andy Duan",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 1199684.0,
 "awd_amount": 1199684.0,
 "awd_min_amd_letter_date": "2020-08-10",
 "awd_max_amd_letter_date": "2022-06-16",
 "awd_abstract_narration": "While artificially intelligent agents have achieved expert-level performance on some specialized tasks, progress on designing agents that are broadly capable---able to reach adequate performance on a wide range of tasks---remains elusive. One major obstacle is that the sensors and actuators required by a general-purpose agent must be very complex, to support all the different tasks it may be required to solve. The resulting complexity makes decision-making much harder and drastically hinders the effectiveness of such agents. By contrast, agents that do only one thing can be given much simpler inputs and outputs that are carefully designed to be low-dimensional, highly informative, and task-relevant; such agents often demonstrate satisfactory performance. This project posits that a key requirement for generally intelligent agents is the ability to autonomously formulate such representations for themselves---as abstactions over their complex sensor and actuator spaces---and plans to design new algorithms to do so. AI systems with this ability could be re-tasked to solve many different problems without modification, rather than requiring substantial (and often prohibitive) engineering effort for each new application.\r\n\r\nThis project aims to develop new algorithms that enable agents to learn compact, task-specific abstractions of new problems, by combining and extending techniques for discovering high-level actions, discovering perceptual abstractions that support planning with high-level actions, and formally characterizing the complexity and value loss of using those abstractions. The project will: 1) design new algorithms for reward-driven (and therefore task-specific) perceptual- and action-abstraction discovery; 2) enable inter-task abstraction transfer (which avoids having to re-learn abstractions from scratch each time) through new algorithms for learning generalized skills and constructing modular action-perception-abstraction packages, and new theory characterizing the value loss of using such generalized abstractions; and 3) create principled methods for incrementally constructing a library of modular action-perception abstractions and for adaptively recruiting existing action-state abstractions to solve new tasks.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "George",
   "pi_last_name": "Konidaris",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "George D Konidaris",
   "pi_email_addr": "George_konidaris@brown.edu",
   "nsf_id": "000732307",
   "pi_start_date": "2020-08-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Littman",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Michael L Littman",
   "pi_email_addr": "mlittman@cs.brown.edu",
   "nsf_id": "000210482",
   "pi_start_date": "2020-08-10",
   "pi_end_date": "2022-06-16"
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "Office of Sponsored Projects",
  "perf_city_name": "Providence",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029129093",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 1199684.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>While artificially intelligent agents have achieved expert-level performance on many individual tasks, progress on designing agents that are broadly capable---able to reach adequate performance on a wide range of tasks---remains elusive. One major obstacle is that the sensors and actuators required by a general-purpose agent must be very complex, to support all the different tasks is may be required to solve. The resulting complexity makes decision-making much harder and drastically hinders the effectiveness of such agents. By contrast, agents that do only one thing can be given much simpler inputs and outputs that are carefully designed to be low-dimensional, highly informative, and task-relevant; such agents often demonstrate satisfactory performance. This proposal posits that a key requirement for generally intelligent agents is the ability to autonomously formulate such representations for themselves---as abstactions over their complex sensor and actuator spaces---and proposes to design new algorithms to do so.</p>\r\n<p>The major goals of the project were: 1) to develop new skill acquisition methods, in the implicitly-specified, black-box, and explicitly-specified reward function setting, 2) to develop methods for learning coupled, modular state-action abstractions, and 3) to develop methods for managing and using a library of such state-action abstractions in the multi-task setting. It resulted in several published research papers, which established a clear sequence of improvements over the state-of-the-art in skill discovery; invented new methods for learning abstract representations for planning with learned skills, and methods for porting skills across tasks. Taken together, these advances have substantially advanced the state-of-the-art in learning task-specific representations, and established such approaches as a viable route to designing broadly-applicable agents. The grant supported nine PhD students, two of which graduated during its duration.&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/17/2025<br>\nModified by: George&nbsp;D&nbsp;Konidaris</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nWhile artificially intelligent agents have achieved expert-level performance on many individual tasks, progress on designing agents that are broadly capable---able to reach adequate performance on a wide range of tasks---remains elusive. One major obstacle is that the sensors and actuators required by a general-purpose agent must be very complex, to support all the different tasks is may be required to solve. The resulting complexity makes decision-making much harder and drastically hinders the effectiveness of such agents. By contrast, agents that do only one thing can be given much simpler inputs and outputs that are carefully designed to be low-dimensional, highly informative, and task-relevant; such agents often demonstrate satisfactory performance. This proposal posits that a key requirement for generally intelligent agents is the ability to autonomously formulate such representations for themselves---as abstactions over their complex sensor and actuator spaces---and proposes to design new algorithms to do so.\r\n\n\nThe major goals of the project were: 1) to develop new skill acquisition methods, in the implicitly-specified, black-box, and explicitly-specified reward function setting, 2) to develop methods for learning coupled, modular state-action abstractions, and 3) to develop methods for managing and using a library of such state-action abstractions in the multi-task setting. It resulted in several published research papers, which established a clear sequence of improvements over the state-of-the-art in skill discovery; invented new methods for learning abstract representations for planning with learned skills, and methods for porting skills across tasks. Taken together, these advances have substantially advanced the state-of-the-art in learning task-specific representations, and established such approaches as a viable route to designing broadly-applicable agents. The grant supported nine PhD students, two of which graduated during its duration.\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 03/17/2025\n\n\t\t\t\t\tSubmitted by: GeorgeDKonidaris\n"
 }
}