{
 "awd_id": "1955487",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CNS Core: Medium: Cross-Layer Design of Video Analytics for the Internet of Things",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032924624",
 "po_email": "amatta@nsf.gov",
 "po_sign_block_name": "Abraham Matta",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 375000.0,
 "awd_amount": 375000.0,
 "awd_min_amd_letter_date": "2020-09-01",
 "awd_max_amd_letter_date": "2023-09-27",
 "awd_abstract_narration": "The emergence of the Internet of Things (IoT) enables many new applications ranging from augmented reality and self-driving cars, to surveillance and cashier-less retail stores. These applications continuously collect video streams from IoT devices, such as sensors, cameras, and radars. They aim to understand the video content to make intelligent decisions, by running sophisticated video analytics tasks, such as counting people and recognizing license plates in the video streams. These video analytics tasks often run a collection of computing resources including IoT devices, edge clusters near the devices and the remote cloud, connected through networks with dynamic bandwidth and latency. This project will enable a high-performance video analytics framework that can support a variety of IoT applications in real-time, with high accuracy, and at scale.\r\n \r\nThe key idea of this project is to enable video analytics for IoT devices by joint optimizations across application, computing, and networking. Today\u2019s solutions often focus on separated optimization, which leads to inaccurate answers to analytical queries, inefficient use of computing resources, and performance degrades when network condition changes. This project's video analytics framework will (1) leverage both network layer information and physical information to tune the parameters in video analytics, in order to optimize task accuracy, instead of network bandwidth, latency or quality of experience, (2) allocate computing resources for analytics tasks to meet multi-dimensional task-level service-level objectives with distributed time tracking and runtime scheduling, and (3) redesign video analytics and encoding algorithms by considering the network and computing constraints. This project will build and test representative video analytics applications on top of the system to demonstrate its capability. The project will facilitate the interactions between the machine learning research community and the systems/networking research community, and result in novel algorithms and efficient networked systems for video analytics. The project will also engage underrepresented groups and undergraduates in research.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yinzhi",
   "pi_last_name": "Cao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yinzhi Cao",
   "pi_email_addr": "ycao43@jhu.edu",
   "nsf_id": "000689464",
   "pi_start_date": "2021-04-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Xin",
   "pi_last_name": "Jin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xin Jin",
   "pi_email_addr": "xinjin@cs.jhu.edu",
   "nsf_id": "000743454",
   "pi_start_date": "2020-09-01",
   "pi_end_date": "2021-04-02"
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182686",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 375000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-dbed897c-7fff-57bb-f661-3988a605a530\">\r\n<p dir=\"ltr\"><span>This research project tackled the growing challenge of processing and analyzing video data from Internet of Things (IoT) devices, focusing on applications from autonomous vehicles to retail surveillance. The research advanced the field by optimizing how video data moves and gets processed across three key layers: IoT devices themselves, local computing centers (edge), and remote data centers (cloud). The project's significance lies in its comprehensive approach to solving video analytics challenges through innovations in computing, networking, and analytics algorithms.</span></p>\r\n<br />\r\n<p dir=\"ltr\"><span>We created innovative solutions for autonomous systems. The OMU accelerator system transformed how flying devices like drones process their surroundings by introducing parallel processing units and efficient memory management. This system achieved faster processing, using two orders of magnitude less energy than standard processors, making autonomous navigation more practical and efficient. The research extended to safety considerations through the MAVFI framework, which addressed the critical challenge of system reliability. MAVFI enabled drones to detect and recover from silent system failures with minimal computational overhead, representing a significant advancement in autonomous system safety.</span></p>\r\n<br />\r\n<p dir=\"ltr\"><span>OctoMap an accelerator for processing point cloud data for autonomous machines intelligently and effectively. We introduced OctoCache, a software system that dramatically improves the mapping system&rsquo;s update speed. OctoCache in 3D environment construction tasks demonstrates significant performance improvement. Furthermore, we validate the OctoCache by deploying it in multiple Unmanned Aerial Vehicle (UAV) autonomous navigation scenarios to quantify the end-to-end benefits.</span></p>\r\n<br />\r\n<p dir=\"ltr\"><span>We proposed HawkVision, which provides low-latency modeless serving of vision DNNs. HawkVision leverages a two-layer edge-cloud architecture that employs confidence scaling to reduce the number of model options while meeting diverse accuracy requirements. It also supports lossy inference under volatile network environments.&nbsp;&nbsp;</span></p>\r\n<br />\r\n<p dir=\"ltr\"><span>The research has demonstrated significant real-world impact through technology transfer to major cloud service providers, semiconductor manufacturers, and telecommunications companies. These partnerships have improved cloud infrastructure efficiency, enhanced capabilities of IoT devices worldwide, and stronger network security implementations.</span></p>\r\n<br />\r\n<p dir=\"ltr\"><span>The project also made substantial educational contributions to develop future technology leaders. It provided advanced training for eight graduate students and two undergraduate researchers who gained hands-on experience with cutting-edge technology. These students worked on various aspects of the project, from developing new algorithms to implementing and testing systems in real-world scenarios. An open educational platform was created at Harvard (tinyml.seas.harvard.edu) that has reached over a thousand students, providing resources and tutorials on machine learning for IoT devices. The research findings were widely shared through seven peer-reviewed publications in leading venues such as NSDI, OSDI, ESWEEK, and DATE and multiple invited talks at major institutions, including Princeton, CMU, and EPFL.</span></p>\r\n<br />\r\n<p dir=\"ltr\"><span>The project's comprehensive approach to video analytics optimization has laid crucial groundwork for the next generation of IoT applications. Integrating improved performance, enhanced reliability, and increased efficiency across all system layers - from individual devices to cloud processing - provides a robust foundation for future developments in IoT technology. This is particularly important as society increasingly relies on real-time video analysis and autonomous decision-making in applications ranging from urban planning to emergency response systems. The successful adoption of these technologies by industry demonstrates their immediate practical value. It suggests their lasting impact on processing and analyzing video data in our increasingly connected world.</span></p>\r\n</span></p><br>\n<p>\n Last Modified: 12/07/2024<br>\nModified by: Yinzhi&nbsp;Cao</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\r\n\n\nThis research project tackled the growing challenge of processing and analyzing video data from Internet of Things (IoT) devices, focusing on applications from autonomous vehicles to retail surveillance. The research advanced the field by optimizing how video data moves and gets processed across three key layers: IoT devices themselves, local computing centers (edge), and remote data centers (cloud). The project's significance lies in its comprehensive approach to solving video analytics challenges through innovations in computing, networking, and analytics algorithms.\r\n\n\r\n\n\nWe created innovative solutions for autonomous systems. The OMU accelerator system transformed how flying devices like drones process their surroundings by introducing parallel processing units and efficient memory management. This system achieved faster processing, using two orders of magnitude less energy than standard processors, making autonomous navigation more practical and efficient. The research extended to safety considerations through the MAVFI framework, which addressed the critical challenge of system reliability. MAVFI enabled drones to detect and recover from silent system failures with minimal computational overhead, representing a significant advancement in autonomous system safety.\r\n\n\r\n\n\nOctoMap an accelerator for processing point cloud data for autonomous machines intelligently and effectively. We introduced OctoCache, a software system that dramatically improves the mapping systems update speed. OctoCache in 3D environment construction tasks demonstrates significant performance improvement. Furthermore, we validate the OctoCache by deploying it in multiple Unmanned Aerial Vehicle (UAV) autonomous navigation scenarios to quantify the end-to-end benefits.\r\n\n\r\n\n\nWe proposed HawkVision, which provides low-latency modeless serving of vision DNNs. HawkVision leverages a two-layer edge-cloud architecture that employs confidence scaling to reduce the number of model options while meeting diverse accuracy requirements. It also supports lossy inference under volatile network environments.\r\n\n\r\n\n\nThe research has demonstrated significant real-world impact through technology transfer to major cloud service providers, semiconductor manufacturers, and telecommunications companies. These partnerships have improved cloud infrastructure efficiency, enhanced capabilities of IoT devices worldwide, and stronger network security implementations.\r\n\n\r\n\n\nThe project also made substantial educational contributions to develop future technology leaders. It provided advanced training for eight graduate students and two undergraduate researchers who gained hands-on experience with cutting-edge technology. These students worked on various aspects of the project, from developing new algorithms to implementing and testing systems in real-world scenarios. An open educational platform was created at Harvard (tinyml.seas.harvard.edu) that has reached over a thousand students, providing resources and tutorials on machine learning for IoT devices. The research findings were widely shared through seven peer-reviewed publications in leading venues such as NSDI, OSDI, ESWEEK, and DATE and multiple invited talks at major institutions, including Princeton, CMU, and EPFL.\r\n\n\r\n\n\nThe project's comprehensive approach to video analytics optimization has laid crucial groundwork for the next generation of IoT applications. Integrating improved performance, enhanced reliability, and increased efficiency across all system layers - from individual devices to cloud processing - provides a robust foundation for future developments in IoT technology. This is particularly important as society increasingly relies on real-time video analysis and autonomous decision-making in applications ranging from urban planning to emergency response systems. The successful adoption of these technologies by industry demonstrates their immediate practical value. It suggests their lasting impact on processing and analyzing video data in our increasingly connected world.\r\n\t\t\t\t\tLast Modified: 12/07/2024\n\n\t\t\t\t\tSubmitted by: YinzhiCao\n"
 }
}