{
 "awd_id": "2027713",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RAPID: Countering COVID-19 Misinformation via Situation-Aware Visually Informed Treatment",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2020-05-01",
 "awd_exp_date": "2022-04-30",
 "tot_intn_awd_amt": 104491.0,
 "awd_amount": 104491.0,
 "awd_min_amd_letter_date": "2020-04-24",
 "awd_max_amd_letter_date": "2020-04-24",
 "awd_abstract_narration": "As the COVID-19 pandemic spreads, countries and cities around the globe have taken stringent measures including quarantine and regional lockdown. The increasing isolation, along with the panic and anxiety, creates challenges for countering misinformation--people are increasingly tapping into online information sources already familiar to them with declining chances of accessing alternative stories. This project will develop mechanisms based on text and image analysis, social psychology, and crowd-sourcing that can be used in a timely manner to counter misinformation during the ongoing COVID-19 crisis and beyond.  One of the novel features of the approach is to deal with a specific instance of misinformation by crowd-sourcing authentic images that counter this misinformation.   This research will contribute to the scientific understanding of misinformation and of persuasive narrative construction, to the assessment of risk for the spread of misinformation, and to the development of mechanisms to counter misinformation. \r\n\r\nThe technical aims of this project are divided into three thrusts. The first thrust will investigate what information content and which specific part of a multimodal social media post (e.g, a piece of text, text with an image, image with an embedded slogan) will receive stronger responses and hence increase the likelihood of the post being shared. The second thrust will create metrics to assess the likelihood of the spread of misinformation based on predictors learned from the content to which users are exposed. The third thrust will focus on the development of a system to counter misinformation based on citizen journalists\u2019 inputs of field investigations and on machine learning techniques. Finally, the system will be evaluated by survey studies and interviews to examine the system\u2019s usability, usefulness, and effectiveness in reducing the spreading and impact of misinformation.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yu-Ru",
   "pi_last_name": "Lin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yu-Ru Lin",
   "pi_email_addr": "yurulin@pitt.edu",
   "nsf_id": "000623654",
   "pi_start_date": "2020-04-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Adriana",
   "pi_last_name": "Kovashka",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Adriana Kovashka",
   "pi_email_addr": "kovashka@cs.pitt.edu",
   "nsf_id": "000690095",
   "pi_start_date": "2020-04-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Wen-Ting",
   "pi_last_name": "Chung",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wen-Ting Chung",
   "pi_email_addr": "wtchung@pitt.edu",
   "nsf_id": "000824147",
   "pi_start_date": "2020-04-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pittsburgh",
  "inst_street_address": "4200 FIFTH AVENUE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4126247400",
  "inst_zip_code": "152600001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "UNIVERSITY OF PITTSBURGH - OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "MKAGLD59JRL1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pittsburgh",
  "perf_str_addr": "4200 Fifth Avenue",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152600001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "158Y00",
   "pgm_ele_name": "COVID-19 Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "096Z",
   "pgm_ref_txt": "COVID-19 Research"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7914",
   "pgm_ref_txt": "RAPID"
  }
 ],
 "app_fund": [
  {
   "app_code": "1N20",
   "app_name": "R&RA CARES Act DEFC N",
   "app_symb_id": "040100",
   "fund_code": "010N2021DB",
   "fund_name": "R&RA CARES Act DEFC N",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 104491.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-fd15dd88-7fff-cbd8-1cd4-3d882c4a9d43\"> </span></p>\n<p dir=\"ltr\"><span>In the global pandemic era of COVID-19, a time filled with high risk and uncertainty, people become more vulnerable than ever to be influenced by problematic information, such as messages provoking strong emotions, discrimination, violence, and distrust. How do such problematic signals accumulate and translate into a toxic influence over online space?&nbsp; This project aims to study the online ecosystem that fertilizes the \"infodemic\" in the COVID-19 outbreak, focusing on the characteristics of misinformation content and consumers. By leveraging computational social science methodology and multi-modal learning, this interdisciplinary research makes several contributions to developing methods to understand the proliferation and persuasive narrative construction of misinformation.</span></p>\n<p dir=\"ltr\"><span>First, &#8203;&#8203;we developed a computational approach to analyze the patterns of persuasive social media content, in terms of popularity and source credibility. Our multi-modal approach, combining image and text, is not only predictive of information popularity and credibility, but also able to uncover how unreliable sources integrate visual elements with textual content in a distorted, biased fashion. This result provides insights into the enhancement of social media literacy and engagement.</span></p>\n<p dir=\"ltr\"><span>Second,&nbsp; through analyzing a large, geopolitically diverse sample of Twitter users and their information consumption over a 6-month period, we identified \"who\" constitutes the population vulnerable to the online misinformation in the pandemic, and what are the robust features and short-term behavior signals that distinguish susceptible users from others. We discovered that (1) contrary to the prior studies on bot influence, our analysis shows that social bots' contribution to misinformation sharing was surprisingly low, and human-like users' misinformation behaviors exhibit heterogeneity; (2) susceptible users appeared to be politically sensitive, active, and responsive to emotionally charged content among susceptible users. In terms of predicting users' susceptibility, we developed an interpretable deep learning model that efficiently forecasts users' transient susceptibility solely based on their short-term news consumption and exposure from their networks. Our results contribute to designing effective intervention mechanisms to mitigate the misinformation dissipation.</span></p>\n<p dir=\"ltr\"><span>Third, through an analysis of over 240 thousand tweets capturing how users shared COVID-19 pandemic-related misinformation news on social media over a five-month period, we study the spread of information and user's level of interaction with the original information source, i.e., from low (copy-and-paste link) to medium (Like), to high (comments). The higher the user's interacting with the original source, the more mutation the spread of information is. Our results indicate a positive relationship between information mutation and spreading outcomes. This study provides the first quantitative evidence of how misinformation propagation may be exacerbated by users' commentary, which has implications for countering misinformation.</span></p>\n<p dir=\"ltr\"><span>Finally, this project has two broader impacts. First, our study yields promising results by characterizing the information ecosystem, which enriches the social solutions in countering misinformation proliferation beyond the fact-checking paradigm. Second, the longitudinal data and techniques we developed enable researchers, platform managers, and policy analysts to discover new insights into information consumption behaviors and test new methods to counter misinformation.</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/30/2022<br>\n\t\t\t\t\tModified by: Yu-Ru&nbsp;Lin</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/2027713/2027713_10666037_1656604210953_ScreenShot2022-06-30at11.47.38AM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/2027713/2027713_10666037_1656604210953_ScreenShot2022-06-30at11.47.38AM--rgov-800width.jpg\" title=\"User susceptibility modeling\"><img src=\"/por/images/Reports/POR/2022/2027713/2027713_10666037_1656604210953_ScreenShot2022-06-30at11.47.38AM--rgov-66x44.jpg\" alt=\"User susceptibility modeling\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Modeling misinformation susceptibility from users' past share history</div>\n<div class=\"imageCredit\">Yu-Ru Lin</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yu-Ru&nbsp;Lin</div>\n<div class=\"imageTitle\">User susceptibility modeling</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nIn the global pandemic era of COVID-19, a time filled with high risk and uncertainty, people become more vulnerable than ever to be influenced by problematic information, such as messages provoking strong emotions, discrimination, violence, and distrust. How do such problematic signals accumulate and translate into a toxic influence over online space?  This project aims to study the online ecosystem that fertilizes the \"infodemic\" in the COVID-19 outbreak, focusing on the characteristics of misinformation content and consumers. By leveraging computational social science methodology and multi-modal learning, this interdisciplinary research makes several contributions to developing methods to understand the proliferation and persuasive narrative construction of misinformation.\nFirst, &#8203;&#8203;we developed a computational approach to analyze the patterns of persuasive social media content, in terms of popularity and source credibility. Our multi-modal approach, combining image and text, is not only predictive of information popularity and credibility, but also able to uncover how unreliable sources integrate visual elements with textual content in a distorted, biased fashion. This result provides insights into the enhancement of social media literacy and engagement.\nSecond,  through analyzing a large, geopolitically diverse sample of Twitter users and their information consumption over a 6-month period, we identified \"who\" constitutes the population vulnerable to the online misinformation in the pandemic, and what are the robust features and short-term behavior signals that distinguish susceptible users from others. We discovered that (1) contrary to the prior studies on bot influence, our analysis shows that social bots' contribution to misinformation sharing was surprisingly low, and human-like users' misinformation behaviors exhibit heterogeneity; (2) susceptible users appeared to be politically sensitive, active, and responsive to emotionally charged content among susceptible users. In terms of predicting users' susceptibility, we developed an interpretable deep learning model that efficiently forecasts users' transient susceptibility solely based on their short-term news consumption and exposure from their networks. Our results contribute to designing effective intervention mechanisms to mitigate the misinformation dissipation.\nThird, through an analysis of over 240 thousand tweets capturing how users shared COVID-19 pandemic-related misinformation news on social media over a five-month period, we study the spread of information and user's level of interaction with the original information source, i.e., from low (copy-and-paste link) to medium (Like), to high (comments). The higher the user's interacting with the original source, the more mutation the spread of information is. Our results indicate a positive relationship between information mutation and spreading outcomes. This study provides the first quantitative evidence of how misinformation propagation may be exacerbated by users' commentary, which has implications for countering misinformation.\nFinally, this project has two broader impacts. First, our study yields promising results by characterizing the information ecosystem, which enriches the social solutions in countering misinformation proliferation beyond the fact-checking paradigm. Second, the longitudinal data and techniques we developed enable researchers, platform managers, and policy analysts to discover new insights into information consumption behaviors and test new methods to counter misinformation.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 06/30/2022\n\n\t\t\t\t\tSubmitted by: Yu-Ru Lin"
 }
}