{
 "awd_id": "1955280",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: The role of trust when learning from robots",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927878",
 "po_email": "slim@nsf.gov",
 "po_sign_block_name": "Soo-Siang Lim",
 "awd_eff_date": "2020-09-15",
 "awd_exp_date": "2021-12-31",
 "tot_intn_awd_amt": 367918.0,
 "awd_amount": 367918.0,
 "awd_min_amd_letter_date": "2020-09-21",
 "awd_max_amd_letter_date": "2020-09-21",
 "awd_abstract_narration": "A decade ago, robots typically played the role of \u201ctool\u201d or \u201cteammate\u201d. Today, although there are some clear cases where the \u201ctool\u201d or \u201cteammate\u201d model is appropriate, most collaborative robots in long-term deployments in homes, workplaces, or schools readily switch back and forth between being an agentic \u201cteammate\u201d to an inanimate \u201ctool\u201d. While people tolerate this shift in perceived agency, it is unknown how this shift impacts interpersonal properties that are typically attributed only to agentic \u201cteammate\u201d robots. This project will evaluate factors that affect how people trust robots, recognizing that the way humans \u201ctrust\u201d non-agentic automation is fundamentally different from the way that we \u201ctrust\u201d agents and agentic robots. What happens to the trust formed while a robot is an agent when it becomes an inanimate tool? What happens when the inanimate tool returns to being an agentic teammate? The proposed research will fill a significant gap in our understanding of how young humans develop trust in robots. While trust in non-agentic robots is well understood, there has been little systematic study of trust in robots that function as collaborative tools. This work has broad applications to future deployment of robots as systems that vary over time between agentic (human-like) and non-agentic (object-like) behavior. \r\n\r\nThe investigators will concentrate on the role of agency in establishing trust in human-robot interactions in an important application domain: children\u2019s learning. Educational robots designed specifically for children are increasingly common, often replacing human channels of social information. However, these robots cannot be successful without trust; because children are inherently social and collaborative learners, trust is a prerequisite for successful learning. Integrating insights from interactive robot design into experiments with preschool and early school age children, the project will determine how shifts in perceived agency impact the formation, maintenance, and repair of trust: Study 1 investigates how variations of low-level perceptual cues over a single interaction influence trust and subsequent learning. Study 2 examines how variations of high-level social cues lead to differential trust and subsequent learning. For these experiments, a set of age-appropriate collaborative learning games were designed. The investigators also created a coding scheme for child behavior as well as a post-interaction child interview to assess children\u2019s perceptions of the robots and to measure effectiveness of learning. Findings and activities of this project could have broad impacts in multiple arenas including: (1) design guidelines that will influence a broad range of application areas including healthcare, manufacturing, and education; (2) enhancement/augmentation of learning, education and training, including research offerings for graduate and undergraduate investigators; (3) broadening of participation in one area of computing, and (4) dissemination of science to the general public and to the research community.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tamar",
   "pi_last_name": "Kushnir",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tamar Kushnir",
   "pi_email_addr": "tamar.kushnir@duke.edu",
   "nsf_id": "000555643",
   "pi_start_date": "2020-09-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "Cornell Univeristy, Department o",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148534401",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127Y00",
   "pgm_ele_name": "Sci of Lrng & Augmented Intel"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "059Z",
   "pgm_ref_txt": "Science of Learning"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 14780.0
  }
 ],
 "por": null
}