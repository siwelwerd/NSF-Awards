{
 "awd_id": "1944069",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER: Enhancing Robot Physical Intelligence via Crowdsourced Surrogate Learning",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032922633",
 "po_email": "aleoness@nsf.gov",
 "po_sign_block_name": "Alex Leonessa",
 "awd_eff_date": "2020-08-15",
 "awd_exp_date": "2026-07-31",
 "tot_intn_awd_amt": 563657.0,
 "awd_amount": 563657.0,
 "awd_min_amd_letter_date": "2020-01-31",
 "awd_max_amd_letter_date": "2020-01-31",
 "awd_abstract_narration": "This Faculty Early Career Development (CAREER) grant develops a novel way to enhance skilled manipulation of objects as performed by human and robotic hands. Challenges associated with dexterous object manipulation have been a bottleneck limiting the application of robots in many production and service applications. This project introduces a novel chopsticks-like robot and associated methods that will allow robots to gradually develop \"physical intelligence\" (skills that can be transferred to novel situations) by learning from a large group of people, who are distributed across physical location and time. The project uses \"crowdsourcing\" to obtain a large set of data from people using the chopsticks robot to guide a similar, remote robot through industrial and social activities. Sensorimotor control signals observed during teleoperation are parsed by a novel artificial intelligence controller to improve autonomous robot skills. An interesting feature of this controller is its ability to compose new object manipulation skills from parts of previously observed skills. The project develops a user training method that leverages the robot's acquired physical intelligence to actively guide and improve robot teleoperation skills of humans. The innovations promise to advance the national health, prosperity and welfare by improving dexterity of robotic and human manipulation skills in a variety of applications, including manufacturing, medical surgery, and home assistance. The project includes an educational component that engages pre-college and college-age students from diverse backgrounds.\r\n\r\nThis project will develop and test a novel focus on improving dexterous object manipulation skills performed by human and robotic hands. The project advances three novel ideas.  First, the PI will use Amazon Mechanical Turk to implement a teleoperation system (user interface, user management system, and robot learning database) linking a group of human operators with remote robots. This approach, called \"Crowdsourced Surrogate Learning\" (CSL), builds a database of sensor, motor, and machine vision data collected while a large number of people separately use a novel chopsticks-like robot to teleoperate a similar robot to conduct industrial and social tasks. These human subjects experiments will provide the data needed for subsequent robot skill learning and generalization using an approach called \"Robot Composite Learning\" (RCL). RCL implements a discretized joint state space of the robot and the object being grasped/manipulated, along with a statistical inference technique, to compose new command signals - in real-time - enabling the two-fingered robot hand to learn never-demonstrated skills such as new, in-hand manipulations of small items. Finally, the PI will develop a \"Reciprocal Skill Induction\" method that enables the CSL/RCL system to actively guide and improve the robot teleoperation skills of humans by providing haptic guidance using \"virtual fixtures\" that fade as a novel skill is learned.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cong",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cong Wang",
   "pi_email_addr": "wangcong@njit.edu",
   "nsf_id": "000714926",
   "pi_start_date": "2020-01-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New Jersey Institute of Technology",
  "inst_street_address": "323 DR MARTIN LUTHER KING JR BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "NEWARK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "9735965275",
  "inst_zip_code": "071021824",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NJ10",
  "org_lgl_bus_name": "NEW JERSEY INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "SGBMHQ7VXNH5"
 },
 "perf_inst": {
  "perf_inst_name": "New Jersey Institute Of Technology",
  "perf_str_addr": "323 Dr Martin Luther King Jr Blvd",
  "perf_city_name": "Newark",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "071021982",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NJ10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "058Y00",
   "pgm_ele_name": "M3X - Mind, Machine, and Motor"
  },
  {
   "pgm_ele_code": "104500",
   "pgm_ele_name": "CAREER: FACULTY EARLY CAR DEV"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "070E",
   "pgm_ref_txt": "INTEG OF HUMAN & COGNITIVE"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7632",
   "pgm_ref_txt": "HUMAN-ROBOT INTERACTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 563657.0
  }
 ],
 "por": null
}