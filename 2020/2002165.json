{
 "awd_id": "2002165",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "PostDoctoral Research Fellowship",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922599",
 "po_email": "sgdewint@nsf.gov",
 "po_sign_block_name": "Stefaan De Winter",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2020-03-12",
 "awd_max_amd_letter_date": "2020-03-12",
 "awd_abstract_narration": "This award is made as part of the FY 2020 Mathematical Sciences Postdoctoral Research Fellowships Program. Each of the fellowships supports a research and training project at a host institution in the mathematical sciences, including applications to other disciplines, under the mentorship of a sponsoring scientist. The title of the project for this fellowship to Hunter S. Chase is \" Model theory and machine learning.\" The host institution for the fellowship is University of Maryland and the sponsoring scientist is Michael Laskowski.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hunter",
   "pi_last_name": "Chase",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Hunter S Chase",
   "pi_email_addr": "",
   "nsf_id": "000811280",
   "pi_start_date": "2020-03-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Chase, Hunter Sato",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "Chicago",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "",
  "inst_zip_code": "60607",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "IL07",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland Department of Mathematics",
  "perf_str_addr": null,
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207424015",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "060Y00",
   "pgm_ele_name": "Workforce (MSPRF) MathSciPDFel"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9219",
   "pgm_ref_txt": "POSTDOCTORAL FELLOWSHIPS IN MATH SCIENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project explored connections between model theory and the foundations of machine learning. Model theory is a branch of mathematical logic that studies the structure of the definable sets in an arbitrary mathematical structure. Within model theory, a number of dividing lines have been identified, which distinguish between theories that exhibit structure and those that exhibit \"wild\" behavior. Many of these dividing lines can be expressed in local combinatorial terms. These combinatorial phenomena frequently appear in a machine learning context as well, characterizing which set systems are learnable for different notions of machine learning. Our work continued a program to develop a dialogue between model theory and machine learning via this common machinery to exchange and develop tools and techniques.</p>\n<p>We studied a framework called machine teaching, in which a teacher and learner cooperate to establish functions that allow the learner to recover a particular concept from a concept class based on a small number of representative points chosen by the teacher. We showed that classes of finite Littlestone dimension, of any cardinality, admitted a teaching function. We also showed that countable classes of VC-dimension 1 admitted a teaching function. Moreover, such a function could be constructed concept by concept, with no knowledge of subsequent concepts other than that the entire class had VC-dimension 1.</p>\n<p>To contribute to the mathematical community, I also mentored a graduate student as she read papers in computability theory.</p><br>\n<p>\n Last Modified: 10/26/2024<br>\nModified by: Hunter&nbsp;S&nbsp;Chase</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project explored connections between model theory and the foundations of machine learning. Model theory is a branch of mathematical logic that studies the structure of the definable sets in an arbitrary mathematical structure. Within model theory, a number of dividing lines have been identified, which distinguish between theories that exhibit structure and those that exhibit \"wild\" behavior. Many of these dividing lines can be expressed in local combinatorial terms. These combinatorial phenomena frequently appear in a machine learning context as well, characterizing which set systems are learnable for different notions of machine learning. Our work continued a program to develop a dialogue between model theory and machine learning via this common machinery to exchange and develop tools and techniques.\n\n\nWe studied a framework called machine teaching, in which a teacher and learner cooperate to establish functions that allow the learner to recover a particular concept from a concept class based on a small number of representative points chosen by the teacher. We showed that classes of finite Littlestone dimension, of any cardinality, admitted a teaching function. We also showed that countable classes of VC-dimension 1 admitted a teaching function. Moreover, such a function could be constructed concept by concept, with no knowledge of subsequent concepts other than that the entire class had VC-dimension 1.\n\n\nTo contribute to the mathematical community, I also mentored a graduate student as she read papers in computability theory.\t\t\t\t\tLast Modified: 10/26/2024\n\n\t\t\t\t\tSubmitted by: HunterSChase\n"
 }
}