{
 "awd_id": "1948341",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: III: Learning Predictive Models with Structured Sparsity: Algorithms and Computations",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2020-08-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 132024.0,
 "awd_amount": 132024.0,
 "awd_min_amd_letter_date": "2020-06-11",
 "awd_max_amd_letter_date": "2020-06-11",
 "awd_abstract_narration": "Recent advances in predictive modeling technology have greatly reinforced human decision-making processes by extracting hidden trends and gaining valuable knowledge from the past events. Predictive modeling for sparse representation is a fundamental methodology in machine and statistical learning that aims to produce robust outcomes by exploiting domain knowledge, formulating mathematical programs with observed data, and solving the problems with computational resources.  For example, if experts believe there are some parts of data that are insignificant, the model should be able to detect and avoid involving such data to increase prediction accuracy. If features of the data possess hierarchical relationships, e.g.,availability of medical measurements depends on which tests were given to the patient, an accurate model must reproduce the structure for practical applications. Achieving such desired conditions through proper modeling is critical to integrate prior understandings of the problem, and adhere to procedural and operational restrictions. This project aims to expand current knowledge of predictive modeling with structured sparsity by introducing a unified framework for many existing problems and providing computational tools through mathematical optimization methodologies.\r\n\r\nThe sparse patterns in the model variables can be formulated exactly by utilizing the discrete property of the indicator function, and approximately by using surrogate functions. The project aims to investigate effectiveness of imposing such conditions by enforcing them as hard constraints. The main objectives include 1) formulating existing problems as constrained optimization problems, which minimizes the model's loss with respect to the provided data while obeying pre-determined sparsity conditions, 2) developing e\u000efficient and robust algorithms that are capable of effectively handling resulting nonconvex constraints, and 3) studying numerical performance of the new method compared to the latest sparse modeling technologies used in practice. Based on the prior work, the investigator aims to develop deterministic and randomized algorithms that compute stationary solutions with desirable theoretical properties through iterative procedures. Specific research tasks include implementing the proposed method applied to simulated and real data, and investigating robustness of the model in terms of prediction accuracy, ability to identify significant components of data, and successful reproduction of desired sparse patterns in the repeated experiments. The outcome of this project including data and implemented products will be shared with the public through open-source communities and online repositories.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Miju",
   "pi_last_name": "Ahn",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Miju Ahn",
   "pi_email_addr": "mijua@smu.edu",
   "nsf_id": "000808061",
   "pi_start_date": "2020-06-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Southern Methodist University",
  "inst_street_address": "6425 BOAZ ST RM 130",
  "inst_street_address_2": "",
  "inst_city_name": "DALLAS",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "2147684708",
  "inst_zip_code": "752051902",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "TX24",
  "org_lgl_bus_name": "SOUTHERN METHODIST UNIVERSITY",
  "org_prnt_uei_num": "S88YPE3BLV66",
  "org_uei_num": "D33QGS3Q3DJ3"
 },
 "perf_inst": {
  "perf_inst_name": "Southern Methodist University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "752750302",
  "perf_ctry_code": "US",
  "perf_cong_dist": "32",
  "perf_st_cong_dist": "TX32",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 132024.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In recent years, predictive modeling has been extensively utilized in diverse application areas to extract valuable knowledge from collected data. The goal of predictive modeling is to build an accurate mathematical model that predicts a future outcome based on provided input features. Building a model involves carefully designing an optimization problem that minimizes the model's error, which is measured using available input and corresponding output collected from past data. Among many characteristics one can implement in a prediction model is the model's ability to reproduce the desired relationship between the input features. For instance, if input A is only available when input B is available, such a relationship should be considered during the training stage of the prediction model. It is also essential that a trained model satisfies all such conditions to serve as a practically usable tool.&nbsp;</p>\n<p>This project is about introducing effective mathematical optimization formulations and computational algorithms for predictive modeling with structured sparsity. We propose a framework that serves as a unified method to solve many existing structured sparsity problems. An example of such a problem involves non-overlapping groups among the input features. In such a setting, the predictive model must utilize either all or none of the features that belong to the same group. Another example is when a feature's availability depends on the other features' allowing potential overlaps between these relationships. To solve these problems, we introduce several computational algorithms that can efficiently solve the proposed formulations.</p>\n<p>When a new scientific method is proposed, it is crucial to understand its properties and what outcomes it can deliver. Our project investigates theoretical understandings of the proposed formulations and the algorithms. These findings provide guarantees on the model quality, sparsity patterns recovered by the models, and convergence of the algorithm outcome. To test our method's performance, we select several problems in statistical learning and other decision-making problems in health care, power systems, and finance. In the selected problems, the model variables present certain relationships due to the data collection process or the known prior relationship between the input features. From our experiments on synthetic and observed data available in public repositories, we compare our method's performance to the latest methods used in the literature. Our results indicate that the new method is capable of including many existing sparse-recovery approaches, implementing desired sparsity patterns in the model, and achieving satisfactory computational performance compared to widely used existing algorithms.</p>\n<p>To date, the project has produced two peer-reviewed publications, two additional journal papers under review, and one working paper. The algorithm implementations used in these works are available to download for the public. Additionally, a Ph.D. dissertation has been produced by the graduate student involved in the project. This project's research outcome has been disseminated in seven national and international conferences and two invited presentations at international institutions. &nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/29/2023<br>\nModified by: Miju&nbsp;Ahn</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn recent years, predictive modeling has been extensively utilized in diverse application areas to extract valuable knowledge from collected data. The goal of predictive modeling is to build an accurate mathematical model that predicts a future outcome based on provided input features. Building a model involves carefully designing an optimization problem that minimizes the model's error, which is measured using available input and corresponding output collected from past data. Among many characteristics one can implement in a prediction model is the model's ability to reproduce the desired relationship between the input features. For instance, if input A is only available when input B is available, such a relationship should be considered during the training stage of the prediction model. It is also essential that a trained model satisfies all such conditions to serve as a practically usable tool.\n\n\nThis project is about introducing effective mathematical optimization formulations and computational algorithms for predictive modeling with structured sparsity. We propose a framework that serves as a unified method to solve many existing structured sparsity problems. An example of such a problem involves non-overlapping groups among the input features. In such a setting, the predictive model must utilize either all or none of the features that belong to the same group. Another example is when a feature's availability depends on the other features' allowing potential overlaps between these relationships. To solve these problems, we introduce several computational algorithms that can efficiently solve the proposed formulations.\n\n\nWhen a new scientific method is proposed, it is crucial to understand its properties and what outcomes it can deliver. Our project investigates theoretical understandings of the proposed formulations and the algorithms. These findings provide guarantees on the model quality, sparsity patterns recovered by the models, and convergence of the algorithm outcome. To test our method's performance, we select several problems in statistical learning and other decision-making problems in health care, power systems, and finance. In the selected problems, the model variables present certain relationships due to the data collection process or the known prior relationship between the input features. From our experiments on synthetic and observed data available in public repositories, we compare our method's performance to the latest methods used in the literature. Our results indicate that the new method is capable of including many existing sparse-recovery approaches, implementing desired sparsity patterns in the model, and achieving satisfactory computational performance compared to widely used existing algorithms.\n\n\nTo date, the project has produced two peer-reviewed publications, two additional journal papers under review, and one working paper. The algorithm implementations used in these works are available to download for the public. Additionally, a Ph.D. dissertation has been produced by the graduate student involved in the project. This project's research outcome has been disseminated in seven national and international conferences and two invited presentations at international institutions. \n\n\n\t\t\t\t\tLast Modified: 11/29/2023\n\n\t\t\t\t\tSubmitted by: MijuAhn\n"
 }
}