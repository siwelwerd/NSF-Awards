{
 "awd_id": "1948531",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: SaTC: RUI: A Cross-Verification Approach for Identifying Tampered Audio",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 174109.0,
 "awd_amount": 174109.0,
 "awd_min_amd_letter_date": "2020-05-06",
 "awd_max_amd_letter_date": "2020-05-06",
 "awd_abstract_narration": "Recent advances in technology have made it possible to create fake videos of celebrities doing or saying things they did not do or say.  There is concern that this technology may be used to influence elections by defaming candidates or to instigate civil unrest through false statements by public officials.  This project focuses on protecting world leaders from such fake impersonations.  It approaches the problem from a history-centric perspective by asking the question, \u201cIs this video a historically verifiable event?\u201d  In the same way that a historian tests a historical claim by cross-checking against other primary sources, we can test the authenticity of an audiovisual recording by cross-checking against other primary sources of audiovisual information.  This project develops such a cross-verification approach for identifying fake or tampered audio content.  The award will support undergraduate research at a highly diverse liberal arts college.\r\n\r\nThis project investigates audio cross-verification in two scenarios.  In the first scenario, the goal is to cross-verify a query with a trusted source recording, which is assumed to be reliable.  In order to identify tampering via insertion, deletion, or modification, the alignment between the query and source recording can be computed using dynamic time warping (DTW).  The key contribution in this scenario is developing an understanding of how to incorporate DTW into an end-to-end learning system using an appropriate smooth relaxation of DTW during training.  In the second scenario, the goal is to cross-verify a query with untrusted source recordings, which may themselves be tampered.  The key contribution in the second scenario is to extend existing alignment techniques to jointly align a collection of recordings in the presence of malicious tampering, and to reconstruct the audio ground truth.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "Tsai",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy Tsai",
   "pi_email_addr": "ttsai@hmc.edu",
   "nsf_id": "000750649",
   "pi_start_date": "2020-05-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvey Mudd College",
  "inst_street_address": "301 PLATT BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "CLAREMONT",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9096218121",
  "inst_zip_code": "917115901",
  "inst_country_name": "United States",
  "cong_dist_code": "28",
  "st_cong_dist_code": "CA28",
  "org_lgl_bus_name": "HARVEY MUDD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "C76JKA5JY2B3"
 },
 "perf_inst": {
  "perf_inst_name": "Harvey Mudd College",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "917115990",
  "perf_ctry_code": "US",
  "perf_cong_dist": "28",
  "perf_st_cong_dist": "CA28",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9229",
   "pgm_ref_txt": "RES IN UNDERGRAD INST-RESEARCH"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 174109.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The key central question that this project addresses is: \"How can we establish the historicity of an audiovisual event in an age of deep fake technology and audio editing software?\"&nbsp; This problem is approached from a history-centric perspective, in which a historical claim is tested by cross-verifying it against other primary sources.&nbsp; Using broadcast recordings from major news agencies as a trusted source, for example, one can determine if a video of a political speech posted on social media is trustworthy, or if it has been tampered.</p>\n<p>The main research outcomes of this project are practical tools for cross-verification of audio recordings.&nbsp; These tools must be accurate, fast to compute, robust against harmless differences (e.g. differences in volume, equalization, encoding format, compression level), and interpretable/explainable.&nbsp; The last characteristic is particularly important because the system's decisions may be the basis for public confidence in the authenticity of data, and must therefore be justifiable and not simply black box predictions.&nbsp;</p>\n<p>One of the primary tools that was developed for cross-verifying one audio recording against another is called Dual Alignment Likelihood Ratio Test (DA-LRT).&nbsp; DA-LRT defines two interpretable hypotheses (tampered vs non-tampered), estimates the most likely temporal alignment between the two audio recordings under each hypothesis, and then performs a hypothesis test on the two alignments.&nbsp; This method is effective in detecting insertion and deletion tampering operations on speech recordings down to &lt;0.25 seconds in duration, and in detecting replacement tampering operations down to 0.5-1.0 seconds in duration.</p>\n<p>Other tools developed in this project include: (a) a novel alignment method that is specifically designed to model discontinuities resulting from insertion, deletion, and replacement tampering operations, (b) several parallelizable approximations of a widely used alignment algorithm called dynamic time warping (DTW) to perform alignment efficiently on long sequences, as well as (c) an exact implementation of DTW that utilizes modern hardware like GPUs that are optimized for parallel processing.</p>\n<p>The broader impacts of this project include:</p>\n<p>1.&nbsp; Tools for establishing trustworthiness of audiovisual data.&nbsp; The cross-verification techniques developed in this project can be used to verify the authenticity of speech recordings, giving the public confidence that what they are hearing is an accurate representation of the truth.</p>\n<p>2.&nbsp; More flexible and efficient alignment techniques.&nbsp; The alignment techniques developed for audio cross-verification can be readily adapted to alignment problems in other domains involving time series data.&nbsp;</p>\n<p>3.&nbsp; Contributing to a diverse, robust STEM workforce.&nbsp; This project enabled twelve students to participate in a research experience for undergraduates.&nbsp; Students received in-depth mentoring and training throughout the process, including writing research papers and presenting their work at an international conference.&nbsp; Six of the twelve students are from groups traditionally underrepresented in STEM.</p>\n<p>4.&nbsp; Infrastructure for education &amp; research.&nbsp; Project funds were used to purchase computational infrastructure that has expanded the education and research opportunities at a small liberal arts college.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/09/2023<br>\n\t\t\t\t\tModified by: Timothy&nbsp;Tsai</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe key central question that this project addresses is: \"How can we establish the historicity of an audiovisual event in an age of deep fake technology and audio editing software?\"  This problem is approached from a history-centric perspective, in which a historical claim is tested by cross-verifying it against other primary sources.  Using broadcast recordings from major news agencies as a trusted source, for example, one can determine if a video of a political speech posted on social media is trustworthy, or if it has been tampered.\n\nThe main research outcomes of this project are practical tools for cross-verification of audio recordings.  These tools must be accurate, fast to compute, robust against harmless differences (e.g. differences in volume, equalization, encoding format, compression level), and interpretable/explainable.  The last characteristic is particularly important because the system's decisions may be the basis for public confidence in the authenticity of data, and must therefore be justifiable and not simply black box predictions. \n\nOne of the primary tools that was developed for cross-verifying one audio recording against another is called Dual Alignment Likelihood Ratio Test (DA-LRT).  DA-LRT defines two interpretable hypotheses (tampered vs non-tampered), estimates the most likely temporal alignment between the two audio recordings under each hypothesis, and then performs a hypothesis test on the two alignments.  This method is effective in detecting insertion and deletion tampering operations on speech recordings down to &lt;0.25 seconds in duration, and in detecting replacement tampering operations down to 0.5-1.0 seconds in duration.\n\nOther tools developed in this project include: (a) a novel alignment method that is specifically designed to model discontinuities resulting from insertion, deletion, and replacement tampering operations, (b) several parallelizable approximations of a widely used alignment algorithm called dynamic time warping (DTW) to perform alignment efficiently on long sequences, as well as (c) an exact implementation of DTW that utilizes modern hardware like GPUs that are optimized for parallel processing.\n\nThe broader impacts of this project include:\n\n1.  Tools for establishing trustworthiness of audiovisual data.  The cross-verification techniques developed in this project can be used to verify the authenticity of speech recordings, giving the public confidence that what they are hearing is an accurate representation of the truth.\n\n2.  More flexible and efficient alignment techniques.  The alignment techniques developed for audio cross-verification can be readily adapted to alignment problems in other domains involving time series data. \n\n3.  Contributing to a diverse, robust STEM workforce.  This project enabled twelve students to participate in a research experience for undergraduates.  Students received in-depth mentoring and training throughout the process, including writing research papers and presenting their work at an international conference.  Six of the twelve students are from groups traditionally underrepresented in STEM.\n\n4.  Infrastructure for education &amp; research.  Project funds were used to purchase computational infrastructure that has expanded the education and research opportunities at a small liberal arts college.\n\n\t\t\t\t\tLast Modified: 08/09/2023\n\n\t\t\t\t\tSubmitted by: Timothy Tsai"
 }
}