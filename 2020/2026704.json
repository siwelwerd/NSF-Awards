{
 "awd_id": "2026704",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER:  Collaborative Research:  III:  Exploring Physics Guided Machine Learning for Accelerating Sensing and Physical Sciences",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Amarda Shehu",
 "awd_eff_date": "2020-05-01",
 "awd_exp_date": "2021-04-30",
 "tot_intn_awd_amt": 50194.0,
 "awd_amount": 50194.0,
 "awd_min_amd_letter_date": "2020-04-20",
 "awd_max_amd_letter_date": "2020-04-20",
 "awd_abstract_narration": "As machine learning (ML) continues to revolutionize the commercial space including vision, speech, and\r\ntext recognition, there is great anticipation in the scientific community to unlock the power of ML for\r\naccelerating scientific discovery. However, black-box ML models, which rely solely on training data and\r\nignore existing scientific knowledge have met with limited success in scientific problems, particularly\r\nwhen labeled data is limited, sometimes even leading to spectacular failures. This is because the black\r\nbox ML models are susceptible to learning spurious relationships that do not generalize well outside the\r\ndata they are trained for. The emerging paradigm of physics-guided machine learning (PGML), which\r\nleverages the unique ability of ML algorithms to automatically extract patterns and models from data with\r\nguidance of the knowledge accumulated in physics (or scientific theories), aims to address the challenges\r\nfaced by black box ML in scientific applications. Significant exploratory efforts are needed to formulate and assess sound PGML approaches for particular scientific problems.\r\n\r\nFor data science, PGML has the potential to transform ML beyond black-box applications by enabling\r\nsolutions that generalize well even on unseen input-output distributions that are different from those\r\nencountered during training, by anchoring ML methods with the scientific body of knowledge. PGML makes a distinct\r\ndeparture from the conventional view that physics-based models and ML models are developed in\r\nisolation but seldom mixed together. The proposed project is fundamentally different from existing body\r\nof research that attempts to combine ML and domain sciences, e.g., by making use of domain-specific\r\nknowledge in ML algorithms in simplistic ways, or making use of data in the physics-based modeling\r\nprocess albeit without allowing data to change the functional forms of existing physics-based models. The tight interplay between data science and the domains of physics and sensing in the project lends itself\r\nnaturally to diverse education activities that complement the research tasks outlined by our team. Over the\r\nduration of this one-year project, the team will develop an integrative course at the graduate level on \"ML\r\nmeets Physics\", which explores topical, emerging themes in this interdisciplinary area. Offerings of the\r\ncourse will draw upon course modules shared between the four universities, such as shared guest videos\r\nand case studies. The physics department at BU has a well-developed \"Physics Outreach Project\" that\r\nannually performs science exhibitions for elementary schools in Binghamton metropolitan area, for which\r\nthe team will create a new exhibition about neural networks and ML. In follow-on work, similar outreach\r\nevents will be replicated at schools (Robinson Middle School in Lowell and Metro STEM Middle School\r\nin Columbus). The PIs are committed to increasing the diversity of involvement at various levels of the\r\ntraining ecosystem impacted by this project, and have planned various coordinated broader impact\r\nactivities for inclusion of female and underrepresented minority students as well as faculty.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anish",
   "pi_last_name": "Arora",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Anish K Arora",
   "pi_email_addr": "anish@cse.ohio-state.edu",
   "nsf_id": "000378457",
   "pi_start_date": "2020-04-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio State University",
  "inst_street_address": "1960 KENNY RD",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBUS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "6146888735",
  "inst_zip_code": "432101016",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OH03",
  "org_lgl_bus_name": "OHIO STATE UNIVERSITY, THE",
  "org_prnt_uei_num": "MN4MDDMN8529",
  "org_uei_num": "DLWBSLWAJWR1"
 },
 "perf_inst": {
  "perf_inst_name": "Ohio State University",
  "perf_str_addr": "",
  "perf_city_name": "Columbus",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "432101016",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OH03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 50194.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>As machine learning (ML) continues to advance the quality of human life through developments in machine vision, automatic translation, and medicine, there is a rising expectation that ML will advance the process of scientific discovery itself. However, modern mainstream black-box machine learning tools tend to learn on data alone and do not consider existing body of scientific knowledge. In this collaborative EAGER project, a team of researchers from Ohio State University, University of Massachusetts Lowell, Binghamton University, and Virginia Tech University aimed at exploring the pathways for embedding the scientific knowledge into ML process. Specifically, the interdisciplinary team aimed at developing the ML algorithms that help solve eigenvalue problems in quantum mechanics and electromagnetism and algorithms that enhance the efficiency of ML models.&nbsp;</p>\n<p>In the case of quantum mechanics, the collaboration between OSU and BU has led to a more efficient and scalable physics guided neural network (PGNN). Previous attempts to solve the Schrodinger's equation have employed physics loss in training a feed-forward network (FFN) to predict the 2<sup>N</sup> wave function coefficients resulting from all&nbsp;2<sup>N</sup> configuration states corresponding to the lowest energy eigenvector for a N-spin Ising model. However, this approach is not scalable because the output layer of the FFN is of the order of dimension d of Hamiltonian matrix which grows exponentially as d = 2<sup>N</sup>, where N is the number of spins.</p>\n<p>We employ physics knowledge in two separate ways, unlike the prior attempt, which only used it in the training loss. Firstly, we use physics to decompose the 2<sup>N</sup> configuration states into subspaces and assign an <em>Expert </em>model to learn only the targets in its own subspace. The subspace to <em>Expert </em>assignment is based on the quantum number of S<sub>z</sub> which is known to be sensitive to the quantum phase transition. Each <em>Expert </em>model therefore needs to learn only a small fraction of 2<sup>N</sup> targets. Additionally, each model is tasked to predict only one target at a time corresponding to a particular state. Second, we leverage a PG loss function, like the prior approach, to enforce the global constraint among the wavefunction components of all 2<sup>N</sup> states, which aids the <em>Ensemble of Experts (EE)</em> to be more generalizable.</p>\n<p>We use a 10-spin Ising model to illustrate the efficacy of our approach. We produce <em>EE</em><em> </em>that has 50x fewer parameters than the 2<sup>N</sup> output FFN model without compromising on the test loss. This allows us to work on a much larger N-spin system that cannot be trained easily by the previous approach.</p>\n<p>In a separate project aimed at scalable generation of radar data, OSU leveraged a modest size corpus of short-range radar data that it had collected in experiments over the past decade and enabled the use of a large corpus of simulation radar data to generate a large corpus of realistic radar data via a physics-guided generative adversarial network. The effort developed programmatic trace generation via a simulation framework that extends the Carla mobility simulator.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/17/2021<br>\n\t\t\t\t\tModified by: Anish&nbsp;K&nbsp;Arora</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/2026704/2026704_10665348_1631885193240_PGMLOutcomesReportImage1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/2026704/2026704_10665348_1631885193240_PGMLOutcomesReportImage1--rgov-800width.jpg\" title=\"Illustrating PGML for Scalable Machine Learning\"><img src=\"/por/images/Reports/POR/2021/2026704/2026704_10665348_1631885193240_PGMLOutcomesReportImage1--rgov-66x44.jpg\" alt=\"Illustrating PGML for Scalable Machine Learning\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Schematic illustration of collaborative expert machines. Left: Atraditional large single machine designed to learn all targets serves as the baseline model. Right: In the Ensemble of Experts approach, the learning targets are classified into several subgroups which is learned by separate Experts.</div>\n<div class=\"imageCredit\">Wei-Cheng Lee</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Anish&nbsp;K&nbsp;Arora</div>\n<div class=\"imageTitle\">Illustrating PGML for Scalable Machine Learning</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/2026704/2026704_10665348_1631885263290_PGMLOutcomesReportImage2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/2026704/2026704_10665348_1631885263290_PGMLOutcomesReportImage2--rgov-800width.jpg\" title=\"Illustrating PGML for Sensor Data Generation\"><img src=\"/por/images/Reports/POR/2021/2026704/2026704_10665348_1631885263290_PGMLOutcomesReportImage2--rgov-66x44.jpg\" alt=\"Illustrating PGML for Sensor Data Generation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A radar embedded (in the car in this example) is used to simulate a radar trace corresponding to the foreground targets (pedestrian to the right of the car in the example) and the other background objects in the scene.  A large number of such traces serve as input to the physics guided GAN training.</div>\n<div class=\"imageCredit\">Sharika Kumari</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Anish&nbsp;K&nbsp;Arora</div>\n<div class=\"imageTitle\">Illustrating PGML for Sensor Data Generation</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nAs machine learning (ML) continues to advance the quality of human life through developments in machine vision, automatic translation, and medicine, there is a rising expectation that ML will advance the process of scientific discovery itself. However, modern mainstream black-box machine learning tools tend to learn on data alone and do not consider existing body of scientific knowledge. In this collaborative EAGER project, a team of researchers from Ohio State University, University of Massachusetts Lowell, Binghamton University, and Virginia Tech University aimed at exploring the pathways for embedding the scientific knowledge into ML process. Specifically, the interdisciplinary team aimed at developing the ML algorithms that help solve eigenvalue problems in quantum mechanics and electromagnetism and algorithms that enhance the efficiency of ML models. \n\nIn the case of quantum mechanics, the collaboration between OSU and BU has led to a more efficient and scalable physics guided neural network (PGNN). Previous attempts to solve the Schrodinger's equation have employed physics loss in training a feed-forward network (FFN) to predict the 2N wave function coefficients resulting from all 2N configuration states corresponding to the lowest energy eigenvector for a N-spin Ising model. However, this approach is not scalable because the output layer of the FFN is of the order of dimension d of Hamiltonian matrix which grows exponentially as d = 2N, where N is the number of spins.\n\nWe employ physics knowledge in two separate ways, unlike the prior attempt, which only used it in the training loss. Firstly, we use physics to decompose the 2N configuration states into subspaces and assign an Expert model to learn only the targets in its own subspace. The subspace to Expert assignment is based on the quantum number of Sz which is known to be sensitive to the quantum phase transition. Each Expert model therefore needs to learn only a small fraction of 2N targets. Additionally, each model is tasked to predict only one target at a time corresponding to a particular state. Second, we leverage a PG loss function, like the prior approach, to enforce the global constraint among the wavefunction components of all 2N states, which aids the Ensemble of Experts (EE) to be more generalizable.\n\nWe use a 10-spin Ising model to illustrate the efficacy of our approach. We produce EE that has 50x fewer parameters than the 2N output FFN model without compromising on the test loss. This allows us to work on a much larger N-spin system that cannot be trained easily by the previous approach.\n\nIn a separate project aimed at scalable generation of radar data, OSU leveraged a modest size corpus of short-range radar data that it had collected in experiments over the past decade and enabled the use of a large corpus of simulation radar data to generate a large corpus of realistic radar data via a physics-guided generative adversarial network. The effort developed programmatic trace generation via a simulation framework that extends the Carla mobility simulator.\n\n\t\t\t\t\tLast Modified: 09/17/2021\n\n\t\t\t\t\tSubmitted by: Anish K Arora"
 }
}