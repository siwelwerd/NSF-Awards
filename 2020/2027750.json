{
 "awd_id": "2027750",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RAPID: ENSURING INTEGRITY OF COVID-19 DATA AND NEWS ACROSS REGIONS",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2020-05-01",
 "awd_exp_date": "2022-04-30",
 "tot_intn_awd_amt": 199748.0,
 "awd_amount": 199748.0,
 "awd_min_amd_letter_date": "2020-04-21",
 "awd_max_amd_letter_date": "2020-04-21",
 "awd_abstract_narration": "Large amounts of epidemiological data are being generated and collected from a variety of sources to understand the impact and propagation of COVID-19. Similarly, huge amounts of news articles are generated and disseminated about the pandemic to keep the population informed. The appropriateness of the actions taken by individuals, corporations, and governments are often based on the quality of data and news. Thus, ensuring the quality of data and news is important. However, malicious actors can alter the attributes of data records, insert spurious records, or suppress records causing any analysis to be inadequate and misinformation to be propagated. This project addresses the critical problem of defining and identifying spurious data and news concerning COVID-19, and tracking the source of misinformation. The project novelty lies in the development of an approach and associated toolset that adapts and combines Machine Learning technologies to detect spurious data and misinformation and presents the results in a manner that is easy for end users to understand and interpret. The approach detects discrepancies in COVID-19 data and traces the flagged discrepancies back to the data sources. The results obtained from the news sources and those obtained from the medical data analysis are compared to determine correlations between the quality of news and the degree and type of data manipulation performed at any region. The project\u2019s impacts are on significantly enhancing the ability to perform accurate scientific analysis, and detecting and explaining news manipulation with respect to COVID-19. The scientific principles developed in the project are expected to be useful outside the medical domain. The PI and the students identified for this project are minorities. The project will be carried out in the Computer Science Department at Colorado State University which is a BRAID affiliate.\r\n\r\nCOVID-19 data discrepancies are related to (1) single records, where some field is modified, (2) sequence of records over time forming a temporal dimension, where spurious records have been inserted or records have been suppressed, and (3) sequences of records across regions forming a spatial dimension, where there is a pattern of manipulation or information disclosure across regions. The approach determines the appropriate combination of autoencoders, Long Short-Term Memory (LSTM), Temporal Convolution Network (TCNs), and Convolution Neural Networks (CNNs) that can work with data obtained from medical sources and news containing both spatial and temporal dimensions. The tools help the investigators\u2019 collaborators at the University of Colorado Anschutz Medical Center and Center for Disease Control and Prevention to perform data integrity checking of medical records and to provide explanations of integrity violations. The tools also handle different types of data and news alterations pertaining to COVID-19.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Indrakshi",
   "pi_last_name": "Ray",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Indrakshi Ray",
   "pi_email_addr": "iray@cs.colostate.edu",
   "nsf_id": "000484109",
   "pi_start_date": "2020-04-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sudipto",
   "pi_last_name": "Ghosh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sudipto Ghosh",
   "pi_email_addr": "ghosh@cs.colostate.edu",
   "nsf_id": "000392748",
   "pi_start_date": "2020-04-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Colorado State University",
  "inst_street_address": "601 S HOWES ST",
  "inst_street_address_2": "",
  "inst_city_name": "FORT COLLINS",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "9704916355",
  "inst_zip_code": "805212807",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "COLORADO STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "LT9CXX8L19G1"
 },
 "perf_inst": {
  "perf_inst_name": "Colorado State University",
  "perf_str_addr": "200 W Lake St",
  "perf_city_name": "Fort Collins",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "805214593",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "158Y00",
   "pgm_ele_name": "COVID-19 Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "096Z",
   "pgm_ref_txt": "COVID-19 Research"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7914",
   "pgm_ref_txt": "RAPID"
  },
  {
   "pgm_ref_code": "8225",
   "pgm_ref_txt": "SaTC Special Projects"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "1N20",
   "app_name": "R&RA CARES Act DEFC N",
   "app_symb_id": "040100",
   "fund_code": "010N2021DB",
   "fund_name": "R&RA CARES Act DEFC N",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 199748.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><dd>\n<div class=\"tinyMCEContent\">\n<p>&nbsp;</p>\n<p>Modern day society relies a lot on data analytics. The results of the analysis depend on the quality of input data. Huge volumes of input data are generated by various heterogeneous sources which are transformed and stored in data warehouses. This transformation process is non-trivial and error-prone. Such errors reduce the quality of the data. Towards this end, our goal was to demonstrate how to find anomalies in large volumes of data and demonstrate the anomalies to the domain-user.&nbsp;</p>\n<p>We proposed an LSTM-autoencoder based approach for data quality testing of sequential Covid-19 records, which provides explanations of constraint violations in a manner that is understandable to end-users. This entailed the development of new data preparation techniques for use by the LSTM-autoencoder. For big volumes of data, the number of anomalies generated may be high. Moreover, the domain experts also need to know the nature of the anomalies. Towards this end, we developed data visualization plots for anomaly explanation. &nbsp;Our approach was evaluated against various Covid-19 datasets. We were able to detect anomalous subsequence in Covid-19 Tracking data set in the number of deaths reported in the New York state using our algorithms. We were also able to detect ten abnormal subsequences in the University Colorado Anschutz Medical Covid-19 Datasets.&nbsp;</p>\n<p>Misinformation also plays a critical role in modern day democracy. Social media is responsible for spreading much of this misinformation. We focused on Twitter data. Tweets have a limit on their length and may use emojis. Consequently, the language structure is different from that found in written forms. Our goal was to detect and thwart the spread of misinformation in Twitter data before it can get propagated.</p>\n<p>We collected a very large volume of Twitter data. We stored them and manually annotated them for various research tasks. We developed a tool that facilitates the labeling process. The tool allows multiple annotators to label Tweets. Whenever there is a discrepancy in the labels of a Tweet, the Tweet gets automatically sent for labeling to an independent annotator.&nbsp;</p>\n<p>We developed an approach to identify whether the information in a Tweet is indeed supported by the cited&nbsp;news article. Our approach is empirically based on a corpus of over 46.86 million Tweets and is divided into&nbsp;two tasks: (i) development of models to detect Tweets containing claim and worth to be fact-checked and (ii)&nbsp;verifying whether the claims made in a Tweet are supported by the newswire article it cites. When a claim does not support the cited news article, it serves to mislead readers and is a source of misinformation. We were able to detect such misinformation even before it starts spreading.&nbsp;We discover that&nbsp;nearly half of the Tweets (43.4%) are not factual and hence not worth checking -- a significant filter, given the&nbsp;sheer volume of social media posts on a platform such as Twitter. Moreover, we find that among the Tweets&nbsp;that contain a seemingly factual claim while citing a news article as supporting evidence, at least 1% are not&nbsp;actually supported by the cited news, and are hence misleading.</p>\n<p>Social media bots also serve to propagate misinformation. We employ an end-to-end neural network architecture for deep fake text detection on Twitter dataset. Our experiments achieve the state of the art performance and improve the classification accuracy by 2% compared to previously tested models. Moreover, our content-level approach can be used for fake posts detection in social media in real-time.&nbsp;</p>\n</div>\n</dd><dd>\n<div class=\"tinyMCEContent\">\n<p>In addition to the research contributions, this project also involved training students. All levels of students were involved in this project, ranging from undergraduate freshmen to post-doc. Undergraduate freshmen were involved with labeling Twitter data. More senior level undergraduate students were involved in developing databases and executing machine learning algorithms. 11 undergraduate students were involved, which included five minorities. The two M.S. students worked mostly on the misinformation detection projects, one of whom was a woman. Three Ph.D.s were involved as well. One focused on data quality and the other two helped on the social media project. &nbsp;Two of these Ph.D.s were women. One of the Ph.D.s subsequently worked as a post-doc. Junior faculty at another institution was involved. The students learned to work in a group setting and also got to work with faculty and students at other institutions.&nbsp;</p>\n<p>Many of these undergraduates are now participating in research in other projects. The two undergraduates who have completed have joined Amazon and Raytheon. The M.S. graduate students are now pursuing their Ph.D.s at a higher ranked university. The Ph.D.s and post-docs all have tenure-track faculty positions.&nbsp;</p>\n</div>\n</dd><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/27/2022<br>\n\t\t\t\t\tModified by: Indrakshi&nbsp;Ray</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\n \n\nModern day society relies a lot on data analytics. The results of the analysis depend on the quality of input data. Huge volumes of input data are generated by various heterogeneous sources which are transformed and stored in data warehouses. This transformation process is non-trivial and error-prone. Such errors reduce the quality of the data. Towards this end, our goal was to demonstrate how to find anomalies in large volumes of data and demonstrate the anomalies to the domain-user. \n\nWe proposed an LSTM-autoencoder based approach for data quality testing of sequential Covid-19 records, which provides explanations of constraint violations in a manner that is understandable to end-users. This entailed the development of new data preparation techniques for use by the LSTM-autoencoder. For big volumes of data, the number of anomalies generated may be high. Moreover, the domain experts also need to know the nature of the anomalies. Towards this end, we developed data visualization plots for anomaly explanation.  Our approach was evaluated against various Covid-19 datasets. We were able to detect anomalous subsequence in Covid-19 Tracking data set in the number of deaths reported in the New York state using our algorithms. We were also able to detect ten abnormal subsequences in the University Colorado Anschutz Medical Covid-19 Datasets. \n\nMisinformation also plays a critical role in modern day democracy. Social media is responsible for spreading much of this misinformation. We focused on Twitter data. Tweets have a limit on their length and may use emojis. Consequently, the language structure is different from that found in written forms. Our goal was to detect and thwart the spread of misinformation in Twitter data before it can get propagated.\n\nWe collected a very large volume of Twitter data. We stored them and manually annotated them for various research tasks. We developed a tool that facilitates the labeling process. The tool allows multiple annotators to label Tweets. Whenever there is a discrepancy in the labels of a Tweet, the Tweet gets automatically sent for labeling to an independent annotator. \n\nWe developed an approach to identify whether the information in a Tweet is indeed supported by the cited news article. Our approach is empirically based on a corpus of over 46.86 million Tweets and is divided into two tasks: (i) development of models to detect Tweets containing claim and worth to be fact-checked and (ii) verifying whether the claims made in a Tweet are supported by the newswire article it cites. When a claim does not support the cited news article, it serves to mislead readers and is a source of misinformation. We were able to detect such misinformation even before it starts spreading. We discover that nearly half of the Tweets (43.4%) are not factual and hence not worth checking -- a significant filter, given the sheer volume of social media posts on a platform such as Twitter. Moreover, we find that among the Tweets that contain a seemingly factual claim while citing a news article as supporting evidence, at least 1% are not actually supported by the cited news, and are hence misleading.\n\nSocial media bots also serve to propagate misinformation. We employ an end-to-end neural network architecture for deep fake text detection on Twitter dataset. Our experiments achieve the state of the art performance and improve the classification accuracy by 2% compared to previously tested models. Moreover, our content-level approach can be used for fake posts detection in social media in real-time. \n\n\n\n\nIn addition to the research contributions, this project also involved training students. All levels of students were involved in this project, ranging from undergraduate freshmen to post-doc. Undergraduate freshmen were involved with labeling Twitter data. More senior level undergraduate students were involved in developing databases and executing machine learning algorithms. 11 undergraduate students were involved, which included five minorities. The two M.S. students worked mostly on the misinformation detection projects, one of whom was a woman. Three Ph.D.s were involved as well. One focused on data quality and the other two helped on the social media project.  Two of these Ph.D.s were women. One of the Ph.D.s subsequently worked as a post-doc. Junior faculty at another institution was involved. The students learned to work in a group setting and also got to work with faculty and students at other institutions. \n\nMany of these undergraduates are now participating in research in other projects. The two undergraduates who have completed have joined Amazon and Raytheon. The M.S. graduate students are now pursuing their Ph.D.s at a higher ranked university. The Ph.D.s and post-docs all have tenure-track faculty positions. \n\n\n\n\t\t\t\t\tLast Modified: 08/27/2022\n\n\t\t\t\t\tSubmitted by: Indrakshi Ray"
 }
}