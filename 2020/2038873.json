{
 "awd_id": "2038873",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: Medium: Robust Learning for Perception-Based Autonomous Systems",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": "7032928126",
 "po_email": "yhuang@nsf.gov",
 "po_sign_block_name": "Yih-Fang Huang",
 "awd_eff_date": "2020-09-15",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 1199055.0,
 "awd_amount": 1199055.0,
 "awd_min_amd_letter_date": "2020-09-08",
 "awd_max_amd_letter_date": "2020-10-14",
 "awd_abstract_narration": "Consider two future autonomous system use-cases: (i) a bomb defusing rover sent into an unfamiliar, GPS and communication denied environment (e.g., a cave or mine), tasked with the objective of locating and defusing an improvised explosive device, and (ii) an autonomous racing drone competing in a future autonomous incarnation of the Drone Racing League.  Both systems will make decisions based on inputs from a combination of simple, single output sensing devices, such as inertial measurement units, and complex, high dimensional output sensing modalities, such as cameras and LiDAR.  This shift from relying only on simple, single output sensing devices to systems that incorporate rich, complex perceptual sensing modalities requires rethinking the design of safety-critical autonomous systems, especially given the inextricable role that machine and deep learning play in the design of modern perceptual sensors.  These two motivating examples raise an even more fundamental question however: given the vastly different dynamics, environments, objectives, and safety/risk constraints, should these two systems have perceptual sensors with different properties?  Indeed, due to the extremely safety critical nature of the bomb defusing task, an emphasis on robustness, risk aversion, and safety seems necessary.  Conversely, the designer of the drone racer may be willing to sacrifice robustness to maximize responsiveness and lower lap-time.  This extreme diversity in requirements highlights the need for a principled approach to navigate tradeoffs in this complex design space, which is what this proposal seeks to develop.  Existing approaches to designing perception/action pipelines are either modular, which often ignore uncertainty and limit interaction between components, or monolithic and end-to-end, which are difficult to interpret, troubleshoot, and have high sample-complexity. \r\n\r\nThis project proposes an alternative approach and rethinks the scientific foundations of using machine learning and computer vision to process rich high-dimensional perceptual data for use in safety-critical cyber-physical control applications.  Thrusts will develop integration between perception, planning and control that allow for their co-design and co-optimization.  Using novel robust learning methods for perceptual representations and predictive models that characterize tradeoffs between robustness (e.g., to lighting & weather changes, rotations) and performance (e.g., responsiveness, discriminativeness), jointly learned perception maps and uncertainty profiles will be abstracted as ``noisy virtual sensors\u201d for use in uncertainty aware perception-based planning & control algorithms with stability, performance, and safety guarantees.  These insights will be integrated into novel perception-based model predictive control algorithms, which allow for planning, stability, and safety guarantees through a unifying optimization-based framework acting on rich perceptual data.  Experimental validation of the benefits of these methods will be conducted at Penn using photorealistic simulations and physical camera equipped quadcopters, and be used to demonstrate perception-based planning and control algorithms at the extremes of speed/safety tradeoffs.   On the educational front, the research outcomes of this proposal will be used to develop a sequence of courses on safe autonomy, safe perception, and learning and control at the University of Pennsylvania. Longer term, the goal of this project is to create a new community of researchers that focus on robust learning for perception-based control. Towards this goal, departmental efforts will be leveraged to increase and diversify the PhD students working on this project.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nikolai",
   "pi_last_name": "Matni",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nikolai Matni",
   "pi_email_addr": "nmatni@seas.upenn.edu",
   "nsf_id": "000825958",
   "pi_start_date": "2020-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kostas",
   "pi_last_name": "Daniilidis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kostas Daniilidis",
   "pi_email_addr": "kostas@cis.upenn.edu",
   "nsf_id": "000207772",
   "pi_start_date": "2020-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "George",
   "pi_last_name": "Pappas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "George Pappas",
   "pi_email_addr": "pappasg@seas.upenn.edu",
   "nsf_id": "000156545",
   "pi_start_date": "2020-09-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "200 S. 33rd Street",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046314",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "791800",
   "pgm_ele_name": "CPS-Cyber-Physical Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 1199055.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"whitespace-pre-wrap break-words\">Autonomous systems increasingly rely on complex perceptual sensors like cameras and LIDAR to make critical real-time decisions. This shift from simple sensors to rich perceptual data creates fundamental challenges in balancing competing objectives like robustness, safety, and performance. This project developed new methods for designing autonomous systems that can systematically reason about uncertainty while maintaining interpretability and modularity between perception and control components.</p>\r\n<p class=\"whitespace-pre-wrap break-words\">This project made significant advances in foundational theory and algorithms for robust perception-based autonomy. Highlights include novel frameworks for certifying robustness of machine learning based perception operating in real-world environments, new methods for active view selection and mapping based on measures of perceptual uncertainty, and rigorous approaches for learning safe controllers from expert demonstrations. A major breakthrough was the development of uncertainty quantification techniques (based on&nbsp;conformal prediction)&nbsp;that provide formal safety guarantees for perception-based planning and control.&nbsp;</p>\r\n<p class=\"whitespace-pre-wrap break-words\">The project's broader impacts include both technical and educational contributions. The developed methods have potential applications in critical domains like autonomous transportation and robotic assistance, where reliable perception-based decision-making is essential. The research was disseminated through numerous publications in top venues and through workshops organized at major conferences in control theory, robotics, and machine learning, which advanced the goal of establishing an interdisciplinary community that studies robust perception-based control. Multiple PhD students and postdoctoral researchers were trained through the project.&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/30/2024<br>\nModified by: Nikolai&nbsp;Matni</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nAutonomous systems increasingly rely on complex perceptual sensors like cameras and LIDAR to make critical real-time decisions. This shift from simple sensors to rich perceptual data creates fundamental challenges in balancing competing objectives like robustness, safety, and performance. This project developed new methods for designing autonomous systems that can systematically reason about uncertainty while maintaining interpretability and modularity between perception and control components.\r\n\n\nThis project made significant advances in foundational theory and algorithms for robust perception-based autonomy. Highlights include novel frameworks for certifying robustness of machine learning based perception operating in real-world environments, new methods for active view selection and mapping based on measures of perceptual uncertainty, and rigorous approaches for learning safe controllers from expert demonstrations. A major breakthrough was the development of uncertainty quantification techniques (based onconformal prediction)that provide formal safety guarantees for perception-based planning and control.\r\n\n\nThe project's broader impacts include both technical and educational contributions. The developed methods have potential applications in critical domains like autonomous transportation and robotic assistance, where reliable perception-based decision-making is essential. The research was disseminated through numerous publications in top venues and through workshops organized at major conferences in control theory, robotics, and machine learning, which advanced the goal of establishing an interdisciplinary community that studies robust perception-based control. Multiple PhD students and postdoctoral researchers were trained through the project.\r\n\n\n\t\t\t\t\tLast Modified: 12/30/2024\n\n\t\t\t\t\tSubmitted by: NikolaiMatni\n"
 }
}