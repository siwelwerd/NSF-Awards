{
 "awd_id": "2007159",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: An Integrated Hardware-Software Architecture for Efficient, Low-Power, Spatially Collaborative Computing in Augmented Reality",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 466000.0,
 "awd_min_amd_letter_date": "2020-06-30",
 "awd_max_amd_letter_date": "2021-09-07",
 "awd_abstract_narration": "Emerging mobile applications are increasingly focused on technology interacting with and augmenting the real-world environment the user occupies. Augmented reality is a technology that places virtual objects on a user\u2019s view of the real world with a wide range of applications such as navigation, gaming, and education. Augmented reality as a technology is inherently extremely computation-heavy, leading to latency, accuracy, and energy-consumption issues on resource-constrained smartphones. Image-recognitio- based augmented reality compounds this issue by requiring the computation of the entire image-recognition pipeline. In addition, mobile hardware is not designed with augmented reality and heavy image-based computations in mind. Mobile caching, multicores, GPUs and other mobile architectures are not being utilized to their full potential to help resolve the issues plaguing mobile augmented reality. This project explores methods to utilize the unique mobile architecture of off-the-shelf smartphones in new ways to realize augmented reality on a wide variety of mobile devices. Specifically, augmented reality has become an important tool for educators at all levels from K-12 all the way through collegiate and post-graduation education. This project will allow for this new educational technology to be more widely utilized in the world.\r\n\r\nThe objective of this project is to enable smartphones to support augmented reality via efficiently and seamlessly computing image-recognition and world-tracking tasks simultaneously, with three research components. (1) Investigate the foundational issues of smartphone-based augmented-reality through approximate-tracking to provide high-quality object tracking at reduced computational and energy loads. (2) Research software-defined caching techniques to utilize the unique nature of mobile augmented reality to provide caching specially designed for highly collaborative device-to-device augmented reality. (3) Explore hardware-based techniques relating to GPGPU computation and cache management to facilitate fast and efficient image-recognition and augmented-reality tasks.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Li",
   "pi_last_name": "Xiao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Li Xiao",
   "pi_email_addr": "lxiao@cse.msu.edu",
   "nsf_id": "000244982",
   "pi_start_date": "2020-06-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Yunhao",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yunhao Liu",
   "pi_email_addr": "yunhao@cse.msu.edu",
   "nsf_id": "000778999",
   "pi_start_date": "2020-06-30",
   "pi_end_date": "2021-09-07"
  }
 ],
 "inst": {
  "inst_name": "Michigan State University",
  "inst_street_address": "426 AUDITORIUM RD RM 2",
  "inst_street_address_2": "",
  "inst_city_name": "EAST LANSING",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "5173555040",
  "inst_zip_code": "488242600",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MI07",
  "org_lgl_bus_name": "MICHIGAN STATE UNIVERSITY",
  "org_prnt_uei_num": "VJKZC4D1JN36",
  "org_uei_num": "R28EKN92ZTZ9"
 },
 "perf_inst": {
  "perf_inst_name": "Michigan State University",
  "perf_str_addr": "428 S. Shaw Lane Room 1128",
  "perf_city_name": "East Lansing",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "488241226",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MI07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 450000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Computer vision on smartphones is commonly achieved through the use of convolutional neural networks (CNNs). CNNs offer accurate image recognition, but struggle with latency when run with resource constraints. Current work in mobile CNNs aim to improve the latency on mobile devices through techniques such as quantization, model compression, early-exit, caching, etc. While these methods can improve the overall latency of image recognition, they also sacrifice significant accuracy. This problem is compounded by the wide range of pre-trained CNNs that have been released over the past decade. Many of these useful CNNs were developed before innovations that improved the efficiency of CNNs. Anyone attempting to use a CNN trained many years ago may be out of luck. We introduce a computation caching scheme paired with early-exit strategies to improve the latency of CNNs on smartphones. Our system has both offline and online components. The offline system is used to find patterns in CNN execution, which are stored on the device. The online component reviews the current state of a CNN execution, determines if it matches a saved pattern, and can choose to forgo the full CNN execution and return a classification immediately. This system improves the speed of image recognition on any smartphone. It also requires no modification to the CNN, and no CNN training, meaning that it can be applied to any CNN that you can find, including many developed years ago. Our system achieves an average latency reduction of 17% while maintaining strong accuracy.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/11/2024<br>\nModified by: Li&nbsp;Xiao</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nComputer vision on smartphones is commonly achieved through the use of convolutional neural networks (CNNs). CNNs offer accurate image recognition, but struggle with latency when run with resource constraints. Current work in mobile CNNs aim to improve the latency on mobile devices through techniques such as quantization, model compression, early-exit, caching, etc. While these methods can improve the overall latency of image recognition, they also sacrifice significant accuracy. This problem is compounded by the wide range of pre-trained CNNs that have been released over the past decade. Many of these useful CNNs were developed before innovations that improved the efficiency of CNNs. Anyone attempting to use a CNN trained many years ago may be out of luck. We introduce a computation caching scheme paired with early-exit strategies to improve the latency of CNNs on smartphones. Our system has both offline and online components. The offline system is used to find patterns in CNN execution, which are stored on the device. The online component reviews the current state of a CNN execution, determines if it matches a saved pattern, and can choose to forgo the full CNN execution and return a classification immediately. This system improves the speed of image recognition on any smartphone. It also requires no modification to the CNN, and no CNN training, meaning that it can be applied to any CNN that you can find, including many developed years ago. Our system achieves an average latency reduction of 17% while maintaining strong accuracy.\n\n\n\t\t\t\t\tLast Modified: 10/11/2024\n\n\t\t\t\t\tSubmitted by: LiXiao\n"
 }
}