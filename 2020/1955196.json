{
 "awd_id": "1955196",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: CNS Core: Medium: Exploiting Synergies Between Machine-Learning Algorithms and Hardware Heterogeneity for High-Performance and Reliable Manycore Computing",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jason Hallstrom",
 "awd_eff_date": "2020-06-15",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2020-06-12",
 "awd_max_amd_letter_date": "2023-02-07",
 "awd_abstract_narration": "Advanced computing systems have long been enablers for breakthroughs in science, engineering, and new technologies. However, with the slowing down of Moore\u2019s law and the relentless needs of Big-Data applications, e.g., deep learning, graph analytics, and scientific simulations, current solutions are not adequate. There is a need for innovative computer architectures and computationally efficient methods to design application-specific hardware systems to optimize performance, power consumption, and reliability. The main focus of this work is design and demonstration of a heterogeneous single-chip manycore platform, integrating CPU, GPU, accelerator, and memory cores, via a network-on-chip to avoid expensive off-chip data transfers. The goal of this project is to address the design of application-specific heterogeneous manycore systems that are poised to achieve unprecedented levels of performance and energy-efficiency for Big-Data applications. The PIs will disseminate research outcomes via publications, seminars, tutorials, and workshops. The project is also leading to the development of an interdisciplinary research-based curriculum integrating computer architectures, machine learning, and data-driven design optimization. Undergraduate and graduate students involved in this research will be trained to apply classroom knowledge to research problems that require next-generation hardware, software, and theoretical expertise. \r\n\r\nThe project will lay the foundations for a novel computing paradigm for Big-Data applications that allows us to quickly design and autonomously self-manage heterogeneous manycore computing systems to improve performance, reduce power consumption, and enhance reliability. In-memory processing can overcome the memory wall, but it introduces new challenges in overall application-specific system optimization. The specific research tasks include: 1) Data-driven multi-objective design space exploration and optimization algorithms for heterogeneous manycore architectures; 2) Reliability assessment and system design for reliability; 3) Structured learning framework for autonomous resource management; and 4) Performance, power, and reliability evaluation using emerging Big-Data application workloads. This framework will combine the benefits of multi-objective design space exploration and optimization, heterogeneity in computation and communication, and data-driven algorithms to improve performance, energy-efficiency, and reliability of manycore platforms.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hai",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hai Li",
   "pi_email_addr": "hai.li@duke.edu",
   "nsf_id": "000538107",
   "pi_start_date": "2020-06-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Krishnendu",
   "pi_last_name": "Chakrabarty",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Krishnendu Chakrabarty",
   "pi_email_addr": "Krishnendu.Chakrabarty@asu.edu",
   "nsf_id": "000322112",
   "pi_start_date": "2020-06-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "2200 W. Main St, Suite 710",
  "perf_city_name": "Durham",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277054010",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 295701.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 154299.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project aims to develop application-specific manycore systems that deliver exceptional performance and energy efficiency, specifically for artificial intelligence (AI) and machine learning (ML) applications. The primary focus is on designing a heterogeneous single-chip manycore platform that minimizes costly off-chip data transfers, leading to improved system performance. The team at Duke has concentrated on integrating resistive random-access memory (ReRAM) based processing-in-memory (PIM) accelerators, which offer the potential to enhance performance, reliability, and energy efficiency. Throughout the project, the team conducted extensive reliability assessments, explored various design options, and optimized the system for performance, power consumption, and reliability using advanced application workloads.</p>\n<p>ReRAM-based PIM architectures have shown promise in accelerating deep neural network (DNN) training and inference. However, computational accuracy is often impacted by non-idealities such as stochastic noise, particularly in the conductance of ReRAM devices. To address this, the team developed a stochastic-noise-aware training method called ReSNA, which improves the accuracy of DNN inference on ReRAM arrays affected by noise. Furthermore, an information-theoretic algorithm, CF-MESMO, was introduced to help designers efficiently explore trade-offs between various design objectives, such as accuracy, area overhead, execution time, and energy consumption. CF-MESMO iteratively selects optimal designs by balancing computational costs with the information gained, enabling designers to make informed trade-offs for their specific needs.</p>\n<p>Additionally, the project explored the impact of non-idealities in ReRAM crossbar arrays as the number of concurrently activated wordlines and bitlines increases. To mitigate these effects, the team proposed a Block-Wise mixed-precision Quantization (BWQ) framework. At the algorithm level, BWQ-A applies a mixed-precision quantization scheme that significantly compresses weights and activations with minimal accuracy loss. At the hardware level, BWQ-H leverages low-bit-width models to enhance DNN inference efficiency on ReRAM devices and introduces a novel precision-aware weight mapping method to improve throughput.</p>\n<p>Another challenge addressed in the project is the limited write endurance of ReRAM-based PIM in neural network training due to frequent weight updates. The team developed the ESSENCE framework, which incorporates an endurance-aware stochastic gradient pruning method to reduce weight reprogrammings without compromising model accuracy. This dynamic approach helps extend the lifetime of ReRAM-based architectures, making them more viable for CNN training.</p>\n<p>The project&rsquo;s outcomes contribute significantly to the field of machine learning acceleration research and industry by promoting a design philosophy that integrates algorithm and hardware design to optimize system performance and scalability. The findings have been published in IEEE Transactions and other top conferences, with practical impacts on future processing systems. Moreover, the project provides valuable training opportunities for undergraduate and graduate students, paving the way for technology transfer and industry collaboration.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/13/2024<br>\nModified by: Hai&nbsp;Li</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe project aims to develop application-specific manycore systems that deliver exceptional performance and energy efficiency, specifically for artificial intelligence (AI) and machine learning (ML) applications. The primary focus is on designing a heterogeneous single-chip manycore platform that minimizes costly off-chip data transfers, leading to improved system performance. The team at Duke has concentrated on integrating resistive random-access memory (ReRAM) based processing-in-memory (PIM) accelerators, which offer the potential to enhance performance, reliability, and energy efficiency. Throughout the project, the team conducted extensive reliability assessments, explored various design options, and optimized the system for performance, power consumption, and reliability using advanced application workloads.\n\n\nReRAM-based PIM architectures have shown promise in accelerating deep neural network (DNN) training and inference. However, computational accuracy is often impacted by non-idealities such as stochastic noise, particularly in the conductance of ReRAM devices. To address this, the team developed a stochastic-noise-aware training method called ReSNA, which improves the accuracy of DNN inference on ReRAM arrays affected by noise. Furthermore, an information-theoretic algorithm, CF-MESMO, was introduced to help designers efficiently explore trade-offs between various design objectives, such as accuracy, area overhead, execution time, and energy consumption. CF-MESMO iteratively selects optimal designs by balancing computational costs with the information gained, enabling designers to make informed trade-offs for their specific needs.\n\n\nAdditionally, the project explored the impact of non-idealities in ReRAM crossbar arrays as the number of concurrently activated wordlines and bitlines increases. To mitigate these effects, the team proposed a Block-Wise mixed-precision Quantization (BWQ) framework. At the algorithm level, BWQ-A applies a mixed-precision quantization scheme that significantly compresses weights and activations with minimal accuracy loss. At the hardware level, BWQ-H leverages low-bit-width models to enhance DNN inference efficiency on ReRAM devices and introduces a novel precision-aware weight mapping method to improve throughput.\n\n\nAnother challenge addressed in the project is the limited write endurance of ReRAM-based PIM in neural network training due to frequent weight updates. The team developed the ESSENCE framework, which incorporates an endurance-aware stochastic gradient pruning method to reduce weight reprogrammings without compromising model accuracy. This dynamic approach helps extend the lifetime of ReRAM-based architectures, making them more viable for CNN training.\n\n\nThe projects outcomes contribute significantly to the field of machine learning acceleration research and industry by promoting a design philosophy that integrates algorithm and hardware design to optimize system performance and scalability. The findings have been published in IEEE Transactions and other top conferences, with practical impacts on future processing systems. Moreover, the project provides valuable training opportunities for undergraduate and graduate students, paving the way for technology transfer and industry collaboration.\n\n\n\t\t\t\t\tLast Modified: 10/13/2024\n\n\t\t\t\t\tSubmitted by: HaiLi\n"
 }
}