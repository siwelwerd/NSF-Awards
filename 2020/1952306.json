{
 "awd_id": "1952306",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FRG: Collaborative Research: Quantile-Based Modeling for Large-Scale Heterogeneous Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-06-01",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2020-03-27",
 "awd_max_amd_letter_date": "2020-03-27",
 "awd_abstract_narration": "The rapid development of technology has led to the tremendous growth of large-scale heterogeneous data in science, economics, engineering, healthcare, and many other disciplines. For example, in a modern health information system, electronic health records routinely collect a large amount of information on many patients from heterogeneous populations across different disease categories. Such data provide unique opportunities to understand the association between features and outcomes across different subpopulations. Existing approaches have not fully addressed the formidable computational and statistical challenges. To tap into the true potential of information-rich data, this project will develop a new computational and statistical paradigm and solid theoretical foundation for analyzing large-scale heterogeneous data. In addition the project will also provide research training opportunities for graduate students.\r\n \r\nThe project will build a unified, quantile-modeling based framework with an overarching goal of achieving effectiveness and reliability in analyzing heterogeneous data, especially when both the number of potential explanatory variables and the sample size are large. The specific goals are (1) to develop resampling-based inference for large-scale heterogeneous data; (2) to develop Bayesian algorithms and scalable and interpretable structure-aware approach for better inference; (3) to develop quantile-optimal decision rule estimation and inference with many covariates; (4) to develop novel estimation and inference procedure for large-scale quantile regression under censoring. The project will address some of the key barriers in scalability to data size and dimensionality, exploration of heterogeneity and structures, need for robustness, and the ability to make use of incomplete observations.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kengo",
   "pi_last_name": "Kato",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kengo Kato",
   "pi_email_addr": "kk976@cornell.edu",
   "nsf_id": "000790621",
   "pi_start_date": "2020-03-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "107 Hoy Road",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148537501",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "1616",
   "pgm_ref_txt": "FOCUSED RESEARCH GROUPS IN MATH SCIENCES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Modeling and analyzing large-scale heterogeneous data&nbsp; is at the forefront of research in many scientific and engineering disciplines, including social and behavioral sciences, healthcare and economics. For example, in modern health information systems, electronic health records routinely collect large amount of information on many patients from heterogeneous populationsacross different disease domains. In clinical settings, there exists abundant evidence that a treatment often has differential effects for different subpopulations. Large-scale data in these scenarios provide unique opportunities to understand heterogeneity across sub-populations,&nbsp;to explore associations between certain features and rare outcomes (e.g., rare diseases or events), and to make optimal personalized recommendations. Especially when the sample size for specific subpopulations is small, important patterns concerning these subpopulations may be hard to discern and might even be treated as outliers. To tap into the true potential of information-rich data, we must address many formidable computational and statistical challenges. Some of the key barriers include scalability to data size and dimensionality, exploration of heterogeneity and structures, need for robustness, and the ability to make sense of incomplete observations (e.g. due to censoring).&nbsp;<br /><br />The outcomes of the project make significant contributions to addressing several fundamental problems in analyzing large-scale heterogeneous data: resampling-based inference for large-scale heterogeneous data; Bayesian algorithms and scalable and interpretable structure-aware approach for better inference; quantile-optimal decision rule estimation and inference with many covariates, and estimation and inference for large-scale quantile regression under censoring. The research outcomes fill in important gaps for large-scale data analysis while balancing the statistical accuracy and computational efficiency. The results will significantly enhance the availability of statistical methodology, algorithms and theory for large-scale heterogeneous data analysis while balancing statistical accuracy and computational efficiency.</p>\n<p><span id=\"docs-internal-guid-354c11f7-7fff-38ea-fe6c-43bcc7db5d31\"> </span></p>\n<p dir=\"ltr\"><span>Research results from this project will have direct applications in diverse fields, such as social and behavioral sciences, climate research, healthcare and economics. The project has produced over twenty published and accepted articles in leading journals including the </span><span>Journal of the American Statistical Association</span><span>,</span><span> Annals of Statistics, Annals of Applied Probability, </span><span>Annals of Applied Statistics, </span><span>Journal of the Royal Statistical Society, Series B, J</span><span>ournal of Machine Learning Research, </span><span>&nbsp;Journal of Econometrics and Econometrics Theory</span><span>.</span><span> </span><span>The PIs gave over 50 research talks on the work in this project during the period of funding at a range of venues including academic conferences and departmental seminars. </span><span>The collaborative project</span><span> has created a strong synergy between senior and junior PIs and provided training and mentorship for multiple Ph.D. students. The focused research group successfully organized two workshops:</span><span>&nbsp;''</span><span>Workshop on Quantile Regression and Data Heterogeneity''&nbsp;</span><span>(February 2022 at University of Miami) and </span><span>''Workshop on Translational Research on Data Heterogeneity'' (April 2024 at University of Washington at St. Louis). PI Xuming He co-edited a special issue of the Journal of Econometrics for the first workshop.&nbsp;</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 09/21/2024<br>\nModified by: Kengo&nbsp;Kato</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nModeling and analyzing large-scale heterogeneous data is at the forefront of research in many scientific and engineering disciplines, including social and behavioral sciences, healthcare and economics. For example, in modern health information systems, electronic health records routinely collect large amount of information on many patients from heterogeneous populationsacross different disease domains. In clinical settings, there exists abundant evidence that a treatment often has differential effects for different subpopulations. Large-scale data in these scenarios provide unique opportunities to understand heterogeneity across sub-populations,to explore associations between certain features and rare outcomes (e.g., rare diseases or events), and to make optimal personalized recommendations. Especially when the sample size for specific subpopulations is small, important patterns concerning these subpopulations may be hard to discern and might even be treated as outliers. To tap into the true potential of information-rich data, we must address many formidable computational and statistical challenges. Some of the key barriers include scalability to data size and dimensionality, exploration of heterogeneity and structures, need for robustness, and the ability to make sense of incomplete observations (e.g. due to censoring).\n\nThe outcomes of the project make significant contributions to addressing several fundamental problems in analyzing large-scale heterogeneous data: resampling-based inference for large-scale heterogeneous data; Bayesian algorithms and scalable and interpretable structure-aware approach for better inference; quantile-optimal decision rule estimation and inference with many covariates, and estimation and inference for large-scale quantile regression under censoring. The research outcomes fill in important gaps for large-scale data analysis while balancing the statistical accuracy and computational efficiency. The results will significantly enhance the availability of statistical methodology, algorithms and theory for large-scale heterogeneous data analysis while balancing statistical accuracy and computational efficiency.\n\n\n \n\n\nResearch results from this project will have direct applications in diverse fields, such as social and behavioral sciences, climate research, healthcare and economics. The project has produced over twenty published and accepted articles in leading journals including the Journal of the American Statistical Association, Annals of Statistics, Annals of Applied Probability, Annals of Applied Statistics, Journal of the Royal Statistical Society, Series B, Journal of Machine Learning Research, Journal of Econometrics and Econometrics Theory. The PIs gave over 50 research talks on the work in this project during the period of funding at a range of venues including academic conferences and departmental seminars. The collaborative project has created a strong synergy between senior and junior PIs and provided training and mentorship for multiple Ph.D. students. The focused research group successfully organized two workshops:''Workshop on Quantile Regression and Data Heterogeneity''(February 2022 at University of Miami) and ''Workshop on Translational Research on Data Heterogeneity'' (April 2024 at University of Washington at St. Louis). PI Xuming He co-edited a special issue of the Journal of Econometrics for the first workshop.\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 09/21/2024\n\n\t\t\t\t\tSubmitted by: KengoKato\n"
 }
}