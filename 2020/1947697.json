{
 "awd_id": "1947697",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: SCH: A Computational Framework for Fair Public Health-Related Decisions",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Michelle Rogers",
 "awd_eff_date": "2020-04-01",
 "awd_exp_date": "2023-03-31",
 "tot_intn_awd_amt": 174797.0,
 "awd_amount": 174797.0,
 "awd_min_amd_letter_date": "2020-03-18",
 "awd_max_amd_letter_date": "2020-03-18",
 "awd_abstract_narration": "Social media is a part of everyday life. A post about college graduation shares the joy of a significant accomplishment. Informing friends about a death in the family can be cathartic.  A simple interaction with a long-lost friend can bring back whimsical childhood memories of simpler times. Given social media's widespread use, it has been used in a broad range of critical health-related applications, including, but not limited to, the early detection of disease outbreaks, extracting and monitoring adverse drug reactions, measuring health behaviors such as smoking use, and mining individual's mental and physical health. Eventually, the detection and treatment of mental and physical health problems may soon meet individuals in the social media platforms they already inhabit. Before these applications are integrated into decision-making processes from public policy to personal health decisions, it is essential to understand how these tools perform in real-world environments. Specifically, decisions must be fair across all factors, such as age, gender, race, ethnicity, and economic status. The main novelty of this project will be in its capacity to measure the fairness of these public health monitoring systems across many underrepresented groups. Overall, if the goal is to identify and treat individuals in online spaces or make policy decisions based on social media data, we must measure the fairness of the tools. Otherwise, the unethical use of biased tools may increase health disparities for many underrepresented groups.\r\n\r\nThis project will introduce a novel framework for measuring the fairness of public health monitoring systems. The major challenge is that measuring the fairness of underrepresented groups is difficult because they rarely appear in standard datasets, or worse, do not appear at all. Moreover, it is both costly and challenging to annotate data for all demographic factors of interest in a timely manner. This project aims to address this limitation in two ways. First, it will use style transfer to generate synthetic data that emulates the lexical, syntactic, and semantic characteristics of text generated by underrepresented groups. Synthetic data for specific groups will be used to overcome the issues of data sparsity to measure fairness. Second, while it is crucial to measure fairness across standard demographic factors, it is also essential to understand how tools will perform for specific communities. Therefore, style transfer methods will be expanded to generate geographic-specific text. The major challenge will be scaling to a large number of locations. This project will address this challenge by taking advantage of recent advances in adversarial learning. Finally, the project will impact the broader AI community via the release of open-source software that implements the tools and techniques this award generates. Moreover, public officials will gain access to easy-to-use tools that describe how the use of individual systems can adversely impact specific communities. More importantly, the tools will help officials make informed decisions about data generated from social media.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anthony",
   "pi_last_name": "Rios",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anthony Rios",
   "pi_email_addr": "anthony.rios@utsa.edu",
   "nsf_id": "000805507",
   "pi_start_date": "2020-03-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at San Antonio",
  "inst_street_address": "1 UTSA CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SAN ANTONIO",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "2104584340",
  "inst_zip_code": "782491644",
  "inst_country_name": "United States",
  "cong_dist_code": "20",
  "st_cong_dist_code": "TX20",
  "org_lgl_bus_name": "THE UNIVERSITY OF TEXAS AT SAN ANTONIO",
  "org_prnt_uei_num": "U44ZMVYU52U6",
  "org_uei_num": "U44ZMVYU52U6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at San Antonio",
  "perf_str_addr": "One UTSA Circle",
  "perf_city_name": "San Antonio",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "782491644",
  "perf_ctry_code": "US",
  "perf_cong_dist": "20",
  "perf_st_cong_dist": "TX20",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 174797.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Social media is a significant part of our daily lives, allowing us to share our achievements, seek comfort during tough times, and reconnect with old friends. Due to its widespread use, it has also been utilized for various important health-related purposes. For example, it has helped in detecting disease outbreaks early, monitoring adverse drug reactions, and understanding health behaviors like smoking habits. Furthermore, it has the potential to play a role in identifying and addressing mental and physical health issues. However, before fully integrating these applications into important decision-making processes, like public policies and personal health choices, it's crucial to ensure fairness and equity across all factors, such as age, gender, race, ethnicity, and economic status. Understanding how these tools perform in real-world situations is essential for their responsible and effective use.</p>\n<p><br />Towards this end, this project had three major outcomes. First, we analyzed bias in state-of-the-art natural language processing models across a broad range of domains, from offensive language detection to tracking influenza infection-related messages on social media. For example, we found that models developed to track influence on social media do not perform the same across different dialects. Likewise, we found that geographic variation (e.g., differences between New York and Texas) can cause substantial differences in the accuracy of offensive language models. Second, we developed novel methods of measuring biased machine learning models. It can be impossible to collect data for all groups of people. Hence our method allows bias measurements when data is unavailable for a specific group on a particular task (e.g., influence detection). Third, multiple students have been trained to measure and analyze the potential harms and biases of natural language processing systems as part of this project. Some of these students have now taken these ideas and implemented them in industry settings.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/26/2023<br>\n\t\t\t\t\tModified by: Anthony&nbsp;Rios</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSocial media is a significant part of our daily lives, allowing us to share our achievements, seek comfort during tough times, and reconnect with old friends. Due to its widespread use, it has also been utilized for various important health-related purposes. For example, it has helped in detecting disease outbreaks early, monitoring adverse drug reactions, and understanding health behaviors like smoking habits. Furthermore, it has the potential to play a role in identifying and addressing mental and physical health issues. However, before fully integrating these applications into important decision-making processes, like public policies and personal health choices, it's crucial to ensure fairness and equity across all factors, such as age, gender, race, ethnicity, and economic status. Understanding how these tools perform in real-world situations is essential for their responsible and effective use.\n\n\nTowards this end, this project had three major outcomes. First, we analyzed bias in state-of-the-art natural language processing models across a broad range of domains, from offensive language detection to tracking influenza infection-related messages on social media. For example, we found that models developed to track influence on social media do not perform the same across different dialects. Likewise, we found that geographic variation (e.g., differences between New York and Texas) can cause substantial differences in the accuracy of offensive language models. Second, we developed novel methods of measuring biased machine learning models. It can be impossible to collect data for all groups of people. Hence our method allows bias measurements when data is unavailable for a specific group on a particular task (e.g., influence detection). Third, multiple students have been trained to measure and analyze the potential harms and biases of natural language processing systems as part of this project. Some of these students have now taken these ideas and implemented them in industry settings.\n\n\t\t\t\t\tLast Modified: 07/26/2023\n\n\t\t\t\t\tSubmitted by: Anthony Rios"
 }
}