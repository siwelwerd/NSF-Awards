{
 "awd_id": "1951250",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "STTR Phase II:  TerraSentia: Ultra-compact, Autonomous, Teachable Under-canopy Phenotyping Robot for Plant Breeders and Crop Scientists",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Anna Brady-Estevez",
 "awd_eff_date": "2020-04-15",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 750000.0,
 "awd_amount": 832000.0,
 "awd_min_amd_letter_date": "2020-04-10",
 "awd_max_amd_letter_date": "2022-10-24",
 "awd_abstract_narration": "The broader impact of this Small Business Technology Transfer (STTR) Phase II project include improving food security, while at the same time enhancing the economic viability and environmental sustainability of large-scale production agriculture. In order to improve crop varieties, agricultural production, and sustainability of farming, there is an urgent need for better technologies to acquire under-canopy plant trait and health data. Examples of high-value under-canopy data include emergence, stem width, corn ear height, plant life-cycle events like flowering and fruiting, and symptoms of pathogens, diseases, and nutrient deficiency. Because these data cannot be obtained by aerial imaging, under-canopy data collection has dramatically greater actionability and value compared to aerial data. However no cost-effective, scalable ways of collecting this data are currently available. In fact, the state of the art is manual data collection by crop scientists (and their students or interns), agronomists, crop-scouts or farmers - an extremely labor intensive, and therefore expensive way of collecting this highly valuable data. Our work will greatly enhance the availability of under-canopy data from field crops, benefiting crop scientists and agricultural product development professionals as well as enable large scale field monitoring and management in production agriculture.  The commercial value of the field data for crop breeding is in excess of $50 Million/year for breeding major row-crops in the US.\r\n\r\nThis STTR Phase II project proposes to establish autonomous data collection under-canopy from field crops using a low-cost ground robot. The proposed work will enhance the ability to collect data autonomously in full-scale crop-breeding fields throughout the season and enable on-site data analytics for remote sites with limited connectivity. Long-term field adaptive autonomy will be achieved through implementation of multiple low-cost sensors. Robot's real-time control algorithms will be developed to adapt camera perspective and robot path in order to obtain the highest quality information from the complex and dynamic under-canopy field environments. Finally, the research will develop hardware specific edge-compute versions of the analytics algorithms to enable on-site data analysis. These innovations will together enable global deployment of the system for effective data collection and phenotyping.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chinmay",
   "pi_last_name": "Soman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chinmay Soman",
   "pi_email_addr": "chinmay@earthsense.co",
   "nsf_id": "000736751",
   "pi_start_date": "2020-04-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "EarthSense, Inc.",
  "inst_street_address": "1800 S OAK ST STE 111",
  "inst_street_address_2": "",
  "inst_city_name": "CHAMPAIGN",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2174024767",
  "inst_zip_code": "618206974",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "EARTHSENSE INC",
  "org_prnt_uei_num": "",
  "org_uei_num": "JAM3S4174UP6"
 },
 "perf_inst": {
  "perf_inst_name": "EarthSense, Inc.",
  "perf_str_addr": "60 Hazelwood Drive",
  "perf_city_name": "Champaign",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618207460",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "159100",
   "pgm_ele_name": "STTR Phase II"
  },
  {
   "pgm_ele_code": "537300",
   "pgm_ele_name": "SBIR Phase II"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8030",
   "pgm_ref_txt": "Chemical Technology"
  },
  {
   "pgm_ref_code": "8032",
   "pgm_ref_txt": "Software Services and Applications"
  },
  {
   "pgm_ref_code": "8240",
   "pgm_ref_txt": "SBIR/STTR CAP"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 816000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This STTR Phase II Award has been critical in enabling EarthSense, Inc. to mature our field autonomy and machine-vision technologies for agriculture. These technologies form the core of our \"Terra\" Autonomy and AI platform that powers our commercial products:</span></p>\n<ol>\n<li><span>TerraSentia: the high-throughput field phenotyping system, including the ultracompact, autonomous robots and teachable autonomy and AI algorithms that's being used worldwide to accelerate the creation of the next generation of productive, sustainable crops</span></li>\n<li><span>TerraSentia+: the autonomous robots for advanced applications in seed breeding, production, and agricultural research.</span></li>\n<li><span>TerraPreta: robots for large-scale soil regeneration and gigaton scale soil carbon sequestration</span></li>\n<li><span>TerraMax: high-payload robots for large scale precision management of sustainable agricultural systems</span></li>\n</ol>\n<p><span>The TerraSentia field phenotyping platform was the primary focus of this award. The TerraSentia platform was designed with initial support from NSF SBIR Phase I (Award # 1820332, July 2018-June 2019). Some of the underlying technologies of TerraSentia were created at the University of Illinois at Urbana Champaign through funding from the ARPA-e TERRA program for creating high-throughput field phenotyping technologies.</span><span><br /></span></p>\n<p><span>Since 2018 EarthSense's public and private sector customers have deployed the increasingly autonomous and capable TerraSentia field robots around the world, resulting in the breaking of the \"field phenotyping bottleneck\". </span></p>\n<p>Phenotyping is the mesurement of physical characgeristic of plants. Measuring the physical properties of a large variety of plants is critical for identifying the genetic characteristics of plants that will result in the best performance under the enivironmental conditions (such as soil conditions, drought, heat, cold, excess rainfaill, diseases and pests, etc.) and management practices (fertilizing, irrigation, etc.) that the plants will experience. In other words, phenotyping plants at high volume and high frequency is critical for enabling crop scientsts to create the next generation of productive, sustainable, climate resilient, and profitable crops.</p>\n<p><span>However, before the TerraSentia system, filed phenotyping was extremely labor intensive and inefficient, since many of the important traits of crops exist under the plant canopy. These traits, such as stem width, fruit count and dminesions, leaf and canopy architecture, etc. have to be meausred by hand, one plant at a time. This causes the field phenotyping bottleneck, resulting in a crop improvement process that is much slower than it can be.</span></p>\n<p>To break the field phenotyping bottleneck, EarthSense had to solve three key problems: reliable autonomy, machine-learning algorithms capable extracting accurate plant traits from complex real-world field data, and capacity to analyze this data in a computationally efficient manner - including on the low-cost, compact TerraSentia robots with limited onboard compute capacity.</p>\n<p>The TerraSentia field phenotyping system is now being used by a variety of field research scientists inculding at major resarch universities inclusing Cornell, UC Davis, Michigan State, Iowa State, Purdue, University of Illinois, Texas A&amp;M, Washington State, University of Missouri, and others. It is also being used by United States Department of Agriculture - Agricultural Research Service, for crops including corn, field beans, sugarcane, and others. Finally, it is being widely used by major global&nbsp; agricultural companies to customize their products for regions including in the US, South America, Europe, and South &amp; South-East Asia.</p>\n<p>Based on the commercial success of the TerraSentia platform, EarthSense has been able to attract some venture capital funding to supplement this grant and our revenues.</p>\n<p>In addition, EarthSense has filed a series of patents relating to our autonomy and AI capabilities developed with the support of this NSF funding.</p>\n<p>Finally, building on the core AI and autonomy capabilities, as well as hardware designed to be low cost and scalable, and our credibility for developing these products, EarthSense has developing a whole family of robots for enabling large-scale sustainable, regenerative, agriculture that can be&nbsp; profitable to farmers all around the world.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/26/2023<br>\n\t\t\t\t\tModified by: Chinmay&nbsp;Soman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis STTR Phase II Award has been critical in enabling EarthSense, Inc. to mature our field autonomy and machine-vision technologies for agriculture. These technologies form the core of our \"Terra\" Autonomy and AI platform that powers our commercial products:\n\nTerraSentia: the high-throughput field phenotyping system, including the ultracompact, autonomous robots and teachable autonomy and AI algorithms that's being used worldwide to accelerate the creation of the next generation of productive, sustainable crops\nTerraSentia+: the autonomous robots for advanced applications in seed breeding, production, and agricultural research.\nTerraPreta: robots for large-scale soil regeneration and gigaton scale soil carbon sequestration\nTerraMax: high-payload robots for large scale precision management of sustainable agricultural systems\n\n\nThe TerraSentia field phenotyping platform was the primary focus of this award. The TerraSentia platform was designed with initial support from NSF SBIR Phase I (Award # 1820332, July 2018-June 2019). Some of the underlying technologies of TerraSentia were created at the University of Illinois at Urbana Champaign through funding from the ARPA-e TERRA program for creating high-throughput field phenotyping technologies.\n\n\nSince 2018 EarthSense's public and private sector customers have deployed the increasingly autonomous and capable TerraSentia field robots around the world, resulting in the breaking of the \"field phenotyping bottleneck\". \n\nPhenotyping is the mesurement of physical characgeristic of plants. Measuring the physical properties of a large variety of plants is critical for identifying the genetic characteristics of plants that will result in the best performance under the enivironmental conditions (such as soil conditions, drought, heat, cold, excess rainfaill, diseases and pests, etc.) and management practices (fertilizing, irrigation, etc.) that the plants will experience. In other words, phenotyping plants at high volume and high frequency is critical for enabling crop scientsts to create the next generation of productive, sustainable, climate resilient, and profitable crops.\n\nHowever, before the TerraSentia system, filed phenotyping was extremely labor intensive and inefficient, since many of the important traits of crops exist under the plant canopy. These traits, such as stem width, fruit count and dminesions, leaf and canopy architecture, etc. have to be meausred by hand, one plant at a time. This causes the field phenotyping bottleneck, resulting in a crop improvement process that is much slower than it can be.\n\nTo break the field phenotyping bottleneck, EarthSense had to solve three key problems: reliable autonomy, machine-learning algorithms capable extracting accurate plant traits from complex real-world field data, and capacity to analyze this data in a computationally efficient manner - including on the low-cost, compact TerraSentia robots with limited onboard compute capacity.\n\nThe TerraSentia field phenotyping system is now being used by a variety of field research scientists inculding at major resarch universities inclusing Cornell, UC Davis, Michigan State, Iowa State, Purdue, University of Illinois, Texas A&amp;M, Washington State, University of Missouri, and others. It is also being used by United States Department of Agriculture - Agricultural Research Service, for crops including corn, field beans, sugarcane, and others. Finally, it is being widely used by major global  agricultural companies to customize their products for regions including in the US, South America, Europe, and South &amp; South-East Asia.\n\nBased on the commercial success of the TerraSentia platform, EarthSense has been able to attract some venture capital funding to supplement this grant and our revenues.\n\nIn addition, EarthSense has filed a series of patents relating to our autonomy and AI capabilities developed with the support of this NSF funding.\n\nFinally, building on the core AI and autonomy capabilities, as well as hardware designed to be low cost and scalable, and our credibility for developing these products, EarthSense has developing a whole family of robots for enabling large-scale sustainable, regenerative, agriculture that can be  profitable to farmers all around the world.\n\n\t\t\t\t\tLast Modified: 06/26/2023\n\n\t\t\t\t\tSubmitted by: Chinmay Soman"
 }
}