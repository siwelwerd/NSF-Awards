{
 "awd_id": "2016922",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Doctoral Dissertation Research:  Linguistic and visual cue competition in novel L2 structure learning and thematic role assignment",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Mary Paster",
 "awd_eff_date": "2020-07-15",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 16409.0,
 "awd_amount": 16409.0,
 "awd_min_amd_letter_date": "2020-07-07",
 "awd_max_amd_letter_date": "2020-07-07",
 "awd_abstract_narration": "This project examines how American English speakers learn a case-marking, flexible word-order language as a second language under different context conditions (with supporting images or translations). It links the real time processing of the new language, as learners read sentences, to the learning outcomes. Learning languages whose structures are different from English poses great difficulty for learners. This project examines the origins of this attested difficulty, and how visual information (images) can guide learners\u2019 attention and help them notice and understand new grammatical structures. It considers the role of the learning environment for grammar learning and can illustrate the way language input is better integrated with non-linguistic, multimodal contextual support. It can guide educators and policy makers in the development of educational software and game design, and online language learning. It can inform the design of successful language programs for U.S. adult learner populations.\r\n\r\nThe studies include a language learning and a subsequent testing phase. During the learning phase, self-paced reading and eye-tracking will show where learners allocate their attention as they read second language sentences, and how attention to different parts of the sentence is modulated by the type of contextual support (images or translations). The goal is to examine how linguistic and visual information interact and compete for learners\u2019 attention. The hypothesis is that visual scenes can make some aspects of grammar \u2018stand out\u2019 as learners compare their sentence interpretation to the visual information. During the testing phase, multiple measures will assess participants\u2019 ability to comprehend and produce the new grammatical structure. These studies can show how multimodal input influences the focus of learners\u2019 attention during real-time sentence reading and how this processing affects their learning. This will advance our understanding of how the mind processes and integrates linguistic and visual information when learning a second language, which has clear educational applications especially in online and multimedia language learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kiel",
   "pi_last_name": "Christianson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kiel Christianson",
   "pi_email_addr": "kiel@illinois.edu",
   "nsf_id": "000383256",
   "pi_start_date": "2020-07-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Tania",
   "pi_last_name": "Ionin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tania Ionin",
   "pi_email_addr": "tionin@illinois.edu",
   "nsf_id": "000530830",
   "pi_start_date": "2020-07-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Melissa",
   "pi_last_name": "Bowles",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Melissa Bowles",
   "pi_email_addr": "bowlesm@illinois.edu",
   "nsf_id": "000582973",
   "pi_start_date": "2020-07-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "ANNA",
   "pi_last_name": "TSIOLA",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "ANNA TSIOLA",
   "pi_email_addr": "annatsiola@gmail.com",
   "nsf_id": "000795979",
   "pi_start_date": "2020-07-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "HAB, 506 S. Wright St.",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "837400",
   "pgm_ele_name": "DDRI Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16409.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Graduate student Anna Tsiola carried out 6 experiments testing how people learn a new language when they are first exposed to it. The NSF grant helped us compensate participants as well as train, give research experience, and compensate undergraduate research assistants.</p>\n<p>We tested differences in the learning process and subsequent outcomes in three different scenarios: 1) when being exposed to only the second lanaguge, 2) when being exposed to the second language along with first-language translations, and 3) when being exposed to the second language together with images displaying the sentence content also visually. Each experiment, which can be described as a language learning session, lasted for about one hour.</p>\n<p>The results showed that when provided with second language information only, learners did not succeed much in deducing and learning the grammatical rules of the language. However, when we added translations and images, the amount of learning increased substantially and most learners were able to notice the grammatical pattern, apply it in their own written sentences, and later report and explain what the grammatical rule was. In addition, images contributed to a more positive learning experience.<br />These results show that if we structure carefully the way we present a new language to learners, and combine it with multimodal (e.g., visual) information, learning can take place fast. Our participant learners managed to notice, learn, and apply a complex grammatical rule in a new, foreign language in only about one hour.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/31/2022<br>\n\t\t\t\t\tModified by: Anna&nbsp;Tsiola</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nGraduate student Anna Tsiola carried out 6 experiments testing how people learn a new language when they are first exposed to it. The NSF grant helped us compensate participants as well as train, give research experience, and compensate undergraduate research assistants.\n\nWe tested differences in the learning process and subsequent outcomes in three different scenarios: 1) when being exposed to only the second lanaguge, 2) when being exposed to the second language along with first-language translations, and 3) when being exposed to the second language together with images displaying the sentence content also visually. Each experiment, which can be described as a language learning session, lasted for about one hour.\n\nThe results showed that when provided with second language information only, learners did not succeed much in deducing and learning the grammatical rules of the language. However, when we added translations and images, the amount of learning increased substantially and most learners were able to notice the grammatical pattern, apply it in their own written sentences, and later report and explain what the grammatical rule was. In addition, images contributed to a more positive learning experience.\nThese results show that if we structure carefully the way we present a new language to learners, and combine it with multimodal (e.g., visual) information, learning can take place fast. Our participant learners managed to notice, learn, and apply a complex grammatical rule in a new, foreign language in only about one hour. \n\n\t\t\t\t\tLast Modified: 10/31/2022\n\n\t\t\t\t\tSubmitted by: Anna Tsiola"
 }
}