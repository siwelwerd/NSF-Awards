{
 "awd_id": "2028818",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: PPoSS: Planning: Scaling Secure Serverless Computing on Heterogeneous Datacenters",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Danella Zhao",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 89832.0,
 "awd_amount": 89832.0,
 "awd_min_amd_letter_date": "2020-08-10",
 "awd_max_amd_letter_date": "2020-08-10",
 "awd_abstract_narration": "Cloud computing has been a dominant computing paradigm that enables many important computing capabilities including large-scale (big) data processing, artificial intelligence, and scientific discoveries. A recent evolution of cloud computing includes the move to serverless computing, which simplifies the deployment of computation while enabling better scaling and higher resource utilization. Meanwhile, datacenters, the backbone of cloud computing, increasingly include heterogeneous compute and memory resources. The move toward serverless computing and heterogeneous architecture of datacenters produces a gap that unless addressed, results in inefficient use of resources. The project seeks to address this gap in order to enable new applications and new functionalities to be provided in the cloud, at lower cost and higher security, providing platforms for the advancement of science, engineering, and commerce. \r\n\r\nFuture datacenters will consist of heterogeneous compute and memory. Applications in the cloud are increasingly varied in their requirements, such as degree and granularity of parallelism; memory latency, capacity, and bandwidth requirements;  and security and privacy requirements. This project investigates serverless computing as a promising programming model for heterogeneous platforms. Serverless platforms decouple system management from application execution: applications provide functions that manipulate data, and leave it to the platform to determine when the function should run, with what input data, and on what physical machine.  Current platforms, such as AWS Lambda, Google Compute Functions or Azure Functions do not fully implement this vision, as they do not expose heterogeneous resources nor manage all resources automatically. This project explores novel abstractions for compute that extend serverless functions to better leverage unique hardware characteristics, and for memory to allow more automated leveraging of workload characteristics such as locality and compute intensity.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Swift",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Michael M Swift",
   "pi_email_addr": "swift@cs.wisc.edu",
   "nsf_id": "000103907",
   "pi_start_date": "2020-08-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Xiangyao",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiangyao Yu",
   "pi_email_addr": "yxy@cs.wisc.edu",
   "nsf_id": "000822151",
   "pi_start_date": "2020-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "1210 West Dayton Street",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537061613",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 89832.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Cloud computing is a growing computing paradigm that enables important computing capabilities including large-scale data processing. Cloud allows users to leverage heterogeneous hardware for high-performance computation and memory without the capital expenditure to acquire the hardware devices. In particular, Graphics Processing Units (GPUs) are computational devices that achieve much higher computational power through massive parallelism and have been widely used in applications including graphics, machine learning, and scientific computing. In this project, we use GPUs to accelerate data analytics applications to achieve much higher processing speed. Specifically, we conducted the following two tasks:</p>\n<p>1. Data compression in GPU.&nbsp;</p>\n<p>A key constraint of existing GPU-based data analytics systems is the limited memory capacity in GPU devices. So that only small workloads can leverage GPU acceleration. Data compression is a powerful technique that can mitigate the capacity limitation in two ways: (1) fitting more data into GPU memory and (2) speeding up data transfer between CPU and GPU. However, compression schemes for GPU today are still limited in compression ratio and/or decompression speed. We identify two limiting factors of existing approaches. First, existing decompression solutions require multiple passes of scanning the global memory to decode layers of compression schemes, incurring significant memory traffic and hurting performance. We present the tile-based decompression model to decompress encoded data in a single pass over global memory and inline with query execution. Second, we develop an efficient implementation of bit-packing-based compression schemes and their optimization techniques in the context of GPU. Our evaluation shows that our schemes can achieve similar compression rates to the best state-of-the-art compression schemes in GPU (i.e., nvCOMP) while being 2.2x and 2.6x faster in decompression speed and query running time.</p>\n<p>2. Hybrid CPU/GPU processing.&nbsp;</p>\n<p>Heterogeneous CPU-GPU query execution is another compelling approach to mitigate the limited GPU memory capacity and PCIe bandwidth between CPU and GPU. However, the design space of heterogeneous CPU-GPU query execution has not been fully explored. We improve state-of-the-art CPU-GPU data analytics engine by optimizing data placement and heterogeneous query execution. First, we introduce a semantic-aware fine-grained caching policy which takes into account various aspects of the workload such as query semantics, data correlation, and query frequency when determining data placement between CPU and GPU. Second, we introduce a heterogeneous query executor which can fully exploit data in both CPU and GPU and coordinate query execution at a fine granularity. We integrate both solutions in a novel hybrid CPU-GPU data analytics engine that we developed. Evaluation on the Star Schema Benchmark shows that the semantic-aware caching policy can outperform the best traditional caching policy by up to 3x.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/23/2023<br>\n\t\t\t\t\tModified by: Xiangyao&nbsp;Yu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nCloud computing is a growing computing paradigm that enables important computing capabilities including large-scale data processing. Cloud allows users to leverage heterogeneous hardware for high-performance computation and memory without the capital expenditure to acquire the hardware devices. In particular, Graphics Processing Units (GPUs) are computational devices that achieve much higher computational power through massive parallelism and have been widely used in applications including graphics, machine learning, and scientific computing. In this project, we use GPUs to accelerate data analytics applications to achieve much higher processing speed. Specifically, we conducted the following two tasks:\n\n1. Data compression in GPU. \n\nA key constraint of existing GPU-based data analytics systems is the limited memory capacity in GPU devices. So that only small workloads can leverage GPU acceleration. Data compression is a powerful technique that can mitigate the capacity limitation in two ways: (1) fitting more data into GPU memory and (2) speeding up data transfer between CPU and GPU. However, compression schemes for GPU today are still limited in compression ratio and/or decompression speed. We identify two limiting factors of existing approaches. First, existing decompression solutions require multiple passes of scanning the global memory to decode layers of compression schemes, incurring significant memory traffic and hurting performance. We present the tile-based decompression model to decompress encoded data in a single pass over global memory and inline with query execution. Second, we develop an efficient implementation of bit-packing-based compression schemes and their optimization techniques in the context of GPU. Our evaluation shows that our schemes can achieve similar compression rates to the best state-of-the-art compression schemes in GPU (i.e., nvCOMP) while being 2.2x and 2.6x faster in decompression speed and query running time.\n\n2. Hybrid CPU/GPU processing. \n\nHeterogeneous CPU-GPU query execution is another compelling approach to mitigate the limited GPU memory capacity and PCIe bandwidth between CPU and GPU. However, the design space of heterogeneous CPU-GPU query execution has not been fully explored. We improve state-of-the-art CPU-GPU data analytics engine by optimizing data placement and heterogeneous query execution. First, we introduce a semantic-aware fine-grained caching policy which takes into account various aspects of the workload such as query semantics, data correlation, and query frequency when determining data placement between CPU and GPU. Second, we introduce a heterogeneous query executor which can fully exploit data in both CPU and GPU and coordinate query execution at a fine granularity. We integrate both solutions in a novel hybrid CPU-GPU data analytics engine that we developed. Evaluation on the Star Schema Benchmark shows that the semantic-aware caching policy can outperform the best traditional caching policy by up to 3x.\n\n\t\t\t\t\tLast Modified: 01/23/2023\n\n\t\t\t\t\tSubmitted by: Xiangyao Yu"
 }
}