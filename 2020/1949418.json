{
 "awd_id": "1949418",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Imprecise Inference from Sequentially Presented Evidence",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032924710",
 "po_email": "clagonza@nsf.gov",
 "po_sign_block_name": "Claudia Gonzalez-Vallejo",
 "awd_eff_date": "2020-04-01",
 "awd_exp_date": "2024-01-31",
 "tot_intn_awd_amt": 449999.0,
 "awd_amount": 449999.0,
 "awd_min_amd_letter_date": "2020-02-27",
 "awd_max_amd_letter_date": "2020-02-27",
 "awd_abstract_narration": "Understanding how people make decisions is crucial to advancing our understanding of economic mechanisms. Rational-choice theory, despite successes in accounting for some aspects of human decision making under uncertainty, fails to capture certain recurrent patterns observed in behavior, such as biases and apparent randomness in choices. Some of these deviations from optimal behavior suggest that information is processed in the brain in a way that introduces imprecision, similar to the imprecision in sensory perception. A growing literature on perceptual judgments argues that in sensory contexts, these imprecisions often actually represent efficient adaptations, given constraints on the available cognitive resources. This raises a question as to whether patterns of imprecision in the case of higher-level cognitive processing (comparisons of numerical magnitudes, estimates of the average values of fluctuating series, and inference about unknown variables) cannot be understood in a similar way. We investigate this hypothesis through an array of experiments in which human subjects are asked to make decisions on the basis of multiple pieces of information, presented sequentially. Decisions made on the basis of sequential evidence are not only important in actual economic life, but also have the advantage as an object of study that they allow us to investigate how each piece of information is separately taken into account in the decision. This reveals the relative allocation of cognitive resources to the processing of each piece of evidence, which in turn sheds light on the underlying constraints faced by the brain. Overall, the main goal of our research is to provide an account of human judgments and economic decisions that is founded on normative principles, and that can be generalized to many problems of human decision-making.\r\n\r\nIn more technical terms, we investigate, in the context of economic decisions, the neurocognitive hypothesis that the brain faces a problem of constrained optimization: that of allocating its limited information-processing resources to achieve the best possible decisions. From this general principle, we derive testable quantitative models of cognitive processing and decision making that make specific predictions regarding the bias and randomness in human choices. In particular, these suboptimal patterns are predicted to depend on prior beliefs about the probability distribution from which the presented evidence is drawn, and on the rewards associated with different responses in a given context. To test this hypothesis, we design six experiments, in which we manipulate both the prior and the reward structure, and we examine the degree to which our proposed models of constrained information processing capture the behavioral patterns found in experimental data.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Woodford",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Woodford",
   "pi_email_addr": "michael.woodford@columbia.edu",
   "nsf_id": "000285591",
   "pi_start_date": "2020-02-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100277235",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132000",
   "pgm_ele_name": "Economics"
  },
  {
   "pgm_ele_code": "132100",
   "pgm_ele_name": "Decision, Risk & Mgmt Sci"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 449999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This project has studied the structure and consequences of random error in cognitive processes, with a focus on errors in human judgments about numerical magnitudes that must be calculated on the basis of a stream of numerical information that arrives sequentially. It is necessary for people to integrate multiple pieces of information in order to make a decision in many contexts; and in the case of economic and financial decisions, the different relevant attributes are often presented numerically. Thus error in the way in which numerical quantities are represented, retrieved from memory, or operated upon can be an important source of error in human decisions. The goal of the project has been to understand better the determinants of such error, in order to better predict how the degree of error should change depending on the problems with which people are confronted.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; One focus of the project has been understanding bias and variability in people&rsquo;s judgments about the relative size of the sums (or averages) of two sequences of numbers, a stylized version of the kind of judgment made when someone decides which of two investments has performed better on average in the past. We find that the errors in people&rsquo;s expressed judgments (in an incentivized laboratory experiment) are well-explained by a model in which the subject&rsquo;s judgment depend on whether the sum of the &ldquo;perceived values&rdquo; of one sequence of numbers is greater than that of the other, where the &ldquo;perceived value&rdquo; of each number is a random draw (on each experimental trial) from a probability distribution that depends on the actual number presented; but this perceived value is neither perfectly predictable, nor equal on average to the number actually presented. We further show that the probability of a correct judgment in the case of two sequences of numbers depends on the context in which the numbers appear --- specifically, on the probability distribution from which the numbers used on separate trials are drawn. Both the way in which bias and variability in responses depend on the sequences presented, and they way in which they change depending on the overall distribution of numbers used across trials, are shown to be consistent with a model in which subjects&rsquo; decisions are optimal (that is, they maximize subjects&rsquo; average financial rewards), subject to the decisions having to be based on noisy (rather than perfectly precise) internal representations of the numbers presented; and in which the degree of random noise in the representation of a particular number is optimally chosen, given a constraint on the feasible precision of the representation scheme as a whole. The solution to this optimization problem depends on the distribution of numbers that must be represented on different trials; and this accounts to an important extent for the way that the distributions of perceived values for given numbers are seen to shift when the numbers presented to subjects are drawn from different distributions.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We also study bias and variability in people&rsquo;s judgments about the probability of occurrence of an event, after a succession of observations of occasions on which the event either does or does not occur. This is again a stylized version of a type of judgment that is fundamental when choosing between investments; but here the focus is on how well people assess the probabilities of different outcomes (i.e., how well they assess risks), rather than on how well they calculate average values. We also observe how experimental subjects adjust their probability beliefs after each additional observation, rather than only asking for a judgment after a complete sequence of observations; this provides further insight into the random errors that arise each time further information is integrated with what had been seen before. We again document the systematic biases that result from imprecision in information integration; one of our most important findings shows that people tend to be excessively conservative in the degree to which they update their beliefs in response to new evidence, when they have seen relatively little evidence, while instead they over-adjust their beliefs cumulatively in response to a longer sequence of evidence, relative to a correct probability calculation. We show that both patterns of bias (as well as the random variation in the same subject&rsquo;s responses when presented with the same sequence of evidence on different trials) can be explained by a single model of noisy cognitive processing. Moreover, the distribution of responses to a given sequence of evidence is found to be different when the distribution of possible evidence sequences used in the experiment changes, and this shift in the pattern of bias in subjects&rsquo; responses can be explained as an efficient adaptation of subjects&rsquo; imprecise cognitive process to the statistics of the environment in which they must make decisions.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 06/27/2024<br>\nModified by: Michael&nbsp;Woodford</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n This project has studied the structure and consequences of random error in cognitive processes, with a focus on errors in human judgments about numerical magnitudes that must be calculated on the basis of a stream of numerical information that arrives sequentially. It is necessary for people to integrate multiple pieces of information in order to make a decision in many contexts; and in the case of economic and financial decisions, the different relevant attributes are often presented numerically. Thus error in the way in which numerical quantities are represented, retrieved from memory, or operated upon can be an important source of error in human decisions. The goal of the project has been to understand better the determinants of such error, in order to better predict how the degree of error should change depending on the problems with which people are confronted.\n\n\n One focus of the project has been understanding bias and variability in peoples judgments about the relative size of the sums (or averages) of two sequences of numbers, a stylized version of the kind of judgment made when someone decides which of two investments has performed better on average in the past. We find that the errors in peoples expressed judgments (in an incentivized laboratory experiment) are well-explained by a model in which the subjects judgment depend on whether the sum of the perceived values of one sequence of numbers is greater than that of the other, where the perceived value of each number is a random draw (on each experimental trial) from a probability distribution that depends on the actual number presented; but this perceived value is neither perfectly predictable, nor equal on average to the number actually presented. We further show that the probability of a correct judgment in the case of two sequences of numbers depends on the context in which the numbers appear --- specifically, on the probability distribution from which the numbers used on separate trials are drawn. Both the way in which bias and variability in responses depend on the sequences presented, and they way in which they change depending on the overall distribution of numbers used across trials, are shown to be consistent with a model in which subjects decisions are optimal (that is, they maximize subjects average financial rewards), subject to the decisions having to be based on noisy (rather than perfectly precise) internal representations of the numbers presented; and in which the degree of random noise in the representation of a particular number is optimally chosen, given a constraint on the feasible precision of the representation scheme as a whole. The solution to this optimization problem depends on the distribution of numbers that must be represented on different trials; and this accounts to an important extent for the way that the distributions of perceived values for given numbers are seen to shift when the numbers presented to subjects are drawn from different distributions.\n\n\n We also study bias and variability in peoples judgments about the probability of occurrence of an event, after a succession of observations of occasions on which the event either does or does not occur. This is again a stylized version of a type of judgment that is fundamental when choosing between investments; but here the focus is on how well people assess the probabilities of different outcomes (i.e., how well they assess risks), rather than on how well they calculate average values. We also observe how experimental subjects adjust their probability beliefs after each additional observation, rather than only asking for a judgment after a complete sequence of observations; this provides further insight into the random errors that arise each time further information is integrated with what had been seen before. We again document the systematic biases that result from imprecision in information integration; one of our most important findings shows that people tend to be excessively conservative in the degree to which they update their beliefs in response to new evidence, when they have seen relatively little evidence, while instead they over-adjust their beliefs cumulatively in response to a longer sequence of evidence, relative to a correct probability calculation. We show that both patterns of bias (as well as the random variation in the same subjects responses when presented with the same sequence of evidence on different trials) can be explained by a single model of noisy cognitive processing. Moreover, the distribution of responses to a given sequence of evidence is found to be different when the distribution of possible evidence sequences used in the experiment changes, and this shift in the pattern of bias in subjects responses can be explained as an efficient adaptation of subjects imprecise cognitive process to the statistics of the environment in which they must make decisions.\n\n\n\t\t\t\t\tLast Modified: 06/27/2024\n\n\t\t\t\t\tSubmitted by: MichaelWoodford\n"
 }
}