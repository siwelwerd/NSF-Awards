{
 "awd_id": "2007076",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Small: Human Validation in Batch Reinforcement Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2020-09-10",
 "awd_max_amd_letter_date": "2021-08-04",
 "awd_abstract_narration": "There exist many settings in which trying out a new decision might be costly, but logs of past decisions and outcomes might help to inform this new decision.  For example, health records track clinical decisions and outcomes; online courses may track different teaching and engagement strategies and final performance; factories may track different process choices and output quality.  Information from past logs may prevent us from making the same mistakes and improve outcomes.  However, learning from such logged data is not easy: not all possible decisions may have been tried, and not all relevant information will have been recorded: for example, a health record may accurately contain what lab tests a patient received but lack potentially relevant information about their home and work environment.  These challenges make it hard for systems to reason about the effect of following a different decision-making strategy than current practice.  Current approaches fall into two main types: statistical methods, which have strong theoretical foundations but require many assumptions; and those based on human expertise, which can be strong but also fallible.  This work brings together the strengths of statistical and human-based approaches to validation to help identify promising decision-making strategies from logged data.\r\n\r\nSpecifically, the project focuses on integrating human and statistical inputs for two major tasks.  The first is the task of converting the raw inputs (histories of measurements) into human-understandable representations, where statistical methods are used to proposed representations that will be useful for defining or summarizing a policy and human input is used to ensure that the representation is intuitive, or at least understandable.  The second is the task of estimating differences in outcomes if a different decision is made.  Here, statistical methods are used to form the initial estimate as well as identify what data are most influential to that estimate, and human input is used to determine whether the estimate is reliable given that it relies particularly on those data.  These two building blocks, which allow us to summarize the data and a policy, as well as estimate outcomes, are then used for both evaluating a given policy and proposing new policies.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Finale",
   "pi_last_name": "Doshi-Velez",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Finale Doshi-Velez",
   "pi_email_addr": "finale@seas.harvard.edu",
   "nsf_id": "000599894",
   "pi_start_date": "2020-09-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Elena",
   "pi_last_name": "Glassman",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Elena L Glassman",
   "pi_email_addr": "glassman@seas.harvard.edu",
   "nsf_id": "000788229",
   "pi_start_date": "2020-09-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University",
  "perf_str_addr": "Maxwell Dworkin, 33 Oxford St.",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021382933",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 150928.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 299072.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>There are many settings in which we have logs of prior decisions and outcomes.&nbsp; For example, in medical settings, it is relatively easy to create a data set containing the sequences of treatments and results of care for a large number of patients.&nbsp; Similarly, it is relatively easy to create a data set of driving trajectories for a large number of cars.&nbsp; The goal of batch reinforcement learning (batch RL) is use these past decision-making logs to come up with better decision making algorithms.&nbsp; Batch RL is especially important and appealing in high stakes settings, where we want to learn as much from past experience as possible and avoid any dangerous experimentation.</p>\r\n<p>However, there is a core challenge: if you only have logs, without the opportunity to try a new algorithm live, how do you know whether a newly proposed decision-making algorithm is better than current practice?&nbsp; Toward this challenge, a number of statistical techniques have been created to estimate the quality of the new algorithm from old data.&nbsp; However, these techniques are limited by assumptions that can be made about the data logs -- e.g., have all important variables been recorded? -- that are often not true in real settings.&nbsp; For example, data logs from patients never tell the whole story of a patient.</p>\r\n<p>Intellectual Merit: While this work produced multiple contributions in learning from human-generated data, the main contribution of this work is a batch RL approach that supports human inspection of the newly proposed decision making algorithm -- so domain experts can investigate for sanity -- that retains strong statistical guarantees.&nbsp; The core idea is to search the data logs for contexts where the humans make different decisions in the same state.&nbsp; For example, cases where two patients might have nearly identical disease presentations but doctors made different treatment choices.&nbsp; These \"forks in the road\" are natural experiments that guide us to the only places where we have statistical grounding to suggest one decision may be better than another.&nbsp; Because the forks in the road are discrete, experts can also inspect each one for whether it makes sense -- reducing a highly complex space to a list of a few fork locations.&nbsp; We prove that our approach gives stronger bounds than alternatives.</p>\r\n<p>Broader Impact: In addition to training graduate and masters students, as well as teaching a seminar based on this material, we applied our algorithm to real contexts in critical care. Our clinical collaborators were able to use the inspectability of our approach to identify that key inputs were missing in our first application of the algorithm; consequently we added those inputs and they verified that now the recommendations seemed sensible.&nbsp; They would not have been able to identify and correct this data processing issue without the inspectability of our approach; this could not be caught by a purely statistical approach.&nbsp; We have disseminated this work not only within the machine learning community but also to the clinical community through publications and talks.&nbsp;</p><br>\n<p>\n Last Modified: 02/13/2025<br>\nModified by: Finale&nbsp; &nbsp;Doshi-Velez</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThere are many settings in which we have logs of prior decisions and outcomes. For example, in medical settings, it is relatively easy to create a data set containing the sequences of treatments and results of care for a large number of patients. Similarly, it is relatively easy to create a data set of driving trajectories for a large number of cars. The goal of batch reinforcement learning (batch RL) is use these past decision-making logs to come up with better decision making algorithms. Batch RL is especially important and appealing in high stakes settings, where we want to learn as much from past experience as possible and avoid any dangerous experimentation.\r\n\n\nHowever, there is a core challenge: if you only have logs, without the opportunity to try a new algorithm live, how do you know whether a newly proposed decision-making algorithm is better than current practice? Toward this challenge, a number of statistical techniques have been created to estimate the quality of the new algorithm from old data. However, these techniques are limited by assumptions that can be made about the data logs -- e.g., have all important variables been recorded? -- that are often not true in real settings. For example, data logs from patients never tell the whole story of a patient.\r\n\n\nIntellectual Merit: While this work produced multiple contributions in learning from human-generated data, the main contribution of this work is a batch RL approach that supports human inspection of the newly proposed decision making algorithm -- so domain experts can investigate for sanity -- that retains strong statistical guarantees. The core idea is to search the data logs for contexts where the humans make different decisions in the same state. For example, cases where two patients might have nearly identical disease presentations but doctors made different treatment choices. These \"forks in the road\" are natural experiments that guide us to the only places where we have statistical grounding to suggest one decision may be better than another. Because the forks in the road are discrete, experts can also inspect each one for whether it makes sense -- reducing a highly complex space to a list of a few fork locations. We prove that our approach gives stronger bounds than alternatives.\r\n\n\nBroader Impact: In addition to training graduate and masters students, as well as teaching a seminar based on this material, we applied our algorithm to real contexts in critical care. Our clinical collaborators were able to use the inspectability of our approach to identify that key inputs were missing in our first application of the algorithm; consequently we added those inputs and they verified that now the recommendations seemed sensible. They would not have been able to identify and correct this data processing issue without the inspectability of our approach; this could not be caught by a purely statistical approach. We have disseminated this work not only within the machine learning community but also to the clinical community through publications and talks.\t\t\t\t\tLast Modified: 02/13/2025\n\n\t\t\t\t\tSubmitted by: Finale Doshi-Velez\n"
 }
}