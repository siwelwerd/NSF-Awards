{
 "awd_id": "2024446",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: INT: Collaborative Research: An Open-Source Framework for Continuous Torque Control of Intuitive Robotic Prosthetic Legs",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032922633",
 "po_email": "aleoness@nsf.gov",
 "po_sign_block_name": "Alex Leonessa",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 560000.0,
 "awd_amount": 560000.0,
 "awd_min_amd_letter_date": "2020-08-03",
 "awd_max_amd_letter_date": "2020-08-03",
 "awd_abstract_narration": "This project will establish an open source set of software control algorithms that will allow an open source robotic prosthetic leg to facilitate rhythmic and non-rhythmic interactions between the human user and the environment. This project builds upon the Open-Source Leg, which is a robust, inexpensive, robotic leg platform that can be easily manufactured, assembled, and programmed. The project's overarching goal is to enable customizable behaviors that are continuously cued by the movement of the user\u2019s body. The project promotes the progress of science by creating open source control hardware and software for compliant actuators that extend the capabilities of the Open-Source Leg. The advantages of compliant torque control, combined with intuitive, expressive control from the user, represents a significant improvement over currently-available prosthetic legs. The project will advance the national health by developing and testing high-level control software that will allow users of the Open Source Leg to seamlessly navigate around obstacles and perform dynamic activities. The improved mobility provided by these technologies will improve the quality of life and functional capabilities of many people living with mobility impairment. Open source hardware and software lower barriers to access for robotic technologies, which makes these robots great candidates not only as assistive co-robots in healthcare and other applications but also as educational tools for undergraduate and graduate students.\r\n\r\nEmerging powered prostheses such as the NSF-funded Open-Source Leg have motors that can restore normative biomechanics to above-knee amputees, but these devices are limited by their control strategies to a small set of pre-defined, steady-state activities. Each activity is typically divided into a discrete progression of gait periods called phases, resulting in a large set of distinct controllers that struggle to continuously coordinate prosthetic limb motion with the user. Discrete control paradigms have not been able to facilitate transient behaviors like transitions between activities or non-rhythmic motions like stepping backwards or stepping over obstacles. Recently, a new control paradigm has emerged that continuously synchronizes or coordinates prosthetic limb motion to the user based on inertial measurements from the user\u2019s body (e.g., the residual limb). However, prior implementations have been limited to lab-specific prosthetic leg designs with stiff actuators that rigidly enforce the kinematic mappings from user motion to prosthetic joint position rather than complying to varying environmental interactions. The recently developed Open-Source Leg presents a unique opportunity to integrate this state-of-the-art control paradigm in a universally accessible testbed with series elastic actuators that soften interactions between the user, prosthesis, and environment. The overall goals of this project are to 1) understand how to achieve closed-loop torque and impedance control in the series elastic actuator of the open-source leg despite unmodeled dynamics from its low-cost design, and 2) understand how to integrate high-fidelity joint impedance control with two novel continuous controllers that promise to allow users to flexibly and seamlessly navigate obstacles and perform dynamic activities.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Rombokas",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Eric S Rombokas",
   "pi_email_addr": "rombokas@uw.edu",
   "nsf_id": "000793382",
   "pi_start_date": "2020-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "4333 Brooklyn Ave NE",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981950001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7632",
   "pgm_ref_txt": "HUMAN-ROBOT INTERACTION"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 560000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-52fa6c78-7fff-710a-fd36-6400a81ce9cd\">\r\n<p dir=\"ltr\"><span>The objective of this project is to establish an open source set of software control algorithms that will allow robotic prosthetic limbs to operate better. The research team is using data collected from people moving in the real world to improve how movement is analyzed. We also have developed new software and methods to generate controls for robotic prosthetic limbs and other devices that help people to move and interact with the world.&nbsp;</span></p>\r\n<p dir=\"ltr\">A key outcome of this research is a broadening of the conception of \"ideal\" movement profiles from purely repeaing cycles, to more natural, fluid, movements. In other words, previous controllers have generally relied on the conception of gait as \"on rails\" along a prescribed repeating pattern, either designed by hand or measured during extremely structured situations such as walking on a treadmill. We have shown that unstructured movement in real-world spaces can be 1) captured at scale and 2) mined for regularities that allow us to generalize away from repeated movement. We can even capture and re-create differences due to personal style. This opens a path for richer, more expressive, and more robust movement control.</p>\r\n<p dir=\"ltr\">The research team&nbsp; also developed a method for incorporating a worn camera to provide computer vision cues in addition to the body movement data. We have shown that optical data contains powerful information about the future movement intent of the wearer. Environmental cues, such as upcoming terrain, or the moment-to-moment movements of the user, can be leveraged to improve controls for the prosthesis.</p>\r\n<p dir=\"ltr\">In order to achieve these research outcomes, we have also introduced a technical innovation in using neural network classifiers as a component of the cost function in training the neural network generative models. This amounts to building an \"adversarial\" ai inside the training of the gait synthesizer. To our knowledge this is the first use of classifier networks in the training of predictive time-series networks, and this technique could have utility in unrelated applications.&nbsp;</p>\r\n<p dir=\"ltr\">In short, this research improves our understanding of how people move, how we can sense and understand it, and how that understanding can lead to improved prosthetic limbs and wearable devices.&nbsp;</p>\r\n<p dir=\"ltr\"><span><br /></span></p>\r\n</span></p><br>\n<p>\n Last Modified: 04/06/2025<br>\nModified by: Eric&nbsp;Scott&nbsp;Rombokas</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\r\n\n\nThe objective of this project is to establish an open source set of software control algorithms that will allow robotic prosthetic limbs to operate better. The research team is using data collected from people moving in the real world to improve how movement is analyzed. We also have developed new software and methods to generate controls for robotic prosthetic limbs and other devices that help people to move and interact with the world.\r\n\n\nA key outcome of this research is a broadening of the conception of \"ideal\" movement profiles from purely repeaing cycles, to more natural, fluid, movements. In other words, previous controllers have generally relied on the conception of gait as \"on rails\" along a prescribed repeating pattern, either designed by hand or measured during extremely structured situations such as walking on a treadmill. We have shown that unstructured movement in real-world spaces can be 1) captured at scale and 2) mined for regularities that allow us to generalize away from repeated movement. We can even capture and re-create differences due to personal style. This opens a path for richer, more expressive, and more robust movement control.\r\n\n\nThe research team also developed a method for incorporating a worn camera to provide computer vision cues in addition to the body movement data. We have shown that optical data contains powerful information about the future movement intent of the wearer. Environmental cues, such as upcoming terrain, or the moment-to-moment movements of the user, can be leveraged to improve controls for the prosthesis.\r\n\n\nIn order to achieve these research outcomes, we have also introduced a technical innovation in using neural network classifiers as a component of the cost function in training the neural network generative models. This amounts to building an \"adversarial\" ai inside the training of the gait synthesizer. To our knowledge this is the first use of classifier networks in the training of predictive time-series networks, and this technique could have utility in unrelated applications.\r\n\n\nIn short, this research improves our understanding of how people move, how we can sense and understand it, and how that understanding can lead to improved prosthetic limbs and wearable devices.\r\n\n\n\n\r\n\t\t\t\t\tLast Modified: 04/06/2025\n\n\t\t\t\t\tSubmitted by: EricScottRombokas\n"
 }
}