{
 "awd_id": "2041303",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Broadening Participation at The Conference on the Mathematical Theory of Deep Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2021-02-01",
 "awd_exp_date": "2024-01-31",
 "tot_intn_awd_amt": 20000.0,
 "awd_amount": 20000.0,
 "awd_min_amd_letter_date": "2020-09-08",
 "awd_max_amd_letter_date": "2020-10-14",
 "awd_abstract_narration": "The Conference on the Mathematical Theory of Deep Learning (DeepMath) is a unique annual meeting dedicated to a truly cross-disciplinary approach to a fundamental understanding of the deep learning methodologies that are revolutionizing machine learning both in academics and in industry. This grant aims to broaden participation at DeepMath; a meeting where diverse researchers across backgrounds and disciplines come together to develop a fundamental theory of Deep Learning, and by proxy other large, distributed learning systems. The central philosophy mirrors how neuroscience began with a mix of physicists, biologists, psychologists, engineers, and mathematicians all interested in the same quandary. By definition, the foundation of such an effort is in broadening participation and maximizing diversity and inclusion to create a truly egalitarian effort. \r\n\r\nThis grant funds new programs aimed at ensuring that our community is accessible and welcoming to those from under-represented groups through (1) fellowship awards, (2) speaker costs (travel and lodging), and (3) broadcasting live streaming and video hosting to broader research community. Specific programs include outreach via targeted advertising and inclusion of members of these groups in the organizing committee, travel grants, childcare grants for economically disadvantaged researchers, and plans for a future mentorship programming collaboration with LatinXinAI and other professional organizations. Assessment via questionnaires and demographic data will determine which efforts succeeded most to continually refine these programs for future years.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Adam",
   "pi_last_name": "Charles",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Adam S Charles",
   "pi_email_addr": "adamsc@jhu.edu",
   "nsf_id": "000810583",
   "pi_start_date": "2020-09-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "3400 N. Charles, Clark Hall",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182681",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 20000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Deep learning has become a crucual tool for scientists across domains. Fair and euitable use, as well as improving the performance capabilities, of these tools requires a thorough understanding of the mathematical foundations that drive them. As this problem is so fundamental, researchers from across disciplines, including mathematics, computer science, physics, engineering, neuroscience, etc. have all begun parallel paths in order to develop a theoretical foundation for deep learning. In The Conference on the&nbsp;Mathematical Theory of Deep Learning we aim to provide a meeting that bridges across disciplines to connect researchers working on this improtant problem from a diversity of&nbsp;approaches. Broadening participation in this conference is a key effort to making the continued progress and ensuring that the community 1) benefits from a broader range of experiences, thoughts, and creativity, and 2) disseminates the current state-of-the-art knowledge to a broader audience. This award enabled both tasks by 1) providing 30 travel grants for childcare or economically disadvantaged attendees, and 2) record and process&nbsp; videos of all lectures for broader dissemination online. The former enabled attendees, primarily women and URMs who are disproportionately impacted by childcare considerations and lack of resources to attend conferences, to participate and bring their advances and creativity in person. The latter has created an online resource that has garnered 58,000 views, making the presentations at DeepMath broadly accessible.&nbsp;</p><br>\n<p>\n Last Modified: 03/31/2024<br>\nModified by: Adam&nbsp;S&nbsp;Charles</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nDeep learning has become a crucual tool for scientists across domains. Fair and euitable use, as well as improving the performance capabilities, of these tools requires a thorough understanding of the mathematical foundations that drive them. As this problem is so fundamental, researchers from across disciplines, including mathematics, computer science, physics, engineering, neuroscience, etc. have all begun parallel paths in order to develop a theoretical foundation for deep learning. In The Conference on theMathematical Theory of Deep Learning we aim to provide a meeting that bridges across disciplines to connect researchers working on this improtant problem from a diversity ofapproaches. Broadening participation in this conference is a key effort to making the continued progress and ensuring that the community 1) benefits from a broader range of experiences, thoughts, and creativity, and 2) disseminates the current state-of-the-art knowledge to a broader audience. This award enabled both tasks by 1) providing 30 travel grants for childcare or economically disadvantaged attendees, and 2) record and process videos of all lectures for broader dissemination online. The former enabled attendees, primarily women and URMs who are disproportionately impacted by childcare considerations and lack of resources to attend conferences, to participate and bring their advances and creativity in person. The latter has created an online resource that has garnered 58,000 views, making the presentations at DeepMath broadly accessible.\t\t\t\t\tLast Modified: 03/31/2024\n\n\t\t\t\t\tSubmitted by: AdamSCharles\n"
 }
}