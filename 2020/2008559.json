{
 "awd_id": "2008559",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: RI: Small: Theoretical Foundations: TheAdvantage of Deep Learning over Traditional Shallow Learning Methods",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 159207.0,
 "awd_amount": 159207.0,
 "awd_min_amd_letter_date": "2020-09-03",
 "awd_max_amd_letter_date": "2020-10-19",
 "awd_abstract_narration": "Machine learning has been a primary driving force behind many current intelligent decision-making systems. Recently it shows a paradigm shift with increasing reliance on deep learning approaches, which have achieved unprecedented performance in various applications such as image processing, speech recognition, language translation, and game playing. Besides the empirical success, provable guarantees and insights into the principles behind the success have also become sought-after goals. However, the lack of adequate understanding is still limiting our capacity to fully exploit the potential of deep learning. This project aims to lay the foundations for supporting the practical trends, by understanding the advantages of deep learning over traditional learning methods, which is crucial for revealing key factors behind the practical success. The project will provide frameworks for proving performance guarantees and advantages of deep learning over traditional learning methods and enable the development of new deep learning methods that are more efficient and accessible.  \r\n\r\nThis project will develop a thorough and systematic approach for understanding the superior empirical performance of deep learning over traditional learning methods and use the obtained insights to design new learning methods. It will develop new theoretical models of properties on the labeling function of the data and the structure of the input leading to the practical success, and also provides frameworks for proving performance guarantees and advantages over shallow learning. It will also design new learning methods that explicitly exploit those properties and thus can be more efficient and accessible. This direction is still largely unexplored, despite significant recent research activities. The planned theoretical and algorithmic solutions are possible through an interdisciplinary mix of tools from machine learning, statistics, and optimization. The proposed program is grounded in the investigators' prior work that includes both theoretical results and empirical validation. If successful, the proposed research can be transformational for modern intelligent systems by laying the foundations for further development. It will also help to solve new theoretical problems from practice that are not adequately addressed by current theory and will have lasting impacts on machine learning and optimization.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yingyu",
   "pi_last_name": "Liang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yingyu Liang",
   "pi_email_addr": "yliang@cs.wisc.edu",
   "nsf_id": "000785013",
   "pi_start_date": "2020-09-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537151218",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7796",
   "pgm_ref_txt": "ALGORITHMIC FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 159207.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Artificial intelligence has made transformative progress in recent years, and the key factor behind the breakthrough is deep learning, a machine learning paradigm that uses large artificial neural networks as system models. Unprecedented empirical success has been achieved in various intelligent tasks such as image classification, speech recognition, natural language processing, and game playing. Deep learning also has been adopted as a powerful tool in various scientific areas, reforming the field of computer science and related research areas, with long-term impacts on societies and people's daily lives.</p>\n<p>While great empirical success has been achieved, the theoretical foundation of deep learning lags behind and has been limiting the capacity to fully exploit the potential of deep learning. In particular, we would like to gain a better understanding of why deep learning has significant advantages in performance over traditional methods using shallow models. This can provide insights into the key principle of its empirical success and help improve existing learning methods or design novel ones.</p>\n<p>This project has investigated the theoretical foundation of the advantage of deep learning from the perspective of exploiting the structure of the data in the learning process. Deep learning has been shown to have a strong ability to exploit the data's structure. This project investigated this ability from two aspects. The first aspect is the structure of the labeling functions to be learned. We show that deep learning indeed has better exploitation than shallow models, by showing that there are examples of labeling functions with hierarchical structures such that deep learning models can learn successfully but shallow models cannot. The second aspect is the structure of the input data. We show that this is crucial for the success of deep learning, by showing that there are examples where deep learning can succeed while shallow models fail, and furthermore, removing the input structure fails deep learning. This indicates the input structure is necessary for success. After we investigated the theoretical foundations, we further applied the theoretical insights to improving existing methods and designing new ones.</p>\n<p>To date, the project has produced multiple peer-reviewed publications in top conferences/journals in machine learning, with further papers in development. The results have been disseminated in conferences and seminars, and related experimental codes have been made public. Several graduate and undergraduate students were trained in machine learning, theoretical analysis, algorithm design, and system development. Furthermore, interdisciplinary research has been carried out with applications in other fields such as biology and material science, speeding up the dissemination of AI techniques.</p><br>\n<p>\n Last Modified: 03/23/2024<br>\nModified by: Yingyu&nbsp;Liang</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nArtificial intelligence has made transformative progress in recent years, and the key factor behind the breakthrough is deep learning, a machine learning paradigm that uses large artificial neural networks as system models. Unprecedented empirical success has been achieved in various intelligent tasks such as image classification, speech recognition, natural language processing, and game playing. Deep learning also has been adopted as a powerful tool in various scientific areas, reforming the field of computer science and related research areas, with long-term impacts on societies and people's daily lives.\n\n\nWhile great empirical success has been achieved, the theoretical foundation of deep learning lags behind and has been limiting the capacity to fully exploit the potential of deep learning. In particular, we would like to gain a better understanding of why deep learning has significant advantages in performance over traditional methods using shallow models. This can provide insights into the key principle of its empirical success and help improve existing learning methods or design novel ones.\n\n\nThis project has investigated the theoretical foundation of the advantage of deep learning from the perspective of exploiting the structure of the data in the learning process. Deep learning has been shown to have a strong ability to exploit the data's structure. This project investigated this ability from two aspects. The first aspect is the structure of the labeling functions to be learned. We show that deep learning indeed has better exploitation than shallow models, by showing that there are examples of labeling functions with hierarchical structures such that deep learning models can learn successfully but shallow models cannot. The second aspect is the structure of the input data. We show that this is crucial for the success of deep learning, by showing that there are examples where deep learning can succeed while shallow models fail, and furthermore, removing the input structure fails deep learning. This indicates the input structure is necessary for success. After we investigated the theoretical foundations, we further applied the theoretical insights to improving existing methods and designing new ones.\n\n\nTo date, the project has produced multiple peer-reviewed publications in top conferences/journals in machine learning, with further papers in development. The results have been disseminated in conferences and seminars, and related experimental codes have been made public. Several graduate and undergraduate students were trained in machine learning, theoretical analysis, algorithm design, and system development. Furthermore, interdisciplinary research has been carried out with applications in other fields such as biology and material science, speeding up the dissemination of AI techniques.\t\t\t\t\tLast Modified: 03/23/2024\n\n\t\t\t\t\tSubmitted by: YingyuLiang\n"
 }
}