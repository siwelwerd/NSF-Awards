{
 "awd_id": "2036368",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Workshop on desiderata for a multimodal dataset for objectionable content detection",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2020-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 43959.0,
 "awd_amount": 43959.0,
 "awd_min_amd_letter_date": "2020-07-27",
 "awd_max_amd_letter_date": "2020-07-27",
 "awd_abstract_narration": "Kids and young adults are increasingly relying on electronic devices as their main source of entertainment. During this screen time, users can watch movies, videos, and play online games on a multitude of platforms. While many platforms have parental controls, many of these app-specific filters have been found to be unreliable and easy to deceive. Exposing kids and young viewers to objectionable content has been documented to correlate with violent behavior and early initiation of sex and alcohol usage in teenagers, and anxiety and fear among children.  Therefore, there is an urgent critical need to develop Artificial Intelligence methods that can help detect objectionable content. \r\n \r\nDeveloping this technology requires new research infrastructure in the form of an extensive repository of consistently labeled movies and video content that currently does not exist. Through the mini-workshop series, the research team will lay the groundwork to design and create this new repository of objectionable content. The resulting infrastructure will help advance technology that will contribute to the crucial goal of providing a safer online space for young users.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thamar",
   "pi_last_name": "Solorio",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Thamar Solorio",
   "pi_email_addr": "thamar.solorio@gmail.com",
   "nsf_id": "000492342",
   "pi_start_date": "2020-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ioannis",
   "pi_last_name": "Kakadiaris",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Ioannis A Kakadiaris",
   "pi_email_addr": "ioannisk@uh.edu",
   "nsf_id": "000095195",
   "pi_start_date": "2020-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Houston",
  "inst_street_address": "4300 MARTIN LUTHER KING BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "HOUSTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7137435773",
  "inst_zip_code": "772043067",
  "inst_country_name": "United States",
  "cong_dist_code": "18",
  "st_cong_dist_code": "TX18",
  "org_lgl_bus_name": "UNIVERSITY OF HOUSTON SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "QKWEF8XLMTT3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Houston",
  "perf_str_addr": "",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "772042015",
  "perf_ctry_code": "US",
  "perf_cong_dist": "18",
  "perf_st_cong_dist": "TX18",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 43959.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-eb0af9ca-7fff-3ba3-66ef-56205f47c343\" style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 12pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Kids and young adults are increasingly relying on electronic devices as their main source of entertainment. During this screen time, users can watch movies, videos, and play online games on a multitude of platforms. While many platforms have parental controls, many of these app-specific filters have been found to be unreliable and easy to deceive. Exposing kids and young viewers to objectionable content has been documented to correlate with violent behavior and early initiation of sex and alcohol usage in teenagers, and anxiety and fear among children. Therefore, there is an urgent critical need to develop Artificial Intelligence methods that can help detect objectionable content.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 12pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Developing this technology requires new research infrastructure in the form of an extensive repository of consistently labeled movies and video content that currently does not exist.This award allowed the research team to study the implications of creating the infrastructure that can support efforts into developing automated methods for detection of objectionable content online.&nbsp;</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 12pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Through a series of online mini-workshops targeting key disciplines, the research team gathered world experts and elicited feedback relevant to creating the large repository. The workshops included child psychologists and mass media experts that helped the research team to form a deeper understanding of the different types of objectionable content, and the potential risks for young viewers. Experts from ethics in AI provided feedback with respect to the potential risks and biases in collecting and annotating content. Finally, speech, language processing, computer vision and machine learning experts contributed ideas on how to make the repository valuable for the different research areas.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The research team published three white papers that document in an organized manner, the findings from the different workshops. These white papers could prove valuable to others interested in carrying out similar research where multiple disciplines should be involved from the initial planning stages of the project.&nbsp;</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/05/2022<br>\n\t\t\t\t\tModified by: Thamar&nbsp;Solorio</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Kids and young adults are increasingly relying on electronic devices as their main source of entertainment. During this screen time, users can watch movies, videos, and play online games on a multitude of platforms. While many platforms have parental controls, many of these app-specific filters have been found to be unreliable and easy to deceive. Exposing kids and young viewers to objectionable content has been documented to correlate with violent behavior and early initiation of sex and alcohol usage in teenagers, and anxiety and fear among children. Therefore, there is an urgent critical need to develop Artificial Intelligence methods that can help detect objectionable content.\nDeveloping this technology requires new research infrastructure in the form of an extensive repository of consistently labeled movies and video content that currently does not exist.This award allowed the research team to study the implications of creating the infrastructure that can support efforts into developing automated methods for detection of objectionable content online. \nThrough a series of online mini-workshops targeting key disciplines, the research team gathered world experts and elicited feedback relevant to creating the large repository. The workshops included child psychologists and mass media experts that helped the research team to form a deeper understanding of the different types of objectionable content, and the potential risks for young viewers. Experts from ethics in AI provided feedback with respect to the potential risks and biases in collecting and annotating content. Finally, speech, language processing, computer vision and machine learning experts contributed ideas on how to make the repository valuable for the different research areas.\nThe research team published three white papers that document in an organized manner, the findings from the different workshops. These white papers could prove valuable to others interested in carrying out similar research where multiple disciplines should be involved from the initial planning stages of the project. \n\n\t\t\t\t\tLast Modified: 12/05/2022\n\n\t\t\t\t\tSubmitted by: Thamar Solorio"
 }
}