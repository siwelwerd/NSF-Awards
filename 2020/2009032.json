{
 "awd_id": "2009032",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Graph Signal Processing Methods for Data-driven System Design",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032920000",
 "po_email": "ahero@nsf.gov",
 "po_sign_block_name": "Alfred Hero",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2020-06-23",
 "awd_max_amd_letter_date": "2020-06-23",
 "awd_abstract_narration": "Data-driven design is leading to unprecedented performance improvements in many widely used systems. Examples of recent successes can be found in speech recognition, advanced video analysis or imaging-based medical diagnosis, to name just a few. This project is motivated by the observation that more data does not always lead to better system design. In fact, extensive use of poorly understood data can create significant risks once systems are deployed. For example, data may introduce bias toward specific system outputs (e.g., lead to incorrect  diagnoses) or performance might degrade significantly under even small changes in data collection (e.g., microphone characteristics, camera resolution). These risks are a major obstacle to wider adoption of data-driven tools, in particular in critical applications.  This project develops methods to select data for improved system design, based on new models for large scale datasets. The ultimate goal of the project is to reduce deployment risk by designing systems based on the most representative dataset rather simply using the largest dataset. \r\n\r\n\r\nIn many applications, such as sensing, anomaly detection, classification, recognition or identification, systems are designed by first collecting significant amounts of data, and then optimizing system parameters using that data. As task complexity, data size and the number of system parameters increase, system analysis and characterization tasks become a major challenge, with estimates often based on end-to-end performance on the training set. Examples of these tasks include (i) estimating system accuracy, (ii) characterizing system stability to changes in data, (iii) determining the correct amounts of data needed for training or (iv) predicting their ability to generalize to different situations. In this project, graph-based approaches are developed to characterize large datasets in high dimensional space. This research is focused on theoretical, algorithmic and practical aspects of system characterization and design. On the theoretical front, this project tackles the problem of designing graphs that capture relevant properties of the data space, developing  asymptotic results to link the distribution of the data to properties of graphs and related graph signals. On the algorithmic front, efficient methods for graph construction and task complexity estimation are developed, with the goal of enabling selection of the most representative dataset. As an application, practical deep learning architectures are considered, methods to increase their robustness are studied, and new strategies for active and transfer learning are developed.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Antonio",
   "pi_last_name": "Ortega",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Antonio Ortega",
   "pi_email_addr": "ortega@sipi.usc.edu",
   "nsf_id": "000154600",
   "pi_start_date": "2020-06-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3740 McClintock Avenue",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900892564",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-866070a0-7fff-00fe-f494-554570480208\"> </span></p>\n<p dir=\"ltr\"><span>The emergence of Artificial Intelligence (AI) and Machine Learning (ML) systems has the potential to transform many aspects of our daily lives. However, AI/ML systems are increasingly complex and require large amounts of data for training. Consequently, while substantial improvements in AI/ML systems performance have been achieved, system complexity makes it difficult to interpret the results. In particular, when these systems fail to provide reliable outputs, it is hard to attribute these failures to specific design flaws or unreliable training data.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>In this project, we have developed methods to improve our understanding of AI/ML systems by focusing solely on the data (and how data are transformed by the system) rather than considering the details of the system architecture. Our work has developed new theories and algorithms while demonstrating the benefits of our methods for practical systems of interest. We have proposed methods to represent the similarity between data items using graphs, developed new algorithms to group similar items (clustering), and extended our ideas from data consisting of images to other datasets (including time series and text data). To demonstrate the benefits of our proposed approaches, we have considered several application case studies in different domains, including self-supervised learning for image data, analysis of EEG data, and identification of data outliers in a text dataset. The key outcome of this project is to demonstrate the feasibility of improving our understanding of complex AI/ML systems by only analyizing the data, providing new specific methods for this analysis. The work has been published in multiple venues, and the code developed in this project is publicly available.&nbsp;</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/20/2024<br>\nModified by: Antonio&nbsp;Ortega</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThe emergence of Artificial Intelligence (AI) and Machine Learning (ML) systems has the potential to transform many aspects of our daily lives. However, AI/ML systems are increasingly complex and require large amounts of data for training. Consequently, while substantial improvements in AI/ML systems performance have been achieved, system complexity makes it difficult to interpret the results. In particular, when these systems fail to provide reliable outputs, it is hard to attribute these failures to specific design flaws or unreliable training data.\n\n\n\n\n\nIn this project, we have developed methods to improve our understanding of AI/ML systems by focusing solely on the data (and how data are transformed by the system) rather than considering the details of the system architecture. Our work has developed new theories and algorithms while demonstrating the benefits of our methods for practical systems of interest. We have proposed methods to represent the similarity between data items using graphs, developed new algorithms to group similar items (clustering), and extended our ideas from data consisting of images to other datasets (including time series and text data). To demonstrate the benefits of our proposed approaches, we have considered several application case studies in different domains, including self-supervised learning for image data, analysis of EEG data, and identification of data outliers in a text dataset. The key outcome of this project is to demonstrate the feasibility of improving our understanding of complex AI/ML systems by only analyizing the data, providing new specific methods for this analysis. The work has been published in multiple venues, and the code developed in this project is publicly available.\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 11/20/2024\n\n\t\t\t\t\tSubmitted by: AntonioOrtega\n"
 }
}