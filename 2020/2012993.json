{
 "awd_id": "2012993",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Authoring Assistance via Contextual Semantic Labeling",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2021-04-30",
 "tot_intn_awd_amt": 216917.0,
 "awd_amount": 216917.0,
 "awd_min_amd_letter_date": "2020-07-06",
 "awd_max_amd_letter_date": "2020-07-06",
 "awd_abstract_narration": "The broader impact of this Small Business Innovation Research (SBIR) Phase I project is to advance Natural Language Processing (NLP) to improve productivity, compliance and insight for businesses. Documents are the underlying fabric of business as they hold detailed agreements, obligations, requirements and terms central to business operations with customers, suppliers, partners and regulators. However, documents still represent \"dark data\", separate and inaccessible to automated business processes. Businesses like commercial real estate, insurance, professional services, financial services, legal firms and many others produce and consume many documents containing similar patterns with innumerable variations. Authoring and executing these agreements is laborious and error-prone, but it is difficult to automate the use of this semi-structured information. This project develops a series of sophisticated steps to discern structure and information from narrative text, applying the latest techniques from several schools of thought in artificial intelligence. This project will enable knowledge workers to gain the assistance of artificial intelligence to author and execute commercial agreements with greater ease, efficiency, precision, confidentiality, compliance and insight.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project is to enhance unstructured human-centered text with a structured computer-optimized version, a \"shadow\" representation of each document that uses XML and database technology to enable innovative software assistance for users and organizations. The research takes a multi-faceted approach, applying computer vision and then creating a pipeline of new algorithms using techniques from Deep Learning, Bayesian, Evolutionary, Symbolic and Classic NLP.  The process operates on \"small\" datasets (10-30 documents) with high accuracy as well as large datasets.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Steven",
   "pi_last_name": "DeRose",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Steven J DeRose",
   "pi_email_addr": "sderose@docugami.com",
   "nsf_id": "000815552",
   "pi_start_date": "2020-07-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "DOCUGAMI, INC.",
  "inst_street_address": "11335 NE 122ND WAY STE 105",
  "inst_street_address_2": "",
  "inst_city_name": "KIRKLAND",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "4259682380",
  "inst_zip_code": "980346933",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "WA01",
  "org_lgl_bus_name": "DOCUGAMI, INC.",
  "org_prnt_uei_num": "RU6DPZBACK59",
  "org_uei_num": "RU6DPZBACK59"
 },
 "perf_inst": {
  "perf_inst_name": "DOCUGAMI, INC.",
  "perf_str_addr": "150 Lake St. S",
  "perf_city_name": "Kirkland",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "980336460",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "WA01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8032",
   "pgm_ref_txt": "Software Services and Applications"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 216917.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Project Outcomes Report</strong><br /><strong>NSF SBIR Phase I grant 2012993</strong><br /><br />This project investigated extracting \"contextual semantic labels\" (\"CSL\"s) from business contracts. This is part of larger goals of assisting in creating new document and extracting structured information.&nbsp; CSLs are defined as</p>\n<blockquote>&nbsp;&nbsp;&nbsp; words or phrases that describe the significance of other words or phrases in relation to the document?s overall purpose and are extracted from the context in the same document (typically very nearby).<br /></blockquote>\n<p>CSLs often (not exclusively) describe named \"entities\". CSLs are not generic labels like \"agent\" or \"subject\", but focus on how entities function in particular documents: a person may be the \"Seller\" (regardless of other, secondary acts of selling). A date may be the deadline for some action(s). Associating the right objects and roles is crucial for document understanding: which party is which is important to almost any contract, as is whether an address represents a property being leased, the address of some party, or something else altogether. CSL identification enables our main product offerings that assist authors in constructing new, similar documents, and extracting reports.<br /><br />We explored multiple AI and NLP approaches for finding accurate CSLs. We hand-annotated several thousand examples based on guidelines and examples we had produced earlier. We found that the concept of a CSL involved even more complexity than we had anticipated, and it was challenging to achieve good inter-rater agreement.<br /><br />Analysis revealed a few factors, including:</p>\n<p>1: CSLs are primarily about connections between things, and the annotation tools we used are not adept at representing this.<br /><br />2: Many entities have multiple connections, and it is not always clear that one is more important. Thus connection types must also be annotated, along with multiple connections to a single object.</p>\n<p>There were also more \"mechanical\" issues such as discontinuous CSLs, and the need to annotate enough examples of lack of any CSL. However, these were not substantial problems compared to the ambiguities and rater mismatch caused by (1) and (2).<br /><br />We did several rounds of editing, guideline revision, and additional annotation. Eventually, despite the difficulties we trained successful deep neural network models to find CSLs, and achieved CSL detection that provides useful and intuitive labels for our end users.<br /><br />Our second approach implemented SQuAD-style question-answering. After training, we posed questions such as \"What is 2020-12-31?\", hoping for response phrases such as \"the lease expires\", etc. We discovered this was very effective if the questions were very carefully formulated. We continue to investigate methods for constructing effective questions, and for making this approach even more robust.<br /><br />Our third approach developed pattern-matching to find entities not found by \"typical\" methods, even when we could not categorize them. For example, a social security number or a product ID from a given company has a reliable pattern, but would not be generalizable in unrestricted contexts. But because we address \"small data\" such as the leases of a particular company, such patterns are useful and discoverable for us. This approach resulted in finding many useful entities and we consider it a key discovery. For the additional entities we can apply the same CSL analysis as in other cases, or simply let the user assign a label to each equivalence class.<br /><br />Finally, we explored super-syntactic parsing methods, namely discourse and semantic parsing. We evaluated many existing systems for both, and found that discourse parsers have several virtues such as handling large-scale phenomena, but provide too little useful signal given the amount of noise also produced. The most frequent RST discourse roles were also too general for us. In the end, we stopped working with discourse parsers in favor of AMR-based semantic parsers. These focus mainly at sentence level, but we found they provide much more valuable information for determining CSLs.<br /><br />We found that some AMR parsers proved quite good at categorizing verbs (and non-verb expressions of states, actions, and processes) into broader semantic types. They were also adept at attaching entities to the right semantic slots of those action types (particularly important for CSL). Fairly often these role labels (along with the other attachments) proved to be what we want as CSLs ? and they could sometimes be found by parsers even when not explicitly stated in the text. Some such finds are not technically \"CSLs\", because not all occur in the text itself; but they are effective for the same purposes in our products, so we're quite happy to use them.<br /><br />In this project we refined our understanding of the problem space, substantially improved our methods of finding CSLs, and introduced new methods such as semantic parsing. We have integrated some of these innovations into our product offering, and are in that process with others. NSF's support for this research under the SBIR Phase I grant has been very important to our progress in building a strong market offering.<br /><br /><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/04/2021<br>\n\t\t\t\t\tModified by: Steven&nbsp;J&nbsp;Derose</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nProject Outcomes Report\nNSF SBIR Phase I grant 2012993\n\nThis project investigated extracting \"contextual semantic labels\" (\"CSL\"s) from business contracts. This is part of larger goals of assisting in creating new document and extracting structured information.  CSLs are defined as\n    words or phrases that describe the significance of other words or phrases in relation to the document?s overall purpose and are extracted from the context in the same document (typically very nearby).\n\n\nCSLs often (not exclusively) describe named \"entities\". CSLs are not generic labels like \"agent\" or \"subject\", but focus on how entities function in particular documents: a person may be the \"Seller\" (regardless of other, secondary acts of selling). A date may be the deadline for some action(s). Associating the right objects and roles is crucial for document understanding: which party is which is important to almost any contract, as is whether an address represents a property being leased, the address of some party, or something else altogether. CSL identification enables our main product offerings that assist authors in constructing new, similar documents, and extracting reports.\n\nWe explored multiple AI and NLP approaches for finding accurate CSLs. We hand-annotated several thousand examples based on guidelines and examples we had produced earlier. We found that the concept of a CSL involved even more complexity than we had anticipated, and it was challenging to achieve good inter-rater agreement.\n\nAnalysis revealed a few factors, including:\n\n1: CSLs are primarily about connections between things, and the annotation tools we used are not adept at representing this.\n\n2: Many entities have multiple connections, and it is not always clear that one is more important. Thus connection types must also be annotated, along with multiple connections to a single object.\n\nThere were also more \"mechanical\" issues such as discontinuous CSLs, and the need to annotate enough examples of lack of any CSL. However, these were not substantial problems compared to the ambiguities and rater mismatch caused by (1) and (2).\n\nWe did several rounds of editing, guideline revision, and additional annotation. Eventually, despite the difficulties we trained successful deep neural network models to find CSLs, and achieved CSL detection that provides useful and intuitive labels for our end users.\n\nOur second approach implemented SQuAD-style question-answering. After training, we posed questions such as \"What is 2020-12-31?\", hoping for response phrases such as \"the lease expires\", etc. We discovered this was very effective if the questions were very carefully formulated. We continue to investigate methods for constructing effective questions, and for making this approach even more robust.\n\nOur third approach developed pattern-matching to find entities not found by \"typical\" methods, even when we could not categorize them. For example, a social security number or a product ID from a given company has a reliable pattern, but would not be generalizable in unrestricted contexts. But because we address \"small data\" such as the leases of a particular company, such patterns are useful and discoverable for us. This approach resulted in finding many useful entities and we consider it a key discovery. For the additional entities we can apply the same CSL analysis as in other cases, or simply let the user assign a label to each equivalence class.\n\nFinally, we explored super-syntactic parsing methods, namely discourse and semantic parsing. We evaluated many existing systems for both, and found that discourse parsers have several virtues such as handling large-scale phenomena, but provide too little useful signal given the amount of noise also produced. The most frequent RST discourse roles were also too general for us. In the end, we stopped working with discourse parsers in favor of AMR-based semantic parsers. These focus mainly at sentence level, but we found they provide much more valuable information for determining CSLs.\n\nWe found that some AMR parsers proved quite good at categorizing verbs (and non-verb expressions of states, actions, and processes) into broader semantic types. They were also adept at attaching entities to the right semantic slots of those action types (particularly important for CSL). Fairly often these role labels (along with the other attachments) proved to be what we want as CSLs ? and they could sometimes be found by parsers even when not explicitly stated in the text. Some such finds are not technically \"CSLs\", because not all occur in the text itself; but they are effective for the same purposes in our products, so we're quite happy to use them.\n\nIn this project we refined our understanding of the problem space, substantially improved our methods of finding CSLs, and introduced new methods such as semantic parsing. We have integrated some of these innovations into our product offering, and are in that process with others. NSF's support for this research under the SBIR Phase I grant has been very important to our progress in building a strong market offering.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 06/04/2021\n\n\t\t\t\t\tSubmitted by: Steven J Derose"
 }
}