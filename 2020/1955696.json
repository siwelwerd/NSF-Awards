{
 "awd_id": "1955696",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CNS Core: Medium: Learning to Cache and Caching to Learn in High Performance Caching Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ann Von Lehmen",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 350000.0,
 "awd_amount": 350000.0,
 "awd_min_amd_letter_date": "2020-09-10",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "Caching is fundamental to cloud computing and content distribution, and is important to the vast number of applications and services they support.  Crucial performance metrics of a caching algorithm are its ability to quickly and accurately learn a changing popularity distribution. However, there is a serious disconnect between empirical studies using real-world traces that account for popularity changes, and analytical performance analysis results that assume a fixed popularity.  A basic goal of this project is to develop a methodology based on online learning and reinforcement learning for caching algorithm design with provable performance guarantees.  This enables the systematic design of caching algorithms that can be tailored to a variety of application contexts. The use-case of these algorithms is in high performance caching networks that support large-scale cloud applications and services.  Emulation of high-performance caching systems to leverage and to empirically evaluate the online learning algorithms developed supports this goal, and provides a real-world context for the methodology developed.  The results will also enhance the performance of content distribution platforms.  At the same time the project develops fundamental theories that pertain to the area of machine learning, specifically to online learning. \r\n\r\nThis project aims at optimally utilizing locally available memory and computing resources of caches, while ensuring provably good performance via fast and accurate learning of content popularity. This requires the conjunction of several mathematical tools to analyze online learning algorithms, as well as strong systems development skills to make the algorithms a reality. The project addresses these key challenges in two main themes. The first theme focuses on systematic design of distributed online learning in networks of caches using collaborative filtering for distributed identification of popular content, and multi-agent reinforcement learning for joint learning and content placement. The second theme focuses on building high performing caching systems using the algorithms developed in the first theme, and quantifying the impacts of the algorithms on real-world applications such as Hipster Shop, an open-source e-commerce website, and Spark data-analytics job pipelines. The immediate impact of this project is in creating high performance caching schemes that apply to cloud computing and content distribution networks. This project also advances the fundamental theory of online learning. The project includes an education plan focusing on machine learning and caching, and outreach in the form of summer camps and seminars for high school students.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Srinivas",
   "pi_last_name": "Shakkottai",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Srinivas Shakkottai",
   "pi_email_addr": "sshakkot@tamu.edu",
   "nsf_id": "000499924",
   "pi_start_date": "2020-09-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Dileep",
   "pi_last_name": "Kalathil",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dileep Kalathil",
   "pi_email_addr": "dileep.kalathil@tamu.edu",
   "nsf_id": "000760025",
   "pi_start_date": "2020-09-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M Engineering Experiment Station",
  "perf_str_addr": "Wisenbaker Engineering Building",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433128",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 350000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has made advancements in caching and content distribution by developing novel online learning algorithms, structured reinforcement learning methods, and scalable multi-agent decision-making frameworks. A primary focus was on optimizing caching strategies through online learning techniques, enabling rapid adaptation to dynamic content request patterns. By leveraging meta-learning, the project improved caching efficiency by transferring knowledge from past tasks, reducing cache miss rates and improving response times in edge networks. Additionally, the project established fundamental sample complexity bounds for constrained reinforcement learning, ensuring that learning-based caching and content delivery policies operate efficiently under real-world constraints.</p>\r\n<p>Beyond caching, the project advanced reinforcement learning-based media streaming by developing structured decision-making approaches that optimize resource allocation while minimizing latency. A key innovation was the use of structured reinforcement learning to exploit problem-specific characteristics, reducing training and inference times while ensuring robust performance across varying network conditions. Additionally, multi-agent reinforcement learning techniques enabled decentralized content distribution in wireless networks, improving Quality of Experience (QoE) while efficiently utilizing bandwidth. These contributions advance the broader fields of network optimization and intelligent content delivery by providing scalable, adaptive solutions for next-generation wireless systems.</p>\r\n<p>The broader impacts of this project extend to scientific advancements, education, and outreach. Theoretical contributions in online learning, constrained reinforcement learning, and meta-learning provide a strong foundation for adaptive decision-making in caching and content distribution. Educationally, the project played a central role in reinforcement learning coursework, equipping students with skills in structured decision-making and scalable learning techniques. Furthermore, as part of outreach activities, the Aggie DeepRacer Project introduced reinforcement learning for autonomous robotics, engaging students in hands-on experimentation with real-world robotic control. This initiative demonstrated the applicability of reinforcement learning in autonomous systems and helped train students in AI-driven decision-making.</p>\r\n<p>Through these efforts, the project has bridged the gap between theoretical research and practical deployment, fostering a new generation of researchers with expertise in adaptive caching, structured RL, and multi-agent learning. By advancing caching, media streaming, and robotics applications, this work lays the foundation for intelligent, efficient content delivery and autonomous decision-making in next-generation networked systems.</p><br>\n<p>\n Last Modified: 01/29/2025<br>\nModified by: Srinivas&nbsp;Shakkottai</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project has made advancements in caching and content distribution by developing novel online learning algorithms, structured reinforcement learning methods, and scalable multi-agent decision-making frameworks. A primary focus was on optimizing caching strategies through online learning techniques, enabling rapid adaptation to dynamic content request patterns. By leveraging meta-learning, the project improved caching efficiency by transferring knowledge from past tasks, reducing cache miss rates and improving response times in edge networks. Additionally, the project established fundamental sample complexity bounds for constrained reinforcement learning, ensuring that learning-based caching and content delivery policies operate efficiently under real-world constraints.\r\n\n\nBeyond caching, the project advanced reinforcement learning-based media streaming by developing structured decision-making approaches that optimize resource allocation while minimizing latency. A key innovation was the use of structured reinforcement learning to exploit problem-specific characteristics, reducing training and inference times while ensuring robust performance across varying network conditions. Additionally, multi-agent reinforcement learning techniques enabled decentralized content distribution in wireless networks, improving Quality of Experience (QoE) while efficiently utilizing bandwidth. These contributions advance the broader fields of network optimization and intelligent content delivery by providing scalable, adaptive solutions for next-generation wireless systems.\r\n\n\nThe broader impacts of this project extend to scientific advancements, education, and outreach. Theoretical contributions in online learning, constrained reinforcement learning, and meta-learning provide a strong foundation for adaptive decision-making in caching and content distribution. Educationally, the project played a central role in reinforcement learning coursework, equipping students with skills in structured decision-making and scalable learning techniques. Furthermore, as part of outreach activities, the Aggie DeepRacer Project introduced reinforcement learning for autonomous robotics, engaging students in hands-on experimentation with real-world robotic control. This initiative demonstrated the applicability of reinforcement learning in autonomous systems and helped train students in AI-driven decision-making.\r\n\n\nThrough these efforts, the project has bridged the gap between theoretical research and practical deployment, fostering a new generation of researchers with expertise in adaptive caching, structured RL, and multi-agent learning. By advancing caching, media streaming, and robotics applications, this work lays the foundation for intelligent, efficient content delivery and autonomous decision-making in next-generation networked systems.\t\t\t\t\tLast Modified: 01/29/2025\n\n\t\t\t\t\tSubmitted by: SrinivasShakkottai\n"
 }
}