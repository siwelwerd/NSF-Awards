{
 "awd_id": "2017917",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MRI: Acquisition of a High Performance Computing Cluster for Next-Generation Computational Science in Southern Colorado",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032927092",
 "po_email": "alsuarez@nsf.gov",
 "po_sign_block_name": "Alejandro Suarez",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 435228.0,
 "awd_amount": 435228.0,
 "awd_min_amd_letter_date": "2020-08-31",
 "awd_max_amd_letter_date": "2022-09-07",
 "awd_abstract_narration": "This project will enable the acquisition, deployment, and maintenance of a high performance computing (HPC) cluster (to be called INCLINE). This instrument will provide much-needed computational resources to the UCCS campus and the Southern Colorado scientific and academic communities. The size and power of the instrument will bridge the growing gap between workstation-level machines and Top 500 supercomputers, allowing researchers to test and leverage code scalability on an HPC platform, to expedite result processing, and to gain expertise on a local HPC environment. The work to be performed will yield insight into biomedical applications, such as microbubble drug delivery and bone fracture, military applications, such as additively manufactured energetics, and civil applications, including improved structural materials.  In addition to research applications, INCLINE will be used as an educational platform for teaching the fundamentals of an HPC to undergraduate and graduate students and allow students to investigate classroom problems more deeply with the computational power provided by an HPC. It will also be used to supplement existing outreach programs to spark enthusiasm and interest in HPC in the Southern Colorado community, which is diverse in both population and the range of applications. \r\n\r\nThe instrument\u2019s state-of-the-art hardware is designed to support a broad range of high-performance scientific applications, ranging from compiler design to computational fluid dynamics. The instrument will contain both CPU compute (including standard and high memory), and GPU nodes. The compute nodes will enable standard massively parallel computations such as computational solid mechanics and fluid dynamics. The GPU nodes will allow acceleration on computational physics and machine learning projects and will be used in conjunction with CPU nodes to test optimal load balancing on heterogeneous architectures. All nodes will be connected using InfiniBand high speed interconnects to minimize latency for communication-intense applications, including CFD and computational solid mechanics. A high speed SCRATCH storage file system will minimize I/O latency for applications with large output file sizes and I/O requirements. The estimated peak performance of the instrument is approximately 90 TFLOPS. The Slurm queueing system will be used to manage accounts and allocations across the diverse user base. The robust design of this instrument will allow it to fill the growing need for a local HPC research facility at UCCS and in Southern Colorado and will facilitate the training of the next generation of computational scientists.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Brandon",
   "pi_last_name": "Runnels",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Brandon Runnels",
   "pi_email_addr": "brunnels@iastate.edu",
   "nsf_id": "000702110",
   "pi_start_date": "2020-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Qing",
   "pi_last_name": "Yi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Qing Yi",
   "pi_email_addr": "yi7@llnl.gov",
   "nsf_id": "000492904",
   "pi_start_date": "2020-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Byeong",
   "pi_last_name": "Lee",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Byeong K Lee",
   "pi_email_addr": "blee@uccs.edu",
   "nsf_id": "000546529",
   "pi_start_date": "2020-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Amanda",
   "pi_last_name": "Morgenstern",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Amanda Morgenstern",
   "pi_email_addr": "amorgens@uccs.edu",
   "nsf_id": "000819853",
   "pi_start_date": "2020-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Quinlan",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "John M Quinlan",
   "pi_email_addr": "jquinlan@uccs.edu",
   "nsf_id": "000819882",
   "pi_start_date": "2020-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Colorado at Colorado Springs",
  "inst_street_address": "1420 AUSTIN BLUFFS PKWY",
  "inst_street_address_2": "",
  "inst_city_name": "COLORADO SPRINGS",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "7192553153",
  "inst_zip_code": "809183733",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "CO05",
  "org_lgl_bus_name": "THE REGENTS OF THE UNIVERSITY OF COLORADO",
  "org_prnt_uei_num": "",
  "org_uei_num": "RH87YDXC1AY5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Colorado at Colorado Springs",
  "perf_str_addr": "1420 Austin Bluffs Pkwy",
  "perf_city_name": "Colorado Springs",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "809183733",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "CO05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "118900",
   "pgm_ele_name": "Major Research Instrumentation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "1189",
   "pgm_ref_txt": "MAJOR RESEARCH INSTRUMENTATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 435228.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The acquisition of the INCLINE high performance computing (HPC) cluster, made possible through an NSF MRI grant, marks a significant addition of technological capability for the University of Colorado Colorado Springs. Like its namesake, the 2,768-step Manitou Incline trail that gains 2000 feet of elevation in less than a mile, the INCLINE HPC cluster represents a transformative elevation of computational research in the Southern Colorado research community. With 30 computational nodes, INCLINE is the first 100 teraflop (&gt;100 trillion calculations per second) instrument to be made available in the region.&nbsp;</p>\n<p>This project has enabled more than 8 million CPU hours dedicated to a diverse range of projects led by faculty and graduate students. More than 90% of the cluster&rsquo;s usage comes from bachelors, master, and doctoral students, engaged in research projects ranging from microstructure analysis in structural materials, computational combustion, and gasdynamics, to enzyme design and compiler hierarchy. These calculations have led to crucial advances in multiple funded projects, with sponsors including the National Science Foundation, Department of Defense, and Department of Energy. These include the development of novel high performance computational physics methods, as well as new models for solid rocket propellant. These results are summarized in numerous journal articles, conference papers, and preprints, with many more to be published during INCLINE&rsquo;s operational lifetime.</p>\n<p>INCLINE has facilitated the development of collaborations between universities in the Southern Colorado region. Many INCLINE users are from other local institutions, including the University of Colorado Denver and Colorado College. INCLINE has also provided support to researchers worldwide, and has served to support cyberinfrastructure projects such as OpenKIM (also NSF funded). Within UCCS, INCLINE has become a platform for instruction as well as research, providing support for students and faculty to familiarize themselves with the HPC environment and run large-scale simulations. It has supported courses and course development as well, with topics ranging from computational mechanics to deep learning.&nbsp;</p>\n<p>Despite initial delays due to the global chip shortage in 2021, INCLINE usage has been constantly accelerating. With several years remaining in its planned operational period, INCLINE will continue to facilitate advances in research and teaching, while laying the groundwork for future expansion of HPC resources in the region.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/19/2024<br>\nModified by: Brandon&nbsp;Runnels</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe acquisition of the INCLINE high performance computing (HPC) cluster, made possible through an NSF MRI grant, marks a significant addition of technological capability for the University of Colorado Colorado Springs. Like its namesake, the 2,768-step Manitou Incline trail that gains 2000 feet of elevation in less than a mile, the INCLINE HPC cluster represents a transformative elevation of computational research in the Southern Colorado research community. With 30 computational nodes, INCLINE is the first 100 teraflop (100 trillion calculations per second) instrument to be made available in the region.\n\n\nThis project has enabled more than 8 million CPU hours dedicated to a diverse range of projects led by faculty and graduate students. More than 90% of the clusters usage comes from bachelors, master, and doctoral students, engaged in research projects ranging from microstructure analysis in structural materials, computational combustion, and gasdynamics, to enzyme design and compiler hierarchy. These calculations have led to crucial advances in multiple funded projects, with sponsors including the National Science Foundation, Department of Defense, and Department of Energy. These include the development of novel high performance computational physics methods, as well as new models for solid rocket propellant. These results are summarized in numerous journal articles, conference papers, and preprints, with many more to be published during INCLINEs operational lifetime.\n\n\nINCLINE has facilitated the development of collaborations between universities in the Southern Colorado region. Many INCLINE users are from other local institutions, including the University of Colorado Denver and Colorado College. INCLINE has also provided support to researchers worldwide, and has served to support cyberinfrastructure projects such as OpenKIM (also NSF funded). Within UCCS, INCLINE has become a platform for instruction as well as research, providing support for students and faculty to familiarize themselves with the HPC environment and run large-scale simulations. It has supported courses and course development as well, with topics ranging from computational mechanics to deep learning.\n\n\nDespite initial delays due to the global chip shortage in 2021, INCLINE usage has been constantly accelerating. With several years remaining in its planned operational period, INCLINE will continue to facilitate advances in research and teaching, while laying the groundwork for future expansion of HPC resources in the region.\n\n\n\t\t\t\t\tLast Modified: 01/19/2024\n\n\t\t\t\t\tSubmitted by: BrandonRunnels\n"
 }
}