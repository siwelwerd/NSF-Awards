{
 "awd_id": "1951027",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: EAGER: Exploring beyond visualization: Data sonification of bacterial chemotaxis patterns",
 "cfda_num": "47.074",
 "org_code": "08070000",
 "po_phone": "7032927123",
 "po_email": "drockcli@nsf.gov",
 "po_sign_block_name": "David Rockcliffe",
 "awd_eff_date": "2020-01-15",
 "awd_exp_date": "2022-12-31",
 "tot_intn_awd_amt": 51472.0,
 "awd_amount": 51472.0,
 "awd_min_amd_letter_date": "2019-12-23",
 "awd_max_amd_letter_date": "2019-12-23",
 "awd_abstract_narration": "In this Era of Big Data an unprecedented amount of information is being collected at rates that are overwhelming researchers' capacity to process data in meaningful ways. Converting streams of numbers into graphical representations has proven to be useful over the past three decades to identify trends in complex data sets such as weather patterns, stock market fluctuations, and flu epidemics. While visualization is a powerful approach to data analysis, not all data are amenable to visualization. Sonification, the mapping of information to sound, is an alternative method for extracting useful information from visually chaotic data. One familiar example of data sonification is a Geiger counter that converts invisible gamma radiation to an audible frequency of clicks. This project demonstrates the utility of sonification in a study of how microbes swim toward nutrients that are critical for their survival. The goal is to promote more widespread use of sonification to analyze big data within the biological research community. Sonification of data can also increase public scientific literacy and public engagement with science and technology. As demonstrated by the catchy Higgs Boson tune, sonified data made the discovery of subatomic particles more accessible to the public. Sound and music are used in this project to provide a medium through which to engage elementary school-age children in a welcoming manner about the excitement of science. Another notable aspect is that data sonification provides a convenient platform to engage sight-impaired individuals in research. The project brings together expertise in biological systems engineering and digital music composition that provide diverse perspectives for cross-training student research assistants.\r\n\r\nIn this project sonification is used to detect changes in the swimming patterns of microorganisms upon exposure to a chemical stimulus (i.e. chemotaxis). When examining a population of swimming microbes through a microscope the movement appears chaotic, making subtle changes in the paths of individual organisms impossible to discern in real time. By mapping visual images to the frequency domain in real-time one can transform the chaotic visual motion to discernible differences in auditory sounds. The specific project objectives are to: (1) identify the features of bacterial swimming motion that are detected in sonified data; (2) optimize video microscopy settings and video filters to enhance the signal-to-noise ratio of the data collected; (3) sonify data in real time to allow simultaneous audio and visual input to an observer; (4) evaluate the robustness of data sonification algorithms for bacteria that have different swimming behaviors; and (5) screen microbes for chemotaxis beyond the training set to evaluate the success of the sonification process. One outcome of this work will be a platform to generate sonified data in real-time that is synchronous with visual observations to allow high-throughput screening of chemotactic responses for various species to different chemoeffectors over a range of concentrations. Another, and perhaps more impactful outcome, will be to significantly expand the tools that biological scientists have at their disposal to identify patterns in complex data that they collect.\r\n\r\nThis award is jointly funded by the Systems and Synthetic Biology Cluster and the Cellular and Dynamics Cluster in the Division of Molecular and Cellular Biology.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "BIO",
 "org_dir_long_name": "Directorate for Biological Sciences",
 "div_abbr": "MCB",
 "org_div_long_name": "Division of Molecular and Cellular Biosciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maxwell",
   "pi_last_name": "Tfirn",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Maxwell D Tfirn",
   "pi_email_addr": "maxwell.tfirn@cnu.edu",
   "nsf_id": "000802394",
   "pi_start_date": "2019-12-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Christopher Newport University",
  "inst_street_address": "1 AVENUE OF THE ARTS",
  "inst_street_address_2": "",
  "inst_city_name": "NEWPORT NEWS",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "7575947392",
  "inst_zip_code": "236063072",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "VA03",
  "org_lgl_bus_name": "CHRISTOPHER NEWPORT UNIVERSITY",
  "org_prnt_uei_num": "VMYDF2TZHHB6",
  "org_uei_num": "VMYDF2TZHHB6"
 },
 "perf_inst": {
  "perf_inst_name": "Christopher Newport University",
  "perf_str_addr": "1 Avenue of the Arts",
  "perf_city_name": "Newport News",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "236063072",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "VA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801100",
   "pgm_ele_name": "Systems and Synthetic Biology"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7465",
   "pgm_ref_txt": "NANOSCALE BIO CORE"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 51472.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">The outcomes of this research show that sonification can be used to hear the change of data over time in a way that our eyes cannot identify. In our experiments certain types of motion worked better than others,&nbsp;but the density of the sound and how it changed was distinct to non-musicians and people with untrained ears. When trying to track individual motion and hear a discernible difference in themotion of bacteria as a whole i.e. wave, was able to be heard very easily. General trends of motion moving along the y-axis were also very easily noticeable by the increase in pitch. As some bacteria moved around the middle while others moved up we were able to hear a difference in the pitch as well as the average frequency. These would normal just be seen as generally movement with our eyes and no pattern could necessarily be detected visually. The effectiveness of the sonifcication is tied into the resolution of the image data. Therefore by filtering out the glare and stuck bacteria, we are able to clean up the image enough to get reliable scanning without many audio artifacts. This shows that image or video data that may have patterns that we can not see with our eyes can show results after sonification. We additionally added some simple audio analysis tools as another layer of data understanding. Using these tools, patterns that we thought we could hear could be verified through audio analysis as well. After looking at the results it appears that sonification can serve as a tool in helping a person to understand something that visually does not make sense or finding a pattern in data that our eyes cannot identify. Throughout our study our sonification when tied into visual and computer analysis techniques gave another layer of data to help in understanding everything that was going on.&nbsp;Since the data is being turned into frequency in Hertz, it can be mapped to pitch to give a more musical interpretation of the data as well.&nbsp;</p>\n<p class=\"p1\">&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/06/2023<br>\n\t\t\t\t\tModified by: Maxwell&nbsp;D&nbsp;Tfirn</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675713886495_ScreenShot2023-02-06at3.03.47PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675713886495_ScreenShot2023-02-06at3.03.47PM--rgov-800width.jpg\" title=\"Software Image\"><img src=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675713886495_ScreenShot2023-02-06at3.03.47PM--rgov-66x44.jpg\" alt=\"Software Image\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Software written in Max/MSP the captures the microscope video and converts it into a sound spectrum.</div>\n<div class=\"imageCredit\">Maxwell Tfirn</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Maxwell&nbsp;D&nbsp;Tfirn</div>\n<div class=\"imageTitle\">Software Image</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675714135774_ScreenShot2023-02-06at3.06.28PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675714135774_ScreenShot2023-02-06at3.06.28PM--rgov-800width.jpg\" title=\"Bacteria Slide and Audio\"><img src=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675714135774_ScreenShot2023-02-06at3.06.28PM--rgov-66x44.jpg\" alt=\"Bacteria Slide and Audio\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A side by side Left a video from a microscope. Right the audio spectrum. (The frame rate is 26fps) The audio image is hundreds of audio frames side by side</div>\n<div class=\"imageCredit\">Maxwell Tfirn</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Maxwell&nbsp;D&nbsp;Tfirn</div>\n<div class=\"imageTitle\">Bacteria Slide and Audio</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675714374432_ScreenShot2023-02-06at3.11.11PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675714374432_ScreenShot2023-02-06at3.11.11PM--rgov-800width.jpg\" title=\"Audio Analysis Data\"><img src=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675714374432_ScreenShot2023-02-06at3.11.11PM--rgov-66x44.jpg\" alt=\"Audio Analysis Data\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The first 19 audio descriptors data from sonification</div>\n<div class=\"imageCredit\">Maxwell Tfirn</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Maxwell&nbsp;D&nbsp;Tfirn</div>\n<div class=\"imageTitle\">Audio Analysis Data</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675714597678_ScreenShot2023-02-06at3.15.39PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675714597678_ScreenShot2023-02-06at3.15.39PM--rgov-800width.jpg\" title=\"Sonification to Music Notation\"><img src=\"/por/images/Reports/POR/2023/1951027/1951027_10648200_1675714597678_ScreenShot2023-02-06at3.15.39PM--rgov-66x44.jpg\" alt=\"Sonification to Music Notation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The data being sonified gets converted to pitch and quantized into sheet music.</div>\n<div class=\"imageCredit\">Maxwell Tfirn</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Maxwell&nbsp;D&nbsp;Tfirn</div>\n<div class=\"imageTitle\">Sonification to Music Notation</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "The outcomes of this research show that sonification can be used to hear the change of data over time in a way that our eyes cannot identify. In our experiments certain types of motion worked better than others, but the density of the sound and how it changed was distinct to non-musicians and people with untrained ears. When trying to track individual motion and hear a discernible difference in themotion of bacteria as a whole i.e. wave, was able to be heard very easily. General trends of motion moving along the y-axis were also very easily noticeable by the increase in pitch. As some bacteria moved around the middle while others moved up we were able to hear a difference in the pitch as well as the average frequency. These would normal just be seen as generally movement with our eyes and no pattern could necessarily be detected visually. The effectiveness of the sonifcication is tied into the resolution of the image data. Therefore by filtering out the glare and stuck bacteria, we are able to clean up the image enough to get reliable scanning without many audio artifacts. This shows that image or video data that may have patterns that we can not see with our eyes can show results after sonification. We additionally added some simple audio analysis tools as another layer of data understanding. Using these tools, patterns that we thought we could hear could be verified through audio analysis as well. After looking at the results it appears that sonification can serve as a tool in helping a person to understand something that visually does not make sense or finding a pattern in data that our eyes cannot identify. Throughout our study our sonification when tied into visual and computer analysis techniques gave another layer of data to help in understanding everything that was going on. Since the data is being turned into frequency in Hertz, it can be mapped to pitch to give a more musical interpretation of the data as well. \n \n\n\t\t\t\t\tLast Modified: 02/06/2023\n\n\t\t\t\t\tSubmitted by: Maxwell D Tfirn"
 }
}