{
 "awd_id": "2003182",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MLWiNS: Resource Constrained Mobile Data Analytics Assisted by the Wireless Edge",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2020-06-24",
 "awd_max_amd_letter_date": "2020-06-24",
 "awd_abstract_narration": "Increasing amounts of data are being collected on mobile telephones and internet-of-things (IoT) devices. Users are interested in analyzing this data to extract actionable information, for example, identifying objects of interest from high-resolution mobile phone pictures. The state-of-the-art technique for such data analysis is via deep learning which makes use of sophisticated software algorithms modeled on the functioning of the human brain. Deep learning algorithms are, however, too complex to run on small, battery constrained mobile devices. The alternative, i.e., transmitting data to the mobile base station where the deep learning algorithm can be executed on a powerful server, consumes too much bandwidth. This project seeks to devise new methods to compress data before transmission, thus reducing bandwidth costs while still allowing for the data to be analyzed at the base station. Departing from existing data compression methods optimized for reproducing the original images, the project will use deep learning itself to compress the data in a fashion that only keeps the critical parts of data necessary for subsequent analysis. The resulting deep learning based compression algorithms will be simple enough to run on mobile devices while drastically reducing the amount of data that needs to be transmitted to mobile base stations for analysis, without significantly compromising the analysis performance. The proposed research will provide greater capability and functionality to mobile device users, enable extended battery lifetimes, and more efficient sharing of the wireless spectrum for analytics tasks. The project also envisions a multi-pronged effort aimed at outreach to communities of interest, educating and training the next generation of machine learning and wireless professionals at the K-12, undergraduate and graduate levels, and broadening participation of under-represented minority groups.\r\n\r\nThe project seeks to learn \u201canalytics-aware\u201d compression schemes from data by training low-complexity compressor deep neural networks (DNNs) that execute on mobile devices and achieve a range of transmission rate and analytics accuracy targets. As a first step, efficient DNN pruning techniques will be developed to minimize the DNN complexity, while maintaining the rate-accuracy efficiency for one or a collection of analytics tasks. Next, to efficiently adapt to varying wireless channel conditions, the project will seek to design adaptive DNN architectures that can operate at variable transmission rates and computational complexities. For instance, when the wireless channel quality drops, the proposed compression scheme will be able to quickly reduce transmission rate in response while ensuring the same analytics accuracy, but at the cost of greater computational power on the mobile device. Further, wireless channel allocation and scheduling policies that leverage the proposed adaptive DNN architectures will be developed to optimize the overall analytics accuracy at the server. The benefits of the proposed approach in terms of total battery life savings for the mobile device will be demonstrated using detailed simulation studies of various wireless protocols including those used for LTE (Long Term Evolution) and mmWave channels.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Siddharth",
   "pi_last_name": "Garg",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Siddharth Garg",
   "pi_email_addr": "sg175@nyu.edu",
   "nsf_id": "000680915",
   "pi_start_date": "2020-06-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yao",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yao Wang",
   "pi_email_addr": "yw523@nyu.edu",
   "nsf_id": "000467592",
   "pi_start_date": "2020-06-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Elza",
   "pi_last_name": "Erkip",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Elza Erkip",
   "pi_email_addr": "elza@nyu.edu",
   "nsf_id": "000488052",
   "pi_start_date": "2020-06-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "2 Metrotech Ctr, Floor 10, room",
  "perf_city_name": "Brooklyn",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "112013838",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "NY07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "021Z",
   "pgm_ref_txt": "Industry Partnerships"
  },
  {
   "pgm_ref_code": "8585",
   "pgm_ref_txt": "NSF/Intel Partnership Projects"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Modern machine learning solutions allow users to automatically perform complex tasks, for example, identify objects in an image, understand natural langauge text and others. These solutions rely on deep neural networks (DNN), which although very powerful, involve heavy computation and would therefore be unsuitable for a device like a mobile phone. An alternative is for a user to upload their images to the cloud where powerful computers can be used to run the deep network quickly and provide a response to the user. But this solution requires uploading large volumes of data to over a wireless network, potentially creating massive congestion on the network.&nbsp;</p>\r\n<p>In this project, we explored a different solution: compressing data before uploading to the cloud. This would reduce congestion on the wireless network, but existing image compression techniques like JPEG that we use daily are designed to compress images so as to preserve their visual appearance when decompressed. However, in the applications we described, for example, automatically detecting&nbsp; objects in an image, the cloud does not need to \"see\" an image in the traditional sense; we only care about how accurately objects in the image have been identified, or more generally, the image analysis task the user wants to perform. The key idea in this project was to design \"task-aware\" image (and other data) compression methods that are optimized not for visual quality but for the task at hand.&nbsp;</p>\r\n<p>In this project, we proposed to design new ``task aware\" image compression methods by leveraging recent progress in the field ``learned image compression\" where a deep neural network is trained to compress images. In our proposed solution, the small compressor DNN runs on the mobile device, compresses images to only retain features of the image relevant to the task at hand, transmitted to the cloud, where it is decompressed and finally passed through the complex task-specific DNN. Thus, the mobile device needs to perform only small amounts of computation, the available wireless bandwidth is used efficiently, and the heavy-duty computation happens on the cloud which has access to high-end processors. We have demonstrated the benefits of this approach for object detection and image classification tasks. We also studied \"scalable\" compression approaches which adapt to fluctuating wireless bandwidth by sending more or less data to the cloud; exploiting extra bandwidth to improve performance on the task, and scaling back when bandwidth is scarce.&nbsp;&nbsp;</p>\r\n<p>We have also investigated the use of task-aware compression methods to improve the efficiency of wireless networks themselves. Modern wireless communication is enabled by feedback from users to the basestation about the quality of the wireless channel, called the channel state information (CSI). This allows the basestation to best deliver data and bandwidth to each user. However, sending CSI itself consumes bandwidth. We have used learned task-aware compression to compress CSI to compress this data so as to maximize its utility to the basestation. We are able to demonstrate signifucant improvement in the overall bandwidth that a basestation is able to deliver to its users via this method. Finally, we have also performed more theoretical investigations of learned task-aware compression in abstract models of wireless networks, namely, for the \"relay\" channel, where a relay can assist in communications between a sender and receiver. We show that our proposed methods can recover the best known relay strategies, suggesting the broad applicability of the proposed methods.&nbsp; &nbsp;</p>\r\n<p>We have disseminated our results to communities of interest include academia and industry via publications, talks at conferences and other venues, and individual meetings. Undergraduate and graduate classes at the PIs' institutions have been enirched with new material on privacy risks in the digital age.&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/25/2024<br>\nModified by: Siddharth&nbsp;Garg</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nModern machine learning solutions allow users to automatically perform complex tasks, for example, identify objects in an image, understand natural langauge text and others. These solutions rely on deep neural networks (DNN), which although very powerful, involve heavy computation and would therefore be unsuitable for a device like a mobile phone. An alternative is for a user to upload their images to the cloud where powerful computers can be used to run the deep network quickly and provide a response to the user. But this solution requires uploading large volumes of data to over a wireless network, potentially creating massive congestion on the network.\r\n\n\nIn this project, we explored a different solution: compressing data before uploading to the cloud. This would reduce congestion on the wireless network, but existing image compression techniques like JPEG that we use daily are designed to compress images so as to preserve their visual appearance when decompressed. However, in the applications we described, for example, automatically detecting objects in an image, the cloud does not need to \"see\" an image in the traditional sense; we only care about how accurately objects in the image have been identified, or more generally, the image analysis task the user wants to perform. The key idea in this project was to design \"task-aware\" image (and other data) compression methods that are optimized not for visual quality but for the task at hand.\r\n\n\nIn this project, we proposed to design new ``task aware\" image compression methods by leveraging recent progress in the field ``learned image compression\" where a deep neural network is trained to compress images. In our proposed solution, the small compressor DNN runs on the mobile device, compresses images to only retain features of the image relevant to the task at hand, transmitted to the cloud, where it is decompressed and finally passed through the complex task-specific DNN. Thus, the mobile device needs to perform only small amounts of computation, the available wireless bandwidth is used efficiently, and the heavy-duty computation happens on the cloud which has access to high-end processors. We have demonstrated the benefits of this approach for object detection and image classification tasks. We also studied \"scalable\" compression approaches which adapt to fluctuating wireless bandwidth by sending more or less data to the cloud; exploiting extra bandwidth to improve performance on the task, and scaling back when bandwidth is scarce.\r\n\n\nWe have also investigated the use of task-aware compression methods to improve the efficiency of wireless networks themselves. Modern wireless communication is enabled by feedback from users to the basestation about the quality of the wireless channel, called the channel state information (CSI). This allows the basestation to best deliver data and bandwidth to each user. However, sending CSI itself consumes bandwidth. We have used learned task-aware compression to compress CSI to compress this data so as to maximize its utility to the basestation. We are able to demonstrate signifucant improvement in the overall bandwidth that a basestation is able to deliver to its users via this method. Finally, we have also performed more theoretical investigations of learned task-aware compression in abstract models of wireless networks, namely, for the \"relay\" channel, where a relay can assist in communications between a sender and receiver. We show that our proposed methods can recover the best known relay strategies, suggesting the broad applicability of the proposed methods. \r\n\n\nWe have disseminated our results to communities of interest include academia and industry via publications, talks at conferences and other venues, and individual meetings. Undergraduate and graduate classes at the PIs' institutions have been enirched with new material on privacy risks in the digital age.\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 11/25/2024\n\n\t\t\t\t\tSubmitted by: SiddharthGarg\n"
 }
}