{
 "awd_id": "2015057",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Real-time computer automated identification and quantification of insects entering the SolaRid insect control device (ICD)",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032920000",
 "po_email": "epiersto@nsf.gov",
 "po_sign_block_name": "Erik Pierstorff",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2022-04-30",
 "tot_intn_awd_amt": 224989.0,
 "awd_amount": 224989.0,
 "awd_min_amd_letter_date": "2020-06-25",
 "awd_max_amd_letter_date": "2020-06-25",
 "awd_abstract_narration": "The broader impact of this Small Business Innovation Research (SBIR) Phase I project is to streamline and optimize interventions for agricultural pest control with Artificial Intelligence (AI) strategies related to image processes.  The proposed project will develop an AI-driven, automated insect count and identification system. In addition to supporting the agricultural industry, the proposed system offers a research tool to study synergisms among attractants, learn more about insect behavior and migration over large land masses, and adapt to changing pest pressures. Furthermore, this system enables monitoring insects that could carry diseases in urban and rural communities as well as refugee camps. \r\n\r\nThe proposed project will advance the translation of an automated solution for pest control at scale.  The project will: 1) automate the quantification and identification of a broad diversity of insects; 2) capture the appropriate data for identification of insects and training the AI system; and 3) process data in real time onboard the device. This project will optimize the use of new circuit boards and firmware in an automated configuration that can ultimately send data to handheld devices.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Donald",
   "pi_last_name": "Richardson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Donald Richardson",
   "pi_email_addr": "drichardson@solaridipm.com",
   "nsf_id": "000816441",
   "pi_start_date": "2020-06-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SOLARID AR, LLC.",
  "inst_street_address": "267 FAYES FOREST RD",
  "inst_street_address_2": "",
  "inst_city_name": "CLINTON",
  "inst_state_code": "AR",
  "inst_state_name": "Arkansas",
  "inst_phone_num": "5015921391",
  "inst_zip_code": "720316012",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "AR02",
  "org_lgl_bus_name": "SOLARID AR LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "YA9SUGXDSN51"
 },
 "perf_inst": {
  "perf_inst_name": "SOLARID AR, LLC.",
  "perf_str_addr": "267 Fayes Forest Road",
  "perf_city_name": "Clinton",
  "perf_st_code": "AR",
  "perf_st_name": "Arkansas",
  "perf_zip_code": "720316012",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "AR02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8038",
   "pgm_ref_txt": "Biotechnology"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 224989.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Real-time Computer Automated Identification and Quantification of Insects Entering the SolaRid Insect Control Device - Outcomes Report</p>\n<p>&nbsp; &nbsp;&nbsp;Randy Sasaki, Drs. Ashley Dowling, and Khoa Luu, Donald Richardson</p>\n<p>Insect pests are a constant threat to agriculture worldwide, causing losses in the U.S. agricultural industry exceeding $45 billion, annually. Many pest species can reach damaging population levels quickly and often the plants do not show obvious symptoms until pest population levels are high. Early detection of initial infestations reduces crop losses and precise responses can significantly reduce the volume of insecticides applied, which reduces operating expenses and toxic chemicals entering our food supply. Detection of pests requires constant monitoring of fields, which requires the placement of traps, workers to continually monitor traps (often on a weekly basis), and accurate identification of the insects captured. This is a very labor-intensive process and requires a certain level of expertise to provide accurate and timely information to the farmer.&nbsp;</p>\n<p>The purpose of this NSF Phase I small business grant was to take an existing trap system developed by SolaRid AR LLC and develop a prototype for an artificial intelligence (AI)-driven automated pest insect identification system. This prototype can be attached to the trap, making it a smart trap that provides real-time information on pest identification and numbers to the farmer. The goal of Phase I was to focus on the hardware for the system but also to begin development of the algorithms for insect detection and identification.&nbsp; The system requires a sensor to detect when an insect enters the trap, cameras to image the flying insects with enough resolution to identify the insect and at speeds fast enough to effectively ?freeze action?, and a flash system to provide enough light to achieve the desired results. For the prototype, the sensor, machine-vision cameras, and lenses were off-the-shelf products used in manufacturing to monitor production lines. Since most characteristics needed for insect identification can be found on the top and sides of the insect body, one camera was placed focusing down onto entering insects and another was placed on the side. This provides two angles for every insect that enters the trap. The flash system was developed in-house as no existing product on the market met the light demands of the system. It surrounds the sensor and provides an array of LEDs located in the same orientation as the cameras. The entire system is controlled by an onboard computer processing unit that receives the signal from the sensor that an insect has broken the infrared, sensor plane and then within a fraction of a second, triggers the flashes and cameras. Eventually, the AI identification of the insect will also occur in this processing unit, eliminating the need to send images through the cloud and making the traps function even in areas with limited cellular networks.</p>\n<p>Much of the software development to produce a final functioning product was not a part of this Phase I project, however, progress was made in several areas. It became clear during early trials that obtaining crisp images of small, fast flying objects at night was going to require both hardware and computer science solutions to achieve our desired results. Our team developed algorithms that increase both brightness and resolution in the final images much like technology typically used for movies when the investigators transform grainy security footage into high-definition images. This advancement made by our team lessened the overall light needed in the system, making it more achievable to get enough light and lessening the overall cost of the system. Additionally, software was developed to control the sensor-camera-flash system so everything could be synchronized to fire when the insect was in the field of view and to allow the system to take a burst of images to capture the insect wings in different points of the&nbsp;wingbeat, thus preventing wing position from obscuring certain characters needed for identification. Lastly, software was developed so the computer could accurately find and extract insects in the images obtained, ignoring any non-insect noise that may be present. This allows the computer to exclusively examine the insect for identifiable features and provide an accurate count of the insects that enter the trap. Many of these developed software products will have use beyond this trap system.</p>\n<p>Overall, many advancements have been made toward production of a fully automated, AI-driven insect identification system that will revolutionize insect monitoring in agricultural systems. Our project has generated proprietary technologies, three published research papers, and multiple sustainable competitive advantages. We have filed provisional patents for algorithms and hardware developed. Prototypes are being field deployed to collect images for use in training the AI identification system, with the final goal of a marketable smart trap, designed for the $2.5 Trillion, global agriculture industry that is adaptable to different crop types around the world.&nbsp; &nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/14/2022<br>\n\t\t\t\t\tModified by: Donald&nbsp;Richardson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nReal-time Computer Automated Identification and Quantification of Insects Entering the SolaRid Insect Control Device - Outcomes Report\n\n    Randy Sasaki, Drs. Ashley Dowling, and Khoa Luu, Donald Richardson\n\nInsect pests are a constant threat to agriculture worldwide, causing losses in the U.S. agricultural industry exceeding $45 billion, annually. Many pest species can reach damaging population levels quickly and often the plants do not show obvious symptoms until pest population levels are high. Early detection of initial infestations reduces crop losses and precise responses can significantly reduce the volume of insecticides applied, which reduces operating expenses and toxic chemicals entering our food supply. Detection of pests requires constant monitoring of fields, which requires the placement of traps, workers to continually monitor traps (often on a weekly basis), and accurate identification of the insects captured. This is a very labor-intensive process and requires a certain level of expertise to provide accurate and timely information to the farmer. \n\nThe purpose of this NSF Phase I small business grant was to take an existing trap system developed by SolaRid AR LLC and develop a prototype for an artificial intelligence (AI)-driven automated pest insect identification system. This prototype can be attached to the trap, making it a smart trap that provides real-time information on pest identification and numbers to the farmer. The goal of Phase I was to focus on the hardware for the system but also to begin development of the algorithms for insect detection and identification.  The system requires a sensor to detect when an insect enters the trap, cameras to image the flying insects with enough resolution to identify the insect and at speeds fast enough to effectively ?freeze action?, and a flash system to provide enough light to achieve the desired results. For the prototype, the sensor, machine-vision cameras, and lenses were off-the-shelf products used in manufacturing to monitor production lines. Since most characteristics needed for insect identification can be found on the top and sides of the insect body, one camera was placed focusing down onto entering insects and another was placed on the side. This provides two angles for every insect that enters the trap. The flash system was developed in-house as no existing product on the market met the light demands of the system. It surrounds the sensor and provides an array of LEDs located in the same orientation as the cameras. The entire system is controlled by an onboard computer processing unit that receives the signal from the sensor that an insect has broken the infrared, sensor plane and then within a fraction of a second, triggers the flashes and cameras. Eventually, the AI identification of the insect will also occur in this processing unit, eliminating the need to send images through the cloud and making the traps function even in areas with limited cellular networks.\n\nMuch of the software development to produce a final functioning product was not a part of this Phase I project, however, progress was made in several areas. It became clear during early trials that obtaining crisp images of small, fast flying objects at night was going to require both hardware and computer science solutions to achieve our desired results. Our team developed algorithms that increase both brightness and resolution in the final images much like technology typically used for movies when the investigators transform grainy security footage into high-definition images. This advancement made by our team lessened the overall light needed in the system, making it more achievable to get enough light and lessening the overall cost of the system. Additionally, software was developed to control the sensor-camera-flash system so everything could be synchronized to fire when the insect was in the field of view and to allow the system to take a burst of images to capture the insect wings in different points of the wingbeat, thus preventing wing position from obscuring certain characters needed for identification. Lastly, software was developed so the computer could accurately find and extract insects in the images obtained, ignoring any non-insect noise that may be present. This allows the computer to exclusively examine the insect for identifiable features and provide an accurate count of the insects that enter the trap. Many of these developed software products will have use beyond this trap system.\n\nOverall, many advancements have been made toward production of a fully automated, AI-driven insect identification system that will revolutionize insect monitoring in agricultural systems. Our project has generated proprietary technologies, three published research papers, and multiple sustainable competitive advantages. We have filed provisional patents for algorithms and hardware developed. Prototypes are being field deployed to collect images for use in training the AI identification system, with the final goal of a marketable smart trap, designed for the $2.5 Trillion, global agriculture industry that is adaptable to different crop types around the world.   \n\n\t\t\t\t\tLast Modified: 06/14/2022\n\n\t\t\t\t\tSubmitted by: Donald Richardson"
 }
}