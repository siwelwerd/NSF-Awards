{
 "awd_id": "1953191",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Parallel Ensemble Learning and Feature Interaction Discovery: High Volume Dynamic Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 452016.0,
 "awd_amount": 452016.0,
 "awd_min_amd_letter_date": "2020-08-08",
 "awd_max_amd_letter_date": "2020-08-08",
 "awd_abstract_narration": "In the digital age, the advancement of technology has enabled data collection at an unprecedented pace including the collection of a variety of dynamic data over time. Such dynamic data potentially holds the key to unlock many mysteries in science, such as how genes interact with each other in the developments of Drosophila and Human alike. However, dynamic data is notoriously challenging to analyze due to its changing nature as well as its massive data size. The PI plans to enhance the modeling toolbox for dynamic data by designing scalable parallel algorithms that aim at both high prediction accuracy and high interpretability through decision-tree based methods. Their applications range across many fields including computational biology and precision medicine. During the course of the proposed research, graduate students will receive training in domain-driven data science and open-source software development. Further dissemination of the proposed research will be through an upcoming book, undergraduate- and graduate-level courses, and presentations at workshops and conferences.\r\n\r\nThe high-volume dynamic data poses challenges to the model training process because the underlying data distribution is varying with time. Algorithms or models have to adapt to the changing dynamic as well as their interpretations. Among statistics and machine learning methods, decision-tree based ensembles are especially favorable for dealing with a large volume of dynamic data because tree ensembles can capture flexible non-linear relationships in the data and are easily interpretable for people to extract useful narratives and information. PI\u2019s prior work, such as iterative Random Forests (iRF) and signed iterative Random Forests (siRF), identifies stable and high-order biomolecule interactions that explain its high predictive accuracy but it only focuses on cross-sectional data at a fixed time point. The proposed research will build on the iRF and siRF algorithms to develop enhanced Random Forest and iRF algorithms for modeling high-volume and dynamic data with interpretable high-order feature interactions. The PI will 1) develop a communication-efficient parallel RF training algorithm (pRF) that can efficiently take advantage of a large number of machines. 2) propose a novel method that discovers feature interactions in the dynamic data with the presence of concept drift: dynamic iterative Random Forests (diRF). 3) carry out a theoretical analysis of pRF and diRF algorithm under time-varying change-detection models where local stationarity conditions are satisfied.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bin",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bin Yu",
   "pi_email_addr": "binyu@stat.berkeley.edu",
   "nsf_id": "000465148",
   "pi_start_date": "2020-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "367 Evans Hall",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947203860",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "111200",
   "pgm_ele_name": "Genetic Mechanisms"
  },
  {
   "pgm_ele_code": "125300",
   "pgm_ele_name": "OFFICE OF MULTIDISCIPLINARY AC"
  },
  {
   "pgm_ele_code": "745400",
   "pgm_ele_name": "MSPA-INTERDISCIPLINARY"
  },
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  },
  {
   "pgm_ele_code": "808400",
   "pgm_ele_name": "CDS&E"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "068Z",
   "pgm_ref_txt": "URoL-Understanding Rules of Life"
  },
  {
   "pgm_ref_code": "7465",
   "pgm_ref_txt": "NANOSCALE BIO CORE"
  },
  {
   "pgm_ref_code": "8084",
   "pgm_ref_txt": "CDS&E"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 452016.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-65ed90f2-7fff-4ea8-b181-dd4b00feac59\"> </span></p>\n<p dir=\"ltr\"><span>The primary objective of this research proposal was to establish a stronger connection between the practical application and theoretical underpinnings of random forests and ensemble methods. In essence, the core aims encompassed enhancing the understanding, interpretability, and predictive capabilities of these techniques through both theoretical explorations and the development of novel methodologies. Furthermore, a notable emphasis was placed on devising computationally efficient algorithms while ensuring the development of high-quality and publicly available software.</span></p>\n<p dir=\"ltr\"><span>The outcomes of this proposal include establishing new theoretical results for Random Forests (RFs) and other tree-based methods </span><span>and developing novel methods to interpret these approaches and improve their predictive accuracy. For example, the PI studied feature selection consistency theory based on stability-driven RFs, obtaining new results on how a theoretically tractable version of iterative Random Forest (iRF) can discover boolean interactions, under a new Locally Spiky Sparse (LSS) model. The LSS model is inspired by thresholding behavior that appears in biological processes, for example, gene regulatory networks, while iRF is an approach proposed by the PI that uses a tree ensemble from iteratively modified RFs to obtain stable non-linear or boolean interactions of features.&nbsp;</span></p>\n<p dir=\"ltr\"><span>The general methodology of RFs was improved via hierarchical shrinkage (HS) and fast interpretable tree sums (FIGS). The former mitigates overfitting when building tree-based models through regularization by shrinking the prediction over each node towards the sample means of its ancestors. The latter mitigates the inefficiency of tree-based models for additive generative models by simultaneously growing trees in a summation with complexity control on the total number of trees. FIGS is particularly well suited for deriving clinical decision instruments, where it </span><span>achieves state-of-the-art performance, and, importantly, the resulting rules match medical domain expertise.&nbsp;</span></p>\n<p dir=\"ltr\"><span>MDI+, a flexible Random Forest-based feature importance framework, was proposed by the PI. MDI+ generalizes the mean decrease in impurity (MDI), by showing that the MDI can be closely tied to the r-squared value from linear regression on a particular set of engineered features. MDI+ allows the analyst to (1) replace the linear regression model and/or r-squared metric with more flexible models and metrics better suited for the given data structure and (2) incorporate additional features or knowledge to mitigate known biases of decision trees. MDI+ significantly outperforms popular feature importance measures in ranking and identifying relevant features across a wide range of simulated settings and in two real-world case studies: drug response prediction and breast cancer subtype prediction.</span></p>\n<p dir=\"ltr\"><span>Furthermore, the PI has theoretically studied the computational aspects of the Bayesian Additive Regression Trees (BART) algorithm. BART is an important statistical algorithm widely used in causal inference problems. BART relies on an MCMC sampler to obtain samples from the posterior of a Bayesian model defined on the space of sums of decision tree functions. The PI obtained a lower bound of the mixing time for a simplified version of BART, which grows exponentially with the number of data points.</span></p>\n<p dir=\"ltr\"><span>In addition, The PI studied panel data analysis, which is a growing literature, especially in economics and other social science fields, with several distinct approaches. The PI's work clarifies previous conceptions on how these approaches are connected by demonstrating that these approaches may yield the same point estimate but differ in their uncertainty estimates. As such, the PI argues that the current practice, which primarily only considers one of these approaches, should not necessarily be the default path taken but rather the researcher ought to apply their domain knowledge to ascertain the most suitable path.&nbsp;</span></p>\n<p dir=\"ltr\"><span>This project has created chances for numerous students and postdoctoral scholars from diverse backgrounds. These opportunities encompassed technical aspects such as the creation of top-notch software packages, alongside guidance and mentorship. In terms of its influence on education, the principal investigator (PI) is playing an active role in extending the curriculum of UC Berkeley's Data Science Education Program (DSEP) to include case studies building on her book 'Veridical Data Science' with h<span id=\"docs-internal-guid-d0ca9793-7fff-e762-94ee-3bab159c2358\"><span>er former graduate student and now a professor at The University of Utah, Rebecca Barter</span></span>. Some of the instances of high-dimensional analysis presented in her book drew inspiration from the accomplishments of this project.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/07/2023<br>\n\t\t\t\t\tModified by: Bin&nbsp;Yu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThe primary objective of this research proposal was to establish a stronger connection between the practical application and theoretical underpinnings of random forests and ensemble methods. In essence, the core aims encompassed enhancing the understanding, interpretability, and predictive capabilities of these techniques through both theoretical explorations and the development of novel methodologies. Furthermore, a notable emphasis was placed on devising computationally efficient algorithms while ensuring the development of high-quality and publicly available software.\nThe outcomes of this proposal include establishing new theoretical results for Random Forests (RFs) and other tree-based methods and developing novel methods to interpret these approaches and improve their predictive accuracy. For example, the PI studied feature selection consistency theory based on stability-driven RFs, obtaining new results on how a theoretically tractable version of iterative Random Forest (iRF) can discover boolean interactions, under a new Locally Spiky Sparse (LSS) model. The LSS model is inspired by thresholding behavior that appears in biological processes, for example, gene regulatory networks, while iRF is an approach proposed by the PI that uses a tree ensemble from iteratively modified RFs to obtain stable non-linear or boolean interactions of features. \nThe general methodology of RFs was improved via hierarchical shrinkage (HS) and fast interpretable tree sums (FIGS). The former mitigates overfitting when building tree-based models through regularization by shrinking the prediction over each node towards the sample means of its ancestors. The latter mitigates the inefficiency of tree-based models for additive generative models by simultaneously growing trees in a summation with complexity control on the total number of trees. FIGS is particularly well suited for deriving clinical decision instruments, where it achieves state-of-the-art performance, and, importantly, the resulting rules match medical domain expertise. \nMDI+, a flexible Random Forest-based feature importance framework, was proposed by the PI. MDI+ generalizes the mean decrease in impurity (MDI), by showing that the MDI can be closely tied to the r-squared value from linear regression on a particular set of engineered features. MDI+ allows the analyst to (1) replace the linear regression model and/or r-squared metric with more flexible models and metrics better suited for the given data structure and (2) incorporate additional features or knowledge to mitigate known biases of decision trees. MDI+ significantly outperforms popular feature importance measures in ranking and identifying relevant features across a wide range of simulated settings and in two real-world case studies: drug response prediction and breast cancer subtype prediction.\nFurthermore, the PI has theoretically studied the computational aspects of the Bayesian Additive Regression Trees (BART) algorithm. BART is an important statistical algorithm widely used in causal inference problems. BART relies on an MCMC sampler to obtain samples from the posterior of a Bayesian model defined on the space of sums of decision tree functions. The PI obtained a lower bound of the mixing time for a simplified version of BART, which grows exponentially with the number of data points.\nIn addition, The PI studied panel data analysis, which is a growing literature, especially in economics and other social science fields, with several distinct approaches. The PI's work clarifies previous conceptions on how these approaches are connected by demonstrating that these approaches may yield the same point estimate but differ in their uncertainty estimates. As such, the PI argues that the current practice, which primarily only considers one of these approaches, should not necessarily be the default path taken but rather the researcher ought to apply their domain knowledge to ascertain the most suitable path. \nThis project has created chances for numerous students and postdoctoral scholars from diverse backgrounds. These opportunities encompassed technical aspects such as the creation of top-notch software packages, alongside guidance and mentorship. In terms of its influence on education, the principal investigator (PI) is playing an active role in extending the curriculum of UC Berkeley's Data Science Education Program (DSEP) to include case studies building on her book 'Veridical Data Science' with her former graduate student and now a professor at The University of Utah, Rebecca Barter. Some of the instances of high-dimensional analysis presented in her book drew inspiration from the accomplishments of this project.\n\n\t\t\t\t\tLast Modified: 09/07/2023\n\n\t\t\t\t\tSubmitted by: Bin Yu"
 }
}