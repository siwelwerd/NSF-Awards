{
 "awd_id": "2002821",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: MLWiNS: A Coding-Centric Approach to Robust, Secure, and Private Distributed Learning over Wireless",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2020-06-01",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 66668.0,
 "awd_amount": 66668.0,
 "awd_min_amd_letter_date": "2020-05-19",
 "awd_max_amd_letter_date": "2020-05-19",
 "awd_abstract_narration": "Human and industrial automation, powered by machine learning (ML) such as Deep Neural Networks (DNNs) and the burgeoning ecosystem of billions of edge computing devices with sensors connected through the infrastructure of the internet (i.e., Internet of Things, or IoT) is shaping the future of our society. Federated learning (also known as, collaborative learning) techniques work across multiple decentralized edge devices and/or servers holding local data samples and facilitate training of the algorithms by exchanging parameters (i.e., weights associated with deep networks) instead of the actual data samples. Federated learning over wireless networks is challenging because of data loss associated with the communication characteristics. The goal of this project is to provide their critically needed augmented intelligence by enabling federated learning at the wireless edge, via an innovative framework, named coded computing. The societal impact of democratizing machine learning on low cost edge devices is also expected to be vast. For instance, smart edge networks that track safety automatically and continuously in workplaces can have a significant societal and economic impact. This project paves the path towards scalable realization of such applications. \r\n\r\nCoded computing has been hugely successful for large-scale distributed machine learning, where one can judiciously create computational redundancy in a coded manner to efficiently deal with communication bottleneck and system disturbances such as stragglers, outages, node failures, and adversarial computations -- precisely the set of challenges that hobble distributed wireless edge computations for machine learning. This project leads to the development of theory and algorithms for federated machine learning over wireless that are driven by fundamental principles informed by coding and information theory. In particular, this project holistically addresses the challenges of (i) wireless bandwidth costs, (ii) resiliency to wireless outages, (iii) security, and (iv) prioritizing user data privacy that is critical for large-scale user participation in wireless edge computing. Another key aspect of wireless networks is that mobile users join and leave the network arbitrarily, and user locations can change frequently. The research team will develop a federated learning framework that can adapt to such dynamic network topologies by designing a self-configurable protocol that can accommodate new users on-the-go, thereby adapting to the changes in the network topology.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kannan",
   "pi_last_name": "Ramchandran",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kannan Ramchandran",
   "pi_email_addr": "kannanr@eecs.berkeley.edu",
   "nsf_id": "000173259",
   "pi_start_date": "2020-05-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "269 Cory Hall",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947201770",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "021Z",
   "pgm_ref_txt": "Industry Partnerships"
  },
  {
   "pgm_ref_code": "8585",
   "pgm_ref_txt": "NSF/Intel Partnership Projects"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 66668.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project aimed to leverage foundational principles from coding theory and information theory to address critical challenges in distributed machine learning (ML), particularly within the context of federated learning (FL) deployed over wireless networks. The overarching goal was to develop novel, efficient, and theoretically grounded algorithms to overcome bottlenecks related to security against adversarial behavior, user data privacy, statistical heterogeneity across distributed clients, fair valuation of contributions, and overall system robustness. Over its duration, the project successfully delivered significant contributions across these key areas.</span><br /><br /><span>A primary focus was tackling the dual challenges of privacy and robustness in the FL aggregation process. Standard FL involves users sending model updates (gradients) to a central server, making the process vulnerable. Malicious (Byzantine) users can send corrupted updates to poison the global model, while honest users risk revealing sensitive information inferred from their raw gradient updates. To combat this, we pioneered the use of coding-theoretic constructs. We introduced FastShare, a novel multi-secret sharing scheme based on the Fast Fourier Transform (FFT). FastShare provides information-theoretic security guarantees, ensuring that colluding parties up to a certain threshold learn nothing about individual user inputs, while simultaneously offering resilience to user dropouts. Building upon this, we developed FastSecAgg, a state-of-the-art secure aggregation protocol. FastSecAgg integrates FastShare to allow the central server to compute the sum of user updates without accessing any individual update, thus preserving privacy. Its coding structure inherently provides robustness against Byzantine users; corrupted inputs can often be detected or their impact mitigated during the decoding process. Furthermore, we developed FastSecDist for privacy-preserving computation of Euclidean distances, crucial for algorithms like k-means or k-NN in a distributed, private manner. These contributions provided highly efficient (leveraging FFT's speed) and provably secure methods for fundamental operations in distributed ML, directly addressing project goals for secure, privacy-preserving, and robust aggregation schemes.</span><br /><br /><span>Another major challenge addressed was the statistical heterogeneity inherent in real-world FL scenarios. Users often possess data drawn from different underlying distributions (non-IID data), making a single global model suboptimal for many participants. To address this, we developed novel strategies for federated clustering. Our core contribution here is the Iterative Federated Clustering Algorithm (IFCA). IFCA elegantly handles heterogeneity by assuming users belong to one of several underlying clusters, each representing a different data distribution or task objective. The algorithm iteratively alternates between two steps: 1) assigning each user to their most likely cluster based on current cluster-specific models, and 2) optimizing the model parameters for each cluster using aggregated gradient information only from users currently assigned to that cluster. This allows the system to learn multiple personalized models tailored to distinct user groups within the federated network. We further extended this framework to develop Unsupervised IFCA (UIFCA), which employs generative models to handle more complex scenarios where data within a single client might even originate from multiple underlying distributions or clusters.</span><br /><br /><span>Complementing the work on heterogeneity and privacy, we investigated the fundamental problem of fairness in federated learning. As users contribute data and computational resources, ensuring fair compensation or recognition is crucial for participation incentives. This is complicated by heterogeneity in data quantity, quality, and, importantly, user-specific privacy requirements. Users demanding higher privacy levels might need to add more noise to their updates, potentially reducing their apparent contribution under naive metrics. We addressed this by developing a rigorous axiomatic framework for defining the fair value of private data. Instead of proposing a single ad-hoc fairness metric, we established desirable properties (axioms) that any reasonable fairness measure should satisfy in the context of FL with heterogeneous privacy constraints. This provides a crucial tool for researchers and practitioners seeking to design FL systems that are not only effective under complex, real-world constraints.</span><br /><br /><span>Finally, insights gained from the fairness research highlighted the difficulty in attributing value without deeply understanding the importance of different data components. This motivated a more recent line of inquiry in the final project phase, focusing on identifying interactions between data features. This is particularly relevant in vertical FL settings where different features reside at different locations (e.g., different sensors in a wireless network). Our key achievement here was the development of the Sparse M&ouml;bius Transform (SMT), an efficient algorithm derived from a novel connection established between feature interaction identification, the combinatorial M&ouml;bius transform, and classical group testing from coding theory. SMT provides a scalable method to pinpoint significant interactions, offering a valuable tool for model interpretability.</span><br /><br /><span>In conclusion, this project successfully advanced the state-of-the-art in distributed machine learning by developing and analyzing novel algorithms grounded in coding and information theory. We delivered solutions enhancing security (FastSecAgg), privacy (FastShare, FastSecAgg), robustness to heterogeneity (IFCA, UIFCA), fairness under privacy constraints, and model interpretability (SMT). These contributions provide essential tools for building more reliable, efficient, understandable federated learning systems for deployment in diverse application domains.</span></p><br>\n<p>\n Last Modified: 04/15/2025<br>\nModified by: Kannan&nbsp;Ramchandran</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/2002821/2002821_10671647_1744757493495_Screenshot_2025_04_15_at_1.49.04__8239_PM--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2002821/2002821_10671647_1744757493495_Screenshot_2025_04_15_at_1.49.04__8239_PM--rgov-800width.png\" title=\"Overview of IFCA\"><img src=\"/por/images/Reports/POR/2025/2002821/2002821_10671647_1744757493495_Screenshot_2025_04_15_at_1.49.04__8239_PM--rgov-66x44.png\" alt=\"Overview of IFCA\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 1</div>\n<div class=\"imageCredit\">UC Berkeley</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Kannan&nbsp;Ramchandran\n<div class=\"imageTitle\">Overview of IFCA</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2002821/2002821_10671647_1744757633280_Screenshot_2025_04_15_at_1.49.46__8239_PM--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2002821/2002821_10671647_1744757633280_Screenshot_2025_04_15_at_1.49.46__8239_PM--rgov-800width.png\" title=\"Packing design for FastSecAgg\"><img src=\"/por/images/Reports/POR/2025/2002821/2002821_10671647_1744757633280_Screenshot_2025_04_15_at_1.49.46__8239_PM--rgov-66x44.png\" alt=\"Packing design for FastSecAgg\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 2</div>\n<div class=\"imageCredit\">UC Berkeley</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Kannan&nbsp;Ramchandran\n<div class=\"imageTitle\">Packing design for FastSecAgg</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project aimed to leverage foundational principles from coding theory and information theory to address critical challenges in distributed machine learning (ML), particularly within the context of federated learning (FL) deployed over wireless networks. The overarching goal was to develop novel, efficient, and theoretically grounded algorithms to overcome bottlenecks related to security against adversarial behavior, user data privacy, statistical heterogeneity across distributed clients, fair valuation of contributions, and overall system robustness. Over its duration, the project successfully delivered significant contributions across these key areas.\n\nA primary focus was tackling the dual challenges of privacy and robustness in the FL aggregation process. Standard FL involves users sending model updates (gradients) to a central server, making the process vulnerable. Malicious (Byzantine) users can send corrupted updates to poison the global model, while honest users risk revealing sensitive information inferred from their raw gradient updates. To combat this, we pioneered the use of coding-theoretic constructs. We introduced FastShare, a novel multi-secret sharing scheme based on the Fast Fourier Transform (FFT). FastShare provides information-theoretic security guarantees, ensuring that colluding parties up to a certain threshold learn nothing about individual user inputs, while simultaneously offering resilience to user dropouts. Building upon this, we developed FastSecAgg, a state-of-the-art secure aggregation protocol. FastSecAgg integrates FastShare to allow the central server to compute the sum of user updates without accessing any individual update, thus preserving privacy. Its coding structure inherently provides robustness against Byzantine users; corrupted inputs can often be detected or their impact mitigated during the decoding process. Furthermore, we developed FastSecDist for privacy-preserving computation of Euclidean distances, crucial for algorithms like k-means or k-NN in a distributed, private manner. These contributions provided highly efficient (leveraging FFT's speed) and provably secure methods for fundamental operations in distributed ML, directly addressing project goals for secure, privacy-preserving, and robust aggregation schemes.\n\nAnother major challenge addressed was the statistical heterogeneity inherent in real-world FL scenarios. Users often possess data drawn from different underlying distributions (non-IID data), making a single global model suboptimal for many participants. To address this, we developed novel strategies for federated clustering. Our core contribution here is the Iterative Federated Clustering Algorithm (IFCA). IFCA elegantly handles heterogeneity by assuming users belong to one of several underlying clusters, each representing a different data distribution or task objective. The algorithm iteratively alternates between two steps: 1) assigning each user to their most likely cluster based on current cluster-specific models, and 2) optimizing the model parameters for each cluster using aggregated gradient information only from users currently assigned to that cluster. This allows the system to learn multiple personalized models tailored to distinct user groups within the federated network. We further extended this framework to develop Unsupervised IFCA (UIFCA), which employs generative models to handle more complex scenarios where data within a single client might even originate from multiple underlying distributions or clusters.\n\nComplementing the work on heterogeneity and privacy, we investigated the fundamental problem of fairness in federated learning. As users contribute data and computational resources, ensuring fair compensation or recognition is crucial for participation incentives. This is complicated by heterogeneity in data quantity, quality, and, importantly, user-specific privacy requirements. Users demanding higher privacy levels might need to add more noise to their updates, potentially reducing their apparent contribution under naive metrics. We addressed this by developing a rigorous axiomatic framework for defining the fair value of private data. Instead of proposing a single ad-hoc fairness metric, we established desirable properties (axioms) that any reasonable fairness measure should satisfy in the context of FL with heterogeneous privacy constraints. This provides a crucial tool for researchers and practitioners seeking to design FL systems that are not only effective under complex, real-world constraints.\n\nFinally, insights gained from the fairness research highlighted the difficulty in attributing value without deeply understanding the importance of different data components. This motivated a more recent line of inquiry in the final project phase, focusing on identifying interactions between data features. This is particularly relevant in vertical FL settings where different features reside at different locations (e.g., different sensors in a wireless network). Our key achievement here was the development of the Sparse Mbius Transform (SMT), an efficient algorithm derived from a novel connection established between feature interaction identification, the combinatorial Mbius transform, and classical group testing from coding theory. SMT provides a scalable method to pinpoint significant interactions, offering a valuable tool for model interpretability.\n\nIn conclusion, this project successfully advanced the state-of-the-art in distributed machine learning by developing and analyzing novel algorithms grounded in coding and information theory. We delivered solutions enhancing security (FastSecAgg), privacy (FastShare, FastSecAgg), robustness to heterogeneity (IFCA, UIFCA), fairness under privacy constraints, and model interpretability (SMT). These contributions provide essential tools for building more reliable, efficient, understandable federated learning systems for deployment in diverse application domains.\t\t\t\t\tLast Modified: 04/15/2025\n\n\t\t\t\t\tSubmitted by: KannanRamchandran\n"
 }
}