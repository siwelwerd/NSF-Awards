{
 "awd_id": "1955532",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: RI: Medium: A Rigorous, General Framework for Tractable Learning of Large-Scale DAGs from Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2020-06-15",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 799933.0,
 "awd_amount": 799933.0,
 "awd_min_amd_letter_date": "2020-06-10",
 "awd_max_amd_letter_date": "2022-05-23",
 "awd_abstract_narration": "Recent advances in machine learning and artificial intelligence owe much of their success to the development of algorithms that learn complicated relationships and understanding complex phenomena from massive datasets. These algorithms have been successfully applied on a diverse array of applications, including medicine, genetics, robotics, marketing, finance, and, increasingly, in societal applications. Despite their many successes, however, these applications continue to suffer from security, transparency, fairness, and interpretability problems. Many of these practical challenges can be traced back to well-known limitations with respect to interpretability, causality, and false discoveries. At the same time, substantial progress has been made in recent years in our understanding of these practical challenges in relatively simple settings with only a few factors and comparatively simple models. This research seeks to integrate these efforts, in order to provide a flexible framework for flexible, interpretable, causal modeling from high-dimensional, complex datasets. The investigated approach specifically seeks to avoid spurious correlations that commonly appear in complex datasets, while retaining the flexibility of modern machine learning algorithms with an eye towards applications in medicine, biology, and finance.\r\n\r\nWhile many applications of machine learning have been driven by impressive advances in complex predictive models, at the same time a need has emerged for models that can extract causal information from massive, unlabeled datasets. Graphical models provide a principled and effective way to uncover this type knowledge from unlabeled data. Although the problem of learning undirected graphs has witnessed a series of remarkable advances over the past decade, directed acyclic graphs (DAGs) that encode directed, potentially causal information, have not benefited from these advances. As a result, there is a pressing need for novel and theoretically sound methods for learning DAGs that can capture complex, asymmetric relationships, reduce model complexity, and most importantly, learn causal relationships for human decision-makers and stakeholders. This project explores a new approach for learning DAGs from data that provides the basis for a general statistical and computational framework, which has been lacking thus far. The technical aims can be divided along three major axes: 1) Developing novel continuous relaxations of the combinatorial optimization problems that arise in structure learning problems, 2) Developing new tools for analyzing the behavior of optimization schemes in highly nonconvex settings, and 3) Theoretical advances in nonparametric causal modeling and its statistical properties.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Pradeep",
   "pi_last_name": "Ravikumar",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Pradeep K Ravikumar",
   "pi_email_addr": "pradeepr@cs.cmu.edu",
   "nsf_id": "000553653",
   "pi_start_date": "2020-06-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Xing",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Eric P Xing",
   "pi_email_addr": "epxing@cs.cmu.edu",
   "nsf_id": "000195787",
   "pi_start_date": "2020-06-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 751365.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 45520.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 3048.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Statistically, we advanced the field in several directions. We developed a detailed nonparametric theory for learning graphical models as well as the first minimax theory for causal models, which allowed us to characterize optimal algorithms for learning causal graphs. This led directly to a new method for variable selection in causal models and showed that it provably improves over state-of-the-art approaches such as the Lasso and subset selection. This is an important subroutine that every causal learning method must implement, and thus has broad implications for the field.</p>\n<p>Finally, on the software front, we delivered two main advances: A detailed comparison of existing methods, involving more than 2M experiments with 11 different methods on more than 60000 datasets, and the release of a new Python library for learning causal models. This library contains implementations of all the algorithms produced over the course of this project, implemented as a general-purpose framework in Torch.</p>\n<p>Overall, the developments from this project have significantly advanced both the foundations and practice of learning of causal models with strong guarantees, which is essential given the growing adoption of ML and AI tools in high-stakes settings such as healthcare and law and broader consumer-facing settings where causality is essential.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 09/29/2024<br>\nModified by: Pradeep&nbsp;K&nbsp;Ravikumar</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nStatistically, we advanced the field in several directions. We developed a detailed nonparametric theory for learning graphical models as well as the first minimax theory for causal models, which allowed us to characterize optimal algorithms for learning causal graphs. This led directly to a new method for variable selection in causal models and showed that it provably improves over state-of-the-art approaches such as the Lasso and subset selection. This is an important subroutine that every causal learning method must implement, and thus has broad implications for the field.\n\n\nFinally, on the software front, we delivered two main advances: A detailed comparison of existing methods, involving more than 2M experiments with 11 different methods on more than 60000 datasets, and the release of a new Python library for learning causal models. This library contains implementations of all the algorithms produced over the course of this project, implemented as a general-purpose framework in Torch.\n\n\nOverall, the developments from this project have significantly advanced both the foundations and practice of learning of causal models with strong guarantees, which is essential given the growing adoption of ML and AI tools in high-stakes settings such as healthcare and law and broader consumer-facing settings where causality is essential.\n\n\n\t\t\t\t\tLast Modified: 09/29/2024\n\n\t\t\t\t\tSubmitted by: PradeepKRavikumar\n"
 }
}