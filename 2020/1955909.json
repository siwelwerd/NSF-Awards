{
 "awd_id": "1955909",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: SHF: Medium: TensorNN: An Algorithm and Hardware Co-design Framework for On-device Deep Neural Network Learning using Low-rank Tensors",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2020-04-29",
 "awd_max_amd_letter_date": "2022-08-25",
 "awd_abstract_narration": "Deep neural network (DNN) is an important Artificial Intelligence (AI) technique and it has recently gained widespread applications in numerous fields such as image recognition, machine translation, autonomous vehicles and healthcare diagnosis. Conventional DNNs are implemented using cloud computing, where a large amount of computing resource is available in a centrally-pooled manner. In order to achieve stronger data privacy, less response time and relaxed data transmission burden, deploying DNN functionality in a distributed manner at the edges of the network has become a very attractive proposition. However, DNN-learning on mobile devices that are at the edge of the network is very challenging due to conflicting requirements of large time and energy consumption, and limited on-device resources. In order to address this challenge, this project leverages low-rank tensors as a powerful mathematical tool for representing and compressing tensor-format data, to form a new family of ultra-low cost deep neural networks. This brings an order-of-magnitude reduction in time and energy consumption for deep neural network learning. Investigations in many areas of BigData research will benefit as well. This project involves graduate and undergraduate students, especially from underrepresented groups, through summer research experiences, and senior design projects to broaden the participation of computing. The outcomes of this project will be disseminated to the community in the format of technical publications, talks and tutorials in both academic institutions and industry.\r\n\r\nIn order to remove the barriers of realizing real-time energy-efficient DNN-learning on the resource and energy-constrained embedded devices, this project considers innovations at three levels: 1) at theory level, it develops a novel redundancy-free matrix-vector multiplication scheme to reduce computational cost, including a new online update scheme for low-rank tensors to enable fast compressed data update; 2) at algorithm level, it develops low-rank tensor-based forward and backward propagation schemes to support low-cost accelerated inference and training, including catastrophic forgetting-resilient training scheme and training-aware compression scheme to improve the learning robustness and memory efficiency; and 3) at hardware design level, it proposes efficient hardware architecture that fully utilize the benefits provided by low-rank tensors to achieve improved hardware performance for on-device DNN inference and learning. Finally, the efficacy of the proposed research will be validated and evaluated, via software implementations on different DNN models in different target applications. A field-programmable gate array (FPGA)-based hardware prototype will also be developed.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bo",
   "pi_last_name": "Yuan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bo Yuan",
   "pi_email_addr": "bo.yuan@soe.rutgers.edu",
   "nsf_id": "000704451",
   "pi_start_date": "2020-04-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "94 Brett Rd.",
  "perf_city_name": "Piscataway Township",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088543925",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 262975.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 137025.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This award has brought the research outcomes on both algorithm and hardware sides. On the algorithm side, new low-cost deep neural network compression methods and the corresponding inference and training solutions are developed. These developed approaches enables much lower memory cost and computation burden than before, making the deployment and use of costly AI models more affordable. On the hardware side, new customized AI hardware accelerator, which fully leverage the algorithmic benefits and also inherently reduces the&nbsp; unexplored architectural challenge, is developed and implemented, maximizing hardware performance, in terms of energy efficiency, throughput, area efficiency. This algorithm and hardware co-design co-optimization framework enables very significant improvement on the execution efficiency of modern AI models across various types of computing platforms, especially on the inexpensive embedded devices, thereby promoting the widesparead deployment of powerful AI techniques in a more effcienct, democratic, affordable and sustainable way. This award also promotes the STEM education and workforce in the United States. Several graduate students are supported and trained by this award. The research outcomes of this project are published and disseminated in several top AI and hardware conferences and journals, further attracting more US students to participate in the AI and semiconductor research activities.&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/12/2025<br>\nModified by: Bo&nbsp;Yuan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis award has brought the research outcomes on both algorithm and hardware sides. On the algorithm side, new low-cost deep neural network compression methods and the corresponding inference and training solutions are developed. These developed approaches enables much lower memory cost and computation burden than before, making the deployment and use of costly AI models more affordable. On the hardware side, new customized AI hardware accelerator, which fully leverage the algorithmic benefits and also inherently reduces the unexplored architectural challenge, is developed and implemented, maximizing hardware performance, in terms of energy efficiency, throughput, area efficiency. This algorithm and hardware co-design co-optimization framework enables very significant improvement on the execution efficiency of modern AI models across various types of computing platforms, especially on the inexpensive embedded devices, thereby promoting the widesparead deployment of powerful AI techniques in a more effcienct, democratic, affordable and sustainable way. This award also promotes the STEM education and workforce in the United States. Several graduate students are supported and trained by this award. The research outcomes of this project are published and disseminated in several top AI and hardware conferences and journals, further attracting more US students to participate in the AI and semiconductor research activities.\r\n\n\n\t\t\t\t\tLast Modified: 01/12/2025\n\n\t\t\t\t\tSubmitted by: BoYuan\n"
 }
}