{
 "awd_id": "1952353",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "PreCheck: Understanding Press Release Exaggeration (PRE) of Scientific Research",
 "cfda_num": "47.075",
 "org_code": "04010000",
 "po_phone": "7032925150",
 "po_email": "tswoodso@nsf.gov",
 "po_sign_block_name": "Thomas S. Woodson",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 375000.0,
 "awd_amount": 375000.0,
 "awd_min_amd_letter_date": "2020-07-01",
 "awd_max_amd_letter_date": "2020-07-01",
 "awd_abstract_narration": "The accuracy of press releases plays a critical role in the public\u2019s understanding of science and public trust in scientific research. However, several types of exaggeration have been found in press releases, such as making causal claims from correlational findings and inference to humans from animal studies. These exaggerations cause misinformation to be spread to the public through both social media and the mainstream media. This project furthers our understanding of how scholarly research findings may be miscommunicated to policymakers and the public by using state-of-the-art techniques in machine learning and artificial intelligence. This project provides an in-depth understanding at both micro- and macro-levels. On the micro-level, the project examines precisely when and where exaggeration occurs. On the macro-level, the project will examine the prevalence of exaggeration over time and across domains and institutions. These findings will provide useful insights for improving the quality of press releases as an important channel for science communication. \r\n\r\nThis research will provide a large-scale, nuanced understanding of exaggerations in press releases issued by research institutions. The project develops a NLP and deep learning tool called PreCheck, which will automatically checking press release exaggeration, Specifically, PreCheck will link the press releases in EurekAlert!, the major academic press release portal, to the original research articles in PubMed, and then use machine learning and NLP techniques to examine each press release regarding two major types of exaggeration: causal claims of correlational findings and inference to humans from animal studies. Once exaggerations can be identified at the individual press release level, aggregated analyses will be done to answer research questions regarding the status and trend of press release exaggeration and its relationship with research areas and research institutions. The study results will be shared with press officers from various research institutions to discuss the research findings and their implications for communicating scientific research through press releases. In addition, PreCheck will be made publicly available so that science communicators can perform their own communication and science consumers can have a way to measure potential exaggeration in research.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SMA",
 "org_div_long_name": "SBE Office of Multidisciplinary Activities",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bei",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bei Yu",
   "pi_email_addr": "byu@syr.edu",
   "nsf_id": "000584073",
   "pi_start_date": "2020-07-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jian",
   "pi_last_name": "Qin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jian Qin",
   "pi_email_addr": "jqin@syr.edu",
   "nsf_id": "000300057",
   "pi_start_date": "2020-07-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Syracuse University",
  "inst_street_address": "900 S CROUSE AVE",
  "inst_street_address_2": "",
  "inst_city_name": "SYRACUSE",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "3154432807",
  "inst_zip_code": "13244",
  "inst_country_name": "United States",
  "cong_dist_code": "22",
  "st_cong_dist_code": "NY22",
  "org_lgl_bus_name": "SYRACUSE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "C4BXLBC11LC6"
 },
 "perf_inst": {
  "perf_inst_name": "Syracuse University",
  "perf_str_addr": "320 Hinds Hall",
  "perf_city_name": "Syracuse",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "132441190",
  "perf_ctry_code": "US",
  "perf_cong_dist": "22",
  "perf_st_cong_dist": "NY22",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "125Y00",
   "pgm_ele_name": "Science of Science"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7626",
   "pgm_ref_txt": "SCIENCE OF SCIENCE POLICY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 375000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main goal of the PreCheck project is to develop natural language processing (NLP) based prediction models to automatically detect exaggerated claims in science press releases, and then apply these methods to analyze the prevalence and trends of exaggeration over time.</p>\n<p>We first annotated corpora to train NLP models, and then used the models to detect exaggerations. We also developed a linking system that was able to link 40,000 press releases to the original research papers with the top-1 accuracy at 94.5%. Our data and models are publicly available on GitHub. We also made a Chrome Extension for the news linking system.</p>\n<p>The project&rsquo;s progress coincided with the release of Large Language Models such as chatGPT. Threfore, we evaluated chatGPT&rsquo;s performance against our fine-tuned models using our annotated corpus. Although ChatGPT shows promise in detecting claim strength, its prediction accuracy significantly lags behind our fine-tuned BERT models. Additionally, ChatGPT appears to exhibit the same confusion as observed among average human readers when judging the strength of conditional causal claims that were softened by hedges.</p>\n<p>Regarding exaggerated claims, our results showed that 22% of press releases made exaggerated causal claims from correlational findings in observational studies. University press releases exaggerated more often than those from journal publishers by a ratio of 1.5 to 1. Encouragingly, the exaggeration rate has slightly decreased over the past 10 years, despite the increase of the total number of press releases. The extrapolations from animal studies to human implications followed similar patterns.</p>\n<p>Concerns about excessive use of causal language in observational studies extends to original research publications. We then further investigate the factors that may influence a scientist&rsquo;s decision to draw causal conclusions from observational studies. We found that women authors, authors with more research experience, authors from larger teams, and authors from countries with a culture of uncertainty avoidance, are less likely to make causal claims when reporting results from observational studies. In addition, causal language was less frequent in papers from journals that publish more observational studies and those with higher impact factors, suggesting a gatekeeping effect by journals.</p>\n<p>This project produced a PhD dissertation, eight papers, two annotated corpora, one chrome extension, and a tutorial, all of which are publicly available.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/29/2024<br>\nModified by: Bei&nbsp;Yu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe main goal of the PreCheck project is to develop natural language processing (NLP) based prediction models to automatically detect exaggerated claims in science press releases, and then apply these methods to analyze the prevalence and trends of exaggeration over time.\n\n\nWe first annotated corpora to train NLP models, and then used the models to detect exaggerations. We also developed a linking system that was able to link 40,000 press releases to the original research papers with the top-1 accuracy at 94.5%. Our data and models are publicly available on GitHub. We also made a Chrome Extension for the news linking system.\n\n\nThe projects progress coincided with the release of Large Language Models such as chatGPT. Threfore, we evaluated chatGPTs performance against our fine-tuned models using our annotated corpus. Although ChatGPT shows promise in detecting claim strength, its prediction accuracy significantly lags behind our fine-tuned BERT models. Additionally, ChatGPT appears to exhibit the same confusion as observed among average human readers when judging the strength of conditional causal claims that were softened by hedges.\n\n\nRegarding exaggerated claims, our results showed that 22% of press releases made exaggerated causal claims from correlational findings in observational studies. University press releases exaggerated more often than those from journal publishers by a ratio of 1.5 to 1. Encouragingly, the exaggeration rate has slightly decreased over the past 10 years, despite the increase of the total number of press releases. The extrapolations from animal studies to human implications followed similar patterns.\n\n\nConcerns about excessive use of causal language in observational studies extends to original research publications. We then further investigate the factors that may influence a scientists decision to draw causal conclusions from observational studies. We found that women authors, authors with more research experience, authors from larger teams, and authors from countries with a culture of uncertainty avoidance, are less likely to make causal claims when reporting results from observational studies. In addition, causal language was less frequent in papers from journals that publish more observational studies and those with higher impact factors, suggesting a gatekeeping effect by journals.\n\n\nThis project produced a PhD dissertation, eight papers, two annotated corpora, one chrome extension, and a tutorial, all of which are publicly available.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 10/29/2024\n\n\t\t\t\t\tSubmitted by: BeiYu\n"
 }
}