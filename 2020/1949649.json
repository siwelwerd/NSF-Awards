{
 "awd_id": "1949649",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Medium: Collaborative: BaitBuster 2.0: Keeping Users Away From Clickbait",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 228401.0,
 "awd_amount": 244401.0,
 "awd_min_amd_letter_date": "2020-06-17",
 "awd_max_amd_letter_date": "2021-06-23",
 "awd_abstract_narration": "Social media sites such as Facebook are popular platforms for spreading clickbait, links with misleading titles that do not deliver on their promises. Not only does clickbait waste users' time, it often directs users to phishing sites and sites containing spyware and malware. A large number of users fall victim to scams on social media, including those spread through clickbait, due to both a lack of awareness and a lack of appropriate warnings on social media platforms. These users are vulnerable to identity theft, online hacking, and the exposure of sensitive information to adversaries. Thus, it is critical to limit the impact of clickbait on users' security. This project is developing novel techniques to detect various forms of clickbait, especially video-based clickbait, and study user behavior on social media to design effective warning systems. The findings from this research are being incorporated into an open-source browser extension called Baitbuster 2.0, building on the original Baitbuster tool for detecting text-based clickbait. To enhance the impact of this tool, the researchers will design new training methods to raise security awareness and help users avoid clickbait in social media. The project also aims to engage underrepresented groups via outreach efforts and through developing videos to encourage women to consider cybersecurity as a career.\r\n\r\nDetecting clickbait is a major challenge, particularly as video becomes a more prominent form of media online, undermining efforts to detect misleading text. To address this challenge, the research team will take an integrated approach examining the effects of techniques used to attract clicks from users, presentation and distribution of clickbait, personalization of clickbait through crawling users\u2019 personal information (i.e., targeted clickbait), automatic generation of face-swapping clickbait, and risk perceptions and security awareness of users. As a first step, the researchers are collecting and analyzing clickbait datasets to explore ways of identifying clickbait on social media. Using these datasets, they are developing novel applications of state-of-the-art machine learning techniques such as optical character recognition and video understanding to automatically identify video clickbait. In another thrust of this project, the researchers are studying users' clicking behavior and corresponding security mental models to better understand their vulnerability to clickbait and examine the effects of a wide range of social engineering techniques used to attract clicks from users. The findings are being used to design warning systems, which will be integrated into BaitBuster 2.0, to warn users intelligently and effectively to avoid clickbait. Finally, the usability and efficacy of the warning system and BaitBuster 2.0 are being evaluated through in-depth user studies.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Naeemul",
   "pi_last_name": "Hassan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Naeemul Hassan",
   "pi_email_addr": "nhassan@umd.edu",
   "nsf_id": "000748081",
   "pi_start_date": "2020-06-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425103",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 228401.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our project focused on understanding and detecting misleading information in online videos, an increasingly important issue in today&rsquo;s digital world. We explored how video titles can misrepresent content, leading viewers to misunderstand or be misled by what they watch. Below are outcomes of this project-</p>\r\n<p><strong>1. A Taxonomy of Misleading Information</strong><br />We identified and categorized different strategies used in misleading video titles. For example, some titles <em>cherry-pick</em> specific details that distort the overall message, while others use <em>exaggeration</em> or <em>undermining</em> techniques to mislead viewers. This taxonomy helps researchers and platforms better understand how misinformation spreads through subtle manipulations in headlines.</p>\r\n<p><strong>2. Dataset Development Method for Subjective Data</strong><br />Since \"misleading\" is often a subjective concept, we developed a crowdsourcing method to annotate videos reliably. This approach gathers multiple perspectives from diverse individuals, ensuring a balanced view on whether a video title is misleading in relation to its content.</p>\r\n<p><strong>3. Curated Dataset of Misleading Videos</strong><br />Using our crowdsourced annotations, we created a carefully curated dataset of misleading videos. This resource is publicly available and can support future research on misinformation, content moderation, and media literacy efforts.</p>\r\n<p><strong>4. A Multi-Modal Detection Model</strong><br />We also developed an advanced deep learning model capable of analyzing both video content and its title (text) to detect misleading information. By combining insights from different types of data (multi-modality), the model can more accurately identify when a video title doesn&rsquo;t align with the content, paving the way for better tools to combat misinformation.</p>\r\n<p><strong>Broader Impacts</strong><br />This project contributes to the fight against online misinformation, providing tools and knowledge that can help platforms, educators, and policymakers. By improving our understanding of how misleading content works and developing methods to detect it, we&rsquo;re helping to create a safer, more informed digital environment.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/20/2025<br>\nModified by: Naeemul&nbsp;Hassan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nOur project focused on understanding and detecting misleading information in online videos, an increasingly important issue in todays digital world. We explored how video titles can misrepresent content, leading viewers to misunderstand or be misled by what they watch. Below are outcomes of this project-\r\n\n\n1. A Taxonomy of Misleading Information\nWe identified and categorized different strategies used in misleading video titles. For example, some titles cherry-pick specific details that distort the overall message, while others use exaggeration or undermining techniques to mislead viewers. This taxonomy helps researchers and platforms better understand how misinformation spreads through subtle manipulations in headlines.\r\n\n\n2. Dataset Development Method for Subjective Data\nSince \"misleading\" is often a subjective concept, we developed a crowdsourcing method to annotate videos reliably. This approach gathers multiple perspectives from diverse individuals, ensuring a balanced view on whether a video title is misleading in relation to its content.\r\n\n\n3. Curated Dataset of Misleading Videos\nUsing our crowdsourced annotations, we created a carefully curated dataset of misleading videos. This resource is publicly available and can support future research on misinformation, content moderation, and media literacy efforts.\r\n\n\n4. A Multi-Modal Detection Model\nWe also developed an advanced deep learning model capable of analyzing both video content and its title (text) to detect misleading information. By combining insights from different types of data (multi-modality), the model can more accurately identify when a video title doesnt align with the content, paving the way for better tools to combat misinformation.\r\n\n\nBroader Impacts\nThis project contributes to the fight against online misinformation, providing tools and knowledge that can help platforms, educators, and policymakers. By improving our understanding of how misleading content works and developing methods to detect it, were helping to create a safer, more informed digital environment.\r\n\n\n\t\t\t\t\tLast Modified: 02/20/2025\n\n\t\t\t\t\tSubmitted by: NaeemulHassan\n"
 }
}