{
 "awd_id": "2006349",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS Core: Small: Optimizing Distributed Transactions on Emerging Hardware",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 499854.0,
 "awd_amount": 499854.0,
 "awd_min_amd_letter_date": "2020-07-08",
 "awd_max_amd_letter_date": "2020-07-08",
 "awd_abstract_narration": "Replicated transactional storage simplifies the programming and reasoning about distributed systems by providing a simple and powerful abstraction: atomic and durable execution of transactions that can survive node failures. As a consequence, many datacenter systems using transactional storage as a critical building block. This project revisits this research topic to address the opportunities and challenges posed by multiple hardware trends, e.g., large core counts on processors, programmable network interfaces, and low-latency storage. The project seeks to build distributed transactional storage systems using principles that reduce coordination and maximize network and storage performance.\r\n\r\nIn particular, the project seeks to optimize distributed transactional storage by taking advantage of modern hardware features ranging from core-heavy servers to programmable network devices and tiered and highly-parallel durable storage. A key goal is to design distributed protocols that minimize cross-core coordination traffic to provide multi-core scalable solutions. Further, the project will distill remote access communication primitives, enabled by a programmable network interface, in order to optimize transaction processing. The project will also examine how to support durable data structures on heterogeneous storage that includes low-latency non-volatile memory.\r\n\r\nDatacenter applications that require support for transactional storage are used by literally billions of people around the globe daily. By improving the efficiency of distributed transactions and reducing latency/overheads, the project seeks to dramatically reduce the cost of existing datacenter-based services as well as make it much cheaper for new public services to be developed. Collaborators at hardware vendors are equal partners in this effort, providing access to new hardware technologies and assisting in project execution and technology transfer to the industry. The developed software will also enrich the distributed systems curriculum at all levels.\r\n\r\nFor the broader community of users and the society at large, the project will periodically release the developed software to enable a rich set of distributed systems and high-performance datacenter applications. A public repository will be maintained until at least December 2025 at https://github.com/arvindkrish/dist-transactions/tree/master.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Arvind",
   "pi_last_name": "Krishnamurthy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Arvind Krishnamurthy",
   "pi_email_addr": "arvind@cs.washington.edu",
   "nsf_id": "000488256",
   "pi_start_date": "2020-07-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "185 Stevens Way CSE101",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981952350",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 499854.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Replicated transactional storage simplifies the programming and reasoning about distributed systems by providing a simple and powerful abstraction: atomic and durable execution of transactions that can survive node failures.&nbsp; As a consequence, many datacenter systems using transactional storage as a key building block.</p>\r\n<p>In this work, we build distributed transactional storage systems using principles that reduce coordination overheads and improve system scalability. There were three key results that were produced by this work.</p>\r\n<p>(1) We studied&nbsp;how to build multicore-scalable, replicated storage systems. We introduced a new guideline for their design, called the Zero-Coordination Principle. We use this principle to design a new multicore-scalable, in-memory, replicated, key-value store, called Meerkat. Unlike existing systems, Meerkat eliminates all cross-core and cross-replica coordination, both of which pose a scalability bottleneck.</p>\r\n<p>(2) We designed Xenic, a SmartNIC-optimized transaction processing system. Xenic applies an asynchronous, aggregated execution model to maximize network and core efficiency. Xenic&rsquo;s codesigned data store achieves low-overhead remote object accesses. Additionally, Xenic uses flexible, point-to-point communication patterns between SmartNICs to minimize transaction commit latency.</p>\r\n<p>(3) We also tackled issues related to host networking performance. We developed CC-NIC, a host-NIC interface optimized for coherent interconnects. We redesigned all aspects of the host-NIC interface (namely, data structures, layouts, and signaling) to take advantage of the new data paths and cache interactions supported by coherent interconnects. To design CC-NIC, we considered the space of access type, layout, homing, and prefetching decisions, for each element of the interface. Our redesign not only offers improved latency but also delegates certain buffer management tasks to the NIC, thus reducing host-side costs.</p>\r\n<p>By improving the efficiency of distributed transactions and reducing latency/overheads, we have developed techniques that can dramatically reduce the cost of provisioning existing datacenter-based services as well as make it much cheaper for new public services to be developed.&nbsp;</p><br>\n<p>\n Last Modified: 01/25/2025<br>\nModified by: Arvind&nbsp;Krishnamurthy</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nReplicated transactional storage simplifies the programming and reasoning about distributed systems by providing a simple and powerful abstraction: atomic and durable execution of transactions that can survive node failures. As a consequence, many datacenter systems using transactional storage as a key building block.\r\n\n\nIn this work, we build distributed transactional storage systems using principles that reduce coordination overheads and improve system scalability. There were three key results that were produced by this work.\r\n\n\n(1) We studiedhow to build multicore-scalable, replicated storage systems. We introduced a new guideline for their design, called the Zero-Coordination Principle. We use this principle to design a new multicore-scalable, in-memory, replicated, key-value store, called Meerkat. Unlike existing systems, Meerkat eliminates all cross-core and cross-replica coordination, both of which pose a scalability bottleneck.\r\n\n\n(2) We designed Xenic, a SmartNIC-optimized transaction processing system. Xenic applies an asynchronous, aggregated execution model to maximize network and core efficiency. Xenics codesigned data store achieves low-overhead remote object accesses. Additionally, Xenic uses flexible, point-to-point communication patterns between SmartNICs to minimize transaction commit latency.\r\n\n\n(3) We also tackled issues related to host networking performance. We developed CC-NIC, a host-NIC interface optimized for coherent interconnects. We redesigned all aspects of the host-NIC interface (namely, data structures, layouts, and signaling) to take advantage of the new data paths and cache interactions supported by coherent interconnects. To design CC-NIC, we considered the space of access type, layout, homing, and prefetching decisions, for each element of the interface. Our redesign not only offers improved latency but also delegates certain buffer management tasks to the NIC, thus reducing host-side costs.\r\n\n\nBy improving the efficiency of distributed transactions and reducing latency/overheads, we have developed techniques that can dramatically reduce the cost of provisioning existing datacenter-based services as well as make it much cheaper for new public services to be developed.\t\t\t\t\tLast Modified: 01/25/2025\n\n\t\t\t\t\tSubmitted by: ArvindKrishnamurthy\n"
 }
}