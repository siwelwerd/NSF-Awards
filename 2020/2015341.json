{
 "awd_id": "2015341",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Understanding Complexity and the Bias-Variance Tradeoff in High Dimensions: Theory and Data Evidence",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2020-06-16",
 "awd_max_amd_letter_date": "2020-06-16",
 "awd_abstract_narration": "The past decade has witnessed a significant rise in the usage of very large machine-learning models in modern data problems; these models have shown success in a variety of tasks, such as image classification, language translation, and speech recognition. More recently, machine learning is entering new fields, such as robotics, autonomous driving, and medicine. However, these models are often not robust to perturbations and are vulnerable to attacks by adversaries. These shortcomings warrant an urgent and insightful understanding of the \"black-box\" nature of these models. The principal investigator plans to understand these models by characterizing their \"complexity\" in a technical manner. A new complexity measure, based on the principle of minimum description length, sheds insight into classical statistical foundations as well as informing how and when these new high-dimensional models will work. This novel complexity measure is promising to enable applications to mission-critical fields like precision medicine, where the collection of a labeled dataset is expensive, by sample-size calculations and improving model selection with limited data. This research has both theoretical and applied impacts in the fields of statistics and machine learning including deep learning. In the duration of the project, graduate students will be trained in theory, domain-driven data science, and open-source software development. The research will be further disseminated through courses, an upcoming book, and presentations at workshops and conferences.\r\n\r\nDeep neural networks (DNNs) in many cases generalize well in the sense that a DNN trained on one task often performs well on similar unseen data for the same task. They can do so despite being highly overparameterized, i.e., the number of parameters is much larger than the number of training samples.  Occam's razor and the bias-variance trade-off wisdom suggest to prefer a simple model when choosing from amongst models of varying complexity with similar performance. The good performance of DNNs, despite the overparametrization, has led many researchers to question the validity of the classical statistical principle of bias-variance trade-off (and preferring a simple model) for high-dimensional settings common in modern machine learning (ML) and statistical tasks.  In this project, the principal investigator begins by reconsidering the definition of a valid complexity measure \u2013 which forms the basis of Occam\u2019s razor and the bias-variance trade-off principle \u2013 for high-dimensional models. Finding one such measure for high-dimensional models has remained a difficult task.  Merely counting the number of parameters is not a valid complexity measure, especially when the number of training examples is small.  The principle of minimum description length will be used to provide a systematic approach to understanding the complexity of high-dimensional linear models, kernel methods, and finally DNNs. The complexity measure will serve as a basis for understanding key concepts such as the bias-variance trade-off and for further analysis into high-dimensional models. The theoretical results will be augmented with an extensive set of data-inspired experiments.  After establishing the bias-variance trade-off with the new complexity measures, these measures will then be investigated for (i) selecting a simple model from amongst a set of competitive models, where simple will be defined via the MDL-based complexity and not the number of parameters, and (ii) regularizing or pruning a large (pre-trained) model, for example, in a transfer learning setting with limited dataset, by trading off the training performance with the complexity of the model.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bin",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bin Yu",
   "pi_email_addr": "binyu@stat.berkeley.edu",
   "nsf_id": "000465148",
   "pi_start_date": "2020-06-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "367 Evans Hall",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947203860",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-3dd293e5-7fff-9774-4746-6bbeb8f76a30\"> </span></p>\n<p dir=\"ltr\"><span>The last decade saw an explosion in the usage of very large machine-learning models across the canonical learning tasks. More recently, machine learning (ML) is entering new fields, such as robotics, autonomous driving, and medicine. However, complex ML models like deep learning (DL) are often not robust to perturbations and are vulnerable to attacks by adversaries. These shortcomings warrant an urgent and insightful understanding of the &ldquo;black-box'' nature of these models, and making them more interpretable.&nbsp;</span></p>\n<p dir=\"ltr\"><span>The PI and team worked to understand these models by characterizing their &ldquo;complexity'' in a technical manner, and developing software that provides the tools to interpret these complex models without losing predictive performance.</span></p>\n<p dir=\"ltr\"><span>First, a new complexity measure was proposed based on the principle of minimum description length, and several investigations on what affects the complexity of these networks was pursued. Such an analysis sheds insight into classical statistical foundations as well as informing how and when these new high-dimensional models will work, and is useful to enable applications to mission-critical fields like precision medicine, where the collection of a labeled dataset is expensive, by sample-size calculations and improving model selection with limited data. Furthermore, the PI and team successfully demonstrated the promises of the softwares developed for feature importance and interpretability of these complex models on two challenging real-world datasets in cosmology and molecular-partner prediction.&nbsp;</span></p>\n<p dir=\"ltr\"><span>The PI and her team successfully demonstrated the promise of Adaptive Wavelet Distillation (AWD) software developed for the interpretability of complex models on two challenging real-world data prediction problems in cosmology and cellular biology. The interpretability and accuracy of tree-based methods were also improved via hierarchical shrinkage. Using precise high-dimensional asymptotics, they characterized training dynamics of neural networks in two \"worlds\": in the Oracle World the model is trained on the population distribution and in the Empirical World the model is trained on a sampled dataset.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Moreover, a feature space interpretability framework, SUFO, was proposed to explore the fine-tuning effect of language models, revealing that a combination of general and domain-specific corpora enhances model performance. The Fast Interpretable Greedy-Tree Sums (FIGS) method was developed to address inefficiencies in tree-based models, offering state-of-the-art performance with fewer decision rules. The MDI+ framework extends traditional feature importance measures in random forests by incorporating flexible models and mitigating biases, improving stability and robustness in identifying relevant features.The PI and team introduced a theoretical version of their empirically useful method iterative random forests (iRF) for Boolean interaction recovery in genomics using Random Forests, and proved consistent interaction discovery under a new Boolean interaction based regression model. Collectively, these works contribute significantly to the fields of machine learning, feature importance evaluation, and the application of advanced models in biomedical data analysis.</span></p>\n<p dir=\"ltr\"><span>Finally, the PI and her team&rsquo;s research concentrated on interpretable DL with applications in medicine and relevant DL theory, pushing the boundaries of computational efficiency, model optimization, and interpretability in machine learning. Their advances in Bayesian Additive Regression Trees (BART) and Latent Space Optimization (LSO) enhance the theoretical and practical understanding of algorithm performance, while novel methodologies like LoRA+ bolster model fine-tuning and interpretability. Together, these contributions drive the development of more robust, efficient, and understandable AI systems.</span></p>\n<p dir=\"ltr\"><span>In summary, the research outcomes of this grant have both theoretical and applied impacts in the fields of statistics and machine learning including deep learning. In the duration of the proposal, graduate students have been trained in theory, domain-driven data science, and open-source software development. The proposed research has been disseminated through courses, the PI&rsquo;s Veridical Data Science book with R. Barter (MIT Press, 2024, vdsbook.com), and presentations at workshops and conferences.</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 08/02/2024<br>\nModified by: Bin&nbsp;Yu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThe last decade saw an explosion in the usage of very large machine-learning models across the canonical learning tasks. More recently, machine learning (ML) is entering new fields, such as robotics, autonomous driving, and medicine. However, complex ML models like deep learning (DL) are often not robust to perturbations and are vulnerable to attacks by adversaries. These shortcomings warrant an urgent and insightful understanding of the black-box'' nature of these models, and making them more interpretable.\n\n\nThe PI and team worked to understand these models by characterizing their complexity'' in a technical manner, and developing software that provides the tools to interpret these complex models without losing predictive performance.\n\n\nFirst, a new complexity measure was proposed based on the principle of minimum description length, and several investigations on what affects the complexity of these networks was pursued. Such an analysis sheds insight into classical statistical foundations as well as informing how and when these new high-dimensional models will work, and is useful to enable applications to mission-critical fields like precision medicine, where the collection of a labeled dataset is expensive, by sample-size calculations and improving model selection with limited data. Furthermore, the PI and team successfully demonstrated the promises of the softwares developed for feature importance and interpretability of these complex models on two challenging real-world datasets in cosmology and molecular-partner prediction.\n\n\nThe PI and her team successfully demonstrated the promise of Adaptive Wavelet Distillation (AWD) software developed for the interpretability of complex models on two challenging real-world data prediction problems in cosmology and cellular biology. The interpretability and accuracy of tree-based methods were also improved via hierarchical shrinkage. Using precise high-dimensional asymptotics, they characterized training dynamics of neural networks in two \"worlds\": in the Oracle World the model is trained on the population distribution and in the Empirical World the model is trained on a sampled dataset.\n\n\nMoreover, a feature space interpretability framework, SUFO, was proposed to explore the fine-tuning effect of language models, revealing that a combination of general and domain-specific corpora enhances model performance. The Fast Interpretable Greedy-Tree Sums (FIGS) method was developed to address inefficiencies in tree-based models, offering state-of-the-art performance with fewer decision rules. The MDI+ framework extends traditional feature importance measures in random forests by incorporating flexible models and mitigating biases, improving stability and robustness in identifying relevant features.The PI and team introduced a theoretical version of their empirically useful method iterative random forests (iRF) for Boolean interaction recovery in genomics using Random Forests, and proved consistent interaction discovery under a new Boolean interaction based regression model. Collectively, these works contribute significantly to the fields of machine learning, feature importance evaluation, and the application of advanced models in biomedical data analysis.\n\n\nFinally, the PI and her teams research concentrated on interpretable DL with applications in medicine and relevant DL theory, pushing the boundaries of computational efficiency, model optimization, and interpretability in machine learning. Their advances in Bayesian Additive Regression Trees (BART) and Latent Space Optimization (LSO) enhance the theoretical and practical understanding of algorithm performance, while novel methodologies like LoRA+ bolster model fine-tuning and interpretability. Together, these contributions drive the development of more robust, efficient, and understandable AI systems.\n\n\nIn summary, the research outcomes of this grant have both theoretical and applied impacts in the fields of statistics and machine learning including deep learning. In the duration of the proposal, graduate students have been trained in theory, domain-driven data science, and open-source software development. The proposed research has been disseminated through courses, the PIs Veridical Data Science book with R. Barter (MIT Press, 2024, vdsbook.com), and presentations at workshops and conferences.\n\n\n\t\t\t\t\tLast Modified: 08/02/2024\n\n\t\t\t\t\tSubmitted by: BinYu\n"
 }
}