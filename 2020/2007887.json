{
 "awd_id": "2007887",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: RI: Small: Wisdom of Crowds with Machines in the Loop",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 233500.0,
 "awd_amount": 233500.0,
 "awd_min_amd_letter_date": "2020-08-10",
 "awd_max_amd_letter_date": "2020-08-10",
 "awd_abstract_narration": "The importance of both human and machine intelligence and their complementarity has given rise to the aspiration for human-machine hybrid computing systems that achieve more than either could alone. Human-in-the-loop computing, where human inputs are sought during the computation process, is a natural approach. However, most human-in-the-loop computing systems focus on how simple human inputs can help machines to better perform their tasks. This research takes the opposite perspective by focusing on a human-centered domain---the wisdom of crowds---and studies how having machines in the loop can improve the efficacy of harnessing the wisdom of crowds. A key challenge is directly evaluating the quality of crowd contributions. This research tackles the problem of obtaining high-quality contributions from the crowd despite the lack of data for such evaluations. This project seeks to make more accurate and robust use of crowd contributions in a broad spectrum of applications in business (e.g. crowd transcription and translation, and online reviews), sciences (e.g. citizen sciences, machine learning, and peer reviews for conferences and journals), education (e.g. peer grading) and other areas.\r\n\t\t\t\t\t\t\r\nThis research investigates two core problems for tapping into the wisdom of crowds in the challenging, yet realistic, non-verification and unsupervised setting where no ground truth is available, addressing two key research questions: (1) how to elicit high-quality information from (potentially strategic) crowd members; and (2) how to aggregate the elicited information to form a high-quality, collective opinion. Lack of verification via ground truth presents a challenge for the mechanism designer to align incentives for elicitation. It also means that the designer does not know whose information should be weighted higher in aggregation given heterogeneous contributions. This research develops a theoretically grounded framework for elicitation and aggregation for settings without verification. It incorporates machine learning methods for the design of elicitation and aggregation mechanisms to achieve provable guarantees for the crowdsourcing applications, with a focus on the quality of elicited information and the quality of the aggregated opinion.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yiling",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yiling Chen",
   "pi_email_addr": "yiling@seas.harvard.edu",
   "nsf_id": "000508042",
   "pi_start_date": "2020-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021385369",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 233500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Data and information are often elicited from people. This project studies the wisdom of the crowd in a challenging yet realistic non-verification and unsupervised setting, where no ground truth is available for evaluating the quality of individuals' contributions. It focuses on two core problems: (1) how to elicit high-quality information from strategic crowd members, and (2) how to aggregate the elicited information to form a high-quality collective opinion.</p>\n<p>On the front of elicitation, the project designs new mechanisms to incentivize individuals to truthfully report their information despite the lack of ground truth. For example, the surrogate scoring rules mechanism takes peer agents' reports as proxy ground truth and designs an error estimation procedure and a bias correction step so that an agent's report is evaluated as if by the unobservable ground truth. In addition to incentivizing truthful reporting, a salient feature of the mechanism is that surrogate scores also quantify the quality of elicited information in expectation.</p>\n<p>Further down the line of elicitation, this project also studies online learning when data are provided by strategic agents in each round. In repeated online linear classification, agents strategically respond to the deployed classifiers over time. We design a strategy-aware algorithm to optimize the online classifier's performance in the presence of strategic agents.</p>\n<p>On the front of aggregation, the project studies the problem of aggregating solicited forecasts, which may vary in quality, into an accurate final prediction. When no ground truth is available, a peer-assessment-based aggregation approach is proposed. Its effectiveness is demonstrated on a diverse collection of 14 human forecast datasets. Moreover, the project also reveals the innate challenge of aggregation as a learning problem. It proves that, when historical ground truth is available, learning to aggregate accurately requires a large sample size in general.</p>\n<p>The project contributes to improving and ensuring information and data quality for subsequenct learning and decision making.&nbsp;</p><br>\n<p>\n Last Modified: 02/19/2024<br>\nModified by: Yiling&nbsp;Chen</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nData and information are often elicited from people. This project studies the wisdom of the crowd in a challenging yet realistic non-verification and unsupervised setting, where no ground truth is available for evaluating the quality of individuals' contributions. It focuses on two core problems: (1) how to elicit high-quality information from strategic crowd members, and (2) how to aggregate the elicited information to form a high-quality collective opinion.\n\n\nOn the front of elicitation, the project designs new mechanisms to incentivize individuals to truthfully report their information despite the lack of ground truth. For example, the surrogate scoring rules mechanism takes peer agents' reports as proxy ground truth and designs an error estimation procedure and a bias correction step so that an agent's report is evaluated as if by the unobservable ground truth. In addition to incentivizing truthful reporting, a salient feature of the mechanism is that surrogate scores also quantify the quality of elicited information in expectation.\n\n\nFurther down the line of elicitation, this project also studies online learning when data are provided by strategic agents in each round. In repeated online linear classification, agents strategically respond to the deployed classifiers over time. We design a strategy-aware algorithm to optimize the online classifier's performance in the presence of strategic agents.\n\n\nOn the front of aggregation, the project studies the problem of aggregating solicited forecasts, which may vary in quality, into an accurate final prediction. When no ground truth is available, a peer-assessment-based aggregation approach is proposed. Its effectiveness is demonstrated on a diverse collection of 14 human forecast datasets. Moreover, the project also reveals the innate challenge of aggregation as a learning problem. It proves that, when historical ground truth is available, learning to aggregate accurately requires a large sample size in general.\n\n\nThe project contributes to improving and ensuring information and data quality for subsequenct learning and decision making.\t\t\t\t\tLast Modified: 02/19/2024\n\n\t\t\t\t\tSubmitted by: YilingChen\n"
 }
}