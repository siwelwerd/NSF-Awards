{
 "awd_id": "2028861",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "PPoSS: Planning: A Cross-Layer Approach to Accelerate Large-Scale Graph Computations on Distributed Platforms",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Danella Zhao",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2020-09-04",
 "awd_max_amd_letter_date": "2020-10-14",
 "awd_abstract_narration": "This work develops a set of new technologies in parallel and distributed algorithms, high-performance numerical methods, compilers, and computer architecture. These technologies accelerate large-scale graph computations on heterogeneous distributed computers. Graph computations are used in many domains, including computational-biology applications, road and network traffic management, product recommendation, and path-planning problems in robotics. The work uses a new approach to solving graph computations that relies on approximation techniques, which allow the computation to be more parallel without hurting correctness. Solving large-scale graph problems delivers advances in multiple scientific domains, as well as in societal issues. The work tackles the problem in a cross-layer manner, focusing on the synergies between algorithms, numerics, compilers, and computer architecture. Optimizing in this way exposes major opportunities. This work is done in collaboration with industrial partners, including IBM, a leading developer of high-end computer systems on which graph problems run. The work also includes an effort to revamp the course offerings in the Computer Science Department at the University of Illinois. In particular, it creates multidisciplinary courses in the general area of graph-related problems, parallel computing, and related technologies. It also provides research opportunities to undergraduates and under-represented students.\r\n\r\nGraphs are one of today\u2019s most important application domains. As the compute and storage needs of individual graph problems dramatically increase, there is a need to find solutions to these problems that are both scalable and broadly applicable. This work performs a cross-layer effort to accelerate large-scale graph computations on distributed machines. In the algorithms area, the work investigates efficient parallel graph algorithms by leveraging approximation, continuous optimization techniques such as linear programming, and the use of sparsification methods. Different models of parallel computation are examined. In the numerics area, this work brings these algorithms to the state of practice by developing distributed-memory libraries of sparse-matrix computations for approximate graph algorithms. These libraries include techniques in graph algorithms, sparse linear solvers, and numerical optimization. In the compiler area, the work develops novel techniques for approximate computation of graph applications, as well as automated verification approaches to guarantee their correctness. In the computer architecture area, the work speeds-up the resulting sparse-matrix computations with novel hardware. Specifically, hardware modules in the processors, memory hierarchies, and network interfaces support a new data type that operates on groups of graph vertices at a time. Also, heterogeneous nodes include hardware accelerators of sparse computations that speed-up these applications multiple times. Overall, the impact of this work will be advancing many graph applications, helping scientific discoveries and improving social interactions.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Josep",
   "pi_last_name": "Torrellas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Josep Torrellas",
   "pi_email_addr": "torrellas@cs.uiuc.edu",
   "nsf_id": "000488177",
   "pi_start_date": "2020-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Chandra",
   "pi_last_name": "Chekuri",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Chandra S Chekuri",
   "pi_email_addr": "chekuri@illinois.edu",
   "nsf_id": "000487026",
   "pi_start_date": "2020-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sasa",
   "pi_last_name": "Misailovic",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sasa Misailovic",
   "pi_email_addr": "misailo@illinois.edu",
   "nsf_id": "000715355",
   "pi_start_date": "2020-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Edgar",
   "pi_last_name": "Solomonik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Edgar Solomonik",
   "pi_email_addr": "solomon2@illinois.edu",
   "nsf_id": "000753924",
   "pi_start_date": "2020-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "The Board of Trustees of the University of Illinois",
  "perf_str_addr": "506 S. Wright Street",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618012302",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This one-year effort has investigated the feasibility of accelerating large-scale graph computations through a cross-layer effort on distributed machines. This synergistic and cross-disciplinary work combines advances in theory of algorithms, numerics, compilers, and computer architecture. As the compute and storage needs of individual graph problems dramatically increase, there is a need to find solutions to these problems that are both scalable and broadly applicable.</p>\n<p><br />Graph applications are both highly parallel and contain computational patterns that are challenging for the state-of-the-art computer systems. We have focused on developing a set of techniques from the four constituting research areas that, in combination, speed-up a parallel application in a synergistic manner. We have chosen to study a parallel implementation of the Multiplicative Weight Update (MWU) method for graph-based linear programs.</p>\n<p><br />In the algorithms area, we studied ways to exploit simple iterative algorithms that perform much better in practice than conventional, theoretically fast algorithms; this includes the study of the densest subgraph problem (DSG) and the densest subgraph local decomposition problem (DSG-LD) in undirected graphs.</p>\n<p><br />In the numerics area, we studied how to bring these algorithms to the state of practice by developing distributed-memory libraries of sparse matrix computations for approximate graph algorithms. These libraries bridge techniques in graph algorithms, sparse linear solvers, and numerical optimization.</p>\n<p><br />In the compiler area, we studied how to develop novel techniques for approximate computation of graph applications, as well as automated runtime verification approaches to guarantee the reliability of these applications.</p>\n<p><br />In the computer systems architecture area, we studied how to speed-up the resulting sparse matrix computations with matrix tiling for caches. In addition, we have developed a machine learning model that predicts the speedups with various Sparse Matrix Vector Multiplication (SpMV) transformations and algorithms.</p>\n<p><br />This work has been published in several prominent conferences and journals in various fields. The work is being cited by peers and multiple other researchers are building on this work to further extend our understanding of the potential of these architectures. Our colleagues at IBM Research are studying our techniques and results.</p>\n<p><br />Under this project, several graduate students in the Computer Science Department of the University of Illinois have been trained. They have been exposed to research that connects multiple disciplines (theory of algorithms, numerical analysis, compilers, and architecture). The students have also collaborated with other professors from the University of Illinois and researchers from companies. In particular, some of the work has been done in close cooperation with IBM. One of the PhD students in the project has started to work for NVIDIA in California.</p>\n<p><br />Finally, some of the material researched has been incorporated in courses taught by the PIs, including Prof. Chandra Chekuri's algorithms courses, Prof. Edgar Solomonik's&nbsp; numerical analysis courses, Prof. Sasa Misailovic's compilers courses, and Prof. Josep Torrellas' computer architecture courses. Undergraduate and graduate students at the University of Illinois have benefited from this research. The PIs plan to continue this work using other funding, and continue to educate students with their research work.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/30/2023<br>\n\t\t\t\t\tModified by: Josep&nbsp;Torrellas</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis one-year effort has investigated the feasibility of accelerating large-scale graph computations through a cross-layer effort on distributed machines. This synergistic and cross-disciplinary work combines advances in theory of algorithms, numerics, compilers, and computer architecture. As the compute and storage needs of individual graph problems dramatically increase, there is a need to find solutions to these problems that are both scalable and broadly applicable.\n\n\nGraph applications are both highly parallel and contain computational patterns that are challenging for the state-of-the-art computer systems. We have focused on developing a set of techniques from the four constituting research areas that, in combination, speed-up a parallel application in a synergistic manner. We have chosen to study a parallel implementation of the Multiplicative Weight Update (MWU) method for graph-based linear programs.\n\n\nIn the algorithms area, we studied ways to exploit simple iterative algorithms that perform much better in practice than conventional, theoretically fast algorithms; this includes the study of the densest subgraph problem (DSG) and the densest subgraph local decomposition problem (DSG-LD) in undirected graphs.\n\n\nIn the numerics area, we studied how to bring these algorithms to the state of practice by developing distributed-memory libraries of sparse matrix computations for approximate graph algorithms. These libraries bridge techniques in graph algorithms, sparse linear solvers, and numerical optimization.\n\n\nIn the compiler area, we studied how to develop novel techniques for approximate computation of graph applications, as well as automated runtime verification approaches to guarantee the reliability of these applications.\n\n\nIn the computer systems architecture area, we studied how to speed-up the resulting sparse matrix computations with matrix tiling for caches. In addition, we have developed a machine learning model that predicts the speedups with various Sparse Matrix Vector Multiplication (SpMV) transformations and algorithms.\n\n\nThis work has been published in several prominent conferences and journals in various fields. The work is being cited by peers and multiple other researchers are building on this work to further extend our understanding of the potential of these architectures. Our colleagues at IBM Research are studying our techniques and results.\n\n\nUnder this project, several graduate students in the Computer Science Department of the University of Illinois have been trained. They have been exposed to research that connects multiple disciplines (theory of algorithms, numerical analysis, compilers, and architecture). The students have also collaborated with other professors from the University of Illinois and researchers from companies. In particular, some of the work has been done in close cooperation with IBM. One of the PhD students in the project has started to work for NVIDIA in California.\n\n\nFinally, some of the material researched has been incorporated in courses taught by the PIs, including Prof. Chandra Chekuri's algorithms courses, Prof. Edgar Solomonik's  numerical analysis courses, Prof. Sasa Misailovic's compilers courses, and Prof. Josep Torrellas' computer architecture courses. Undergraduate and graduate students at the University of Illinois have benefited from this research. The PIs plan to continue this work using other funding, and continue to educate students with their research work.\n\n\t\t\t\t\tLast Modified: 04/30/2023\n\n\t\t\t\t\tSubmitted by: Josep Torrellas"
 }
}