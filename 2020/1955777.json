{
 "awd_id": "1955777",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CNS Core: Medium: Learning to Cache and Caching to Learn in High Performance Caching Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ann Von Lehmen",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2020-09-10",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "Caching is fundamental to cloud computing and content distribution, and is important to the vast number of applications and services they support.  Crucial performance metrics of a caching algorithm are its ability to quickly and accurately learn a changing popularity distribution. However, there is a serious disconnect between empirical studies using real-world traces that account for popularity changes, and analytical performance analysis results that assume a fixed popularity.  A basic goal of this project is to develop a methodology based on online learning and reinforcement learning for caching algorithm design with provable performance guarantees.  This enables the systematic design of caching algorithms that can be tailored to a variety of application contexts. The use-case of these algorithms is in high performance caching networks that support large-scale cloud applications and services.  Emulation of high-performance caching systems to leverage and to empirically evaluate the online learning algorithms developed supports this goal, and provides a real-world context for the methodology developed.  The results will also enhance the performance of content distribution platforms.  At the same time the project develops fundamental theories that pertain to the area of machine learning, specifically to online learning. \r\n\r\nThis project aims at optimally utilizing locally available memory and computing resources of caches, while ensuring provably good performance via fast and accurate learning of content popularity. This requires the conjunction of several mathematical tools to analyze online learning algorithms, as well as strong systems development skills to make the algorithms a reality. The project addresses these key challenges in two main themes. The first theme focuses on systematic design of distributed online learning in networks of caches using collaborative filtering for distributed identification of popular content, and multi-agent reinforcement learning for joint learning and content placement. The second theme focuses on building high performing caching systems using the algorithms developed in the first theme, and quantifying the impacts of the algorithms on real-world applications such as Hipster Shop, an open-source e-commerce website, and Spark data-analytics job pipelines. The immediate impact of this project is in creating high performance caching schemes that apply to cloud computing and content distribution networks. This project also advances the fundamental theory of online learning. The project includes an education plan focusing on machine learning and caching, and outreach in the form of summer camps and seminars for high school students.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Vijay",
   "pi_last_name": "Subramanian",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Vijay G Subramanian",
   "pi_email_addr": "vgsubram@umich.edu",
   "nsf_id": "000610770",
   "pi_start_date": "2020-09-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "1301 Beal Avenue",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092122",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project we developed methodologies for online learning and reinforcement learning broadly in networking systems&mdash;e.g., for video-streaming over wireless, for caching algorithm design, for scheduling and resource allocation in communication networks&mdash;with provable finite-time performance guarantees. We took a broad perspective so that the developed methods could be used in many contexts. Specifically, we considered several aspects that arise in queueing models of communication networks and in networking systems. The aspects we focussed on were: 1) complex stochastic dynamics; 2) countable state-spaces; 3) sampling-based measurements of systems for decision-making; 4) multi-agents aspects like information asymmetry and achieving scalability. We also studied automated trace generation using modern machine learning methods. Our findings can be broadly summarized as follows:</p>\n<p><br />1. Information state based RL algorithms for multi-agent teams: A key step in being able to develop RL algorithms with provable performance guarantees for the unknown model setting in decentralized multi-agent teams is to characterize an approximate information state that is not only sufficient for a dynamic programming but also has good regret (to control sub-optimality of the control policies developed). For a large class of multi-agent teams, we provided a direct characterization of an information state that allows for optimal solutions. As the information state may also grow with time, this framework then is used to study when a good time-invariant approximate information state can be developed.</p>\n<p><br />2. Learning-based optimal control of queueing system models of communication networks: Optimal control in many systems, particularly continuous-time queueing systems, is not easily amenable to reinforcement learning (RL) methods owing to the lack of dense reward signals and due to complex structures inherent in these system. Using model-class knowledge, however, information rewards (to predict the data generated) are available. Using these alternate signals, we explored the design of optimal controls. We studied three problems in this context: 1) optimal admission control to an Erlang-blocking system with unknown service rate and holding cost; 2) optimal admission control to a single-server with unknown service rate and holding cost; and 3) parametric countable state controlled Markov chains. For these we developed low-regret learning-based optimal control algorithms using either a perturbed maximum-likelihood estimate or Thompson sampling.</p>\n<p><br />3. Learning-based optimal control of multi-agent systems with applications to networking systems: Building on our information-state work, we studied algorithms for cooperative systems with multiple-agents with the goal to develop optimal control methodologies in a data-driven manner. Within this topic we also looked at a decentralized multi-agent formulation for wireless media streaming; this is a collaborative project with the TAMU team. This involved the development of learning-based control for partially observed Markov decision processes with constraints. In the wireless media streaming problem feedback delays creates information asymmetry and a decentralized team control problem. We have developed a decentralized team formulation and planning solution. We developed a general result for control of such decentralized team systems with joint constraints, and applied that to the video-streaming problem to develop not only scalable optimal algorithms but learning-based solutions.</p>\n<p><br />4. ML models based trace generation: We explored different ML models, particularly deep learning models, for automated statistically identical trace generation. With the hidden state dynamical system estimation viewpoint, we used a point process formulation to reproduce traces. Recurrent Neural Network based schemes were able to predict the trace well only over a short time window. We explored transformers, LSTMs and linear models as alternatives with promising results for linear models.</p><br>\n<p>\n Last Modified: 02/20/2024<br>\nModified by: Vijay&nbsp;G&nbsp;Subramanian</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn this project we developed methodologies for online learning and reinforcement learning broadly in networking systemse.g., for video-streaming over wireless, for caching algorithm design, for scheduling and resource allocation in communication networkswith provable finite-time performance guarantees. We took a broad perspective so that the developed methods could be used in many contexts. Specifically, we considered several aspects that arise in queueing models of communication networks and in networking systems. The aspects we focussed on were: 1) complex stochastic dynamics; 2) countable state-spaces; 3) sampling-based measurements of systems for decision-making; 4) multi-agents aspects like information asymmetry and achieving scalability. We also studied automated trace generation using modern machine learning methods. Our findings can be broadly summarized as follows:\n\n\n\n1. Information state based RL algorithms for multi-agent teams: A key step in being able to develop RL algorithms with provable performance guarantees for the unknown model setting in decentralized multi-agent teams is to characterize an approximate information state that is not only sufficient for a dynamic programming but also has good regret (to control sub-optimality of the control policies developed). For a large class of multi-agent teams, we provided a direct characterization of an information state that allows for optimal solutions. As the information state may also grow with time, this framework then is used to study when a good time-invariant approximate information state can be developed.\n\n\n\n2. Learning-based optimal control of queueing system models of communication networks: Optimal control in many systems, particularly continuous-time queueing systems, is not easily amenable to reinforcement learning (RL) methods owing to the lack of dense reward signals and due to complex structures inherent in these system. Using model-class knowledge, however, information rewards (to predict the data generated) are available. Using these alternate signals, we explored the design of optimal controls. We studied three problems in this context: 1) optimal admission control to an Erlang-blocking system with unknown service rate and holding cost; 2) optimal admission control to a single-server with unknown service rate and holding cost; and 3) parametric countable state controlled Markov chains. For these we developed low-regret learning-based optimal control algorithms using either a perturbed maximum-likelihood estimate or Thompson sampling.\n\n\n\n3. Learning-based optimal control of multi-agent systems with applications to networking systems: Building on our information-state work, we studied algorithms for cooperative systems with multiple-agents with the goal to develop optimal control methodologies in a data-driven manner. Within this topic we also looked at a decentralized multi-agent formulation for wireless media streaming; this is a collaborative project with the TAMU team. This involved the development of learning-based control for partially observed Markov decision processes with constraints. In the wireless media streaming problem feedback delays creates information asymmetry and a decentralized team control problem. We have developed a decentralized team formulation and planning solution. We developed a general result for control of such decentralized team systems with joint constraints, and applied that to the video-streaming problem to develop not only scalable optimal algorithms but learning-based solutions.\n\n\n\n4. ML models based trace generation: We explored different ML models, particularly deep learning models, for automated statistically identical trace generation. With the hidden state dynamical system estimation viewpoint, we used a point process formulation to reproduce traces. Recurrent Neural Network based schemes were able to predict the trace well only over a short time window. We explored transformers, LSTMs and linear models as alternatives with promising results for linear models.\t\t\t\t\tLast Modified: 02/20/2024\n\n\t\t\t\t\tSubmitted by: VijayGSubramanian\n"
 }
}