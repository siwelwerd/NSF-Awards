{
 "awd_id": "2007784",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Automatic Qualitative and Quantitative Verification of CUDA Code",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 499996.0,
 "awd_amount": 499996.0,
 "awd_min_amd_letter_date": "2020-05-15",
 "awd_max_amd_letter_date": "2020-10-28",
 "awd_abstract_narration": "General-purpose programming on Graphics Processing Units (GPUs) has become prevalent in fields such as machine learning. As a result, NVIDIA has developed the CUDA (Compute Unified Device Architecture) framework to support programmers in effectively using GPUs by implementing specialized functions, called kernels, in a dialect of C++. However, the unusual executionmodel of CUDA may result in performance anomalies that would be difficult to predict for novice CUDA programmers. The objective of this project is to develop reasoning techniques and automated tools for predicting the resource usage of CUDA kernels. The outcomes of this project will greatly benefit software programmers, including novices, in writing more efficient kernels.\r\n\r\nThe difficulty in analyzing the performance of CUDA, as opposed to other imperative languages, is that the same code runs in parallel on many threads that store independent copies of local program variables. This project is developing novel analyses that can reason about multiple copies of program variables when necessary for precision but elide this information when possible to maintain scalability. Furthermore, the performance of CUDA code crucially depends upon its ability to hide latency of, for example, memory operations, by quickly switching among many threads. Reasoning precisely about execution times of CUDA kernels therefore requires reasoning about the latency of such operations and the behavior of the GPU's thread scheduler. The tools and analyses developed in this project can open the emerging field of General-Purpose GPU programming to a wider array of developers and improve the quality and efficiency of code in several important domains of computing.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jan",
   "pi_last_name": "Hoffmann",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jan Hoffmann",
   "pi_email_addr": "jhoffmann@cmu.edu",
   "nsf_id": "000636870",
   "pi_start_date": "2020-05-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie Mellon University",
  "perf_str_addr": "5000 Forbes Avenue",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 499996.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-a1e66753-7fff-12bd-59f5-81a388c5a995\"> </span></p>\r\n<p dir=\"ltr\"><span>Many important computational problems, such as training a neural network or processing images, are massively data-parallel. Such algorithms are naturally suitable for execution on Graphics Processing Units (GPUs), special-purpose chips which consist of many (often thousands) processing units designed for vector operations. CUDA is a popular platform developed by NVIDIA for enabling general-purpose programs to run on GPUs. Developing efficient CUDA code comes with novel challenges and small changes, which might be inconsequential for sequential CPU code, can have drastic impact on the performance of the code.</span></p>\r\n<p dir=\"ltr\">This project has supported the development of reasoning techniques and automated tools for predicting the resource use of CUDA code and aiding programmers, including novice CUDA programmers, in writing more efficient code. The specific results include the design and implementation of a precisely-defined cost model that accurately reflects resource use of CUDA code, a program logic for statically proving resource bounds, and an automated amortized resource analysis (AARA) that automatically infers worst-case bounds. In addition to inferring worst-case bounds, the tools developed as part of this project can also automatically apply optimizations to CUDA code, using the inferred bounds to estimate which combination of optimizations will perform the best. This work has also led to foundational results that are applicable to general data-parallel and sequential programs. The highlights include (1) a new technique for statically generating worst-case inputs for parallel and concurrent code and (2) graph types that statically and compactly describe families of dependency graphs that might arise from running a parallel program. Both techniques can be used by programmers to better understand the dynamic behavior of the code at development time and to identify potential performance issues.</p>\r\n<p dir=\"ltr\"><span>The research results are publically available and have been peer-reviewed and published at prestigious programming language and verification conferences such as POPL, PLDI, and LICS.&nbsp; By supporting developers in making CUDA code more efficient, these works have the potential to improve the scalability of GPU programming and lower the energy consumption of data centers. The project has also facilitated the integration of CUDA and data-parallel programming into education and has partly supported the research of 8 graduate students at Carnegie Mellon University and the Illinois Institute of Technology.</span></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/24/2025<br>\nModified by: Jan&nbsp;Hoffmann</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \r\n\n\nMany important computational problems, such as training a neural network or processing images, are massively data-parallel. Such algorithms are naturally suitable for execution on Graphics Processing Units (GPUs), special-purpose chips which consist of many (often thousands) processing units designed for vector operations. CUDA is a popular platform developed by NVIDIA for enabling general-purpose programs to run on GPUs. Developing efficient CUDA code comes with novel challenges and small changes, which might be inconsequential for sequential CPU code, can have drastic impact on the performance of the code.\r\n\n\nThis project has supported the development of reasoning techniques and automated tools for predicting the resource use of CUDA code and aiding programmers, including novice CUDA programmers, in writing more efficient code. The specific results include the design and implementation of a precisely-defined cost model that accurately reflects resource use of CUDA code, a program logic for statically proving resource bounds, and an automated amortized resource analysis (AARA) that automatically infers worst-case bounds. In addition to inferring worst-case bounds, the tools developed as part of this project can also automatically apply optimizations to CUDA code, using the inferred bounds to estimate which combination of optimizations will perform the best. This work has also led to foundational results that are applicable to general data-parallel and sequential programs. The highlights include (1) a new technique for statically generating worst-case inputs for parallel and concurrent code and (2) graph types that statically and compactly describe families of dependency graphs that might arise from running a parallel program. Both techniques can be used by programmers to better understand the dynamic behavior of the code at development time and to identify potential performance issues.\r\n\n\nThe research results are publically available and have been peer-reviewed and published at prestigious programming language and verification conferences such as POPL, PLDI, and LICS. By supporting developers in making CUDA code more efficient, these works have the potential to improve the scalability of GPU programming and lower the energy consumption of data centers. The project has also facilitated the integration of CUDA and data-parallel programming into education and has partly supported the research of 8 graduate students at Carnegie Mellon University and the Illinois Institute of Technology.\r\n\n\n\t\t\t\t\tLast Modified: 01/24/2025\n\n\t\t\t\t\tSubmitted by: JanHoffmann\n"
 }
}