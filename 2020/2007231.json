{
 "awd_id": "2007231",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS Core: Small: New Caching Paradigms for Distributed and Dynamic Networks",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927855",
 "po_email": "aabouzei@nsf.gov",
 "po_sign_block_name": "Alhussein Abouzeid",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2020-08-27",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "Over the last few decades, Content Distribution Networks (CDNs) have been used to cache data of popular interest closer to the end-users in order to make them rapidly accessible whenever requested. This results in substantial time savings from an end-user\u2019s perspective when retrieving popular content like video feeds. It also helps to reduce the bandwidth demands on the overall network.  This is achieved by developing efficient mechanisms that employ popularity-based indicators to store or evict content from the cache memory. However, with the advent of emerging technologies such as the Internet-of-Things (IoT) and cyberphysical systems, the dynamics and requirements of networks are witnessing significant changes that call for fundamentally new caching solutions that extend beyond the purview of CDNs to the wireless edge and the end-user devices. These new networks will be composed of a large number of highly mobile devices (e.g., mobile phones) with intermittent, delay-sensitive, and personalized demand to be supported over resource-limited wireless channels. To address these new challenges, this project undertakes the task of democratizing caching by proposing a systematic methodology that encompasses the wireless edge and the end-users in the design of provably good caching strategies for increasingly dynamic and disparate networks. \r\n\r\nThis project is motivated by the observation that caching within and at the endpoints of networks must differ fundamentally from each other, as well as from existing caching strategies optimized for today's CDNs. In particular, the project identifies and systematically investigates complementary scenarios that must employ different caching principles based on the position of the memory space and the nature of demand it receives. In each scenario, the project takes a holistic approach to the design to incorporate generation and demand dynamics, wireless communication capabilities and limitations, variety of uncertainties in the traffic and environment, and quality-of-service requirements. This research is multi-disciplinary and will bring together elements from queueing, scheduling, anomaly detection, coding, learning and control theories towards the design of integrated and adaptive caching solutions. This interdisciplinary research will be integrated into the curricula and will help train the next generation of engineers and academicians with the tools it takes to succeed in solving increasingly complex and challenging problems. The investigators are committed to recruit women and under-represented minority students in their research.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ness",
   "pi_last_name": "Shroff",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ness Shroff",
   "pi_email_addr": "shroff@ece.osu.edu",
   "nsf_id": "000445637",
   "pi_start_date": "2020-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Atilla",
   "pi_last_name": "Eryilmaz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Atilla Eryilmaz",
   "pi_email_addr": "eryilmaz.2@osu.edu",
   "nsf_id": "000502165",
   "pi_start_date": "2020-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio State University",
  "inst_street_address": "1960 KENNY RD",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBUS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "6146888735",
  "inst_zip_code": "432101016",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OH03",
  "org_lgl_bus_name": "OHIO STATE UNIVERSITY, THE",
  "org_prnt_uei_num": "MN4MDDMN8529",
  "org_uei_num": "DLWBSLWAJWR1"
 },
 "perf_inst": {
  "perf_inst_name": "Ohio State University",
  "perf_str_addr": "2015 Neil Ave.",
  "perf_city_name": "Columbus",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "432101272",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OH03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Edge caching is critical for various edge applications and use cases such as:&nbsp;</p>\r\n<ul>\r\n<li><strong>Autonomous transportation:</strong>&nbsp;Where one can store (pre-scanned) geographic/congestion/environmental information at edges for fast decision making.</li>\r\n<li><strong>Intelligent/adaptive/personalized&nbsp; education:&nbsp;</strong>Where &nbsp;education materials based on users&rsquo; interests and abilities can be stored at the network edges for fast data retrieval.&nbsp;</li>\r\n<li><strong>Edge computing:</strong>&nbsp;Where we can store pre-computed data at edges (e.g., product embeddings for recommendation services) for accelerating computation&hellip;</li>\r\n</ul>\r\n<p>Our edge caching works has impacted al of these applications by developing:&nbsp;</p>\r\n<ul>\r\n<li><span>New edge caching policies optimized for the <strong>individualized edge demands.</strong> The idea is that&nbsp; <span>an individual user may not be interested in requesting the same data item again, if it has recently requested it. Such individualized dynamics are not apparent in the aggregated data requests at the core and have not been considered in popularity-driven caching designs for the core. Hence, these traditional caching policies that focus on popularity based designs could induce significant inefficiencies when applied at the edges. </span>Our proposed policies actively evict the data items that are not likely to be requested in the near future, and strategically bring them back into the cache via overhearing when they become popular again. Both through theoretical analysis and numerical simulations, we have demonstrated that the proposed edge caching policies could outperform the popularity-driven policies that are optimal at the core.</span></li>\r\n<li>Edge caching policies that address the implicit impact of <strong>multiple storage layers </strong>from the edge to the core of the network. The idea here is that edge caching performance is impacted by a variety of storage layers from the edge cache to intermediate caches to the backend core caches in a complex and implicit manner. In our work, we develop online learning&nbsp; and update edge caching decisions to&nbsp;implicit impact of multiple storage layers&nbsp; and develop solutions that significantly outperform the state of the art.&nbsp;</li>\r\n<li>A suite of edge caching policies that account for the increasingly prominent <strong>content generation dynamics</strong>, leading to the development of the foundations and methods for a<strong>&nbsp;fresh caching</strong> framework. This framework has contributed to the understanding and management of how to modify the traditional caching strategies in today's content distribution networks (developed under the assumption of static or quasi-static content) towards those new designs that accommodates ageing and rapidly changing content that increasingly more applications (such as social networking and autonomous transportation) require. Our studies have revealed in what aspects and under what conditions do the existing caching solutions must be fundamentally revised to maximize performance under dynamic content generation.&nbsp;<br /><br />&nbsp;</li>\r\n</ul>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/29/2025<br>\nModified by: Atilla&nbsp;Eryilmaz</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nEdge caching is critical for various edge applications and use cases such as:\r\n\r\nAutonomous transportation:Where one can store (pre-scanned) geographic/congestion/environmental information at edges for fast decision making.\r\nIntelligent/adaptive/personalized education:Where education materials based on users interests and abilities can be stored at the network edges for fast data retrieval.\r\nEdge computing:Where we can store pre-computed data at edges (e.g., product embeddings for recommendation services) for accelerating computation\r\n\r\n\n\nOur edge caching works has impacted al of these applications by developing:\r\n\r\nNew edge caching policies optimized for the individualized edge demands. The idea is that an individual user may not be interested in requesting the same data item again, if it has recently requested it. Such individualized dynamics are not apparent in the aggregated data requests at the core and have not been considered in popularity-driven caching designs for the core. Hence, these traditional caching policies that focus on popularity based designs could induce significant inefficiencies when applied at the edges. Our proposed policies actively evict the data items that are not likely to be requested in the near future, and strategically bring them back into the cache via overhearing when they become popular again. Both through theoretical analysis and numerical simulations, we have demonstrated that the proposed edge caching policies could outperform the popularity-driven policies that are optimal at the core.\r\nEdge caching policies that address the implicit impact of multiple storage layers from the edge to the core of the network. The idea here is that edge caching performance is impacted by a variety of storage layers from the edge cache to intermediate caches to the backend core caches in a complex and implicit manner. In our work, we develop online learning and update edge caching decisions toimplicit impact of multiple storage layers and develop solutions that significantly outperform the state of the art.\r\nA suite of edge caching policies that account for the increasingly prominent content generation dynamics, leading to the development of the foundations and methods for afresh caching framework. This framework has contributed to the understanding and management of how to modify the traditional caching strategies in today's content distribution networks (developed under the assumption of static or quasi-static content) towards those new designs that accommodates ageing and rapidly changing content that increasingly more applications (such as social networking and autonomous transportation) require. Our studies have revealed in what aspects and under what conditions do the existing caching solutions must be fundamentally revised to maximize performance under dynamic content generation.\n\n\r\n\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 01/29/2025\n\n\t\t\t\t\tSubmitted by: AtillaEryilmaz\n"
 }
}