{
 "awd_id": "2012546",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Task-Aware Quantization in Data Science: Theory and Fast Algorithms",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922113",
 "po_email": "ygorb@nsf.gov",
 "po_sign_block_name": "Yuliya Gorb",
 "awd_eff_date": "2020-08-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2020-07-20",
 "awd_max_amd_letter_date": "2020-07-20",
 "awd_abstract_narration": "Machine learning algorithms are ubiquitous, and their applications in data science are on the rise. This project focuses on developing computationally efficient algorithms in data-science applications where discretization, also known as quantization, plays a fundamental role. Here quantization is the process that replaces real numbers, like those obtained from sensor measurements, by elements in a finite set. This makes them amenable to efficient digital representation, storage, compression, and transmission. Applications of interest include deep learning, an area that has led to sensational breakthroughs in a stunning range of areas. One of its frontiers is building neural networks on hardware that can be put into handheld and wearable devices as well as those in smart homes. For that, neural networks must be efficiently quantized; a key goal of this project is to devise algorithms for this task. Another application concerns edge devices, such as sensors in a sensor network, which communicate and perform computations under severe power limitations. A goal of this project is to develop computationally efficient algorithms for quantizing and compressing their data to enable reducing power use. A third application involves recommender systems, which collect users\u2019 discretized ratings of products and transform them into other product recommendations for others. The project provides training for graduate students through involvement in the research.\r\n\r\nThis project focuses on developing computationally efficient quantization algorithms with provable error guarantees. It is motivated by three important application areas. First, in settings where the goal is discretizing the parameters of a function, as in the compression of deep neural networks, it seeks quantization algorithms to generate functionally equivalent networks that require many fewer bits to store. The second motivating area involves settings where inference tasks must be done on edge-devices, under communication and computation constraints, as in sensor-networks. Here, the focus is on computationally efficient measurement, quantization, and inference algorithms that entail minimal memory and power requirements. Third, in applications where signal recovery is the goal and measurements are inherently binary and expensive to collect, as in recommender systems, the focus is on devising and studying efficient adaptive algorithms for sequential selection of the measurements. This project, which aims to develop state of the art task-aware algorithms, entails developing and using tools from several areas of mathematics, including methods from geometric functional analysis and non-asymptotic random matrix theory. Connections with frame theory, compressed sensing, and noise-shaping quantization will also be established. In analyzing the algorithms, discrete geometry, optimization, and numerical analysis techniques will be developed and employed. To compare theoretical guarantees associated with this project with best possible ones, approximation theory will be essential.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rayan",
   "pi_last_name": "Saab",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rayan Saab",
   "pi_email_addr": "rsaab@ucsd.edu",
   "nsf_id": "000653192",
   "pi_start_date": "2020-07-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 Gilman Drive",
  "perf_city_name": "LA JOLLA",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930934",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Project Title: Task-Aware Quantization in Data Science: Theory and Fast Algorithms<br /><br /><strong>Overview:&nbsp;</strong>Quantization is the process of approximating data by reducing it to a smaller, more manageable set of values, enabling its representation and processing with a small number of bits. This process is critical for efficiently storing and processing large datasets, training AI models, and running applications on devices with limited memory and power. This project developed new quantization methods and established a solid mathematical foundation for their use, motivated by applications in data science and machine learning.<br />We focused on three main objectives: 1) Compressing large machine learning models, such as deep neural networks, so they use less memory and power without sacrificing performance. 2) Designing efficient algorithms so that small devices, like smartphones and sensors, can process data with limited resources. 3) Developing efficient adaptive ways to collect and analyze data for applications like recommendation systems, where gathering information is expensive or time-consuming.</p>\r\n<p><br />An overaching goal of &nbsp;this work was to couple practical efficiency with rigorous theoretical guarantees.</p>\r\n<p><strong>Intellectual Merit<br /></strong><br /><span style=\"text-decoration: underline;\"><strong>Compressing AI Models:</strong></span> Our research led to efficient methods for shrinking neural networks by quantizing their internal parameters. For instance, one approach reduced the parameters to just three possible values ({-1, 0, 1}), dramatically cutting memory requirements while maintaining accuracy. This method, published in the Journal of Machine Learning Research, is simple enough to run on low-power devices, making advanced AI more accessible for everyday applications.<br />Building on this, we extended the method to handle more complex neural network architectures, including convolutional layers commonly used in image processing. These refinements, published in the SIAM Journal on Mathematics of Data Science, come with theoretical guarantees and were shown to perform well in practical scenarios. We also introduced stochastic variations of these methods to handle deep networks more effectively, removing prior limitations on the types of data they could handle.<br />Collaborating with industry partners, we also developed a new framework for optimizing low-bit computations in AI models. This work, currently under review, demonstrates strong performance in tasks like image classification and language generation.<br /><br /><span style=\"text-decoration: underline;\"><strong>Enabling Small Devices to Process Data Efficiently:&nbsp;</strong></span>To meet the demands of small devices with limited memory, we designed a fast, distance-preserving method for embedding large datasets into compact binary codes. This technique allows devices to quickly and accurately estimate similarities between data points&mdash;essential for applications like searching for similar images or recommending products. Tests on real-world datasets showed that our method is both faster and more accurate than many existing techniques, as presented at ICLR 2021. We also explored how certain techniques known as noise-shaping quantization techniques could be used to compress important features (Random Fourier Features), which are a popular tool in machine learning. This work, published in Information and Inference: A Journal of the IMA, demonstrated how quantization can maintain computational efficiency while preserving accuracy in tasks that rely on kernel methods.&nbsp;<br /><br /><span style=\"text-decoration: underline;\"><strong>Improving Data Collection and Analysis:</strong></span> Motivated by recommendation systems and other applications where data collection can be expensive, we developed adaptive measurement techniques to maximize the value of each collected data point. By leveraging mathematical insights about geometric properties in high-dimensional spaces, we created algorithms that efficiently select measurements to improve accuracy. These findings were published in ACHA.<br /><br /><span style=\"text-decoration: underline;\"><strong>Other Contributions: </strong></span>We made significant advances in understanding mathematical structures critical to quantization and data processing. For example, we studied the behavior (namely the singular vectors) of certain important matrices, known as higher order difference matrices, proving new bounds that can be leveraged to understand the behavior of quantization algorithms when used for a particular efficient measurement technique (compressed sensing). This work, published in Linear Algebra and Its Applications, strengthens the theoretical underpinnings of modern data science techniques.<br /><br /><strong>Broader Impacts<br /></strong><br />The results of this project have practical and societal benefits:<br /><br /><span style=\"text-decoration: underline;\"><strong>Energy-Efficient AI</strong></span>: Our quantization methods can help enable AI models to run on low-power devices, such as smartphones or sensors, or to make them cheaper to run on higher end devices.<br /><br /><span style=\"text-decoration: underline;\"><strong>Advancing Research and Industry:</strong></span> Collaborations with industry partners ensured our methods address real-world challenges, such as optimizing AI models.<br /><br /><span style=\"text-decoration: underline;\"><strong>Educational Opportunities:</strong></span> Students and postdoctoral researchers played key roles in this project, gaining skills in algorithm design, theory, and practical implementation. Several have since transitioned to impactful careers in academia and industry.<br /><br /><span style=\"text-decoration: underline;\"><strong>Knowledge Dissemination:</strong></span> Results were shared widely through high-profile journals, conferences, and public forums, ensuring broad exposure and encouraging adoption of these methods.<br /><br /><br /></p><br>\n<p>\n Last Modified: 11/28/2024<br>\nModified by: Rayan&nbsp;Saab</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nProject Title: Task-Aware Quantization in Data Science: Theory and Fast Algorithms\n\nOverview:Quantization is the process of approximating data by reducing it to a smaller, more manageable set of values, enabling its representation and processing with a small number of bits. This process is critical for efficiently storing and processing large datasets, training AI models, and running applications on devices with limited memory and power. This project developed new quantization methods and established a solid mathematical foundation for their use, motivated by applications in data science and machine learning.\nWe focused on three main objectives: 1) Compressing large machine learning models, such as deep neural networks, so they use less memory and power without sacrificing performance. 2) Designing efficient algorithms so that small devices, like smartphones and sensors, can process data with limited resources. 3) Developing efficient adaptive ways to collect and analyze data for applications like recommendation systems, where gathering information is expensive or time-consuming.\r\n\n\n\nAn overaching goal of this work was to couple practical efficiency with rigorous theoretical guarantees.\r\n\n\nIntellectual Merit\n\nCompressing AI Models: Our research led to efficient methods for shrinking neural networks by quantizing their internal parameters. For instance, one approach reduced the parameters to just three possible values ({-1, 0, 1}), dramatically cutting memory requirements while maintaining accuracy. This method, published in the Journal of Machine Learning Research, is simple enough to run on low-power devices, making advanced AI more accessible for everyday applications.\nBuilding on this, we extended the method to handle more complex neural network architectures, including convolutional layers commonly used in image processing. These refinements, published in the SIAM Journal on Mathematics of Data Science, come with theoretical guarantees and were shown to perform well in practical scenarios. We also introduced stochastic variations of these methods to handle deep networks more effectively, removing prior limitations on the types of data they could handle.\nCollaborating with industry partners, we also developed a new framework for optimizing low-bit computations in AI models. This work, currently under review, demonstrates strong performance in tasks like image classification and language generation.\n\nEnabling Small Devices to Process Data Efficiently:To meet the demands of small devices with limited memory, we designed a fast, distance-preserving method for embedding large datasets into compact binary codes. This technique allows devices to quickly and accurately estimate similarities between data pointsessential for applications like searching for similar images or recommending products. Tests on real-world datasets showed that our method is both faster and more accurate than many existing techniques, as presented at ICLR 2021. We also explored how certain techniques known as noise-shaping quantization techniques could be used to compress important features (Random Fourier Features), which are a popular tool in machine learning. This work, published in Information and Inference: A Journal of the IMA, demonstrated how quantization can maintain computational efficiency while preserving accuracy in tasks that rely on kernel methods.\n\nImproving Data Collection and Analysis: Motivated by recommendation systems and other applications where data collection can be expensive, we developed adaptive measurement techniques to maximize the value of each collected data point. By leveraging mathematical insights about geometric properties in high-dimensional spaces, we created algorithms that efficiently select measurements to improve accuracy. These findings were published in ACHA.\n\nOther Contributions: We made significant advances in understanding mathematical structures critical to quantization and data processing. For example, we studied the behavior (namely the singular vectors) of certain important matrices, known as higher order difference matrices, proving new bounds that can be leveraged to understand the behavior of quantization algorithms when used for a particular efficient measurement technique (compressed sensing). This work, published in Linear Algebra and Its Applications, strengthens the theoretical underpinnings of modern data science techniques.\n\nBroader Impacts\n\nThe results of this project have practical and societal benefits:\n\nEnergy-Efficient AI: Our quantization methods can help enable AI models to run on low-power devices, such as smartphones or sensors, or to make them cheaper to run on higher end devices.\n\nAdvancing Research and Industry: Collaborations with industry partners ensured our methods address real-world challenges, such as optimizing AI models.\n\nEducational Opportunities: Students and postdoctoral researchers played key roles in this project, gaining skills in algorithm design, theory, and practical implementation. Several have since transitioned to impactful careers in academia and industry.\n\nKnowledge Dissemination: Results were shared widely through high-profile journals, conferences, and public forums, ensuring broad exposure and encouraging adoption of these methods.\n\n\n\t\t\t\t\tLast Modified: 11/28/2024\n\n\t\t\t\t\tSubmitted by: RayanSaab\n"
 }
}