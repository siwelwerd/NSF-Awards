{
 "awd_id": "2040222",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: Programming Tools for Adaptive Data Analysis",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2020-01-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 152696.0,
 "awd_amount": 152696.0,
 "awd_min_amd_letter_date": "2020-08-18",
 "awd_max_amd_letter_date": "2020-10-14",
 "awd_abstract_narration": "False discovery, or overfitting, occurs when an empirical researcher draws a conclusion based on a dataset that does not generalize to new data.  Although there are many statistical methods for preventing false discovery, most are designed for static data analysis, where a dataset is used only once.  However, modern data analysis is adaptive, and often the same datasets are reused for multiple studies by multiple researchers.  Adaptivity has been identified by statisticians as one cause of non-reproducible research, and this project?s broader significance and importance will be to begin addressing this problem.  Specifically, this project will build a prototype programming tool for preventing false discovery arising from adaptive data analysis.  The intellectual merits are to incorporate and extend recent theoretical advances on this problem into a programming framework that allows researchers to analyze datasets adaptively with robust guarantees that overfitting will not occur.\r\n\r\nThe project builds on a surprising recent connection between differential privacy and false discovery, a robust statistical guarantee that emerged recently to protect the privacy of sensitive data. This line of work shows that when data is analyzed in a differentially private way, then false discoveries cannot occur. Differential privacy is also programmable, and allows complex differentially private algorithms to be built from simple components, so it is an ideal programming framework for adaptive data analysis.  This project is extending existing differentially private programming frameworks to adaptive data analysis.  The PIs are also developing new algorithmic and programming languages tools for adaptive data analysis, and incorporating them into the first prototype system for this application.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Marco",
   "pi_last_name": "Gaboardi",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Marco G Gaboardi",
   "pi_email_addr": "gaboardi@bu.edu",
   "nsf_id": "000702904",
   "pi_start_date": "2020-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Trustees of Boston University",
  "inst_street_address": "1 SILBER WAY",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173534365",
  "inst_zip_code": "022151703",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "TRUSTEES OF BOSTON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "THL6A6JLE1S7"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of Boston University",
  "perf_str_addr": "881 Commonwealth Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "022151300",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 152696.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p dir=\"ltr\"><span>A false discovery occurs when a researcher draws a conclusion based on a dataset that does not generalize to new data.&nbsp; Despite decades of research by the statistics community, false discovery remains a source of consternation in the empirical sciences.&nbsp; While there are many sources of false discovery, one that has been receiving increased attention is adaptivity?most statistical tools are designed for static data analysis, where a dataset is used once, whereas modern data analysis is adaptive, and the same datasets are reused in complex ways that invalidate classical methods for preventing false discovery.&nbsp; Adaptivity has even been blamed for a ?statistical crisis? in science.</span></p>\n<p>The outcome of this project was to develop new algorithmic and programming-language tools to ensure statistically sound adaptive data analysis.&nbsp; These tools are based on a recent surprising connection between false discovery and differential privacy, a criterion that emerged for protecting the privacy of sensitive data.&nbsp; This line of work showed that when data is analyzed in a differentially private manner, then false discoveries cannot occur, leading to new methods for preventing false discovery in adaptive data analysis that have greater statistical power than all previous methods.&nbsp; Perhaps most remarkably, these methods are also programmable, allowing complex statistical algorithms to be built from simple ?queries,? so it is an ideal programming framework for adaptive data analysis.&nbsp;</p>\n<p>The technical core of our project was twofold:&nbsp; to develop practical algorithmic tools for adaptive data analysis and to develop new programming language tools for adaptive data analysis.&nbsp; The PIs are continuing to incorporate these tools into a prototype system to support non-expert users engaging in adaptive data analysis.</p>\n<p>On the programming language side, this project led to many technical advances to the state-of-the-art, namely:</p>\n<ul>\n<li>Novel program logics and type systems to reason about properties of probabilistic programs in terms of distributions and expectation.</li>\n<li>New program analysis techniques to reason about the number of rounds of adaptivity in a program representing an adaptive data analysis.</li>\n<li>New type systems to reason about adversarial probabilistic computations.</li>\n<li>New program logics to reason about relaxations of differential privacy.&nbsp;</li>\n</ul><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/12/2021<br>\n\t\t\t\t\tModified by: Marco&nbsp;G&nbsp;Gaboardi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "A false discovery occurs when a researcher draws a conclusion based on a dataset that does not generalize to new data.  Despite decades of research by the statistics community, false discovery remains a source of consternation in the empirical sciences.  While there are many sources of false discovery, one that has been receiving increased attention is adaptivity?most statistical tools are designed for static data analysis, where a dataset is used once, whereas modern data analysis is adaptive, and the same datasets are reused in complex ways that invalidate classical methods for preventing false discovery.  Adaptivity has even been blamed for a ?statistical crisis? in science.\n\nThe outcome of this project was to develop new algorithmic and programming-language tools to ensure statistically sound adaptive data analysis.  These tools are based on a recent surprising connection between false discovery and differential privacy, a criterion that emerged for protecting the privacy of sensitive data.  This line of work showed that when data is analyzed in a differentially private manner, then false discoveries cannot occur, leading to new methods for preventing false discovery in adaptive data analysis that have greater statistical power than all previous methods.  Perhaps most remarkably, these methods are also programmable, allowing complex statistical algorithms to be built from simple ?queries,? so it is an ideal programming framework for adaptive data analysis. \n\nThe technical core of our project was twofold:  to develop practical algorithmic tools for adaptive data analysis and to develop new programming language tools for adaptive data analysis.  The PIs are continuing to incorporate these tools into a prototype system to support non-expert users engaging in adaptive data analysis.\n\nOn the programming language side, this project led to many technical advances to the state-of-the-art, namely:\n\nNovel program logics and type systems to reason about properties of probabilistic programs in terms of distributions and expectation.\nNew program analysis techniques to reason about the number of rounds of adaptivity in a program representing an adaptive data analysis.\nNew type systems to reason about adversarial probabilistic computations.\nNew program logics to reason about relaxations of differential privacy. \n\n\n\t\t\t\t\tLast Modified: 12/12/2021\n\n\t\t\t\t\tSubmitted by: Marco G Gaboardi"
 }
}