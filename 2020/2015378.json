{
 "awd_id": "2015378",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Statistical Properties of Privacy-Preserving Algorithms: Optimality, Adaptivity, and Stability",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-07-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 100000.0,
 "awd_amount": 100000.0,
 "awd_min_amd_letter_date": "2020-06-19",
 "awd_max_amd_letter_date": "2022-06-27",
 "awd_abstract_narration": "The increasing popularity of large-scale data analysis raises privacy concerns. The tremendous amount of data collected by data curators such as search engines, social network platforms, and medical institutions contain potentially sensitive information about individuals. With the rapid emergence of data-driven technologies, it has been increasingly important to respect the privacy of individuals. A central question is: how to build privacy-preserving algorithms to protect individual privacy without sacrificing the utility in a large degree? This project aims to develop rigorous tools and methodologies to analyze privacy-preserving algorithms.\r\n \r\nThe research objective of this project is to develop statistical theories and applications of privacy-preserving algorithms. In particular, the technical goals include (1) the statistical optimality of privacy-preserving algorithms in parametric models; (2) the statistical optimality and adaptivity of privacy-preserving algorithms in nonparametric regression, with focus on random forests algorithms, and; (3) the stability of privacy-preserving algorithms with applications to post-selection inference and adversarial robustness of deep neural networks. The new theoretical understandings will not only shed light on current privacy-preserving methodologies but also lead to new methodological developments of stable and adversarially robust algorithms.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Linjun",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Linjun Zhang",
   "pi_email_addr": "linjun.zhang@rutgers.edu",
   "nsf_id": "000816347",
   "pi_start_date": "2020-06-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "110 Frelinghuysen Rd",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 32379.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 33720.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 33901.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The primary objectives of this project were to develop differentially private algorithms across various statistical models and to investigate the role these privacy-preserving algorithms play in the adversarial robustness of deep neural networks. These algorithms aim to ensure the secure handling of data, maintaining the delicate balance between privacy and the need for high-quality statistical information.</p>\n<p>The proposed algorithms and theoretical models are intended to form a solid foundation for a comprehensive understanding of the intricate trade-off between privacy preservation and statistical accuracy. This is a critical consideration in an era where data privacy is paramount and yet statistical validity is essential for informed decision-making in various disciplines.</p>\n<p>The Principal Investigator (PI) has been vigilant in disseminating the project's findings, showcasing them at several conferences to broaden both the comprehension of the results and the overall awareness of data privacy issues. This extends to a variety of fields beyond statistics, further highlighting the interdisciplinary nature of this research. Additionally, the PI took an active role in the organization of a workshop focused on differential privacy and Census noisy-measurement files. The goal of this workshop was to provide a practical guide for the users of Census data, delineating general methodologies to maintain differential privacy.</p>\n<p>The PI has displayed an active involvement in the study of differential privacy, a field that demonstrates the interplay between statistics, computer science, and social science. The research methodologies developed in this project are expected to have far-reaching impacts not only on these individual disciplines but also on the way they intersect and interact.</p>\n<p>Throughout this process, the PI has been mentoring a group of students across various academic levels: five PhD candidates, and ten undergraduates. The topics they have been focusing on are closely related to the core themes of this project, including differential privacy, transfer learning, algorithmic fairness, and representation learning. This diverse group of students' participation has enabled the exploration of these topics from multiple perspectives, while their contributions have added depth and breadth to the project's overall scope.</p>\n<p class=\"p1\">&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/02/2023<br>\n\t\t\t\t\tModified by: Linjun&nbsp;Zhang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe primary objectives of this project were to develop differentially private algorithms across various statistical models and to investigate the role these privacy-preserving algorithms play in the adversarial robustness of deep neural networks. These algorithms aim to ensure the secure handling of data, maintaining the delicate balance between privacy and the need for high-quality statistical information.\n\nThe proposed algorithms and theoretical models are intended to form a solid foundation for a comprehensive understanding of the intricate trade-off between privacy preservation and statistical accuracy. This is a critical consideration in an era where data privacy is paramount and yet statistical validity is essential for informed decision-making in various disciplines.\n\nThe Principal Investigator (PI) has been vigilant in disseminating the project's findings, showcasing them at several conferences to broaden both the comprehension of the results and the overall awareness of data privacy issues. This extends to a variety of fields beyond statistics, further highlighting the interdisciplinary nature of this research. Additionally, the PI took an active role in the organization of a workshop focused on differential privacy and Census noisy-measurement files. The goal of this workshop was to provide a practical guide for the users of Census data, delineating general methodologies to maintain differential privacy.\n\nThe PI has displayed an active involvement in the study of differential privacy, a field that demonstrates the interplay between statistics, computer science, and social science. The research methodologies developed in this project are expected to have far-reaching impacts not only on these individual disciplines but also on the way they intersect and interact.\n\nThroughout this process, the PI has been mentoring a group of students across various academic levels: five PhD candidates, and ten undergraduates. The topics they have been focusing on are closely related to the core themes of this project, including differential privacy, transfer learning, algorithmic fairness, and representation learning. This diverse group of students' participation has enabled the exploration of these topics from multiple perspectives, while their contributions have added depth and breadth to the project's overall scope.\n \n\n\t\t\t\t\tLast Modified: 10/02/2023\n\n\t\t\t\t\tSubmitted by: Linjun Zhang"
 }
}