{
 "awd_id": "2027176",
 "agcy_id": "NSF",
 "tran_type": "CoopAgrmnt",
 "awd_istr_txt": "Cooperative Agreement",
 "awd_titl_txt": "Collaborative Research: Chameleon Phase III: A Large-Scale, Reconfigurable Experimental Environment for Cloud Research",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922935",
 "po_email": "dmedhi@nsf.gov",
 "po_sign_block_name": "Deepankar Medhi",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 3001028.0,
 "awd_amount": 3001028.0,
 "awd_min_amd_letter_date": "2020-08-12",
 "awd_max_amd_letter_date": "2022-09-08",
 "awd_abstract_narration": "Chameleon is a deeply reconfigurable experimental testbed supporting Computer Science (CS) systems experimentation. The platform consists of two sites, University of Chicago (UC) and Texas Advanced Computing Center (TACC), along with support functionalities from Northwestern University and the University of North Carolina. the platform balances investment in large-scale hardware to support Big Compute and Big Data experimentation with diversity reflected by smaller clusters of graphic processing units (GPUs), field programmable gate arrays (FPGAs), specialized architectures, and innovative networking hardware. Users can reconfigure this hardware at bare-metal level, boot from custom kernel, get access to serial console, or provision and reconfigure Software Defined Networking (SDN)-enabled switches. Since its public availability in July 2015, Chameleon has attracted a community of over 4,000 users working on over 600 education and research projects.\r\n\r\nIn Phase III, Chameleon will greatly expand its core capabilities by adding new hardware and new features. The range of supported experiments will expand to include Internet of Things (IoT) and edge computing, a broader range of networking experiments, and experimentation with disaggregated hardware. The system will also expand its support for reproducibility by providing tools that allow investigators to package their experiments for replication, and making it possible to publish, discover, and cite them easily. Finally, phase 3 will see a continuation of work on packaging CHameleon Infrastructure, known as CHI-in-a-Box, which allows others to deploy and manage testbeds similar to Chameleon. \r\n\r\nThe Chameleon project will continue its mission of providing a platform for CS research and education in cloud computing, a critical skillset for future computing professionals. Unlike traditional experimental platforms, Chameleon is built on a mainstream open source cloud technology (OpenStack); this not only means that its users and operators gain familiarity with mainstream cloud functions simply by working with the testbed \u2013 but also that open source contributions by the Chameleon project directly impact a system widely used in the cloud industry. Finally, through its support of experiment management and repeatability, Chameleon impacts CS experimental methodology and makes more efficient research possible. \r\n\r\nTo use Chameleon or learn more about the system, visit www.chameleoncloud.org. For anyone interested in the development side of the system or the packaging of Chameleon, i.e., CHI-in-a-Box, visit the github repository at https://github.com/ChameleonCloud/chi-in-a-box/wiki. If a user would like to explore traces from Chameleon to date, see https://www.scienceclouds.org/cloud-traces/. These sites will be maintained throughout the duration of the project.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Stanzione",
   "pi_mid_init": "",
   "pi_sufx_name": "Jr",
   "pi_full_name": "Daniel Stanzione",
   "pi_email_addr": "dan@tacc.utexas.edu",
   "nsf_id": "000193108",
   "pi_start_date": "2020-08-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas",
  "perf_str_addr": "3925 W Braker Lane, Suite 3340",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787595316",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "TX37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "289000",
   "pgm_ele_name": "CISE Research Resources"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8002",
   "pgm_ref_txt": "CISE Research Resources"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0123",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 1893211.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 659686.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 448131.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-fc86761a-7fff-e141-0727-fae358117562\">\r\n<p dir=\"ltr\"><span>The Chameleon project designed and deployed a scientific instrument: a large-scale, deeply reconfigurable testbed designed specifically to support cloud computing research. Chameleon differs substantially from other compute resources in that it is directly focused on supporting systems research in computer science. This type of research focuses on investigating challenges in the low level of system stack including designing new operating systems and virtualization solutions, investigating performance variability, power management, or building new networking protocols. While other scientific computing resources provide tremendous computing power for engineering and domain science research, as production systems, the computers themselves and their system software components cannot be changed by the end user. Chameleon, in contrast, provides tremendous flexibility to computing researchers; users can start with \"bare metal\" allocations and deploy them on a range of innovative hardware types.</span></p>\r\n<p dir=\"ltr\"><span>In Phase 3, Chameleon significantly expanded its capabilities by extending from cloud to edge computing through CHI@Edge, allowing researchers to explore the emerging edge-to-cloud computing continuum. This expansion created a fleet of over 40 edge devices, including 20 NVIDIA Jetson Nanos, 28 Raspberry Pis, and 4 NVIDIA Jetson Xavier NX devices, along with support and tools for user device enrollment and management. The project also enhanced its core hardware offerings with state-of-the-art computing resources including composable systems using Liqid and GigaIO technology, advanced GPU nodes such as NVIDIA A100s, and specialized architectures like Fujitsu A64FX ARM processors from the Fugaku supercomputer.</span></p>\r\n<p dir=\"ltr\"><span>A major achievement of Phase 3 was the maturation of CHI-in-a-Box, Chameleon's packaging of testbed infrastructure, which enabled the creation of seven new associate sites contributed entirely on a volunteer basis. This democratization of testbed operations allowed institutions to easily join the Chameleon ecosystem, including both long-running associate sites (like Northwestern University, NCAR with its ARM processors, and IIT with 80 nodes) and innovative \"pop-up\" sites configured for specific events - such as Purdue's contribution of 400 nodes for IndySCC 2022 and CU Boulder's provision of 164 nodes from their retired Summit cluster for IndySCC 2023. This expansion significantly broadened the range of resources available to researchers while making the operation of complex experimental testbeds more accessible to the broader community.</span></p>\r\n<p dir=\"ltr\"><span>Phase 3 saw substantial growth in educational usage and reproducible research support. The testbed supported over 150 educational projects engaging more than 2,000 users through university courses, summer schools, graduate research, workshops, and student competitions. New features were developed specifically to support educational use cases, including tools for managing large classes and \"experiment patterns\" that capture common experimental workflows. Simultaneously, Chameleon enhanced its support for reproducible research by working with over 12 major computer science conferences including SC, USENIX FAST, SIGMOD,&nbsp; and others to support their reproducible research evaluation processes. The Trovi artifact repository was developed to enable better discovery and sharing of experimental artifacts, with features to track impact and usage metrics. These initiatives helped establish reproducibility as a core practice in computer science research, with Chameleon becoming the default platform for several conferences' reproducibility initiatives.</span></p>\r\n<p dir=\"ltr\"><span>By the end of Phase 3, Chameleon had served over 11,000 users working on more than 1,200 unique projects in computer science research, education, and innovative applications. Users came from over 250 institutions across more than 100 countries, and their work resulted in more than 730 scientific publications. The testbed saw particularly strong usage in emerging areas such as machine learning and edge computing, while also supporting critical research in cybersecurity, operating systems, power management, and many other areas of computing research. Through its combination of innovative hardware, flexible infrastructure, and strong support for both research and education, Chameleon continues to serve as a vital instrument for advancing computer science research and education.</span></p>\r\n<div><span><br /></span></div>\r\n</span></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/25/2025<br>\nModified by: Daniel&nbsp;Stanzione</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\r\n\n\nThe Chameleon project designed and deployed a scientific instrument: a large-scale, deeply reconfigurable testbed designed specifically to support cloud computing research. Chameleon differs substantially from other compute resources in that it is directly focused on supporting systems research in computer science. This type of research focuses on investigating challenges in the low level of system stack including designing new operating systems and virtualization solutions, investigating performance variability, power management, or building new networking protocols. While other scientific computing resources provide tremendous computing power for engineering and domain science research, as production systems, the computers themselves and their system software components cannot be changed by the end user. Chameleon, in contrast, provides tremendous flexibility to computing researchers; users can start with \"bare metal\" allocations and deploy them on a range of innovative hardware types.\r\n\n\nIn Phase 3, Chameleon significantly expanded its capabilities by extending from cloud to edge computing through CHI@Edge, allowing researchers to explore the emerging edge-to-cloud computing continuum. This expansion created a fleet of over 40 edge devices, including 20 NVIDIA Jetson Nanos, 28 Raspberry Pis, and 4 NVIDIA Jetson Xavier NX devices, along with support and tools for user device enrollment and management. The project also enhanced its core hardware offerings with state-of-the-art computing resources including composable systems using Liqid and GigaIO technology, advanced GPU nodes such as NVIDIA A100s, and specialized architectures like Fujitsu A64FX ARM processors from the Fugaku supercomputer.\r\n\n\nA major achievement of Phase 3 was the maturation of CHI-in-a-Box, Chameleon's packaging of testbed infrastructure, which enabled the creation of seven new associate sites contributed entirely on a volunteer basis. This democratization of testbed operations allowed institutions to easily join the Chameleon ecosystem, including both long-running associate sites (like Northwestern University, NCAR with its ARM processors, and IIT with 80 nodes) and innovative \"pop-up\" sites configured for specific events - such as Purdue's contribution of 400 nodes for IndySCC 2022 and CU Boulder's provision of 164 nodes from their retired Summit cluster for IndySCC 2023. This expansion significantly broadened the range of resources available to researchers while making the operation of complex experimental testbeds more accessible to the broader community.\r\n\n\nPhase 3 saw substantial growth in educational usage and reproducible research support. The testbed supported over 150 educational projects engaging more than 2,000 users through university courses, summer schools, graduate research, workshops, and student competitions. New features were developed specifically to support educational use cases, including tools for managing large classes and \"experiment patterns\" that capture common experimental workflows. Simultaneously, Chameleon enhanced its support for reproducible research by working with over 12 major computer science conferences including SC, USENIX FAST, SIGMOD, and others to support their reproducible research evaluation processes. The Trovi artifact repository was developed to enable better discovery and sharing of experimental artifacts, with features to track impact and usage metrics. These initiatives helped establish reproducibility as a core practice in computer science research, with Chameleon becoming the default platform for several conferences' reproducibility initiatives.\r\n\n\nBy the end of Phase 3, Chameleon had served over 11,000 users working on more than 1,200 unique projects in computer science research, education, and innovative applications. Users came from over 250 institutions across more than 100 countries, and their work resulted in more than 730 scientific publications. The testbed saw particularly strong usage in emerging areas such as machine learning and edge computing, while also supporting critical research in cybersecurity, operating systems, power management, and many other areas of computing research. Through its combination of innovative hardware, flexible infrastructure, and strong support for both research and education, Chameleon continues to serve as a vital instrument for advancing computer science research and education.\r\n\n\r\n\r\n\n\n\t\t\t\t\tLast Modified: 02/25/2025\n\n\t\t\t\t\tSubmitted by: DanielStanzione\n"
 }
}