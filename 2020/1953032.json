{
 "awd_id": "1953032",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Mixed-Autonomy Traffic Networks: Routing Games and Learning Human Choice Models",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": "7032925394",
 "po_email": "rnash@nsf.gov",
 "po_sign_block_name": "Richard Nash",
 "awd_eff_date": "2020-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 180000.0,
 "awd_amount": 180000.0,
 "awd_min_amd_letter_date": "2020-08-10",
 "awd_max_amd_letter_date": "2020-08-10",
 "awd_abstract_narration": "Autonomous and connected vehicles are soon becoming a significant part of roads normally used by human drivers. Such vehicles hold the promise of safer streets, better fuel efficiency, more flexibility in tailoring to specific drivers\u2019 needs, and time savings. However, the appearance of autonomous vehicles driving on roads shared by human-driven cars introduce many interesting and timely challenges. The goal of this proposal is to study (i) traffic networks with mixed autonomy where a fraction of cars are autonomous and the rest are human-driven, and (ii) how humans choose their routes in a traffic network given different options of autonomous service and prices. By studying models of humans\u2019 choices and investigating the characterizations of traffic flow in networks with mixed autonomy, the project develops routing policies to lead the network to an efficient equilibrium with low average latency.\r\n\r\nThis proposal aims to study routing games and human choice models for traffic networks with mixed autonomy. Many studies have shown that mobility can be enhanced in traffic networks such as freeways or signalized intersections when all cars are autonomous; however, such improvement is far from clear for a network with mixed autonomy. The goal of this project is to study the game theory of mixed-autonomy traffic networks and control the autonomous cars\u2019 routing decisions such that the system reaches an optimum equilibrium. Moreover, a novel approach in learning human choices of prices in autonomous transportation services versus latency, or travel time, is developed. Finally, using the well-known fundamental diagram of traffic and cell-transmission model, a dynamic mixed-autonomy traffic model is introduced. Using this dynamic model, we will leverage tools from reinforcement learning to route autonomous cars dynamically and optimally. The proposed research considers both theoretical study of routing games as well as implementation of the developed algorithms in traffic simulators, in particular simulation of Urban Mobility (SUMO). The learned human choice models will also be validated through human subject studies.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dorsa",
   "pi_last_name": "Sadigh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dorsa Sadigh",
   "pi_email_addr": "dorsa@cs.stanford.edu",
   "nsf_id": "000769760",
   "pi_start_date": "2020-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "353 Serra Mall, Gates Building",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943055008",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760700",
   "pgm_ele_name": "EPCN-Energy-Power-Ctrl-Netwrks"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "092E",
   "pgm_ref_txt": "Control systems & applications"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 180000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>In this project, we studied the problem of better understanding mixed-autonomy traffic networks. Many studies have shown that mobility can be enhanced in traffic networks such as freeways or signalized intersections when all cars are autonomous; however, such improvement is far from clear for a network with mixed autonomy. We focus on the mixed-autonomy setting, and develop formal technique that represent the relationship between traffic flow, latency, and density in these scenarios. We use these formal models to characterize different equilibria that emerge in mixed-autonomy traffic network, and further develop a body of active learning algorithms to better understand human preferences and incentivize them toward specific routing choices through pricing mechanisms. Finally we study dynamic routing of autonomous vehicles in mixed autonomy networks using reinforcement learning techniques. Our results demonstrate these algorithms are in fact able to incentivize human drivers to take routes that effectively reduce congestions, and our techniques are able to accurately model human preferences.</span></p>\n<p><span>This work directly impacts the application of autonomous driving and traffic, as it can shape how a fleet of autonomous vehicles interact with other human-driven vehicles on the road. This can potentially have impacts in other human-autonomy systems beyond the space of driving and traffic, and allow for effective incentive design and human modeling when a fleet of autonomous systems interact with other human operators.</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/26/2023<br>\nModified by: Dorsa&nbsp;Sadigh</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn this project, we studied the problem of better understanding mixed-autonomy traffic networks. Many studies have shown that mobility can be enhanced in traffic networks such as freeways or signalized intersections when all cars are autonomous; however, such improvement is far from clear for a network with mixed autonomy. We focus on the mixed-autonomy setting, and develop formal technique that represent the relationship between traffic flow, latency, and density in these scenarios. We use these formal models to characterize different equilibria that emerge in mixed-autonomy traffic network, and further develop a body of active learning algorithms to better understand human preferences and incentivize them toward specific routing choices through pricing mechanisms. Finally we study dynamic routing of autonomous vehicles in mixed autonomy networks using reinforcement learning techniques. Our results demonstrate these algorithms are in fact able to incentivize human drivers to take routes that effectively reduce congestions, and our techniques are able to accurately model human preferences.\n\n\nThis work directly impacts the application of autonomous driving and traffic, as it can shape how a fleet of autonomous vehicles interact with other human-driven vehicles on the road. This can potentially have impacts in other human-autonomy systems beyond the space of driving and traffic, and allow for effective incentive design and human modeling when a fleet of autonomous systems interact with other human operators.\n\n\n\t\t\t\t\tLast Modified: 11/26/2023\n\n\t\t\t\t\tSubmitted by: DorsaSadigh\n"
 }
}