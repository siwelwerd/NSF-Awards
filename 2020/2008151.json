{
 "awd_id": "2008151",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS Core: Small: Importance-Aware Compressive Inference for Efficient Embedded Vision",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032920000",
 "po_email": "doliveir@nsf.gov",
 "po_sign_block_name": "Daniela Oliveira",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 499737.0,
 "awd_amount": 499737.0,
 "awd_min_amd_letter_date": "2020-08-17",
 "awd_max_amd_letter_date": "2020-10-19",
 "awd_abstract_narration": "This project explores the concept of Compressive Inference in the context of energy-efficient and low-latency machine learning and artificial intelligence (AI) applications. Compressive Inference is the biologically inspired idea of using highly heterogeneous, multi-round,feedback-controlled sampling and analysis of signals to minimize latency and energy consumption while maximizing inference accuracy, which stands in contrast to the commonly optimized but often less relevant objective of signal reconstruction accuracy. Methods of restructuring and compressing knowledge representations to improve efficiency are also being explored. The project focuses on applications and systems facing tight energy consumption and latency constraints, namely computer vision applications running on low-power embedded systems, although many of the ideas developed will have application in other domains, e.g., datacenter-based machine learning and AI applications.\r\n\r\nBased on preliminary results, it is likely that the project will enable order-of-magnitude improvements in machine learning and AI application inference latencies and energy consumptions, thereby enabling the deployment of sophisticated analysis techniques in applications where they were previously impractical, e.g., low-cost home security systems and agricultural sensing applications, as well as applications where sophisticated analysis was detrimentally resource and power hungry, e.g., autonomous driving and wearable vision-based assistants. The resulting improvement in efficiency will enable local, on-device learning, thereby making it possible for machine learning and AI systems to adapt to their environments, thereby reducing the tendency to perform poorly on data dissimilar to samples in centralized training datasets. The project also has an educational component, in which students with a broad range of backgrounds will learn about state-of-the-art approaches to machine learning, AI, and embedded system design.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Dick",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Robert P Dick",
   "pi_email_addr": "dickrp@umich.edu",
   "nsf_id": "000167402",
   "pi_start_date": "2020-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "3003 South State St. Room 1062",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091274",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 499737.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project had the goal of developing new ideas that enable computers to efficiently make correct decisions. Computers running artificial intelligence (AI) and machine learning algorithms are already capable of making good decisions, and in many applications such as determining what a picture shows or diagnosing a disease, they do as well as people. However, most AI systems require a lot of computer time and electrical energy for training and decision making. Although expensive, it's feasible for AI algorithms running in huge compute centers with large electrical power supplies. Unfortunately, it's often infeasible for AI algorithms running on embedded systems: computers other than servers and desktops such as those in vehicles, medical devices, and wearable electronics. Embedded systems with constraints on computation speed, instantaneous power consumption, and battery energy generally cannot support conventional compute-intensive and power-hungry AI algorithms. To develop techniques to make difficult decisions on such resource-constrained embedded systems, this project studied the most time- and energy-efficient decision-making systems known: biological organisms like humans.<br /><br />Biological visual information processing systems are very picky about the information they capture and analyze. For example, only a tiny part of your field of view contains dense information (in other words, has high-resolution). People direct their eyes sequentially to different things to gather information until they know enough to make a decision. They look at the most important and informative things based the decision they are trying to make and what they have already learned from previous glances. It turns out that this is extraordinarily efficient because it spends energy and time only on the small amount of information actually needed to make a correct decision. When this approach is replicated in a compact embedded system and compared with the conventional approach of capturing and analyzing everything at high resolution, it speeds up decisions and reduces energy consumption by eight times, and the decisions are just as good. Encouraged by this finding, the project studied and developed several other technologies for efficient inference and learning.<br /><br />Another way of improving efficient decision making is to simplify a model, making it smaller and reducing its computation and energy requirements. Removing (hopefully superfluous) network parameters is called \"pruning\". The project studied the effects of different approaches to pruning to determine the circumstances in which each enables the most improvement in efficiency with the least reduction in decision quality.<br /><br />Pushing AI efficiency to an extreme level without making incorrect decisions requires a deep understanding of how AI systems learn. The project studied how AI systems that generate images learn new concepts, for example \"shape\" and \"color\". It found that when generating an image requires complex concepts based on multiple simple concepts, a learning generative AI system is very bad at using the complex concepts until it has a nearly perfect grasp of every simple foundational concept upon which the complex concept builds. This suggests ways to make learning more efficient, e.g., by focusing on all poorly understood simple concepts before attempting to teach complex concepts.<br /><br />The project also developed ways to efficiently preserve user privacy when data are gathered from personal embedded devices as mobile phones and wearable electronics. Transmitting images and audio recordings from personal devices can undermine user privacy. It might be possible to analyze the data locally, but each user may gather too little data to allow the local model to learn to make good decisions. Instead, many user device may learn from their local data and share what they have learned with each other via a server. This approach, called \"federated learning\" doesn't require that images and audio recordings ever leave user devices. However, existing approaches typically required that users locally \"label\" their data, essentially telling the AI system its meaning. This is too tedious for widespread use. Existing approaches also typically had difficulty dealing with heterogeneity data distributions; for example, pictures from Arizona look different than pictures from Michigan. This project developed a federated learning approach called Orchestra that needs no local labeling, is highly efficient, works well in the presence of heterogeneity, and ensures a provably low probability of reconstructing individual samples, such as images, at the server. One key idea was learning abstract (latent) vector-based representations of samples that make it practical to cluster together related samples and share locally learned information without revealing details about samples used for learning.<br /><br />The project's findings are publicly available and have been shared with researchers and designers. Several were directly used to improve specific AI applications including automatically detecting wildfires, video compression, and air pollution estimation.&nbsp; Some of these ideas are being used in the development of a wearable device that helps with childhood education. Project team members are also working to help a major social media company extend the privacy-preserving ideas developed in the project.</p><br>\n<p>\n Last Modified: 01/02/2024<br>\nModified by: Robert&nbsp;P&nbsp;Dick</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2008151/2008151_10698180_1704167205141_mult_capabilities1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2008151/2008151_10698180_1704167205141_mult_capabilities1--rgov-800width.png\" title=\"Concept distance from the training set governs the order in which compositional capabilities emerge\"><img src=\"/por/images/Reports/POR/2024/2008151/2008151_10698180_1704167205141_mult_capabilities1--rgov-66x44.png\" alt=\"Concept distance from the training set governs the order in which compositional capabilities emerge\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">(a) Concept graph (cube) depicting training data points (blue nodes) and\nconcept distances. (b) Compositional generalization sequenced by distance. (c) Delayed emergence of abilities to generate underrepresented attribute (gender) for distant classes.</div>\n<div class=\"imageCredit\">Maya Okawa</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Robert&nbsp;P&nbsp;Dick\n<div class=\"imageTitle\">Concept distance from the training set governs the order in which compositional capabilities emerge</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704061602704_fire1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704061602704_fire1--rgov-800width.png\" title=\"Analysis of two images containing fire\"><img src=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704061602704_fire1--rgov-66x44.png\" alt=\"Analysis of two images containing fire\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Images contain fire with different kinds of shapes, sizes, and illumination. The left column contains the original image and the right column contains the ground truth segmentation map. It is important to recognize flames that are present and also minimize false alarms.</div>\n<div class=\"imageCredit\">Tony Zhang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Robert&nbsp;P&nbsp;Dick\n<div class=\"imageTitle\">Analysis of two images containing fire</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704060983915_mech_mode_conn1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704060983915_mech_mode_conn1--rgov-800width.png\" title=\"Mechanistic similarity\"><img src=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704060983915_mech_mode_conn1--rgov-66x44.png\" alt=\"Mechanistic similarity\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Mechanistic similarity is based on how models respond to unit interventions. Yellow circles represent the prediction of  a given model (column) on a counterfactual image (row). Models with predictions invariant to the same interventions (&#952;1 &#8764; &#952;2 ) are mechanistically similar.</div>\n<div class=\"imageCredit\">Ekdeep Lubana</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Robert&nbsp;P&nbsp;Dick\n<div class=\"imageTitle\">Mechanistic similarity</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704060214648_orchestra1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704060214648_orchestra1--rgov-800width.png\" title=\"Orchestra privacy preserving federated learning algorithm\"><img src=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704060214648_orchestra1--rgov-66x44.png\" alt=\"Orchestra privacy preserving federated learning algorithm\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Pipeline: 1) Orchestra prompts clients to compute representations on local data. 2) Local centroids are computed. 3) Centroids aggregated on server. 4) Standard FL model averaging step. 5) Global centroids returned to clients. Local training: 6) Input sampled, transformed, and assigned to cluster.</div>\n<div class=\"imageCredit\">Project Participants</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Robert&nbsp;P&nbsp;Dick\n<div class=\"imageTitle\">Orchestra privacy preserving federated learning algorithm</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704062657959_fire2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704062657959_fire2--rgov-800width.png\" title=\"Comparison of fire segmentation methods\"><img src=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704062657959_fire2--rgov-66x44.png\" alt=\"Comparison of fire segmentation methods\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Comparison of fire segmentation methods on images with complex backgrounds and various flame sizes. a) Input image, b) Ground-truth segmentation, c) DeepLabv3, d) DRAN,\ne) AttaNet, f) BiSeNetV2, g) New method.</div>\n<div class=\"imageCredit\">Tony Zhang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Robert&nbsp;P&nbsp;Dick\n<div class=\"imageTitle\">Comparison of fire segmentation methods</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704060650696_orchestra2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704060650696_orchestra2--rgov-800width.png\" title=\"Orchestra robustness to heterogeneity\"><img src=\"/por/images/Reports/POR/2023/2008151/2008151_10698180_1704060650696_orchestra2--rgov-66x44.png\" alt=\"Orchestra robustness to heterogeneity\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">CIFAR-10 and 100 clients used to compare Orchestra against federated versions of centralized SSL techniques. Under the linear probe protocol, we see that direct extension methods are sensitive to heterogeneity, while Orchestra remains robust and achieves better absolute accuracy.</div>\n<div class=\"imageCredit\">Ekdeep Lubana</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Robert&nbsp;P&nbsp;Dick\n<div class=\"imageTitle\">Orchestra robustness to heterogeneity</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project had the goal of developing new ideas that enable computers to efficiently make correct decisions. Computers running artificial intelligence (AI) and machine learning algorithms are already capable of making good decisions, and in many applications such as determining what a picture shows or diagnosing a disease, they do as well as people. However, most AI systems require a lot of computer time and electrical energy for training and decision making. Although expensive, it's feasible for AI algorithms running in huge compute centers with large electrical power supplies. Unfortunately, it's often infeasible for AI algorithms running on embedded systems: computers other than servers and desktops such as those in vehicles, medical devices, and wearable electronics. Embedded systems with constraints on computation speed, instantaneous power consumption, and battery energy generally cannot support conventional compute-intensive and power-hungry AI algorithms. To develop techniques to make difficult decisions on such resource-constrained embedded systems, this project studied the most time- and energy-efficient decision-making systems known: biological organisms like humans.\n\nBiological visual information processing systems are very picky about the information they capture and analyze. For example, only a tiny part of your field of view contains dense information (in other words, has high-resolution). People direct their eyes sequentially to different things to gather information until they know enough to make a decision. They look at the most important and informative things based the decision they are trying to make and what they have already learned from previous glances. It turns out that this is extraordinarily efficient because it spends energy and time only on the small amount of information actually needed to make a correct decision. When this approach is replicated in a compact embedded system and compared with the conventional approach of capturing and analyzing everything at high resolution, it speeds up decisions and reduces energy consumption by eight times, and the decisions are just as good. Encouraged by this finding, the project studied and developed several other technologies for efficient inference and learning.\n\nAnother way of improving efficient decision making is to simplify a model, making it smaller and reducing its computation and energy requirements. Removing (hopefully superfluous) network parameters is called \"pruning\". The project studied the effects of different approaches to pruning to determine the circumstances in which each enables the most improvement in efficiency with the least reduction in decision quality.\n\nPushing AI efficiency to an extreme level without making incorrect decisions requires a deep understanding of how AI systems learn. The project studied how AI systems that generate images learn new concepts, for example \"shape\" and \"color\". It found that when generating an image requires complex concepts based on multiple simple concepts, a learning generative AI system is very bad at using the complex concepts until it has a nearly perfect grasp of every simple foundational concept upon which the complex concept builds. This suggests ways to make learning more efficient, e.g., by focusing on all poorly understood simple concepts before attempting to teach complex concepts.\n\nThe project also developed ways to efficiently preserve user privacy when data are gathered from personal embedded devices as mobile phones and wearable electronics. Transmitting images and audio recordings from personal devices can undermine user privacy. It might be possible to analyze the data locally, but each user may gather too little data to allow the local model to learn to make good decisions. Instead, many user device may learn from their local data and share what they have learned with each other via a server. This approach, called \"federated learning\" doesn't require that images and audio recordings ever leave user devices. However, existing approaches typically required that users locally \"label\" their data, essentially telling the AI system its meaning. This is too tedious for widespread use. Existing approaches also typically had difficulty dealing with heterogeneity data distributions; for example, pictures from Arizona look different than pictures from Michigan. This project developed a federated learning approach called Orchestra that needs no local labeling, is highly efficient, works well in the presence of heterogeneity, and ensures a provably low probability of reconstructing individual samples, such as images, at the server. One key idea was learning abstract (latent) vector-based representations of samples that make it practical to cluster together related samples and share locally learned information without revealing details about samples used for learning.\n\nThe project's findings are publicly available and have been shared with researchers and designers. Several were directly used to improve specific AI applications including automatically detecting wildfires, video compression, and air pollution estimation. Some of these ideas are being used in the development of a wearable device that helps with childhood education. Project team members are also working to help a major social media company extend the privacy-preserving ideas developed in the project.\t\t\t\t\tLast Modified: 01/02/2024\n\n\t\t\t\t\tSubmitted by: RobertPDick\n"
 }
}