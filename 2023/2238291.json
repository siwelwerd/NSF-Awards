{
 "awd_id": "2238291",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Scalable and Adaptable Sparsity-driven Methods for more Efficient AI Systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2023-03-01",
 "awd_exp_date": "2028-02-29",
 "tot_intn_awd_amt": 550306.0,
 "awd_amount": 320335.0,
 "awd_min_amd_letter_date": "2023-01-25",
 "awd_max_amd_letter_date": "2025-04-02",
 "awd_abstract_narration": "Artificial Intelligence (AI) and, in particular, Deep Neural Networks (DNN) have achieved better than human accuracy on many cognitive tasks involving images, natural language processing, and protein structure, among others.  Unfortunately, due to high data processing demands, AI systems are typically run on power-hungry specialized computing hardware.  Quantization, or approximation to smaller numerical values, has been used to reduce computing requirements.  However, the fixed low bit-width DNNs may suffer losses in accuracy due to quantization errors.  Many existing software solutions for quantization are also fixed or limited in bit-width choices.  To address this trade-off and leverage data sparsity, the research team will investigate state-of-the-art methods and develop novel data quantization, encoding, and compression algorithms to integrate with existing AI systems.  The methods developed have the potential to not only improve performance but also to reduce power requirements and boost the energy efficiency of AI systems.  They will enable AI applications such as DNN inference on small devices, thus reducing the load on cloud infrastructure, improving user experience, providing data privacy, and avoiding security risks.  The work proposed in this project has the potential to push the boundaries in many AI applications that run on energy storage-constrained devices, such as smart sensing, wearable devices, and autonomous driving.  The research and educational tools will facilitate and increase student and research community participation in advancing AI research.  The work will be conducted at a minority-serving institution, and the funding will support students from underrepresented groups.\r\n\r\nThe research goal of this project is to investigate quantization and compression methods that can leverage sparsity and improve efficiency in AI systems.  The principal investigator (PI) plans to study adaptable quantization and compression methods to leverage sparsity in AI systems while minimizing the overhead in non-sparse situations and minimizing accuracy loss.  The trade-off between accuracy and performance with the proposed methods will be studied and defined for automated tunable prioritization of either accuracy, performance, or energy efficiency.  The PI plans to develop a prototype with parallel execution of the proposed methods to make the proposed methods truly effective for data centers and advanced hardware architectures.  The proposed methods will be packaged into an AI vector primitives library that will be integrated with several popular Deep Learning frameworks as proof of concept, primarily targeting GPU and CPU systems.  An integration API will be developed for frameworks like Pytorch or TensorFlow to allow easy integration with other vector primitives.  Software libraries will be integrated with a web-based learning platform with automated feedback and a motivating environment to encourage student participation in solving AI challenges.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gheorghi",
   "pi_last_name": "Guzun",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gheorghi Guzun",
   "pi_email_addr": "gheorghi.guzun@sjsu.edu",
   "nsf_id": "000785319",
   "pi_start_date": "2023-01-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "San Jose State University Foundation",
  "inst_street_address": "210 N 4TH ST FL 4",
  "inst_street_address_2": "",
  "inst_city_name": "SAN JOSE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "4089241400",
  "inst_zip_code": "951125569",
  "inst_country_name": "United States",
  "cong_dist_code": "18",
  "st_cong_dist_code": "CA18",
  "org_lgl_bus_name": "SAN JOSE STATE UNIVERSITY RESEARCH FOUNDATION",
  "org_prnt_uei_num": "LJBXV5VF2BT9",
  "org_uei_num": "LJBXV5VF2BT9"
 },
 "perf_inst": {
  "perf_inst_name": "San Jose State University Foundation",
  "perf_str_addr": "210 4TH ST 3RD FL",
  "perf_city_name": "SAN JOSE",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "951125569",
  "perf_ctry_code": "US",
  "perf_cong_dist": "18",
  "perf_st_cong_dist": "CA18",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002728DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 211590.0
  },
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 108745.0
  }
 ],
 "por": null
}