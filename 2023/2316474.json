{
 "awd_id": "2316474",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Components, Correlates and Mechanisms of Object Recognition",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032924886",
 "po_email": "sfischer@nsf.gov",
 "po_sign_block_name": "Simon Fischer-Baum",
 "awd_eff_date": "2023-08-01",
 "awd_exp_date": "2026-07-31",
 "tot_intn_awd_amt": 386744.0,
 "awd_amount": 386744.0,
 "awd_min_amd_letter_date": "2023-07-24",
 "awd_max_amd_letter_date": "2023-07-24",
 "awd_abstract_narration": "Visual decisions play a crucial role in various occupations, impacting experts who make these decisions countless times each day. The project aims to understand how and why people vary their ability to make visual decisions. By analyzing the performance of large groups of participants across multiple tasks, the project seeks to uncover different aspects of visual abilities, particularly in relation to perception and memory. It compares general object recognition with other abilities routinely measured by psychologists and explores how visual abilities can help predict an individual's potential to become a perceptual expert. Additional activities engage high school students and teach them about the benefits of using less culturally-biased abilities for aptitude testing. The findings hold the potential to impact occupations reliant on visual decision-making, such as forensics and medical imaging, fostering inclusivity in testing and advancing research in visual cognition.\r\n\r\nEmploying a multivariate and latent variables approach, in which each construct is measured by several tasks, the project explores the structure of abilities that support object recognition. It explores how they relate to established abilities, how they predict the acquisition of expertise, and what mechanisms underlie these individual differences. The project develops a broad range of tasks with good psychometric properties for the study of object recognition, testing for a distinction between perceptual and mnemonic components. The work assesses the incremental predictive power of object recognition abilities over existing abilities, both general (like intelligence) and perceptual (like spatial processing) in the prediction of expertise acquired through multi-session learning. Collaborations with experts in detecting green gas emissions in satellite images and in dermatology training provide real-world situations in which to assess the predictive validity of the measures. The project also investigates three mechanisms through studies that explore the interaction between visual abilities and manipulations targeting well-known mechanisms of increasing complexity: Perceptual Differentiation, Statistical Learning, and Dimensional Learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Isabel",
   "pi_last_name": "Gauthier",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Isabel Gauthier",
   "pi_email_addr": "isabel.gauthier@vanderbilt.edu",
   "nsf_id": "000111918",
   "pi_start_date": "2023-07-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Vanderbilt University",
  "inst_street_address": "110 21ST AVE S",
  "inst_street_address_2": "",
  "inst_city_name": "NASHVILLE",
  "inst_state_code": "TN",
  "inst_state_name": "Tennessee",
  "inst_phone_num": "6153222631",
  "inst_zip_code": "372032416",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "TN05",
  "org_lgl_bus_name": "VANDERBILT UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "GTNBNWXJ12D5"
 },
 "perf_inst": {
  "perf_inst_name": "Vanderbilt University",
  "perf_str_addr": "110 21ST AVE S",
  "perf_city_name": "NASHVILLE",
  "perf_st_code": "TN",
  "perf_st_name": "Tennessee",
  "perf_zip_code": "372032416",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "TN05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  },
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 386744.0
  }
 ],
 "por": null
}