{
 "awd_id": "2301412",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RR: The Validity of Cartridge Case Comparison Conclusions Under Field-Based Conditions",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "reginald sheehan",
 "awd_eff_date": "2022-10-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 704337.0,
 "awd_amount": 149554.0,
 "awd_min_amd_letter_date": "2022-11-03",
 "awd_max_amd_letter_date": "2022-11-03",
 "awd_abstract_narration": "The National Research Council in 2009 called for scientists to quantify the validity of forensic techniques under realistic, field-based conditions. This call was prompted because it is increasingly apparent there are potential gaps in knowledge about the validity of a broad range of forensic techniques. Yet, the results of forensic science are often viewed as objective, and as such they are accepted and used by law enforcement and courts, and beyond. This project will investigate and quantify the validity of fired gun cartridge case comparison, a commonly used forensic technique. Because this technique relies on visual inspection of fired cartridge cases, it is a subjective process that is susceptible to human judgment error. However, even though this technique is subjective, it can still be a valid technique if the rate of human judgment error is low under a variety of field-based conditions. Because all forensic conclusions involve some degree of uncertainty, this research can advance understanding about the validity of forensic science. \r\n\r\nThe project will use a controlled experiment under field-based conditions to address whether conventional peer-review procedures effectively discover forensic errors before they are communicated to law enforcement and the courts, and whether the rate at which forensic errors occur varies based on the quality of toolmarks produced by different firearm brands. The project is grounded in psychological theory related to decision-making and cognitive processing, and it accords with calls for rigorous scientific tests to evaluate the validity of forensic techniques. The research brings scientific methods (including experimental manipulations) to the study of the validity of cartridge case comparisons, including the robustness (in the context of conventional peer-review procedures) and reliability (across different field-based conditions) of this technique. This research has the potential to transform forensic science practices by emphasizing the importance of communicating the degree of uncertainty that characterizes forensic conclusions, while identifying potential threats to conventional peer-review procedures. This project is jointly supported by National Science Foundation and the National Institute of Justice.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Stephanie",
   "pi_last_name": "Madon",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Stephanie J Madon",
   "pi_email_addr": "madon@asu.edu",
   "nsf_id": "000147167",
   "pi_start_date": "2022-11-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "ARIZONA STATE UNIVERSITY",
  "perf_str_addr": "660 S MILL AVE STE 312",
  "perf_city_name": "TEMPE",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852813670",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "137200",
   "pgm_ele_name": "LSS-Law And Social Sciences"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "040Z",
   "pgm_ref_txt": "Robust and Reliable Science"
  },
  {
   "pgm_ref_code": "1372",
   "pgm_ref_txt": "LAW AND SOCIAL SCIENCES"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 149554.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The validity of forensic science has come under heavy scrutiny. The National Research Council (2009) released a report on the state of forensic science in which it identified significant deficits in knowledge about the validity of a broad range of forensic techniques. The President's Council of Advisors on Science and Technology (2016) reiterated many of the same concerns. Both reports emphasized the need for research to examine sources of human judgment error in the analysis of forensic evidence and for good reason: Invalid or improper forensic analysis is a leading cause of wrongful conviction in the US (Morgan, 2023). The funded research examined the validity of cartridge case comparison under field-based conditions.</p>\n<p>The findings of the research supported three major conclusions:</p>\n<ol>\n<li>Cartridge case      comparison is a highly valid technique characterized by low error rates.</li>\n<li>Inconclusive      decisions possess exculpatory probative value.</li>\n<li>Non-blind      verification can lead forensic examiners to miss or confirm forensic      errors made by previous examiners. </li>\n</ol>\n<p>Many guns use ammunition in which the bullet is encased in a jacket. This jacket is called a cartridge case. During the firing process, a gun will imprint toolmarks onto a cartridge case and then eject it, making the cartridge case recoverable from a crime scene. In a criminal investigation, a firearm examiner will microscopically compare cartridge cases recovered from a crime scene to cartridge cases fired from a suspect's gun to determine whether the suspect's gun was the source of the recovered cartridge cases. Firearm examiners make this determination using a categorical scale that includes the broad classifications of identification (a clear match), inconclusive (neither a clear match nor clear mismatch), elimination (a clear mismatch), and unsuitable (insufficient toolmarks to render a conclusion). Because decisions of source determination depend on visual inspection of cartridge cases, it is a subjective process that is susceptible to human judgment error (NRC, 2009).</p>\n<p>In the funded research, trained firearm examiners employed in private, municipal, county, state, and federal crime laboratories across the US evaluated 16 unique sets of fired cartridge cases, including eight sets at Wave 1 and eight sets at Wave 2. At both waves, the examiners evaluated the sets and rendered a forensic decision of identification, inconclusive, elimination, or unsuitable. On average, half of the sets evaluated at each wave had been fired by the same gun and the other half had been fired by different guns.</p>\n<p>The data collected at Wave 1 addressed whether cartridge case comparison is a valid crime-solving tool. Forensic decisions provided by 228 trained firearm examiners showed that cartridge case comparison is a highly valid technique characterized by low error rates. However, inconclusive decisions constituted over one-fifth of all decisions rendered, and approximately 85% of these inconclusive decisions corresponded to cartridge cases that had been fired by different guns. The finding that most inconclusive decisions corresponded to cartridge cases that had been fired by different guns shows that inconclusive decisions possess exculpatory probative value. Hence, prosecutors should disclose inconclusive decisions to the defense, and defense attorneys should consider inconclusive decisions as a possible basis for post-conviction actions.</p>\n<p>The data collected at Wave 2 addressed whether nonblind verification is a suboptimal procedure for double-checking the accuracy of a forensic decision. Verification in forensic examination is intended to safeguard against forensic error, but not all verification procedures may be equally effective in achieving this goal. Blind verification, which nearly all scholars recommend, shields a verifying examiner from knowledge of a previous examiner&rsquo;s results, whereas non-blind verification does not. With nonblind verification, verifying examiners reanalyze evidence while being privy to a previous examiner's results. Data provided by 191 trained firearm examiners who had also participated in Wave 1 showed that knowledge of a previous examiner's purported forensic decision worsened examiners' performance when the previous decision was incorrect and improved examiners' performance when the previous decision was correct. These findings indicate that nonblind verification can cause forensic examiners to miss or confirm an error made by a previous examiner and point to the value of blind verification in casework where the ground-truth status of evidence can never be known.</p>\n<p><strong>References</strong></p>\n<p>National Research Council, Strengthening forensic science in the United States: A path forward. National Academies Press.</p>\n<p>Holdren, J. P., Lander, E. S., Press, W., Savitz, M. (2016). Forensic science in criminal courts: Ensuring scientific validity of feature-comparison methods. President&rsquo;s Committee of Advisors on Science and Technology.</p>\n<p>Morgan, J. (2023). Wrongful convictions and claims of false or misleading forensic evidence. Journal of Forensic Sciences, 68, 908-961. DOI: 10.1111/1556-4029.15233</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/14/2023<br>\nModified by: Stephanie&nbsp;J&nbsp;Madon</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe validity of forensic science has come under heavy scrutiny. The National Research Council (2009) released a report on the state of forensic science in which it identified significant deficits in knowledge about the validity of a broad range of forensic techniques. The President's Council of Advisors on Science and Technology (2016) reiterated many of the same concerns. Both reports emphasized the need for research to examine sources of human judgment error in the analysis of forensic evidence and for good reason: Invalid or improper forensic analysis is a leading cause of wrongful conviction in the US (Morgan, 2023). The funded research examined the validity of cartridge case comparison under field-based conditions.\n\n\nThe findings of the research supported three major conclusions:\n\nCartridge case      comparison is a highly valid technique characterized by low error rates.\nInconclusive      decisions possess exculpatory probative value.\nNon-blind      verification can lead forensic examiners to miss or confirm forensic      errors made by previous examiners. \n\n\n\nMany guns use ammunition in which the bullet is encased in a jacket. This jacket is called a cartridge case. During the firing process, a gun will imprint toolmarks onto a cartridge case and then eject it, making the cartridge case recoverable from a crime scene. In a criminal investigation, a firearm examiner will microscopically compare cartridge cases recovered from a crime scene to cartridge cases fired from a suspect's gun to determine whether the suspect's gun was the source of the recovered cartridge cases. Firearm examiners make this determination using a categorical scale that includes the broad classifications of identification (a clear match), inconclusive (neither a clear match nor clear mismatch), elimination (a clear mismatch), and unsuitable (insufficient toolmarks to render a conclusion). Because decisions of source determination depend on visual inspection of cartridge cases, it is a subjective process that is susceptible to human judgment error (NRC, 2009).\n\n\nIn the funded research, trained firearm examiners employed in private, municipal, county, state, and federal crime laboratories across the US evaluated 16 unique sets of fired cartridge cases, including eight sets at Wave 1 and eight sets at Wave 2. At both waves, the examiners evaluated the sets and rendered a forensic decision of identification, inconclusive, elimination, or unsuitable. On average, half of the sets evaluated at each wave had been fired by the same gun and the other half had been fired by different guns.\n\n\nThe data collected at Wave 1 addressed whether cartridge case comparison is a valid crime-solving tool. Forensic decisions provided by 228 trained firearm examiners showed that cartridge case comparison is a highly valid technique characterized by low error rates. However, inconclusive decisions constituted over one-fifth of all decisions rendered, and approximately 85% of these inconclusive decisions corresponded to cartridge cases that had been fired by different guns. The finding that most inconclusive decisions corresponded to cartridge cases that had been fired by different guns shows that inconclusive decisions possess exculpatory probative value. Hence, prosecutors should disclose inconclusive decisions to the defense, and defense attorneys should consider inconclusive decisions as a possible basis for post-conviction actions.\n\n\nThe data collected at Wave 2 addressed whether nonblind verification is a suboptimal procedure for double-checking the accuracy of a forensic decision. Verification in forensic examination is intended to safeguard against forensic error, but not all verification procedures may be equally effective in achieving this goal. Blind verification, which nearly all scholars recommend, shields a verifying examiner from knowledge of a previous examiners results, whereas non-blind verification does not. With nonblind verification, verifying examiners reanalyze evidence while being privy to a previous examiner's results. Data provided by 191 trained firearm examiners who had also participated in Wave 1 showed that knowledge of a previous examiner's purported forensic decision worsened examiners' performance when the previous decision was incorrect and improved examiners' performance when the previous decision was correct. These findings indicate that nonblind verification can cause forensic examiners to miss or confirm an error made by a previous examiner and point to the value of blind verification in casework where the ground-truth status of evidence can never be known.\n\n\nReferences\n\n\nNational Research Council, Strengthening forensic science in the United States: A path forward. National Academies Press.\n\n\nHoldren, J. P., Lander, E. S., Press, W., Savitz, M. (2016). Forensic science in criminal courts: Ensuring scientific validity of feature-comparison methods. Presidents Committee of Advisors on Science and Technology.\n\n\nMorgan, J. (2023). Wrongful convictions and claims of false or misleading forensic evidence. Journal of Forensic Sciences, 68, 908-961. DOI: 10.1111/1556-4029.15233\n\n\n\t\t\t\t\tLast Modified: 12/14/2023\n\n\t\t\t\t\tSubmitted by: StephanieJMadon\n"
 }
}