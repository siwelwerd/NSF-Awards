{
 "awd_id": "2226601",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Machine Learning for Student Reasoning during Challenging Concept Questions",
 "cfda_num": "47.041",
 "org_code": "07050000",
 "po_phone": "7032927286",
 "po_email": "apawley@nsf.gov",
 "po_sign_block_name": "Alice Pawley",
 "awd_eff_date": "2023-04-01",
 "awd_exp_date": "2026-03-31",
 "tot_intn_awd_amt": 171743.0,
 "awd_amount": 171743.0,
 "awd_min_amd_letter_date": "2023-03-21",
 "awd_max_amd_letter_date": "2023-03-21",
 "awd_abstract_narration": "Artificial Intelligence (AI), and more specifically, language models, have been drastically changing how students and instructors think about learning and assessment. While there are legitimate concerns about how the use of these tools could be detrimental to learning, this research project aims to leverage language models to better prepare engineering learners of the 21st Century. The research project will use modern AI and machine learning (ML) tools to automate analysis of student-written responses to challenging concept questions. These qualitative questions are often used in large STEM classes to support active learning pedagogies; they require minimum calculations and focus on the application of underlying physical and chemical phenomena to various situations. With previous NSF funding, we have developed the Concept Warehouse (NSF DUE 1023099, 1821439, 2135190), a classroom response system where students provide written justifications to concept questions. Providing written justifications targets development of reasoning and sense-making skills in students and can also better prepare them for discussions with peers resulting in broader effectiveness of active learning pedagogies. However, expository prose also presents a daunting amount of information for instructors to process. In this project, we will leverage recent advancements in machine learning tools and natural language processing technologies to develop automated processes to analyze student-written justifications to challenging concept questions.\r\n\r\nThis project will join engineering education researchers at Tufts University and AI/ML researchers at the University of Massachusetts Lowell. We will focus on the following research questions: (1) Based on human coding, what ideas do students use in explaining challenging concept questions in statics? How do these vary among challenging concept questions studied? (2) How well can Transformer-based ML models replicate the coding done by the human coders? For isomorphic question pairs, how well do ML models trained on the first question\u2019s explanations perform on the second question? More generally, can ML-based coding based on one question be applied successfully to code the data for other questions, and what are the limits to this generalizability? We will complete three research tasks: (1) data collection of written responses for the same concept questions from nine or more engineering statics instructors at different institutions; (2) manual coding of a subset of students\u2019 written explanations, and (3) developing and evaluating ML coding methods, followed by ML coding of the complete set of collected written explanations. While the project focuses on engineering statics, it is expected that findings will transfer to challenging questions in other engineering and science topics. Ultimately, successful implementation of machine learning will support learning and instruction of challenging concepts. Expected outcomes include a developing understanding of advantages and disadvantages of different ML approaches including their accuracy, determination of minimum data size requirements to apply the algorithms, and the ability to transfer learning from one question to isomorphic questions that require similar reasoning patterns. For instructors, data generated can provide real-time information about the different ways students are reasoning with examples of common cases. For engineering education researchers, characterizing explanations in different settings will support investigations of how student thinking relates to instructional practices and environments.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "EEC",
 "org_div_long_name": "Division of Engineering Education and Centers",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anna",
   "pi_last_name": "Rumshisky",
   "pi_mid_init": "",
   "pi_sufx_name": "Dr.",
   "pi_full_name": "Anna Rumshisky",
   "pi_email_addr": "arumshisky@gmail.com",
   "nsf_id": "000611069",
   "pi_start_date": "2023-03-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Lowell",
  "inst_street_address": "220 PAWTUCKET ST STE 400",
  "inst_street_address_2": "",
  "inst_city_name": "LOWELL",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "9789344170",
  "inst_zip_code": "018543573",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "MA03",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS LOWELL",
  "org_prnt_uei_num": "",
  "org_uei_num": "LTNVSTJ3R6D5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Lowell",
  "perf_str_addr": "One University Avenue",
  "perf_city_name": "LOWELL",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "018543643",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "MA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "134000",
   "pgm_ele_name": "EngEd-Engineering Education"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "110E",
   "pgm_ref_txt": "EDUCATION RESEARCH"
  },
  {
   "pgm_ref_code": "1340",
   "pgm_ref_txt": "ENGINEERING EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 171743.0
  }
 ],
 "por": null
}