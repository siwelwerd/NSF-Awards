{
 "awd_id": "2238968",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Robust and Collaborative Perception and Navigation for Construction Robots",
 "cfda_num": "47.041, 47.070",
 "org_code": "05020000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2023-09-01",
 "awd_exp_date": "2028-08-31",
 "tot_intn_awd_amt": 599999.0,
 "awd_amount": 599999.0,
 "awd_min_amd_letter_date": "2023-02-16",
 "awd_max_amd_letter_date": "2024-07-12",
 "awd_abstract_narration": "The construction industry is responsible for maintaining aging civil infrastructure and build new facilities that can accommodate the social needs of the 21st century. This is in addition to the ongoing critical need to address long-standing problems in occupational safety, labor productivity, costs, and labor shortage. A promising technical solution is to introduce mobile robots on construction jobsites. It is possible to leverage recent discoveries in robotics and artificial intelligence (AI) to tackle those aforementioned challenges. However, unlike manufacturing automation or self-driving cars, construction robots face unique challenges due to the need to navigate dynamic environments. Such robots are also required to work closely with humans in a variaty of tasks and often handle heavy payloads. This award supports fundamental robotics research to allow better perception and navigation for construction jobsite monitoring robots. It will produce an intelligent mobile robot team equipped with cameras to autonomously monitor construction progress and operations to improve jobsite efficiency and safety. The results of this research will be widely applicable to scenarios beyond construction, ranging from connected and autonomous vehicles to service robotics in smart and accessible cities. The project will facilitate collaboration between robotics, artificial intelligence, and civil and mechanical engineering. Furthermore, it aims to broaden participation of underrepresented groups in engineering via educational games, multi-disciplinary robotics curriculum, and workforce training workshops.\r\n\r\nMobile robotics in construction jobsites are often limited by perception challenges due to occlusion and limited field of view. In dynamic jobsites, limited perception leads to navigation and inefficient assistance. To improve the robustness, reliability, and scalability of the vision system in mobile robots, novel self-supervised and graph-based representation learning will be used to extract, organize, and reason about places and objects from high-dimensional sensory inputs. This research will advance the state of the art  along three directions: (1) robust navigation from topological representations for monitoring in dynamic and ever-changing jobsites, (2) collaborative perception for  providing safer operation monitoring and collision warnings on busy jobsites, and (3) integrated perception and navigation at both the algorithm, system, and dataset levels. The research will be validated in real construction jobsites through industry partners, and the resulting software, hardware design, and dataset will be open source to stimulate future research.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chen",
   "pi_last_name": "Feng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chen Feng",
   "pi_email_addr": "cfeng@nyu.edu",
   "nsf_id": "000785529",
   "pi_start_date": "2023-02-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "70 WASHINGTON SQ S",
  "perf_city_name": "NEW YORK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 475000.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 124999.0
  }
 ],
 "por": null
}