{
 "awd_id": "2303389",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Machine Learning Actors to Improve Connectedness across Remote Teams",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032924392",
 "po_email": "amonk@nsf.gov",
 "po_sign_block_name": "Alastair Monk",
 "awd_eff_date": "2023-08-01",
 "awd_exp_date": "2024-01-31",
 "tot_intn_awd_amt": 275000.0,
 "awd_amount": 275000.0,
 "awd_min_amd_letter_date": "2023-07-17",
 "awd_max_amd_letter_date": "2023-07-17",
 "awd_abstract_narration": "The broader impact /commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to develop machine learning-powered actors (ML actors) that facilitate social encounters between friends, strangers, classmates, and coworkers in user-generated spaces across the Metaverse. The shift towards virtual work, learning, and socialization has been accompanied by significant societal disruption. Over the past few years, people across the United States reported increasing levels of loneliness and isolation. Building off research that shows games are a powerful tool for team building, and non-player characters have a significant impact on building empathy, this project uses ML actors as the building blocks of free-to-play, multiplayer, cooperative games designed to bring remote workers together socially. \r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project aims to address the challenge of making ML actors viable for user-generated worlds. In order to be effective in the Metaverse, ML actors will need to navigate unfamiliar settings, player dialogue, and behaviors that are hard to predict. Characters will need to be trained on vast quantities of data with some human supervision. This project seeks to prove that ML actors can be trained from large amounts of data by users of no technical background and those actors can then be deployed in a virtual environment in which they are responsive to their environment and player choices. This project has three main steps: 1) learning a large multimodal hierarchical task network from thousands of movie scripts and game logs, 2) connecting that model to a character in a 3D environment, and 3) testing a game with remote teams to gauge efficacy and enjoyability.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeffrey",
   "pi_last_name": "Orkin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jeffrey Orkin",
   "pi_email_addr": "jeff.orkin@gmail.com",
   "nsf_id": "000893312",
   "pi_start_date": "2023-07-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "CENTRAL CASTING AI INC",
  "inst_street_address": "1 QUAIL RUN DR",
  "inst_street_address_2": "",
  "inst_city_name": "METHUEN",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "3127880668",
  "inst_zip_code": "018441579",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "MA03",
  "org_lgl_bus_name": "CENTRAL CASTING AI INC",
  "org_prnt_uei_num": "",
  "org_uei_num": "RLV9WDWMT877"
 },
 "perf_inst": {
  "perf_inst_name": "CENTRAL CASTING AI INC",
  "perf_str_addr": "1 QUAIL RUN DR",
  "perf_city_name": "METHUEN",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "018441579",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "MA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "010E",
   "pgm_ref_txt": "DISABILITY RES & HOMECARE TECH"
  },
  {
   "pgm_ref_code": "1654",
   "pgm_ref_txt": "HUMAN COMPUTER INTERFACE"
  },
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01AB2324DB",
   "fund_name": "R&RA DRSA DEFC AAB",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 275000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p dir=\"ltr\"><span>This NSF SBIR Phase I award supported research and development to create machine learning powered actors (ML actors) to improve connectedness in virtual spaces. Witnessing a shift towards remote work and socialization, and inspired by research showing AI characters can be a powerful tool for building empathy and connection, we set out to demonstrate we could train ML actors that were effective facilitators of social connection. Over the course of the award, we demonstrated that we could use a new approach to automated planning, a large multi-modal task network planner, to control the behavior of virtual characters in 3D environments. In parallel, we demonstrated that non-technical users can create dialogue and behaviors for this novel planning system- a result that has significant implications for broadening participation in the creation and utilization of AI powered characters.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Our research plan centered on three key technical objectives, each of which was successfully completed over the course of the award. First, we proved that we could effectively train a large multi-modal task network planner on vast quantities of data while requiring minimal human intervention in the training process. Second, we demonstrated that large multi-modal task network planners can power character behaviors in 3D environments- producing highly varied, engaging user experiences. Finally, results of testing the authoring system with non-technical users demonstrate that it is feasible for users of varied technical skill levels to create and customize characters powered by large multi-modal task network planners. The resulting innovation of our research and development is a system for producing fully formed ML actors that can navigate an array of situations in different virtual environments and are customizable by users of no technical ability. This innovation has significant implications for the development of video games, training simulations, media and entertainment.</span></p>\n<p dir=\"ltr\"><span>At the onset of the award, we hypothesized that our solution would initially be commercialized through products aimed at helping remote teams stay connected socially. This hypothesis was developed when the landscape of remote work looked much different than it does today. Informed by new data that shows organizations are shifting to hybrid or in person models of work, we explored new markets for commercialization. Over the course of the award, we identified promising opportunities working with video game studios working on open world games. While we see tremendous potential for this innovation to disrupt the video game industry, AI characters that can adapt to unfamiliar spaces and myriad user choices, unlock significant advances across education, training, and skill development. The learned LMM-HTNs and knowledge graphs capture world semantics valuable to simulations outside of games, and to robotics.</span></p>\n<p dir=\"ltr\"><span>This work demonstrates a new paradigm of content creation for video games and other animated or interactive media, that combines human direction and creativity with powerful workflow automation and real-time reasoning. Traditionally, developers have authored a character's physical behaviors and branching dialogue by hand, either through code or by configuring components of a decision making architecture. Architectures have progressed from simple finite state machines, to hierarchically structured behavior trees, to generative automated planning systems. However, configuration is a complex technical task requiring engineers to be involved creating bottlenecks and increasing expenses. Our approach combines recent advances in machine learning with a focus on human design and control to produce a system that is uniquely suited for use in commercial simulations while remaining inspectable, editable and controllable by users of any level of technical expertise.</span></p>\n<p dir=\"ltr\"><span>Our results have significant implications for broadening participation in STEM careers particularly in fostering an interest in artificial intelligence. With the field of AI developing and expanding rapidly, it is more important than ever to foster an interest in, and understanding of, AI in young people. Our system can be a key tool for fostering this learning. Our no-code approach to character authoring enables users of any age, or level of technical expertise, to get started creating and using AI characters in virtual environments. By giving young people the opportunity to incorporate AI characters into games or virtual environments they are building, we can start them on the path to understanding how complex AI systems function and instilling a desire to learn more about the discipline.&nbsp;</span></p><br>\n<p>\n Last Modified: 02/02/2024<br>\nModified by: Jeffrey&nbsp; &nbsp;Orkin</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis NSF SBIR Phase I award supported research and development to create machine learning powered actors (ML actors) to improve connectedness in virtual spaces. Witnessing a shift towards remote work and socialization, and inspired by research showing AI characters can be a powerful tool for building empathy and connection, we set out to demonstrate we could train ML actors that were effective facilitators of social connection. Over the course of the award, we demonstrated that we could use a new approach to automated planning, a large multi-modal task network planner, to control the behavior of virtual characters in 3D environments. In parallel, we demonstrated that non-technical users can create dialogue and behaviors for this novel planning system- a result that has significant implications for broadening participation in the creation and utilization of AI powered characters.\n\n\nOur research plan centered on three key technical objectives, each of which was successfully completed over the course of the award. First, we proved that we could effectively train a large multi-modal task network planner on vast quantities of data while requiring minimal human intervention in the training process. Second, we demonstrated that large multi-modal task network planners can power character behaviors in 3D environments- producing highly varied, engaging user experiences. Finally, results of testing the authoring system with non-technical users demonstrate that it is feasible for users of varied technical skill levels to create and customize characters powered by large multi-modal task network planners. The resulting innovation of our research and development is a system for producing fully formed ML actors that can navigate an array of situations in different virtual environments and are customizable by users of no technical ability. This innovation has significant implications for the development of video games, training simulations, media and entertainment.\n\n\nAt the onset of the award, we hypothesized that our solution would initially be commercialized through products aimed at helping remote teams stay connected socially. This hypothesis was developed when the landscape of remote work looked much different than it does today. Informed by new data that shows organizations are shifting to hybrid or in person models of work, we explored new markets for commercialization. Over the course of the award, we identified promising opportunities working with video game studios working on open world games. While we see tremendous potential for this innovation to disrupt the video game industry, AI characters that can adapt to unfamiliar spaces and myriad user choices, unlock significant advances across education, training, and skill development. The learned LMM-HTNs and knowledge graphs capture world semantics valuable to simulations outside of games, and to robotics.\n\n\nThis work demonstrates a new paradigm of content creation for video games and other animated or interactive media, that combines human direction and creativity with powerful workflow automation and real-time reasoning. Traditionally, developers have authored a character's physical behaviors and branching dialogue by hand, either through code or by configuring components of a decision making architecture. Architectures have progressed from simple finite state machines, to hierarchically structured behavior trees, to generative automated planning systems. However, configuration is a complex technical task requiring engineers to be involved creating bottlenecks and increasing expenses. Our approach combines recent advances in machine learning with a focus on human design and control to produce a system that is uniquely suited for use in commercial simulations while remaining inspectable, editable and controllable by users of any level of technical expertise.\n\n\nOur results have significant implications for broadening participation in STEM careers particularly in fostering an interest in artificial intelligence. With the field of AI developing and expanding rapidly, it is more important than ever to foster an interest in, and understanding of, AI in young people. Our system can be a key tool for fostering this learning. Our no-code approach to character authoring enables users of any age, or level of technical expertise, to get started creating and using AI characters in virtual environments. By giving young people the opportunity to incorporate AI characters into games or virtual environments they are building, we can start them on the path to understanding how complex AI systems function and instilling a desire to learn more about the discipline.\t\t\t\t\tLast Modified: 02/02/2024\n\n\t\t\t\t\tSubmitted by: Jeffrey Orkin\n"
 }
}