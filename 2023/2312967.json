{
 "awd_id": "2312967",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Medium: From Vision to Dynamics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2023-08-15",
 "awd_exp_date": "2026-07-31",
 "tot_intn_awd_amt": 1200000.0,
 "awd_amount": 1200000.0,
 "awd_min_amd_letter_date": "2023-06-20",
 "awd_max_amd_letter_date": "2023-06-20",
 "awd_abstract_narration": "In the realms of health and sports, detailed analysis of human movement provides guidance for individualized performance assessment, training, and health evaluation. Data collection for biomechanical analysis of human motion is typically performed using expensive, specialized hardware that requires experiments to be carried out in a constrained lab setting. Computer vision algorithms that use video cameras for data collection enable observation in more natural environments with minimal cost, but current vision-based estimates of body pose and motion are not biomechanically accurate and lack a quantitative model of the physical forces underlying human movement. This research effort will train a modern machine learning system to perform imagery-based estimation of biomechanically accurate body pose, motion and force, turning informal computer vision into a scientific measurement tool for human movement and stability research in unconstrained, everyday settings using readily available low-cost video cameras.  The results will enable novel applications in personalized training and preventative medicine, and lead to strategies for improving flexibility and stability among the elderly, reducing fall-induced mortality and improving quality of life, serving NSF's mission to promote progress of science to advance the national health.  An outreach program covering topics in human and robot stability will inspire K-12 students with demonstrations that combine exercise, augmented reality, and humanoid robots.\r\n\r\nThe project team will collect a unique, multi-modal human motion dataset and use it to train a novel deep learning system that combines multi-task regression with a biomechanical human motion model to estimate, from visual data alone, accurate pose and motion as well as dynamics such as muscle torques and ground reaction forces. The results will fill an existing gap between visual observation of kinematics and the inference of body dynamics, greatly improving the ability of computer vision to make inferences about balance and stability that require dynamics information. Data-driven discovery of discriminative features that are causal or correlated to stability will lead to identifying the most stability-enhancing poses/moves for a movement sequence and new measures for estimating stability of a person in motion. Guided by the scientific research, four applications will be explored: 1) Developing a vision-based stability surveillance system that can quantify and monitor changes in stability; 2) Developing a vision-based personal trainer for teaching stability-enhancing exercises; 3) Analyzing historical sports videos to reveal changes in performance styles and dynamics; and 4) Studying methods for retargeting human movements to a humanoid robot while maintaining stability.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Collins",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Robert T Collins",
   "pi_email_addr": "rcollins@cse.psu.edu",
   "nsf_id": "000105362",
   "pi_start_date": "2023-06-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yanxi",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yanxi Liu",
   "pi_email_addr": "yanxi@cse.psu.edu",
   "nsf_id": "000096837",
   "pi_start_date": "2023-06-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Challis",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "John H Challis",
   "pi_email_addr": "jhc10@psu.edu",
   "nsf_id": "000214969",
   "pi_start_date": "2023-06-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "201 Old Main",
  "perf_city_name": "University Park",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168021503",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "PA15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 1200000.0
  }
 ],
 "por": null
}