{
 "awd_id": "2331065",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: End-to-End Learning of Paradoxes and Interpretations for Data Storytelling",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927978",
 "po_email": "racharya@nsf.gov",
 "po_sign_block_name": "Raj Acharya",
 "awd_eff_date": "2023-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 125000.0,
 "awd_amount": 125000.0,
 "awd_min_amd_letter_date": "2023-06-06",
 "awd_max_amd_letter_date": "2023-06-06",
 "awd_abstract_narration": "Can we use AI and machine learning to automatically create compelling narratives from extensive data sets, like business data, demographics, and economic statistics? This project aims to answer this question in the affirmative and make data storytelling accessible to everyone, even those without advanced big data skills. Data storytelling is a powerful technique for understanding and extracting valuable insights from large data sets. However, it can be daunting for individuals who lack the technical expertise to navigate and interpret big data effectively. In this project, we propose an innovative approach to automatic data storytelling by learning from paradoxes found within a large data set. Paradoxes are unexpected contradictions that exist within data, and they hold the potential to uncover critical and surprising information. By harnessing these paradoxes, we can craft engaging narratives that highlight the most interesting and important aspects of the data, especially for decision-makers and data consumers. The ultimate goal of this project is to develop open-source software that facilitates creating compelling data stories. The outcomes and findings will be made publicly available, ensuring that individuals and organizations can benefit from this project. Additionally, the insights gained from this research will be incorporated into data science courses, empowering future data storytellers with the necessary skills to communicate complex information effectively. By democratizing data storytelling through the use of paradoxes and making it accessible to a wider audience, we can unlock the hidden potential of extensive datasets and strengthen data-driven decision-making in various domains.\r\n\r\nThis project will address the core challenges of paradox identification through two main thrusts. First, we will focus on investigating concise and non-redundant representations of statistical relationships among variables in data. Our goal is to formulate representations that are both concise and minimal, ensuring efficiency in conveying information. To demonstrate the feasibility and potential of our approach, we will specifically examine Simpson's paradox in this pilot project. Second, building on the established model, we will develop efficient and scalable algorithms to find data paradoxes and their interpretations. Our focus will be on exploring the efficiency, completeness, and non-redundancy of the learning process, using real-world datasets for evaluation. The knowledge and insights gained from this research will be integrated into data science education and training programs, enhancing the skills and capabilities of future data scientists. This project's transformative nature lies in its recognition of data storytelling as a fundamental approach within the realm of data science. The algorithms and tools we develop will substantially enhance the abilities of data scientists, statisticians, and business intelligence analysts to explore data, uncover new knowledge, and deliver valuable insights. As a result, these advancements will have wide-ranging applications and be of significant value to diverse communities. By addressing the challenges of paradox learning and advancing the field of data storytelling, this project will facilitate the exploration and interpretation of complex data, ultimately enabling more informed decision-making to a wider set of people and driving innovation across various sectors.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jian",
   "pi_last_name": "Pei",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jian Pei",
   "pi_email_addr": "j.pei@duke.edu",
   "nsf_id": "000897394",
   "pi_start_date": "2023-06-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "2200 W MAIN ST",
  "perf_city_name": "DURHAM",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277054640",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 125000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we conducted an in-depth exploration of redundancies among Simpson's paradoxes in multi-dimensional datasets, revealing their underlying causes. A key outcome of the research is the discovery of what we term \"coverage redundancy.\" The idea behind this is that multiple Simpson's paradoxes are redundant if they highlight the same group of data entities, even if different features are used. This insight allows us to categorize Simpson's paradoxes into distinct, non-redundant groups, effectively eliminating coverage redundancy from our analysis.</p>\n<p>Building on this foundational concept, we developed fast and efficient algorithms to detect coverage redundancy, group redundant Simpson's paradoxes, and provide a concise, non-redundant representation of Simpson's paradoxes. Additionally, we explored the likelihood of encountering coverage redundancy in a given multi-dimensional data distribution, helping to answer whether Simpson's paradoxes are rare or common occurrences in various datasets.</p>\n<p>Our implementation of these algorithms was rigorously tested using both real-world and synthetic datasets, demonstrating their practical value. Particularly, we conducted multiple case studies using real data sets in various applications to clearly demonstrate that coverage redundancy exists and is not rare in real data sets. Therefore, finding and eliminating coverage redundancy are important for data science practice.</p>\n<p>The software developed during this project will soon be released as open-source, making these tools accessible to the broader research community. Furthermore, we are in the final stages of preparing a research paper detailing our findings, which will be submitted for peer review and publication.</p>\n<p>The project has supported the work of two Ph.D. students, one of whom is female, contributing to the growth of emerging scholars in this field. Additionally, the topic of Simpson's paradox and its redundancy has been incorporated into the curriculum of an introductory data science course, furthering educational outreach.</p>\n<p>This research has opened several promising avenues for future exploration. One such direction is the investigation of \"similar coverage redundancy\" and \"common latent variable redundancy,\" two more nuanced and sophisticated generalizations of coverage redundancy. We are also working to extend the concept of Simpson's paradox from its traditional application in categorical data to numeric and textual datasets, broadening its scope and applicability. Lastly, we are exploring how Simpson's paradoxes and their interrelations can be leveraged to create narrative frameworks for knowledge discovery and interpretation in large-scale datasets.</p><br>\n<p>\n Last Modified: 10/24/2024<br>\nModified by: Jian&nbsp;Pei</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn this project, we conducted an in-depth exploration of redundancies among Simpson's paradoxes in multi-dimensional datasets, revealing their underlying causes. A key outcome of the research is the discovery of what we term \"coverage redundancy.\" The idea behind this is that multiple Simpson's paradoxes are redundant if they highlight the same group of data entities, even if different features are used. This insight allows us to categorize Simpson's paradoxes into distinct, non-redundant groups, effectively eliminating coverage redundancy from our analysis.\n\n\nBuilding on this foundational concept, we developed fast and efficient algorithms to detect coverage redundancy, group redundant Simpson's paradoxes, and provide a concise, non-redundant representation of Simpson's paradoxes. Additionally, we explored the likelihood of encountering coverage redundancy in a given multi-dimensional data distribution, helping to answer whether Simpson's paradoxes are rare or common occurrences in various datasets.\n\n\nOur implementation of these algorithms was rigorously tested using both real-world and synthetic datasets, demonstrating their practical value. Particularly, we conducted multiple case studies using real data sets in various applications to clearly demonstrate that coverage redundancy exists and is not rare in real data sets. Therefore, finding and eliminating coverage redundancy are important for data science practice.\n\n\nThe software developed during this project will soon be released as open-source, making these tools accessible to the broader research community. Furthermore, we are in the final stages of preparing a research paper detailing our findings, which will be submitted for peer review and publication.\n\n\nThe project has supported the work of two Ph.D. students, one of whom is female, contributing to the growth of emerging scholars in this field. Additionally, the topic of Simpson's paradox and its redundancy has been incorporated into the curriculum of an introductory data science course, furthering educational outreach.\n\n\nThis research has opened several promising avenues for future exploration. One such direction is the investigation of \"similar coverage redundancy\" and \"common latent variable redundancy,\" two more nuanced and sophisticated generalizations of coverage redundancy. We are also working to extend the concept of Simpson's paradox from its traditional application in categorical data to numeric and textual datasets, broadening its scope and applicability. Lastly, we are exploring how Simpson's paradoxes and their interrelations can be leveraged to create narrative frameworks for knowledge discovery and interpretation in large-scale datasets.\t\t\t\t\tLast Modified: 10/24/2024\n\n\t\t\t\t\tSubmitted by: JianPei\n"
 }
}