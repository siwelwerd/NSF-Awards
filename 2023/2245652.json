{
 "awd_id": "2245652",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: RI: Understanding Activities of Daily Living in Indoor Scenarios",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2023-08-01",
 "awd_exp_date": "2026-01-31",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 185000.0,
 "awd_min_amd_letter_date": "2023-02-08",
 "awd_max_amd_letter_date": "2025-04-23",
 "awd_abstract_narration": "It is projected that, by 2050, one-in-six  people in the world will be over the age of 65. This is up from one-in-11 in 2019. Thus, older adults are a growing demographic group in society. Because aging is related to increased healthcare utilization, as are pandemics, this increasing demographic translates into the need to increase the workforce in healthcare. The rising demand for healthcare can be combated by deploying activity monitoring systems, which could help monitor the health status of older patients and support the early detection of health issues. Thus, building such monitoring systems requires an automated understanding of Activities of Daily Living (ADL) performed by humans. Most of the investigations towards modeling human activities owing to the advances in computer vision are targeted for generic internet videos. Existing models are fabricated for recognition in web videos whereas viewpoint variation and subtle motion that characterize ADLs generally cannot handle uncertainty and tend to underperform in real-world scenarios. Moreover, they have difficulties distinguishing similarly looking activities. Thus, the key objective of this project is to build a framework for recognizing ADLs that can be deployed in monitoring systems. The project will also perform complementary educational and outreach activities that engage STEM students.\r\n\r\nThis project will develop a multi-modal framework predominantly based on the RGB color model and pose modalities due to their easy accessibility in indoor scenarios. This framework aims at addressing two important challenges - the limited availability of labeled ADL videos and how to combine different heterogeneous modalities (RGB and Poses) for classifying activities. Thus, this project will explore the integration of two interrelated research directions: (1) a study on learning from limited training distribution; and, (2) a study on combining modalities like RGB and depth.  In the first study, the project will explore the possibilities of mitigating the limitation of the scale of available data in the ADL domain for effective training of neural networks for video understanding. In the second study, the team will aim at improving the effectiveness of RGB-based human activity recognition by leveraging the human localized regions within a scene. Finally, we will develop a multi-modal neural network model for ADL by integrating human localized RGB and 3D poses of a human actor. This research study will reveal several new dimensions towards understanding ADLs that will also benefit the computer vision community.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Srijan",
   "pi_last_name": "Das",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Srijan Das",
   "pi_email_addr": "sdas24@uncc.edu",
   "nsf_id": "000894918",
   "pi_start_date": "2023-02-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Charlotte",
  "inst_street_address": "9201 UNIVERSITY CITY BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTE",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "7046871888",
  "inst_zip_code": "282230001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NC12",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHARLOTTE",
  "org_prnt_uei_num": "NEYCH3CVBTR6",
  "org_uei_num": "JB33DT84JNA5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Charlotte",
  "perf_str_addr": "9201 UNIVERSITY CITY BLVD",
  "perf_city_name": "CHARLOTTE",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "282230001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NC12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 175000.0
  },
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 10000.0
  }
 ],
 "por": null
}