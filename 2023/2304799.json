{
 "awd_id": "2304799",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps: Detecting Performance Degradation and Failures of Deep Neural Networks in Cancer Imaging",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922061",
 "po_email": "jcamelio@nsf.gov",
 "po_sign_block_name": "Jaime A. Camelio",
 "awd_eff_date": "2023-03-15",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2023-03-09",
 "awd_max_amd_letter_date": "2023-03-09",
 "awd_abstract_narration": "The broader impact/commercial potential of this I-Corps project is the development of a failure detection framework that learns the behavior of the machine learning model under various noisy conditions.  This solution is currently focused on cancer imaging applications, especially head and neck, lung and brain cancers. Neural networks are used in many areas of the human endeavor, and their use is expected to increase exponentially. These machine learning models do not provide a measure of confidence in the decisions and fail without warning. There are no solutions for addressing these issues except manually monitoring and reviewing the performance of these models after deployment. The proposed technology can integrate seamlessly with any machine learning model before or after deployment and output model confidence in the decision with minimal additional computational cost. The proposed technology will help artificial intelligence find its true potential in mission-critical areas. The proposed mechanisms for detecting performance degradation and model failure can provide a path to achieve the much-desired trustworthiness in artificial intelligence models. The applicability of the proposed technology encompasses various areas, including healthcare, transportation, cybersecurity, economics, environment, and financial services.\r\n\r\nThis I-Corps project is based on the development of a generalized framework that quantifies the performance and detects failure in all types of machine learning models, including convolutional neural networks and transformers. This framework does not require retraining of the original model and can be used as an out-of-the-box solution. This technique consists of different methods to identify the type of machine learning model and its output. This information is used to specify a fixed threshold or learn a dynamic one. These threshold values serve as a guide for identifying the performance degradation of the machine learning model. In the first case, the technology defines a fixed threshold value based on the model performance on the test dataset with a changing signal-to-noise ratio. The second method learns the threshold value using a shallow neural network. The proposed failure detection methods seamlessly integrate with the original machine learning model and abstain from making decisions when the model\u2019s confidence is below the threshold. This technique, when used during the machine learning model training phase, can help improve model accuracy.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ghulam",
   "pi_last_name": "Rasool",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ghulam Rasool",
   "pi_email_addr": "ghulam.rasool@moffitt.org",
   "nsf_id": "000790254",
   "pi_start_date": "2023-03-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "H. Lee Moffitt Cancer Center and Research Institute Hospital Inc",
  "inst_street_address": "12902 USF MAGNOLIA DR",
  "inst_street_address_2": "",
  "inst_city_name": "TAMPA",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "8137456804",
  "inst_zip_code": "336129416",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "FL15",
  "org_lgl_bus_name": "H. LEE MOFFITT CANCER CENTER AND RESEARCH INSTITUTE HOSPITAL, INC.",
  "org_prnt_uei_num": "DVHKP4N619V9",
  "org_uei_num": "DVHKP4N619V9"
 },
 "perf_inst": {
  "perf_inst_name": "H. Lee Moffitt Cancer Center and Research Institute Hospital Inc",
  "perf_str_addr": "12902 MAGNOLIA DR",
  "perf_city_name": "TAMPA",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "336129416",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "FL15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1757",
   "pgm_ref_txt": "Quantitative sys bio and biotech"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The deployment of Artificial Intelligence (AI) in healthcare is driving significant transformations, yet ensuring its safe and effective implementation continues to present formidable challenges. This project focused on developing robust failure detection mechanisms for AI models in healthcare, ensuring their reliability in real-world clinical applications. By leveraging Bayesian uncertainty estimation, our research provided a systematic method to identify when AI models fail, degrade performance, or encounter unfamiliar data&mdash;an essential safeguard for AI-driven diagnostics.</p>\r\n<p>Key Findings and Accomplishments</p>\r\n<ol>\r\n<li>&nbsp;<strong>AI Failure Detection for Medical Imaging</strong>: We developed a framework to monitor and detect failures in AI models used for medical imaging, particularly in radiology and pathology applications. This method enhances trust and safety in AI-driven diagnostic tools by ensuring that predictions are flagged when uncertainty is high.</li>\r\n<li><strong>Expansion to a Generative AI Evaluation Platform</strong>: Recognizing the broader need for AI performance evaluation, we expanded our focus beyond medical imaging to create a comprehensive AI model evaluation platform. This platform, known as The Medical Arena, assesses large language models (LLMs) and generative AI systems for use in clinical trial matching, patient-provider communication, and medical record summarization.</li>\r\n<li><strong>Industry Engagement and Commercialization Pathways</strong>: &nbsp;Through the NSF I-Corps program, we conducted over 100 customer discovery interviews with AI developers, hospital administrators, and healthcare professionals. These engagements revealed that AI users prefer integrated failure detection solutions rather than standalone tools, guiding our strategic pivot toward a platform-based AI evaluation system.</li>\r\n<li><strong>Institutional and Industry Collaboration</strong>: &nbsp;We partnered with Moffitt Cancer Center&rsquo;s AI research initiatives and engaged with NVIDIA to incorporate advanced AI model benchmarking and optimization techniques into our platform. These collaborations are helping build scalable, secure, and regulatory-compliant AI evaluation infrastructure for hospital systems.</li>\r\n</ol>\r\n<p>Broader Impacts</p>\r\n<p>This project has played a crucial role in enhancing trust in AI-driven healthcare by ensuring that AI models operate safely and predictably, thereby increasing public and clinician confidence in AI-assisted decision-making. Additionally, it has contributed to advancing AI governance and regulation by establishing best practices for AI model validation, supporting compliance with healthcare regulations, and influencing future AI policy frameworks. Beyond healthcare, the techniques developed for AI performance monitoring have interdisciplinary applications in financial modeling, cybersecurity, and industrial automation, ensuring that AI systems across multiple sectors remain reliable, fair, and transparent.</p>\r\n<p>This project has laid the groundwork for future AI safety research, paving the way for a scalable, open-source AI evaluation platform that will support hospitals, researchers, and industry leaders in developing trustworthy AI solutions for critical applications.</p><br>\n<p>\n Last Modified: 02/14/2025<br>\nModified by: Ghulam&nbsp;Rasool</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe deployment of Artificial Intelligence (AI) in healthcare is driving significant transformations, yet ensuring its safe and effective implementation continues to present formidable challenges. This project focused on developing robust failure detection mechanisms for AI models in healthcare, ensuring their reliability in real-world clinical applications. By leveraging Bayesian uncertainty estimation, our research provided a systematic method to identify when AI models fail, degrade performance, or encounter unfamiliar dataan essential safeguard for AI-driven diagnostics.\r\n\n\nKey Findings and Accomplishments\r\n\r\nAI Failure Detection for Medical Imaging: We developed a framework to monitor and detect failures in AI models used for medical imaging, particularly in radiology and pathology applications. This method enhances trust and safety in AI-driven diagnostic tools by ensuring that predictions are flagged when uncertainty is high.\r\nExpansion to a Generative AI Evaluation Platform: Recognizing the broader need for AI performance evaluation, we expanded our focus beyond medical imaging to create a comprehensive AI model evaluation platform. This platform, known as The Medical Arena, assesses large language models (LLMs) and generative AI systems for use in clinical trial matching, patient-provider communication, and medical record summarization.\r\nIndustry Engagement and Commercialization Pathways: Through the NSF I-Corps program, we conducted over 100 customer discovery interviews with AI developers, hospital administrators, and healthcare professionals. These engagements revealed that AI users prefer integrated failure detection solutions rather than standalone tools, guiding our strategic pivot toward a platform-based AI evaluation system.\r\nInstitutional and Industry Collaboration: We partnered with Moffitt Cancer Centers AI research initiatives and engaged with NVIDIA to incorporate advanced AI model benchmarking and optimization techniques into our platform. These collaborations are helping build scalable, secure, and regulatory-compliant AI evaluation infrastructure for hospital systems.\r\n\r\n\n\nBroader Impacts\r\n\n\nThis project has played a crucial role in enhancing trust in AI-driven healthcare by ensuring that AI models operate safely and predictably, thereby increasing public and clinician confidence in AI-assisted decision-making. Additionally, it has contributed to advancing AI governance and regulation by establishing best practices for AI model validation, supporting compliance with healthcare regulations, and influencing future AI policy frameworks. Beyond healthcare, the techniques developed for AI performance monitoring have interdisciplinary applications in financial modeling, cybersecurity, and industrial automation, ensuring that AI systems across multiple sectors remain reliable, fair, and transparent.\r\n\n\nThis project has laid the groundwork for future AI safety research, paving the way for a scalable, open-source AI evaluation platform that will support hospitals, researchers, and industry leaders in developing trustworthy AI solutions for critical applications.\t\t\t\t\tLast Modified: 02/14/2025\n\n\t\t\t\t\tSubmitted by: GhulamRasool\n"
 }
}