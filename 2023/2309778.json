{
 "awd_id": "2309778",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Theory and Applications of Structure-Conforming Deep Operator Learning",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927212",
 "po_email": "jmead@nsf.gov",
 "po_sign_block_name": "Jodi Mead",
 "awd_eff_date": "2023-06-01",
 "awd_exp_date": "2026-05-31",
 "tot_intn_awd_amt": 156046.0,
 "awd_amount": 156046.0,
 "awd_min_amd_letter_date": "2023-05-30",
 "awd_max_amd_letter_date": "2023-05-30",
 "awd_abstract_narration": "The first-principle-based approach has achieved considerable success in numerous engineering and scientific disciplines, including fluid and solid mechanics, electromagnetism, and more. Among its most significant applications are partial differential equations (PDEs) which, in conjunction with their analysis and numerical algorithms, represent some of the most powerful tools humanity has ever developed for understanding the material world. However, increasingly complex mathematical models arising from physics, biology, and chemistry challenge the efficacy of first-principle-based approaches for solving practical problems, such as those in fluid turbulence, molecular dynamics, and large-scale inverse problems. A major obstacle for numerical algorithms is the so-called curse of dimensionality.  Fueled by advances in Graphics Processing Unit and Tensor Processing Unit general-purpose computing, deep neural networks (DNNs) and deep learning approaches excel in combating the curse of dimensionality and demonstrate immense potential for solving complex problems in science and engineering. This project aims to investigate how mathematical structures within a problem can inform the design and analysis of innovative DNNs, particularly in the context of inverse problems where unknown parameters are inferred from measurements, such as electrical impedance tomography. Additionally, the programming component in this project will focus on training the next generation of computational mathematicians.\r\n\r\nThe Operator Learning (OpL) framework in deep learning provides a unique perspective for tackling challenging and potentially ill-posed PDE-based problems. This project will explore the potential of OpL to mitigate the ill-posedness of many inverse problems, as its powerful approximation capability combined with offline training and online prediction properties lead to high-quality, rapid reconstructions. The project seeks to bridge OpL and classical methodologies by integrating mathematical structures from classical problem-solving approaches into DNN architectures. In particular, the project will shed light on the mathematical properties of the attention mechanism, the backbone of state-of-the-art DNN Transformers, such as those in GPT and AlphaFold 2.  Furthermore, the project will examine the flexibility of attention neural architectures, enabling the fusion of attention mechanisms with important methodologies in applied mathematics, such as Galerkin projection or Fredholm integral equations, in accordance with the a priori mathematical structure of a problem. This project will also delve into the mathematical foundations of attention through the lens of spectral theory in Hilbert spaces, seeking to understand how the emblematic query-key-value architecture contributes to the rich representational power and diverse approximation capabilities of Transformers.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shuhao",
   "pi_last_name": "Cao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shuhao Cao",
   "pi_email_addr": "scao@umkc.edu",
   "nsf_id": "000765850",
   "pi_start_date": "2023-05-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Missouri-Kansas City",
  "inst_street_address": "118 UNIVERSITY HALL",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBIA",
  "inst_state_code": "MO",
  "inst_state_name": "Missouri",
  "inst_phone_num": "8162355839",
  "inst_zip_code": "652113020",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "MO03",
  "org_lgl_bus_name": "THE CURATORS OF THE UNIVERSITY OF MISSOURI",
  "org_prnt_uei_num": "",
  "org_uei_num": "J9CDGR596MN3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Missouri-Kansas City",
  "perf_str_addr": "5100 ROCKHILL RD",
  "perf_city_name": "KANSAS CITY",
  "perf_st_code": "MO",
  "perf_st_name": "Missouri",
  "perf_zip_code": "641102446",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MO05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 156046.0
  }
 ],
 "por": null
}