{
 "awd_id": "2310834",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Simulation-based Inference through Random Features",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2023-08-15",
 "awd_exp_date": "2026-07-31",
 "tot_intn_awd_amt": 225000.0,
 "awd_amount": 225000.0,
 "awd_min_amd_letter_date": "2023-07-26",
 "awd_max_amd_letter_date": "2023-07-26",
 "awd_abstract_narration": "Scientists use simulations to model all kinds of complex systems, from astronomy and ecology, through climatology and finance, to epidemiology and chemical engineering. Once scientists pin down all the parameters in a simulation model, it's easy to run it forward and see what it predicts. Going the other way, from outcomes back to parameters, is usually much harder, but it's the crucial step in fitting models to actual data from the real world, and so knowing which simulations are trustworthy. Good simulation modelers put lots of time and effort into working out what the crucial aspects or \"features\" of the data are for their models, and then adjusting their models so the simulation output matches those features of real data. This project aims to make such simulation-based inference nearly automatic. Bringing together ideas machine learning and nonlinear dynamics shows that simulation models can be fit by matching about two randomly-chosen features for every parameter. The project will make this into a practical and generic tool for simulation, by adapting the basic method to work with different types of data (time series, spatial, networks, etc.), writing software to automatically pick the features and adjust the model parameters, and developing statistical methods to quantify the uncertainty of the results. This can benefit every area of science and technology that uses simulations. The project will contribute to the training of STEM researchers through the involvement of a post-doctoral fellow and a graduate student.\r\n\r\nScientists increasingly express their ideas in generative models which produce fine-grained simulations of the processes they study. Traditional statistical approaches to parameter inference are ill-adapted to such models: just evaluating the likelihood function is usually computationally intractable, never mind optimizing it. Many techniques of simulation-based inference have developed in response, but these typically require picking multiple summary statistics or features, and tuning the generative model's parameters so that summaries calculated on simulations match those calculated on empirical data. Practitioners often spend considerable effort on carefully designing these summaries, aiming to minimize the loss of information from the full data. This project will free simulation-based inference from the need to design informative summaries, by instead using random functions of the data. This draws on two literatures not previously connected to simulation-based inference. One is work in machine learning over the last decade, which has highlighted the power of \"random features\", showing that predictions based on random functions of high-dimensional data are nearly as good as predictions based on optimal functions of the data. The other is now-classic work in nonlinear dynamics from the 1980s and 1990s, which suggests that 2d+1 random features should suffice to capture d underlying parameters. Bringing these ideas together with the well-established results on simulation-based inference will provide a simple, practical methodology of parameter estimation, uncertainty quantification and hypothesis testing, applicable to a wide range of modern simulation models.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cosma",
   "pi_last_name": "Shalizi",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Cosma R Shalizi",
   "pi_email_addr": "cshalizi@cmu.edu",
   "nsf_id": "000477036",
   "pi_start_date": "2023-07-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 FORBES AVE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 225000.0
  }
 ],
 "por": null
}