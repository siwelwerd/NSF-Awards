{
 "awd_id": "2331831",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SLES: A Theoretical Lens on Generative AI Safety: Near and Long Term",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2023-11-01",
 "awd_exp_date": "2026-10-31",
 "tot_intn_awd_amt": 800000.0,
 "awd_amount": 800000.0,
 "awd_min_amd_letter_date": "2023-09-18",
 "awd_max_amd_letter_date": "2023-09-18",
 "awd_abstract_narration": "Generative AI technologies like ChatGPT have taken the world by storm with their ability to synthesize strikingly coherent text, code, and more. The pace with which these systems continue to improve in quality and increasingly shape diverse facets of society and industry is remarkable, yet the field's proficiency in controlling and ensuring the reliability of these systems has not quite kept up. These models remain notoriously prone to confidently making factually incorrect yet convincing-sounding statements. Even when they in principle have all of the knowledge that they need to prevent this, the models often still stumble in putting the pieces together. As this technology makes its way into mission-critical contexts like healthcare or policy decisions, it is crucial to avoid such failure modes. This research will develop mathematically rigorous AI deployment methods that come with solid theoretical assurances that the systems will not stray from their intended behavior in this way. The findings of this project will be instrumental in establishing sustainable checks and fail safes so that generative AI technologies can scale in a controlled fashion that is aligned with human interests. \r\n\r\nThe research aims to tackle a mixture of both near-term challenges in safety for generative AI as well as emerging, longer-term ones that will arise as these models grow in their capabilities. For the former, the project will establish mathematical parameters for factuality and non-hallucination in generative models. This encompasses detecting instances when models make factual assertions, calibrating confidence scores for these assertions, reliably attributing these assertions to their sources in the training data, and encouraging models to abstain from generation when faced with sufficiently out-of-distribution input. Another goal is investigating methodologies to elicit and edit knowledge stored in generative models, as well as isolating fundamental barriers to doing so based on tools from fine-grained complexity theory and computational notions of entropy. For safety in the longer-term, the project will examine the feasibility of integrating emergency stop functionality into AI systems based on cryptographic backdoors, as well as implementing \"AI arms protocols\" based on zero knowledge proofs to publicly certify their safety properties while keeping certain components of these systems private. The research will also rigorously stress-test existing proposals for scalable oversight of AI systems, like natural-language debate and iterated amplification, using techniques from combinatorial game theory and average-case analysis of recursive heuristics.\r\n\r\nThis research is supported by a partnership between the National Science Foundation and Open Philanthropy.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sitan",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sitan Chen",
   "pi_email_addr": "sitan@seas.harvard.edu",
   "nsf_id": "000840633",
   "pi_start_date": "2023-09-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Boaz",
   "pi_last_name": "Barak",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Boaz Barak",
   "pi_email_addr": "b@boazbarak.org",
   "nsf_id": "000063068",
   "pi_start_date": "2023-09-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sham",
   "pi_last_name": "Kakade",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sham Kakade",
   "pi_email_addr": "sham@seas.harvard.edu",
   "nsf_id": "000553028",
   "pi_start_date": "2023-09-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University",
  "perf_str_addr": "150 Western Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021341037",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "248Y00",
   "pgm_ele_name": "AI-Safety"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "4082CYXXDB",
   "fund_name": "NSF TRUST FUND",
   "fund_symb_id": "048960"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 800000.0
  }
 ],
 "por": null
}