{
 "awd_id": "2240133",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Extended Reality Meets AI: Designing Interactions for Novel Human-AI Systems",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924420",
 "po_email": "cbethel@nsf.gov",
 "po_sign_block_name": "Cindy Bethel",
 "awd_eff_date": "2023-09-01",
 "awd_exp_date": "2028-08-31",
 "tot_intn_awd_amt": 606290.0,
 "awd_amount": 230952.0,
 "awd_min_amd_letter_date": "2023-02-24",
 "awd_max_amd_letter_date": "2024-07-12",
 "awd_abstract_narration": "Research in human-computer interaction aims to develop user-centered systems that provide access to effective lifelong learning across the full range of knowledge domains and skills. A key area is learning motor or physical skills of tremendous practical (such as training for surgery), scientific (such as understanding motor memory) and cultural (such as music and sports) interest. To learn new motor skills or recover them after an injury, people often need intensive training or rehabilitation therapy with an expert who can instruct, assess performance, provide feedback, support, and motivate. Working with an expert can ensure learners achieve desired results, exercise correctly, avoid injury, and gain insights into their own performance. But an expert may not always be accessible or available, particularly in situations where demand for experts exceeds supply or when people have personal, monetary, or geographic limitations that prevent access. To deal with the absence of an expert, alternatives for learning at home include books, videos, apps, and online services (such as ClassPass, Peloton, Mirror). Although these options successfully provide explanations and demonstrations, none of them can provide meaningful real-time feedback to the trainees. This project leverages recent advances in Artificial Intelligence (AI) and eXtended Reality (XR) technologies to build new types of interactive motor skill training and rehabilitation systems where users receive real-time feedback from AI agents represented as 3D avatars. By building AI agents that emulate the real-time verbal and non-verbal behaviors of a human expert, the project will provide foundational knowledge on underlying principles that govern human-AI interactions in the context of motor skill learning (specifically, rehabilitation therapy). The project has the potential to broaden access to motor skill learning and rehabilitation at home by reducing financial or psychological barriers at low cost, with low intrusion, and at scale. Given that algorithms are increasingly making inroads into societally consequential domains, understanding how humans and AI agents interact has broad potential implications for the design of responsible and explainable AI. \r\n\r\nThe goal of this project is to investigate the design of AI-XR (artificial intelligence - extended reality) systems for motor skill learning and rehab. Specifically, the project advances a new human-AI interface paradigm in which the AI is represented as a 3D humanoid agent in XR that can mimic the real-time verbal and non-verbal behaviors of a human trainer to support motor learning in the absence of a human expert. Human expert trainers make use of multimodal feedback through visual, auditory, and haptic channels when providing the necessary explanations, demonstrations, and corrections of physical motion performance. To emulate natural interactions between a trainee and an expert trainer, the AI agents will be designed to recognize and respond to a user\u2019s physical actions in real-time to near-real-time, appear and act human-like, and use verbal and non-verbal behaviors (such as eye gaze, head nods, facial expressions, and gestures) to communicate. Developing AI agents for motor learning therefore presents numerous technical and generalizable research challenges, including (i) how to design effective multimodal instruction and feedback mechanisms and (ii) how to enable natural interactions between the user and an AI agent. To tackle these challenges, the project will implement new (i) algorithms and AI models for comprehensive body motion and error analysis; (ii) multimodal instruction and feedback techniques; and (iii) applications for fitness training and rehab that demonstrate the new human-AI interaction paradigm. The AI agent and system designs will be evaluated by performing controlled experiments with users. The evaluation of this research project will be through three applications for: (1) physical fitness, (2) sports injury rehabilitation, and (3) facial paralysis rehabilitation. Implementations of parts of this research in play- and peer-based educational activities for middle and high school students will be designed to be interactive and engaging, while eliciting problem solving and critical thinking. The goal is to guide the next generation to think deeply about AI and its implications on human behavior and by extension, on society.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Misha",
   "pi_last_name": "Sra",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Misha Sra",
   "pi_email_addr": "sra@cs.ucsb.edu",
   "nsf_id": "000812687",
   "pi_start_date": "2023-02-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Barbara",
  "inst_street_address": "3227 CHEADLE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA BARBARA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8058934188",
  "inst_zip_code": "931060001",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SANTA BARBARA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G9QBQDH39DF4"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Barbara",
  "perf_str_addr": "3227 CHEADLE HALL",
  "perf_city_name": "SANTA BARBARA",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "931060001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002728DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 113893.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 117059.0
  }
 ],
 "por": null
}