{
 "awd_id": "2334061",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: SaTC: RUI: Understanding and Addressing the Security and Privacy Needs of At-Risk Populations",
 "cfda_num": "47.070, 47.075",
 "org_code": "05050000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2023-03-15",
 "awd_exp_date": "2024-03-31",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 71209.0,
 "awd_min_amd_letter_date": "2023-07-13",
 "awd_max_amd_letter_date": "2023-11-10",
 "awd_abstract_narration": "Technology and the internet are increasingly involved in our personal as well as public lives, providing people with many benefits, but also creating risks to our privacy. Minority and marginalized groups especially benefit from information, community, and social engagement when they use technology. However, they are also in more danger. They are more likely to be targeted, and may have fewer resources to protect themselves. Technology may not be designed for their needs. Such groups are especially at risk when their personal lives are revealed and, in some cases, communicated to many online. They can face a variety of unusual security and privacy concerns, including the revelation of their offline identity, targeted harassment or doxing, and usability failures such as account lockout when interacting with security systems that use abnormal behavior (such as the use of pseudonyms) as heuristics for suspicion. This project will study how people who may be at risk use technology and what security and privacy dangers they experience. It has the goal to create new technology that better meets the needs of all people in our society. \r\n\r\nThis project investigates how people's personal lives can be compromised online and what computer security and privacy challenges they have. The project uses surveys and interviews, and designs systems informed by the results of those data. Contributions will include the development of guidelines for inclusive design and the generalization of those guidelines to marginalized groups, the creation of new systems responding to problems faced by these groups, and the evaluation of the effectiveness of these systems for supporting users' real world needs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ada",
   "pi_last_name": "Lerner",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ada Lerner",
   "pi_email_addr": "ada@ccs.neu.edu",
   "nsf_id": "000749243",
   "pi_start_date": "2023-07-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 HUNTINGTON AVE",
  "perf_city_name": "BOSTON",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9229",
   "pgm_ref_txt": "RES IN UNDERGRAD INST-RESEARCH"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 71209.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-9340ac8a-7fff-6a75-0fcb-4144801dca1f\"> </span></p>\n<p dir=\"ltr\"><span>Technology is everywhere today, and everyone faces security and privacy challenges. However, some people face especially strong challenges because they are commonly targeted, are disadvantaged in society, or are otherwise vulnerable to harm. Such groups are important to study, both to protect them and to learn from the expertise they often develop about how to protect themselves individually and collectively. Studying these groups can therefore help make society more equitable not just for these groups but for others as well. We used a variety of methods, including interviews, surveys, and measurements of the web and social media, to study vulnerable groups, develop insights and new theories to describe their experiences, and guide people who make technology and researchers on how to build and use technology in ways that are safer for all.</span></p>\n<p dir=\"ltr\"><span>Students and early career scientists from many backgrounds got to conduct research and explore career options through this project, with 9 undergraduate students, 1 PhD student, 1 postdoctoral researcher, and 1 early career principal investigator conducting the research and authoring scientific papers. Here, we summarize key results from peer-reviewed publications from this project:</span></p>\n<p dir=\"ltr\"><span>&nbsp;</span>1) Online survey platforms are often used by researchers who need to survey lots of people. We wanted to know how representative of a) the general population and, b) specific, vulnerable populations the people who take surveys on these platforms are. We compared the results of a survey we ran on several platforms with the results of that same survey run by the Pew Research Center using best practices for representative surveys. We found that for certain types of questions, the responses of online participants are quite representative. But, people in online samples were significantly different in certain ways, such as in their factual knowledge about computer security and privacy. We also found that in general, the more vulnerable a population, the less accurate an online sample is. This guides researchers to know when they can use this convenient way of finding people to survey and when they must use other methods to accurately understand people's experiences of security and privacy.</p>\n<p dir=\"ltr\">2) Researchers have increasingly recognized the importance of investigating the experiences of vulnerable populations; however, our work found that lumping people together simply because of their demographics can be less effective, especially when it comes to security and privacy research, because the ways that people protect themselves and their communities are intimately related to the specific activities in which they are involved. We learned this by studying people who are members of the fandoms for various media, who often share identity characteristics that make them vulnerable and whose privacy practices are deeply informed by the cultural norms of the community of fans. We hope that this will support future work by our group and by others to expand these lessons to other examples of what we call \"activity-defined communities\".</p>\n<p dir=\"ltr\">3) Bridging the space between research and practical advice, we looked at how people understand (or misunderstand) words that are commonly used to discuss both legal and technical aspects of privacy. We found that different words or phrases are misunderstood much more or less often than other words or phrases. We also found that these misunderstandings vary significantly in terms of how they make people feel, such as in terms of how much they trust a service or app that uses the term to describe data privacy practices. We hope that these results can inform researchers, app makers, and regulators in determining when people are likely to be deceived or tricked by language and how people can be given truthful and fair understanding of the apps they use.</p>\n<p dir=\"ltr\">4) We explored how vulnerable populations interact within online communities, including how they think about risks of privacy, hate, and harassment. We call these ways of thinking \"risk models\", and they can help anyone building or regulating technology to understand what people different from themselves are afraid of and how technology can help. We also looked at how people in online fandom share personal information, and how sharing personal information and vulnerability help to build a trusting community that will respect and enforce privacy for one another.</p>\n<p dir=\"ltr\">5) Much of the moderation that takes place on apps such as Reddit and Discord is done by volunteer users with busy lives, making both practical and emotional support key to help them protect their communities from hate and harassment. We categorized the different ways that moderators of vulnerable communities help each other out, describing those ways in detail. We also investigated the ways that the features of an app can be co-opted or abused by people who harass others, and provided advice for how the designers of technology can anticipate these kinds of abuses and design their apps to be harder to abuse.</p><br>\n<p>\n Last Modified: 07/30/2024<br>\nModified by: Ada&nbsp;Lerner</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nTechnology is everywhere today, and everyone faces security and privacy challenges. However, some people face especially strong challenges because they are commonly targeted, are disadvantaged in society, or are otherwise vulnerable to harm. Such groups are important to study, both to protect them and to learn from the expertise they often develop about how to protect themselves individually and collectively. Studying these groups can therefore help make society more equitable not just for these groups but for others as well. We used a variety of methods, including interviews, surveys, and measurements of the web and social media, to study vulnerable groups, develop insights and new theories to describe their experiences, and guide people who make technology and researchers on how to build and use technology in ways that are safer for all.\n\n\nStudents and early career scientists from many backgrounds got to conduct research and explore career options through this project, with 9 undergraduate students, 1 PhD student, 1 postdoctoral researcher, and 1 early career principal investigator conducting the research and authoring scientific papers. Here, we summarize key results from peer-reviewed publications from this project:\n\n\n1) Online survey platforms are often used by researchers who need to survey lots of people. We wanted to know how representative of a) the general population and, b) specific, vulnerable populations the people who take surveys on these platforms are. We compared the results of a survey we ran on several platforms with the results of that same survey run by the Pew Research Center using best practices for representative surveys. We found that for certain types of questions, the responses of online participants are quite representative. But, people in online samples were significantly different in certain ways, such as in their factual knowledge about computer security and privacy. We also found that in general, the more vulnerable a population, the less accurate an online sample is. This guides researchers to know when they can use this convenient way of finding people to survey and when they must use other methods to accurately understand people's experiences of security and privacy.\n\n\n2) Researchers have increasingly recognized the importance of investigating the experiences of vulnerable populations; however, our work found that lumping people together simply because of their demographics can be less effective, especially when it comes to security and privacy research, because the ways that people protect themselves and their communities are intimately related to the specific activities in which they are involved. We learned this by studying people who are members of the fandoms for various media, who often share identity characteristics that make them vulnerable and whose privacy practices are deeply informed by the cultural norms of the community of fans. We hope that this will support future work by our group and by others to expand these lessons to other examples of what we call \"activity-defined communities\".\n\n\n3) Bridging the space between research and practical advice, we looked at how people understand (or misunderstand) words that are commonly used to discuss both legal and technical aspects of privacy. We found that different words or phrases are misunderstood much more or less often than other words or phrases. We also found that these misunderstandings vary significantly in terms of how they make people feel, such as in terms of how much they trust a service or app that uses the term to describe data privacy practices. We hope that these results can inform researchers, app makers, and regulators in determining when people are likely to be deceived or tricked by language and how people can be given truthful and fair understanding of the apps they use.\n\n\n4) We explored how vulnerable populations interact within online communities, including how they think about risks of privacy, hate, and harassment. We call these ways of thinking \"risk models\", and they can help anyone building or regulating technology to understand what people different from themselves are afraid of and how technology can help. We also looked at how people in online fandom share personal information, and how sharing personal information and vulnerability help to build a trusting community that will respect and enforce privacy for one another.\n\n\n5) Much of the moderation that takes place on apps such as Reddit and Discord is done by volunteer users with busy lives, making both practical and emotional support key to help them protect their communities from hate and harassment. We categorized the different ways that moderators of vulnerable communities help each other out, describing those ways in detail. We also investigated the ways that the features of an app can be co-opted or abused by people who harass others, and provided advice for how the designers of technology can anticipate these kinds of abuses and design their apps to be harder to abuse.\t\t\t\t\tLast Modified: 07/30/2024\n\n\t\t\t\t\tSubmitted by: AdaLerner\n"
 }
}