{
 "awd_id": "2242432",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps: Augmented Reality-Powered 3D Interactive Instructions",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922061",
 "po_email": "jcamelio@nsf.gov",
 "po_sign_block_name": "Jaime A. Camelio",
 "awd_eff_date": "2022-11-15",
 "awd_exp_date": "2023-10-31",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2022-11-14",
 "awd_max_amd_letter_date": "2022-11-14",
 "awd_abstract_narration": "The broader impact/commercial potential of this I-Corps project is the development of Augmented Reality (AR)-powered 3D interactive instruction technologies for broad applications in block toys, furniture, manufacturing, building construction, and educational services industries. The products in these industries are becoming increasingly complex and confusing instruction manuals can lead to poor construction or missed educational opportunities for users. By providing the customers with advanced AR-based instructions, the proposed technology is expected to help improve the assembly processes and increase the educational information. The broader impacts of the technology may impact education, design, gaming, medicine, and other industries. \r\n\r\nThis I-Corps project is based on the development of an Augmented Reality (AR)-based technology for the assembly, manufacturing, construction, and education industries. Applications of the proposed technology have been prototyped and evaluated. Using the proposed technology, physical assembly may be guided by virtual parts. In this platform, the technology of realistic object occlusion reveals the true spatial relationships between physical and virtual parts and between users\u2019 real hands and virtual parts, in the step-by-step assembly process. The proposed virtual-physical model alignment is highly accurate using various AR registration methods. The integration of these features makes AR instructions possible for large, small, or tiny parts assembly, validated through working prototypes for assembling artifacts such as block toys and furniture, and through quantitative measures of the accuracies of registration and occlusions. In addition, a heuristic evaluation of features of the proposed technology has led to findings that the method could advance AR instructions in terms of enhancing part visibility, the match between mental models and visualization, and the alignment of physical and virtual parts in perspective views and spatial transformations.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Wei",
   "pi_last_name": "Yan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wei Yan",
   "pi_email_addr": "wyan@tamu.edu",
   "nsf_id": "000486680",
   "pi_start_date": "2022-11-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M University",
  "inst_street_address": "400 HARVEY MITCHELL PKY S STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778454375",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A & M UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JF6XLNB4CDJ5"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M University",
  "perf_str_addr": "3137 TAMU",
  "perf_city_name": "COLLEGE STATION",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433137",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079E",
   "pgm_ref_txt": "VISUALIZATION & VIRTUAL DESIGN"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The project &ldquo;I-Corps: Augmented Reality-Powered 3D Interactive Instructions&rdquo;</span>&nbsp;has <span>investigated the market opportunities of Augmented Reality (AR)-assisted instructions for assembly.</span></p>\n<p><span>Intellectual merit</span>: The team has completed the NSF I-Corps training and conducted more than 140 interviews for customer and partner discovery,&nbsp;with companies, users, educators, vendors, and Mixed Reality (MR) experts. The findings include: the main difficulty in assembly is that conventional 2-Dimensional graphic-based instructions cause costly mistakes and rework in the assembly process, and there is a high demand for a new instruction technology for assembly. Such a new technology has been prototyped as a novel, marker-less, step-by-step, in-situ, multi-3D-models registration-based,&nbsp;highly accurate&nbsp;AR instruction method&nbsp;for large or small part assembly. The prototype employs multiple assembly phase models, each for machine learning-trained, 3D model-based AR registration. The AR registration ensures object recognition and tracking persist during the assembly process. When coupled with a step count, the AR registration enables precise display of the correct virtual part at each step, while the physical 3D model&rsquo;s geometry updates at each step of the assembly. The use of the phases simplifies the complex design of AR-based assembly instructions. Testing and heuristic evaluation findings indicate that the method provides robust instructions for assembly with promising applicability at different model scales and assembly scenarios.</p>\n<p><span>Broader impacts</span>: Utilizing the NSF I-Corps project results, the team and collaborators have developed a business model and a research &amp; development plan for MR-based 3D instructions for assembly, construction, and training, aiming to increase safety and productivity in the Architecture/Engineering/Construction industries, which can be expanded to other industries, such as manufacturing, medicine, and healthcare, and STEM education. The team&rsquo;s project outcomes also include work accepted by IEEE VR 2024 Conference, a PhD dissertation, a provisional patent application, and collaboration for technology commercialization.</p><br>\n<p>\n Last Modified: 02/25/2024<br>\nModified by: Wei&nbsp;Yan</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708304892410_Phases_with_text--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708304892410_Phases_with_text--rgov-800width.png\" title=\"Multi-3D-Models Registration-Based Augmented Reality (AR) Instructions for Assembly\"><img src=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708304892410_Phases_with_text--rgov-66x44.png\" alt=\"Multi-3D-Models Registration-Based Augmented Reality (AR) Instructions for Assembly\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Multi-3D-Models for AR registration</div>\n<div class=\"imageCredit\">Seda Tuzun Canadinc and Wei Yan</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Wei&nbsp;Yan\n<div class=\"imageTitle\">Multi-3D-Models Registration-Based Augmented Reality (AR) Instructions for Assembly</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708305040722_BRICKxAR_M3DMR_3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708305040722_BRICKxAR_M3DMR_3--rgov-800width.jpg\" title=\"Multi-3D-Models Registration-Based Augmented Reality (AR) Instructions for Assembly\"><img src=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708305040722_BRICKxAR_M3DMR_3--rgov-66x44.jpg\" alt=\"Multi-3D-Models Registration-Based Augmented Reality (AR) Instructions for Assembly\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Multiple 3D models of the assembly for machine learning</div>\n<div class=\"imageCredit\">Seda Tuzun Canadinc and Wei Yan</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Wei&nbsp;Yan\n<div class=\"imageTitle\">Multi-3D-Models Registration-Based Augmented Reality (AR) Instructions for Assembly</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708302877083_BRICKxAR_M3DMR--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708302877083_BRICKxAR_M3DMR--rgov-800width.png\" title=\"Augmented Reality-Powered 3D Interactive Instructions\"><img src=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708302877083_BRICKxAR_M3DMR--rgov-66x44.png\" alt=\"Augmented Reality-Powered 3D Interactive Instructions\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Realistic visualization of assembly steps and accurate registration even if assembly is moved by hand.</div>\n<div class=\"imageCredit\">Seda Tuzun Canadinc and Wei Yan</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Wei&nbsp;Yan\n<div class=\"imageTitle\">Augmented Reality-Powered 3D Interactive Instructions</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708302988856_BRICKxAR_M3DMR_2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708302988856_BRICKxAR_M3DMR_2--rgov-800width.png\" title=\"Multi-3D-Models Registration-Based Augmented Reality Instructions for Assembly\"><img src=\"/por/images/Reports/POR/2024/2242432/2242432_10837857_1708302988856_BRICKxAR_M3DMR_2--rgov-66x44.png\" alt=\"Multi-3D-Models Registration-Based Augmented Reality Instructions for Assembly\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Multi-3D-Models Registration-Based Augmented Reality Instructions for Assembly</div>\n<div class=\"imageCredit\">Seda Tuzun Canadinc and Wei Yan</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Wei&nbsp;Yan\n<div class=\"imageTitle\">Multi-3D-Models Registration-Based Augmented Reality Instructions for Assembly</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe project I-Corps: Augmented Reality-Powered 3D Interactive Instructionshas investigated the market opportunities of Augmented Reality (AR)-assisted instructions for assembly.\n\n\nIntellectual merit: The team has completed the NSF I-Corps training and conducted more than 140 interviews for customer and partner discovery,with companies, users, educators, vendors, and Mixed Reality (MR) experts. The findings include: the main difficulty in assembly is that conventional 2-Dimensional graphic-based instructions cause costly mistakes and rework in the assembly process, and there is a high demand for a new instruction technology for assembly. Such a new technology has been prototyped as a novel, marker-less, step-by-step, in-situ, multi-3D-models registration-based,highly accurateAR instruction methodfor large or small part assembly. The prototype employs multiple assembly phase models, each for machine learning-trained, 3D model-based AR registration. The AR registration ensures object recognition and tracking persist during the assembly process. When coupled with a step count, the AR registration enables precise display of the correct virtual part at each step, while the physical 3D models geometry updates at each step of the assembly. The use of the phases simplifies the complex design of AR-based assembly instructions. Testing and heuristic evaluation findings indicate that the method provides robust instructions for assembly with promising applicability at different model scales and assembly scenarios.\n\n\nBroader impacts: Utilizing the NSF I-Corps project results, the team and collaborators have developed a business model and a research & development plan for MR-based 3D instructions for assembly, construction, and training, aiming to increase safety and productivity in the Architecture/Engineering/Construction industries, which can be expanded to other industries, such as manufacturing, medicine, and healthcare, and STEM education. The teams project outcomes also include work accepted by IEEE VR 2024 Conference, a PhD dissertation, a provisional patent application, and collaboration for technology commercialization.\t\t\t\t\tLast Modified: 02/25/2024\n\n\t\t\t\t\tSubmitted by: WeiYan\n"
 }
}