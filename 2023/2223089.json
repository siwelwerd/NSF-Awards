{
 "awd_id": "2223089",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Developing an Automated Outbound Packing System",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922936",
 "po_email": "emirowsk@nsf.gov",
 "po_sign_block_name": "Ela Mirowski",
 "awd_eff_date": "2023-02-15",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 275000.0,
 "awd_amount": 275000.0,
 "awd_min_amd_letter_date": "2023-02-15",
 "awd_max_amd_letter_date": "2023-02-15",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to enable the fast and efficient loading of parcels into shipping containers ranging from small delivery vans to maritime shipping containers. This project will focus on demonstrating the feasibility of an algorithmic approach and robotic development. The technology is a step towards creating a fully autonomous system with expanded robotics capability to further enhance the efficiency and speed of outbound shipping for customers. Over 3,000 parcels are shipped every second. However, in the U.S., one out of every four trucks is empty, two are less than 50% filled, and only one is filled over 50% capacity.  Initial projections indicate that the technology under development could decrease trucking costs by 20%, reduce loading costs by 70-80%, and decrease loading time by 30%, all while meeting the demands of peak shipping seasons. Overall, increasing the density of parcel shipping will reduce greenhouse gas emissions (400 tons/per truck/per year), reduce traffic congestion, and enable smaller businesses to compete with large organizations by reducing their logistics and shipping operating costs.\r\n\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project will focus on advancing a bin packing algorithm to minimize void space in outbound shipping containers. The 3-Dimentional Bin Packing Problem (3D-BPP) is a classic Nonlinear Programming (NP)-hard problem that has been studied for decades. To solve the problem, an effective and easy-to-implement constrained, quantum accelerated, deep reinforcement learning model is being developed. Monte Carlo Tree Search is an unsupervised, heuristic search algorithm technique in which the learning agent learns to predict the expected value of a variable occurring at the end of a sequence of states. Deep reinforcement learning (DRL) extends this technique by allowing the learned state-values to guide actions which subsequently change the environment state. A proof-of-concept assessment showed that the learned strategy meaningfully outperforms the state-of-the-art methods. Outcome success metrics for this project are >90% utilization rate, sub 24 hours of model training time, and >2500 parcels/hour for any given data set. This foundation will be expanded by integrating many unique box sizes, exploring model performance in the face of broader circumstances (e.g., lookahead and stacking parameters, General Processing Unit (GPU) vs quantum training), and developing of a robotic gripper to enact algorithmic output.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "DAmelio",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Peter DAmelio",
   "pi_email_addr": "pete@gridironrobotics.com",
   "nsf_id": "000848851",
   "pi_start_date": "2023-02-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "GRIDIRON ROBOTICS LLC",
  "inst_street_address": "31 OAK AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHALFONT",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2156055085",
  "inst_zip_code": "189142812",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "PA01",
  "org_lgl_bus_name": "GRIDIRON ROBOTICS LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "P682XB2QANS9"
 },
 "perf_inst": {
  "perf_inst_name": "GRIDIRON ROBOTICS LLC",
  "perf_str_addr": "557 HEATONS MILL DR",
  "perf_city_name": "LANGHORNE",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "190471521",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "PA01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7632",
   "pgm_ref_txt": "HUMAN-ROBOT INTERACTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01AB2324DB",
   "fund_name": "R&RA DRSA DEFC AAB",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 275000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Online 3D Bin Packing Problem (3D-BPP) presents a significant challenge with applications in industrial automation and logistics. Traditional methods often rely on spatial discretization with limited resolution or struggle to address complex practical constraints. Recent advancements have focused on improving the efficiency and applicability of bin packing solutions. Our approach leverages a novel hierarchical representation known as the Packing Configuration Tree (PCT) to address these limitations.</p>\n<p>To enhance the practical applicability of online 3D-BPP, we propose a method that integrates the PCT with Deep Reinforcement Learning (DRL). PCT offers a comprehensive description of the bin packing state and action space, facilitating effective policy learning. Key aspects of the methodology include:</p>\n<ol>\n<li><strong>Packing Configuration Tree (PCT):</strong> A hierarchical representation that details the state and action spaces of bin packing. The size of the action space is proportional to the number of leaf nodes, allowing for efficient training of DRL models even in continuous solution spaces.</li>\n<li><strong>Deep Reinforcement Learning (DRL):</strong> The DRL model is trained using the PCT, learning packing policies that outperform traditional heuristic methods. The DRL approach adapts to various practical constraints and improves the robustness and effectiveness of packing strategies.</li>\n<li><strong>Training Process:</strong> During training, PCT is expanded based on heuristic rules, which helps in refining the DRL model. This combination enables the development of a more effective packing policy compared to heuristic-only methods.</li>\n</ol>\n<p>Our approach has demonstrated superior performance in extensive evaluations, outperforming existing online BPP methods and proving versatile in accommodating different practical constraints.</p>\n<p><strong>Conclusion</strong></p>\n<p>This approach to solving the online 3D Bin Packing Problem (3D-BPP) using the Packing Configuration Tree (PCT) and Deep Reinforcement Learning (DRL) represents a significant advancement in the field. The PCT provides a comprehensive hierarchical representation of the state and action spaces, allowing the DRL agent to be trained efficiently and perform effectively. By leveraging graph attention networks to extract state features from the PCT, our method successfully manages complex practical constraints while keeping the action space manageable.</p>\n<p>We have reinforced the work by adding the following improvements:</p>\n<ol>\n<li><strong>Increased System Size and Capability:</strong> We have enhanced the system to handle more complex scenarios, such as filling an entire 53-foot container. The system can now handle a diverse set of boxes, making it flexible to any set of boxes from common vendors.</li>\n<li><strong>Isaac Sim Integration:</strong> This integration helps simulate system performance and connect all pieces of the work together, providing a cohesive solution.</li>\n<li><strong>Handling Reachability:</strong> We addressed reachability by dividing the entire system into smaller subsystems and filling each portion until the space is fully utilized.</li>\n<li><strong>Look-Ahead Mechanism (Beta):</strong> We have added a look-ahead mechanism that allows the system to see several boxes ahead, increasing the efficiency of the packing scheme.</li>\n</ol>\n<p><strong>Future Work</strong></p>\n<p>Future research will focus on extending our method to address more challenging packing scenarios, such as irregular shape packing. This involves dealing with more complex solution spaces and higher training costs for DRL agents. Key areas for exploration include:</p>\n<ol>\n<li><strong>Further Training on Stronger GPUs:</strong> We aim to train the models on stronger GPUs and larger system sizes to achieve better results in real-world scenarios involving very large system sizes and more diverse sets of boxes.</li>\n<li><strong>Enhanced System with Isaac Sim Feedback Loop:</strong> We plan to implement a new enhanced system that utilizes Isaac Sim in a feedback loop. This will allow the system state to be updated from multiple sources, such as computer vision, ensuring more accurate and efficient packing solutions.</li>\n</ol>\n<p>By continuing to refine and expand our approach, we aim to create a robust solution for the 3D Bin Packing Problem that can be widely applied in various industrial and logistics contexts, offering significant improvements in efficiency and practicality.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 08/16/2024<br>\nModified by: Peter&nbsp;Damelio</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe Online 3D Bin Packing Problem (3D-BPP) presents a significant challenge with applications in industrial automation and logistics. Traditional methods often rely on spatial discretization with limited resolution or struggle to address complex practical constraints. Recent advancements have focused on improving the efficiency and applicability of bin packing solutions. Our approach leverages a novel hierarchical representation known as the Packing Configuration Tree (PCT) to address these limitations.\n\n\nTo enhance the practical applicability of online 3D-BPP, we propose a method that integrates the PCT with Deep Reinforcement Learning (DRL). PCT offers a comprehensive description of the bin packing state and action space, facilitating effective policy learning. Key aspects of the methodology include:\n\nPacking Configuration Tree (PCT): A hierarchical representation that details the state and action spaces of bin packing. The size of the action space is proportional to the number of leaf nodes, allowing for efficient training of DRL models even in continuous solution spaces.\nDeep Reinforcement Learning (DRL): The DRL model is trained using the PCT, learning packing policies that outperform traditional heuristic methods. The DRL approach adapts to various practical constraints and improves the robustness and effectiveness of packing strategies.\nTraining Process: During training, PCT is expanded based on heuristic rules, which helps in refining the DRL model. This combination enables the development of a more effective packing policy compared to heuristic-only methods.\n\n\n\nOur approach has demonstrated superior performance in extensive evaluations, outperforming existing online BPP methods and proving versatile in accommodating different practical constraints.\n\n\nConclusion\n\n\nThis approach to solving the online 3D Bin Packing Problem (3D-BPP) using the Packing Configuration Tree (PCT) and Deep Reinforcement Learning (DRL) represents a significant advancement in the field. The PCT provides a comprehensive hierarchical representation of the state and action spaces, allowing the DRL agent to be trained efficiently and perform effectively. By leveraging graph attention networks to extract state features from the PCT, our method successfully manages complex practical constraints while keeping the action space manageable.\n\n\nWe have reinforced the work by adding the following improvements:\n\nIncreased System Size and Capability: We have enhanced the system to handle more complex scenarios, such as filling an entire 53-foot container. The system can now handle a diverse set of boxes, making it flexible to any set of boxes from common vendors.\nIsaac Sim Integration: This integration helps simulate system performance and connect all pieces of the work together, providing a cohesive solution.\nHandling Reachability: We addressed reachability by dividing the entire system into smaller subsystems and filling each portion until the space is fully utilized.\nLook-Ahead Mechanism (Beta): We have added a look-ahead mechanism that allows the system to see several boxes ahead, increasing the efficiency of the packing scheme.\n\n\n\nFuture Work\n\n\nFuture research will focus on extending our method to address more challenging packing scenarios, such as irregular shape packing. This involves dealing with more complex solution spaces and higher training costs for DRL agents. Key areas for exploration include:\n\nFurther Training on Stronger GPUs: We aim to train the models on stronger GPUs and larger system sizes to achieve better results in real-world scenarios involving very large system sizes and more diverse sets of boxes.\nEnhanced System with Isaac Sim Feedback Loop: We plan to implement a new enhanced system that utilizes Isaac Sim in a feedback loop. This will allow the system state to be updated from multiple sources, such as computer vision, ensuring more accurate and efficient packing solutions.\n\n\n\nBy continuing to refine and expand our approach, we aim to create a robust solution for the 3D Bin Packing Problem that can be widely applied in various industrial and logistics contexts, offering significant improvements in efficiency and practicality.\n\n\n\t\t\t\t\tLast Modified: 08/16/2024\n\n\t\t\t\t\tSubmitted by: PeterDamelio\n"
 }
}