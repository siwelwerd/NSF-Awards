{
 "awd_id": "2331904",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SLES: CRASH - Challenging Reinforcement-learning based Adversarial scenarios for Safety Hardening",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2023-12-01",
 "awd_exp_date": "2026-11-30",
 "tot_intn_awd_amt": 799803.0,
 "awd_amount": 799803.0,
 "awd_min_amd_letter_date": "2023-09-18",
 "awd_max_amd_letter_date": "2023-09-18",
 "awd_abstract_narration": "Autonomous vehicles, with their reliance on learning-enabled components for key operations, promise an exciting future for transportation. Yet, assuring the safety of these vehicles amid unpredictable real-world traffic scenarios filled with 'unknown unknowns' remains a significant hurdle. While on-road testing is essential, it is time-consuming, risky, and insufficient due to the rarity of safety-critical traffic situations. High-fidelity simulations present a promising way to complement these efforts, allowing us to stress-test autonomous vehicles in a myriad of challenging scenarios. This raises key questions: how can we generate rare, but realistic traffic situations in simulation that would truly stress test an autonomous vehicle's safety? Moreover, how can we continuously improve the autonomous vehicle's software to learn from each identified failure? In response, this project offers an innovative approach where we purposefully introduce rare but realistic scenarios in simulation that may cause autonomous vehicles to fail, and then enhance the software to ensure these failures do not reoccur. The implications of the research extends beyond safety improvements, having the potential to redefine industry practices, shape regulatory frameworks for autonomous vehicle safety, and ensure the safe and reliable deployment of autonomous vehicles.\r\n\r\nThe project will develop a new framework, named CRASH - Challenging Reinforcement-learning based Adversarial scenarios for Safety Hardening. CRASH leverages a novel multi-agent adversarial deep reinforcement learning setting to automatically and effectively stress test existing autonomous vehicle software stacks, helping identify potential failures in motion planning. It then enhances the AV's safety performance by improving its ability to avoid repeating these failures and learn from them. Notably, CRASH emphasizes the realistic, plausible, and naturalistic aspects of identified AV failures, mirroring unexpected situations in real-world traffic conditions. The real strength of CRASH is its iterative process, where after each falsification, an improvement simulation leads to continuous enhancement of the autonomous vehicle stack - an approach the team termed safety hardening. This iterative refinement fortifies an AV's safety, allowing it to navigate unexpected traffic situations more efficiently, thereby increasing its resilience. The project provides a pragmatic and reliable pathway to advance the safety testing of autonomous vehicles that rely heavily on learning-enabled components so that they can navigate our roads with an enhanced level of safety and robustness.\r\n\r\nThis research is supported by a partnership between the National Science Foundation and Open Philanthropy.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Madhur",
   "pi_last_name": "Behl",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Madhur Behl",
   "pi_email_addr": "mb2kg@virginia.edu",
   "nsf_id": "000741979",
   "pi_start_date": "2023-09-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Shangtong",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shangtong Zhang",
   "pi_email_addr": "shangtong.zhang.cs@gmail.com",
   "nsf_id": "000925627",
   "pi_start_date": "2023-09-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Virginia Main Campus",
  "inst_street_address": "1001 EMMET ST N",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTESVILLE",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "4349244270",
  "inst_zip_code": "229034833",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "VA05",
  "org_lgl_bus_name": "RECTOR & VISITORS OF THE UNIVERSITY OF VIRGINIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJG6HU8PA4S5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Virginia Main Campus",
  "perf_str_addr": "1001 N EMMET ST",
  "perf_city_name": "CHARLOTTESVILLE",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "229034833",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "VA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "248Y00",
   "pgm_ele_name": "AI-Safety"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "4082CYXXDB",
   "fund_name": "NSF TRUST FUND",
   "fund_symb_id": "048960"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 799803.0
  }
 ],
 "por": null
}