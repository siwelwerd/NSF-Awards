{
 "awd_id": "2319507",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FMiTF: Track-2 : Rigorous and Scalable Formal Floating-Point Error Analysis from LLVM",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2023-08-01",
 "awd_exp_date": "2025-01-31",
 "tot_intn_awd_amt": 100000.0,
 "awd_amount": 100000.0,
 "awd_min_amd_letter_date": "2023-07-19",
 "awd_max_amd_letter_date": "2023-07-19",
 "awd_abstract_narration": "This project aims to enhance the reliability of numerical computations running on modern processing hardware by ensuring that the imprecision related errors due to finite machine representation sizes are within acceptable limits. In particular, this work targets arithmetic rounding caused by the floating-point number system. It is important to contain numerical error, given that critical scientific simulation data or important machine learning-related data are represented inside the computer memory. With the growing pressure to optimize on data movement in order to reduce energy consumption, many programs are switching to even lower precision numerical representations. This trend can introduce additional errors and hence one cannot really hope to eliminate all the error, but instead design algorithms that tolerate this error. This project develops a framework based on the versatile and popular LLVM language technologies within which multiple collaborating error analysis tools can be plugged in.\r\n\r\nThe core technical approach taken in this work is the choice of LLVM as a common intermediate form for error analysis. While many academic research tools for such error analysis have been created, they cannot interoperate nor allow traditional programs to be subject to error analysis. The project proposes a framework called LLFPError that allows error analysis tools that target different error types to be integrated. This provides the designer with a comprehensive picture of numerical errors, including highlighting errors such as catastrophic cancellation, floating-point exceptions and floating-point rounding errors. The study and refinement of error analysis tools must be driven by realistic programming constructs but offered in a simplified form so as not to inundate the analysis tool. In this regard, the LLFPError will run program-slicing tools on realistic kernels that have been employed in the field. With this, LLFPError will not run the risk of analyzing examples that fall within a narrow scope.  This also allows this project to harden existing error analysis tools as well as develop newer tools and release such tools along with our extended benchmark suite. This project, across two years, will result in the release of integrated error analysis tools as well as realistic examples. This helps meet one of the important needs in high performance computing (HPC) and machine learning (ML), namely versatile and comprehensive error analysis. Our eventual goal is to help grow the community of tool builders who target HPC and ML, thus paving the way for more reliable scientific simulations as well as reliable and explainable machine learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ganesh",
   "pi_last_name": "Gopalakrishnan",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Ganesh L Gopalakrishnan",
   "pi_email_addr": "ganesh@cs.utah.edu",
   "nsf_id": "000160895",
   "pi_start_date": "2023-07-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "201 PRESIDENTS CIR",
  "perf_city_name": "SALT LAKE CITY",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841129049",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "094Y00",
   "pgm_ele_name": "FMitF: Formal Methods in the F"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "071Z",
   "pgm_ref_txt": "FMitF-Formal Methods in the Field"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 100000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This recently completed project significantly advanced the state-of-the-art in floating-point error analysis through the d\\evelopment of robust tools targeting LLVM-based numerical software. Given the criticality of numerical accuracy across dom\\ains ranging from analyzing ill-conditioned matrices in modern power grids to ensuring correctness in automobile navigatio\\n systems, our work directly addressed an urgent need faced by the numerical programming community. This urgency has been \\heightened by the proliferation of low-precision CPUs and GPUs created in response to the need for low-energy machine lear\\ning applications. Such non-standard hardware often subtly influence numerical correctness due to hardware and compiler-le\\vel variabilities.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<br />The project delivered several tangible outcomes. Foremost among these were tools realized to detect cancellations, measure\\&nbsp;rounding errors, and assess path stability. We successfully implemented shadow-value calculations within FPChecker, achie\\ving acceptable efficiency levels. Comparative analyses against tools such as Candy yielded insights into numerical cancel\\lations.<br />Our efforts also encompassed rounding error analysis via guided random testing combined with symbolic Automatic Differenti\\ation (AD). Leveraging computational graphs and test programs compiled from Varity programs, we recreated and validated pr\\ior results, further implementing path-stability assessments in our SeeSaw tool.</p>\r\n<p><br />A noteworthy contribution has been the development of GPU-FPX as an improved binary analysis method for GPU floating-point programs. Currently GPU-FPX is being extended to cover tensor-core based computations.</p>\r\n<p>&nbsp;</p>\r\n<p>INTELLECTUAL MERITS: A significant highlight was the introduction of the CiRE tool (C++ based Incremental Rigorous Error Analyzer), a welcome a\\nd timely contribution to the LLVM numerical accuracy community. CiRE addresses a fundamental gap: it estimates worst-case\\&nbsp;roundoff errors at the outputs of single-block LLVM IR functions. By interfacing directly with LLVM IR generated by widel\\y used compilers such as Clang, CiRE provides valuable insights into how LLVM's aggressive fast-math optimizations affect \\numerical correctness. Through rigorous error estimation, CiRE enables programmers to quantify and reason about compiler-i\\nduced numerical inaccuracies, empowering informed decisions regarding performance-accuracy trade-offs.</p>\r\n<p>&nbsp;</p>\r\n<p><br />BROADER IMPACTS: We intend to develop the tools from this project further, providing the first solution for numerous pressing needs: (1) tr\\adeoffs between accuracy and speed for compiler-optimized codes, (2) error differences when codes are ported from source l\\anguages (e.g., C and C++) to modern safe languages (e.g., Rust and Julia). These additions will contribute to preserving the semantics of numerical computations when languages evolve and codes are migrated between them.</p>\r\n<p>&nbsp;</p>\r\n<p>FUTURE WORK:&nbsp;<br />Despite its success, CiRE has clear areas for further improvement and extension. Currently, CiRE is limited to single basi\\c blocks, unable to handle conditionals that introduce control-flow divergence. Future directions identified include exten\\ding CiRE to support conditionals and multi-block LLVM IR programs, as well as leveraging parallel execution models to enh\\ance analysis efficiency. Additionally, incorporating hashing-based query reuse techniques demonstrated in other tools suc\\h as Satire could further improve performance.</p>\r\n<p>&nbsp;</p>\r\n<p>CONCLUSIONS:<br />In conclusion, this project contributed numerous tools CiRE emerges as a versatile and powerful tool for compiler programmers, effectively addressing compiler-induced numerical accuracy concerns. It supports mixed-precision analysis, explicitly handles LLVM instructions like `fptrunc` and `fpext`, and provides robust, actionable insights into numerical errors indu\\ced by optimization passes.</p><br>\n<p>\n Last Modified: 04/19/2025<br>\nModified by: Ganesh&nbsp;L&nbsp;Gopalakrishnan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis recently completed project significantly advanced the state-of-the-art in floating-point error analysis through the d\\evelopment of robust tools targeting LLVM-based numerical software. Given the criticality of numerical accuracy across dom\\ains ranging from analyzing ill-conditioned matrices in modern power grids to ensuring correctness in automobile navigatio\\n systems, our work directly addressed an urgent need faced by the numerical programming community. This urgency has been \\heightened by the proliferation of low-precision CPUs and GPUs created in response to the need for low-energy machine lear\\ning applications. Such non-standard hardware often subtly influence numerical correctness due to hardware and compiler-le\\vel variabilities.                                                    \nThe project delivered several tangible outcomes. Foremost among these were tools realized to detect cancellations, measure\\rounding errors, and assess path stability. We successfully implemented shadow-value calculations within FPChecker, achie\\ving acceptable efficiency levels. Comparative analyses against tools such as Candy yielded insights into numerical cancel\\lations.\nOur efforts also encompassed rounding error analysis via guided random testing combined with symbolic Automatic Differenti\\ation (AD). Leveraging computational graphs and test programs compiled from Varity programs, we recreated and validated pr\\ior results, further implementing path-stability assessments in our SeeSaw tool.\r\n\n\n\nA noteworthy contribution has been the development of GPU-FPX as an improved binary analysis method for GPU floating-point programs. Currently GPU-FPX is being extended to cover tensor-core based computations.\r\n\n\n\r\n\n\nINTELLECTUAL MERITS: A significant highlight was the introduction of the CiRE tool (C++ based Incremental Rigorous Error Analyzer), a welcome a\\nd timely contribution to the LLVM numerical accuracy community. CiRE addresses a fundamental gap: it estimates worst-case\\roundoff errors at the outputs of single-block LLVM IR functions. By interfacing directly with LLVM IR generated by widel\\y used compilers such as Clang, CiRE provides valuable insights into how LLVM's aggressive fast-math optimizations affect \\numerical correctness. Through rigorous error estimation, CiRE enables programmers to quantify and reason about compiler-i\\nduced numerical inaccuracies, empowering informed decisions regarding performance-accuracy trade-offs.\r\n\n\n\r\n\n\n\nBROADER IMPACTS: We intend to develop the tools from this project further, providing the first solution for numerous pressing needs: (1) tr\\adeoffs between accuracy and speed for compiler-optimized codes, (2) error differences when codes are ported from source l\\anguages (e.g., C and C++) to modern safe languages (e.g., Rust and Julia). These additions will contribute to preserving the semantics of numerical computations when languages evolve and codes are migrated between them.\r\n\n\n\r\n\n\nFUTURE WORK:\nDespite its success, CiRE has clear areas for further improvement and extension. Currently, CiRE is limited to single basi\\c blocks, unable to handle conditionals that introduce control-flow divergence. Future directions identified include exten\\ding CiRE to support conditionals and multi-block LLVM IR programs, as well as leveraging parallel execution models to enh\\ance analysis efficiency. Additionally, incorporating hashing-based query reuse techniques demonstrated in other tools suc\\h as Satire could further improve performance.\r\n\n\n\r\n\n\nCONCLUSIONS:\nIn conclusion, this project contributed numerous tools CiRE emerges as a versatile and powerful tool for compiler programmers, effectively addressing compiler-induced numerical accuracy concerns. It supports mixed-precision analysis, explicitly handles LLVM instructions like `fptrunc` and `fpext`, and provides robust, actionable insights into numerical errors indu\\ced by optimization passes.\t\t\t\t\tLast Modified: 04/19/2025\n\n\t\t\t\t\tSubmitted by: GaneshLGopalakrishnan\n"
 }
}