{
 "awd_id": "2212930",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Robotic system outputting natural tactile-sign language to aid Deaf and Deafblind communication",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922936",
 "po_email": "emirowsk@nsf.gov",
 "po_sign_block_name": "Ela Mirowski",
 "awd_eff_date": "2023-02-15",
 "awd_exp_date": "2023-10-31",
 "tot_intn_awd_amt": 255975.0,
 "awd_amount": 255975.0,
 "awd_min_amd_letter_date": "2023-02-06",
 "awd_max_amd_letter_date": "2023-02-06",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will contribute to the fields of low-cost anthropomorphic robotics as well as machine translation. Leveraging advancements in low-cost manufacturing and deep learning, the project is developing an accessible and state-of-the-art complaint robot with robust remote processing. Using remote processing to avoid expensive microprocessors and memory capabilities, the proposed cloud server can capture any wifi-based communication and entertainment, while translating language with custom standards and user preferences in real-time. By granting DeafBlind (DB) individuals newfound independence and privacy, the success of the project will revolutionize how DB individuals interact with their community as well as provide immediate access to the abled world\u2019s resources. The market opportunity is estimated at $213 billion annually. This product will have a significant impact on the assistive technology field, targeting the historically underserved DB populations, for whom there is little innovation. Importantly, this would be the first commercialized signing robot. \r\n\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project will provide a convenient and accessible method for DeafBlind (DB) people to interact with the world. The current lack of communication aides among the DB community requires all people with severe deafblindness to rely on human interpreters to interact with the hearing/sighted world. However, with extensive lead times for these expensive services, DB individuals regularly experience isolation and loneliness. This research aims to achieve a fully compliant, flexible fingerspelling anthropomorphic hand. Additionally, this research aims to develop the first architecture for translating between a spoken and signed language. Technical research requires investigation into motion capture mapping and storage of continuous motion as well as tendon actuation schemes to achieve a low-cost 18 degrees of freedom robotic hand. Additionally, linguistics research explores DB language usage (syntax, morphology, sign production, etc.) as well as preferences based on demographic data. Anticipated technical results include a robotic hand that can sign with >90% recognition from DB users, signing at variable speeds ranging from one to two signs per second with accurate translation patterns between the source language and outputted tactile signs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Samantha",
   "pi_last_name": "Johnson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Samantha Johnson",
   "pi_email_addr": "Sjohnson@tatumrobotics.com",
   "nsf_id": "000869115",
   "pi_start_date": "2023-02-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "TATUM ROBOTICS LLC",
  "inst_street_address": "37 COTTAGE ST",
  "inst_street_address_2": "",
  "inst_city_name": "HUDSON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "9786188598",
  "inst_zip_code": "017491513",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "MA03",
  "org_lgl_bus_name": "TATUM ROBOTICS LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "T96WB9YLSG29"
 },
 "perf_inst": {
  "perf_inst_name": "Tatum Robotics",
  "perf_str_addr": "37 Cottage St",
  "perf_city_name": "Hudson",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "017491513",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "MA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7632",
   "pgm_ref_txt": "HUMAN-ROBOT INTERACTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01AB2324DB",
   "fund_name": "R&RA DRSA DEFC AAB",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 255975.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Tatum Robotics&rsquo; NSF SBIR Phase I supported the research and development of an anthropomorphic robotic device, the Tatum T1, that can output the fingerspelled alphabet of American Sign Language (ASL). The Tatum T1 can convert any English text input into ASL fingerspelling output. This output, performed on a human-like robotic hand/wrist system made of 3D-printed materials, would make things like eBooks, emails, text messages, and news articles accessible to the DeafBlind community for the first time in their primary language.</p>\n<p>Because they can neither near nor see, DeafBlind individuals use a tactile form of sign language. This means that when a person signs to a DeafBlind person, the DeafBlind person keeps a hand over the signer's hand, receiving the language through touch. The Tatum T1 works the same way, as a signing partner for a DeafBlind person to understand through touch. This community has faced little to no learning curve receiving the device's output since the robot mirrors the language they receive from other people in their everyday lives.</p>\n<p>This NSF Phase I had three major components. In terms of hardware, the team achieved the actuation of all 45 handshapes required of ASL, developed a DeafBlind-friendly user interface, and integrated haptic feedback to signal messages to the user. Software efforts keep the robot's data in the cloud, making it easily customizable even from afar. Linguistics developments include the conversion of English text into clear handshapes, as well as translation rules that make it possible to translate English text into a variety of ASL gloss outputs.</p>\n<p>The Tatum T1's hardware is comprised of a fully compliant robotic system with 18 degrees of freedom that can achieve complex handshapes without ever harming a user by gripping with too much force. Importantly, Tatum Robotics prioritizes the opinions and perspectives of DeafBlind community members at every stage of project development. Every facet of the Tatum T1 has been evaluated by DeafBlind individuals; the user interface, the hand movements, the timings of the motion, the language output, the content the Tatum T1 delivers, the functions the robot performs, etc. have all been thoroughly tested with DeafBlind individuals.</p>\n<p>So far, the Tatum T1 has shown a recognition rate of 98% with 45 DeafBlind testers. Our translations from English into glossed tactile ASL achieve success rates between 80% - 90%. The Tatum team remains excited about the opportunities awarded by the SBIR Phase I grant, and DeafBlind folks eagerly anticipate the next phase for the Tatum T1.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/20/2023<br>\nModified by: Samantha&nbsp;Johnson</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nTatum Robotics NSF SBIR Phase I supported the research and development of an anthropomorphic robotic device, the Tatum T1, that can output the fingerspelled alphabet of American Sign Language (ASL). The Tatum T1 can convert any English text input into ASL fingerspelling output. This output, performed on a human-like robotic hand/wrist system made of 3D-printed materials, would make things like eBooks, emails, text messages, and news articles accessible to the DeafBlind community for the first time in their primary language.\n\n\nBecause they can neither near nor see, DeafBlind individuals use a tactile form of sign language. This means that when a person signs to a DeafBlind person, the DeafBlind person keeps a hand over the signer's hand, receiving the language through touch. The Tatum T1 works the same way, as a signing partner for a DeafBlind person to understand through touch. This community has faced little to no learning curve receiving the device's output since the robot mirrors the language they receive from other people in their everyday lives.\n\n\nThis NSF Phase I had three major components. In terms of hardware, the team achieved the actuation of all 45 handshapes required of ASL, developed a DeafBlind-friendly user interface, and integrated haptic feedback to signal messages to the user. Software efforts keep the robot's data in the cloud, making it easily customizable even from afar. Linguistics developments include the conversion of English text into clear handshapes, as well as translation rules that make it possible to translate English text into a variety of ASL gloss outputs.\n\n\nThe Tatum T1's hardware is comprised of a fully compliant robotic system with 18 degrees of freedom that can achieve complex handshapes without ever harming a user by gripping with too much force. Importantly, Tatum Robotics prioritizes the opinions and perspectives of DeafBlind community members at every stage of project development. Every facet of the Tatum T1 has been evaluated by DeafBlind individuals; the user interface, the hand movements, the timings of the motion, the language output, the content the Tatum T1 delivers, the functions the robot performs, etc. have all been thoroughly tested with DeafBlind individuals.\n\n\nSo far, the Tatum T1 has shown a recognition rate of 98% with 45 DeafBlind testers. Our translations from English into glossed tactile ASL achieve success rates between 80% - 90%. The Tatum team remains excited about the opportunities awarded by the SBIR Phase I grant, and DeafBlind folks eagerly anticipate the next phase for the Tatum T1.\n\n\n\t\t\t\t\tLast Modified: 11/20/2023\n\n\t\t\t\t\tSubmitted by: SamanthaJohnson\n"
 }
}