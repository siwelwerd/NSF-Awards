{
 "awd_id": "2303820",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: OAC: An Efficient Lossy Compression Framework for Reducing Memory Footprint for Extreme-Scale Deep Learning on GPU-Based HPC Systems",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032922625",
 "po_email": "jjli@nsf.gov",
 "po_sign_block_name": "Juan Li",
 "awd_eff_date": "2022-10-01",
 "awd_exp_date": "2024-04-30",
 "tot_intn_awd_amt": 174593.0,
 "awd_amount": 92649.0,
 "awd_min_amd_letter_date": "2022-10-28",
 "awd_max_amd_letter_date": "2022-10-28",
 "awd_abstract_narration": "Deep learning (DL) has rapidly evolved to a state-of-the-art technique in many science and technology disciplines, such as scientific exploration, national security, smart environment, and healthcare. Many of these DL applications require using high-performance computing (HPC) resources to process large amounts of data. Researchers and scientists, for instance, are employing extreme-scale DL applications in HPC infrastructures to classify extreme weather patterns and high-energy particles. In recent years, using Graphics Processing Units (GPUs) to accelerate DL applications has attracted increasing attention. However, the ever-increasing scales of DL applications bring many challenges to today\u2019s GPU-based HPC infrastructures. The key challenge is the huge gap (e.g., one to two orders of magnitude) between the memory requirement and its availability on GPUs. This project aims to fill this gap by developing a novel framework to reduce the memory demand effectively and efficiently via data compression technologies for extreme-scale DL applications. The proposed research will enhance the GPU-based HPC infrastructures in broad communities for many scientific disciplines that rely on DL technologies. The project will connect machine learning and HPC communities and increase interactions between them. Educational and engagement activities include developing new curriculum related to data compression, mentoring a selected group of high school students in a year-long  research project for a regional Science Fair competition, and increasing the community's understanding of leveraging HPC infrastructures for DL technologies. The project will also encourage student interest in research related to DL technologies on HPC environment and promote research collaborations with multiple national laboratories.\r\n\r\nExisting state-of-the-art GPU memory saving methods for training extreme-scale deep neural networks (DNNs) suffer from high performance overhead and/or low memory footprint reduction. Error-bounded lossy compression is a promising approach to significantly reduce the memory footprint while still meeting the required analysis accuracy. This project will explore how to leverage error-bounded lossy compression on DNN intermediate data to reduce the memory footprint for extreme-scale DNN training. The project has a three-stage research plan. First, the team will comprehensively investigate the impacts of applying error-bounded lossy compression to DNN intermediate data on both validation accuracy and training performance, using different error-bounded lossy compressors, compression modes, and error bounds on the targeted DNNs and datasets. Second, the team will optimize the compression quality of suitable error-bounded lossy compressors on different intermediate data based on the impact analysis outcome, and design an efficient scheme to adaptively apply a best-fit compression solution. Finally, the team will optimize the compression performance on the proposed lossy compression framework for state-of-the-art GPUs. The team will evaluate the proposed framework on high-resolution climate analytics and high-energy particle physics applications and compare it with existing state-of-the-art techniques based on both the memory footprint reduction ratio and training performance improvements (e.g., throughput, time, epoch number).  The project will enable scientists and researchers to train extreme-scale DNNs with a given set of computing resources in a fast and efficient manner, opening opportunities for new discoveries.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dingwen",
   "pi_last_name": "Tao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dingwen Tao",
   "pi_email_addr": "ditao@iu.edu",
   "nsf_id": "000785936",
   "pi_start_date": "2022-10-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Indiana University",
  "inst_street_address": "107 S INDIANA AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BLOOMINGTON",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "3172783473",
  "inst_zip_code": "474057000",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IN09",
  "org_lgl_bus_name": "TRUSTEES OF INDIANA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "YH86RTW2YVJ4"
 },
 "perf_inst": {
  "perf_inst_name": "Indiana University",
  "perf_str_addr": "107 S INDIANA AVE",
  "perf_city_name": "BLOOMINGTON",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "474057000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IN09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "026Y00",
   "pgm_ele_name": "CRII CISE Research Initiation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 77649.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 15000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has greatly advanced the career of the Principal Investigator (PI), who joined the University of Alabama (UA), Washington State University (WSU), and Indiana University (IU) as a tenure-track assistant professor and later as an associate professor. Through this initiative, the PI has successfully established the High-Performance Data Analytics and Computing Lab (HiPDAC Lab). Leading a team, the PI developed innovative compression methods and tools to support large-scale deep learning training on High-Performance Computing (HPC) systems.</p>\n<p>The project has resulted in three key technical contributions: First, the team introduced COMET, a memory-efficient convolutional neural network (CNN) training framework that uses error-bounded lossy compression to significantly reduce memory requirements. This allows for training larger models or accelerating the training process. COMET incorporates a rigorous error-controlling mechanism. The team performed a theoretical analysis of compression error propagation from altered activation data to gradients and empirically investigated the impact of these altered gradients on the training process. Second, building on their analysis, the team optimized the error-bounded lossy compression method known as \"cuSZ\" and proposed an adaptive error-bound control scheme for activation data compression. Third, the team implemented their solution in a state-of-the-art CNN training framework and compared it with the original solution. Experiments demonstrated that the developed framework can reduce training memory consumption by up to 13.5X compared to the baseline and 1.8X compared to another leading compression-based framework, with minimal or no loss in accuracy. The project has resulted in 19 papers published in major computer systems venues.</p>\n<p>In addition to research, the PI is committed to educational activities. The research findings have been integrated into three courses: \"High Performance Computing\" at UA and \"Cloud Computing\" at IU, both at undergraduate and graduate levels. The project has engaged six PhD students and two undergraduate students, and has contributed to the graduation of two PhD students.</p><br>\n<p>\n Last Modified: 08/26/2024<br>\nModified by: Dingwen&nbsp;Tao</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project has greatly advanced the career of the Principal Investigator (PI), who joined the University of Alabama (UA), Washington State University (WSU), and Indiana University (IU) as a tenure-track assistant professor and later as an associate professor. Through this initiative, the PI has successfully established the High-Performance Data Analytics and Computing Lab (HiPDAC Lab). Leading a team, the PI developed innovative compression methods and tools to support large-scale deep learning training on High-Performance Computing (HPC) systems.\n\n\nThe project has resulted in three key technical contributions: First, the team introduced COMET, a memory-efficient convolutional neural network (CNN) training framework that uses error-bounded lossy compression to significantly reduce memory requirements. This allows for training larger models or accelerating the training process. COMET incorporates a rigorous error-controlling mechanism. The team performed a theoretical analysis of compression error propagation from altered activation data to gradients and empirically investigated the impact of these altered gradients on the training process. Second, building on their analysis, the team optimized the error-bounded lossy compression method known as \"cuSZ\" and proposed an adaptive error-bound control scheme for activation data compression. Third, the team implemented their solution in a state-of-the-art CNN training framework and compared it with the original solution. Experiments demonstrated that the developed framework can reduce training memory consumption by up to 13.5X compared to the baseline and 1.8X compared to another leading compression-based framework, with minimal or no loss in accuracy. The project has resulted in 19 papers published in major computer systems venues.\n\n\nIn addition to research, the PI is committed to educational activities. The research findings have been integrated into three courses: \"High Performance Computing\" at UA and \"Cloud Computing\" at IU, both at undergraduate and graduate levels. The project has engaged six PhD students and two undergraduate students, and has contributed to the graduation of two PhD students.\t\t\t\t\tLast Modified: 08/26/2024\n\n\t\t\t\t\tSubmitted by: DingwenTao\n"
 }
}