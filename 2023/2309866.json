{
 "awd_id": "2309866",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FRR: Semi-Structured, Under-Specified, Partially-Observable Robotic Rearrangement",
 "cfda_num": "47.041, 47.070",
 "org_code": "05010000",
 "po_phone": "7032922585",
 "po_email": "pprabhak@nsf.gov",
 "po_sign_block_name": "Pavithra Prabhakar",
 "awd_eff_date": "2023-08-15",
 "awd_exp_date": "2026-07-31",
 "tot_intn_awd_amt": 699498.0,
 "awd_amount": 699498.0,
 "awd_min_amd_letter_date": "2023-08-10",
 "awd_max_amd_letter_date": "2023-08-10",
 "awd_abstract_narration": "The project aims to develop advanced technologies for intelligent robots to efficiently and autonomously interact with objects in everyday, human environments, such as homes and grocery stores, given general, natural language task descriptions. This technology addresses significant societal issues, including the support of older adults in independent living. As people age, reduced mobility often leads to frequent and severe injuries due to impaired vision, home hazards, and weakness. Household robots can assist with tasks like retrieving, transferring, and rearranging items, such as setting up a dinner table or grabbing a jar from the back of a cabinet. Similarly, rearranging robots can assist with labor-intensive, repetitive inventory management tasks in retail operations. Such tasks, like tidying and restocking shelves, are labor-intensive and can lead to injuries, while these jobs are often difficult to fill and have high turnover rates.\r\n\r\nReliably performing these object manipulation tasks in human, semi-structured environments involves significant uncertainty and remains challenging for modern robotics. Furthermore, new objects are frequently introduced and manipulated in semi-structured environments, such as modern homes or grocery stores, further complicating the task for robots. In particular, autonomous robots face multiple hurdles in solving manipulation tasks in these scenarios, including (1) a robot must derive a complete manipulation plan from implicit task specifications given by non-expert humans, (2) the robot must achieve accurate scene understanding in environments where prior knowledge of objects is not always available, and (3) the planning process must respect realistic partial observability constraints, where sensors like RGB-D cameras can only inspect portions of a scene at a time. To address the limitations of the state-of-the-art, the project will develop a novel Iterative Scene Understanding and Rearrangement Planning framework. The framework will build increasingly accurate models of a robot's environment progressively.  The adaptive scene representation will contain the identities, geometries, and possible locations of partially observed objects, to a level sufficient for safely and effectively resolving human-assigned tasks. This representation will be leveraged to efficiently execute manipulation tasks provided by people as natural language commands under realistic visibility constraints. The project will also lay the groundwork for efficient implementations of this framework, aiming to deliver natural, high-quality solutions that achieve desirable guarantees, such as safety, resolution completeness, and solution optimality.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kostas",
   "pi_last_name": "Bekris",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kostas Bekris",
   "pi_email_addr": "kostas.bekris@cs.rutgers.edu",
   "nsf_id": "000520262",
   "pi_start_date": "2023-08-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jingjin",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jingjin Yu",
   "pi_email_addr": "jingjin.yu@rutgers.edu",
   "nsf_id": "000704533",
   "pi_start_date": "2023-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "3 RUTGERS PLZA",
  "perf_city_name": "NEW BRUNSWICK",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "089018559",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 699498.0
  }
 ],
 "por": null
}