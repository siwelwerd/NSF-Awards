{
 "awd_id": "2238168",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Making Underwater Robots Live Underwater",
 "cfda_num": "47.041, 47.070",
 "org_code": "05050000",
 "po_phone": "7032928950",
 "po_email": "rwachter@nsf.gov",
 "po_sign_block_name": "Ralph Wachter",
 "awd_eff_date": "2023-05-01",
 "awd_exp_date": "2028-04-30",
 "tot_intn_awd_amt": 599998.0,
 "awd_amount": 348074.0,
 "awd_min_amd_letter_date": "2023-03-13",
 "awd_max_amd_letter_date": "2023-08-31",
 "awd_abstract_narration": "This Faculty Early Career Development (CAREER) project seeks to endow underwater resident capability for underwater robots. With the new capability, underwater robots will overcome the limited onboard energy, thus, could conduct persistent ocean sensing and connect them with other ocean observing systems to collect key observations at coastal and remote locations (e.g., under-ice or at deep sea) on critical energetic, transient, and unpredictable ocean processes (such as erupting submarine volcanos, triggered biogeochemical plumes, episodical anoxic upwelling waters). Moreover, underwater resident robots could provide persistent monitoring of structural health and water properties to support reliable offshore energy and aquaculture production, addressing the grand challenges, i.e., climate change and food security. The project will integrate research with educational programs on training the workforce in underwater robotics and ocean technology. Specifically, this project will support: 1) two graduate students to conduct fundamental research on underwater robots; 2) up to twenty high school students to build underwater robots and interact with underwater docking systems through summer workshops; 3) two capstone projects on underwater docking arm design and building allowing up to 10 undergraduate students to conduct original research; and 4) integrate research into two robotic classes (about 80 students) in the forms of special topics and demonstrations.\r\n\r\nWith an overarching goal of achieving safe and reliable underwater docking operations, this project seeks to advance three fundamental robotic topics: underwater localization, dynamic modeling, and nonlinear control. First, a learning-augmented pose estimator will be developed to advance vision-based robot localization. The method will adapt deep neural networks (DNNs) to derive the slant range between a camera to a light beacon-based color intensities from a single image. Second, a new DNN-based dynamic model will be created for underwater robots. The model will be trained using real-world data to capture the highly nonlinear mapping between the robot's actuation control signals and the robot states, which are typically ignored or simplified in existing underwater system identification and modeling methods. The new model will potentially improve vehicle control and localization performance, which are critical for underwater docking. Third, a new sampling-based solver will be designed and validated for nonlinear model predictive control. The method will offer an end-to-end computational tractable solution to control multiple robot states simultaneously while incorporating actuation constraints, energy optimization, and model uncertainties. Finally, the student-led research will develop an underwater docking arm to accommodate different AUV systems and environmental impacts.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mingxi",
   "pi_last_name": "Zhou",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mingxi Zhou",
   "pi_email_addr": "mzhou@uri.edu",
   "nsf_id": "000792794",
   "pi_start_date": "2023-03-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rhode Island",
  "inst_street_address": "75 LOWER COLLEGE RD RM 103",
  "inst_street_address_2": "",
  "inst_city_name": "KINGSTON",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018742635",
  "inst_zip_code": "028811974",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "RI02",
  "org_lgl_bus_name": "UNIVERSITY OF RHODE ISLAND",
  "org_prnt_uei_num": "NSA8T7PLC9K3",
  "org_uei_num": "CJDNG9D14MW7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rhode Island",
  "perf_str_addr": "75 LOWER COLLEGE",
  "perf_city_name": "KINGSTON",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "028811974",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "RI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 348074.0
  }
 ],
 "por": null
}