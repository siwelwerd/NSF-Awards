{
 "awd_id": "2304303",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "STTR Phase I:  Subcanopy 3D forest mapping by uncrewed aerial vehicle",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922936",
 "po_email": "emirowsk@nsf.gov",
 "po_sign_block_name": "Ela Mirowski",
 "awd_eff_date": "2023-05-15",
 "awd_exp_date": "2024-01-31",
 "tot_intn_awd_amt": 274929.0,
 "awd_amount": 274929.0,
 "awd_min_amd_letter_date": "2023-05-10",
 "awd_max_amd_letter_date": "2023-05-10",
 "awd_abstract_narration": "The broader/commercial impact of this Small Business Technology Transfer (STTR) Phase I project is a tool to help mitigate the wildfire crisis in the western United States. Prescribed burns are one of the most effective ways to prevent the uncontrolled, large-scale wildfires that devastate entire ecosystems, communities, and economies, but the environmental assessment required for burns may delay the burn by months or years due to overburdened agencies. The innovation addresses this pain point with an automated survey solution, reducing both the paperwork burden and the potential for error in burn area vegetation mapping and spatial fire modeling. The solution ensures that prescribed burn plans use the best available vegetation data, providing fire managers with an accurate prediction of expected fire behavior for determining control strategy, staffing, and resources. This innovation would be the first automated prescribed burn spatial fire modeling solution using an autonomous Unmanned Aerial Vehicle (UAV). This innovation meets the STTR program\u2019s focus on unproven, high-impact innovations because sub-canopy mapping by UAV is a cutting-edge application of autonomous flight, with challenges in optimization and decision-making. The application of UAV technology to prescribed burn environmental assessments will help to address the growing wildfire crisis in the United States by reducing the delay between the decision to burn at a selected site and the execution of the burn. \r\n\r\nThe technical hurdles to be addressed by the proposed project include both real-time, sub-canopy 3D mapping and optimization for constraints across sensor requirements, cluttered environment exploration, and SWAP (size, weight, and power) limitations. The goals are to produce a high-fidelity, open-source. UAV exploration environment, to implement 3D mapping on a resource-constrained computer that meets UAV payload requirements, to incorporate species-specific decision-making criteria into the UAV exploration algorithm, and to conduct validation testing to verify technical and early commercial feasibility. To achieve these goals, the development plan includes a series of milestones following a test-driven, development project management strategy, including simulation testing (software in the loop), tabletop testing (hardware in the loop), and field tests.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Erin",
   "pi_last_name": "Linebarger",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Erin M Linebarger",
   "pi_email_addr": "erin@robotics88.com",
   "nsf_id": "000780678",
   "pi_start_date": "2023-05-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "George",
   "pi_last_name": "Kantor",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "George Kantor",
   "pi_email_addr": "kantor@ri.cmu.edu",
   "nsf_id": "000281381",
   "pi_start_date": "2023-05-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "MORPHOBOTICS LLC",
  "inst_street_address": "47 WOOD AVE STE 2",
  "inst_street_address_2": "",
  "inst_city_name": "BARRINGTON",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "5085966433",
  "inst_zip_code": "028063503",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "ROBOTICS 88, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "VNNMU85L26M7"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie Mellon University",
  "perf_str_addr": "5000 Forbes Ave",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "150500",
   "pgm_ele_name": "STTR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01AB2324DB",
   "fund_name": "R&RA DRSA DEFC AAB",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 274929.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-c20bb191-7fff-cdcd-a57b-3bad710ddebf\"> </span></p>\n<p dir=\"ltr\"><span>This project proved the feasibility of building 3D maps in real time on a resource-constrained computer onboard a UAV (uncrewed aerial vehicle). Additionally, we demonstrated a proof of concept UAV that can be tailored to find certain plant species of interest. Details for each component of the project are below. This project is a step toward the Robotics 88 autonomous UAV optimized for building vegetation maps to inform spatial fire modeling in prescribed burn planning. The </span><strong>broader impact</strong><span> of this project is its potential to reduce the risk of catastrophic wildfires, and the </span><strong>intellectual merits</strong><span> of this project are in the novel applications this opens up for 3D mapping algorithms on an edge device.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><strong>Optimal subcanopy flight combines 3D mapping with 2.5D exploration</strong></p>\n<p dir=\"ltr\"><span>We tested multiple SLAM (simultaneous localization and mapping) algorithms for 3D pointcloud mapping from LiDAR to find the fastest and most accurate solution, given the limited computing constraints onboard. We originally proposed 3D exploration as well, in which the UAV chooses its possible destinations from a volumetric search, but we found that vertical exploration slowed overall progress without notable benefit to the resulting map. We then pivoted to 2.5D exploration, in which the possible destinations are chosen from a 2.5D map (i.e., a 2D representation of 3D space), but the UAV navigates and chooses its altitude in 3D. This produced highly efficient exploration with fast and accurate maps.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><strong>Produced open source AirSim ROS wrapper with MAVROS and SLAM support built-in</strong></p>\n<p dir=\"ltr\"><span>AirSim is the most popular drone simulator for testing autonomous control, leveraging the Unreal engine for high-fidelity physics, but the existing wrappers had notable weak spots. In particular, there did not exist an AirSim ROS wrapper optimized for both MAVROS control (ROS wrapper for MAVlink, the most common drone comms protocol) and SLAM. We provide detailed instructions for using this wrapper with either ArduCopter or PX4. We made this publicly available to support the robotics research community, as there are many requests for SLAM integration in the issues sections of prior AirSim ROS wrappers. Our custom ROS wrapper is available on GitHub here: </span><a href=\"https://github.com/robotics-88/airsim-mavros-wrapper\"><span>https://github.com/robotics-88/airsim-mavros-wrapper</span></a><span>.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><strong>Pittsburgh flight tests verified the SLAM algorithm&rsquo;s real-time performance on edge device</strong></p>\n<p dir=\"ltr\"><span>Robotics 88 and our STTR subawardees at the Carnegie Mellon University robotics department conducted two days of flight tests in Pittsburgh using the Robotics 88 prototype quadcopter. Development testing was primarily conducted using our AirSim UAV simulator, but flight tests were critical to verify real-time performance on a resource-constrained device. Our modular control setup enabled testing three different SLAM algorithms with the same 2.5D exploration previously described. All three algorithms ran in real-time while the UAV was in flight, but one algorithm produced the most superior pointcloud map in terms of accuracy and spatial correctness.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><strong>Autonomous exploration can be tailored toward a tree species of interest&nbsp;</strong></p>\n<p dir=\"ltr\"><span>We designed an exploration control algorithm for navigating through the midstory of a forest to seek out ash trees. Our generalizable decision-making algorithm is the enabling factor for subcanopy flight control, but it has an added benefit that it can easily be adapted to specific applications by adding or removing decision criteria. Ash trees are dying off rapidly due to the emerald ash borer beetle, so there are multiple reasons to seek out the stands of ash trees. Ecologists want to find resistant ash trees to see if they can breed resistant ash, and prescribed burn managers will need to plan around any large stands of dead ash trees, which could impact fire behavior.</span></p>\n<p><br /><span>For more information, see </span><a href=\"http://www.robotics88.com\"><span>www.robotics88.com</span></a><span>. </span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 04/28/2024<br>\nModified by: Erin&nbsp;M&nbsp;Linebarger</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314374967_airsim_explore__2_--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314374967_airsim_explore__2_--rgov-800width.png\" title=\"Simulated drone exploration in AirSim\"><img src=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314374967_airsim_explore__2_--rgov-66x44.png\" alt=\"Simulated drone exploration in AirSim\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Simulated drone flight with our AirSim wrapper enables MAVROS integration and SLAM (simultaneous localization and mapping).</div>\n<div class=\"imageCredit\">Robotics 88</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Erin&nbsp;M&nbsp;Linebarger\n<div class=\"imageTitle\">Simulated drone exploration in AirSim</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314497997_decco_diagram__2_--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314497997_decco_diagram__2_--rgov-800width.png\" title=\"The Robotics 88 Decco UAS\"><img src=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314497997_decco_diagram__2_--rgov-66x44.png\" alt=\"The Robotics 88 Decco UAS\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The prototype UAS (uncrewed aircraft system) used in flight tests during this NSF STTR.</div>\n<div class=\"imageCredit\">Robotics 88</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Erin&nbsp;M&nbsp;Linebarger\n<div class=\"imageTitle\">The Robotics 88 Decco UAS</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314945651_pittsburgh4--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314945651_pittsburgh4--rgov-800width.png\" title=\"Pittsburgh forest pointcloud map\"><img src=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314945651_pittsburgh4--rgov-66x44.png\" alt=\"Pittsburgh forest pointcloud map\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The pointcloud produced in-flight during Pittsburgh field tests captures trees and a trail, aligned with the RGN (red/green/near-infrared) image shown left.</div>\n<div class=\"imageCredit\">Robotics 88</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Erin&nbsp;M&nbsp;Linebarger\n<div class=\"imageTitle\">Pittsburgh forest pointcloud map</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314778992_erin_tyler--rgov-214x142.JPG\" original=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314778992_erin_tyler--rgov-800width.JPG\" title=\"Prep for drone flight\"><img src=\"/por/images/Reports/POR/2024/2304303/2304303_10861726_1714314778992_erin_tyler--rgov-66x44.JPG\" alt=\"Prep for drone flight\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The Robotics 88 team about to initiate an autonomous flight.</div>\n<div class=\"imageCredit\">Francisco Yandun</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Erin&nbsp;M&nbsp;Linebarger\n<div class=\"imageTitle\">Prep for drone flight</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThis project proved the feasibility of building 3D maps in real time on a resource-constrained computer onboard a UAV (uncrewed aerial vehicle). Additionally, we demonstrated a proof of concept UAV that can be tailored to find certain plant species of interest. Details for each component of the project are below. This project is a step toward the Robotics 88 autonomous UAV optimized for building vegetation maps to inform spatial fire modeling in prescribed burn planning. The broader impact of this project is its potential to reduce the risk of catastrophic wildfires, and the intellectual merits of this project are in the novel applications this opens up for 3D mapping algorithms on an edge device.\n\n\n\n\n\nOptimal subcanopy flight combines 3D mapping with 2.5D exploration\n\n\nWe tested multiple SLAM (simultaneous localization and mapping) algorithms for 3D pointcloud mapping from LiDAR to find the fastest and most accurate solution, given the limited computing constraints onboard. We originally proposed 3D exploration as well, in which the UAV chooses its possible destinations from a volumetric search, but we found that vertical exploration slowed overall progress without notable benefit to the resulting map. We then pivoted to 2.5D exploration, in which the possible destinations are chosen from a 2.5D map (i.e., a 2D representation of 3D space), but the UAV navigates and chooses its altitude in 3D. This produced highly efficient exploration with fast and accurate maps.\n\n\n\n\n\nProduced open source AirSim ROS wrapper with MAVROS and SLAM support built-in\n\n\nAirSim is the most popular drone simulator for testing autonomous control, leveraging the Unreal engine for high-fidelity physics, but the existing wrappers had notable weak spots. In particular, there did not exist an AirSim ROS wrapper optimized for both MAVROS control (ROS wrapper for MAVlink, the most common drone comms protocol) and SLAM. We provide detailed instructions for using this wrapper with either ArduCopter or PX4. We made this publicly available to support the robotics research community, as there are many requests for SLAM integration in the issues sections of prior AirSim ROS wrappers. Our custom ROS wrapper is available on GitHub here: https://github.com/robotics-88/airsim-mavros-wrapper.\n\n\n\n\n\nPittsburgh flight tests verified the SLAM algorithms real-time performance on edge device\n\n\nRobotics 88 and our STTR subawardees at the Carnegie Mellon University robotics department conducted two days of flight tests in Pittsburgh using the Robotics 88 prototype quadcopter. Development testing was primarily conducted using our AirSim UAV simulator, but flight tests were critical to verify real-time performance on a resource-constrained device. Our modular control setup enabled testing three different SLAM algorithms with the same 2.5D exploration previously described. All three algorithms ran in real-time while the UAV was in flight, but one algorithm produced the most superior pointcloud map in terms of accuracy and spatial correctness.\n\n\n\n\n\nAutonomous exploration can be tailored toward a tree species of interest\n\n\nWe designed an exploration control algorithm for navigating through the midstory of a forest to seek out ash trees. Our generalizable decision-making algorithm is the enabling factor for subcanopy flight control, but it has an added benefit that it can easily be adapted to specific applications by adding or removing decision criteria. Ash trees are dying off rapidly due to the emerald ash borer beetle, so there are multiple reasons to seek out the stands of ash trees. Ecologists want to find resistant ash trees to see if they can breed resistant ash, and prescribed burn managers will need to plan around any large stands of dead ash trees, which could impact fire behavior.\n\n\n\nFor more information, see www.robotics88.com. \n\n\n\n\n\n\t\t\t\t\tLast Modified: 04/28/2024\n\n\t\t\t\t\tSubmitted by: ErinMLinebarger\n"
 }
}