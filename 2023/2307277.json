{
 "awd_id": "2307277",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RAPID/Collaborative Research: Datasets for Uncrewed Aerial System (UAS) and Remote Responder Performance from Hurricane Ian",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032925365",
 "po_email": "jberg@nsf.gov",
 "po_sign_block_name": "Jordan Berg",
 "awd_eff_date": "2023-02-01",
 "awd_exp_date": "2024-01-31",
 "tot_intn_awd_amt": 54460.0,
 "awd_amount": 54460.0,
 "awd_min_amd_letter_date": "2023-02-15",
 "awd_max_amd_letter_date": "2023-02-15",
 "awd_abstract_narration": "This Grants for Rapid Response Research (RAPID) project will curate, supplement, and analyze data collected over a period of intensive uncrewed aerial system (UAS) operations, carried out as part of the State of Florida\u2019s response to Hurricane Ian. From September 27, 2022, just before Hurricane Ian made landfall, and continually for the next nine days, teams from Florida State University and Texas A&M University helped coordinate 24 UAS pilots flying 16 different models of fixed-wing and rotorcraft UAS over Charlotte, Lee, and Hardee counties. These missions obtained aerial imagery to survey wind and flood damage, direct ground response, support strategic planning and resource allocation, monitor threats to public safety, and provide documentation for subsequent emergency relief funding. Under this award, the research team will curate 55,000 images and videos collected during the disaster, comprising over 750 gigabytes of data, and supporting material such as flight schedules and log files. The curated data, and derived products such as aerial maps and edited video, will be made publicly available for open-source use. The project will analyze the mission logs and data products to assess pilot performance over time, and will document variables potentially influencing pilot performance, including pilot skill, prior training and experience, operations tempo, and fatiguing conditions, supplemented by individual and collective interviews with the UAS pilots. The image dataset and derived products will help the computer vision/machine learning (CV/ML) community design better algorithms for identifying threats to public safety, damaged structures, and people in distress.  The pilot performance dataset will be made available to the research community, to characterize human-robot performance, formulate best practices, and to understand deviation in behaviors and sources of mission error. The resulting insights into proper matching of vehicles, pilots, missions, and operational parameters will increase the ability of UAS platforms and pilots to save lives and accelerate economic recovery after a disaster. The datasets can help the domestic UAS industry improve products for response to a broad class of natural disasters, including wildfires and flooding, and for use in extreme environments, such as in oil and gas exploration and extraction and for in nuclear reactors and nuclear waste sites. The project will support the creation of better workflow procedures to reduce human error, increasing trust in the technology by UAS operators and other first responders, and facilitating adoption of UAS for emergency response. The project will broaden participation in science, with three women out of the four co-PIs, and will engage STEM students to help annotate the UAS imagery. \r\n\r\nThis project will curate vehicle and pilot data from the deployment of uncrewed aerial systems (UAS) during Hurricane Ian by Florida State University and Texas A&M University for the robotics, computer vision/machine learning (CV/ML), human-robot interaction, and geospatial land-use communities. The project has the following three objectives: 1) Curate the data (imagery, log files, flight schedules, etc.) and data products (images, video, orthomosaic maps, digital surface maps) collected during the disaster and make available for open-source use; 2) Interview the UAS pilots individually and collectively in order to capture human-robot performance, best practices, deviation in behaviors, and sources of error; and 3) Analyze the mission logs and data products for performance (quality or completeness) and document the quality over time by pilots, prior training, and frequency of flying the missions in normative conditions, the operations tempo, and fatiguing conditions. From a robotics perspective, it will contribute to the emerging model of how multiple agents may be used during disasters, and the consequences for design, performance specifications, the role of artificial intelligence, and wireless communications. Such a model can greatly increase the competitiveness of the domestic drone industry, as well as motivate novel directions in swarm research. Research stemming from this project will generate guidelines for data collection in future disasters, setting the stage for advances in engineering and computing for disasters. It will increase the availability of training data for CV/ML and serve as a testbed for transfer of learned features from other disasters; both of which could lead to fundamental advances in machine learning. From a human-factors perspective, it will generate a new methodology for creating human-robot datasets that combine on-site direct data (with no experimenters in the field) with post-event data. This methodology would overcome current barriers in conducting empirical investigations into scientific questions on extreme work environments because of the prohibition on embedded experimenters. This methodology is expected to transfer to other extreme work environments, such as nuclear, space, oil and gas industry, and the military. The human-robot data itself could lead to major findings in human error and workforce training. From a geospatial perspective, the data can help establish the impact of rising sea levels, the built environment, and prior storm surge and flooding mitigations. Overall, the project will benefit society by increasing the ability to save lives and accelerate economic recovery after a disaster with UAS and is expected to create findings and methods that will generalize to new technologies for extreme environments.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Merrick",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Merrick",
   "pi_email_addr": "dmerrick@fsu.edu",
   "nsf_id": "000758057",
   "pi_start_date": "2023-02-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Florida State University",
  "inst_street_address": "874 TRADITIONS WAY",
  "inst_street_address_2": "",
  "inst_city_name": "TALLAHASSEE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "8506445260",
  "inst_zip_code": "323060001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "FL02",
  "org_lgl_bus_name": "FLORIDA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JF2BLNN4PJC3"
 },
 "perf_inst": {
  "perf_inst_name": "Florida State University",
  "perf_str_addr": "874 TRADITIONS WAY",
  "perf_city_name": "TALLAHASSEE",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "323060001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "FL02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  },
  {
   "pgm_ref_code": "7914",
   "pgm_ref_txt": "RAPID"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 54460.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p dir=\"ltr\">This project curated data from the deployment of drones at Hurricane Ian by Florida State University and Texas A&amp;M for the robotics, computer vision/machine learning, human-robot interaction, and geospatial land-use communities.&nbsp;</p>\n<p dir=\"ltr\">It had three specific objectives:&nbsp;</p>\n<ol>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Curate the data (imagery, log files, flight schedules, etc.) and data products (images, video, orthomosaic maps, digital surface maps) collected during the disaster and make them available for open-source use;&nbsp;</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Interview the pilots individually and collectively to capture human-robot performance, best practices, deviation in behaviors, and sources of error; and&nbsp;</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Analyze the mission logs and data products for performance (quality or completeness) and document the quality over time by pilots, prior training, and frequency of flying the missions in normative conditions, the operations tempo, and fatiguing conditions.</p>\n</li>\n</ol>\n<p>FSU created a two day full scale exercise for pilots and teams that participated in Hurricane Ian response. The exercise simulated post-disaster field conditions, requiring pilots to capture data over a large geographic area over a 24 hour period. This exericse was designed to measure pilot performance, specifically in field environments. The particpants were interviewed by researchers from Texas A&amp;M University, and responses were compared to previous data from Hurricane Ian.&nbsp;&nbsp;</p>\n<p>In addition to the exercise component, the project created a tagged, curated dataset of data collected during Hurricane Ian, totalling over 2TB of raw and processed information.&nbsp; This data was analyzed by Texas A&amp;M University and made available under an open source license.&nbsp;</p><br>\n<p>\n Last Modified: 08/29/2024<br>\nModified by: David&nbsp;Merrick</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2307277/2307277_10847730_1724955479733_group_photo_21APR23_sm--rgov-214x142.JPG\" original=\"/por/images/Reports/POR/2024/2307277/2307277_10847730_1724955479733_group_photo_21APR23_sm--rgov-800width.JPG\" title=\"Field Exercise Group Photo\"><img src=\"/por/images/Reports/POR/2024/2307277/2307277_10847730_1724955479733_group_photo_21APR23_sm--rgov-66x44.JPG\" alt=\"Field Exercise Group Photo\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Participants in the field exercise pose as a group at the end of the event. April 2023</div>\n<div class=\"imageCredit\">FSU Center for Disaster Risk Policy</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">David&nbsp;Merrick\n<div class=\"imageTitle\">Field Exercise Group Photo</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project curated data from the deployment of drones at Hurricane Ian by Florida State University and Texas A&M for the robotics, computer vision/machine learning, human-robot interaction, and geospatial land-use communities.\n\n\nIt had three specific objectives:\n\n\n\n\nCurate the data (imagery, log files, flight schedules, etc.) and data products (images, video, orthomosaic maps, digital surface maps) collected during the disaster and make them available for open-source use;\n\n\n\n\nInterview the pilots individually and collectively to capture human-robot performance, best practices, deviation in behaviors, and sources of error; and\n\n\n\n\nAnalyze the mission logs and data products for performance (quality or completeness) and document the quality over time by pilots, prior training, and frequency of flying the missions in normative conditions, the operations tempo, and fatiguing conditions.\n\n\n\n\nFSU created a two day full scale exercise for pilots and teams that participated in Hurricane Ian response. The exercise simulated post-disaster field conditions, requiring pilots to capture data over a large geographic area over a 24 hour period. This exericse was designed to measure pilot performance, specifically in field environments. The particpants were interviewed by researchers from Texas A&M University, and responses were compared to previous data from Hurricane Ian.\n\n\nIn addition to the exercise component, the project created a tagged, curated dataset of data collected during Hurricane Ian, totalling over 2TB of raw and processed information. This data was analyzed by Texas A&M University and made available under an open source license.\t\t\t\t\tLast Modified: 08/29/2024\n\n\t\t\t\t\tSubmitted by: DavidMerrick\n"
 }
}