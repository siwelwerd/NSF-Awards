{
 "awd_id": "2319470",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ATD: Activity Aware Bayesian Deep Learning",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927021",
 "po_email": "ewilmer@nsf.gov",
 "po_sign_block_name": "Elizabeth Wilmer",
 "awd_eff_date": "2023-09-01",
 "awd_exp_date": "2026-08-31",
 "tot_intn_awd_amt": 90000.0,
 "awd_amount": 90000.0,
 "awd_min_amd_letter_date": "2023-08-03",
 "awd_max_amd_letter_date": "2023-08-03",
 "awd_abstract_narration": "This project will research next-generation deep learning AI models for comprehending objects, activity, and context from overhead imagery and sensor data.  This work will use Large Language Models (LLMs) to create machine reasoning that replicates human reasoning at a scale, speed, and complexity unachievable with human analysts.  Different types of data collected from satellites and aircraft are currently processed separately, leading to siloed information without context. This research will use LLMs to synthesize multiple data sources with context, location, and time, producing Activity-Aware Deep Learning AI.  Current deep learning AI can take pixel-based information in images to object-based (groups of pixels) information, and the current state-of-the-art scene-based (groups of objects) information.  This project will enable a new level of activity-based information: what are the objects doing in the scene? what is the broader context? For example, a blue tarp in a US suburb is likely covering an object to protect it from weather, but multiple blue tarps along streets following a natural disaster may be indications of people in makeshift shelters in need of help. The Activity-Aware DL models developed research will comprehend these different situations using LLMs, with no activity-specific training beyond the logic already present in the LLMs. Software developed will be made available as open source, and new editions of textbooks on the area written by the investigator will be released.  \r\n\r\nThere are existing models for determining object-based information from sensor data.  For example, convolutional neural networks can identify objects in high resolution imagery, and Bayesian models can accurately identify chemical species present on the ground in hyperspectral imagery.  Even simple prompts into LLMs including just objects and location can produce activity-aware information.  For example, the text prompt \u201cWhy are there rows of XYZ military vehicles []?\u201d where [] can be filled in with \u201coutside Location A\u201d, \u201cIn Location B\u201d, or \u201cat Location C\u201d will produce different conclusions when put into the ChatGPT LLM without explicit context training. The current project will develop neural network architectures that can translate \u2018what is present\u2019 class probabilities from an object-based model, combine this with geospatial information, and generate a text prompt input into an LLM to determine activity and context. Particular attention will be focused on developing prompts that do not generate factually inaccurate output from the LLM.  Models will be developed in TensorFlow software to facilitate sharing. Bayesian probabilities will be used throughout the models to provide regularization and interpretability of the models, facilitating future ongoing research in this area.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Basener",
   "pi_mid_init": "F",
   "pi_sufx_name": "",
   "pi_full_name": "William F Basener",
   "pi_email_addr": "wb8by@virginia.edu",
   "nsf_id": "000114086",
   "pi_start_date": "2023-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Virginia Main Campus",
  "inst_street_address": "1001 EMMET ST N",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTESVILLE",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "4349244270",
  "inst_zip_code": "229034833",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "VA05",
  "org_lgl_bus_name": "RECTOR & VISITORS OF THE UNIVERSITY OF VIRGINIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJG6HU8PA4S5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Virginia Main Campus",
  "perf_str_addr": "1001 N EMMET ST",
  "perf_city_name": "CHARLOTTESVILLE",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "229034833",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "VA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": null,
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "6877",
   "pgm_ref_txt": "ALGORITHMS IN THREAT DETECTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 90000.0
  }
 ],
 "por": null
}