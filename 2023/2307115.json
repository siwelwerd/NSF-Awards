{
 "awd_id": "2307115",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Regularized divergences and their gradient flows, generative modeling and structure-preserving learning.",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922948",
 "po_email": "slevine@nsf.gov",
 "po_sign_block_name": "Stacey Levine",
 "awd_eff_date": "2023-08-01",
 "awd_exp_date": "2026-07-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2023-07-27",
 "awd_max_amd_letter_date": "2023-07-27",
 "awd_abstract_narration": "Generative modeling algorithms underlie many recent and ongoing advances in artificial intelligence, both in popular image and text generation tools as well as scientific applications such as materials design, medical imaging, drug discovery, and cosmology, to name a few. The goal of such algorithms is to learn and construct a model starting from data and available knowledge, and then deploy the learned model to generate new predictions. These predictions are in the form of new data such as new images, new text or even new candidate molecules for drug design. This project involves the development of new mathematical tools from information theory, deep learning, differential equations and probability theory to design, improve, explain and ultimately trust such learning algorithms.  The investigators will also apply these new algorithms to merge data sets from different cancer studies, addressing a critical need to improve data analysis by integrating data from the same disease but which are obtained using different studies, technologies, and patient groups. The primary goal of the proposed research is to develop new reliable machine learning algorithms when data is scarce or expensive to obtain. Graduate students will be trained in this field as part of this research project.\r\n\r\nProbability divergences and metrics are mathematical objects designed to measure discrepancies between different probabilistic models or between models and data and are especially adept in very high-dimensional settings. Divergences need to be carefully designed to construct models which best describe the available data. This project will combine tools from optimal transport, information theory, partial differential equations and deep learning to develop Lipschitz regularized divergences which interpolate between Wasserstein metrics and information-theoretic divergences (e.g. the Kullback-Leibler divergence) and which provide flexible families of loss functions to compare non-absolutely continuous probability measures. In machine learning applications one often needs to build algorithms to model target distributions which are singular, either by their intrinsic nature such as probabilities concentrated on low dimensional structures and/or because they are often only known through data. These new divergences will be combined with deep learning to build gradient flows in a probability space which are capable of transporting any initial distribution to a target data set. These new methods will also be adapted for structure-preserving learning, arising in applications ranging from medicine to the design of new molecules, where data can exhibit symmetries or physical constraints. This additional knowledge will be taken into account in the probability divergence to build structure-preserving generative algorithms in an efficient way. The essential role of structure in generative algorithms will be studied and quantified whenever data is scarce and/or expensive to obtain.  One of the demonstration areas of this research is in bioinformatics, where available real datasets, even when they involve the same disease, have low sample size due to budgetary constraints or limited availability of patients e.g., in the case of rare diseases.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Luc",
   "pi_last_name": "Rey-Bellet",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Luc Rey-Bellet",
   "pi_email_addr": "lr7q@math.umass.edu",
   "nsf_id": "000196997",
   "pi_start_date": "2023-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Markos",
   "pi_last_name": "Katsoulakis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Markos Katsoulakis",
   "pi_email_addr": "markos@math.umass.edu",
   "nsf_id": "000109971",
   "pi_start_date": "2023-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "COMMONWEALTH AVE",
  "perf_city_name": "AMHERST",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "01003",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126600",
   "pgm_ele_name": "APPLIED MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": null
}