{
 "awd_id": "2230398",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Software-Defined Sub-Terahertz Imaging Radar for Algorithmic Agility and All-Weather Transportation Safety",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922936",
 "po_email": "emirowsk@nsf.gov",
 "po_sign_block_name": "Ela Mirowski",
 "awd_eff_date": "2023-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 275000.0,
 "awd_amount": 295000.0,
 "awd_min_amd_letter_date": "2023-07-05",
 "awd_max_amd_letter_date": "2024-06-25",
 "awd_abstract_narration": "The broader/commercial impact of this Small Business Innovation Research (SBIR) Phase I project is the development of a universal, affordable, and sustainable sensing solution to enable perimeter security and transportation safety under all weather conditions. Current sensing solutions available today are based on a single modality, expensive to deploy, and not robust to adverse weather conditions.  Current solutions also employ proprietary sensor processing interfaces, do not provide the quality of data needed for decision-making by continuous learning, are hard to upgrade, and have poor size, weight, and power specifications. In contrast, the proposed technology leverages the strengths of multiple sensing modalities on a single, converged, open compute platform to enable robust perception in adverse weather conditions while offering significant advantages to the total cost of ownership. The technology has a wide range of applications in sectors as diverse as automotive, robotics, enterprise, aerospace, and defense. The solution developed under this project has the potential to save lives by reducing the number of road accidents, improving the driver reaction time, protecting vulnerable road users such as pedestrians and bicyclists, reducing the downtime for a shipping company, minimizing the costs associated with collision claims and repairs, and detecting, classifying, alerting, and tracking threats on the ground and in the air. \r\n\r\nThis Small Business Innovation Research Phase I project develops a novel, scalable, centralized sensing platform and a multi-spectral sensor prototype to realize ultra-fine resolution in range, Doppler, azimuth, and elevation domains using commercial, off-the-shelf processing elements. Advanced compression algorithms are employed to transport sensor measurements over secure, open, low-cost, and low-latency interfaces to the centralized processing unit to enable multi-modal sensor processing, early sensor fusion, and high-dimensional perception for higher-level decision-making. The de-coupled sensing and processing architecture produces unprecedented access to measurement-level data to enable artificial intelligence and machine learning-based algorithmic discovery. False-alarm-constrained global object detection algorithms are employed to enable localization, navigation, and mapping for operation under adverse weather conditions. Proof-of-concept sensor hardware is developed with laboratory and field experiments to validate the architecture, technology, algorithms, and software. Some of the key technology risks addressed in this proposal are antenna design and fabrication at millimeter frequencies and above, cascading of multiple radio frequency transceivers to realize a large number of spatial channels, and hardware-level synchronization across the sensors.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ramesh",
   "pi_last_name": "Annavajjala",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ramesh Annavajjala",
   "pi_email_addr": "ramesh@bluefusion.tech",
   "nsf_id": "000728248",
   "pi_start_date": "2023-07-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "BLUEFUSION INC.",
  "inst_street_address": "7 LARCHWOOD LN",
  "inst_street_address_2": "",
  "inst_city_name": "NATICK",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "8585317769",
  "inst_zip_code": "017603047",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "BLUEFUSION INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "VJG6FPT5GCH6"
 },
 "perf_inst": {
  "perf_inst_name": "BLUEFUSION INC.",
  "perf_str_addr": "24 SCHOOL ST FL 2",
  "perf_city_name": "BOSTON",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021085140",
  "perf_ctry_code": "US",
  "perf_cong_dist": "08",
  "perf_st_cong_dist": "MA08",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  },
  {
   "pgm_ele_code": "809100",
   "pgm_ele_name": "SBIR Outreach & Tech. Assist"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "059P",
   "pgm_ref_txt": "SCIENCE IN MOTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01AB2324DB",
   "fund_name": "R&RA DRSA DEFC AAB",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 270000.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 25000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our NSF Phase-1 project is focused on the feasibility study, design, and initial prototype development of a multi-modal and multi-spectral sensing solution by deeply integrating a multiple-input and multiple-output (MIMO) imaging radar with an RGB/IR vision sensor to enable enhanced situational awareness, long-range detection capability, and robust classification and tracking under adverse weather conditions for industries and applications as diverse as transportation and logistics, autonomous mobile robots, critical infrastructure protection, space, and defense. Our Phase-1 project resulted in significant technical achievements across three main areas which are summarized below:</p>\n<p><strong><span style=\"text-decoration: underline;\">1. Long-Range MIMO Imaging Radar Feasibility Study, Design, and Initial Prototyping:</span></strong></p>\n<p>As part of this phase-1 project, we have successfully designed a novel long-range MIMO imaging radar. Our MIMO imaging radar enables 1-degree beamwidth (i.e., spatial resolution) simultaneously in azimuth and elevation with a novel antenna placement. By leveraging a cascade architecture with multiple commercial-off-the-shelf (COTS) radar transceiver chips, the effective isotropic radiated power is enhanced without any external power amplifiers to increase the target detection range. Our design addressed the phase coherency and clock synchronization challenges associated with millimeter frequencies by employing a master clock, power divider, frequency, and phase calibration, and carefully controlling the inter-chip timing imbalance. Our project encompassed the entire development cycle, including architectural tradeoffs, modeling, analysis, simulations, design of radar transceiver board schematics, transceiver board layout, and the production of limited-quantity prototype boards. Our MIMO imaging radar system offers several key features and benefits, including:</p>\n<ul>\n<li>Enhanced Range and Resolution: By utilizing the MIMO technology with virtual antenna arrays, transmit and receive beamforming, our solution can achieve a range of several hundred meters to detect weak objects, and a range resolution as small as 3 centimeters. With 1-degree spatial resolution, our solution offers up to 900x more spatial data compared with the state-of-the-art radar solutions. </li>\n<li>Scalability and Flexibility: Modular design of our radar system allows for scalability and adaptability to different deployment scenarios and applications. Our radar sensor can be configured with varying numbers of antennas and transceiver units to meet specific requirements such as large, medium, short, and ultra-short range target detection. </li>\n<li>Software-defined Radar Signal Processing: With access to radar reflections from our transceiver board as captured by the raw ADC (analog-to-digital converter) samples, our solution enables software-defined radar signal processing with algorithmic agility, data-driven workflows, debuggability, interference avoidance, reduced power consumption, and lower solution cost.&nbsp; </li>\n</ul>\n<p><strong><span style=\"text-decoration: underline;\">2. RGB+IR Camera Module Feasibility Study, Design, and Initial Prototyping:</span></strong></p>\n<p>In parallel with our imaging radar development, our project also focused on the feasibility of designing a compact RGB+IR camera module to address the gaps associated with radar-based detection of color (i.e., traffic lights and lane markings) and signs (i.e., stop signs and posted speed limits). Our proposed design integrates both visible spectrum and infrared imaging capabilities into a compact and versatile package. Like the imaging radar design, our camera module underwent rigorous design phases starting with the choice of imaging chip that satisfies the resolution, frame rate, field of view, power consumption, and cost. Additionally, we ensured that our imaging module can withstand extreme temperatures by picking an automotive-grade component. Once we converged on the imaging chip that addressed our requirements, we proceeded with schematics, layout, and production of limited-quantity prototype boards. Our integrated RGB/IR camera module offers several advantages, including:</p>\n<ul>\n<li>Multimodal Imaging Capabilities: By combining RGB and IR capabilities on a single chip, our imaging module enables simultaneous capture of visual and infrared images. This allows for comprehensive scene analysis and enhanced situational awareness in diverse environments.</li>\n<li>Compact Form Factor: The compact design of our imaging module facilitates integration into various platforms and systems, including unmanned aerial vehicles (UAVs), ground vehicles, and surveillance systems.</li>\n<li>High-Quality Imaging: Our imaging module produces 5 Megapixels resolution at up to 60 frames per sec to enable advanced computer vision-based detection, classification, and tracking of targets across different lighting and environmental conditions.</li>\n</ul>\n<p><strong><span style=\"text-decoration: underline;\">3. Data Fusion Solution Feasibility Study, Design, and Initial Prototyping:</span></strong></p>\n<p>One of the key achievements of our Phase-1 project is the development of a sophisticated data fusion solution to integrate MIMO imaging radar with the RGB/IR cameras at the hardware level. Our data fusion solution offers the following capabilities:</p>\n<ul>\n<li>Synchronization and Triggering: Our solution ensures precise synchronization and simultaneous triggering of the imaging radar and RGB+IR cameras, enabling coordinated operation and data capture.</li>\n<li>Dynamic Sensor Modality Configuration: Users can dynamically configure the imaging radar and RGB+IR cameras independently, adjusting parameters such as resolution, frame rate, and imaging modes to suit specific application requirements.</li>\n<li>Unified Data Streaming over Open Interfaces: Our solution facilitates seamless capture and streaming of data from both vision and radar sub-systems over a single multi-Gigabit Ethernet interface, simplifying data acquisition and processing workflows. As Ethernet technology is widely adopted across various industries and applications, our Ethernet based sensor fusion streaming solution helps contribute to openness, interoperability, and accessibility.</li>\n</ul><br>\n<p>\n Last Modified: 07/01/2024<br>\nModified by: Ramesh&nbsp;Annavajjala</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nOur NSF Phase-1 project is focused on the feasibility study, design, and initial prototype development of a multi-modal and multi-spectral sensing solution by deeply integrating a multiple-input and multiple-output (MIMO) imaging radar with an RGB/IR vision sensor to enable enhanced situational awareness, long-range detection capability, and robust classification and tracking under adverse weather conditions for industries and applications as diverse as transportation and logistics, autonomous mobile robots, critical infrastructure protection, space, and defense. Our Phase-1 project resulted in significant technical achievements across three main areas which are summarized below:\n\n\n1. Long-Range MIMO Imaging Radar Feasibility Study, Design, and Initial Prototyping:\n\n\nAs part of this phase-1 project, we have successfully designed a novel long-range MIMO imaging radar. Our MIMO imaging radar enables 1-degree beamwidth (i.e., spatial resolution) simultaneously in azimuth and elevation with a novel antenna placement. By leveraging a cascade architecture with multiple commercial-off-the-shelf (COTS) radar transceiver chips, the effective isotropic radiated power is enhanced without any external power amplifiers to increase the target detection range. Our design addressed the phase coherency and clock synchronization challenges associated with millimeter frequencies by employing a master clock, power divider, frequency, and phase calibration, and carefully controlling the inter-chip timing imbalance. Our project encompassed the entire development cycle, including architectural tradeoffs, modeling, analysis, simulations, design of radar transceiver board schematics, transceiver board layout, and the production of limited-quantity prototype boards. Our MIMO imaging radar system offers several key features and benefits, including:\n\nEnhanced Range and Resolution: By utilizing the MIMO technology with virtual antenna arrays, transmit and receive beamforming, our solution can achieve a range of several hundred meters to detect weak objects, and a range resolution as small as 3 centimeters. With 1-degree spatial resolution, our solution offers up to 900x more spatial data compared with the state-of-the-art radar solutions. \nScalability and Flexibility: Modular design of our radar system allows for scalability and adaptability to different deployment scenarios and applications. Our radar sensor can be configured with varying numbers of antennas and transceiver units to meet specific requirements such as large, medium, short, and ultra-short range target detection. \nSoftware-defined Radar Signal Processing: With access to radar reflections from our transceiver board as captured by the raw ADC (analog-to-digital converter) samples, our solution enables software-defined radar signal processing with algorithmic agility, data-driven workflows, debuggability, interference avoidance, reduced power consumption, and lower solution cost. \n\n\n\n2. RGB+IR Camera Module Feasibility Study, Design, and Initial Prototyping:\n\n\nIn parallel with our imaging radar development, our project also focused on the feasibility of designing a compact RGB+IR camera module to address the gaps associated with radar-based detection of color (i.e., traffic lights and lane markings) and signs (i.e., stop signs and posted speed limits). Our proposed design integrates both visible spectrum and infrared imaging capabilities into a compact and versatile package. Like the imaging radar design, our camera module underwent rigorous design phases starting with the choice of imaging chip that satisfies the resolution, frame rate, field of view, power consumption, and cost. Additionally, we ensured that our imaging module can withstand extreme temperatures by picking an automotive-grade component. Once we converged on the imaging chip that addressed our requirements, we proceeded with schematics, layout, and production of limited-quantity prototype boards. Our integrated RGB/IR camera module offers several advantages, including:\n\nMultimodal Imaging Capabilities: By combining RGB and IR capabilities on a single chip, our imaging module enables simultaneous capture of visual and infrared images. This allows for comprehensive scene analysis and enhanced situational awareness in diverse environments.\nCompact Form Factor: The compact design of our imaging module facilitates integration into various platforms and systems, including unmanned aerial vehicles (UAVs), ground vehicles, and surveillance systems.\nHigh-Quality Imaging: Our imaging module produces 5 Megapixels resolution at up to 60 frames per sec to enable advanced computer vision-based detection, classification, and tracking of targets across different lighting and environmental conditions.\n\n\n\n3. Data Fusion Solution Feasibility Study, Design, and Initial Prototyping:\n\n\nOne of the key achievements of our Phase-1 project is the development of a sophisticated data fusion solution to integrate MIMO imaging radar with the RGB/IR cameras at the hardware level. Our data fusion solution offers the following capabilities:\n\nSynchronization and Triggering: Our solution ensures precise synchronization and simultaneous triggering of the imaging radar and RGB+IR cameras, enabling coordinated operation and data capture.\nDynamic Sensor Modality Configuration: Users can dynamically configure the imaging radar and RGB+IR cameras independently, adjusting parameters such as resolution, frame rate, and imaging modes to suit specific application requirements.\nUnified Data Streaming over Open Interfaces: Our solution facilitates seamless capture and streaming of data from both vision and radar sub-systems over a single multi-Gigabit Ethernet interface, simplifying data acquisition and processing workflows. As Ethernet technology is widely adopted across various industries and applications, our Ethernet based sensor fusion streaming solution helps contribute to openness, interoperability, and accessibility.\n\t\t\t\t\tLast Modified: 07/01/2024\n\n\t\t\t\t\tSubmitted by: RameshAnnavajjala\n"
 }
}