{
 "awd_id": "2308597",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CIF: Small: New Theory and Applications of Non-smooth and Non-Lipschitz Riemannian Optimization",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032920000",
 "po_email": "ahero@nsf.gov",
 "po_sign_block_name": "Alfred Hero",
 "awd_eff_date": "2022-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 316750.0,
 "awd_amount": 251673.0,
 "awd_min_amd_letter_date": "2023-01-18",
 "awd_max_amd_letter_date": "2023-01-18",
 "awd_abstract_narration": "Non-convex optimization problems are ubiquitous in fields as diverse as data science, machine learning, and information science and engineering, thereby creating a need for algorithms to efficiently solve such problems. This project will study an important but less developed area in non-convex optimization, namely non-smooth and non-Lipschitz Riemannian optimization. The outcomes of this project will provide insights into important classes of non-convex optimization problems, and will lead to the development of new tools for solving them. New teaching material on non-convex optimization problems will be produced for educating the next generation students in this important class of applications. The societal impact of this exploration will be to benefit new applications in areas such as gene expression, autonomous driving and cancer studies. \r\n\r\nWhile existing theory and algorithms for Riemannian optimization usually require the objective function to be differentiable, in contrast this project focuses on non-smooth and non-Lipschitz Riemannian optimization. In particular, the project will study several algorithms for non-smooth optimization that are less developed in the Riemannian setting, including the manifold alternating direction method of multipliers, the inertial manifold proximal gradient method, the stochastic manifold proximal point algorithm, and the manifold prox-linear algorithm. For Riemannian optimization with a non-Lipschitz objective, the investigators will derive the corresponding optimality conditions and then design two algorithms that are based on a smoothing technique, namely the Riemannian smoothing gradient descent method and the Riemannian smoothing trust region method. The proposed algorithms will be implemented to solve real-world applications such as the clustering of single-cell RNA sequencing data, and 3D object detection and 3D tracking in autonomous driving.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shiqian",
   "pi_last_name": "Ma",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shiqian Ma",
   "pi_email_addr": "sqma@rice.edu",
   "nsf_id": "000753161",
   "pi_start_date": "2023-01-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "William Marsh Rice University",
  "inst_street_address": "6100 MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "Houston",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7133484820",
  "inst_zip_code": "770051827",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "TX09",
  "org_lgl_bus_name": "WILLIAM MARSH RICE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "K51LECU1G8N3"
 },
 "perf_inst": {
  "perf_inst_name": "William Marsh Rice University",
  "perf_str_addr": "6100 MAIN ST",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "770051827",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "TX09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7797",
   "pgm_ref_txt": "COMM & INFORMATION FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 251672.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project investigates theory and solution methods for a class of important but less developed area in non-convex optimization: Riemannian optimization with non-smooth and/or non-Lipschitz objective. This class of problems finds many important applications in machine learning, statistics, signal processing, and robotics etc.</p>\r\n<p>&nbsp;</p>\r\n<p>With the support of this award, the PI developed some very influential algorithms for solving Riemannian optimization with non-smooth and/or non-Lipschitz objective, including Riemannian alternating direction method of multipliers (ADMM), manifold proximal linear (ManPL) algorithm, and Riemannian smoothing gradient descent method. In particular, the Riemannian ADMM is designed for solving Riemannian optimization with a non-smooth objective. This is the first convergent ADMM algorithm for Riemannian optimization with non-smooth objective. The ManPL algorithm is designed for solving Riemannian optimization with non-smooth objective and a composition structure. The Riemannian smoothing gradient descent method is designed for dealing with Riemannian optimization with non-Lipschitz objective. Rigorous convergence analysis of these methods has been established. These new theory and algorithms have been applied to important applications in machine learning, statistics, and signal processing. The PI and collaborators also developed computer codes of these methods which have been uploaded in Github. This award has contributed to papers in optimization journals and machine learning conferences, as well as invited conference and seminar talks.</p>\r\n<p>&nbsp;</p>\r\n<p>The broader impacts of this award are felt whenever a Riemannian optimization problem with non-smooth and/or non-Lipschitz objective needs to be solved. The award has also been used to train the next-generation researchers in optimization, machine learning, and data science. The outcome of this project also generated teaching materials for numerical optimization courses which can benefit and undergraduate students and PhD students in the field, as well as researchers and practitioners in academia, industry and government.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/08/2024<br>\nModified by: Shiqian&nbsp;Ma</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project investigates theory and solution methods for a class of important but less developed area in non-convex optimization: Riemannian optimization with non-smooth and/or non-Lipschitz objective. This class of problems finds many important applications in machine learning, statistics, signal processing, and robotics etc.\r\n\n\n\r\n\n\nWith the support of this award, the PI developed some very influential algorithms for solving Riemannian optimization with non-smooth and/or non-Lipschitz objective, including Riemannian alternating direction method of multipliers (ADMM), manifold proximal linear (ManPL) algorithm, and Riemannian smoothing gradient descent method. In particular, the Riemannian ADMM is designed for solving Riemannian optimization with a non-smooth objective. This is the first convergent ADMM algorithm for Riemannian optimization with non-smooth objective. The ManPL algorithm is designed for solving Riemannian optimization with non-smooth objective and a composition structure. The Riemannian smoothing gradient descent method is designed for dealing with Riemannian optimization with non-Lipschitz objective. Rigorous convergence analysis of these methods has been established. These new theory and algorithms have been applied to important applications in machine learning, statistics, and signal processing. The PI and collaborators also developed computer codes of these methods which have been uploaded in Github. This award has contributed to papers in optimization journals and machine learning conferences, as well as invited conference and seminar talks.\r\n\n\n\r\n\n\nThe broader impacts of this award are felt whenever a Riemannian optimization problem with non-smooth and/or non-Lipschitz objective needs to be solved. The award has also been used to train the next-generation researchers in optimization, machine learning, and data science. The outcome of this project also generated teaching materials for numerical optimization courses which can benefit and undergraduate students and PhD students in the field, as well as researchers and practitioners in academia, industry and government.\r\n\n\n\t\t\t\t\tLast Modified: 12/08/2024\n\n\t\t\t\t\tSubmitted by: ShiqianMa\n"
 }
}