{
 "awd_id": "2318984",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NCS-FO: Brain-Informed Goal-Oriented and Bidirectional Deep Emotion Inference",
 "cfda_num": "47.041, 47.070, 47.075",
 "org_code": "04040000",
 "po_phone": "7032924502",
 "po_email": "dkravitz@nsf.gov",
 "po_sign_block_name": "Dwight Kravitz",
 "awd_eff_date": "2023-09-01",
 "awd_exp_date": "2027-08-31",
 "tot_intn_awd_amt": 920000.0,
 "awd_amount": 975000.0,
 "awd_min_amd_letter_date": "2023-08-09",
 "awd_max_amd_letter_date": "2024-06-20",
 "awd_abstract_narration": "Human emotions are dynamic, multidimensional responses to challenges and opportunities that emerge from network interactions in the brain. Disruptions of these dynamics underlie emotional dysregulation in many mental disorders including anxiety and depression. To empirically study the neural basis of human emotion inference, experimenters often have observers view natural images varying in affective content, while at the same time recording their brain activity using electroencephalogram (EEG) and/or Functional magnetic resonance imaging (fMRI). Despite extensive research over the last few decades, much remains to be learned about the computational principles subserving the recognition of emotions in natural scenes. A major roadblock faced by empirical neuroscientists is the inability to carry out precisely manipulate human neural systems and test the consequences in imaging data. Deep Neural Networks (DNN), owing to their high relevance to human neural systems and extraordinary prediction capability, have become a promising tool for testing these sorts of hypotheses in swift and nearly costless computer simulations. The overarching goal of this project is to develop a neuroscience-inspired, DNN-based deep learning framework for emotion inference in real-world scenarios by synergistically integrating neuron-, circuit-, and system-level mechanisms. Recognizing that the state-of-the-art DNNs are centered on bottom-up and feedforward-only processing, which disagrees with the strong goal-oriented top-down modulation recurrence observed in the physiology, this project aims to enrich DNNs and enable closer AI-neuroscience interaction by incorporating goal-oriented top-down modulation and reciprocal interactions DNNs and test the model assumptions and predictions on neuroimaging data.\r\n\r\nTo meet these goals, the project aims to develop a brain-inspired goal-oriented and bidirectional deep learning model for emotion inference. Despite the great promise shown by today\u2019s deep learning as a framework for modeling biological vision, their architecture is limited to emulating the visual cortex for face/object/scene recognition and rarely goes beyond the inferotemporal cortex (IT), which is necessary for modeling high-level cognitive processes. In this project, we propose to build a biologically plausible deep learning architecture by integrating an in-silico amygdala module into the visual cortex architecture in DNN (the VCA model). The researchers hope to build neuron-, circuit-, and system-level modulation via goal-oriented attention priming, and multi-pathway predictive coding to 1) elucidate the mechanism of selectivity underlying preference and response to naturalistic emotions by artificial neurons; 2) differentiate fine-grained emotional responses via multi-path predictive coding, and 3) refine the neuroscientific understanding of human neuro-behavioral data by comparing attention priming and temporal generalization observed in simultaneous fMRI-EEG data to the computational observations using our brain-inspired VCA model. This project introduces two key innovations, both patterned after how brain operates, into DNN architecture and demonstrate their superior performance when applied to complex real-world tasks. Successful execution of the project can lead to the development of a new generation of AI-models that are inspired by neuroscience and that may in turn power neuroscience research.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ruogu",
   "pi_last_name": "Fang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ruogu Fang",
   "pi_email_addr": "ruogu.fang@bme.ufl.edu",
   "nsf_id": "000678411",
   "pi_start_date": "2023-08-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mingzhou",
   "pi_last_name": "Ding",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mingzhou Ding",
   "pi_email_addr": "mding@bme.ufl.edu",
   "nsf_id": "000235088",
   "pi_start_date": "2023-08-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andreas",
   "pi_last_name": "Keil",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andreas Keil",
   "pi_email_addr": "akeil@ufl.edu",
   "nsf_id": "000077306",
   "pi_start_date": "2023-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1523 UNION RD RM 207",
  "perf_city_name": "GAINESVILLE",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326111941",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "019Z",
   "pgm_ref_txt": "Grad Prep APG:Enhan. Experience"
  },
  {
   "pgm_ref_code": "1504",
   "pgm_ref_txt": "GRANT OPP FOR ACAD LIA W/INDUS"
  },
  {
   "pgm_ref_code": "170E",
   "pgm_ref_txt": "Interagency Agreements"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "8551",
   "pgm_ref_txt": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 920000.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 55000.0
  }
 ],
 "por": null
}