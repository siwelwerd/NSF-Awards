{
 "awd_id": "2208902",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "STTR Phase I:  Integrating Vision-Guided Collaborative Robots for Postharvest Processing of Produce",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2023-01-15",
 "awd_exp_date": "2024-12-31",
 "tot_intn_awd_amt": 212153.0,
 "awd_amount": 212153.0,
 "awd_min_amd_letter_date": "2023-01-03",
 "awd_max_amd_letter_date": "2024-06-17",
 "awd_abstract_narration": "The broader impact of this Small Business Technology Transfer (STTR) Phase I project is to empower the processors of harvested fruits and vegetables with the flexibility to use robotic automation to meet their labor needs. The automation uses collaborative robots (cobots) guided by computer vision, which are potentially safe around humans. The technology will help assure consistent produce quality and processing rates. Through a robust cobot-based solution, the project will provide an affordable, sustainable, and safe means for farms of all sizes to keep up with their production goals, which will sustain competition and the nation\u2019s food supply. This project has the added benefit of upskilling workers in farms by creating openings for more technically oriented positions, both in monitoring and maintaining the cobots. Instead of tediously programming the cobot for each use, the project is introducing a new way of translating the tasks performed by humans to the cobot by learning from camera recordings. It will also improve understanding of how cobots can safely be used alongside humans in a shared working space.\r\n\r\nThis Small Business Technology Transfer (STTR) Phase 1 project aims to make it possible to use cobots with human workers on tasks that go beyond the traditional pick-and-place. The proposed technology will automate processing line tasks that require computer vision, which is challenging because accurate and reliable perception must guide the robot\u2019s motion. Research has coalesced the technical challenges on the path to a viable commercial product around five steps. These start with a formal description of the task domain followed by using robust implementations of noise-tolerant machine learning algorithms for automatically learning the task, and end with a solution that integrates the learned task behavior with a vision-guided cobot system. Phase 1 will support research toward addressing two problems. The first is to design an intuitive way to elicit a precise specification of the client\u2019s task domain. A digital conversational assistant will utilize multiple modalities for the elicitation. The second is the inability of available implementations to generate coworker-aware and efficient cobot movements. The research will investigate and develop significant improvements to the cobot motion to improve coworker safety while reducing the processing time by an expected 50%.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Evan",
   "pi_last_name": "Johnston",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Evan Johnston",
   "pi_email_addr": "evan.johnston.uga@gmail.com",
   "nsf_id": "000868705",
   "pi_start_date": "2023-01-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Prashant",
   "pi_last_name": "Doshi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Prashant Doshi",
   "pi_email_addr": "pdoshi@uga.edu",
   "nsf_id": "000219732",
   "pi_start_date": "2023-01-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "INVERSAI, INC.",
  "inst_street_address": "111 RIVERBEND RD",
  "inst_street_address_2": "STE 270",
  "inst_city_name": "ATHENS",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "7062068891",
  "inst_zip_code": "306021514",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "GA10",
  "org_lgl_bus_name": "INVERSAI, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "QENNBEH1KM63"
 },
 "perf_inst": {
  "perf_inst_name": "University of Georgia",
  "perf_str_addr": "415 Boyd GSRC",
  "perf_city_name": "Athens",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "306020001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "GA10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "150500",
   "pgm_ele_name": "STTR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6856",
   "pgm_ref_txt": "ARTIFICIAL INTELL & COGNIT SCI"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 212153.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>InversAI's Phase I NSF STTR research concentrated on automating line processing tasks. Doing so is challenging when integrating computer vision and robotics. Accurate and reliable perception must guide robot motion in real-time and cannot be pre-planned. To accomplish this, InversAI divided its research into two distinct thrusts.</p>\r\n<p>The&nbsp;<strong>first</strong>&nbsp;research thrust focused on eliciting the task domain and learning it. This is accomplished through InversAI's machine learning pipeline, Cobot Learning Technology (CoboLT). CoboLT begins with the Domain Elicitation Software (DES), which is a streamlined and automated means of domain description. DES is novel for its ease of use, and it is targeted at users who do not necessarily have prior knowledge of artificial intelligence or machine learning concepts.</p>\r\n<p>CoboLT works with SA-Net, a deep neural network, to classify states and actions observed in video and depth camera streams. These classifications are used with CoboLT's inverse reinforcement learning algorithms to learn the agent's preferences and their behavior in every state. This allows an agent's behavior to be replicated simply by observing them.</p>\r\n<p>Upon testing this pipeline both internally and with users uninvolved with the project, InversAI has verified that CoboLT is intuitive and adaptable. Beyond the full technology pipeline described in this report, it also has potential applications in any task where learning the preferences of the agent is valuable, such as modeling the preferences of malicious hackers in cyber attacks to better combat their activities.</p>\r\n<p>The&nbsp;<strong>second</strong>&nbsp;research thrust focused on improving its PrecisionSort solution. PrecisionSort is designed for use with collaborative robots (cobots) to work alongside humans at processing lines. Its behavior is guided by the behavior obtained from CoboLT. Beginning with onions, it picks, inspects, and sorts produce according to its quality.&nbsp; Although CoboLT informs the task behavior, cobot arm movement is subject to the motion planning algorithm used, and has a substantial impact on performance speed.</p>\r\n<p>To improve the throughput, InversAI developed a new motion planning technique, CoWARRT. This technique greatly simplifies robot arm movement while avoiding undue distractions for nearby human co-workers. It now sorts onions twice as quickly compared to prior to the NSF STTR Phase I award. InversAI visited multiple farms to trial PrecisionSort, both revealing both the challenges of operating a real world environment and demonstrating the technology's ability to overcome these challenges.</p>\r\n<p>In partnership with the University of Georgia, InversAI conducted a study on a cobot using the CoWARRT technique to assess its social acceptability. Over two dozen students from the Computer Science department participated in the study, where they worked beside and across the robot. At the end of the study, they completed a survey regarding their experience. The general consensus was that working with the robot felt safe and comfortable, meaning this new algorithm has greatly improved throughput without sacrificing its social acceptability.</p>\r\n<p>CoboLT and PrecisionSort provide three main societal benefits:</p>\r\n<ol>\r\n<li><strong>Worker Upskilling.</strong>&nbsp;Employees at line facilities will learn how to supervise the cobot, leading to increased public scientific literacy. This has the additional benefit of improving worker safety, as many line tasks tend to be repetivie and lead to chronic injuries over time; by contrast, line supervision is less physically taxing. Providing additional opportunities to interact with robots is vital in a world that continues to integrate both robotics and AI into every discipline. This change will allow employees to keep pace with the changing demands of the economy.</li>\r\n<li><strong>Affordability.</strong>&nbsp;InversAI is first targeting small and medium-sized farms with this technology. Many of these farms are unable to afford conventional forms of automation due to their prohibitive price point, yet a solution is needed due to a rapidly dwindling human labor force. The labor problem is severe enough that farms typically rely on H-2A labor, which provides temporary visas to workers outside of the United States to work in agriculture; yet, even this tends to be insufficient to satisfy labor requirements during peak seasons. By contrast, PrecisionSort will be offered at an affordable rate comparable to that of human employees, allowing smaller farms to stay in business alongside the larger ones. By fostering healthy competition between farms, the price of produce will remain affordable.</li>\r\n<li><strong>Food accessibility.</strong>&nbsp;Due to the long hours that human employees work, errors are unaovidable. This leads to bad produce reaching the grocery shelves, and occasionally leads to good produce being discarded. By contrast, cobots do not grow tired, and offer twice the accuracy of humans while remaining consistent.</li>\r\n</ol>\r\n<p>InversAI is in talks with multiple farms who have expressed interest in the company's technology. With PrecisionSort and CoboLT, farms will have the ability to restore their produce throughput to pre-pandemic levels, while improving conditions for their employees and ensuring that quality produce is stocked on the nation's grocery shelves.</p>\r\n<ol> </ol><br>\n<p>\n Last Modified: 12/13/2024<br>\nModified by: Evan&nbsp;Johnston</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734108506913_cobolt--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734108506913_cobolt--rgov-800width.png\" title=\"CoboLT Architecture\"><img src=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734108506913_cobolt--rgov-66x44.png\" alt=\"CoboLT Architecture\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The architecture of CoboLT is comprised of numerous components. Each component is modular and designed to both work with the pipeline and standalone.</div>\n<div class=\"imageCredit\">InversAI</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Evan&nbsp;Johnston\n<div class=\"imageTitle\">CoboLT Architecture</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734107712972_transition--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734107712972_transition--rgov-800width.png\" title=\"DES\"><img src=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734107712972_transition--rgov-66x44.png\" alt=\"DES\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Using the GUI, DES can automatically determine certain inputs without users having to explicitly specify them.</div>\n<div class=\"imageCredit\">InversAI</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Evan&nbsp;Johnston\n<div class=\"imageTitle\">DES</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734108775309_pick--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734108775309_pick--rgov-800width.png\" title=\"PrecisionSort Picking\"><img src=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734108775309_pick--rgov-66x44.png\" alt=\"PrecisionSort Picking\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">PrecisionSort at a farm. The cobot arm is reaching out to pick up an onion for inspection.</div>\n<div class=\"imageCredit\">InversAI</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Evan&nbsp;Johnston\n<div class=\"imageTitle\">PrecisionSort Picking</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734109072263_inspect--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734109072263_inspect--rgov-800width.png\" title=\"PrecisionSort Inspection\"><img src=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734109072263_inspect--rgov-66x44.png\" alt=\"PrecisionSort Inspection\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The cobot positions the onion in front of the camera to perform a closer inspection.</div>\n<div class=\"imageCredit\">InversAI</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Evan&nbsp;Johnston\n<div class=\"imageTitle\">PrecisionSort Inspection</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734109283508_IMG20241115113012--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734109283508_IMG20241115113012--rgov-800width.jpg\" title=\"PrecisionSort Processing\"><img src=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734109283508_IMG20241115113012--rgov-66x44.jpg\" alt=\"PrecisionSort Processing\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">PrecisionSort is guided by SA-Net, which identifies onions as blemished or unblemished.</div>\n<div class=\"imageCredit\">InversAI</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Evan&nbsp;Johnston\n<div class=\"imageTitle\">PrecisionSort Processing</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734107522781_A_M_PSBot--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734107522781_A_M_PSBot--rgov-800width.jpg\" title=\"InversAI Personnel At Farm\"><img src=\"/por/images/Reports/POR/2024/2208902/2208902_10842017_1734107522781_A_M_PSBot--rgov-66x44.jpg\" alt=\"InversAI Personnel At Farm\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">InversAI personnel at a farm where a PrecisionSort trial was held.</div>\n<div class=\"imageCredit\">InversAI</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Evan&nbsp;Johnston\n<div class=\"imageTitle\">InversAI Personnel At Farm</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nInversAI's Phase I NSF STTR research concentrated on automating line processing tasks. Doing so is challenging when integrating computer vision and robotics. Accurate and reliable perception must guide robot motion in real-time and cannot be pre-planned. To accomplish this, InversAI divided its research into two distinct thrusts.\r\n\n\nThefirstresearch thrust focused on eliciting the task domain and learning it. This is accomplished through InversAI's machine learning pipeline, Cobot Learning Technology (CoboLT). CoboLT begins with the Domain Elicitation Software (DES), which is a streamlined and automated means of domain description. DES is novel for its ease of use, and it is targeted at users who do not necessarily have prior knowledge of artificial intelligence or machine learning concepts.\r\n\n\nCoboLT works with SA-Net, a deep neural network, to classify states and actions observed in video and depth camera streams. These classifications are used with CoboLT's inverse reinforcement learning algorithms to learn the agent's preferences and their behavior in every state. This allows an agent's behavior to be replicated simply by observing them.\r\n\n\nUpon testing this pipeline both internally and with users uninvolved with the project, InversAI has verified that CoboLT is intuitive and adaptable. Beyond the full technology pipeline described in this report, it also has potential applications in any task where learning the preferences of the agent is valuable, such as modeling the preferences of malicious hackers in cyber attacks to better combat their activities.\r\n\n\nThesecondresearch thrust focused on improving its PrecisionSort solution. PrecisionSort is designed for use with collaborative robots (cobots) to work alongside humans at processing lines. Its behavior is guided by the behavior obtained from CoboLT. Beginning with onions, it picks, inspects, and sorts produce according to its quality. Although CoboLT informs the task behavior, cobot arm movement is subject to the motion planning algorithm used, and has a substantial impact on performance speed.\r\n\n\nTo improve the throughput, InversAI developed a new motion planning technique, CoWARRT. This technique greatly simplifies robot arm movement while avoiding undue distractions for nearby human co-workers. It now sorts onions twice as quickly compared to prior to the NSF STTR Phase I award. InversAI visited multiple farms to trial PrecisionSort, both revealing both the challenges of operating a real world environment and demonstrating the technology's ability to overcome these challenges.\r\n\n\nIn partnership with the University of Georgia, InversAI conducted a study on a cobot using the CoWARRT technique to assess its social acceptability. Over two dozen students from the Computer Science department participated in the study, where they worked beside and across the robot. At the end of the study, they completed a survey regarding their experience. The general consensus was that working with the robot felt safe and comfortable, meaning this new algorithm has greatly improved throughput without sacrificing its social acceptability.\r\n\n\nCoboLT and PrecisionSort provide three main societal benefits:\r\n\r\nWorker Upskilling.Employees at line facilities will learn how to supervise the cobot, leading to increased public scientific literacy. This has the additional benefit of improving worker safety, as many line tasks tend to be repetivie and lead to chronic injuries over time; by contrast, line supervision is less physically taxing. Providing additional opportunities to interact with robots is vital in a world that continues to integrate both robotics and AI into every discipline. This change will allow employees to keep pace with the changing demands of the economy.\r\nAffordability.InversAI is first targeting small and medium-sized farms with this technology. Many of these farms are unable to afford conventional forms of automation due to their prohibitive price point, yet a solution is needed due to a rapidly dwindling human labor force. The labor problem is severe enough that farms typically rely on H-2A labor, which provides temporary visas to workers outside of the United States to work in agriculture; yet, even this tends to be insufficient to satisfy labor requirements during peak seasons. By contrast, PrecisionSort will be offered at an affordable rate comparable to that of human employees, allowing smaller farms to stay in business alongside the larger ones. By fostering healthy competition between farms, the price of produce will remain affordable.\r\nFood accessibility.Due to the long hours that human employees work, errors are unaovidable. This leads to bad produce reaching the grocery shelves, and occasionally leads to good produce being discarded. By contrast, cobots do not grow tired, and offer twice the accuracy of humans while remaining consistent.\r\n\r\n\n\nInversAI is in talks with multiple farms who have expressed interest in the company's technology. With PrecisionSort and CoboLT, farms will have the ability to restore their produce throughput to pre-pandemic levels, while improving conditions for their employees and ensuring that quality produce is stocked on the nation's grocery shelves.\r\n \t\t\t\t\tLast Modified: 12/13/2024\n\n\t\t\t\t\tSubmitted by: EvanJohnston\n"
 }
}