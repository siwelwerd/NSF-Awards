{
 "awd_id": "2301940",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: SHF: Small: Towards Robust Deep Learning Computing on GPUs",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2022-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 160241.0,
 "awd_amount": 137683.0,
 "awd_min_amd_letter_date": "2022-11-03",
 "awd_max_amd_letter_date": "2022-11-03",
 "awd_abstract_narration": "Graphics processing units (GPU) have become one of the most promising computing engines in many application domains such as scientific simulations and deep learning. With the massive parallel processing power provided by GPUs, most of the state-of-the-art server and edge systems employ GPUs as the core computing engines for deep-learning model training and inference. As the performance of deep learning models becomes one of the most important delimiters that determines market revenue of the model creators and the convenience of daily lives of model consumers, it is critical to enforce reliable and robust deep-learning computation. This project aims to explore the challenges and opportunities to address the reliability and privacy implications of GPU computing as a deep-learning accelerator and design lightweight protection schemes.\r\n\r\nThe technical aims of this project are divided into three thrusts. The first thrust explores and evaluates possible vulnerabilities and their impact on GPU-based deep-learning computing. The second thrust tackles the vulnerabilities at the compute-unit level by redesigning GPU building blocks, such as new scheduling algorithms and activation acceleration logic. The third thrust explores selective integrity protection mechanisms in communication channels and memory subsystems to transfer data between the CPU and GPU without imposing significant performance overhead. The proposed solutions will mitigate architectural and system vulnerabilities in GPU-based deep learning computing, which will enable the deep learning algorithm developers to focus more on performance improvement and technological advancement, and the consumers to use deep learning-based cognitive products without privacy concerns. The findings of this research will be integrated into undergraduate and graduate courses as well as various outreach activities on K-12 education, and publicly shared through open-source repositories.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nima",
   "pi_last_name": "Karimian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nima Karimian",
   "pi_email_addr": "nima.karimian@mail.wvu.edu",
   "nsf_id": "000798441",
   "pi_start_date": "2022-11-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "West Virginia University Research Corporation",
  "inst_street_address": "886 CHESTNUT RIDGE ROAD",
  "inst_street_address_2": "",
  "inst_city_name": "MORGANTOWN",
  "inst_state_code": "WV",
  "inst_state_name": "West Virginia",
  "inst_phone_num": "3042933998",
  "inst_zip_code": "265052742",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WV02",
  "org_lgl_bus_name": "WEST VIRGINIA UNIVERSITY RESEARCH CORPORATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "M7PNRH24BBM8"
 },
 "perf_inst": {
  "perf_inst_name": "West Virginia University Research Corporation",
  "perf_str_addr": "886 CHESTNUT RIDGE ROAD",
  "perf_city_name": "MORGANTOWN",
  "perf_st_code": "WV",
  "perf_st_name": "West Virginia",
  "perf_zip_code": "265052742",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WV02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 137683.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Graphics Processing Units (GPUs) have emerged as a crucial computing engine in various domains, including scientific simulations and deep learning. Leveraging their massive parallel processing capabilities, state-of-the-art server and edge systems rely on GPUs as the primary computing engine for training and deploying deep learning models. As the performance of deep learning models becomes a key factor in determining market revenue and user convenience, ensuring reliable and robust deep learning computation is critical. This project investigates vulnerabilities and performance bottlenecks in GPU computing, particularly in the context of deep learning. With the growing importance of GPUs in emerging workloads, understanding potential vulnerabilities in the era of hardware attacks is essential for securing deep learning computations.</p>\r\n<p>&nbsp;</p>\r\n<p><strong>Intellectual contributions:</strong></p>\r\n<p>While side-channel attacks on CPUs have been extensively researched, our findings reveal that model encryption using AES for deep learning workloads is susceptible to such attacks. Specifically, we discovered that GPU runtime execution under electromagnetic analysis can leak sensitive information about deep learning models, enabling parameter extraction and reverse engineering. To address these vulnerabilities, our team has developed techniques that leverage hardware security features to safeguard deep learning parameters. Additionally, we have created: Digital Fingerprint Memory: A novel approach to secure hyperparameters of deep learning models. Hardware-Based Encryption: A method to encrypt deep learning parameters using hardware security features, ensuring the confidentiality and integrity of sensitive model information. Our findings have been published in <em>ISQED</em>'24, <em>CSR</em>'23.</p>\r\n<p>&nbsp;</p>\r\n<p><strong>Broader Impacts:</strong></p>\r\n<p>Our project led to several publications in reputable scientific conferences, showcasing new findings and insights. These papers are accessible through the NSF Public Access Repository, contributing to the advancement of knowledge in the scientific community.</p>\r\n<p>We shared our research outcomes through various channels, including:</p>\r\n<ul>\r\n<li>Three      conference presentations</li>\r\n<li>Organizing      a summer camp for high school students, promoting STEM education and      awareness</li>\r\n<li>Hosting      a targeted webinar, fostering collaboration among scientists and      stakeholders</li>\r\n</ul>\r\n<p>These initiatives have helped raise awareness, promote cooperation, and inspire the next generation of cybersecurity professionals.</p>\r\n<p><strong>Education and Training</strong></p>\r\n<ul>\r\n<li><strong>Ph.D.      Student Training</strong>: Three Ph.D. students gained invaluable hands-on      experience and training in cybersecurity, empowering them to drive      innovation and advancements in the field.</li>\r\n<li><strong>Curriculum      Integration</strong>: Project outcomes were incorporated into graduate courses,      inspiring students to pursue post-graduate degrees in computer engineering      and cybersecurity. This integration has helped motivate the next      generation of experts to address emerging challenges in cybersecurity.</li>\r\n</ul>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/16/2025<br>\nModified by: Nima&nbsp;Karimian</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nGraphics Processing Units (GPUs) have emerged as a crucial computing engine in various domains, including scientific simulations and deep learning. Leveraging their massive parallel processing capabilities, state-of-the-art server and edge systems rely on GPUs as the primary computing engine for training and deploying deep learning models. As the performance of deep learning models becomes a key factor in determining market revenue and user convenience, ensuring reliable and robust deep learning computation is critical. This project investigates vulnerabilities and performance bottlenecks in GPU computing, particularly in the context of deep learning. With the growing importance of GPUs in emerging workloads, understanding potential vulnerabilities in the era of hardware attacks is essential for securing deep learning computations.\r\n\n\n\r\n\n\nIntellectual contributions:\r\n\n\nWhile side-channel attacks on CPUs have been extensively researched, our findings reveal that model encryption using AES for deep learning workloads is susceptible to such attacks. Specifically, we discovered that GPU runtime execution under electromagnetic analysis can leak sensitive information about deep learning models, enabling parameter extraction and reverse engineering. To address these vulnerabilities, our team has developed techniques that leverage hardware security features to safeguard deep learning parameters. Additionally, we have created: Digital Fingerprint Memory: A novel approach to secure hyperparameters of deep learning models. Hardware-Based Encryption: A method to encrypt deep learning parameters using hardware security features, ensuring the confidentiality and integrity of sensitive model information. Our findings have been published in ISQED'24, CSR'23.\r\n\n\n\r\n\n\nBroader Impacts:\r\n\n\nOur project led to several publications in reputable scientific conferences, showcasing new findings and insights. These papers are accessible through the NSF Public Access Repository, contributing to the advancement of knowledge in the scientific community.\r\n\n\nWe shared our research outcomes through various channels, including:\r\n\r\nThree      conference presentations\r\nOrganizing      a summer camp for high school students, promoting STEM education and      awareness\r\nHosting      a targeted webinar, fostering collaboration among scientists and      stakeholders\r\n\r\n\n\nThese initiatives have helped raise awareness, promote cooperation, and inspire the next generation of cybersecurity professionals.\r\n\n\nEducation and Training\r\n\r\nPh.D.      Student Training: Three Ph.D. students gained invaluable hands-on      experience and training in cybersecurity, empowering them to drive      innovation and advancements in the field.\r\nCurriculum      Integration: Project outcomes were incorporated into graduate courses,      inspiring students to pursue post-graduate degrees in computer engineering      and cybersecurity. This integration has helped motivate the next      generation of experts to address emerging challenges in cybersecurity.\r\n\r\n\n\n\t\t\t\t\tLast Modified: 01/16/2025\n\n\t\t\t\t\tSubmitted by: NimaKarimian\n"
 }
}