{
 "awd_id": "2231975",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "HCC: Small: Robust Object Detection for Mobile Augmented Reality in the Wild",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2023-11-01",
 "awd_exp_date": "2026-10-31",
 "tot_intn_awd_amt": 599817.0,
 "awd_amount": 599817.0,
 "awd_min_amd_letter_date": "2023-09-06",
 "awd_max_amd_letter_date": "2023-09-06",
 "awd_abstract_narration": "Mobile augmented reality (AR), which integrates virtual objects with real environments, has shown outstanding potential in many areas including retail, education, and healthcare. The progress made in AR and machine learning over the last several years has given rise to opportunities to generate AR experiences that are well-matched with specific contexts, by leveraging the outputs of machine-learning-based object-detection algorithms that identify objects and their locations in the field of view of the AR device. However, existing object-detection methods are brittle, often making mistakes due to variations in lighting, object positions, device capabilities, and users\u2019 actions. This project's goal, then, is to develop more robust object-detection methods and AR techniques that use them, grounded in real-world use cases. The motivating scenario is settings where a facility administrator would like users to benefit from object-detection-integrated AR experiences over the course of months or years: for example, teachers using AR-enhanced learning in a classroom, museum curators using AR to enrich visitors\u2019 experience, or managers of a construction site or a factory deploying AR-based safety guidance for workers. The project team\u2019s goal is to help administrators develop a variety of AR experiences with minimal workload, without placing restrictions on the state of the facility in terms of both its appearance and contents. This project will enable a wide range of context-aware AR applications, such as AR-based safety guidance, accessibility assistance, and support for health and well-being. The research will engage multiple diverse cohorts of undergraduate and high school students, both throughout the school year and on intense integrated summer research project experiences. Interactive demonstrations developed as part of this research will be showcased at K-12-oriented events. \r\n\r\nThis project will enhance the reliability of AR object detectors on multiple dimensions, via the development of new AR-specific object-detection training approaches, performance monitoring techniques, input and output sanity-checking methods, and application interfaces. The work is divided into three thrusts. The first thrust will design and develop a robust AR object detection framework that will enhance the reliability of AR object detectors by adapting them to the conditions in a given location and by validating the correctness of AR object detectors\u2019 inputs and outputs. The second thrust will examine the performance of AR object-detection algorithms across large and diverse groups of users and across a set of diverse AR devices; the team will design and develop mechanisms for adapting object detectors to specific users and devices with limited labeled data. The third thrust will examine the performance of AR object detectors in naturally changing environments across long-term deployments. This work will involve capturing a set of environments over a 12-month period, designing strategies for performance monitoring of AR object detectors, and developing approaches to maintain AR object detectors\u2019 performance over time by future-proofing and retraining them.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maria",
   "pi_last_name": "Gorlatova",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maria Gorlatova",
   "pi_email_addr": "maria.gorlatova@duke.edu",
   "nsf_id": "000761546",
   "pi_start_date": "2023-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "2200 W MAIN ST STE 710",
  "perf_city_name": "DURHAM",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277084677",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 599817.0
  }
 ],
 "por": null
}