{
 "awd_id": "2309443",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps: Liveness detection and integrity authentication of digital audio",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032924749",
 "po_email": "mwasko@nsf.gov",
 "po_sign_block_name": "Molly Wasko",
 "awd_eff_date": "2023-03-15",
 "awd_exp_date": "2024-02-29",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2023-03-08",
 "awd_max_amd_letter_date": "2023-03-08",
 "awd_abstract_narration": "The broader impact/commercial potential of this I-Corps project is the development of a reliable liveness detection and integrity authentication tool for digital audio. Recent technological advances in the areas of artificial intelligence, fake audio generation, and easy access to smart speakers pose serious security and privacy threats to voice activated devices/services (VAD/S)-based systems. Researchers have demonstrated existing VAD/S are vulnerable to attacks and the growing adoption of VAD/S for e-commerce, voice-based search, and speaker recognition-based banking and remote identity verification highlights the problem. The proposed technology aims to secure VAD/S, e.g., Google Home, Amazon Alexa, Apple Siri, etc., against a growing number of attacks including spoofing, replay, and deepfake attacks. Specifically, the proposed technology may reliably detect and prevent attacks on speaker/speech recognition systems using liveness detection for real-time systems and determine integrity verification for off-line systems. In addition, the proposed technology may benefit other areas including multimedia forensics, e-discovery, remote biometric verification, law enforcement and the entertainment industry.\r\n\r\nThis I-Corps project is based on the development of real-time liveness detection and integrity authentication of digital audio data. This is a relevant problem that concerns security of many critical applications central to modern digital usage such as speaker verification, speech recognition, fintech, e-commerce, and social medial platforms. Reliable liveness detection may be used to counter the threat of deepfakes to speaker verification and the spread of disinformation and falsehood on social media platforms while safeguarding speaker verification systems commonly used for noninvasive identity verification. The proposed liveness detection and integrity verification of audio data framework relies on the physics of acoustic and photo-acoustic processes and mathematical modeling of distortion artifacts due replay attacks.  The solution will use these to detect liveness of audio with the input of voice activated devices and services. In addition, the proposed innovation leverages the acoustic environment, acquisition device, and post-processing artifacts for forensic analysis and content integrity authentication. This technology may protect VAD/S against the growing number of attacks and provide forensic examiners and law enforcement personnel with a powerful, computationally efficient, scalable, and reliable tool to perform online as well as offline forensics analysis.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hafiz",
   "pi_last_name": "Malik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hafiz Malik",
   "pi_email_addr": "hafiz@umich.edu",
   "nsf_id": "000504526",
   "pi_start_date": "2023-03-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Dearborn",
  "inst_street_address": "4901 EVERGREEN RD",
  "inst_street_address_2": "",
  "inst_city_name": "Dearborn",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481282406",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "MI12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "RY78VSF6P4G3"
 },
 "perf_inst": {
  "perf_inst_name": "Regents of the University of Michigan - Dearborn",
  "perf_str_addr": "4901 EVERGREEN RD",
  "perf_city_name": "Dearborn",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481282406",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "MI12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8027",
   "pgm_ref_txt": "Cyber Secur - Cyberinfrastruc"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Recent studies show that voice-activated devices and services (VAD/S), such as Google Home, Amazon Alexa, and Apple Siri, are a booming market. Currently valued at over $10 billion, this sector is projected to almost triple, reaching over $27 billion by 2026. Functions like voice-activated shopping, voice search, banking through speaker recognition, and remote identity verification are quickly becoming commonplace.</p>\n<p><br />During a regional customer discovery initiative, we found that the automotive industry is briskly integrating speech recognition technologies into future vehicle models. But with rapid advancements in artificial intelligence, the creation of fake audio, and the widespread use of smart speakers, significant security and privacy risks for VAD/S have surfaced. Numerous studies have confirmed that current VAD/S can be compromised by these threats. Our proposed technology is designed to reliably identify and block attacks on speaker and speech recognition systems. It features live detection for use in real-time systems and integrity checks for offline use.&nbsp;</p>\n<p>Our project's goal is to assess the market demand for solid, real-time detection of audio authenticity, as well as for verifying the integrity of digital audio. In an age where artificially generated audio poses new challenges, it's essential to validate the authenticity and integrity of digital audio, which has vast implications for security in finance, national defense, intelligence operations, and public welfare.</p>\n<p><br />Moreover, the rise of \"deepfake\" audio used to spread misinformation on social media only adds urgency to our mission. Current audio verification systems fall short as they cannot conclusively link a digital recording to the specific microphone used or its recording environment. Our innovative technology analyzes audio to unearth clues about the recording's environment, the device used, and any post-processing, utilizing these indicators to validate audio integrity.</p>\n<p><br />Our prototype, dubbed FakeXpose, has been developed based on 170 interviews assessing market needs and has already proven its worth by detecting fraudulent audios, including those that targeted political events. This tool has gained attention from over 25 national media outlets and led to over 100 inquiries about multimedia integrity.</p>\n<p>We're now pursuing a Small Business Innovation Research (SBIR) grant to bring FakeXpose to market.</p>\n<p>The intellectual crux of this project lies in recognizing market needs for safeguarding voice-activated devices and services from an ever-evolving array of threats and in bridging the technological gaps to protect these devices. With substantial contributions that reach across various domains, this project has broad implications for security in the digital landscape, offering significant benefits to society in terms of upholding the integrity of information in legal, media, political, business, and scientific realms.</p><br>\n<p>\n Last Modified: 06/29/2024<br>\nModified by: Hafiz&nbsp;Malik</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nRecent studies show that voice-activated devices and services (VAD/S), such as Google Home, Amazon Alexa, and Apple Siri, are a booming market. Currently valued at over $10 billion, this sector is projected to almost triple, reaching over $27 billion by 2026. Functions like voice-activated shopping, voice search, banking through speaker recognition, and remote identity verification are quickly becoming commonplace.\n\n\n\nDuring a regional customer discovery initiative, we found that the automotive industry is briskly integrating speech recognition technologies into future vehicle models. But with rapid advancements in artificial intelligence, the creation of fake audio, and the widespread use of smart speakers, significant security and privacy risks for VAD/S have surfaced. Numerous studies have confirmed that current VAD/S can be compromised by these threats. Our proposed technology is designed to reliably identify and block attacks on speaker and speech recognition systems. It features live detection for use in real-time systems and integrity checks for offline use.\n\n\nOur project's goal is to assess the market demand for solid, real-time detection of audio authenticity, as well as for verifying the integrity of digital audio. In an age where artificially generated audio poses new challenges, it's essential to validate the authenticity and integrity of digital audio, which has vast implications for security in finance, national defense, intelligence operations, and public welfare.\n\n\n\nMoreover, the rise of \"deepfake\" audio used to spread misinformation on social media only adds urgency to our mission. Current audio verification systems fall short as they cannot conclusively link a digital recording to the specific microphone used or its recording environment. Our innovative technology analyzes audio to unearth clues about the recording's environment, the device used, and any post-processing, utilizing these indicators to validate audio integrity.\n\n\n\nOur prototype, dubbed FakeXpose, has been developed based on 170 interviews assessing market needs and has already proven its worth by detecting fraudulent audios, including those that targeted political events. This tool has gained attention from over 25 national media outlets and led to over 100 inquiries about multimedia integrity.\n\n\nWe're now pursuing a Small Business Innovation Research (SBIR) grant to bring FakeXpose to market.\n\n\nThe intellectual crux of this project lies in recognizing market needs for safeguarding voice-activated devices and services from an ever-evolving array of threats and in bridging the technological gaps to protect these devices. With substantial contributions that reach across various domains, this project has broad implications for security in the digital landscape, offering significant benefits to society in terms of upholding the integrity of information in legal, media, political, business, and scientific realms.\t\t\t\t\tLast Modified: 06/29/2024\n\n\t\t\t\t\tSubmitted by: HafizMalik\n"
 }
}