{
 "awd_id": "2413937",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "HCC: Small: NSF-DST: GameSignAI: Using AI to Help Deaf Children Acquire Language Skills",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2025-05-01",
 "awd_exp_date": "2027-04-30",
 "tot_intn_awd_amt": 549999.0,
 "awd_amount": 549999.0,
 "awd_min_amd_letter_date": "2025-04-23",
 "awd_max_amd_letter_date": "2025-04-23",
 "awd_abstract_narration": "Ninety-five percent of deaf children in the US are born to hearing parents, most of whom never learn sign language well enough to teach it to their children. This puts these children at risk for delayed communication development compared to hearing children or deaf children of deaf parents. These communication delays may lead to social isolation, mental health issues, and lowered quality of life. Using educational games to help bridge these gaps has been proposed, but little educational software is designed for American Sign Language (ASL) and even less for sign languages of other countries. This project's goal is to create a framework for mobile device developers to use on-device sign language recognition to develop educational software for Deaf children and their hearing parents. The plan is to develop educational software, tools, datasets and machine learning models and release them via open-source so the research can be replicated for other sign languages world-wide. To establish that the tools can generalize across languages, the project team will develop versions of the software for both ASL and for Indian Sign Language (ISL). ISL is both less studied than ASL and has a large user population, making it an excellent second language to work in. To ensure the work is well-suited to the needs of deaf people, the work will be done in close collaboration with the Deaf community, and with participation of Deaf student researchers. \r\n\r\nThe main technical focus of the project is to develop a framework that allows the rapid development of educational software that (a) can target multiple sign languages and (b) can be practically deployed without specialized hardware or setup requirements. The concrete educational software to be developed is based on two educational games for sign language previously developed by the research team that use word- and phrase-level ASL recognition in their gameplay. One key part of the project is the creation of robust datasets of ASL and ISL use, including fingerspelling, word, and phrase-level expressions. These datasets will both drive the creation of new recognition models and support linguistic analysis of ASL use. A second key element is designing novel algorithms for both recognizing sign language that are accurate enough to be useful and cope with disfluencies, flexible enough to support both adult and children's signing, and efficient enough to run on tablets and smartphones. The third key element is developing game design principles for educational software for sign language: avoiding the need for English-based instruction, appropriately responding to both well-formed and disfluent signing, and ways to assess and improve both users' receptivity and expressiveness around sign language. The research team will assess the effectiveness of both the software itself, in terms of its effects on children's language development, and the framework, in terms of its ability to be useful to other languages, developers, and researchers.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thad",
   "pi_last_name": "Starner",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Thad Starner",
   "pi_email_addr": "thadstarner@gmail.com",
   "nsf_id": "000219101",
   "pi_start_date": "2025-04-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue",
  "perf_city_name": "ATLANTA",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 549999.0
  }
 ],
 "por": null
}