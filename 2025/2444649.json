{
 "awd_id": "2444649",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Motion in action: Integrating multisensory inputs for posture stabilization and complex action acquisition",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2025-08-01",
 "awd_exp_date": "2028-07-31",
 "tot_intn_awd_amt": 489062.0,
 "awd_amount": 489062.0,
 "awd_min_amd_letter_date": "2025-04-09",
 "awd_max_amd_letter_date": "2025-04-09",
 "awd_abstract_narration": "Daily movements \u2013 from catching a ball to staying balanced while opening a heavy door \u2013 showcase the brain's remarkable ability to control movement and at the same time maintain stability. While these actions appear simple, they involve sophisticated interactions among different sensory systems, including vision, proprioception (muscle sense), and balance. This research project aims to understand how the brain coordinates these sensory systems to enable goal-oriented movement and stability. Using innovative virtual reality and robotic technology, the research team studies how humans control their movements and balance when interacting with moving objects. The team will develop computer models simulating how different sensory systems work together during these interactions.  This knowledge is crucial for improving human-robot interactions in environments that require physical collaboration. The project includes educational outreach through summer camps teaching middle school students about the brain and movement, emphasizing how neurological conditions affect balance and movement coordination. Camps for high school students include exploration of educational and career opportunities at the intersection of neuroscience, movement science, and robotics. \r\n\r\nWhile the individual sensory processing pathways are well characterized, the mechanisms by which the brain integrates multiple sensory signals to produce complex actions, such as intercepting a moving ball, remain poorly understood. The project aims to elucidate how the nervous system processes visual motion signals to modulate anticipatory postural adjustments and compensatory postural adjustments during interactions with moving objects. The research tests two theoretical frameworks: the feedback error learning model, which proposes that skill acquisition occurs through iterative updating of internal models, and the hierarchical sensory predictive control model, which posits that internal models update intersensory mappings (between vision, proprioception, and vestibular sensation) to regulate motor responses. The experimental paradigm employs a novel virtual reality and robotic system that allows precise control of object motion and contact forces. Participants interact with moving virtual objects while researchers measure smooth pursuit eye movements, muscle activation patterns, and limb dynamics. The experimental design systematically manipulates visual tracking conditions and object motion parameters to investigate how different sensory inputs contribute to motor learning. Data analysis combines traditional motor control measures with computational modeling approaches. This research advances our fundamental understanding of how the brain controls movement while generating insights relevant to human-robot interaction and rehabilitation medicine.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tarkeshwar",
   "pi_last_name": "Singh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tarkeshwar Singh",
   "pi_email_addr": "tsingh@psu.edu",
   "nsf_id": "000830776",
   "pi_start_date": "2025-04-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "201 OLD MAIN",
  "perf_city_name": "UNIVERSITY PARK",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168021503",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "PA15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 489062.0
  }
 ],
 "por": null
}