{
 "awd_id": "2446371",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Attentional guidance and decisions during visual search",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032925187",
 "po_email": "echua@nsf.gov",
 "po_sign_block_name": "Elizabeth F. Chua",
 "awd_eff_date": "2025-03-15",
 "awd_exp_date": "2028-02-29",
 "tot_intn_awd_amt": 624041.0,
 "awd_amount": 341347.0,
 "awd_min_amd_letter_date": "2025-03-12",
 "awd_max_amd_letter_date": "2025-03-12",
 "awd_abstract_narration": "Humans perform visual search tasks many times throughout the day. Examples include searching for the perfect snack in a supermarket, looking for a misplaced phone in a cluttered room, or finding a friend in a busy restaurant. The efficiency with which humans perform these tasks has a significant impact on the quality of daily life. The current project uses behavior, eye-tracking, virtual reality, brain activity, and computational modeling to test the idea that the efficiency of visual search depends on two stages of processing with two different computational goals: 1) a first stage with \u201cgood enough\u201d attentional guidance to select potential targets for closer inspection, and 2) a second stage involving a decision that emphasizes accuracy over speed. The overall goal is to understand organizing principles that make visual search efficient. In addition to the scientific work, this project supports the training and professional development of undergraduate students with activities that build scientific literacy, analytical skills, and emphasize links between classroom learning and the workforce.\r\n\r\nThe project tests hypotheses that guidance and decisions in visual search rely on different types of information because they have different computational goals, not because they work on different feature types. One set of experiments tests the prediction that during visual search, attentional guidance prioritizes speed over accuracy, but that decisions prioritize accuracy over speed. To do this, simple stimulus arrays in which the precision and feature-dimension used for guidance and decisions are separately measured using eye-tracking data, electroencephalography/event-related potentials (EEG/ERPs), and drift-diffusion modeling (DDM). Another set of experiments, also using behavior, EEG, and DDMs, test the prediction that attentional guidance relies on non-target information such as prior knowledge about typical scenes because they act as rapidly detectable spatial cues for the target.  Additionally, the project uses immersive virtual reality and DDMs to examine search efficiency in naturalistic contexts and test for hierarchical processes in which guidance prioritizes information and leads to reductions in the search space. Overall, the project aims to address important limitations of existing models of attention and aims to understand how visual search is efficient.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Joy",
   "pi_last_name": "Geng",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Joy J Geng",
   "pi_email_addr": "jgeng@ucdavis.edu",
   "nsf_id": "000557854",
   "pi_start_date": "2025-03-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Davis",
  "perf_str_addr": "1850 RESEARCH PARK DR STE 300",
  "perf_city_name": "DAVIS",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956186153",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169900",
   "pgm_ele_name": "Cognitive Neuroscience"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1699",
   "pgm_ref_txt": "COGNEURO"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002728DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 341347.0
  }
 ],
 "por": null
}