{
 "awd_id": "2430673",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: TaskDCL: Adapting Mixed Reality Training Programs to Real-World Scenes to enhance Human-AI Teaming in Emergency Responses",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032922633",
 "po_email": "aleoness@nsf.gov",
 "po_sign_block_name": "Alex Leonessa",
 "awd_eff_date": "2025-01-01",
 "awd_exp_date": "2026-12-31",
 "tot_intn_awd_amt": 299861.0,
 "awd_amount": 299861.0,
 "awd_min_amd_letter_date": "2024-11-22",
 "awd_max_amd_letter_date": "2024-11-22",
 "awd_abstract_narration": "This EArly-concept Grant for Exploratory Research (EAGER) project funds research that intends to speed up the development of mixed reality and artificial intelligence technologies to help first responders, aiming to reduce training-related risks and casualties. The research team will work with the Fairfax Fire and Rescue Department to explore how AI can be used in mixed reality tools to improve training and effectiveness for first responders. By adding virtual elements like fires, hazards, firefighters, robots, and people in need of rescue to real-life scenes, these mixed reality scenarios help first responders practice handling real-world challenges through interactive training. The project will also involve a postdoctoral researcher and undergraduate students, including those from underrepresented groups in science and technology fields. The team will share their findings at conferences focused on mixed reality and training.\r\n\r\nThis EAGER project offers a novel interdisciplinary research perspective by integrating concepts and techniques from mixed reality, artificial intelligence, human-computer interaction, and movement science to advance first responder training. The goal is to devise a novel optimization-based generative framework for adapting mixed reality training scenarios to real scenes, which will offer ample training opportunities for first responders to practice, accomplishing different first-responder tasks (e.g., firefighting, search and rescue) via human-artificial intelligence collaboration enabled by mixed reality headsets. To carry out the research, the team will first investigate how artificial intelligence techniques could be integrated with mixed reality devices to provide first response assistance. The team will then devise a generative framework based on optimization techniques for adapting mixed reality training scenarios to real scenes. The team will conduct user studies to evaluate the performance gain brought about by the advanced mixed reality interfaces and the synthesized training scenarios.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lap Fai",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lap Fai Yu",
   "pi_email_addr": "craigyu@gmu.edu",
   "nsf_id": "000701257",
   "pi_start_date": "2024-11-22",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Joel",
   "pi_last_name": "Martin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Joel Martin",
   "pi_email_addr": "jmarti38@gmu.edu",
   "nsf_id": "000817036",
   "pi_start_date": "2024-11-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "George Mason University",
  "inst_street_address": "4400 UNIVERSITY DR",
  "inst_street_address_2": "",
  "inst_city_name": "FAIRFAX",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "7039932295",
  "inst_zip_code": "220304422",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "VA11",
  "org_lgl_bus_name": "GEORGE MASON UNIVERSITY",
  "org_prnt_uei_num": "H4NRWLFCDF43",
  "org_uei_num": "EADLFP7Z72E5"
 },
 "perf_inst": {
  "perf_inst_name": "George Mason University",
  "perf_str_addr": "4400 UNIVERSITY DR",
  "perf_city_name": "FAIRFAX",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "220304422",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "VA11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "058Y00",
   "pgm_ele_name": "M3X - Mind, Machine, and Motor"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7632",
   "pgm_ref_txt": "HUMAN-ROBOT INTERACTION"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 299861.0
  }
 ],
 "por": null
}