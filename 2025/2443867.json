{
 "awd_id": "2443867",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Robust Learning from Preference Feedback",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032924551",
 "po_email": "jzhu@nsf.gov",
 "po_sign_block_name": "Jun Zhu",
 "awd_eff_date": "2025-10-01",
 "awd_exp_date": "2030-09-30",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 85950.0,
 "awd_min_amd_letter_date": "2025-01-21",
 "awd_max_amd_letter_date": "2025-01-21",
 "awd_abstract_narration": "In recent years, preference feedback\u2014comparative inputs such as \u201cA is better than B\u201d\u2014has emerged as a vital resource for guiding decision-making systems. Unlike explicit labels, preference feedback is often easier to collect and can be particularly valuable in subjective tasks where defining ideal outcomes is difficult. However, real-world preference data are often noisy, sparse, and heterogeneous, posing significant challenges to existing statistical methods. For example, recommendation systems may encounter incomplete feedback from users who abandon tasks due to fatigue or provide inconsistent inputs due to individual biases. This project aims to address the challenges of learning from preference feedback by developing robust statistical methods and advancing the theoretical foundations of preference-based learning. Additionally, it seeks to prepare students to tackle these challenges by integrating the research findings into innovative teaching platforms and educational curricula.\r\n\r\nThe project will focus on three key areas of learning from preference feedback: ranking from pairwise comparisons, user-item rating systems, and reinforcement learning from human feedback. To advance the field, the project will (1) develop robust algorithms for ranking that account for ill-conditioned sampling mechanisms and relax parametric modeling assumptions; (2) propose new estimation and uncertainty quantification methods for user-item ratings that work effectively in sparse and heterogeneous settings; and (3) introduce novel frameworks for reinforcement learning that incorporate \u201cout-of-list\u201d preference feedback while addressing the issue of distribution shifts. Through these contributions, the project will bridge the gap between statistical theory and practical applications, creating tools to enhance decision-making systems across diverse domains.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cong",
   "pi_last_name": "Ma",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cong Ma",
   "pi_email_addr": "congma2015@gmail.com",
   "nsf_id": "000918284",
   "pi_start_date": "2025-01-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "5801 S ELLIS AVE",
  "perf_city_name": "CHICAGO",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606375418",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002829DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002728DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002930DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 85950.0
  }
 ],
 "por": null
}