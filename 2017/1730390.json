{
 "awd_id": "1730390",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CyberTraining: DSE: Cyber Carpentry:  Data Life-Cycle Training using the Datanet Federation Consortium Platform",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Alan Sussman",
 "awd_eff_date": "2017-11-01",
 "awd_exp_date": "2021-10-31",
 "tot_intn_awd_amt": 499641.0,
 "awd_amount": 499641.0,
 "awd_min_amd_letter_date": "2017-06-28",
 "awd_max_amd_letter_date": "2017-06-28",
 "awd_abstract_narration": "The emergence of massive data collections has ushered a paradigm shift in the way scientific research is conducted and new knowledge is discovered.  This shift necessitates students to be trained in team-based, interdisciplinary, complex data-oriented approaches designed to translate scientific data into new solutions in order to promote the progress of science; to advance the national health, prosperity and welfare, and to secure the national defense.  The proliferation of cyberinfrastructure (CI) tools necessitate addressing the needs of domain scientists from multiple angles, including data access, metadata management, large-scale analytics and workflows, data and application discovery and sharing, and data preservation.  Training with such a holistic perspective is indeed daunting with a tool and solution landscape that is still fragmented.  Integrated solutions, such as the Datanet Federation Consortium (DFC) Platform, provide a way to ease this overload and help touch upon all of these needed functionalities.  The aim of this project is to make it easier for next generation workforce in STEM disciplines to learn all aspects of data-intensive computing environment and, more importantly, to work together with other researchers with complementary expertise.\r\n\r\nStudents in STEM disciplines need to be educated in (i) practices of data organization, (ii) importance of provenance, metadata and ontology, (iii) conformance to authentication, authorization and access control protocols, (iv) models for data sharing, discovery and curation, (v) necessity for reproducible data science workflows, (vi) practices in dealing with large-scale data computation using super computers and cloud computing, and (vii) distributed data management practices.  The Datanet Federation Consortium (DFC) is an NSF-funded project that has implemented a data-centered cyber platform that has integrated tools for end-to-end data life-cycle management and data-intensive high performance computation.  This project aims to use the DFC Platform to provide training for STEM graduate students in leading-edge data-intensive practices, in all aspects of data-intensive computing environments.  Their training workshops will be multi-disciplinary, including  earth system sciences, biological sciences, social and information sciences, marine sciences and engineering.  The short term goal of the project is to provide intensive, short duration training discipline-centric workshops, called Cyber Carpentries.  These workshops will lead to Certificates in Data Science, preparing a better scientific workforce with advanced data-intensive CI capabilities.  For the long-term, project plans to develop self-paced tutorials and a sequence of courses that can be adapted in different STEM disciplines with concentration in data life-cycle management and data-intensive computing.  The practicums will involve large datasets from multiple science data repositories including several NSF-funded large-scale cyberinfrastructure such as iRODS, CyVerse, DataONE, SEAD, TerraPop, DataVerse and HydroShare - all of which are integrated through the DFC Platform.  Project will recruit students from HBCUs and MSIs for its workshops and will work closely with faculty from these universities to help them adopt the courses developed through this project.  All material developed as part of the project will be made available as open course material.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Arcot",
   "pi_last_name": "Rajasekar",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Arcot K Rajasekar",
   "pi_email_addr": "rajaseka@email.unc.edu",
   "nsf_id": "000233964",
   "pi_start_date": "2017-06-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Hao",
   "pi_last_name": "Xu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hao Xu",
   "pi_email_addr": "xuh@email.unc.edu",
   "nsf_id": "000672401",
   "pi_start_date": "2017-06-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Melanie",
   "pi_last_name": "Feinberg",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Melanie Feinberg",
   "pi_email_addr": "melanie_feinberg@unc.edu",
   "nsf_id": "000744064",
   "pi_start_date": "2017-06-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "100 Manning Hall",
  "perf_city_name": "Chapel Hill",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275993360",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "044Y00",
   "pgm_ele_name": "CyberTraining - Training-based"
  },
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7361",
   "pgm_ref_txt": "EDUCATION AND WORKFORCE"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 499641.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Data-intensive research is becoming the new model in all STEM disciplines. But graduate students are not offered training in the best practices of Data Science and learn by trial and error. At a time when thousands of scientists and engineers are creating and using large number of distributed datasets and exploring an increasingly diverse mix of phenomena, the need for training in the areas of data life-cycle management and data-intensive computation becomes very important. Data-intensive research and data-enabled scientific discovery require a paradigm shift from the current graduate education model of individual achievement within a single scientific domain to a model applying team-based, multi-disciplinary, data-oriented open science approach designed to translate scientific data into new solutions to meet today&rsquo;s critical challenges.</p>\n<p><strong>Intellectual Merit: </strong>In this project, we developed a new training model that harnesses the power of data and computation in collaborative environments. We call this the Data Intensive Cyber Environment (DICE) learning model that teaches the interplay between data, computation and humans, using collaboration framework that integrates multiple tools and resources. Our approach is based on four tenets: (1) Graduate training must incorporate data life-cycle management training. (2) Graduate training must incorporate reproducible data-oriented scientific workflow and computation training. (3) Graduate training must incorporate interdisciplinary training that couples the domain sciences with data science. (4) Graduate training must prepare students to collaborate across data-enabled research teams. We emphasize that this approach is distinct from today&rsquo;s graduate training, which offers scant training in large-scale distributed data management and also training is in either data science or a domain science (e.g., biology, sociology, political science, economics), but does not integrate the two within a single curriculum designed to prepare the next generation of domain-data scientists.</p>\n<p>Based on our model and derived from our experience in multi-disciplinary team science in the NSF funded Datanet Federation Consortium (DFC) project, we conducted two workshops for doctoral students and post-doctoral fellows (over two summers). The workshop training materials were put together by experienced researchers, who were very much involved in designing, developing and applying the DFC Platform for end-to-end data-intensive applications as well as other leading nation-wide projects funded by the NSF. The practicums involved large datasets from diverse science data repositories and using Science portals such as the CyVerse and HydroShare and applying the NSF funded cyberinfrastructure such as the iRODS, XSEDE and Jetstream. Students learnt to use clusters and cloud computing facilities and applied concepts in collaborative and reusable computing and workflows using coordination and coordination tools as well as packaging and deployments tools. In addition to tools and techniques, the hands-on group project taught them how to perform reproducible science &ndash; both through lessons as well as practice. The aim was for each project group to implement a project from end-to-end, including accessing distributed data, preparing and cleaning it and then using large-scale resources such as the Jetstream and Amazon AWS to perform modeling and analytics. The main idea is not just to create a one-off project but bundle it in such a way that it becomes reproducible. All of the groups produced reproducible workflows by the end of their workshops and successfully handed over to another team to run, test and reuse their work. The group project also paired multiple STEM students into an interdisciplinary team which helped them to find common grounds for working across disciplines.</p>\n<p><strong>Broader Impact:</strong> Jim Gray defined the Fourth Paradigm of scientific discovery as the outcome of advanced computing architectures, diverse communication technologies, novel software algorithms and collaborative science driven by the &lsquo;data deluge&rsquo;. Our model is a realization of this and the workshop was a way to develop such data-driven team research. The insights gained from such cross-fertilization will be very useful as data science is becoming increasingly multi-disciplinary. The curriculum developed during this project has been used in creating two new courses and modifying two existing courses to teach open team science and collaborative reproducible research for undergraduate and graduate students in information sciences. Hence, the impact of the work will be broad. The workshops had a very broad representation in terms of demographics as well as disciplinary sciences. Of the 41 students trained in the workshop, 25 were women, 13 students were from EPSCoR states and 4 students were from under-represented communities. &nbsp;The students represented six different directorates in NSF: BIO, CISE, ENG, GEO, MPS and SBE and hence were exposed to good cross-fertilization of ideas, tools and methods during the project training.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/11/2022<br>\n\t\t\t\t\tModified by: Arcot&nbsp;K&nbsp;Rajasekar</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nData-intensive research is becoming the new model in all STEM disciplines. But graduate students are not offered training in the best practices of Data Science and learn by trial and error. At a time when thousands of scientists and engineers are creating and using large number of distributed datasets and exploring an increasingly diverse mix of phenomena, the need for training in the areas of data life-cycle management and data-intensive computation becomes very important. Data-intensive research and data-enabled scientific discovery require a paradigm shift from the current graduate education model of individual achievement within a single scientific domain to a model applying team-based, multi-disciplinary, data-oriented open science approach designed to translate scientific data into new solutions to meet today\u2019s critical challenges.\n\nIntellectual Merit: In this project, we developed a new training model that harnesses the power of data and computation in collaborative environments. We call this the Data Intensive Cyber Environment (DICE) learning model that teaches the interplay between data, computation and humans, using collaboration framework that integrates multiple tools and resources. Our approach is based on four tenets: (1) Graduate training must incorporate data life-cycle management training. (2) Graduate training must incorporate reproducible data-oriented scientific workflow and computation training. (3) Graduate training must incorporate interdisciplinary training that couples the domain sciences with data science. (4) Graduate training must prepare students to collaborate across data-enabled research teams. We emphasize that this approach is distinct from today\u2019s graduate training, which offers scant training in large-scale distributed data management and also training is in either data science or a domain science (e.g., biology, sociology, political science, economics), but does not integrate the two within a single curriculum designed to prepare the next generation of domain-data scientists.\n\nBased on our model and derived from our experience in multi-disciplinary team science in the NSF funded Datanet Federation Consortium (DFC) project, we conducted two workshops for doctoral students and post-doctoral fellows (over two summers). The workshop training materials were put together by experienced researchers, who were very much involved in designing, developing and applying the DFC Platform for end-to-end data-intensive applications as well as other leading nation-wide projects funded by the NSF. The practicums involved large datasets from diverse science data repositories and using Science portals such as the CyVerse and HydroShare and applying the NSF funded cyberinfrastructure such as the iRODS, XSEDE and Jetstream. Students learnt to use clusters and cloud computing facilities and applied concepts in collaborative and reusable computing and workflows using coordination and coordination tools as well as packaging and deployments tools. In addition to tools and techniques, the hands-on group project taught them how to perform reproducible science &ndash; both through lessons as well as practice. The aim was for each project group to implement a project from end-to-end, including accessing distributed data, preparing and cleaning it and then using large-scale resources such as the Jetstream and Amazon AWS to perform modeling and analytics. The main idea is not just to create a one-off project but bundle it in such a way that it becomes reproducible. All of the groups produced reproducible workflows by the end of their workshops and successfully handed over to another team to run, test and reuse their work. The group project also paired multiple STEM students into an interdisciplinary team which helped them to find common grounds for working across disciplines.\n\nBroader Impact: Jim Gray defined the Fourth Paradigm of scientific discovery as the outcome of advanced computing architectures, diverse communication technologies, novel software algorithms and collaborative science driven by the \u2018data deluge\u2019. Our model is a realization of this and the workshop was a way to develop such data-driven team research. The insights gained from such cross-fertilization will be very useful as data science is becoming increasingly multi-disciplinary. The curriculum developed during this project has been used in creating two new courses and modifying two existing courses to teach open team science and collaborative reproducible research for undergraduate and graduate students in information sciences. Hence, the impact of the work will be broad. The workshops had a very broad representation in terms of demographics as well as disciplinary sciences. Of the 41 students trained in the workshop, 25 were women, 13 students were from EPSCoR states and 4 students were from under-represented communities.  The students represented six different directorates in NSF: BIO, CISE, ENG, GEO, MPS and SBE and hence were exposed to good cross-fertilization of ideas, tools and methods during the project training.\n\n \n\n\t\t\t\t\tLast Modified: 02/11/2022\n\n\t\t\t\t\tSubmitted by: Arcot K Rajasekar"
 }
}