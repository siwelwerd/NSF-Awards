{
 "awd_id": "1720487",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Fine-Scale Singularity Detection in Multi-Dimensional Imaging with Regular, Orientable, Symmetric, Frame Atoms with Small Support",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922948",
 "po_email": "slevine@nsf.gov",
 "po_sign_block_name": "Stacey Levine",
 "awd_eff_date": "2017-07-15",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2017-07-20",
 "awd_max_amd_letter_date": "2017-07-20",
 "awd_abstract_narration": "One of life's essential characteristic is movement. Whether it is the spectacular, delicate dance of the unblemished, white swan in Tchaikovsky's Swan Lake, or the early attempts of a toddler to use his or her hands, the neurology of movement is uniquely common for all animals and humans: learning a motor skill, and the necessary muscle coordination. With practice the skill is perfected. Finally, the retainment of this experience-based learning process is the conclusion of this learning process. The ultimate goal of this project is to provide new tools to neuroscientists who study the biological basis of learning at the cell level using live animals. This function is facilitated by a number of anatomical changes in the structure of the cytoplasm of neural cells, such as the formation of lengthy branches known as axons and dendrites, and at a fine scale of dendritic spines and axonal buttons. The latter are less anatomically permanent structures arising on the surface of these cytoplasmic extensions. Dendritic spines and axonal buttons form synapses, which are the communication gateways between neurons. The research team will develop mathematical and computational tools for automatizing the study of spine populations in live neurons, and of their time-evolution during learning. The anticipated outcomes will provide neuroscientists with a number of software tools which will automatize the analysis of synaptic strength and its evolution with learning. These findings will contributed to the better understanding the biological mechanisms of autism and drug addictions.\r\n\r\nThe investigators on this project will develop algorithms for the 3D digital segmentations of dendritic surfaces including spines from 3D images acquired with a certain type of microscope, which uses laser light and works as a scanner by exploiting the natural ability of neurons to fluoresce. They aim to generate accurate binary reconstructions of a dendritic arbor including its spines. The primary challenge in this project is that image acquisition of live neurons has a resolution which provides limited detail of the spines. Often, images contain noise which further complicates the extraction of accurate, binary 3D reconstructions of dendritic surfaces showing spine details. Overcoming this problem is a core goal of the project because spine volume estimation quantifies synaptic strength. These unique challenges lead the investigators to the development of novel mathematical tools for fine scale analysis. They will build ensembles of short in size 3D imaging, 3D-orientation selective, frame-based filters, suitable for sensing curves and surfaces in noisy images. These filters will be designed to respond to local changes of image smoothness. Information obtained from these filters at various scales, will be utilized as input for multilayer, deep-learning inspired neural networks which will determine in an image which voxels belong to spine surfaces. Further algorithmic tools will be developed to track every spine of a dendrite individually over time. The same filtering tools will be used in a different application domain, the generation of illumination neutral images, in real-time. This will help the fast, high throughput removal of the effects of uneven illumination in images inhibiting the detection, by software or the naked eye of contours associated with shapes or textures in a scene. The investigators will develop the mathematical theory of illumination neutralization using concepts from fractal and microlocal analysis. The illumination neutralization algorithm is envisioned to work for real-time video analysis and in conjunction with face verification algorithms with the potential to be used in face recognition, laser microscopy and remote sensing applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Emanuel",
   "pi_last_name": "Papadakis",
   "pi_mid_init": "I",
   "pi_sufx_name": "",
   "pi_full_name": "Emanuel I Papadakis",
   "pi_email_addr": "mpapadak@math.uh.edu",
   "nsf_id": "000395648",
   "pi_start_date": "2017-07-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Demetrio",
   "pi_last_name": "Labate",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Demetrio Labate",
   "pi_email_addr": "dlabate@math.uh.edu",
   "nsf_id": "000259813",
   "pi_start_date": "2017-07-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Houston",
  "inst_street_address": "4300 MARTIN LUTHER KING BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "HOUSTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7137435773",
  "inst_zip_code": "772043067",
  "inst_country_name": "United States",
  "cong_dist_code": "18",
  "st_cong_dist_code": "TX18",
  "org_lgl_bus_name": "UNIVERSITY OF HOUSTON SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "QKWEF8XLMTT3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Houston",
  "perf_str_addr": "4800 Calhoun",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "772043008",
  "perf_ctry_code": "US",
  "perf_cong_dist": "18",
  "perf_st_cong_dist": "TX18",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  },
  {
   "pgm_ele_code": "745400",
   "pgm_ele_name": "MSPA-INTERDISCIPLINARY"
  },
  {
   "pgm_ele_code": "771400",
   "pgm_ele_name": "Modulation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8007",
   "pgm_ref_txt": "BioMaPS"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The work supported by this award was motivated by two problems arising from neuroscience imaging and the elimination of the effects of illumination and visibility variations in the analysis of natural images at a variety of spectra associated with natural or artificial light.</p>\n<p>Neuroscience imaging is a broad and modern area of research rapidly growing due to technological advances in high-resolution fluorescent microscopy that enable the visualization of neurons and their subcellular compartments both in vivo and in vitro. Specifically, our ongoing and future work in neuroscience imaging aims at developing a new generation of quantitative tools to facilitate the modeling of fundamental biological processes related to neuronal activity at cell level.</p>\n<p>Image formation is the mechanism light is emitted from objects in a scene of interest, e.g., a landscape or a selfie, and captured by a camera sensor clearly affects the quality and quantity of details captured in an image. Various factors between an object and a camera may affect image formation, e.g., the presence of smoke or precipitation, uneven or weak illumination of a scene will affect the luminous energy reaching the camera sensor. A representative example of such an image is a landscape enveloped by haze or light fog.</p>\n<p>With the support of this award, we developed theoretical models for image formation under the combined effect of uneven or weak illumination and low visibility conditions. Moreover, we investigated how deep neural network object detectors and classifiers can be used to identify the presence of various objects in an image or video and how to label them. &nbsp;Special attention was given to object detection with inputs from several imaging applications: Hyperspectral satellite images used for vegetation and human structures classification, cartoon images labelling and astrocyte cell detection and count. Astrocyte cells play a key role as a brain defense mechanism. Recent studies indicate that they have a special role in cognition and addictions thus highlighting the significance of this largely overlooked class of astroglia cells.</p>\n<p>&nbsp;</p>\n<p>A significant part of the theoretical work of the project was provided a new and simple method for the construction of novel families of digital filters in any number of dimensions that can be used for the iterative analysis of 2D, 3D images or multidimensional datasets. These new filters can be designed to capture the shape of structures in those images and their sensitivity is directed toward certain ?angular? sectors of the space. We choose them in a way that all angular sectors of the space are covered as if we direct a telescope to any direction in the 3D space. For any angular sector we may use more than one filter to capture shape properties of structures present in an image. Moreover, the design affords numerical stability and speed in the analysis and the reconstruction (the reversal of the analysis process) of an input image.&nbsp; One of the surprising discoveries of our project resulted from the use of such digital filters in low level processing of input images by a new class of artificial neural networks designed to mimic the action of human visual system at the retinal level. We successfully used these neural networks for the automated analysis of structures on the ground visible in satellite images.</p>\n<p>&nbsp;</p>\n<p>The findings of our work have added social value because they contribute to the development of quantitative analysis of analysis tools that can facilitate a better understanding of mechanisms underlying the insurgence of brain disorders including neurodegeneration and addictions. The image and video clarifier we studied seems to be able to find its way in underwater camera inspections of distressed vessels in coastal waters where visibility is lower than in the open sea. Moving such vessels without accurately assessing the integrity of their hulls may result in environmental damages and even total losses.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Last but not least, this award offered financial support and training opportunities for seven graduate students and three post-doctoral associates, out of which two and two respectively from each rank were female.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/13/2022<br>\n\t\t\t\t\tModified by: Emanuel&nbsp;I&nbsp;Papadakis</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1720487/1720487_10504622_1670953782396_Astro_figure1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1720487/1720487_10504622_1670953782396_Astro_figure1--rgov-800width.jpg\" title=\"Astrocyte segmentation with the GESU deep neural network\"><img src=\"/por/images/Reports/POR/2022/1720487/1720487_10504622_1670953782396_Astro_figure1--rgov-66x44.jpg\" alt=\"Astrocyte segmentation with the GESU deep neural network\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This is a result of the earlier work with the support of this award. Astrocyte cells are important glial cells in the human brain. Originally thought to be a defensive mechanism now seem to play a role in cognitive functions. Here we show schematically how we separate individual cells in images.</div>\n<div class=\"imageCredit\">Demetrio Labate and Emanuel Papadakis</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Emanuel&nbsp;I&nbsp;Papadakis</div>\n<div class=\"imageTitle\">Astrocyte segmentation with the GESU deep neural network</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1720487/1720487_10504622_1670956551712_GT--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1720487/1720487_10504622_1670956551712_GT--rgov-800width.jpg\" title=\"Astrocyte cells under a laser microscope\"><img src=\"/por/images/Reports/POR/2022/1720487/1720487_10504622_1670956551712_GT--rgov-66x44.jpg\" alt=\"Astrocyte cells under a laser microscope\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The astrocyte cells in this image section are marked by by blue rectangles. In this project we worked to develop methods for the accurate automated detection and count of these cells. This is a first but fundamental step in the study of the populations and evolution of astrocytes.</div>\n<div class=\"imageCredit\">https://data.broadinstitute.org/bbbc/image\\_sets.html</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Emanuel&nbsp;I&nbsp;Papadakis</div>\n<div class=\"imageTitle\">Astrocyte cells under a laser microscope</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1720487/1720487_10504622_1670960390968_Picture1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1720487/1720487_10504622_1670960390968_Picture1--rgov-800width.jpg\" title=\"Flying through the clouds\"><img src=\"/por/images/Reports/POR/2022/1720487/1720487_10504622_1670960390968_Picture1--rgov-66x44.jpg\" alt=\"Flying through the clouds\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Snapshot from a real-time video clarifier. At 4K resolution the video clarifier is still experimental. The original picture is shown on the left panel. The right panel is more clear as the effect of the cloud cover opacity is partially removed.</div>\n<div class=\"imageCredit\">Lolaark Vision Inc</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">Emanuel&nbsp;I&nbsp;Papadakis</div>\n<div class=\"imageTitle\">Flying through the clouds</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe work supported by this award was motivated by two problems arising from neuroscience imaging and the elimination of the effects of illumination and visibility variations in the analysis of natural images at a variety of spectra associated with natural or artificial light.\n\nNeuroscience imaging is a broad and modern area of research rapidly growing due to technological advances in high-resolution fluorescent microscopy that enable the visualization of neurons and their subcellular compartments both in vivo and in vitro. Specifically, our ongoing and future work in neuroscience imaging aims at developing a new generation of quantitative tools to facilitate the modeling of fundamental biological processes related to neuronal activity at cell level.\n\nImage formation is the mechanism light is emitted from objects in a scene of interest, e.g., a landscape or a selfie, and captured by a camera sensor clearly affects the quality and quantity of details captured in an image. Various factors between an object and a camera may affect image formation, e.g., the presence of smoke or precipitation, uneven or weak illumination of a scene will affect the luminous energy reaching the camera sensor. A representative example of such an image is a landscape enveloped by haze or light fog.\n\nWith the support of this award, we developed theoretical models for image formation under the combined effect of uneven or weak illumination and low visibility conditions. Moreover, we investigated how deep neural network object detectors and classifiers can be used to identify the presence of various objects in an image or video and how to label them.  Special attention was given to object detection with inputs from several imaging applications: Hyperspectral satellite images used for vegetation and human structures classification, cartoon images labelling and astrocyte cell detection and count. Astrocyte cells play a key role as a brain defense mechanism. Recent studies indicate that they have a special role in cognition and addictions thus highlighting the significance of this largely overlooked class of astroglia cells.\n\n \n\nA significant part of the theoretical work of the project was provided a new and simple method for the construction of novel families of digital filters in any number of dimensions that can be used for the iterative analysis of 2D, 3D images or multidimensional datasets. These new filters can be designed to capture the shape of structures in those images and their sensitivity is directed toward certain ?angular? sectors of the space. We choose them in a way that all angular sectors of the space are covered as if we direct a telescope to any direction in the 3D space. For any angular sector we may use more than one filter to capture shape properties of structures present in an image. Moreover, the design affords numerical stability and speed in the analysis and the reconstruction (the reversal of the analysis process) of an input image.  One of the surprising discoveries of our project resulted from the use of such digital filters in low level processing of input images by a new class of artificial neural networks designed to mimic the action of human visual system at the retinal level. We successfully used these neural networks for the automated analysis of structures on the ground visible in satellite images.\n\n \n\nThe findings of our work have added social value because they contribute to the development of quantitative analysis of analysis tools that can facilitate a better understanding of mechanisms underlying the insurgence of brain disorders including neurodegeneration and addictions. The image and video clarifier we studied seems to be able to find its way in underwater camera inspections of distressed vessels in coastal waters where visibility is lower than in the open sea. Moving such vessels without accurately assessing the integrity of their hulls may result in environmental damages and even total losses. \n\n \n\nLast but not least, this award offered financial support and training opportunities for seven graduate students and three post-doctoral associates, out of which two and two respectively from each rank were female.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/13/2022\n\n\t\t\t\t\tSubmitted by: Emanuel I Papadakis"
 }
}