{
 "awd_id": "1651843",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Deep Robotic Learning with Large Datasets: Toward Simple and Reliable Lifelong Learning Frameworks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Juan Wachs",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 549998.0,
 "awd_amount": 549998.0,
 "awd_min_amd_letter_date": "2017-03-02",
 "awd_max_amd_letter_date": "2020-07-23",
 "awd_abstract_narration": "Learning robot behaviors from large data sets is an important way to make robots more capable and reliable.  This project will develop algorithms for autonomous robotic skill learning that can easily be used by novice hobbyists with low-cost robots. If deployed widely, such an approach could be used to gather a large number of robotic motions, which can be combined to improve the robot's skills.  Availability of large datasets has proven critical in machine learning application areas, from computer vision to speech recognition, and the ability to collect a large amount of robotic interaction data would substantially increase the capabilities of learning-based robotic systems. Since the approach will be designed for untrained users, it also doubles as an effective tool for robotics education.\r\n\r\nDeep learning has emerged as a powerful technique for taming the complexity of the real world. The success of deep learning depends on the availability of large datasets, which traditionally have been difficult to obtain for robotic learning. This project will focus on deep learning algorithms that can be used for effective and reliable robotic skill learning, generating intelligent actions directly from raw sensory input, with an eye towards enabling widespread deployment for large-scale data collection. To that end, the proposed research will aim to: (1) devise reliable and robust real-world robotic learning algorithms that can collect experience without human oversight or intervention; (2) build algorithms centered around transfer learning, whereby experience from prior tasks can be used to inform dramatically faster learning of new skills with potentially different robotic platforms; and (3) devise algorithms that can effectively control heterogeneous, low-cost, imprecise robots, so as to facilitate widespread deployment and the project's educational mission.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sergey",
   "pi_last_name": "Levine",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sergey Levine",
   "pi_email_addr": "sergey.levine@gmail.com",
   "nsf_id": "000705338",
   "pi_start_date": "2017-03-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947201776",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 112716.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 114595.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 218745.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 103942.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The aims of this project were focused on developing algorithms for robotic learning that could allow low-cost robotic arms to autonomously learn a variety of manipulation skills directly in the real world, with a minimum amount of human effort and engineering for each new skill the robot needs to learn. To this end, our research on this project has focused on fundamental advances in machine learning algorithms as well as experimental robotics research. Particularly relevant highlights of robotic learning systems and algorithms that resulted from this research include:</p>\n<p>MTRF: a robotic learning system that could enable fully autonomous real-world training for a multi-fingered hand to learn complex in-hand manipulation skills. In this system, a robotic hand would simultaneously learn multiple different skills to not only perform a particular task (e.g., dexterously reorienting an object in the hand), but also for supporting the learning of this task (e.g., picking up the object if the hand dropped it between trials). In our experiments, MTRF could enable a robotic hand to train for up to 80 hours completely autonomously, without human intervention (see Figure 1).</p>\n<p>Skew-Fit: a self-supervised robotic learning system where the robot would autonomously propose goals for itself to explore a new environment, directly by generating candidate ?goal images? that it believes it can reach. Skew-Fit resulted in significant quantitative improvements over state-of-the-art goal-conditioned learning methods at the time of publication, and enabled a real-world robotic arm to fully autonomously learn to open a door using raw image observations, without ever being told that the door opening task was relevant and without any manually specified objective function (see Figure 2).</p>\n<p>RoboNet and Bridge Data: We collected two large datasets to support our research on generalizable learning of robotic manipulation with low-cost robotic arms. These datasets are specifically intended to facilitate generalization, by providing a multi-task, multi-environment, and multi-robot database of manipulation behaviors that can be used to pretrain robotic control policies that could then be finetuned to individual downstream skills. RoboNet consists of data from 7 different robotic platforms, but with largely random motions, while Bridge Data is a more focused dataset with a single low-cost robotic arm, but with over 70 tasks, 7000+ demonstration trajectories, and about a dozen environments (see Figure 3).</p>\n<p>ARIEL: a system for robotic learning that can use prior data to initialize both forward and backward controllers for a given task: the forward controller attempts to perform the task, while the backward controller puts the environment back the way it was so that the robot can attempt again. Both directions are initialized from diverse prior data to give the robot a strong starting point, and are then trained simultaneously through autonomous real-world interaction (see Figure 4).</p>\n<p>FLAP: a system for robotic learning that integrates model-free learning and model-based planning, where a model-free goal-reaching policy is trained on the Bridge Data dataset described above, and then a predictive model is trained to predict the outcomes of triggering this goal-conditioned policy. The higher-level model is then used to plan temporally extended skills (e.g., simple ?cooking-inspired? behaviors, like putting objects in a pot, moving the pot, turning on the range, etc.). FLAP provides a general recipe to utilize large diverse robotics datasets to bootstrap learning enabled skills and then utilize them for temporally extended tasks (see Figure 5).</p>\n<p>Together, these advances have brought us significantly closer to robotic systems that can be initialized from broad multi-task datasets, and then trained autonomously in the real world to acquire new skills that can be defined by non-expert users (e.g., through examples). Our final evaluations for many of these systems use low-cost robotic arms (with costs around $3000 USD), making the results significantly more accessible and reproducible than more conventional robotics research, which tends to use expensive high-end industrial arms.</p>\n<p>The broader impacts of this project include the above-mentioned efforts to improve accessibility of robotics research through the use of lower-cost hardware, an undergraduate mentoring program aimed at undergraduates from underrepresented backgrounds, extensive efforts at facilitating undergraduate research in robotics, and teaching activities that include a publicly available deep reinforcement learning course that has been viewed online by thousands of learners.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/07/2022<br>\n\t\t\t\t\tModified by: Sergey&nbsp;Levine</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918303141_figure1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918303141_figure1--rgov-800width.jpg\" title=\"Figure 1: MTRF\"><img src=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918303141_figure1--rgov-66x44.jpg\" alt=\"Figure 1: MTRF\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A multi-task learning system enables a robotic hand to autonomously learn complex in-hand manipulation skills</div>\n<div class=\"imageCredit\">Sergey Levine</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Sergey&nbsp;Levine</div>\n<div class=\"imageTitle\">Figure 1: MTRF</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918385526_figure2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918385526_figure2--rgov-800width.jpg\" title=\"Figure 2: Skew-Fit\"><img src=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918385526_figure2--rgov-66x44.jpg\" alt=\"Figure 2: Skew-Fit\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The Skew-Fit system enables a robot to propose its own goals to practice. Here, the robot was placed in front of a door, and autonomously learned to open it without any human-specified objective function.</div>\n<div class=\"imageCredit\">Sergey Levine, Murtaza Dalal, Vitchyr Pong</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Sergey&nbsp;Levine</div>\n<div class=\"imageTitle\">Figure 2: Skew-Fit</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918455193_figure3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918455193_figure3--rgov-800width.jpg\" title=\"Figure 3: RoboNet\"><img src=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918455193_figure3--rgov-66x44.jpg\" alt=\"Figure 3: RoboNet\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The RoboNet dataset contains thousands of trials from 7 different robots in numerous environments, providing a large dataset for initializing training of downstream robotics tasks.</div>\n<div class=\"imageCredit\">Frederik Ebert</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Sergey&nbsp;Levine</div>\n<div class=\"imageTitle\">Figure 3: RoboNet</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918521267_figure4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918521267_figure4--rgov-800width.jpg\" title=\"Figure 4: ARIEL\"><img src=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918521267_figure4--rgov-66x44.jpg\" alt=\"Figure 4: ARIEL\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The ARIEL system enables a robot to autonomously practice a new skill by initializing both a \"forward\" and \"backward\" controller from a diverse previously collected dataset.</div>\n<div class=\"imageCredit\">Homer Walke</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Sergey&nbsp;Levine</div>\n<div class=\"imageTitle\">Figure 4: ARIEL</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918581719_figure5--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918581719_figure5--rgov-800width.jpg\" title=\"Figure 5: FLAP\"><img src=\"/por/images/Reports/POR/2022/1651843/1651843_10475484_1659918581719_figure5--rgov-66x44.jpg\" alt=\"Figure 5: FLAP\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The FLAP system uses the Bridge Data dataset to train a goal-conditioned policy, which can then be utilized by a higher level planner to perform temporally extended multi-stage tasks using a low-cost robotic arm</div>\n<div class=\"imageCredit\">Kuan Fang</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Sergey&nbsp;Levine</div>\n<div class=\"imageTitle\">Figure 5: FLAP</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe aims of this project were focused on developing algorithms for robotic learning that could allow low-cost robotic arms to autonomously learn a variety of manipulation skills directly in the real world, with a minimum amount of human effort and engineering for each new skill the robot needs to learn. To this end, our research on this project has focused on fundamental advances in machine learning algorithms as well as experimental robotics research. Particularly relevant highlights of robotic learning systems and algorithms that resulted from this research include:\n\nMTRF: a robotic learning system that could enable fully autonomous real-world training for a multi-fingered hand to learn complex in-hand manipulation skills. In this system, a robotic hand would simultaneously learn multiple different skills to not only perform a particular task (e.g., dexterously reorienting an object in the hand), but also for supporting the learning of this task (e.g., picking up the object if the hand dropped it between trials). In our experiments, MTRF could enable a robotic hand to train for up to 80 hours completely autonomously, without human intervention (see Figure 1).\n\nSkew-Fit: a self-supervised robotic learning system where the robot would autonomously propose goals for itself to explore a new environment, directly by generating candidate ?goal images? that it believes it can reach. Skew-Fit resulted in significant quantitative improvements over state-of-the-art goal-conditioned learning methods at the time of publication, and enabled a real-world robotic arm to fully autonomously learn to open a door using raw image observations, without ever being told that the door opening task was relevant and without any manually specified objective function (see Figure 2).\n\nRoboNet and Bridge Data: We collected two large datasets to support our research on generalizable learning of robotic manipulation with low-cost robotic arms. These datasets are specifically intended to facilitate generalization, by providing a multi-task, multi-environment, and multi-robot database of manipulation behaviors that can be used to pretrain robotic control policies that could then be finetuned to individual downstream skills. RoboNet consists of data from 7 different robotic platforms, but with largely random motions, while Bridge Data is a more focused dataset with a single low-cost robotic arm, but with over 70 tasks, 7000+ demonstration trajectories, and about a dozen environments (see Figure 3).\n\nARIEL: a system for robotic learning that can use prior data to initialize both forward and backward controllers for a given task: the forward controller attempts to perform the task, while the backward controller puts the environment back the way it was so that the robot can attempt again. Both directions are initialized from diverse prior data to give the robot a strong starting point, and are then trained simultaneously through autonomous real-world interaction (see Figure 4).\n\nFLAP: a system for robotic learning that integrates model-free learning and model-based planning, where a model-free goal-reaching policy is trained on the Bridge Data dataset described above, and then a predictive model is trained to predict the outcomes of triggering this goal-conditioned policy. The higher-level model is then used to plan temporally extended skills (e.g., simple ?cooking-inspired? behaviors, like putting objects in a pot, moving the pot, turning on the range, etc.). FLAP provides a general recipe to utilize large diverse robotics datasets to bootstrap learning enabled skills and then utilize them for temporally extended tasks (see Figure 5).\n\nTogether, these advances have brought us significantly closer to robotic systems that can be initialized from broad multi-task datasets, and then trained autonomously in the real world to acquire new skills that can be defined by non-expert users (e.g., through examples). Our final evaluations for many of these systems use low-cost robotic arms (with costs around $3000 USD), making the results significantly more accessible and reproducible than more conventional robotics research, which tends to use expensive high-end industrial arms.\n\nThe broader impacts of this project include the above-mentioned efforts to improve accessibility of robotics research through the use of lower-cost hardware, an undergraduate mentoring program aimed at undergraduates from underrepresented backgrounds, extensive efforts at facilitating undergraduate research in robotics, and teaching activities that include a publicly available deep reinforcement learning course that has been viewed online by thousands of learners.\n\n \n\n\t\t\t\t\tLast Modified: 08/07/2022\n\n\t\t\t\t\tSubmitted by: Sergey Levine"
 }
}