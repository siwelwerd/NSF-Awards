{
 "awd_id": "1730181",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CI-New: Collaborative Research: An Infrastructure that Combines Eye Tracking into Integrated Development Environments to Study Software Development and Program Comprehension",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2017-06-01",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 290610.0,
 "awd_amount": 320610.0,
 "awd_min_amd_letter_date": "2017-05-10",
 "awd_max_amd_letter_date": "2020-03-11",
 "awd_abstract_narration": "The software engineering research community is now using eye trackers to study how developers comprehend and develop software. Unfortunately, eye trackers have limited features and functionality, which need to be augmented to effectively study the behavior of software developers performing programming and contextual tasks. Eye tracking devices only allow scientists to study fixed, limited-size, stimuli (e.g., block of text or image). Studies normally require that the text fit on one screen (or page). There is very limited or no support to allow such things as scrolling through longer documents or switching back and forth between documents on a computer. While this is sufficient to study how people read one line of code or a sentence it is wholly inadequate to study how programmers attempt to comprehend or develop a large software system.\r\n\r\nThe objective of the research is to address this limitation and drastically expand the types and size of stimuli that can be studied using an eye tracking device. In addition to supporting source code artifacts, it also supports artifacts such as stack overflow documents, bug reports, testing documents, and requirements.\u00a0This enables software engineering researchers to conduct large-scale realistic eye-tracking studies seamlessly within a software development environment.  This eye-tracking-enabled infrastructure for studying program comprehension has the potential to transform the way lab studies and field studies are designed and executed as it advances the state of the art in conducting eye tracking studies in software engineering.  The infrastructure directly impacts society by paving the way to further improve IDEs to support the developer in various software engineering tasks through the various research projects it facilitates. The immediate impact is to facilitate controlled laboratory and field environments for a community of researchers. The research may lead to software development tools that incorporate eye-tracking as part of a more productive programming environment leading to higher quality software.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jonathan",
   "pi_last_name": "Maletic",
   "pi_mid_init": "I",
   "pi_sufx_name": "",
   "pi_full_name": "Jonathan I Maletic",
   "pi_email_addr": "jmaletic@kent.edu",
   "nsf_id": "000331945",
   "pi_start_date": "2017-05-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Kent State University",
  "inst_street_address": "1500 HORNING RD",
  "inst_street_address_2": "",
  "inst_city_name": "KENT",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "3306722070",
  "inst_zip_code": "442420001",
  "inst_country_name": "United States",
  "cong_dist_code": "14",
  "st_cong_dist_code": "OH14",
  "org_lgl_bus_name": "KENT STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "KXNVA7JCC5K6"
 },
 "perf_inst": {
  "perf_inst_name": "Kent State University",
  "perf_str_addr": "",
  "perf_city_name": "Kent",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "442420001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "14",
  "perf_st_cong_dist": "OH14",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 290610.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 10000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 10000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 10000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Overview</strong></p>\n<p>Eye trackers are a critical research tool in understanding how people comprehend visual stimuli. Eye movements are essential to cognitive processes because they focus a person?s visual attention on the parts of a visible stimulus that are processed by the brain. The project focus is on how eye tracking can help researchers investigate how software developers perform tasks in software development environments with the goal of improving developer support for those tasks. For a fixed stimulus such as an image that?s the same size as the screen mapping the eye to the location a person is looking at is relatively straightforward geometry.&nbsp; Changes to the stimulus (screen), such as scrolling a large file or context switching (opening multiple files), complicate the problem because the stimulus is constantly changing. Commercial eye tracking software provides limited support for scrolling and no support for context switching.&nbsp; Although a fixed sized stimulus is sufficient to study a few lines of source code it is wholly inadequate to study how programmers comprehend an entire software system as they do in the industry. This project addresses this limitation and drastically expands the types and size of stimuli that can be studied using an eye tracking device. The various types of artifacts supported are source code, Stack Overflow documents, bug reports, documentation, and requirements. This will enable software engineering researchers to conduct large-scale realistic eye-tracking studies seamlessly within a software development environment.</p>\n<p><strong>Intellectual Merit</strong></p>\n<p>The project developed a new infrastructure namely, iTrace, that makes eye tracking accessible within a variety of existing software development environments and the Chrome browser. The theoretical foundations offered by eye tracking technology were investigated and practical solutions that maintain the accuracy and validity of the gaze data were delivered. In addition, feasible use of eye trackers at various speeds were also tested and a novel solution was engineered to support high-speed trackers above 60 Hz and beyond without compromising gaze mapping to the correct screen element being viewed. iTrace also comes packaged with a post processing Toolkit that consolidates all the data into a lightweight database where one can run event detection algorithms, query the data, and export the data for further statistical analysis. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>\n<p>iTrace directly enables new research in several software engineering research areas such as program comprehension, code summarization, code review, and code recommendation systems.&nbsp; The contributions of this project are a forward step towards making eye tracking a novel method in identifying software developer?s fine-grained navigation and viewing behavior while they work on realistic software tasks. This project brings together eye tracking and software engineering research to advance the state of the art in conducting eye tracking studies in software engineering.</p>\n<p><strong>Broader Impacts</strong></p>\n<p>iTrace transforms the way lab studies and field studies are designed and executed by advancing the state of the art in conducting eye tracking studies in software engineering.&nbsp; It eliminates the tedious tasks by making the interface seamless from the user?s perspective.&nbsp; With recorded eye gaze data, researchers can determine exactly what a developer was viewing and how they read and navigate the code and other software artifacts.&nbsp; This behavior can greatly help in devising better tools, which in turn helps in writing good quality software. A new research paradigm in software engineering has emerged from this infrastructure which transforms how eye tracking studies are conducted thereby increasing the external validity of the results because they are based on realistic settings and merge with already existing developer environments.&nbsp; Besides connecting with an eye tracker and a quick calibration, the developer?s environment does not change as everything is implicitly collected behind the scenes while they work.&nbsp;&nbsp; A growing number of education, software engineering, and psychology researchers are using iTrace in related eye tracking studies.&nbsp; Additionally, this same technology is directly generalizable to other types of environments such as spreadsheets, books, and legal documents that seek to study and understand human reading and navigation behavior.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/15/2022<br>\n\t\t\t\t\tModified by: Jonathan&nbsp;I&nbsp;Maletic</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1730181/1730181_10487088_1660590595170_iTrace--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1730181/1730181_10487088_1660590595170_iTrace--rgov-800width.jpg\" title=\"iTrace\"><img src=\"/por/images/Reports/POR/2022/1730181/1730181_10487088_1660590595170_iTrace--rgov-66x44.jpg\" alt=\"iTrace\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Overview of iTrace architecture</div>\n<div class=\"imageCredit\">Jonathan I Maletic</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Jonathan&nbsp;I&nbsp;Maletic</div>\n<div class=\"imageTitle\">iTrace</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nOverview\n\nEye trackers are a critical research tool in understanding how people comprehend visual stimuli. Eye movements are essential to cognitive processes because they focus a person?s visual attention on the parts of a visible stimulus that are processed by the brain. The project focus is on how eye tracking can help researchers investigate how software developers perform tasks in software development environments with the goal of improving developer support for those tasks. For a fixed stimulus such as an image that?s the same size as the screen mapping the eye to the location a person is looking at is relatively straightforward geometry.  Changes to the stimulus (screen), such as scrolling a large file or context switching (opening multiple files), complicate the problem because the stimulus is constantly changing. Commercial eye tracking software provides limited support for scrolling and no support for context switching.  Although a fixed sized stimulus is sufficient to study a few lines of source code it is wholly inadequate to study how programmers comprehend an entire software system as they do in the industry. This project addresses this limitation and drastically expands the types and size of stimuli that can be studied using an eye tracking device. The various types of artifacts supported are source code, Stack Overflow documents, bug reports, documentation, and requirements. This will enable software engineering researchers to conduct large-scale realistic eye-tracking studies seamlessly within a software development environment.\n\nIntellectual Merit\n\nThe project developed a new infrastructure namely, iTrace, that makes eye tracking accessible within a variety of existing software development environments and the Chrome browser. The theoretical foundations offered by eye tracking technology were investigated and practical solutions that maintain the accuracy and validity of the gaze data were delivered. In addition, feasible use of eye trackers at various speeds were also tested and a novel solution was engineered to support high-speed trackers above 60 Hz and beyond without compromising gaze mapping to the correct screen element being viewed. iTrace also comes packaged with a post processing Toolkit that consolidates all the data into a lightweight database where one can run event detection algorithms, query the data, and export the data for further statistical analysis.      \n\niTrace directly enables new research in several software engineering research areas such as program comprehension, code summarization, code review, and code recommendation systems.  The contributions of this project are a forward step towards making eye tracking a novel method in identifying software developer?s fine-grained navigation and viewing behavior while they work on realistic software tasks. This project brings together eye tracking and software engineering research to advance the state of the art in conducting eye tracking studies in software engineering.\n\nBroader Impacts\n\niTrace transforms the way lab studies and field studies are designed and executed by advancing the state of the art in conducting eye tracking studies in software engineering.  It eliminates the tedious tasks by making the interface seamless from the user?s perspective.  With recorded eye gaze data, researchers can determine exactly what a developer was viewing and how they read and navigate the code and other software artifacts.  This behavior can greatly help in devising better tools, which in turn helps in writing good quality software. A new research paradigm in software engineering has emerged from this infrastructure which transforms how eye tracking studies are conducted thereby increasing the external validity of the results because they are based on realistic settings and merge with already existing developer environments.  Besides connecting with an eye tracker and a quick calibration, the developer?s environment does not change as everything is implicitly collected behind the scenes while they work.   A growing number of education, software engineering, and psychology researchers are using iTrace in related eye tracking studies.  Additionally, this same technology is directly generalizable to other types of environments such as spreadsheets, books, and legal documents that seek to study and understand human reading and navigation behavior.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 08/15/2022\n\n\t\t\t\t\tSubmitted by: Jonathan I Maletic"
 }
}