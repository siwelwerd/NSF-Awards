{
 "awd_id": "1718221",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Novel Generative Models for High-Diversity Visual Speculation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2017-08-17",
 "awd_max_amd_letter_date": "2017-08-17",
 "awd_abstract_narration": "The amount of available data and its dimensionality is soaring, and by now, images are one of the most widely used modalities for sharing impressions. This makes easy-to-use image editing capabilities increasingly important. However present day editing techniques are either very simple or designed for expert users which have a detailed understanding of image properties. This project contributes to an understanding of easy to use algorithms for complex image editing, which we refer to as visual speculation. Examples include attribute transformation (change a scene recorded in summer to what it could have looked like during winter), colorization (producing a color image from a monochrome input), and reshading (changing the illumination of the image). These tasks have numerous applications by producing controllable and photorealistic images for different purposes such as virtual/augmented reality content generation. The project integrated with education through curriculum development and supporting graduate/undergraduate student research.\r\n\r\n\r\nThis research studies methods for visual speculation, i.e., applying complex image editing tasks which modify existing pictures to fit the users? desire while looking real. Examples include: attribute transformation, colorization, and reshading. In each case, solutions are widely ambiguous and good methods generate a diverse range of plausible solutions while offering control to the user. These requirements pose challenges for existing methods which struggle to provide diversity while retaining control. For example, straightforward conditioning based on control variables causes artifacts because the amount of data per instance is no longer sufficient. To alleviate those issues, the proposed work develops high-diversity, high-quality generation models by augmenting state-of-the-art deep generative machinery with image representations that expose data sharing opportunities. The insights obtained from this work result in image editing capabilities that provide high-level control mechanisms.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alexander",
   "pi_last_name": "Schwing",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alexander Schwing",
   "pi_email_addr": "aschwing@illinois.edu",
   "nsf_id": "000734749",
   "pi_start_date": "2017-08-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Forsyth",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "David A Forsyth",
   "pi_email_addr": "daf@cs.uiuc.edu",
   "nsf_id": "000391155",
   "pi_start_date": "2017-08-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Svetlana",
   "pi_last_name": "Lazebnik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Svetlana Lazebnik",
   "pi_email_addr": "slazebni@illinois.edu",
   "nsf_id": "000298493",
   "pi_start_date": "2017-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618207473",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Computer vision has always been concerned with 'full scene understanding.' Quoting Richard Feynman's \"What I cannot create, I do not understand,\" we argued in our proposal written in 2016, that automatic and data-driven modeling of the generation process of images, i.e., image generation, is one of the targets in computer vision and should be advanced significantly within 5 years.</p>\n<p>During the time of this research project (2017 to 2022), our and other researcher contributions have significantly advanced the field of image generation. While image generation was still at its infancy in 2017, and we as well as others were barely able to generate images at a resolution of 128x128 showing single category objects (e.g., faces, birds, or flowers), results of image generation now (2022/2023) are increasingly difficult to differentiate from real-world images. To the surprise of artists, an AI-generated image even won an art prize in 2022 [1].</p>\n<p>Present-day image generation can modify attributes of an image. For instance, given an image illustrating a scene captured in summer, image generation techniques can modify the image to look like it was captured in winter. We described such an application in the introduction of the proposal, and we were able to develop and demonstrate such a method in 2022. Some results are illustrated in the enclosed Fig. 1.</p>\n<p>Present-day image generation methods are now also able to learn a 3D understanding of the scene from only 2D images. For instance, given a reasonably large set of images illustrating human faces, current image generation methods recover a reasonable 3D face geometry without ever having been told about the 3D face geometry. We developed and demonstrated such a method in 2022. Some results are illustrated in the enclosed Fig. 2.</p>\n<p>Present-day image generation techniques can now also create high-resolution images from text queries. In 2017, this technology was at its infancy and the generated results were confinded to individual object categories like birds or flowers. Given a description of the desired content of an image about any object category, recently (2022) developed methods produce images that often reflect the description surprisingly accurately.</p>\n<p>The developed methods form the foundations for many exciting applications that can be used to great benefit of our society. However, we also want to caution that these techniques can be misused to fabricate misleading yet convincing evidence. We encourage everyone to remain informed about the progress of this field beyond the conducted research as these technique will be developed further and form the bases of the excitement regarding generative AI in early 2023.</p>\n<p>References:</p>\n<p>[1]&nbsp;<a href=\"https://www.nytimes.com/2022/09/02/technology/ai-artificial-intelligence-artists.html\">https://www.nytimes.com/2022/09/02/technology/ai-artificial-intelligence-artists.html</a></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/12/2023<br>\n\t\t\t\t\tModified by: Alexander&nbsp;Schwing</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1718221/1718221_10515800_1676221154462_Fig1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1718221/1718221_10515800_1676221154462_Fig1--rgov-800width.jpg\" title=\"Transforming a given image to depict more clouds or more snow\"><img src=\"/por/images/Reports/POR/2023/1718221/1718221_10515800_1676221154462_Fig1--rgov-66x44.jpg\" alt=\"Transforming a given image to depict more clouds or more snow\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Results of our image transformation model which performs high-level edits to add snow or clouds to a given image.</div>\n<div class=\"imageCredit\">https://arxiv.org/abs/2102.01187</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Alexander&nbsp;Schwing</div>\n<div class=\"imageTitle\">Transforming a given image to depict more clouds or more snow</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1718221/1718221_10515800_1676221370738_Fig2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1718221/1718221_10515800_1676221370738_Fig2--rgov-800width.jpg\" title=\"3D-aware and view-consistent image generation\"><img src=\"/por/images/Reports/POR/2023/1718221/1718221_10515800_1676221370738_Fig2--rgov-66x44.jpg\" alt=\"3D-aware and view-consistent image generation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Results of our method to generate 3D aware images that can be rendered in a view-consistent manner from different view-points.</div>\n<div class=\"imageCredit\">https://arxiv.org/abs/2207.10642</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Alexander&nbsp;Schwing</div>\n<div class=\"imageTitle\">3D-aware and view-consistent image generation</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nComputer vision has always been concerned with 'full scene understanding.' Quoting Richard Feynman's \"What I cannot create, I do not understand,\" we argued in our proposal written in 2016, that automatic and data-driven modeling of the generation process of images, i.e., image generation, is one of the targets in computer vision and should be advanced significantly within 5 years.\n\nDuring the time of this research project (2017 to 2022), our and other researcher contributions have significantly advanced the field of image generation. While image generation was still at its infancy in 2017, and we as well as others were barely able to generate images at a resolution of 128x128 showing single category objects (e.g., faces, birds, or flowers), results of image generation now (2022/2023) are increasingly difficult to differentiate from real-world images. To the surprise of artists, an AI-generated image even won an art prize in 2022 [1].\n\nPresent-day image generation can modify attributes of an image. For instance, given an image illustrating a scene captured in summer, image generation techniques can modify the image to look like it was captured in winter. We described such an application in the introduction of the proposal, and we were able to develop and demonstrate such a method in 2022. Some results are illustrated in the enclosed Fig. 1.\n\nPresent-day image generation methods are now also able to learn a 3D understanding of the scene from only 2D images. For instance, given a reasonably large set of images illustrating human faces, current image generation methods recover a reasonable 3D face geometry without ever having been told about the 3D face geometry. We developed and demonstrated such a method in 2022. Some results are illustrated in the enclosed Fig. 2.\n\nPresent-day image generation techniques can now also create high-resolution images from text queries. In 2017, this technology was at its infancy and the generated results were confinded to individual object categories like birds or flowers. Given a description of the desired content of an image about any object category, recently (2022) developed methods produce images that often reflect the description surprisingly accurately.\n\nThe developed methods form the foundations for many exciting applications that can be used to great benefit of our society. However, we also want to caution that these techniques can be misused to fabricate misleading yet convincing evidence. We encourage everyone to remain informed about the progress of this field beyond the conducted research as these technique will be developed further and form the bases of the excitement regarding generative AI in early 2023.\n\nReferences:\n\n[1] https://www.nytimes.com/2022/09/02/technology/ai-artificial-intelligence-artists.html\n\n \n\n\t\t\t\t\tLast Modified: 02/12/2023\n\n\t\t\t\t\tSubmitted by: Alexander Schwing"
 }
}