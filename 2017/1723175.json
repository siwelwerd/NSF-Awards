{
 "awd_id": "1723175",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Computational Methods for Hierarchical Manifold Learning",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Christopher Stark",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 329954.0,
 "awd_amount": 329954.0,
 "awd_min_amd_letter_date": "2017-06-13",
 "awd_max_amd_letter_date": "2017-06-13",
 "awd_abstract_narration": "The enormous practical success of deep learning warrants a clear and concise mathematical explanation. Although the components of a neural network, and the rules for propagation of information through the layers, are extremely simple, there is to date a lack of a corresponding deep understanding of the roles of the various mechanisms involved. Second, there is a lack of transparency: While a given set of network weights may fit scientific or engineering data in-sample and even generalize well out-of-sample, using a neural net to explain the data or the system producing the data is usually very difficult or impossible.  In this project, the PI will leverage recent progress in mathematical methods from applied and computational harmonic analysis to develop a hierarchical algorithm, based on manifold learning, to replicate the strikingly successful properties of deep learning while adding improved accuracy, adaptability to data, smoothness priors, and transparency.\r\n\r\nA sequence of computational projects is planned to develop a hierarchical algorithm for deep learning, based on representing manifolds by the Laplace-Beltrami operator. Proposed work supports the construction of a complete algorithm that uses layers of manifold learning kernel methods to represent data in a deep manifold learning infrastructure.  The development of the learning algorithm consists of three parts: (1) the construction of a hierarchical manifold learning architecture, using eigenfunctions of the Laplace-Beltrami operator to represent data, and replicating the sharing and pooling features of neural networks, (2) building innovative algorithms for the purpose of optimizing the solution to identification problems, and (3) development of resampling methods to handle large data sets.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "Sauer",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy D Sauer",
   "pi_email_addr": "tsauer@gmu.edu",
   "nsf_id": "000400901",
   "pi_start_date": "2017-06-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "George Mason University",
  "inst_street_address": "4400 UNIVERSITY DR",
  "inst_street_address_2": "",
  "inst_city_name": "FAIRFAX",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "7039932295",
  "inst_zip_code": "220304422",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "VA11",
  "org_lgl_bus_name": "GEORGE MASON UNIVERSITY",
  "org_prnt_uei_num": "H4NRWLFCDF43",
  "org_uei_num": "EADLFP7Z72E5"
 },
 "perf_inst": {
  "perf_inst_name": "George Mason University",
  "perf_str_addr": "4400 University Drive, Mail Stop",
  "perf_city_name": "Fairfax",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "220304422",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "VA11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126600",
   "pgm_ele_name": "APPLIED MATHEMATICS"
  },
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  },
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 329954.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The research project developed manifold learning techniques and dynamical systems concepts that will be essential to build the next generation of data analysis, including innovations in geometry, topology and deep learning methods. Research efforts were carried out on a number of areas, including (1) topological data analysis, involving extensions of the Laplacian eigenmap and diffusion map methodologies for manifold learning, and study of network dynamics, (2) data assimilation and filtering for nonlinear systems, including inference from observations of dynamical networks, and (3) learning from large data sets, including sampling questions in high dimensions.</span></p>\n<p><span>In the realm of gopyological data analysis, w<span>e showed that the method of k-nearest neighbors is geometrically consistent in the sense that under certain conditions, the unnormalized graph Laplacian converges to the Laplace-Beltrami operator, spectrally as well as pointwise. In fact, we proved for compact (and conjectured for noncompact) manifolds that CkNN is the unique unweighted construction that yields a geometry consistent with the connected components of the underlying manifold in the limit of large data.&nbsp; As applications we derived a new fast clustering algorithm and a method to identify patterns in natural images topologically. We conjecture that CkNN is topologically consistent, meaning that the homology of the Vietoris-Rips complex (implied by the graph Laplacian) converges to the homology of the underlying manifold.</span></span></p>\n<p><span><span><span>In the field of data assimilation, we published path-breaking research on the effects of correlation between observation noise and system noise in modern linear and nonliner Kalman filters. The paper explains why we expect these correlations to occur in operational data assimilation contexts and make recommendations on how to exploit the correlations. This research appeared in Monthly Weather Review, a top-level journal for the numerical weather prediction community, in 2018.</span><br /></span></span></p>\n<p>Finally, w<span>ith the advent of the COVID-19 epidemic, we also turned our attention in part to disease modeling. In this direction, we have produced new research on (1) methods of modeling non-contagious diseases like hydrocephalus, endemic in neonates in third-world countries, (2) identifiabiility of parameters early in epidemics in SEIR and related models, and (3) a new data assimilation methodology called the Poisson Kalman Filter where we replace the Gaussian noise assumptions with Poisson noise, which is more appropriate for data fusion in contagious epidemic modeling.&nbsp;</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/18/2021<br>\n\t\t\t\t\tModified by: Timothy&nbsp;D&nbsp;Sauer</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe research project developed manifold learning techniques and dynamical systems concepts that will be essential to build the next generation of data analysis, including innovations in geometry, topology and deep learning methods. Research efforts were carried out on a number of areas, including (1) topological data analysis, involving extensions of the Laplacian eigenmap and diffusion map methodologies for manifold learning, and study of network dynamics, (2) data assimilation and filtering for nonlinear systems, including inference from observations of dynamical networks, and (3) learning from large data sets, including sampling questions in high dimensions.\n\nIn the realm of gopyological data analysis, we showed that the method of k-nearest neighbors is geometrically consistent in the sense that under certain conditions, the unnormalized graph Laplacian converges to the Laplace-Beltrami operator, spectrally as well as pointwise. In fact, we proved for compact (and conjectured for noncompact) manifolds that CkNN is the unique unweighted construction that yields a geometry consistent with the connected components of the underlying manifold in the limit of large data.  As applications we derived a new fast clustering algorithm and a method to identify patterns in natural images topologically. We conjecture that CkNN is topologically consistent, meaning that the homology of the Vietoris-Rips complex (implied by the graph Laplacian) converges to the homology of the underlying manifold.\n\nIn the field of data assimilation, we published path-breaking research on the effects of correlation between observation noise and system noise in modern linear and nonliner Kalman filters. The paper explains why we expect these correlations to occur in operational data assimilation contexts and make recommendations on how to exploit the correlations. This research appeared in Monthly Weather Review, a top-level journal for the numerical weather prediction community, in 2018.\n\n\nFinally, with the advent of the COVID-19 epidemic, we also turned our attention in part to disease modeling. In this direction, we have produced new research on (1) methods of modeling non-contagious diseases like hydrocephalus, endemic in neonates in third-world countries, (2) identifiabiility of parameters early in epidemics in SEIR and related models, and (3) a new data assimilation methodology called the Poisson Kalman Filter where we replace the Gaussian noise assumptions with Poisson noise, which is more appropriate for data fusion in contagious epidemic modeling. \n\n\t\t\t\t\tLast Modified: 12/18/2021\n\n\t\t\t\t\tSubmitted by: Timothy D Sauer"
 }
}