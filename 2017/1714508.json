{
 "awd_id": "1714508",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Enabling In-Network Computation for Datacenter Applications",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 475000.0,
 "awd_amount": 475000.0,
 "awd_min_amd_letter_date": "2017-07-28",
 "awd_max_amd_letter_date": "2017-07-28",
 "awd_abstract_narration": "The emergence of programmable network devices, such as reconfigurable switches and customizable network accelerators, along with the increasing traffic of data centers, motivate the use of in-network computation. Today's latest reconfigurable switches support configurable per-packet processing, including customizable packet headers, customizable packet processing, and the ability to maintain state inside the switch. Given this hardware trend, this project seeks to offload computing operations onto intermediate networking devices for a broad range of application services ranging from distributed storage to big data analytics and distributed machine learning, thus optimizing the operations of data center applications. \r\n\r\nThe project's primary goal is to build a programming framework to enable in-network computing using programmable networking hardware. In designing and implementing this framework, the project addresses the following research questions: First, the project tackles how to best integrate reconfigurable switches and network accelerators into a data center network, as they both have limitations in terms of the operations that they can execute. Second, a key project goal is to identify what is a simple and yet powerful programming application program interface (API) for these programmable devices to support a broad class of applications. Third, another key challenge addressed is how to keep state and computations on these devices consistent with that of application servers, and how to co-design data center applications to take advantage of the performance benefits enabled by this paradigm. \r\n\r\nThis project seeks to improve the efficiency of network-intensive data center applications that are used by literally billions of people around the globe on a daily basis. By improving their efficiency, one can dramatically reduce the cost of data center services as well as make it much cheaper for new public services to be developed. Collaborators at various switch vendors are equal partners in this effort, providing access to new technologies as well as assisting in technology transfer to the industry.  The project will integrate undergraduate students as researchers, and material from the project will be incorporated into both undergraduate and graduate courses.\r\n\r\nA key project goal is to publicly release developed software and enable a rich set of high-performance data center applications. All software will be made public as soon as they are developed, hosted via GitHub at https://github.com/arvindkrish/incbricks and accessible from the project website at the University of Washington. A mirrored version of this repository will be maintained at the University for at least five years.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Arvind",
   "pi_last_name": "Krishnamurthy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Arvind Krishnamurthy",
   "pi_email_addr": "arvind@cs.washington.edu",
   "nsf_id": "000488256",
   "pi_start_date": "2017-07-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "185 Stevens Way",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981952350",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 475000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We seek to take advantage of emerging networking hardware that is programmable and customizable in order to suit application needs. Today's latest reconfigurable switches support configurable per-packet processing, including customizable packet headers, header processing primitives in the data plane, and the ability to maintain state inside the switch. Examples include Intel FlexPipe, Barefoot Network products, and the Cavium XPliant devices. In addition to these programmable switches, we are also witnessing the advent of programmable network accelerators (e.g., Cavium's Octeon), which are highly parallel and yet low-power devices, that are capable of performing a substantial amount of packet processing.</p>\n<p>Given this hardware trend, our project seeks to offload computing operations onto intermediate networking devices (e.g., switches, accelerator devices) for a broad range of application services ranging from distributed storage to big data analytics and distributed machine learning. Our programming framework would enable applications to execute program logic on these devices in a customizable manner. There are many benefits of doing so, including reduction in end-to-end latencies for application-level operations, reduction in datacenter traffic, and energy savings due to the use of low-power accelerators instead of server-class machines.</p>\n<p>We explore a hardware-software co-designed system that allows doing in-network computations on a programmable networking middlebox that is built using a reconfigurable switch and a programmable network accelerator. Our work provides new abstractions and an execution framework for the use of programmable network devices, while respecting the hardware constraints that are associated with these technologies. We also prototype a diverse set of applications that can use in-network computing support and evaluate the performance benefits made possible by this paradigm.</p>\n<p>In particular, we build a programming framework to enable in-networking computing using programmable networking hardware and provide applications with significant performance gains. In designing and implementing this framework, we address the following research questions that haven't been addressed before:&nbsp; First, how to best integrate reconfigurable switches and network accelerators into a datacenter network? Both reconfigurable switches and network accelerators have limitations; reconfigurable switches can operate at line rate, but typically limit the type and number of operations performed ona packet and the amount of state maintained inside the switch, whereas network accelerators can perform more complex computations but cannot sustain large amounts of traffic. Second, what is a simple and yet powerful programming API for these programmable devices in order to support a broad class of applications? Third, how to keep state and computations on these devices consistent with that of application servers? And, finally, how to co-design datacenter applications to take advantage of the performance benefits enabled by this paradigm?&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/27/2020<br>\n\t\t\t\t\tModified by: Arvind&nbsp;Krishnamurthy</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWe seek to take advantage of emerging networking hardware that is programmable and customizable in order to suit application needs. Today's latest reconfigurable switches support configurable per-packet processing, including customizable packet headers, header processing primitives in the data plane, and the ability to maintain state inside the switch. Examples include Intel FlexPipe, Barefoot Network products, and the Cavium XPliant devices. In addition to these programmable switches, we are also witnessing the advent of programmable network accelerators (e.g., Cavium's Octeon), which are highly parallel and yet low-power devices, that are capable of performing a substantial amount of packet processing.\n\nGiven this hardware trend, our project seeks to offload computing operations onto intermediate networking devices (e.g., switches, accelerator devices) for a broad range of application services ranging from distributed storage to big data analytics and distributed machine learning. Our programming framework would enable applications to execute program logic on these devices in a customizable manner. There are many benefits of doing so, including reduction in end-to-end latencies for application-level operations, reduction in datacenter traffic, and energy savings due to the use of low-power accelerators instead of server-class machines.\n\nWe explore a hardware-software co-designed system that allows doing in-network computations on a programmable networking middlebox that is built using a reconfigurable switch and a programmable network accelerator. Our work provides new abstractions and an execution framework for the use of programmable network devices, while respecting the hardware constraints that are associated with these technologies. We also prototype a diverse set of applications that can use in-network computing support and evaluate the performance benefits made possible by this paradigm.\n\nIn particular, we build a programming framework to enable in-networking computing using programmable networking hardware and provide applications with significant performance gains. In designing and implementing this framework, we address the following research questions that haven't been addressed before:  First, how to best integrate reconfigurable switches and network accelerators into a datacenter network? Both reconfigurable switches and network accelerators have limitations; reconfigurable switches can operate at line rate, but typically limit the type and number of operations performed ona packet and the amount of state maintained inside the switch, whereas network accelerators can perform more complex computations but cannot sustain large amounts of traffic. Second, what is a simple and yet powerful programming API for these programmable devices in order to support a broad class of applications? Third, how to keep state and computations on these devices consistent with that of application servers? And, finally, how to co-design datacenter applications to take advantage of the performance benefits enabled by this paradigm? \n\n \n\n\t\t\t\t\tLast Modified: 10/27/2020\n\n\t\t\t\t\tSubmitted by: Arvind Krishnamurthy"
 }
}