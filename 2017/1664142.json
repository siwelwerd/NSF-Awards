{
 "awd_id": "1664142",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: SI2-SSI: EVOLVE: Enhancing the Open MPI Software for Next Generation Architectures and Applications",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Seung-Jong Park",
 "awd_eff_date": "2017-06-01",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 1566215.0,
 "awd_amount": 1566215.0,
 "awd_min_amd_letter_date": "2017-05-26",
 "awd_max_amd_letter_date": "2017-05-26",
 "awd_abstract_narration": "For nearly two decades, the Message Passing Interface (MPI) has been an essential part of the High-Performance Computing ecosystem and consequently a key enabler for important scientific breakthroughs. It is a fundamental building block for most large-scale simulations from physics, chemistry, biology, material sciences as engineering.  Open MPI is an open source implementation of the MPI specification, widely used and adopted by the research community as well as industry. The Open MPI library is jointly developed and maintained by a consortium of academic institutions, national labs and industrial partners. It is installed on virtually all large-scale computer systems in the US as well as in the rest of the world. The goal of this project is to enhance and modernize the Open MPI library in the context of the ongoing evolution of modern computer systems, and to ensure its future operability on all upcoming architectures. We aim at implementing fundamental software techniques that can be used in many-core systems to execute MPI-based parallel applications more efficiently, and to tolerate process and memory failures at all scales, from current systems, up to the extreme scales expected before the end of the decade.\r\n\r\nOpen MPI is an open source implementation of the Message Passing Interface (MPI) specification. The MPI API is currently being extended to consider the needs of application developers in terms of efficiency, productivity and resilience. The project will also support academic involvement in the design, development and evaluation of the Open MPI software, and ensure academic presence in the MPI Forum. The goal of this proposal is to enhance the Open MPI software library, focusing on two aspects: (1) Extend Open MPI to support new features of the MPI specification. Open MPI will continue to support all new features of current and upcoming MPI specifications. The two most significant areas within the context of this proposal are (a) extensions to better support hybrid programming models and (b) support for fault tolerance in MPI applications. To improve support for hybrid programming models, the MPI Forum is currently considering introducing the notion of MPI Endpoints, which could be used by different threads of an MPI rank to instantiate multiple separate communication contexts. The goal within this project is to develop an implementation of endpoints to support effective hybrid programming model, and to extend the concept to other aspects of parallel applications such as File I/O operations. One of the project partners (UTK) leads the current proposal in the MPI Forum to expose failures and ensure the continuation of the execution of MPI applications. In the context of this SSI proposal, the goal is to harden, improve, and expand the support of the existing ULFM implementation in Open MPI and thus enable end-users to design application-specific resilience approaches for future platforms. (2) Enhance the Open MPI core to support new architectures and improve scalability. While Open MPI has demonstrated very good scalability in the past, there is significant work to be done to ensure similarly good performance on future architectures. Specifically, we propose a groundbreaking rework of the startup environment that will improve process launch scalability, increase support for asynchronous progress of operations, enable support for accelerators, and reduce sensitivity to system noise. The project would also enhance the support for File I/O operations as part of the Open MPI package by expanding our work on highly scalable collective I/O operations through delegation and exploring the utilization of burst buffers as temporary storage.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "George",
   "pi_last_name": "Bosilca",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "George M Bosilca",
   "pi_email_addr": "bosilca@icl.utk.edu",
   "nsf_id": "000348594",
   "pi_start_date": "2017-05-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Thomas",
   "pi_last_name": "Herault",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas Herault",
   "pi_email_addr": "herault@icl.utk.edu",
   "nsf_id": "000595689",
   "pi_start_date": "2017-05-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Aurelien",
   "pi_last_name": "Bouteiller",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aurelien Bouteiller",
   "pi_email_addr": "bouteill@icl.utk.edu",
   "nsf_id": "000595690",
   "pi_start_date": "2017-05-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Tennessee Knoxville",
  "inst_street_address": "201 ANDY HOLT TOWER",
  "inst_street_address_2": "",
  "inst_city_name": "KNOXVILLE",
  "inst_state_code": "TN",
  "inst_state_name": "Tennessee",
  "inst_phone_num": "8659743466",
  "inst_zip_code": "379960001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "TN02",
  "org_lgl_bus_name": "UNIVERSITY OF TENNESSEE",
  "org_prnt_uei_num": "LXG4F9K8YZK5",
  "org_uei_num": "FN2YCS2YAUW3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Tennessee Knoxville",
  "perf_str_addr": "1 Circle Park",
  "perf_city_name": "Knoxville",
  "perf_st_code": "TN",
  "perf_st_name": "Tennessee",
  "perf_zip_code": "379960003",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "TN02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "800400",
   "pgm_ele_name": "Software Institutes"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "8004",
   "pgm_ref_txt": "Software Institutes"
  },
  {
   "pgm_ref_code": "8009",
   "pgm_ref_txt": "Scientifc Software Integration"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 1566215.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Due to major changes in the hardware architecture and scale of scientific computing platforms maintaining the portability of existing codes while ensuring future code developments have access to novel hardware capabilities is a major challenge. The Message Passing Interface (MPI) is an international standardization effort, to define the critical requirements and capabilities of a distributed programming paradigm, the most basic building block of any distributed application, from scientific simulation to machine learning.</p>\n<p>&nbsp;</p>\n<p>In the context of this project, we have actively participated into the standardization efforts to define and validate the logical constructs necessary for building reliable distributed software components, an infrastructure that would fuel the software design of tomorrow, allowing these software components to be more effective, more accurate and more reliable. Building upon this standardization thrust, we have actively pursued the implementation of the proposed concepts into one of the most widely used implementation of the MPI concepts, the Open MPI library, improving the software stack in all modern aspects from threading support to new hardware support, resilience, accelerator integration and more. In addition to being one of the mainstream MPI implementations available, Open MPI has been a critical software component, enabling ground-breaking science in physics, chemistry, biology, and many other scientific domains, both in academia and industry. As a result of our sustained efforts done together with a large and active open-source community, Open MPI has evolved into a production quality, widely available and used library, a software component used in mostly all platforms and parallel applications.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/14/2023<br>\n\t\t\t\t\tModified by: George&nbsp;M&nbsp;Bosilca</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDue to major changes in the hardware architecture and scale of scientific computing platforms maintaining the portability of existing codes while ensuring future code developments have access to novel hardware capabilities is a major challenge. The Message Passing Interface (MPI) is an international standardization effort, to define the critical requirements and capabilities of a distributed programming paradigm, the most basic building block of any distributed application, from scientific simulation to machine learning.\n\n \n\nIn the context of this project, we have actively participated into the standardization efforts to define and validate the logical constructs necessary for building reliable distributed software components, an infrastructure that would fuel the software design of tomorrow, allowing these software components to be more effective, more accurate and more reliable. Building upon this standardization thrust, we have actively pursued the implementation of the proposed concepts into one of the most widely used implementation of the MPI concepts, the Open MPI library, improving the software stack in all modern aspects from threading support to new hardware support, resilience, accelerator integration and more. In addition to being one of the mainstream MPI implementations available, Open MPI has been a critical software component, enabling ground-breaking science in physics, chemistry, biology, and many other scientific domains, both in academia and industry. As a result of our sustained efforts done together with a large and active open-source community, Open MPI has evolved into a production quality, widely available and used library, a software component used in mostly all platforms and parallel applications.\n\n \n\n\t\t\t\t\tLast Modified: 02/14/2023\n\n\t\t\t\t\tSubmitted by: George M Bosilca"
 }
}