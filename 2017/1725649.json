{
 "awd_id": "1725649",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SPX: Collaborative Research: Cross-layer Application-Aware Resilience at Extreme Scale (CAARES)",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2017-08-15",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 267247.0,
 "awd_amount": 267247.0,
 "awd_min_amd_letter_date": "2017-08-09",
 "awd_max_amd_letter_date": "2018-01-29",
 "awd_abstract_narration": "The increasing demands of science and engineering applications push the limits of current large-scale systems, and is expected to achieve exascale (10^18 FLOPS) performance early in the next decade. One of the lesser studied challenge at extreme scales is the reliability of the computing system itself, primarily due to the very large number of cores and components utilized and to the sharp decrease of the Mean Time Between Failures on such systems (in the order of tens of minutes). This project departs from the traditional single component fault management model, and explores how multiple software libraries (and application components) used in the context of a single parallel application can interact to provide the holistic fault management support necessary for parallel applications targeting capability computing. This exploration will not be limited to software developed using a single parallel programming paradigm, but will be extended to encompass the more challenging case where multiple programming paradigms can be combined to achieve a common goal, to simulate a set of large scale scientific applications in use today.\u00a0\r\n\t\r\nThe goal of this project is to depart from the current siloed resilience mechanisms, and propose cross-layer composition solutions that can fundamentally address these resilience challenges at extreme scales.\u00a0This exploration will not be limited to software developed using a single parallel programming paradigm, but will be extended to encompass the more challenging case where multiple programming paradigms can be combined to achieve a common goal, to simulate a set of large scale scientific applications in use today. More specifically, this proposal will address the following research challenges: (1) development of a theoretical foundation for a deeper understanding of the challenges and opportunities arising from combining different resilience models and methodologies; (2) design of a flexible programming abstraction to allow different resilience models and mechanisms to be combined to cooperate and address resilience in a more holistic manner; and (3) development of basic, programming paradigm independent, constructs necessary to implement cross-layer and domain-specific approaches to support resilience and to understand related performance / quality trade-offs. The proposed approach will be validated by exposing these generic abstractions in two different programming paradigms (MPI and OpenSHMEM), by creating and developing specialized concepts for each of these paradigms. This will enable the assessment of the validity of the concepts and the corresponding overheads imposed by the different software layers, using few software frameworks and applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Manish",
   "pi_last_name": "Parashar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Manish Parashar",
   "pi_email_addr": "manish.parashar@utah.edu",
   "nsf_id": "000148826",
   "pi_start_date": "2017-08-09",
   "pi_end_date": "2018-01-29"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ivan",
   "pi_last_name": "Rodero",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ivan Rodero",
   "pi_email_addr": "ivan.rodero@utah.edu",
   "nsf_id": "000631333",
   "pi_start_date": "2018-01-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers Discovery Informatics Institute",
  "perf_str_addr": "96 Frelinghuysen Road",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548018",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 267247.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In-situ workflow approaches, such as those based on data staging and in-situ/in-transit data-management, have emerged as effective solutions for addressing data-related challenges at extreme scales, and are being adopted by applications across current high-end computing systems. However, failures continue to present significant challenges at all execution scales. For example, while these techniques effectively address the specific failure modes/class they target, they are largely incompatible with each other, operate at distinct software layers, and often implement their own independent and incompatible software stacks.</p>\n<p>The goal of this research activity was to address these resiliency related challenges and develop conceptual solutions as well as a software framework that can guarantee data resiliency for large-scale data-intensive simulation workflows. Our approach was based on the premise that while applications utilize various data resiliency schemes, the underlying framework that is used to share data across coupled applications should also be resilient to failures. Central to our efforts has been the design of a data management framework that enables support for various data resiliency schemes like erasure codes and redundancy. The research efforts also included data verification schemes to guarantee that data is not corrupted when the data is being shared across coupled applications.&nbsp;Due to the dependencies, interactions and data exchanges between application components, naively applying states-of-the-arts fault tolerance scheme for the individual component cannot maintain the consistent state of workflows during the failure recovery. Our research efforts have also explored design and development of workflow-level checkpoint/restart strategy for in-situ workflows.</p>\n<p>Research activities as part of this effort have explored data resilience mechanisms that can support in-memory data recovery with high-performance, low overhead and minimum interference with regular data operation is needed to guarantee the data reliability for data management framework. Since multiple applications in an in-situ workflow interact by sharing/exchanging data, it is important to detect, isolate and correct silent errors in a component application as early as possible and to prevent the propagation of these errors between components. We have thus designed and developed data verification mechanism is required for In-situ workflows to identify error corrupted components and minimize its impact. To further minimize the impact of rollback from a failure across different components of a scientific workflow, we have also explored workflow-level fault tolerance mechanism to minimize the interference between components during recovery, while still maintaining consistent states of workflows.</p>\n<p>This research has resulted in novel data staging abstractions and mechanisms that are enabling application workflows at very large scales. Furthermore, the results of this research have been deployed within the DataSpaces software, which is being used by multiple applications. The data resiliency capabilities resulting from this project are can be directly used by scientific applications in multiple domains, including fusion and combustion, without making significant changes to their codes.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/03/2020<br>\n\t\t\t\t\tModified by: Ivan&nbsp;Rodero</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn-situ workflow approaches, such as those based on data staging and in-situ/in-transit data-management, have emerged as effective solutions for addressing data-related challenges at extreme scales, and are being adopted by applications across current high-end computing systems. However, failures continue to present significant challenges at all execution scales. For example, while these techniques effectively address the specific failure modes/class they target, they are largely incompatible with each other, operate at distinct software layers, and often implement their own independent and incompatible software stacks.\n\nThe goal of this research activity was to address these resiliency related challenges and develop conceptual solutions as well as a software framework that can guarantee data resiliency for large-scale data-intensive simulation workflows. Our approach was based on the premise that while applications utilize various data resiliency schemes, the underlying framework that is used to share data across coupled applications should also be resilient to failures. Central to our efforts has been the design of a data management framework that enables support for various data resiliency schemes like erasure codes and redundancy. The research efforts also included data verification schemes to guarantee that data is not corrupted when the data is being shared across coupled applications. Due to the dependencies, interactions and data exchanges between application components, naively applying states-of-the-arts fault tolerance scheme for the individual component cannot maintain the consistent state of workflows during the failure recovery. Our research efforts have also explored design and development of workflow-level checkpoint/restart strategy for in-situ workflows.\n\nResearch activities as part of this effort have explored data resilience mechanisms that can support in-memory data recovery with high-performance, low overhead and minimum interference with regular data operation is needed to guarantee the data reliability for data management framework. Since multiple applications in an in-situ workflow interact by sharing/exchanging data, it is important to detect, isolate and correct silent errors in a component application as early as possible and to prevent the propagation of these errors between components. We have thus designed and developed data verification mechanism is required for In-situ workflows to identify error corrupted components and minimize its impact. To further minimize the impact of rollback from a failure across different components of a scientific workflow, we have also explored workflow-level fault tolerance mechanism to minimize the interference between components during recovery, while still maintaining consistent states of workflows.\n\nThis research has resulted in novel data staging abstractions and mechanisms that are enabling application workflows at very large scales. Furthermore, the results of this research have been deployed within the DataSpaces software, which is being used by multiple applications. The data resiliency capabilities resulting from this project are can be directly used by scientific applications in multiple domains, including fusion and combustion, without making significant changes to their codes.\n\n\t\t\t\t\tLast Modified: 12/03/2020\n\n\t\t\t\t\tSubmitted by: Ivan Rodero"
 }
}