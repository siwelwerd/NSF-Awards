{
 "awd_id": "1704914",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: CHS: Medium: Collaborative Research: Improving Pedestrian Safety in Urban Cities using Intelligent Wearable Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Erik Brunvand",
 "awd_eff_date": "2017-06-01",
 "awd_exp_date": "2021-05-31",
 "tot_intn_awd_amt": 125916.0,
 "awd_amount": 125916.0,
 "awd_min_amd_letter_date": "2017-05-26",
 "awd_max_amd_letter_date": "2020-06-18",
 "awd_abstract_narration": "Using smartphones while walking poses an increasingly common safety problem for people in urban environments. Whether listening to music, texting, or talking, pedestrians that are absorbed with their smartphones are considerably less likely to notice important auditory cues of danger, such as the honks and sounds of approaching vehicles, putting pedestrians at far greater risk of being hit. This project aims to develop an intelligent wearable system that uses miniature microphones - embedded in earphones or headsets - to detect and locate approaching vehicles and warn the wearer of imminent dangers from cars, buses, motorbikes, trucks, and trams. \r\n\r\nThe system comprises multiple microphones embedded in a wearable headset, an ultra-low-power feature extraction and data  processing pipeline, and a set of machine-learning classifiers running on a smartphone. This project is organized in four research thrusts: (1) designing an architecture and data processing pipeline for a wearable system composed of heterogeneous embedded modules; (2) devising an ultra-low-power, analog, signal-processing application-specific integrated circuit (ASIC) for energy-efficient, on-board feature extraction; (3) modeling and optimizing machine-learning classifiers for acoustic event detection and localization; and (4) designing an interface and feedback mechanisms that are optimized for the users' perceptual, cognitive, and motor control abilities.\r\n\r\nThis research will help reduce pedestrian injuries and fatalities, and expand knowledge on designing wearable systems for enhancing safety in cities, workplaces, and the home. The underlying framework can be generalized to other systems - employing low-power signal processors and algorithms to solve real-time sensing and classification problems of many kinds. Research products will be made publicly available to anyone to apply these techniques in their own system designs. Course modules developed on embedded systems, mobile computing, and Internet-of-Things will be used at the three participating universities to train undergraduate and graduate students, and will be made available online.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Josh",
   "pi_last_name": "New",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Josh New",
   "pi_email_addr": "jnew@barnard.edu",
   "nsf_id": "000624088",
   "pi_start_date": "2017-05-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Barnard College",
  "inst_street_address": "3009 BROADWAY",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128542708",
  "inst_zip_code": "100276909",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "BARNARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LPQ1NHRK78M9"
 },
 "perf_inst": {
  "perf_inst_name": "Barnard College",
  "perf_str_addr": "3009 Broadway",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100276598",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 68104.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 41072.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16740.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Smartphones have been implicated in the significant increase of pedestrian injuries and deaths: not only by distracting drivers, but also pedestrians who are using (e.g. texting) and/or listening to smartphones (e.g. headphones) around traffic.&nbsp; Working with groups of engineers and programmers from Columbia and UNC-Chapel Hill, our team of cognitive psychology researchers at Barnard College collaborated on the development of a safety system to help pedestrians avoid these accidents.&nbsp; This wearable system uses earphones/headsets with embedded sensors to help detect, locate, and warn pedestrians of imminent dangers from nearby objects, such as approaching cars from their sounds.&nbsp;</p>\n<p>Our laboratory's behavioral research contributed to the overarching project by determining how the system's functions and alerts could be optimized with respect to the users' sensory, perceptual, and cognitive capacities.&nbsp; Our foremost objective was to determine what kinds of information and forms of system alerts would be most readily perceived, understood, and acted upon by users.&nbsp; To do this, we established a novel psychophysical paradigm - adapted from a well-founded test of visual attention - to evaluate how well people could detect approaching objects while browsing on their smartphones.&nbsp; Participants monitored a projected, ultrawide screen for target objects emerging from their far periphery and moving directly in front of them - as would an automobile on a colliding path.&nbsp; Unsurprisingly, when participants were allowed to browse on their smartphones, participants were much slower to report targets' appearances via foot pedal press - targets oftentimes even went completely undetected.&nbsp; This lowered awareness, however, was virtually eliminated when targets were accompanied by a preceding alert - as this project's system would provide.&nbsp;</p>\n<p>Our research with this approach uncovered a number of employable findings including, 1) that even the simplest alerts can completely restore situational awareness to smartphone-distracted individuals, 2) directional tones - emanating from the left or right - are even better alerts in complex environments, although 3) verbal directional warnings (e.g. LEFT) are very slowly processed and are probably unsuitable for this system despite their unambiguity, and 4) alerts delivered via headphones (as this system would generate) are likely to be as effective as alerts sounded in the actual environment - such as the audible DON'T WALK sounds in the Accessible Pedestrian Signals system.&nbsp;</p>\n<p>Interestingly, we found that participants' sensitivity to alerts - and responsivity to appearing targets - does not steadily worsen over time.&nbsp; That is, observers are not increasingly immersed in their smartphone activities - nor grow increasingly unaware of their surroundings with time.&nbsp; Despite smartphones' profound abilities to engross attention, users could instead be shifting attention adaptively - whether intermittently to assess their surroundings, or more sustainedly to navigate complex areas (e.g., intersections).&nbsp; It was therefore anticipated that the efficacy of our system's alerts would be more accurately estimated by testing participants' abilities to detect hazards in a more realistic, and dynamic simulated environment.&nbsp; A second branch of research had been underway to develop a naturalistic testing environment when all in-person behavioral research and undergraduate instruction was discontinued due to the COVID-19 pandemic.&nbsp; This immersive testing framework was comprised of a three-dimensional cityscape that could be rendered and animated in real-time using Unreal Engine and had an experimental structure controlled by custom C++ programming.&nbsp;</p>\n<p>Both the initial behavioral research and latter technical development of a virtual testing environment provided a number of teaching, learning, and training opportunities.&nbsp; These experiments were conducted by Dr. Joshua New and undergraduate researchers in his cognitive science laboratory at Barnard College - an all-women's, liberal arts institution.&nbsp; His laboratory was composed entirely of female undergraduate students enrolled at the College. These student researchers worked directly with the PI and were involved in every aspect of the research from experimental design, implementation, and data analysis, to their &#64257;nal conference presentations.&nbsp; The nature of this funded project was also intrinsically transdisciplinary, and the students' participation in this research involved exposure and training in a number of STEM disciplines including computer programming, human-computer interactions and advanced statistical analysis.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/12/2022<br>\n\t\t\t\t\tModified by: Josh&nbsp;New</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSmartphones have been implicated in the significant increase of pedestrian injuries and deaths: not only by distracting drivers, but also pedestrians who are using (e.g. texting) and/or listening to smartphones (e.g. headphones) around traffic.  Working with groups of engineers and programmers from Columbia and UNC-Chapel Hill, our team of cognitive psychology researchers at Barnard College collaborated on the development of a safety system to help pedestrians avoid these accidents.  This wearable system uses earphones/headsets with embedded sensors to help detect, locate, and warn pedestrians of imminent dangers from nearby objects, such as approaching cars from their sounds. \n\nOur laboratory's behavioral research contributed to the overarching project by determining how the system's functions and alerts could be optimized with respect to the users' sensory, perceptual, and cognitive capacities.  Our foremost objective was to determine what kinds of information and forms of system alerts would be most readily perceived, understood, and acted upon by users.  To do this, we established a novel psychophysical paradigm - adapted from a well-founded test of visual attention - to evaluate how well people could detect approaching objects while browsing on their smartphones.  Participants monitored a projected, ultrawide screen for target objects emerging from their far periphery and moving directly in front of them - as would an automobile on a colliding path.  Unsurprisingly, when participants were allowed to browse on their smartphones, participants were much slower to report targets' appearances via foot pedal press - targets oftentimes even went completely undetected.  This lowered awareness, however, was virtually eliminated when targets were accompanied by a preceding alert - as this project's system would provide. \n\nOur research with this approach uncovered a number of employable findings including, 1) that even the simplest alerts can completely restore situational awareness to smartphone-distracted individuals, 2) directional tones - emanating from the left or right - are even better alerts in complex environments, although 3) verbal directional warnings (e.g. LEFT) are very slowly processed and are probably unsuitable for this system despite their unambiguity, and 4) alerts delivered via headphones (as this system would generate) are likely to be as effective as alerts sounded in the actual environment - such as the audible DON'T WALK sounds in the Accessible Pedestrian Signals system. \n\nInterestingly, we found that participants' sensitivity to alerts - and responsivity to appearing targets - does not steadily worsen over time.  That is, observers are not increasingly immersed in their smartphone activities - nor grow increasingly unaware of their surroundings with time.  Despite smartphones' profound abilities to engross attention, users could instead be shifting attention adaptively - whether intermittently to assess their surroundings, or more sustainedly to navigate complex areas (e.g., intersections).  It was therefore anticipated that the efficacy of our system's alerts would be more accurately estimated by testing participants' abilities to detect hazards in a more realistic, and dynamic simulated environment.  A second branch of research had been underway to develop a naturalistic testing environment when all in-person behavioral research and undergraduate instruction was discontinued due to the COVID-19 pandemic.  This immersive testing framework was comprised of a three-dimensional cityscape that could be rendered and animated in real-time using Unreal Engine and had an experimental structure controlled by custom C++ programming. \n\nBoth the initial behavioral research and latter technical development of a virtual testing environment provided a number of teaching, learning, and training opportunities.  These experiments were conducted by Dr. Joshua New and undergraduate researchers in his cognitive science laboratory at Barnard College - an all-women's, liberal arts institution.  His laboratory was composed entirely of female undergraduate students enrolled at the College. These student researchers worked directly with the PI and were involved in every aspect of the research from experimental design, implementation, and data analysis, to their &#64257;nal conference presentations.  The nature of this funded project was also intrinsically transdisciplinary, and the students' participation in this research involved exposure and training in a number of STEM disciplines including computer programming, human-computer interactions and advanced statistical analysis. \n\n \n\n \n\n\t\t\t\t\tLast Modified: 05/12/2022\n\n\t\t\t\t\tSubmitted by: Josh New"
 }
}