{
 "awd_id": "1733873",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AITF: Applied Algorithmic Foundation for Scheduling Multiprogrammed Parallelizable Workloads",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 650000.0,
 "awd_amount": 650000.0,
 "awd_min_amd_letter_date": "2017-08-23",
 "awd_max_amd_letter_date": "2018-02-01",
 "awd_abstract_narration": "Most modern computing systems contain multiprocessor hardware which is shared by many applications.  In these systems, good scheduling algorithms that decide how to allocate resources among applications are crucial to ensure good quality of service and efficient use of system resources.  This project will design foundational algorithms and prototype implementations of scheduling algorithms that provide guarantees of performance and resource utilization for these shared machines.  This work will shape the efficiency of critical computing infrastructure by improving performance of parallel systems from personal computers to data centers to supercomputers.   All results, including published articles and software artifacts, will be released to the public via world-wide web.  The PIs will integrate research with education by incorporating this research into the PIs' graduate courses and training PhD, MS, and BS students in applied and theoretical parallel computing research.\r\n\r\nThe project will involve designing practically efficient schedulers guided by theoretical foundations.  The PIs will design a theory of multi-programmed scheduling for parallel programs by considering a variety of scheduling objectives important to system designers.  In particular, the research will focus on optimizing latency objectives that are used in servers, clouds, and interactive systems.  The PIs will also explore efficient mechanisms that can be used to implement these algorithms in practice and perform empirical validations of their designs.  By combining theoretical analysis with feedback from empirical evaluations, the proposed work will gain insights that will advance the state of the art of both theory and practice of parallel job scheduling.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Benjamin",
   "pi_last_name": "Moseley",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Benjamin J Moseley",
   "pi_email_addr": "moseleyb85@gmail.com",
   "nsf_id": "000671246",
   "pi_start_date": "2017-08-23",
   "pi_end_date": "2018-02-01"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "I-Ting",
   "pi_last_name": "Lee",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "I-Ting A Lee",
   "pi_email_addr": "angelee@wustl.edu",
   "nsf_id": "000678883",
   "pi_start_date": "2018-02-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kunal",
   "pi_last_name": "Agrawal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kunal Agrawal",
   "pi_email_addr": "kunal@cse.wustl.edu",
   "nsf_id": "000555177",
   "pi_start_date": "2017-08-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "I-Ting",
   "pi_last_name": "Lee",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "I-Ting A Lee",
   "pi_email_addr": "angelee@wustl.edu",
   "nsf_id": "000678883",
   "pi_start_date": "2017-08-23",
   "pi_end_date": "2018-02-01"
  }
 ],
 "inst": {
  "inst_name": "Washington University",
  "inst_street_address": "1 BROOKINGS DR",
  "inst_street_address_2": "",
  "inst_city_name": "SAINT LOUIS",
  "inst_state_code": "MO",
  "inst_state_name": "Missouri",
  "inst_phone_num": "3147474134",
  "inst_zip_code": "631304862",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MO01",
  "org_lgl_bus_name": "WASHINGTON UNIVERSITY, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "L6NFUM28LQM5"
 },
 "perf_inst": {
  "perf_inst_name": "Washington University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MO",
  "perf_st_name": "Missouri",
  "perf_zip_code": "631304899",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "MO01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723900",
   "pgm_ele_name": "Algorithms in the Field"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 650000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\"><span class=\"s1\">When many parallel applications share a multiprocessor machine, the system&nbsp;</span>scheduler must decide how to schedule this multiprogrammed workload.&nbsp; This project developed empirically efficient schedulers backed by a theoretical foundation for how to efficiently allocate the various resources (e.g., processors and shared cache) on a machine or across multiple machines in parallel computing environments when jobs arrive over time.</p>\n<p class=\"p1\"><span class=\"s1\">In this project, we have designed and developed many efficient algorithms for&nbsp;</span>allocating resources.&nbsp; One direction taken models the parallel jobs as direct-acyclic graph (DAG), and we have developed practically efficient scheduling algorithms for allocating processors that optimize for various objectives relating to the job completion time, including minimizing average flow time, maximizing throughput with job deadlines, and so on).&nbsp; In terms of intellectual merits, this work advances the knowledge of scheduling parallel jobs.&nbsp; Prior to this project, few results were known for scheduling parallel DAG jobs that arrive over time for the competitive analysis model and this project has developed a theory that parallels what is known in simpler single machine environments.&nbsp;</p>\n<p class=\"p1\"><span class=\"s1\">Another direction taken uses stochastic models to uncover efficiencies in&nbsp;</span>parallel computing settings.&nbsp; We have considered one problem where jobs have multiple phases, where the job is more parallelizable in some phases and less in others.&nbsp; We have designed allocation policies that allow one to minimize mean response time.&nbsp; In another work, a machine learning algorithm was designed to minimize makespan circumventing strong lower bounds on worst case analysis for a large and predictable class of jobs.&nbsp; In terms of intellectual merits, this work introduced some of the first queuing models for parallel jobs settings.&nbsp; This has been a major target in the area as it has been challenging to understand the dynamics of queuing systems when multiple processors are available. This led to a deeper understanding of the underlying algorithms that give optimal quality of service guarantees.&nbsp; These results are backed by empirical results demonstrating the practical utility of the newly developed algorithms.</p>\n<p class=\"p1\"><span class=\"s1\">Finally, we have also considered resource allocation problems relating to&nbsp;</span>memory.&nbsp; In one problem, we have designed a page replacement policies for high-bandwidth memories which are increasingly becoming a part of the memory stack.&nbsp; Surprisingly, it turns out that such high-bandwidth memories must be treated differently from cache and have different optimization metrics.&nbsp; We designed nearly optimal management policies for these memory systems.&nbsp; We have also studies how to best manage a cache shared by multiple parallel streams of accesses automatically.&nbsp; This is a long standing open problem, and we gave tight upper and lower bounds on the competitive ratio with O(1) resource augmentation.&nbsp; In terms of intellectual merits, this line of work lays the algorithmic foundations for managing high-bandwidth memories and caches shared by multiple parallel streams.</p>\n<p class=\"p1\"><span class=\"s1\">In terms of broader impacts, this body of work unlock the improved efficiencies&nbsp;</span>in parallel computing and distributed computing environments.&nbsp; This will result in the machines being utilized more efficiently and therefore consuming less energy to complete the necessary computations.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/17/2023<br>\n\t\t\t\t\tModified by: I-Ting&nbsp;A&nbsp;Lee</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "When many parallel applications share a multiprocessor machine, the system scheduler must decide how to schedule this multiprogrammed workload.  This project developed empirically efficient schedulers backed by a theoretical foundation for how to efficiently allocate the various resources (e.g., processors and shared cache) on a machine or across multiple machines in parallel computing environments when jobs arrive over time.\nIn this project, we have designed and developed many efficient algorithms for allocating resources.  One direction taken models the parallel jobs as direct-acyclic graph (DAG), and we have developed practically efficient scheduling algorithms for allocating processors that optimize for various objectives relating to the job completion time, including minimizing average flow time, maximizing throughput with job deadlines, and so on).  In terms of intellectual merits, this work advances the knowledge of scheduling parallel jobs.  Prior to this project, few results were known for scheduling parallel DAG jobs that arrive over time for the competitive analysis model and this project has developed a theory that parallels what is known in simpler single machine environments. \nAnother direction taken uses stochastic models to uncover efficiencies in parallel computing settings.  We have considered one problem where jobs have multiple phases, where the job is more parallelizable in some phases and less in others.  We have designed allocation policies that allow one to minimize mean response time.  In another work, a machine learning algorithm was designed to minimize makespan circumventing strong lower bounds on worst case analysis for a large and predictable class of jobs.  In terms of intellectual merits, this work introduced some of the first queuing models for parallel jobs settings.  This has been a major target in the area as it has been challenging to understand the dynamics of queuing systems when multiple processors are available. This led to a deeper understanding of the underlying algorithms that give optimal quality of service guarantees.  These results are backed by empirical results demonstrating the practical utility of the newly developed algorithms.\nFinally, we have also considered resource allocation problems relating to memory.  In one problem, we have designed a page replacement policies for high-bandwidth memories which are increasingly becoming a part of the memory stack.  Surprisingly, it turns out that such high-bandwidth memories must be treated differently from cache and have different optimization metrics.  We designed nearly optimal management policies for these memory systems.  We have also studies how to best manage a cache shared by multiple parallel streams of accesses automatically.  This is a long standing open problem, and we gave tight upper and lower bounds on the competitive ratio with O(1) resource augmentation.  In terms of intellectual merits, this line of work lays the algorithmic foundations for managing high-bandwidth memories and caches shared by multiple parallel streams.\nIn terms of broader impacts, this body of work unlock the improved efficiencies in parallel computing and distributed computing environments.  This will result in the machines being utilized more efficiently and therefore consuming less energy to complete the necessary computations.\n\n\t\t\t\t\tLast Modified: 02/17/2023\n\n\t\t\t\t\tSubmitted by: I-Ting A Lee"
 }
}