{
 "awd_id": "1714623",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: Eye Movement Biometrics in Virtual and Augmented Reality",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jeremy Epstein",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 499988.0,
 "awd_amount": 647981.0,
 "awd_min_amd_letter_date": "2017-08-16",
 "awd_max_amd_letter_date": "2020-02-10",
 "awd_abstract_narration": "Virtual and augmented reality (VR/AR) applications are expected to play an increasingly important role in many aspects of everyday life; however, we do not yet have effective methods for protecting VR/AR systems from cybersecurity threats. The goal of this research is to make VR/AR systems more secure via the development of highly accurate and counterfeit-resistant biometric techniques based on eye movements. These techniques are based on the computational modeling of multiple characteristics of the way individuals move their eyes. The development of trustworthy solutions for performing biometric recognition in such systems is critical for the creation of a cybersecurity infrastructure that can adequately serve emerging applications of VR/AR for social networking, health monitoring, and economic transactions. Improved understanding of distinctive eye movement features could also facilitate their use for the detection of cyber-sickness, stress, fatigue, concussions and other states that manifest in abnormalities of human vision. The education component of the project will help recruit a greater number of diverse students to careers in computer science as well as interdisciplinary studies involving computer science, and it will better prepare students to be key players in the next generation of innovators.\r\n\r\nThe goal of this project is to advance the current state of security in VR/AR systems via the development of highly accurate and counterfeit-resistant biometric techniques based on eye movements. The problem of eye movement-driven biometrics in VR/AR environments is significantly more challenging due to the 3-D environment which produces very complex eye movements that are hard to accurately classify and also the much larger number of extracted eye movement-driven features when compared to the eye movement-driven biometrics in 2D spaces. This project has two major thrusts: (1) biometric recognition: establishing the baseline for person recognition performance via eye movement characteristics in VR/AR environments; and (2) counterfeit-resistance: researching the robustness against spoofing attacks (e.g., attempts to defeat a biometric system through the introduction of fake biometric samples). This research provides answers to important questions related to the uniqueness, variability, scalability, and longevity of eye movement characteristics in VR/AR environments. The outcome of this work will be a new method to address the biometric security vulnerabilities of current and future VR/AR systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Oleg",
   "pi_last_name": "Komogortsev",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Oleg V Komogortsev",
   "pi_email_addr": "ok11@txstate.edu",
   "nsf_id": "000518752",
   "pi_start_date": "2017-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas State University - San Marcos",
  "inst_street_address": "601 UNIVERSITY DR",
  "inst_street_address_2": "",
  "inst_city_name": "SAN MARCOS",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5122452314",
  "inst_zip_code": "786664684",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "TX15",
  "org_lgl_bus_name": "TEXAS STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HS5HWWK1AAU5"
 },
 "perf_inst": {
  "perf_inst_name": "Texas State University - San Marcos",
  "perf_str_addr": "601 University dr",
  "perf_city_name": "San Marcos",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "786664684",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "TX15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 499988.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 115993.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project concentrated on understanding highly dynamic and individualistic traits related to eye-movements and their relationship to internal, non-visible, anatomical properties of the human eye and the brain&rsquo;s strategies for guiding visual attention to assess the utility of eye-movement biometrics &ndash; an accurate and spoof resistant method of person&rsquo;s authentication.</p>\n<p>&nbsp;</p>\n<p>We found individual differences in ways people move their eyes on macro and micro scale. If eye motility is recorded with high enough quality the differences in eye-movement patterns of any two individuals are such that it is possible to distinguish between them with an accuracy comparable to fingerprints. This discovery validates eye-movements as an authentication method for devices that have eye tracking capabilities. This is an important finding that will allow to potentially create accurate and spoof resistant device-unlock features aided by eye-movement analysis.&nbsp;</p>\n<p>&nbsp;</p>\n<p>We also found via theoretical analysis and the empirical work with the data that eye-movement-driven biometrics cannot be employed for identification purposes when the pool of users is large. This finding has large privacy-related implications in the positive way, because it puts away fears that people can be somehow be re-identified based on eye-movements. It is important to understand that users can be reliably authenticated, but not re-identified if a pool of users is large. This can be simply interpreted as that eye-movement signal contains enough information to indicate that this person is the same or different, but it does not contain enough unique information to allow to find one specific person in a large pool of people. This is very different from iris-based biometrics where there is enough information to distinguish a person in a large group of people.</p>\n<p>&nbsp;</p>\n<p>The findings that eye-movement signal contains units of information that are person specific were verified via statistical methods, which were based on the idea of improving authentication accuracy by selecting uncorrelated eye motility-derived features that have high degree of temporal persistence. The use of statistical methods in eye-movement-driven biometrics helps to understand and interpret the nature of the phenomenon of why fingerprint-like accuracy of user authentication can be achieved from eye-movement signal.&nbsp;</p>\n<p>&nbsp;</p>\n<p>We have also created machine learning (ML) architectures that outperformed statistical methods and provided higher authentication accuracy while requiring less data to do so, making eye-movement-driven authentication comparable to a 4-digit pin in terms of its performance, and thus making it a practical authentication method that can be considered for actual use.</p>\n<p>&nbsp;</p>\n<p>Interestingly we found that features extracted by ML architecture from eye-movement signal follow recommendation of the statistical theory that was created by analyzing hand crafted features. ML based features are normally distributed, correlated between themselves only weekly, and are temporally persistent. Further research is required to better understand this phenomenon.&nbsp;</p>\n<p>&nbsp;</p>\n<p>While ML methods allow to achieve best authentication performance, we feel that conventional statistical pipeline allows to specifically understand why it is possible to answer following questions by analyzing information encoded in eye-movements: &ldquo;How to assess neurological health of a person using same features that are employed for person authentication?&rdquo;, &ldquo;How such human states as fatigue, emotions, stress affect eye-movement signal and the performance of eye-movement biometrics system in the authentication and health assessment mode?&rdquo;, &ldquo;How quality of the captured eye tracking signal affects the performance of the eye-movement-driven biometric system in authentication and health assessment mode?&rdquo;. We feel that if such questions are answered with ML methods alone it would not provide a meaningful insight why certain level of accuracy is achieved on a specific dataset and how this level of performance will perform on a different set of data. Eye-movements provide a beautiful and analytically tenable ecosystem where it is possible to understand the neurological component that initiates the movement, oculomotor plant that executes them and a gaze estimation pipeline that assesses the state of the eye. While ML black box can achieve a certain accuracy number it does not explain why exactly this level of performance is actually possible.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>We have also verified the efficacy of eye-movements as a tool against print attacks - printed images of the human eye that are presented to a biometric system.</p>\n<p>&nbsp;</p>\n<p>We have made publicly available the eye-movement datasets that were recorded as a result of this line of work to facilitate future research in the domain of eye-movement biometrics.</p>\n<p>&nbsp;</p>\n<p>Our findings of high authentication accuracy and spoofing resistance have positive implications for future virtual and augmented reality platforms, which are expected to incorporate eye tracking hardware to support better display quality and enable other applications of eye tracking. Assuming that eye motility signal capture on such platforms can be done with high enough quality, eye-movements can be used as one of the most secure ways to authenticate people in VR/AR devices or even provide broader user understanding while following strict privacy guidelines.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/29/2023<br>\n\t\t\t\t\tModified by: Oleg&nbsp;V&nbsp;Komogortsev</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project concentrated on understanding highly dynamic and individualistic traits related to eye-movements and their relationship to internal, non-visible, anatomical properties of the human eye and the brain\u2019s strategies for guiding visual attention to assess the utility of eye-movement biometrics &ndash; an accurate and spoof resistant method of person\u2019s authentication.\n\n \n\nWe found individual differences in ways people move their eyes on macro and micro scale. If eye motility is recorded with high enough quality the differences in eye-movement patterns of any two individuals are such that it is possible to distinguish between them with an accuracy comparable to fingerprints. This discovery validates eye-movements as an authentication method for devices that have eye tracking capabilities. This is an important finding that will allow to potentially create accurate and spoof resistant device-unlock features aided by eye-movement analysis. \n\n \n\nWe also found via theoretical analysis and the empirical work with the data that eye-movement-driven biometrics cannot be employed for identification purposes when the pool of users is large. This finding has large privacy-related implications in the positive way, because it puts away fears that people can be somehow be re-identified based on eye-movements. It is important to understand that users can be reliably authenticated, but not re-identified if a pool of users is large. This can be simply interpreted as that eye-movement signal contains enough information to indicate that this person is the same or different, but it does not contain enough unique information to allow to find one specific person in a large pool of people. This is very different from iris-based biometrics where there is enough information to distinguish a person in a large group of people.\n\n \n\nThe findings that eye-movement signal contains units of information that are person specific were verified via statistical methods, which were based on the idea of improving authentication accuracy by selecting uncorrelated eye motility-derived features that have high degree of temporal persistence. The use of statistical methods in eye-movement-driven biometrics helps to understand and interpret the nature of the phenomenon of why fingerprint-like accuracy of user authentication can be achieved from eye-movement signal. \n\n \n\nWe have also created machine learning (ML) architectures that outperformed statistical methods and provided higher authentication accuracy while requiring less data to do so, making eye-movement-driven authentication comparable to a 4-digit pin in terms of its performance, and thus making it a practical authentication method that can be considered for actual use.\n\n \n\nInterestingly we found that features extracted by ML architecture from eye-movement signal follow recommendation of the statistical theory that was created by analyzing hand crafted features. ML based features are normally distributed, correlated between themselves only weekly, and are temporally persistent. Further research is required to better understand this phenomenon. \n\n \n\nWhile ML methods allow to achieve best authentication performance, we feel that conventional statistical pipeline allows to specifically understand why it is possible to answer following questions by analyzing information encoded in eye-movements: \"How to assess neurological health of a person using same features that are employed for person authentication?\", \"How such human states as fatigue, emotions, stress affect eye-movement signal and the performance of eye-movement biometrics system in the authentication and health assessment mode?\", \"How quality of the captured eye tracking signal affects the performance of the eye-movement-driven biometric system in authentication and health assessment mode?\". We feel that if such questions are answered with ML methods alone it would not provide a meaningful insight why certain level of accuracy is achieved on a specific dataset and how this level of performance will perform on a different set of data. Eye-movements provide a beautiful and analytically tenable ecosystem where it is possible to understand the neurological component that initiates the movement, oculomotor plant that executes them and a gaze estimation pipeline that assesses the state of the eye. While ML black box can achieve a certain accuracy number it does not explain why exactly this level of performance is actually possible.\n\n \n\n \n\nWe have also verified the efficacy of eye-movements as a tool against print attacks - printed images of the human eye that are presented to a biometric system.\n\n \n\nWe have made publicly available the eye-movement datasets that were recorded as a result of this line of work to facilitate future research in the domain of eye-movement biometrics.\n\n \n\nOur findings of high authentication accuracy and spoofing resistance have positive implications for future virtual and augmented reality platforms, which are expected to incorporate eye tracking hardware to support better display quality and enable other applications of eye tracking. Assuming that eye motility signal capture on such platforms can be done with high enough quality, eye-movements can be used as one of the most secure ways to authenticate people in VR/AR devices or even provide broader user understanding while following strict privacy guidelines.\n\n\t\t\t\t\tLast Modified: 01/29/2023\n\n\t\t\t\t\tSubmitted by: Oleg V Komogortsev"
 }
}