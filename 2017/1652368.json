{
 "awd_id": "1652368",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Lineage-driven Fault Injection",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Erik Brunvand",
 "awd_eff_date": "2017-03-01",
 "awd_exp_date": "2022-02-28",
 "tot_intn_awd_amt": 475000.0,
 "awd_amount": 483000.0,
 "awd_min_amd_letter_date": "2017-01-25",
 "awd_max_amd_letter_date": "2021-03-01",
 "awd_abstract_narration": "With each passing day, Americans become more dependent on large-scale, cloud-based distributed systems for everything from commerce (e.g., shopping for groceries) to transportation (e.g. booking a cab) to communication (e.g., making plans via a chat app) to storage (e.g., archiving baby photos).  These systems operate at a scale where machine crashes and network interruptions are the rule rather than the exception.  Unfortunately, writing fault tolerant software -- programs that attempt to detect and mitigate such failures, in order to prevent data loss or system unavailability -- remains an art form.  Application programmers, data analysts and mobile developers have few tools to help them implement, maintain and debug fault-tolerant systems. To address these needs, we introduce lineage-driven fault injection (LDFI), a novel bug-finding methodology that uses data lineage to reason backwards (from effects to causes) about combinations of faults could prevented desired system outcomes. If the project succeeds, it will improve the overall availability and resiliency of these increasingly critical systems. It will also provide a new class of tools for the distributed programmers who must build and maintain cloud systems, identifying and explaining bugs at all stages of the development process, from specification to post-production.  \r\n\r\n\r\nLDFI combines ideas from database theory, distributed systems, formal methods, optimization, reliability and data visualization. By exercising only the faults that it can prove could have affected a known good outcome, LDFI can identify invariant violations and user-visible failures using orders of magnitude fewer executions than conventional techniques such as random or heuristic fault injection. LDFI generalizes the notion of data lineage beyond data management , using it to explain large-scale system outcomes and to identify redundant computations that can mask faults. Given a model of a system's built-in redundancy, LDFI can use state-of-the-art solvers to generate hypotheses to exercise via fault injection infrastructures. This project engenders new research in areas such as query explanations, low-overhead system tracing, and how-to analysis.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Alvaro",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Peter A Alvaro",
   "pi_email_addr": "palvaro@ucsc.edu",
   "nsf_id": "000727366",
   "pi_start_date": "2017-01-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Cruz",
  "inst_street_address": "1156 HIGH ST",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA CRUZ",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8314595278",
  "inst_zip_code": "950641077",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "CA19",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA SANTA CRUZ",
  "org_prnt_uei_num": "",
  "org_uei_num": "VXUFPE4MCZH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Cruz",
  "perf_str_addr": null,
  "perf_city_name": "Santa Cruz",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "950641077",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "CA19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 190000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 103000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 95000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 95000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-f62b6754-7fff-d1a3-cf79-d094365462b7\"> </span></p>\n<p dir=\"ltr\"><span>We depend on distributed systems for increasingly many aspects of our day-to-day lives, and yet they remain stubbornly difficult to reason about, to program, to test, to extend, and to debug.&nbsp; These difficulties arise from a combination of fundamental issues unique to distributed systems (in particular, uncertainty about which computers may </span><span>fail</span><span> in some way) and incidental issues that arise in software systems at scale (such as large and highly dynamic codebases developed by separate teams).</span></p>\n<p dir=\"ltr\"><span>The LDFI project began with the insight that observability infrastructure, which permits us, via mechanisms such as tracing and lineage, to reason about distributed system executions from the outside, may hold the key to addressing cross-cutting concerns ranging from theoretical issues such as program correctness to operational ones such as incident response.</span></p>\n<p dir=\"ltr\"><span>Our initial research targeted the problem of bug finding.&nbsp; Identifying latent bugs in distributed systems is challenging: the combinatorial space of possible schedules under fault makes exhaustive testing intractable, while purely random approaches such as Chaos Engineering are unlikely to find corner case bugs triggered by deep perturbations. The prototype for Lineage-driven Fault Injection (LDFI) asked the following question: </span><span>if we had perfect lineage information that described how distributed system outcomes were achieved, could we use it to test them more effectively and efficiently than existing techniques?</span><span>&nbsp; The answer was yes! By observing the fine-grained lineage that </span><span>explains</span><span> how distributed system executions achieve correct states, LDFI was able to build models of how the systems use redundancy (e.g., data replication, message retry, fallback paths) to overcome failures.&nbsp; By using these models to prune the space of possible executions that needed to be searched, LDFI outperformed random testing approaches by an order of magnitude. Unfortunately, the \"perfect information\" requirement constrained the applicability of the approach, requiring programs to be written in a custom language for a solver that only simulated distributed executions.</span></p>\n<p dir=\"ltr\"><span>Supported by this award, our lab extended the LDFI approach from a narrow research prototype into a flexible methodology for finding bugs in large-scale, microservice-based systems. We generalized LDFI to integrate with state-of-the-art tracing and fault injection infrastructures, and showed the viability of this approach during our collaboration with Netflix (SoCC 2016). Since then, we have applied a similar methodology at Uber and Ebay.&nbsp; Because not all distributed systems are instrumented with the sophisticated tracers and fault injectors available at these industry leaders, our lab pursued innovation in tracing and fault injection infrastructures exploring co-designs that implement both concerns via the mechanism of context propagation (HotCloud 2019, SoCC 2021), as well as new forms of data lineage that better model systems with time-varying state (SoCC 2018).</span></p>\n<p dir=\"ltr\"><span>Discovering that a bug exists ? for example, by witnessing an error in a test ? is just the tip of the iceberg. The next step is to localize the problem to a single component and begin the process of debugging and ultimately repairing the program (or at the very least, taking some remediation that allows the system to continue running!) Lineage that helped us to trigger a bug can surely be of some use in these tasks as well. We focused on these problems in the final phase of the project, which proceeded in two phases. In the first, returning to the perfect information assumptions with which the LDFI began, we showed that differential reasoning over rich lineage can not only </span><span>localize</span><span> bugs to individual lines of code, but can in many cases give us enough information to </span><span>automatically repair</span><span> the programs (CIDR 2019).&nbsp; In the second, we showed that even under the pragmatic assumption that our only source of lineage was distributed traces, differential reasoning can effectively localize large-scale site incidents to individual components, where mitigations can be applied (arXiv 2022).</span></p>\n<p dir=\"ltr\"><span>The results and impacts of the LDFI project have been disseminated to the public at every available opportunity.&nbsp; This includes not only publication in top peer-reviewed venues and collaborations with industry leaders, but via articles trade publications (e.g., ACM Queue and O'Reilly), appearances at top industry conferences (e.g., Qcon, Velocity), and incorporation into course material at UC Santa Cruz.&nbsp; Materially and via mentorship these projects supported two Doctoral students and two Masters students.</span></p>\n<p dir=\"ltr\">&nbsp;</p>\n<p dir=\"ltr\">&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/04/2022<br>\n\t\t\t\t\tModified by: Peter&nbsp;A&nbsp;Alvaro</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nWe depend on distributed systems for increasingly many aspects of our day-to-day lives, and yet they remain stubbornly difficult to reason about, to program, to test, to extend, and to debug.  These difficulties arise from a combination of fundamental issues unique to distributed systems (in particular, uncertainty about which computers may fail in some way) and incidental issues that arise in software systems at scale (such as large and highly dynamic codebases developed by separate teams).\nThe LDFI project began with the insight that observability infrastructure, which permits us, via mechanisms such as tracing and lineage, to reason about distributed system executions from the outside, may hold the key to addressing cross-cutting concerns ranging from theoretical issues such as program correctness to operational ones such as incident response.\nOur initial research targeted the problem of bug finding.  Identifying latent bugs in distributed systems is challenging: the combinatorial space of possible schedules under fault makes exhaustive testing intractable, while purely random approaches such as Chaos Engineering are unlikely to find corner case bugs triggered by deep perturbations. The prototype for Lineage-driven Fault Injection (LDFI) asked the following question: if we had perfect lineage information that described how distributed system outcomes were achieved, could we use it to test them more effectively and efficiently than existing techniques?  The answer was yes! By observing the fine-grained lineage that explains how distributed system executions achieve correct states, LDFI was able to build models of how the systems use redundancy (e.g., data replication, message retry, fallback paths) to overcome failures.  By using these models to prune the space of possible executions that needed to be searched, LDFI outperformed random testing approaches by an order of magnitude. Unfortunately, the \"perfect information\" requirement constrained the applicability of the approach, requiring programs to be written in a custom language for a solver that only simulated distributed executions.\nSupported by this award, our lab extended the LDFI approach from a narrow research prototype into a flexible methodology for finding bugs in large-scale, microservice-based systems. We generalized LDFI to integrate with state-of-the-art tracing and fault injection infrastructures, and showed the viability of this approach during our collaboration with Netflix (SoCC 2016). Since then, we have applied a similar methodology at Uber and Ebay.  Because not all distributed systems are instrumented with the sophisticated tracers and fault injectors available at these industry leaders, our lab pursued innovation in tracing and fault injection infrastructures exploring co-designs that implement both concerns via the mechanism of context propagation (HotCloud 2019, SoCC 2021), as well as new forms of data lineage that better model systems with time-varying state (SoCC 2018).\nDiscovering that a bug exists ? for example, by witnessing an error in a test ? is just the tip of the iceberg. The next step is to localize the problem to a single component and begin the process of debugging and ultimately repairing the program (or at the very least, taking some remediation that allows the system to continue running!) Lineage that helped us to trigger a bug can surely be of some use in these tasks as well. We focused on these problems in the final phase of the project, which proceeded in two phases. In the first, returning to the perfect information assumptions with which the LDFI began, we showed that differential reasoning over rich lineage can not only localize bugs to individual lines of code, but can in many cases give us enough information to automatically repair the programs (CIDR 2019).  In the second, we showed that even under the pragmatic assumption that our only source of lineage was distributed traces, differential reasoning can effectively localize large-scale site incidents to individual components, where mitigations can be applied (arXiv 2022).\nThe results and impacts of the LDFI project have been disseminated to the public at every available opportunity.  This includes not only publication in top peer-reviewed venues and collaborations with industry leaders, but via articles trade publications (e.g., ACM Queue and O'Reilly), appearances at top industry conferences (e.g., Qcon, Velocity), and incorporation into course material at UC Santa Cruz.  Materially and via mentorship these projects supported two Doctoral students and two Masters students.\n \n \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 06/04/2022\n\n\t\t\t\t\tSubmitted by: Peter A Alvaro"
 }
}