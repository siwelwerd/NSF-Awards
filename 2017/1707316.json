{
 "awd_id": "1707316",
 "agcy_id": "NSF",
 "tran_type": "CoopAgrmnt",
 "awd_istr_txt": "Cooperative Agreement",
 "awd_titl_txt": "NeuroNex Technology Hub: Multimodal Integrated Neural Technologies (MINT) - Connecting Physiology to Functional Mapping",
 "cfda_num": "47.074",
 "org_code": "08080200",
 "po_phone": "7032927163",
 "po_email": "rsbeaman@nsf.gov",
 "po_sign_block_name": "Reed Beaman",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 3100000.0,
 "awd_amount": 7750000.0,
 "awd_min_amd_letter_date": "2017-07-31",
 "awd_max_amd_letter_date": "2023-07-18",
 "awd_abstract_narration": "In order to understand how neural signals propagate to conduct specific functions in behaving animals and how individual neurons are physically connected in the context of behavior, advanced tools should be available at the hands of neuroscientists. The Multimodal Integrated Neural Technologies (MINT) hub aims to develop and provide tools that are able to read from and modulate neurons at multiple sites independently at high spatial and temporal resolutions. The hub will disseminate tools and methods to correlate the recorded cell activity with the structural connection. In this way, the connectivity of active cells can be visualized, labeled, and traced for detailed functional mapping. The mission of the MINT hub is to provide a collection of tools, synergistically developed, integrated, and available to the neuroscience community, to address one theme: connecting neurophysiology and structural analysis with a greater scale and resolution. The synergistic integration of these neurotechnology tools at the MINT Hub would accelerate the rate of discovery in neuroscience. This in turn can be expected to pave the way to improved treatments for neurological disorders and to breakthroughs in artificial intelligence, especially neuromorphic computing. The MINT hub will provide annual training workshops for new users to be familiar with new technologies and able to use them effectively. To achieve sustainability, the hardware tools will be actively marketed to the community and those with sustainable volume will be transitioned to commercialization partners. Importantly, this program will cross-train neuroscience and technology personnel during the course of this program, resulting in preparation of a new generation of multi-disciplinary engineers and scientists.\r\n\r\nThis hub uniquely combines high-density electrodes, chemical sensing, optical stimulation, and cell labeling. Fiberless high-density optoelectrodes can allow optical stimulation of individual or few neurons with high specificity and selectivity using monolithically integrated micro-LEDs or optical waveguides on multi-shank silicon probes. Carbon microthreads will be used to create advanced arrays that will dramatically increase the ability to record from interconnected neurons and label those cells with high accuracy. Advanced metal alloys will also be used to greatly enhance the signal-to-noise ratio of miniaturized electrodes. The MINT hub will innovate viral vector delivery and tissue clearing in the nervous system and combine these with multispectral labeling for intact cell phenotyping. Furthermore, an open-source software will be developed to improve the accuracy and efficiency of anatomical reconstruction for creating connectivity maps. The MINT hub will validate the developed tools and methods in three in-vivo experiments to exemplify what can be accomplished when the proposed modalities and methods are synergistically integrated. This NeuroTechnology Hub award is co-funded by the Division of Emerging Frontiers within the Directorate for Biological Sciences, and the Division of Chemical, Bioengineering, Environmental & Transport Systems within the Directorate for Engineering as part of the BRAIN Initiative and NSF's Understanding the Brain activities.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "BIO",
 "org_dir_long_name": "Directorate for Biological Sciences",
 "div_abbr": "DBI",
 "org_div_long_name": "Division of Biological Infrastructure",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Euisik",
   "pi_last_name": "Yoon",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Euisik Yoon",
   "pi_email_addr": "esyoon@umich.edu",
   "nsf_id": "000326857",
   "pi_start_date": "2017-07-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gyorgy",
   "pi_last_name": "Buzsaki",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gyorgy Buzsaki",
   "pi_email_addr": "gyorgy.buzsaki@nyumc.org",
   "nsf_id": "000370901",
   "pi_start_date": "2017-07-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Weiland",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "James D Weiland",
   "pi_email_addr": "weiland@umich.edu",
   "nsf_id": "000561652",
   "pi_start_date": "2017-07-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Cynthia",
   "pi_last_name": "Chestek",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cynthia Chestek",
   "pi_email_addr": "cchestek@umich.edu",
   "nsf_id": "000606328",
   "pi_start_date": "2017-07-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Viviana",
   "pi_last_name": "Gradinaru",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Viviana Gradinaru",
   "pi_email_addr": "viviana@caltech.edu",
   "nsf_id": "000663888",
   "pi_start_date": "2017-07-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "1301 Beal Ave",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092122",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "534500",
   "pgm_ele_name": "Engineering of Biomed Systems"
  },
  {
   "pgm_ele_code": "727500",
   "pgm_ele_name": "Cross-BIO Activities"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 1550000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 1550000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 3049997.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 1600003.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Multimodal Integrated Neural Technologies (MINT) project focused on developing, improving and disseminating novel tools to investigate the nervous system throughout the experimental pipeline, from molecular approaches and activity recording tools to probe the brain, to tissue postprocessing and anatomical circuitry mapping. Our project encompassed multiple fronts:</p>\n<p>First, the improvement of the tissue-recording/stimulation surface interface in neural electrodes is an area of opportunity for successful recording/stimulation of neural tissue. Nanofractal platinum-iridium electrode materials were demonstrated on multiple substrates, including gold on silicon, gold on polyimide, and carbon. Robustness of the material when deposited on carbon was demonstrated in vivo and in vitro. This material has high efficiency for neural stimulation.</p>\n<p>Second, silicon-based electrodes are a reliable tool for recording the electrical signals generated from individual neurons. The predefined recording layout when combined with microscopic light sources (cell-sized &micro;LEDs), allows for the control of very small volumes of light sensitive neurons, gaining not only genetic specificity but also high temporal and spatial resolution optical stimulation while simultaneously recording extracellular signals. With this aim in mind, we developed an artifact-free &micro;LED optoelectrode platform in 2 modalities, normal density (32 recording and 12 &micro;LEDs) and high-density (up to 128 recording and 64 &micro;LEDs) for covering large brain areas and local circuit interrogation.</p>\n<p>Along with the development of the &micro;LED optoelectrodes, we have also developed a system front end capable of simultaneously recording from all 128 channels and individually controlling 64 &micro;LEDs in a small and lightweight package, that when paired with our high-density optoelectrode, allows for high spatial-temporal resolution circuit interrogation in the freely behaving rodent.</p>\n<p>Third, Carbon fiber electrodes have many benefits including chemical sensing and minimal tissue damage. The Chestek Lab has developed high density carbon fiber arrays that can be used for chronic single cell electrophysiological recordings or dopaminergic measurements.</p>\n<p>Fourth, we have developed new methods and identified new reagents for characterizing the structure and function of neurons in the rodent brain. We developed a high-throughput method for identifying improved viral vectors for gene delivery to the brain.&nbsp; We integrated clearing methods for imaging large tissue volumes with non-invasive viral vector labeling of neurons with fluorescent proteins, including to characterize the morphology of neurons implicated with pathology in a model of a rare genetic disorder.&nbsp; We also developed reagents for improved viral vector-based optogenetic manipulation of neuron activity and methods to integrate optogenetics with cell type and morphology determination. In parallel, we have released review and protocol publications on tissue clearing and viral vector production, conducted in-person workshops and one-on-one consultations, and broadly disseminated reagents to ensure that researchers are able to adopt our technologies. As a result of these efforts, the viral vectors identified and implemented in this project have been received by hundreds of laboratories worldwide and are driving diverse discoveries resulting in dozens of publications each year.</p>\n<p>Fifth, we continued to improve Brainbow AAVs usefulness and accessibility. We disseminated Brainbow AAVs via Addgene and the University of Michigan Vector Core. To better promote the adaptation of Brainbow in neuroscience, we also established a collaboration with the University of Zurich Vector Facility (VVF), which started to produce and disseminate AAV.Brainbow1 series of viruses in 2024.</p>\n<p>Along with the Brainbow technology and in an effort to disseminate computational tools for neuronal tracing and reconstruction, we made significant contributions, including but not limited to the nTracer2 software development. In particular, we published GitHub repositories to share several software:</p>\n<p>1) SISF, a novel scalable 3D image file format for cloud storage and retrieval of large-scale brain image data from HPC (high-performance computing) storage clusters with very fast I/O speed. (GitHub link)</p>\n<p>2) We develop a content delivery network (CDN) for converting between SISF and other file formats. This CDN is written in C/C++ to have optimal data I/O speed for retrieval of any arbitrary imaging volume within the whole SISF storage space. (GitHub link)</p>\n<p>3)&nbsp; We develop a novel lossy compression pipeline, which combines the optimal quantization and compression artifact minimization algorithms developed in our lab. We show that this pipeline outperforms lossless compression in data reduction performance by tens to ten thousand-fold while preserving very high fidelity of image quantification analysis, including single molecular localization, AI-based segmentation, and neuron reconstruction. (GitHub link).</p>\n<p>Altogether these tools conform to a wide range of approaches that tackle different aspects of brain physiology with cutting-edge technologies, enabling neuroscientists to study the structure and map the nervous system with unprecedented accuracy.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 08/31/2024<br>\nModified by: Euisik&nbsp;Yoon</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe Multimodal Integrated Neural Technologies (MINT) project focused on developing, improving and disseminating novel tools to investigate the nervous system throughout the experimental pipeline, from molecular approaches and activity recording tools to probe the brain, to tissue postprocessing and anatomical circuitry mapping. Our project encompassed multiple fronts:\n\n\nFirst, the improvement of the tissue-recording/stimulation surface interface in neural electrodes is an area of opportunity for successful recording/stimulation of neural tissue. Nanofractal platinum-iridium electrode materials were demonstrated on multiple substrates, including gold on silicon, gold on polyimide, and carbon. Robustness of the material when deposited on carbon was demonstrated in vivo and in vitro. This material has high efficiency for neural stimulation.\n\n\nSecond, silicon-based electrodes are a reliable tool for recording the electrical signals generated from individual neurons. The predefined recording layout when combined with microscopic light sources (cell-sized LEDs), allows for the control of very small volumes of light sensitive neurons, gaining not only genetic specificity but also high temporal and spatial resolution optical stimulation while simultaneously recording extracellular signals. With this aim in mind, we developed an artifact-free LED optoelectrode platform in 2 modalities, normal density (32 recording and 12 LEDs) and high-density (up to 128 recording and 64 LEDs) for covering large brain areas and local circuit interrogation.\n\n\nAlong with the development of the LED optoelectrodes, we have also developed a system front end capable of simultaneously recording from all 128 channels and individually controlling 64 LEDs in a small and lightweight package, that when paired with our high-density optoelectrode, allows for high spatial-temporal resolution circuit interrogation in the freely behaving rodent.\n\n\nThird, Carbon fiber electrodes have many benefits including chemical sensing and minimal tissue damage. The Chestek Lab has developed high density carbon fiber arrays that can be used for chronic single cell electrophysiological recordings or dopaminergic measurements.\n\n\nFourth, we have developed new methods and identified new reagents for characterizing the structure and function of neurons in the rodent brain. We developed a high-throughput method for identifying improved viral vectors for gene delivery to the brain. We integrated clearing methods for imaging large tissue volumes with non-invasive viral vector labeling of neurons with fluorescent proteins, including to characterize the morphology of neurons implicated with pathology in a model of a rare genetic disorder. We also developed reagents for improved viral vector-based optogenetic manipulation of neuron activity and methods to integrate optogenetics with cell type and morphology determination. In parallel, we have released review and protocol publications on tissue clearing and viral vector production, conducted in-person workshops and one-on-one consultations, and broadly disseminated reagents to ensure that researchers are able to adopt our technologies. As a result of these efforts, the viral vectors identified and implemented in this project have been received by hundreds of laboratories worldwide and are driving diverse discoveries resulting in dozens of publications each year.\n\n\nFifth, we continued to improve Brainbow AAVs usefulness and accessibility. We disseminated Brainbow AAVs via Addgene and the University of Michigan Vector Core. To better promote the adaptation of Brainbow in neuroscience, we also established a collaboration with the University of Zurich Vector Facility (VVF), which started to produce and disseminate AAV.Brainbow1 series of viruses in 2024.\n\n\nAlong with the Brainbow technology and in an effort to disseminate computational tools for neuronal tracing and reconstruction, we made significant contributions, including but not limited to the nTracer2 software development. In particular, we published GitHub repositories to share several software:\n\n\n1) SISF, a novel scalable 3D image file format for cloud storage and retrieval of large-scale brain image data from HPC (high-performance computing) storage clusters with very fast I/O speed. (GitHub link)\n\n\n2) We develop a content delivery network (CDN) for converting between SISF and other file formats. This CDN is written in C/C++ to have optimal data I/O speed for retrieval of any arbitrary imaging volume within the whole SISF storage space. (GitHub link)\n\n\n3) We develop a novel lossy compression pipeline, which combines the optimal quantization and compression artifact minimization algorithms developed in our lab. We show that this pipeline outperforms lossless compression in data reduction performance by tens to ten thousand-fold while preserving very high fidelity of image quantification analysis, including single molecular localization, AI-based segmentation, and neuron reconstruction. (GitHub link).\n\n\nAltogether these tools conform to a wide range of approaches that tackle different aspects of brain physiology with cutting-edge technologies, enabling neuroscientists to study the structure and map the nervous system with unprecedented accuracy.\n\n\n\t\t\t\t\tLast Modified: 08/31/2024\n\n\t\t\t\t\tSubmitted by: EuisikYoon\n"
 }
}