{
 "awd_id": "1717607",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Enabling Software Engineering Virtual Assistant Technology",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 407218.0,
 "awd_amount": 407218.0,
 "awd_min_amd_letter_date": "2017-05-22",
 "awd_max_amd_letter_date": "2017-05-22",
 "awd_abstract_narration": "The objective of this research project is to address key barriers in adapting natural language processing techniques to problems in creating virtual assistants for software engineering.  Virtual assistants such as Siri, Cortana, and Alexa are claiming an increasing role in computing for everyday tasks, but multiple barriers prevent existing virtual assistant technology from being applied to software engineering tasks.  The long-term goal of the project is that virtual assistants will improve productivity for software engineers.\r\n\r\nThis proposal targets two of those barriers: 1) conversation analysis and modeling, and 2) reference expression generation.  The first of these problems, in a nutshell, is that experiments in natural language modeling conversations tend to cover topics with similar outcomes, while conversations about software may have a much wider range of possible outcomes.  The second problem is that much research in natural language processing is focused on how humans refer to physical objects that have attributes that are universally preferred while in contrast, software artifacts tend not to have measurable attributes that people use as descriptions.  The chief broader impact is an application to assistive technology for persons who are visually impaired.  Virtual assistants have the potential to alleviate barriers-to-entry into computing careers faced by visually impaired persons by creating a voice interface for answering software development questions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Collin",
   "pi_last_name": "McMillan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Collin McMillan",
   "pi_email_addr": "collin.mcmillan@nd.edu",
   "nsf_id": "000626801",
   "pi_start_date": "2017-05-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Notre Dame",
  "inst_street_address": "940 GRACE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "NOTRE DAME",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "5746317432",
  "inst_zip_code": "465565708",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "IN02",
  "org_lgl_bus_name": "UNIVERSITY OF NOTRE DAME DU LAC",
  "org_prnt_uei_num": "FPU6XGFXMBE9",
  "org_uei_num": "FPU6XGFXMBE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Notre Dame",
  "perf_str_addr": "Fitzpatrick Hall",
  "perf_city_name": "Notre Dame",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "465565637",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "IN02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 407218.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The research objective of this proposal is to address key barriers to adapting natural language processing techniques to problems in creating virtual assistants for software engineering.<br /><br />Programmers frequently face a dilemma when they have questions: get an answer right away by asking a fellow programmer, or continue struggling to answer the question him or herself. On the one hand, asking another programmer is easy and will save time in the short term. But on the other hand, the question will interrupt the teammate and cause him or her to have reduced productivity. This dilemma has been reported in many studies both within and outside software engineering as well as the PI's own preliminary work. Programmers' favorite source of information is other programmers, but it is a limited resource due to time constraints.<br /><br />Documentation is frequently cited as a second source. Documentation has the advantage of including information specific to the project on which the programmer is working. It also is inexpensive to use and can be made easily accessible online. But, documentation is expensive to produce and is static. The only information that is available is what the author decides to write. If the programmer has a question not in the documentation, he or she may turn to a search engine or programming forum, but these sources rarely have project-specific information. They may have general programming help, but not answers to questions about specific or closed-source projects.<br /><br />A tantalizing alternative is a virtual assistant. Virtual assistants such as Siri, Cortana, and Alexa are claiming an increasing role in computing for everyday tasks. They simplify duties such as planning meals and finding music, and are part of a broader trend towards automated productivity services. Virtual assistants for software engineering have been envisioned for decades, with the dream being a system that can mimic the answers that human teammates would give. With recent breakthroughs in virtual assistant technology, this dream seems within reach.<br /><br />This project centers around the following three research tasks:<br /><br />Task 1: Create a robust model of question/answer conversations between programmers. The goal of this task is to model what programmers do when asking and answering questions, so that we can A) determine the type of question a programmer is asking and B) predict the type of appropriate response. Current models used in software engineering treat conversations somewhat shallowly, such as a \"bag of words,\" which do not capture high-level concepts such as intent. This task first involves collecting conversation data and includes experiments in which researchers are embedded in industrial environments. The task then involves using a mixture of qualitative and quantitative analysis to determine classes of turns in the conversations, and training ML algorithms to predict the order of the classes of turns. The idea is that our predictive models will represent the flow of a conversation that a virtual assistant should use, and is based on NLP work in conversation analysis.<br /><br />Task 2: Generate expressions that refer to software components in a human-like manner. The goal of this task is to study how programmers refer to software components, so that we can design algorithms that extract the data necessary to make similar references and to express that data in the correct form. The idea is that in Task 1, we will discover the appropriate time in the conversation for the data to be expressed, but in Task 2 we generate an appropriate expression. The key research challenge for us will be to represent the software project as a knowledge base without requiring manual effort to define an ontology, and design an algorithm expressive enough to generate references on the fly. Our work in this task is inspired by work on reference expression generation in NLP and extensive SE research on mining software repositories. However, note that we do not necessarily include surface realization as part of the generation process, since that is typically a different task in NLP.<br /><br />Task 3: Evaluate the techniques in both laboratory and real-life settings. Natural language generation systems are typically evaluated on two criteria: A) expressiveness, which is the percent of items for which the algorithm can create a correct reference, and B) suitability/similarity of the references to human experts. While expressiveness can largely be evaluated in cross-validation experiments or even by proof, suitability to human experts will require onsite experiments both in open-source communities and at industrial partners.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/08/2021<br>\n\t\t\t\t\tModified by: Collin&nbsp;Mcmillan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe research objective of this proposal is to address key barriers to adapting natural language processing techniques to problems in creating virtual assistants for software engineering.\n\nProgrammers frequently face a dilemma when they have questions: get an answer right away by asking a fellow programmer, or continue struggling to answer the question him or herself. On the one hand, asking another programmer is easy and will save time in the short term. But on the other hand, the question will interrupt the teammate and cause him or her to have reduced productivity. This dilemma has been reported in many studies both within and outside software engineering as well as the PI's own preliminary work. Programmers' favorite source of information is other programmers, but it is a limited resource due to time constraints.\n\nDocumentation is frequently cited as a second source. Documentation has the advantage of including information specific to the project on which the programmer is working. It also is inexpensive to use and can be made easily accessible online. But, documentation is expensive to produce and is static. The only information that is available is what the author decides to write. If the programmer has a question not in the documentation, he or she may turn to a search engine or programming forum, but these sources rarely have project-specific information. They may have general programming help, but not answers to questions about specific or closed-source projects.\n\nA tantalizing alternative is a virtual assistant. Virtual assistants such as Siri, Cortana, and Alexa are claiming an increasing role in computing for everyday tasks. They simplify duties such as planning meals and finding music, and are part of a broader trend towards automated productivity services. Virtual assistants for software engineering have been envisioned for decades, with the dream being a system that can mimic the answers that human teammates would give. With recent breakthroughs in virtual assistant technology, this dream seems within reach.\n\nThis project centers around the following three research tasks:\n\nTask 1: Create a robust model of question/answer conversations between programmers. The goal of this task is to model what programmers do when asking and answering questions, so that we can A) determine the type of question a programmer is asking and B) predict the type of appropriate response. Current models used in software engineering treat conversations somewhat shallowly, such as a \"bag of words,\" which do not capture high-level concepts such as intent. This task first involves collecting conversation data and includes experiments in which researchers are embedded in industrial environments. The task then involves using a mixture of qualitative and quantitative analysis to determine classes of turns in the conversations, and training ML algorithms to predict the order of the classes of turns. The idea is that our predictive models will represent the flow of a conversation that a virtual assistant should use, and is based on NLP work in conversation analysis.\n\nTask 2: Generate expressions that refer to software components in a human-like manner. The goal of this task is to study how programmers refer to software components, so that we can design algorithms that extract the data necessary to make similar references and to express that data in the correct form. The idea is that in Task 1, we will discover the appropriate time in the conversation for the data to be expressed, but in Task 2 we generate an appropriate expression. The key research challenge for us will be to represent the software project as a knowledge base without requiring manual effort to define an ontology, and design an algorithm expressive enough to generate references on the fly. Our work in this task is inspired by work on reference expression generation in NLP and extensive SE research on mining software repositories. However, note that we do not necessarily include surface realization as part of the generation process, since that is typically a different task in NLP.\n\nTask 3: Evaluate the techniques in both laboratory and real-life settings. Natural language generation systems are typically evaluated on two criteria: A) expressiveness, which is the percent of items for which the algorithm can create a correct reference, and B) suitability/similarity of the references to human experts. While expressiveness can largely be evaluated in cross-validation experiments or even by proof, suitability to human experts will require onsite experiments both in open-source communities and at industrial partners.\n\n\t\t\t\t\tLast Modified: 09/08/2021\n\n\t\t\t\t\tSubmitted by: Collin Mcmillan"
 }
}