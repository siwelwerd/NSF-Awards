{
 "awd_id": "1717775",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR:  Small:  Collaborative Research:  EUReCa:  Enabling Untethered VR/AR System via Human-centric Graphic Computing and Distributed Data Processing",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Erik Brunvand",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 249799.0,
 "awd_amount": 249799.0,
 "awd_min_amd_letter_date": "2017-08-03",
 "awd_max_amd_letter_date": "2017-08-03",
 "awd_abstract_narration": "Virtual Reality (VR) and Augmented Reality (AR) devices, especially their mobile versions are newly emergent technologies. However, a major challenge that VR/AR technologies faces is the gap between the increasing needs for graphic and data processing and the limited computing capability of the mobile hardware. Two researchers from GMU and Duke form a team to develop an innovative VR/AR system, namely, \"EUReCa\", which tackles the challenge of human-centric graphic processing and distributed data processing. This research studies VR/AR system design using standard workloads to understand the computation source utilization that leads to development of usage model, and reduces the computation loads via task allocation, thereby enhancing the efficiency and scalability of computation. The research outcomes will benefit both research and industry at large by integrating the innovations of human interaction and advanced data processing technologies. The education plan enhances existing curricula and pedagogy by integrating interdisciplinary modules on computer graphic, embedded systems, and machine learning with newly developed teaching practices, and gives special attention to women and underrepresented minority groups.\r\n \r\nThe project performs three tasks. Task 1 models the computation resource utilization of VR/AR systems by considering the system configuration and dynamics of user operations. Task 2 explores efficient human-centric graphic rendering framework for reducing computation loads of VR/AR systems. Task 3 exploits novel schemes to enhance computation efficiency via balancing the computation loads and data allocations in graphic rendering and deep neural network (DNN) applications. The techniques will be evaluated on mobile devices.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiang",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiang Chen",
   "pi_email_addr": "xchen26@gmu.edu",
   "nsf_id": "000737352",
   "pi_start_date": "2017-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "George Mason University",
  "inst_street_address": "4400 UNIVERSITY DR",
  "inst_street_address_2": "",
  "inst_city_name": "FAIRFAX",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "7039932295",
  "inst_zip_code": "220304422",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "VA11",
  "org_lgl_bus_name": "GEORGE MASON UNIVERSITY",
  "org_prnt_uei_num": "H4NRWLFCDF43",
  "org_uei_num": "EADLFP7Z72E5"
 },
 "perf_inst": {
  "perf_inst_name": "George Mason University",
  "perf_str_addr": "4400 University Drive",
  "perf_city_name": "Fairfax",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "220304442",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "VA11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 249799.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>=Overview=</p>\n<p>Virtual Reality (VR) devices and Augmented Reality (AR), especially the ones on mobile platforms, have replaced smartphones as two new major emerging markets of electronics. Specifically, AR overlays virtual objects on a user&rsquo;s real world with interactive visual supplementations, while VR places the user in a virtual world with immersive experience. However, the challenges that VR/AR technologies faces are the increasing gap between the needs for graphic and data processing and limited computing capability of the hardware. And existing VR/AR devices unfortunately cannot effectively tackle the two aspects of the above challenge simultaneously. So, how to realize a VR/AR system that is untethered from the constraints of computation capacity and power consumption has become a common commitment of all the researchers in the community</p>\n<p>&nbsp;</p>\n<p>=Intellectual Merit=</p>\n<p>Three major research tasks were proposed to address the computation performance enhancement of VR/AR systems in three perspectives &ndash; computation resource, computation load, and computation capacity: Task 1 demystified the computation resource utilization of VR/AR systems, by considering the impacts of static configuration of the system and dynamics of user operations. The obtained analysis and understanding served as the theory and statistic foundations of the other tasks. Task 2 defined a human-centric graphic rendering framework for computation load reduction of VR/AR systems. Task 3 exploited computation capacity escalation innovations, taking advantages of the distributed data processing and the balanced data allocation in critical tasks (i.e., graphic rendering, deep neural network).</p>\n<p>&nbsp;</p>\n<p>=Major Outcomes=</p>\n<p>The expected research outcome of the proposed project is an integrated human/device co-design methodology that can be applied to not only VR/AR systems but other interactive mobile platforms. The proposed computation performance enhancement can effectively reduce the computation load, escalate the computation capacity while preserve optional functionality and user experience. Following the proposed research tasks, we have the following major research outcomes (with more than 15 publications):</p>\n<p>1.&nbsp;&nbsp;&nbsp;&nbsp; We investigated the dynamic mobile computing scenarios (regarding heterogeneous software and hardware configurations, application deployment differences) and develop effective data processing and optimization schemes (for both graphic rendering and artificial intelligence (AI) oriented sensing data processing). These works could largely accelerate the computing performance of mobile (and more generic edge) systems, enhance the context adaptation capability, and escalate the user experiences in various mobile devices (esp. VR/AR devices). These outcomes are well presented in a serious of publications in EDA, mobile system, and computer architecture domains.</p>\n<p>2.&nbsp;&nbsp;&nbsp;&nbsp; We examined the human factor in the mobile computing systems, especially with the multi-media processing for VR/AR applications. Specifically, we analyzed the human visual attention mechanisms in the intelligent data processing flow, which also promoted a highly cited survey paper. Leveraging such thorough understanding, (a) we delivered a series high-performing computing optimization schemes based on human vision attention; (b) we developed a set of new computing libraries for fine-grained image feature-oriented computing paradigm (while conventional paradigms are mainly oriented by pixels); (c) we improved a series of VR/AR related visual computing applications.</p>\n<p>3.&nbsp;&nbsp;&nbsp;&nbsp; We exploited a series of works targeting large-scale computing systems and distributed mobile systems to balance the computation loads and data allocations. Specifically, some emerging techniques were incorporated during the recent research (e.g., heterogeneous edge collaboration, federated learning). These works set a foundation of profound development for this project, especially beyond 2021 when large-scale &ldquo;metaverse&rdquo; concept is revived, where large-scale VR/AR systems play the major role.</p>\n<p>The results of the project build a solid foundation for the next-generation wearable devices with untethered mobile VR/AR system and the support of innovative interactive applications with advanced critical algorithms. Such a foundation will bridge the divergence of the mobile system and the computational intelligence societies in the relevant research from the viewpoints of both hardware and software.</p>\n<p>&nbsp;</p>\n<p>=Broader Impacts=</p>\n<p>During the project, we have built close collaboration with Microsoft, IBM, Comcast and Facebook, especially in the VR/AR and intelligent computing areas. Through these collaborations, our research benefits VR/AR research and industry at large by inspiring an interactive design philosophy between the human-centric design and advanced data processing technologies for system performance (e.g., power and bandwidth) and scalability. The results lead to a holistic methodology composed of human computer interaction, machine learning, software optimization, and an integrated software/hardware co-design.</p>\n<p>Benefited by this project, the education plan well enhanced existing curricula by integrating interdisciplinary modules on computer graphic, embedded system, and machine learning with innovative teaching practices. And three new courses are proposed at GMU. Three Ph.D. students are graduated and started their careers in both industry and academia (one is dedicated supported by this project, while the others collaboratively worked on this project). Special attentions were given to women and underrepresented minority groups.</p>\n<p>Moreover, the broader impact of the project is well reached by wide result dissemination via research publications, seminars, workshops, short courses, modern media, and upcoming technology transfer activities.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/02/2022<br>\n\t\t\t\t\tModified by: Xiang&nbsp;Chen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n=Overview=\n\nVirtual Reality (VR) devices and Augmented Reality (AR), especially the ones on mobile platforms, have replaced smartphones as two new major emerging markets of electronics. Specifically, AR overlays virtual objects on a user\u2019s real world with interactive visual supplementations, while VR places the user in a virtual world with immersive experience. However, the challenges that VR/AR technologies faces are the increasing gap between the needs for graphic and data processing and limited computing capability of the hardware. And existing VR/AR devices unfortunately cannot effectively tackle the two aspects of the above challenge simultaneously. So, how to realize a VR/AR system that is untethered from the constraints of computation capacity and power consumption has become a common commitment of all the researchers in the community\n\n \n\n=Intellectual Merit=\n\nThree major research tasks were proposed to address the computation performance enhancement of VR/AR systems in three perspectives &ndash; computation resource, computation load, and computation capacity: Task 1 demystified the computation resource utilization of VR/AR systems, by considering the impacts of static configuration of the system and dynamics of user operations. The obtained analysis and understanding served as the theory and statistic foundations of the other tasks. Task 2 defined a human-centric graphic rendering framework for computation load reduction of VR/AR systems. Task 3 exploited computation capacity escalation innovations, taking advantages of the distributed data processing and the balanced data allocation in critical tasks (i.e., graphic rendering, deep neural network).\n\n \n\n=Major Outcomes=\n\nThe expected research outcome of the proposed project is an integrated human/device co-design methodology that can be applied to not only VR/AR systems but other interactive mobile platforms. The proposed computation performance enhancement can effectively reduce the computation load, escalate the computation capacity while preserve optional functionality and user experience. Following the proposed research tasks, we have the following major research outcomes (with more than 15 publications):\n\n1.     We investigated the dynamic mobile computing scenarios (regarding heterogeneous software and hardware configurations, application deployment differences) and develop effective data processing and optimization schemes (for both graphic rendering and artificial intelligence (AI) oriented sensing data processing). These works could largely accelerate the computing performance of mobile (and more generic edge) systems, enhance the context adaptation capability, and escalate the user experiences in various mobile devices (esp. VR/AR devices). These outcomes are well presented in a serious of publications in EDA, mobile system, and computer architecture domains.\n\n2.     We examined the human factor in the mobile computing systems, especially with the multi-media processing for VR/AR applications. Specifically, we analyzed the human visual attention mechanisms in the intelligent data processing flow, which also promoted a highly cited survey paper. Leveraging such thorough understanding, (a) we delivered a series high-performing computing optimization schemes based on human vision attention; (b) we developed a set of new computing libraries for fine-grained image feature-oriented computing paradigm (while conventional paradigms are mainly oriented by pixels); (c) we improved a series of VR/AR related visual computing applications.\n\n3.     We exploited a series of works targeting large-scale computing systems and distributed mobile systems to balance the computation loads and data allocations. Specifically, some emerging techniques were incorporated during the recent research (e.g., heterogeneous edge collaboration, federated learning). These works set a foundation of profound development for this project, especially beyond 2021 when large-scale \"metaverse\" concept is revived, where large-scale VR/AR systems play the major role.\n\nThe results of the project build a solid foundation for the next-generation wearable devices with untethered mobile VR/AR system and the support of innovative interactive applications with advanced critical algorithms. Such a foundation will bridge the divergence of the mobile system and the computational intelligence societies in the relevant research from the viewpoints of both hardware and software.\n\n \n\n=Broader Impacts=\n\nDuring the project, we have built close collaboration with Microsoft, IBM, Comcast and Facebook, especially in the VR/AR and intelligent computing areas. Through these collaborations, our research benefits VR/AR research and industry at large by inspiring an interactive design philosophy between the human-centric design and advanced data processing technologies for system performance (e.g., power and bandwidth) and scalability. The results lead to a holistic methodology composed of human computer interaction, machine learning, software optimization, and an integrated software/hardware co-design.\n\nBenefited by this project, the education plan well enhanced existing curricula by integrating interdisciplinary modules on computer graphic, embedded system, and machine learning with innovative teaching practices. And three new courses are proposed at GMU. Three Ph.D. students are graduated and started their careers in both industry and academia (one is dedicated supported by this project, while the others collaboratively worked on this project). Special attentions were given to women and underrepresented minority groups.\n\nMoreover, the broader impact of the project is well reached by wide result dissemination via research publications, seminars, workshops, short courses, modern media, and upcoming technology transfer activities. \n\n\t\t\t\t\tLast Modified: 01/02/2022\n\n\t\t\t\t\tSubmitted by: Xiang Chen"
 }
}