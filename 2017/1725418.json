{
 "awd_id": "1725418",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: High-Performance Computational Standards For Redistricting",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Brian Humes",
 "awd_eff_date": "2017-09-15",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 211306.0,
 "awd_amount": 211306.0,
 "awd_min_amd_letter_date": "2017-08-14",
 "awd_max_amd_letter_date": "2017-08-14",
 "awd_abstract_narration": "General Abstract\r\nThis project develops computational tools that objectively evaluate redistricting plans, and automate the creation of redistricting plans to satisfy particular criteria selected by users. The tool will provide a mechanism for decision-makers to use when negotiating redistricting plans, eliminating the inherent bias that arises when the data and the ability to propose plans are available to only a few political interests. The project will entail multiple elements, namely:  formulate the redistricting problem as a discrete optimization problem, introduce quantitative measurements to score maps on a wide set of criteria, create novel optimization algorithms customized for the redistricting problem to identify maps that score well on given criteria, and create a computational tool that allows states, individuals, and political parties to negotiate redistricting plans. In addition to the development of the computational tool, this project will engage in a detailed study of how to use computational models to shed new substantive insight and aid in the creation of fairness standards in the American redistricting process. Such standards have been elusive despite decades of effort. The broader impact of the work seeks to transform the upcoming future redistricting rounds by opening it up to participation to a broader and more diverse group of stakeholders.  Likewise the tool will provide greater flexibility and enhanced capabilities for developing redistricting plans than ever before. In the research realm, the algorithm development will also be applicable to large-scale optimization problems that utilize massively parallel computing architecture. The project also contributes to graduate education, providing instruction about the application of computational approaches to an array of social scientific questions.\r\n\r\nTechnical Abstract\r\nThe contributions of this work span a variety of disciplines including political science, law, computer science, math, operations research, and supercomputing. In the computer science and supercomputing realm, the research will tune and enable a parallel genetic algorithm library to scale to hundreds of thousands of processors. The algorithm advances operations research heuristics for large combinatorial optimization problems. The implementation is a hybrid metaheuristic that combines the search capabilities of evolutionary algorithms with refinements for diversification and intensification to empower a more efficient and effective search process. The mathematical approach yields new quantitative measures of political phenomenon. In political science and law, the project will create a new ability to synthesize and analyze massive amounts of data that will yield new substantive insights about fairness standards for redistricting as well as the effect and impact of redistricting on the democratic process.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Wendy",
   "pi_last_name": "Tam",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Wendy K Tam",
   "pi_email_addr": "wendy.k.tam@vanderbilt.edu",
   "nsf_id": "000439353",
   "pi_start_date": "2017-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yan",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yan Liu",
   "pi_email_addr": "yanliu@illinois.edu",
   "nsf_id": "000741538",
   "pi_start_date": "2017-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "506 S. Wright Street",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "137100",
   "pgm_ele_name": "Political Science"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 211306.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our project developed computational tools for redistricting. &nbsp;We further used these tools to engage in a detailed study of how to use computational models to shed new substantive insights into and aid in the creation of fairness standards for the redistricting process.</p>\n<p><br />Our work involved developing the theoretical and mathematical underpinnings of the model as well as the actual coding of the computational algorithm. From a theoretical perspective, we have explored the statistical and mathematical foundations of simulation and optimization models. We developed an algorithm that harnesses the massive computing power that is available on the world's fastest supercomputers. &nbsp;Our theoretic work is not confined to redistricting, but is broadly applicable across a wide range of substantive problems. Our published work has appeared in the scholarly journals of a variety of disciplines including political science, law, public policy, statistics, physics, operations research, and computer science. &nbsp;We also wrote for the general scientific community with publications in Nature and Science.</p>\n<p>Our ideas and algorithms were used in a variety of redistricting law suits, argued before state and federal courts as well as the Supreme Court. &nbsp;This work involved a novel conceptualization of partisan fairness and the development of metrics for this purpose.</p>\n<p>We presented our work before many different types of audiences, including K-12 students, high school groups, undergraduates, quantitative finance groups, lawyers and judges, as well as academic audiences with specializations in mathematics, law, political science, and statistics.</p>\n<p>We anticpate that our research will have an impact on the 2020 redistricting cycle. &nbsp;Our work has changed how people conceptualize what can be done with redistricting, but the change in the actual practice is in the hands of politicians and independent redistricting commissions.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/01/2020<br>\n\t\t\t\t\tModified by: Wendy&nbsp;K&nbsp;Cho</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOur project developed computational tools for redistricting.  We further used these tools to engage in a detailed study of how to use computational models to shed new substantive insights into and aid in the creation of fairness standards for the redistricting process.\n\n\nOur work involved developing the theoretical and mathematical underpinnings of the model as well as the actual coding of the computational algorithm. From a theoretical perspective, we have explored the statistical and mathematical foundations of simulation and optimization models. We developed an algorithm that harnesses the massive computing power that is available on the world's fastest supercomputers.  Our theoretic work is not confined to redistricting, but is broadly applicable across a wide range of substantive problems. Our published work has appeared in the scholarly journals of a variety of disciplines including political science, law, public policy, statistics, physics, operations research, and computer science.  We also wrote for the general scientific community with publications in Nature and Science.\n\nOur ideas and algorithms were used in a variety of redistricting law suits, argued before state and federal courts as well as the Supreme Court.  This work involved a novel conceptualization of partisan fairness and the development of metrics for this purpose.\n\nWe presented our work before many different types of audiences, including K-12 students, high school groups, undergraduates, quantitative finance groups, lawyers and judges, as well as academic audiences with specializations in mathematics, law, political science, and statistics.\n\nWe anticpate that our research will have an impact on the 2020 redistricting cycle.  Our work has changed how people conceptualize what can be done with redistricting, but the change in the actual practice is in the hands of politicians and independent redistricting commissions.\n\n\t\t\t\t\tLast Modified: 09/01/2020\n\n\t\t\t\t\tSubmitted by: Wendy K Cho"
 }
}