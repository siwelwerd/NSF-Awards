{
 "awd_id": "1715475",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Integrating Flexible Normalization Models of Visual Cortex into Deep Neural Networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 349996.0,
 "awd_amount": 349996.0,
 "awd_min_amd_letter_date": "2017-08-17",
 "awd_max_amd_letter_date": "2017-08-17",
 "awd_abstract_narration": "Recent advances in artificial intelligence models of deep neural networks have led to tremendous progress in artificial systems that recognize objects in scenes, and in a host of other applications such as speech recognition, and robotics. Although deep neural networks often incorporate computations inspired by the brain, these have typically been applied in a fairly simple and restrictive manner, rather than based on more principled models of neural processing in the brain. Using vision as a paradigmatic example, this project proposes that artificial systems can benefit from integrating approaches that have been developed in biological models of neural processing of scenes. The biological models make use of contextual flexibility, whereby neurons are influenced in a rich way by the image structure that spatially surrounds a given object or feature. This flexibility is expected to improve task performance in deep neural networks, and to impact development of artificial systems that are more compatible with human cognition. The resulting framework, with its deep architecture spanning multiple layers of processing, will, in turn, make predictions about neural processing in the brain, which will impact the neuroscience and cognitive science communities. \r\n\r\nThis project focuses specifically on normalization, a nonlinear computation that is ubiquitous in the brain, and that has been shown to benefit task performance in deep neural networks. The project will develop more principled strategies for determining normalization in deep convolutional neural networks. The main focus will be on learning a form of flexible normalization based on scene statistics models of visual cortex. In this framework, normalization is recruited only to the degree that a visual input is inferred to contain statistical dependencies across space. Performance will be tested for classification and segmentation on large-scale image databases, and will also target tasks more suited to mid-level vision such as figure/ground judgment. This will result in better understanding of normalization nonlinearities in deep convolutional networks, and the implications of flexible normalization for task performance and generalization compared to other forms of normalization. Biologically, normalization is poorly understood beyond primary visual cortex. The models developed will help shed light on the equivalence of this inference for middle cortical areas, and make predictions about what image structure leads to recruitment of normalization. This project will also include launching of an interdisciplinary Deep Learning Discussion Group.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Odelia",
   "pi_last_name": "Schwartz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Odelia Schwartz",
   "pi_email_addr": "odelia@cs.miami.edu",
   "nsf_id": "000154468",
   "pi_start_date": "2017-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Miami",
  "inst_street_address": "1320 SOUTH DIXIE HIGHWAY STE 650",
  "inst_street_address_2": "",
  "inst_city_name": "CORAL GABLES",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3052843924",
  "inst_zip_code": "331462919",
  "inst_country_name": "United States",
  "cong_dist_code": "27",
  "st_cong_dist_code": "FL27",
  "org_lgl_bus_name": "UNIVERSITY OF MIAMI",
  "org_prnt_uei_num": "",
  "org_uei_num": "RQMFJGDTQ5V3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Miami",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "331462926",
  "perf_ctry_code": "US",
  "perf_cong_dist": "27",
  "perf_st_cong_dist": "FL27",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 349996.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project focused on the incorporation of biologically inspired computations, and specifically divisive normalization, into artificial deep neural networks, and the implications for both biological and artificial vision. Normalization is prevalent in neuroscience and in artificial intelligence models of deep neural networks. However, the normalization computation in deep neural networks has often been implemented in a restrictive manner. We focused on a model known as flexible normalization, that captures understanding about the brain in the first area of cortical visual processing (area V1). In the model, the response of a neuron to a visual input in a center location is suppressed via normalization, to the degree that the center and surround visual structure in the image (according to the V1 feature selectivity) are deemed statistically similar. This relates to highlighting salient information in which the center is different from the surround.</span></p>\n<p><span>We extended the flexible normalization approach to more complex visual features beyond V1, by incorporating flexible normalization into deep neural networks. Unlike V1, which can be described in terms of simple features such as orientation, scale, and spatial position, similarly parsimonious coordinate frames for intermediate levels of visual processing in the brain, are not well understood. Flexible normalization suppressed the responses of artificial neurons in intermediate layers of the deep neural network, when the center and surround were deemed statistically similar according to more complex features, such as textures and other geometric arrangements of features tiling the space. Intermediate layers were more effective than the first layer in suppressing background homogeneous structure and therefore highlighting salient information. The resulting model makes predictions about when normalization is recruited in middle areas of the visual cortex in the brain. This is useful for studying contextual influences that go beyond V1 features in neuroscience and psychology. We further incorporated normalization in multiple layers of deep neural networks that were trained on visual object classification tasks. We found that for shallower neural networks with less layers, a heuristic of flexible normalization (particularly due to incorporating a weighted normalization signal) outperformed other forms of normalization that are commonly used in machine learning. This is useful in artificial intelligence for designing models that require fewer layers to achieve task performance, by appropriately choosing the divisive normalization nonlinearity.</span></p>\n<p><span>As part of the broad impacts, we ran a new deep learning discussion group at the University of Miami, including students and faculty. We used this forum for learning, exchanging ideas, stimulating discussions and interactions, and bringing people up to speed about recent advances in the broader field of deep learning.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/23/2021<br>\n\t\t\t\t\tModified by: Odelia&nbsp;Schwartz</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project focused on the incorporation of biologically inspired computations, and specifically divisive normalization, into artificial deep neural networks, and the implications for both biological and artificial vision. Normalization is prevalent in neuroscience and in artificial intelligence models of deep neural networks. However, the normalization computation in deep neural networks has often been implemented in a restrictive manner. We focused on a model known as flexible normalization, that captures understanding about the brain in the first area of cortical visual processing (area V1). In the model, the response of a neuron to a visual input in a center location is suppressed via normalization, to the degree that the center and surround visual structure in the image (according to the V1 feature selectivity) are deemed statistically similar. This relates to highlighting salient information in which the center is different from the surround.\n\nWe extended the flexible normalization approach to more complex visual features beyond V1, by incorporating flexible normalization into deep neural networks. Unlike V1, which can be described in terms of simple features such as orientation, scale, and spatial position, similarly parsimonious coordinate frames for intermediate levels of visual processing in the brain, are not well understood. Flexible normalization suppressed the responses of artificial neurons in intermediate layers of the deep neural network, when the center and surround were deemed statistically similar according to more complex features, such as textures and other geometric arrangements of features tiling the space. Intermediate layers were more effective than the first layer in suppressing background homogeneous structure and therefore highlighting salient information. The resulting model makes predictions about when normalization is recruited in middle areas of the visual cortex in the brain. This is useful for studying contextual influences that go beyond V1 features in neuroscience and psychology. We further incorporated normalization in multiple layers of deep neural networks that were trained on visual object classification tasks. We found that for shallower neural networks with less layers, a heuristic of flexible normalization (particularly due to incorporating a weighted normalization signal) outperformed other forms of normalization that are commonly used in machine learning. This is useful in artificial intelligence for designing models that require fewer layers to achieve task performance, by appropriately choosing the divisive normalization nonlinearity.\n\nAs part of the broad impacts, we ran a new deep learning discussion group at the University of Miami, including students and faculty. We used this forum for learning, exchanging ideas, stimulating discussions and interactions, and bringing people up to speed about recent advances in the broader field of deep learning.\n\n\t\t\t\t\tLast Modified: 12/23/2021\n\n\t\t\t\t\tSubmitted by: Odelia Schwartz"
 }
}