{
 "awd_id": "1703957",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Medium: Collaborative Research: Fast Photorealistic Computer Graphics Rendering of Non-Smooth Surfaces",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 408000.0,
 "awd_min_amd_letter_date": "2017-06-21",
 "awd_max_amd_letter_date": "2021-06-14",
 "awd_abstract_narration": "Computer graphics is finding growing application to virtual visual prototyping for the design of materials and products where appearance is important.  Using graphics rendering on a display to replace physical prototypes could potentially make it faster and cheaper to bring new products and designs to market.  But such applications demand high fidelity in the appearance of specific real materials on displays with ever-higher resolution.  The fundamental problem is that current mathematical models for light reflection assume that details smaller than a pixel can be ignored, and replaced by smooth averages.  At high resolutions this assumption breaks down; most materials start to appear noisy, grainy, or glittery as one looks closer.  But to simply include microscopic detail in the model and continue with conventional rendering methods would be far too slow. This project will develop a range of methods to model the visible effects of sub-pixel details without greatly increasing the time and expense of rendering images.  The results of this research will generalize a broad range of material models used in computer graphics so that they work under close-range observation.  It will transform the field by fundamentally changing the definition of surface reflectance and by providing a suite of new tools for implementing and designing reflectance in industrial applications including automotive design, virtual prototyping, visual effects, and predictive product visualization.\r\n\r\nAccurately rendering the appearance of materials has always been a central problem of computer graphics.  With today's ever-higher display resolutions, and applications demanding exact reproduction of specific materials, the status quo in material modeling is reaching its limits.  The problem is that the standard approach to modeling surface reflectance, the Bi-directional Reflectance Distribution Function (BRDF), fundamentally assumes that surface roughness is far smaller than the scale of pixels.  But rough surfaces, which can be modeled by smooth BRDF models for more distant or lower-resolution views, start to appear noisy, grainy, or glittery as one looks closer and the effects of individual scattering elements become visible.  This produces \"shimmering\" or \"glints\" in a variety of materials that are difficult to model using current technology, including metallic paints used on cars, bead-blasted and brushed metal finishes popular for electronics, and the ubiquitous textured finishes on injection-molded plastic, as well as in fabrics, wood finishes and wood grain, and many other materials.  This project will develop new ways to think about surface reflection in terms of reflectance models that build in spatial and angular variation at their core, without assuming smoothness at small scales.  These models account for the visible effects of individual scattering features, and spatial and angular detail emerges naturally as the viewing and illumination conditions reveal it.  Several mathematical representations for detailed materials are proposed, covering both surface and subsurface effects, to form the core of a full end-to-end pipeline that spans new acquisition methods and rendering techniques.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ravi",
   "pi_last_name": "Ramamoorthi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ravi Ramamoorthi",
   "pi_email_addr": "ravir@cs.ucsd.edu",
   "nsf_id": "000486826",
   "pi_start_date": "2017-06-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 Gilman Dr",
  "perf_city_name": "La Jolla",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930404",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 400000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of our research is to create images of highly detailed surfaces with realistic materials.&nbsp; Our primary motivation is for computer graphics, to reproduce the intricate appearance of a scratched car door, the glints off the ocean, or the fine scratches on a teacup.&nbsp; However, there are also a variety of applications for manufacturing and advertising.&nbsp; Reproducing these effects involves simulating how light reflects off these highly detailed surfaces, which requires new mathematical tools as well as considering new mathematical models that study the wave nature of light.&nbsp; Moreover, we need to have new ways to model the materials in a scene like cloth or leather.&nbsp; In particular, we need to know how they reflect light towards the viewer.&nbsp; One can easily imagine applications like careful interior decoration, and visualization of new objects in ecommerce in one's living room with highly realistic effects in augmented or virtual reality.&nbsp;&nbsp;</p>\n<p><br />Our initial work in collaboration with colleagues at Cornell establishes a new method for creating realistic images of fine-scale detail, while considering the wave propagation of light to more accurately simulate real-world phenomena and include colored highlights.&nbsp; This provides more accurate results than the more conventional geometric optics models used so far in computer graphics, and can create beautiful imagery such as the scratches on kitchen cutlery, a realistic rendering of the speckle on a Macbook, or the brushed metal highlights on a tumbler.&nbsp; Moreover, the computation time does not introduce much overhead over more conventional approximations.&nbsp; The work has had substantial impact in subsequent methods that capture interference and wave optics properties of light such as speckle, iridescence etc.</p>\n<p><br />Subsequently, in collaboration with colleagues at Cornell, Adobe and Texas A&amp;M University, we have shown how detailed appearance, or more formally specular microgeometry, can be generated using modern deep learning or machine learning models by a variation of generative adversarial networks.&nbsp; This is the first such learning or AI-based method to create detailed realistic appearance and can be used with a variety of approaches including measured appearance data, wave optics and geometric optics.&nbsp; We develop a new partial evaluation strategy that enables computational efficiency, showcasing a variety of results, including for fabrics, and ways to design particular types of patterns.&nbsp;&nbsp;</p>\n<p><br />Other work in the learning direction has explored the use of neural networks to represent realistic and complex materials in a more unified fashion.&nbsp; With colleagues at Adobe, we have shown how the common mipmapping method in computer graphics to represent materials at a variety of different scales can be extended to a neural mipmap that can represent not just flat textures but general materials with shadowing and surface relief, whose appearance changes with lighting and viewing directions.&nbsp; Subsequently, we have extended these effects to capture accurate silhouettes and consider curvatures.&nbsp;&nbsp;</p>\n<p><br />The above represent only some highlights of work done at UCSD under the grant.&nbsp; We have also developed methods for very high quality portrait relighting from a relatively sparse set of images, partial work towards a method for photorealistic indoor scene datasets, and reconstruction methods for fast rendering in computer graphics using techniques known as photon mapping and path guiding.&nbsp; Some of these results are already having significant impact for other researchers using our datasets for their studies, and are being looked at by industry for adoption in practical systems.</p>\n<p><br />Within the broader impact of the grant, we have introduced a new online course on computer graphics rendering, which is simultaneously available to our local students and to the general public via UCSD Online.&nbsp; Nearly a 1,000 students have registered already for this course which teaches all of the steps towards building a modern path tracer for realistic image synthesis in computer graphics.&nbsp;&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/17/2022<br>\n\t\t\t\t\tModified by: Ravi&nbsp;Ramamoorthi</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663447919878_waveoptics1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663447919878_waveoptics1--rgov-800width.jpg\" title=\"Cutlery rendered with geometric and wave optics\"><img src=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663447919878_waveoptics1--rgov-66x44.jpg\" alt=\"Cutlery rendered with geometric and wave optics\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We present the first practical method for rendering specular reflection from arbitrary high-resolution microstructure (represented as discretizedheightfields) using wave optics, with more natural appearance and colored glints.  Insets show representative normal distributions/reflectance functions.</div>\n<div class=\"imageCredit\">Rendering Specular Microgeometry with Wave Optics by Yan, Hasan,  Walter, Marschner, Ramamoorthi</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ravi&nbsp;Ramamoorthi</div>\n<div class=\"imageTitle\">Cutlery rendered with geometric and wave optics</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448067889_waveoptics2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448067889_waveoptics2--rgov-800width.jpg\" title=\"Tumbler Rendered with Wave Optics\"><img src=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448067889_waveoptics2--rgov-66x44.jpg\" alt=\"Tumbler Rendered with Wave Optics\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The Tumbler scene rendered with two point lights and environment lighting, showing brushed aluminum with strong anisotropy. Insets compareour spectral method (top row) with the geometric method (bottom row). We see that the geometric method produces wider highlight peaks butnarrower highlights.</div>\n<div class=\"imageCredit\">Rendering Specular Geometry with Wave Optics by Yan, Hasan, Walter, Marschner, Ramamoorthi</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ravi&nbsp;Ramamoorthi</div>\n<div class=\"imageTitle\">Tumbler Rendered with Wave Optics</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448273593_portrait--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448273593_portrait--rgov-800width.jpg\" title=\"Super-Resolution Portrait Relighting\"><img src=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448273593_portrait--rgov-66x44.jpg\" alt=\"Super-Resolution Portrait Relighting\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our model (a) is able to produce accurate relighting results underhigh-frequency environments by super-resolving the light stage before performing image-based relighting [Debevec et al. 2000]. Using the light stage data as-provided (b) results in ghosting.</div>\n<div class=\"imageCredit\">Light Stage Super-Resolution: Continuous High-Frequency Relighting by Sun, Xu, Zhang, Fanello, Rhemann, Debevec, Tsai, Barron, Ramamoorthi</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ravi&nbsp;Ramamoorthi</div>\n<div class=\"imageTitle\">Super-Resolution Portrait Relighting</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448592106_alexgan--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448592106_alexgan--rgov-800width.jpg\" title=\"Learning Generative Models for Rendering Specular Microgeometry\"><img src=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448592106_alexgan--rgov-66x44.jpg\" alt=\"Learning Generative Models for Rendering Specular Microgeometry\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our technique renders specular microstructure by learning high-frequency angular patterns (which we term generalized NDFs normal distribution functions) from synthetic ormeasured examples. We utilize conditional generative adversarial networks (GANs).  The right two columns show example NDF images</div>\n<div class=\"imageCredit\">Learning Generative Models for Rendering Specular MicroGeometry by Kuznetsov, Hasan, Xu, Yan, Walter, Kalantari, Marschner, Ramamoorthi</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ravi&nbsp;Ramamoorthi</div>\n<div class=\"imageTitle\">Learning Generative Models for Rendering Specular Microgeometry</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448778180_neumip--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448778180_neumip--rgov-800width.jpg\" title=\"Representing Complex Visual Appearance Using Multi-Resolution Neural Materials\"><img src=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448778180_neumip--rgov-66x44.jpg\" alt=\"Representing Complex Visual Appearance Using Multi-Resolution Neural Materials\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our multi-resolution neural material representing Twisted Wool, rendered seamlessly among standard materials. The neural representation is trained using hundreds of reflectance queries per texel, across multiple resolutions, and is independent of the underlyinginput (here, displaced geometry).</div>\n<div class=\"imageCredit\">NeuMIP: Multi-Resolution Neural Materials by Kuznetsov, Mullia, Xu, Hasan, Ramamoorthi</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ravi&nbsp;Ramamoorthi</div>\n<div class=\"imageTitle\">Representing Complex Visual Appearance Using Multi-Resolution Neural Materials</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448950688_curved--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448950688_curved--rgov-800width.jpg\" title=\"Rendering Neural Materials on Curved Surfaces\"><img src=\"/por/images/Reports/POR/2022/1703957/1703957_10494926_1663448950688_curved--rgov-66x44.jpg\" alt=\"Rendering Neural Materials on Curved Surfaces\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Five different neural materials applied to curved bounding geometries. The materials are treated as silhouettebidirectional texture functions (SBTFs), are learned from synthetic microstructure data, and represented using a collection offeature textures and small fully connected neural networks.</div>\n<div class=\"imageCredit\">Rendering Neural Materials on Curved Surfaces by Kuznetsov, Wang, Mullia, Luan, Xu, Hasan, Ramamoorthi</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ravi&nbsp;Ramamoorthi</div>\n<div class=\"imageTitle\">Rendering Neural Materials on Curved Surfaces</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe goal of our research is to create images of highly detailed surfaces with realistic materials.  Our primary motivation is for computer graphics, to reproduce the intricate appearance of a scratched car door, the glints off the ocean, or the fine scratches on a teacup.  However, there are also a variety of applications for manufacturing and advertising.  Reproducing these effects involves simulating how light reflects off these highly detailed surfaces, which requires new mathematical tools as well as considering new mathematical models that study the wave nature of light.  Moreover, we need to have new ways to model the materials in a scene like cloth or leather.  In particular, we need to know how they reflect light towards the viewer.  One can easily imagine applications like careful interior decoration, and visualization of new objects in ecommerce in one's living room with highly realistic effects in augmented or virtual reality.  \n\n\nOur initial work in collaboration with colleagues at Cornell establishes a new method for creating realistic images of fine-scale detail, while considering the wave propagation of light to more accurately simulate real-world phenomena and include colored highlights.  This provides more accurate results than the more conventional geometric optics models used so far in computer graphics, and can create beautiful imagery such as the scratches on kitchen cutlery, a realistic rendering of the speckle on a Macbook, or the brushed metal highlights on a tumbler.  Moreover, the computation time does not introduce much overhead over more conventional approximations.  The work has had substantial impact in subsequent methods that capture interference and wave optics properties of light such as speckle, iridescence etc.\n\n\nSubsequently, in collaboration with colleagues at Cornell, Adobe and Texas A&amp;M University, we have shown how detailed appearance, or more formally specular microgeometry, can be generated using modern deep learning or machine learning models by a variation of generative adversarial networks.  This is the first such learning or AI-based method to create detailed realistic appearance and can be used with a variety of approaches including measured appearance data, wave optics and geometric optics.  We develop a new partial evaluation strategy that enables computational efficiency, showcasing a variety of results, including for fabrics, and ways to design particular types of patterns.  \n\n\nOther work in the learning direction has explored the use of neural networks to represent realistic and complex materials in a more unified fashion.  With colleagues at Adobe, we have shown how the common mipmapping method in computer graphics to represent materials at a variety of different scales can be extended to a neural mipmap that can represent not just flat textures but general materials with shadowing and surface relief, whose appearance changes with lighting and viewing directions.  Subsequently, we have extended these effects to capture accurate silhouettes and consider curvatures.  \n\n\nThe above represent only some highlights of work done at UCSD under the grant.  We have also developed methods for very high quality portrait relighting from a relatively sparse set of images, partial work towards a method for photorealistic indoor scene datasets, and reconstruction methods for fast rendering in computer graphics using techniques known as photon mapping and path guiding.  Some of these results are already having significant impact for other researchers using our datasets for their studies, and are being looked at by industry for adoption in practical systems.\n\n\nWithin the broader impact of the grant, we have introduced a new online course on computer graphics rendering, which is simultaneously available to our local students and to the general public via UCSD Online.  Nearly a 1,000 students have registered already for this course which teaches all of the steps towards building a modern path tracer for realistic image synthesis in computer graphics.  \n\n \n\n\t\t\t\t\tLast Modified: 09/17/2022\n\n\t\t\t\t\tSubmitted by: Ravi Ramamoorthi"
 }
}