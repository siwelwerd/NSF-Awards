{
 "awd_id": "1705047",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: Medium: Collaborative Research: Scale-Out Near-Data Acceleration of Machine Learning",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 600000.0,
 "awd_amount": 600000.0,
 "awd_min_amd_letter_date": "2017-06-28",
 "awd_max_amd_letter_date": "2021-04-23",
 "awd_abstract_narration": "A growing number of commercial and enterprise systems increasingly rely on machine learning algorithms. This shift is, on the one hand, due to the breakthroughs in machine learning algorithms that extract insights from massive amounts of data. Therefore, such systems need to process ever-increasing amounts of data, demanding higher memory bandwidth and capacity. However, the bandwidth between processors and off-chip memory has not increased due to various stringent physical constraints. Besides, data transfers between the processors and the off-chip memory consume orders of magnitude more energy than on-chip computation due to the disparity between interconnection and transistor scaling.\r\n\r\nExploiting recent 3D-stacking technology, the researcher community has explored near-data processing architectures that place processors and memory on the same chip. However, it is unclear whether or not such processing-in-memory (PIM) attempts will be successful for commodity computing systems due to the high cost of 3D-stacking technology and demanded change in existing processor, memory and/or applications. Faced with these challenges, the PIs are to investigate near-data processing platforms that do not require any change in processor, memory and applications, exploiting deep insights on commodity memory subsystems and network software stack. The success of this project will produce inexpensive but powerful near-data processing platforms that can directly run existing machine learning applications without any modification.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Josep",
   "pi_last_name": "Torrellas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Josep Torrellas",
   "pi_email_addr": "torrellas@cs.uiuc.edu",
   "nsf_id": "000488177",
   "pi_start_date": "2019-02-14",
   "pi_end_date": "2021-04-23"
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Nam Sung",
   "pi_last_name": "Kim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nam Sung Kim",
   "pi_email_addr": "nskim@illinois.edu",
   "nsf_id": "000512015",
   "pi_start_date": "2017-06-28",
   "pi_end_date": "2019-02-14"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nam Sung",
   "pi_last_name": "Kim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nam Sung Kim",
   "pi_email_addr": "nskim@illinois.edu",
   "nsf_id": "000512015",
   "pi_start_date": "2021-04-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618207473",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 324930.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 167035.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 108035.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The prevalence of connected computing platforms and recent breakthroughs in data sciences are transforming the IT industry, sparking a move toward solutions that extract insights from the copious amount of raw information. As such, these solutions need to process ever-increasing amounts of data, demanding higher memory bandwidth and capacity. However, off-chip memory bandwidth has been stagnant due to various stringent physical constraints. Additionally, off-chip data transfer requires orders of magnitude more energy than on-chip computation due to the disparity between the interconnection and transistor scaling. Faced with these challenges, the research community has begun to revisit the Processing-In-Memory (PIM) paradigm and attempt to surmount the limitations of the past PIM architectures using 3D and 2.5D stacking. Nevertheless, these inspiring efforts can suffer from the high cost of stacking processing elements atop DRAM, customizing DRAMs and CPUs, and rewriting existing applications. Moreover, these solutions do not address the ever-increasing capacity requirements that have become a defining characteristic of the modern data analytics and machine learning applications. This project aimed to tackle these shortcomings and developed various PIM technologies. Among these technologies, two (HBM-PIM and AxDIMM) are prototyped by a leading memory manufacturer. HBM-PIM and AxDIMM were later further explored by researchers in both the industry and the academia, profoundly impacting further research directions of high-performance and energy-efficient computing especially for emerging machine learning (ML) and artificial intelligence (AI) applications.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/25/2023<br>\n\t\t\t\t\tModified by: Nam Sung&nbsp;Kim</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe prevalence of connected computing platforms and recent breakthroughs in data sciences are transforming the IT industry, sparking a move toward solutions that extract insights from the copious amount of raw information. As such, these solutions need to process ever-increasing amounts of data, demanding higher memory bandwidth and capacity. However, off-chip memory bandwidth has been stagnant due to various stringent physical constraints. Additionally, off-chip data transfer requires orders of magnitude more energy than on-chip computation due to the disparity between the interconnection and transistor scaling. Faced with these challenges, the research community has begun to revisit the Processing-In-Memory (PIM) paradigm and attempt to surmount the limitations of the past PIM architectures using 3D and 2.5D stacking. Nevertheless, these inspiring efforts can suffer from the high cost of stacking processing elements atop DRAM, customizing DRAMs and CPUs, and rewriting existing applications. Moreover, these solutions do not address the ever-increasing capacity requirements that have become a defining characteristic of the modern data analytics and machine learning applications. This project aimed to tackle these shortcomings and developed various PIM technologies. Among these technologies, two (HBM-PIM and AxDIMM) are prototyped by a leading memory manufacturer. HBM-PIM and AxDIMM were later further explored by researchers in both the industry and the academia, profoundly impacting further research directions of high-performance and energy-efficient computing especially for emerging machine learning (ML) and artificial intelligence (AI) applications.\n\n\t\t\t\t\tLast Modified: 02/25/2023\n\n\t\t\t\t\tSubmitted by: Nam Sung Kim"
 }
}