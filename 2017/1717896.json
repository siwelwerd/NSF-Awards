{
 "awd_id": "1717896",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Efficiently Learning Neural Network Architectures with Applications",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 449920.0,
 "awd_amount": 449920.0,
 "awd_min_amd_letter_date": "2017-06-26",
 "awd_max_amd_letter_date": "2017-06-26",
 "awd_abstract_narration": "In the last few years there have been several breakthroughs in machine learning and artificial intelligence due to the success of tools for learning \"deep neural networks\" including the best computer program for playing Go, the best programs for automatically playing Atari games, and the best tools for several fundamental object-recognition tasks.  These are considered some of the most exciting new results in all of computer science.\r\n\r\nFrom a theoretical perspective, however, the mathematics underlying these neural networks is not as satisfying.  We have few rigorous results that explain how and why heuristics for learning deep neural networks perform so well in practice. The primary research goal of this proposal is to develop provably efficient algorithms for learning neural networks that have rigorous performance guarantees and give applications to related problems from machine learning.  Given the ubiquity of machine learning algorithms, this research will have direct impact on data science problems from a diverse set of fields including biology (protein interaction networks) and security (differential privacy).  The PI is also developing a new data mining course at UT-Austin that will incorporate the latest research from these areas.\r\n\r\nA central technical question of this work is that of the most expressive class of neural networks that can be provably learned in polynomial time.  Furthermore, the algorithm should be robust to noisy data.  A neural network can be thought of as a type of directed circuit where the internal nodes compute some activation function of a linear combination of the inputs.  The classical example of an activation function is a sigmoid, but the ReLU (rectified linear unit) has become very popular.  In a recent work, the PI showed that a neural network consisting of a sum of one layer of sigmoids is learnable in fully-polynomial time, even in the presence of noise.  This is the most expressive class known to be efficiently learnable.  Can this result be extended to more sophisticated networks?  This question has interesting tie-ins to kernel methods and kernel approximations.\r\n\r\nFor the ReLU activiation, the PI has shown that this problem is most likely computationally intractable in the worst case.  The intriguing question then becomes that of the minimal assumptions needed to show that these networks are computationally tractable.  In a recent work, the PI has shown that there are distributional assumptions that imply fully-polynomial-time algorithms for learning sophisticated networks of ReLUs.  Can these assumptions be weakened?  This work has to do with proving that certain algorithms do not overfit by using compression schemes.  Another type of assumption that the weights of the unknown network are chosen in some random way (as opposed to succeeding in the worst-case).  This corresponds to the notion of random initialization from machine learning.  Can we prove a type of smoothed analysis for learning neural networks, where we can give fully-polynomial-time learning algorithms for almost all networks?\r\n\r\nFinally, in this proposal we will explore what other tasks can be reduced to various types of simple neural network learning.  For example, the problem of one-bit compressed sensing can be viewed as learning a threshold activation using as few samples as possible.  Still, we lack a one-bit compressed sensing algorithm that has optimal tolerance for noise.  Another canonical example is matrix or tensor completion, where it is possible to reduce these challenges to learning with respect to polynomial activations.  Finding the proper regularization to ensure low sample complexity is an exciting area of research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Adam",
   "pi_last_name": "Klivans",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Adam R Klivans",
   "pi_email_addr": "klivans@cs.utexas.edu",
   "nsf_id": "000284027",
   "pi_start_date": "2017-06-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "101 E. 27th St.",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121532",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 449920.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project focused on developing advanced algorithms for learning neural networks and understanding the computational difficulty of related tasks.&nbsp;</p>\n<p>Backpropagation and gradient descent are the modern workhorses for training neural networks.&nbsp; While these algorithms work well in practice, it is possible that better algorithms are out there, waiting to be discovered.&nbsp; We have seen the importance of using big data and big compute for modern machine learning systems, but core questions about what algorithm to use remain unanswered.&nbsp;</p>\n<p>In this project we took the first steps towards an a theory of approximation algorithms for learning neural networks.&nbsp; We gave new algorithms for learning classes of neural networks that provably cannot be learned using gradient descent.&nbsp; We also gave strong new hardness results, showing that even in the simplest possible cases (Gaussian distribution, one layer networks), gradient descent will fail to achieve small test error.&nbsp;&nbsp;</p>\n<p>In particular, we gave an algorithm that shows how to learn any neural network with two nonlinear layers in polynomial time for any distribution over the unit sphere.&nbsp; This algorithm, called Alphatron, combines isotonic regression with kernel methods.&nbsp;</p>\n<p>We also gave the first fixed parameter tractable algorithm for learning ReLU networks of any depth with respect to the Gaussian distribution.&nbsp; Such a result provably cannot be obtained by gradient descent. Our algorithm suggests a novel preprocessing step for training deep nets.&nbsp;</p>\n<p>Our hardness results explained the difficulty of learning neural networks even with the domain is Gaussian.&nbsp; This shows that the difficulty of learning neural networks does not simply stem from discrete combinatorial or cryptographic primitives but is more related to the architecture itself.&nbsp;</p>\n<p>The hardness results we proved&nbsp;tell us that we need to better understand what distributional assumptions to take in order to find provably efficient algorithms.&nbsp; We came up with the first such assumption-- eigenvalue decay of the Gram matrix-- and showed that this assumption implies polynonmial-time learnability for neural networks.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/06/2022<br>\n\t\t\t\t\tModified by: Adam&nbsp;R&nbsp;Klivans</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project focused on developing advanced algorithms for learning neural networks and understanding the computational difficulty of related tasks. \n\nBackpropagation and gradient descent are the modern workhorses for training neural networks.  While these algorithms work well in practice, it is possible that better algorithms are out there, waiting to be discovered.  We have seen the importance of using big data and big compute for modern machine learning systems, but core questions about what algorithm to use remain unanswered. \n\nIn this project we took the first steps towards an a theory of approximation algorithms for learning neural networks.  We gave new algorithms for learning classes of neural networks that provably cannot be learned using gradient descent.  We also gave strong new hardness results, showing that even in the simplest possible cases (Gaussian distribution, one layer networks), gradient descent will fail to achieve small test error.  \n\nIn particular, we gave an algorithm that shows how to learn any neural network with two nonlinear layers in polynomial time for any distribution over the unit sphere.  This algorithm, called Alphatron, combines isotonic regression with kernel methods. \n\nWe also gave the first fixed parameter tractable algorithm for learning ReLU networks of any depth with respect to the Gaussian distribution.  Such a result provably cannot be obtained by gradient descent. Our algorithm suggests a novel preprocessing step for training deep nets. \n\nOur hardness results explained the difficulty of learning neural networks even with the domain is Gaussian.  This shows that the difficulty of learning neural networks does not simply stem from discrete combinatorial or cryptographic primitives but is more related to the architecture itself. \n\nThe hardness results we proved tell us that we need to better understand what distributional assumptions to take in order to find provably efficient algorithms.  We came up with the first such assumption-- eigenvalue decay of the Gram matrix-- and showed that this assumption implies polynonmial-time learnability for neural networks. \n\n \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 03/06/2022\n\n\t\t\t\t\tSubmitted by: Adam R Klivans"
 }
}