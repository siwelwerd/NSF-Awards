{
 "awd_id": "1704899",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: CHS: Medium: Collaborative Research: Improving Pedestrian Safety in Urban Cities using Intelligent Wearable Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2017-06-01",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 766642.0,
 "awd_amount": 766642.0,
 "awd_min_amd_letter_date": "2017-05-26",
 "awd_max_amd_letter_date": "2019-09-18",
 "awd_abstract_narration": "Using smartphones while walking poses an increasingly common safety problem for people in urban environments. Whether listening to music, texting, or talking, pedestrians that are absorbed with their smartphones are considerably less likely to notice important auditory cues of danger, such as the honks and sounds of approaching vehicles, putting pedestrians at far greater risk of being hit. This project aims to develop an intelligent wearable system that uses miniature microphones - embedded in earphones or headsets - to detect and locate approaching vehicles and warn the wearer of imminent dangers from cars, buses, motorbikes, trucks, and trams. \r\n\r\nThe system comprises multiple microphones embedded in a wearable headset, an ultra-low-power feature extraction and data  processing pipeline, and a set of machine-learning classifiers running on a smartphone. This project is organized in four research thrusts: (1) designing an architecture and data processing pipeline for a wearable system composed of heterogeneous embedded modules; (2) devising an ultra-low-power, analog, signal-processing Application-Specific Integrated Circuit (ASIC) for energy-efficient, on-board feature extraction; (3) modeling and optimizing machine-learning classifiers for acoustic event detection and localization; and (4) designing an interface and feedback mechanisms that are optimized for the users' perceptual, cognitive, and motor control abilities.\r\n\r\nThis research will help reduce pedestrian injuries and fatalities, and expand knowledge on designing wearable systems for enhancing safety in cities, workplaces, and the home. The underlying framework can be generalized to other systems - employing low-power signal processors and algorithms to solve real-time sensing and classification problems of many kinds. Research products will be made publicly available to anyone to apply these techniques in their own system designs. Course modules developed on embedded systems, mobile computing, and Internet-of-Things will be used at the three participating universities to train undergraduate and graduate students, and will be made available online.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiaofan",
   "pi_last_name": "Jiang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaofan Jiang",
   "pi_email_addr": "jiang@ee.columbia.edu",
   "nsf_id": "000721831",
   "pi_start_date": "2017-05-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Kinget",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Peter R Kinget",
   "pi_email_addr": "kinget@ee.columbia.edu",
   "nsf_id": "000235176",
   "pi_start_date": "2017-05-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100276902",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 392733.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 373909.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-09fe2eee-7fff-b8b5-6a2e-a73638ce3932\"> </span></p>\n<p dir=\"ltr\"><span>This Project Outcomes Report for the General Public is displayed verbatim as submitted by the Principal Investigator (PI) for this award. Any opinions, findings, and conclusions or recommendations expressed in this Report are those of the PI and do not necessarily reflect the views of the National Science Foundation; NSF has not approved or endorsed its content.</span></p>\n<p dir=\"ltr\"><span>This project developed a wearable system (PAWS) consisting of multi-channel audio sensors embedded in a headset to help detect and localize vehicles based on their engine and tire noises, from up to 60m away, and alert the user with low latency and high accuracy. The team demonstrated an effective design approach for low-latency wearable systems that partitions the data processing pipeline between feature extractions in the embedded front-end and machine learning classifiers in the smartphone. To further reduce power consumption of the battery-powered headset, the team designed a custom integrated circuit for computing relative delays between multiple channels of audio with nW power consumption, demonstrating the&nbsp;</span>feasibility of low-cost custom ASICs in wearable system design. In the second phase of the project, the team tackled the challenge of construction worker safety, where sounds of machineries are orders of magnitude louder than vehicles. This project introduced the idea of using probabilistic models of noises to update acoustic filters to remove targeted machine sounds. This work was published in top-tier sensing systems and IoT forums, including a paper at IoTJ 2019, a paper at IPSN 2021, a best presentation award at VNC 2018, and a best demo award at IoTDI 2018.</p>\n<p dir=\"ltr\">Recognizing the importance of audio in many applications beyond urban safety, in the third phase of the project, the team investigated a generalized adaptive audio filtering platform. This platform introduces the idea of content-informed beamforming (CIBF) that combines signal processing and machine learning, to enable custom sounds to be enhanced or filtered out, and can be easily adapted for a wide range of real-time and resource-constrained mobile, embedded, and cyber-physical systems. CIBF incorporates data-driven constraints, from a wide range of different sound models and feature representations, into traditional physics-based beamforming, to learn filter coefficients to filter out or enhance specific sounds depending on the application. The power and versatility of this intelligent acoustic filtering platform were demonstrated through diverse application scenarios, including privacy-aware sleep monitoring, wildlife sound classification, breathing sounds detection, and enhanced urban safety. This work was published in IPSN 2022. It can be easily extended to other acoustic signals such as vibration, ultrasound, and infrasound.</p>\n<p dir=\"ltr\">Two custom chips were designed and taped out. The first is an ultra-low-power analog-to-feature converter custom IC for estimating the time difference of arrival (TDoA) of audio signals. A novel polarity-coincidence correlation adaptive time-delay estimation (PCC-ATE) technique was implemented which uses a negative-feedback architecture and 1-bit front-end ADCs to implement a 78.2nW prototype in 0.18um CMOS. This technology and design can be broadly applied to a large range of TDoA-based localization applications. The design was published at CICC 2018 and a US patent was filed. The second chip is designed to convert analog audio at its input directly into a digital feature vector at its output that is then fed into an off-chip classifier for audio recognition. The feature extraction occurs in hardware in the analog domain prior to digitization, which leads to drastic power savings due to the efficiency of analog versus digital at the low resolutions.</p>\n<p dir=\"ltr\">6 PhD students at Columbia University were supported, of which 3 graduated and successfully defended their theses based on research conducted as part of this project. Multiple undergraduate and master students gained valuable coding and hardware design skills and experiences through this project. The PIs and their students organized summer workshops to give female high school students from the Harlem and Bronx neighborhoods hands-on experiences with building circuits and writing software code. Ideas from this project were integrated into the undergraduate-level Internet-of-Things course and Cyber-Physical Systems seminar taught at Columbia University.</p>\n<p dir=\"ltr\">In addition to conference awards and paper publications, this project received many media recognitions, including from the New York Post, Fast Company, IEEE Signal Processing Magazine, Mashable, and Gizmodo.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/13/2023<br>\n\t\t\t\t\tModified by: Xiaofan&nbsp;Jiang</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185551310_1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185551310_1--rgov-800width.jpg\" title=\"Pedestrian wearing PAWS\"><img src=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185551310_1--rgov-66x44.jpg\" alt=\"Pedestrian wearing PAWS\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An inattentive pedestrian wearing a PAWS headset, and a screen shotof the PAWS application user interface.</div>\n<div class=\"imageCredit\">Columbia ICSL</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xiaofan&nbsp;Jiang</div>\n<div class=\"imageTitle\">Pedestrian wearing PAWS</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185639110_2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185639110_2--rgov-800width.jpg\" title=\"PAWS Headset\"><img src=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185639110_2--rgov-66x44.jpg\" alt=\"PAWS Headset\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">(Left) Teardown of the PAWS headset; the front-end hardwareis exposed inside the left ear housing. (Right) Close up of the PCB that comprises the PAWS front-end hardware.</div>\n<div class=\"imageCredit\">Columbia ICSL</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xiaofan&nbsp;Jiang</div>\n<div class=\"imageTitle\">PAWS Headset</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185800453_3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185800453_3--rgov-800width.jpg\" title=\"PAWS ASIC\"><img src=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185800453_3--rgov-66x44.jpg\" alt=\"PAWS ASIC\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Custom integrated circuit for computing acoustic features directly from multi-channel audio, used in PAWS Low-Energy</div>\n<div class=\"imageCredit\">Columbia Kinget Group</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xiaofan&nbsp;Jiang</div>\n<div class=\"imageTitle\">PAWS ASIC</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185902797_4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185902797_4--rgov-800width.jpg\" title=\"PAWS ASIC Photo\"><img src=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697185902797_4--rgov-66x44.jpg\" alt=\"PAWS ASIC Photo\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Photo of ASIC</div>\n<div class=\"imageCredit\">Columbia ICSL and Kinget Group</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xiaofan&nbsp;Jiang</div>\n<div class=\"imageTitle\">PAWS ASIC Photo</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697186115651_5--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697186115651_5--rgov-800width.jpg\" title=\"CSafe Helmet\"><img src=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697186115651_5--rgov-66x44.jpg\" alt=\"CSafe Helmet\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The CSafe embedded platform, consisting of an an array of four microphones integrated into a feature extraction system. Twomicrophones are shown (the front and right microphones), while the other two are on the back and leftside of the helmet.</div>\n<div class=\"imageCredit\">Columbia ICSL</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xiaofan&nbsp;Jiang</div>\n<div class=\"imageTitle\">CSafe Helmet</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697186230791_6--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697186230791_6--rgov-800width.jpg\" title=\"AvA System Architecture\"><img src=\"/por/images/Reports/POR/2023/1704899/1704899_10490048_1697186230791_6--rgov-66x44.jpg\" alt=\"AvA System Architecture\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Content-informed beamforming architecture</div>\n<div class=\"imageCredit\">Columbia ICSL</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xiaofan&nbsp;Jiang</div>\n<div class=\"imageTitle\">AvA System Architecture</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nThis Project Outcomes Report for the General Public is displayed verbatim as submitted by the Principal Investigator (PI) for this award. Any opinions, findings, and conclusions or recommendations expressed in this Report are those of the PI and do not necessarily reflect the views of the National Science Foundation; NSF has not approved or endorsed its content.\nThis project developed a wearable system (PAWS) consisting of multi-channel audio sensors embedded in a headset to help detect and localize vehicles based on their engine and tire noises, from up to 60m away, and alert the user with low latency and high accuracy. The team demonstrated an effective design approach for low-latency wearable systems that partitions the data processing pipeline between feature extractions in the embedded front-end and machine learning classifiers in the smartphone. To further reduce power consumption of the battery-powered headset, the team designed a custom integrated circuit for computing relative delays between multiple channels of audio with nW power consumption, demonstrating the feasibility of low-cost custom ASICs in wearable system design. In the second phase of the project, the team tackled the challenge of construction worker safety, where sounds of machineries are orders of magnitude louder than vehicles. This project introduced the idea of using probabilistic models of noises to update acoustic filters to remove targeted machine sounds. This work was published in top-tier sensing systems and IoT forums, including a paper at IoTJ 2019, a paper at IPSN 2021, a best presentation award at VNC 2018, and a best demo award at IoTDI 2018.\nRecognizing the importance of audio in many applications beyond urban safety, in the third phase of the project, the team investigated a generalized adaptive audio filtering platform. This platform introduces the idea of content-informed beamforming (CIBF) that combines signal processing and machine learning, to enable custom sounds to be enhanced or filtered out, and can be easily adapted for a wide range of real-time and resource-constrained mobile, embedded, and cyber-physical systems. CIBF incorporates data-driven constraints, from a wide range of different sound models and feature representations, into traditional physics-based beamforming, to learn filter coefficients to filter out or enhance specific sounds depending on the application. The power and versatility of this intelligent acoustic filtering platform were demonstrated through diverse application scenarios, including privacy-aware sleep monitoring, wildlife sound classification, breathing sounds detection, and enhanced urban safety. This work was published in IPSN 2022. It can be easily extended to other acoustic signals such as vibration, ultrasound, and infrasound.\nTwo custom chips were designed and taped out. The first is an ultra-low-power analog-to-feature converter custom IC for estimating the time difference of arrival (TDoA) of audio signals. A novel polarity-coincidence correlation adaptive time-delay estimation (PCC-ATE) technique was implemented which uses a negative-feedback architecture and 1-bit front-end ADCs to implement a 78.2nW prototype in 0.18um CMOS. This technology and design can be broadly applied to a large range of TDoA-based localization applications. The design was published at CICC 2018 and a US patent was filed. The second chip is designed to convert analog audio at its input directly into a digital feature vector at its output that is then fed into an off-chip classifier for audio recognition. The feature extraction occurs in hardware in the analog domain prior to digitization, which leads to drastic power savings due to the efficiency of analog versus digital at the low resolutions.\n6 PhD students at Columbia University were supported, of which 3 graduated and successfully defended their theses based on research conducted as part of this project. Multiple undergraduate and master students gained valuable coding and hardware design skills and experiences through this project. The PIs and their students organized summer workshops to give female high school students from the Harlem and Bronx neighborhoods hands-on experiences with building circuits and writing software code. Ideas from this project were integrated into the undergraduate-level Internet-of-Things course and Cyber-Physical Systems seminar taught at Columbia University.\nIn addition to conference awards and paper publications, this project received many media recognitions, including from the New York Post, Fast Company, IEEE Signal Processing Magazine, Mashable, and Gizmodo. \n\n \n\n\t\t\t\t\tLast Modified: 10/13/2023\n\n\t\t\t\t\tSubmitted by: Xiaofan Jiang"
 }
}