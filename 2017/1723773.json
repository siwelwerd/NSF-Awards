{
 "awd_id": "1723773",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAPA: Collaborative Research: A Multi-Paradigm Programming Infrastructure for Heterogeneous Architectures",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2017-09-15",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 425000.0,
 "awd_amount": 501000.0,
 "awd_min_amd_letter_date": "2017-08-31",
 "awd_max_amd_letter_date": "2021-05-28",
 "awd_abstract_narration": "Heterogeneous computing with extensive use of hardware accelerators, such as FPGAs and GPUs, has shown great promise to bring in orders of magnitude improvement in computing efficiency for a wide range of applications. However, such heterogeneous platforms are difficult to program, especially with FPGAs, limiting their use to only a small subset of programmers with specialized hardware knowledge.  The intellectual merits of this research are to develop a highly productive multi-paradigm programming infrastructure for heterogeneous architectures that integrates convenient heterogeneous programming models, automated compilation for high-level domain-specific languages, novel runtime, and debugging support. The project's broader significance and importance are to introduce the latest research into multiple graduate and undergraduate courses and tutorials at major conferences, with the goal of training a new generation of diverse students and professionals to use heterogeneous programming models. These programmers will be able to apply the developed infrastructure effectively to many important compute-intensive applications in our society to further the digital revolution.  \r\n\r\nSpecifically, the project has four innovative research components: (1) a new programming model, named HeteroCL, that enables programming of heterogeneous systems in a single unified program, (2) a reusable methodology to efficiently transform high-level DSLs to HeteroCL, (3) an efficient runtime system that support the HeteroCL programming model and high-level DSLs, with unique capability of dynamic and intelligent co-scheduling of workloads to CPUs and accelerators at multiple levels of computing hierarchy,  and (4) novel FPGA performance debugging tools for instrumentation and performance monitoring.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jason",
   "pi_last_name": "Cong",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jason Cong",
   "pi_email_addr": "cong@cs.ucla.edu",
   "nsf_id": "000301151",
   "pi_start_date": "2017-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Miryung",
   "pi_last_name": "Kim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Miryung Kim",
   "pi_email_addr": "miryung@cs.ucla.edu",
   "nsf_id": "000676266",
   "pi_start_date": "2017-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles, Computer Science Dept.",
  "perf_str_addr": "Box 951596, 4731J BH",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900951596",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "021Z",
   "pgm_ref_txt": "Industry Partnerships"
  },
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "2878",
   "pgm_ref_txt": "SPECIAL PROJECTS - CCF"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  },
  {
   "pgm_ref_code": "8585",
   "pgm_ref_txt": "NSF/Intel Partnership Projects"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 141667.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 157667.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 141666.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 60000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Domain-specific accelerators (DSAs), such as the Tensor Processing Unit (TPU), are shown to provide orders of magnitude performance and energy efficiency improvement over the widely used general-purpose CPUs.&nbsp;&nbsp;However, DSA design is limited to a small group of circuit designers. The goal of this project is to enable millions of software programmers to efficiently design DSAs (at least on programmable fabrics, such as FPGAs) without much hardware design experience, so that they can carry out efficient heterogeneous computing using both CPUs and FPGAs. To achieve this goal, we took a four-pronged approach:</p>\n<ul>\n<li>Architecture-guided optimization</li>\n<li>Automated code transformation and pragma insertion</li>\n<li>Support of high-level domain-specific languages (DSLs)</li>\n<li>Automated code refactoring, testing, and program repair</li>\n</ul>\n<p>One good example of architecture-guided optimization is automated generation of systolic arrays (SA), an efficient architecture that uses only local communication between adjacent processing elements. It is&nbsp;&nbsp;used by TPU and many other deep-learning accelerators, but it?s not easy to design. A&nbsp;<a href=\"https://arxiv.org/pdf/1711.07606.pdf\">2017 Intel study</a>&nbsp;showed that 4?18 months are required to design high-quality SA, even with HLS tools. Our work,&nbsp;<a href=\"https://dl.acm.org/doi/10.1145/3431920.3439292\">AutoSA</a>&nbsp;supported under this project, provides a fully automated solution. Once a programmer marks a section of C or C++ code to be implemented in the SA architecture, AutoSA can generate an array of processing elements and an associated data communication network, optimizing computation throughput. For the convolutional neural network example, AutoSA generates an optimized SA with over 9,600 lines of C code including pragmas, achieving more than 200x speedup over a single-core CPU.&nbsp;</p>\n<p>For programs that do not easily fit to common computation patterns (such as SA or stencil computation, for which we have good solutions using architecture-guided optimization), our second approach is to perform automated code transformation and pragma insertion to repeatedly parallelize or pipeline the computation based on bottleneck analysis or guided by graph-based deep learning. Building upon the open-source Merlin Compiler from AMD/Xilinx, our tool named&nbsp;<a href=\"https://dl.acm.org/doi/10.1145/3431920.3439464\">AutoDSE</a>&nbsp;can eliminate most, if not all, pragmas inserted by expert hardware designers and achieve comparable or even better performance (as demonstrated on Xilinx?s Vitis HLS library for vision acceleration).</p>\n<p>The third effort is to further raise the level of design abstraction to support DSLs so that software developers in certain application domains can create DSAs easily. For example, based on the open-source&nbsp;<a href=\"https://dl.acm.org/doi/10.1145/3289602.3293910\">HeteroCL</a>&nbsp;intermediate representation, we can support Halide, a widely-used image processing DSL with the advantageous property of decoupling algorithm specification from performance optimization. For the blur-filter example written in 8 lines of Halide code, our tool can generate 1,455 lines of optimized HLS C code with 439 lines of pragmas, achieving 3.9x speedup over a 28-core CPU.</p>\n<p>The fourth effort is on automated code refactoring, automated testing, and&nbsp;automated program repair to lower the barrier of heterogeneous application development for software engineers without deep hardware expertise.&nbsp;For example, we designed an automated refactoring technique, called HeteroRefactor, that monitors FPGA-specific dynamic invariants (e.g., the required bitwidth of integer and floating-point variables, and the size of recursive data structures and stacks) and uses this knowledge of dynamic invariants to automatically refactor the kernel to make traditionally HLS-incompatible programs synthesizable and to optimize the accelerator?s resource usage and frequency further. Furthermore, we designed an automated test generation technique, called HeteroFuzz that detects platform-dependent differential behavior between CPU and FPGA fully automatically. To reduce the long latency of simulating heterogeneous applications, HeteroFuzz employs a three-pronged approach that incorporates multi-dimensional accelerator feedback, dynamic probabilistic mutations, and selective invocations.&nbsp; Finally, we designed an automated program repair technique, called HeteroGen that takes C/C++ code as input and automatically generates an HLS version with test behavior preservation and better performance.&nbsp;</p>\n<p>This project led to over 30 publications in top conferences and journals (including two Best Paper Awards) and 9 open-source releases. It supported seven PhD and postdoc researchers (including 43% female, which is considerably higher than the departmental average) and two undergraduate students under a REU award (both went on for graduate studies).&nbsp;&nbsp;Both the PI and co-PI have given multiple keynote speeches, including the keynote by co-PI Miryung Kim on ?Software Developer Tools for Democratizing Heterogeneous Computing Applications? (available on Youtube:&nbsp;<a href=\"https://youtu.be/ikDB8hx73tk\">https://youtu.be/ikDB8hx73tk</a>)&nbsp;at the ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA) in July 2022 and the keynote by PI Jason Cong on \"Democratizing IC Design and Customized Computing?&nbsp;&nbsp;(available on YouTube&nbsp;<a href=\"https://youtu.be/qlqjymTcLdI\">https://youtu.be/qlqjymTcLdI</a>) at the 2022 ACM/IEEE International Conference on Computer-Aided Design (ICCAD) in Oct. 2022.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/06/2022<br>\n\t\t\t\t\tModified by: Jason&nbsp;Cong</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDomain-specific accelerators (DSAs), such as the Tensor Processing Unit (TPU), are shown to provide orders of magnitude performance and energy efficiency improvement over the widely used general-purpose CPUs.  However, DSA design is limited to a small group of circuit designers. The goal of this project is to enable millions of software programmers to efficiently design DSAs (at least on programmable fabrics, such as FPGAs) without much hardware design experience, so that they can carry out efficient heterogeneous computing using both CPUs and FPGAs. To achieve this goal, we took a four-pronged approach:\n\nArchitecture-guided optimization\nAutomated code transformation and pragma insertion\nSupport of high-level domain-specific languages (DSLs)\nAutomated code refactoring, testing, and program repair\n\n\nOne good example of architecture-guided optimization is automated generation of systolic arrays (SA), an efficient architecture that uses only local communication between adjacent processing elements. It is  used by TPU and many other deep-learning accelerators, but it?s not easy to design. A 2017 Intel study showed that 4?18 months are required to design high-quality SA, even with HLS tools. Our work, AutoSA supported under this project, provides a fully automated solution. Once a programmer marks a section of C or C++ code to be implemented in the SA architecture, AutoSA can generate an array of processing elements and an associated data communication network, optimizing computation throughput. For the convolutional neural network example, AutoSA generates an optimized SA with over 9,600 lines of C code including pragmas, achieving more than 200x speedup over a single-core CPU. \n\nFor programs that do not easily fit to common computation patterns (such as SA or stencil computation, for which we have good solutions using architecture-guided optimization), our second approach is to perform automated code transformation and pragma insertion to repeatedly parallelize or pipeline the computation based on bottleneck analysis or guided by graph-based deep learning. Building upon the open-source Merlin Compiler from AMD/Xilinx, our tool named AutoDSE can eliminate most, if not all, pragmas inserted by expert hardware designers and achieve comparable or even better performance (as demonstrated on Xilinx?s Vitis HLS library for vision acceleration).\n\nThe third effort is to further raise the level of design abstraction to support DSLs so that software developers in certain application domains can create DSAs easily. For example, based on the open-source HeteroCL intermediate representation, we can support Halide, a widely-used image processing DSL with the advantageous property of decoupling algorithm specification from performance optimization. For the blur-filter example written in 8 lines of Halide code, our tool can generate 1,455 lines of optimized HLS C code with 439 lines of pragmas, achieving 3.9x speedup over a 28-core CPU.\n\nThe fourth effort is on automated code refactoring, automated testing, and automated program repair to lower the barrier of heterogeneous application development for software engineers without deep hardware expertise. For example, we designed an automated refactoring technique, called HeteroRefactor, that monitors FPGA-specific dynamic invariants (e.g., the required bitwidth of integer and floating-point variables, and the size of recursive data structures and stacks) and uses this knowledge of dynamic invariants to automatically refactor the kernel to make traditionally HLS-incompatible programs synthesizable and to optimize the accelerator?s resource usage and frequency further. Furthermore, we designed an automated test generation technique, called HeteroFuzz that detects platform-dependent differential behavior between CPU and FPGA fully automatically. To reduce the long latency of simulating heterogeneous applications, HeteroFuzz employs a three-pronged approach that incorporates multi-dimensional accelerator feedback, dynamic probabilistic mutations, and selective invocations.  Finally, we designed an automated program repair technique, called HeteroGen that takes C/C++ code as input and automatically generates an HLS version with test behavior preservation and better performance. \n\nThis project led to over 30 publications in top conferences and journals (including two Best Paper Awards) and 9 open-source releases. It supported seven PhD and postdoc researchers (including 43% female, which is considerably higher than the departmental average) and two undergraduate students under a REU award (both went on for graduate studies).  Both the PI and co-PI have given multiple keynote speeches, including the keynote by co-PI Miryung Kim on ?Software Developer Tools for Democratizing Heterogeneous Computing Applications? (available on Youtube: https://youtu.be/ikDB8hx73tk) at the ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA) in July 2022 and the keynote by PI Jason Cong on \"Democratizing IC Design and Customized Computing?  (available on YouTube https://youtu.be/qlqjymTcLdI) at the 2022 ACM/IEEE International Conference on Computer-Aided Design (ICCAD) in Oct. 2022.\n\n\t\t\t\t\tLast Modified: 12/06/2022\n\n\t\t\t\t\tSubmitted by: Jason Cong"
 }
}