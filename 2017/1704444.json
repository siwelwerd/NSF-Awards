{
 "awd_id": "1704444",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Large: Collaborative Research: Pervasive Data Ethics for Computational Research",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Bainbridge",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 423045.0,
 "awd_amount": 423045.0,
 "awd_min_amd_letter_date": "2017-07-31",
 "awd_max_amd_letter_date": "2017-07-31",
 "awd_abstract_narration": "This project promotes the progress of science and technology development by providing the empirical knowledge needed to advance fair, just computational research.  Big, pervasive data about people enables fundamentally new computational research, but also raises new ethical challenges, such as accounting for distributed harms at scale, protecting against the risks of unpredictable future uses of data, and ensuring fairness in automated decision-making. National debates have erupted over online experiments, leaked datasets, and the definition of \"public\" data. Investigators struggle to advise students on engaging vulnerable populations or navigating terms of service. Regulators debate how to translate traditional ethical principles into workable policy guidance. Research addressing these challenges has hit roadblocks caused by a lack of empirical knowledge about emerging norms and expectations. This project discovers how diverse stakeholders - big data researchers, platforms, regulators, and user communities - understand their ethical obligations and choices, and how their decisions impact data system design and use. It also compares stakeholder perspectives against the risks and realities of pervasive data itself, answering fundamental questions about the fairness and ethics of such research. Understanding how computing researchers adapt their practices in the big data era, and highlighting points of convergence or conflict with data realities, user expectations, and regulatory practices, will produce concrete guidance for pervasive data ethics. In addition to improving ethical approaches for studying people in computing contexts, this work empowers researchers with actionable information about emergent norms and risks. Outputs, such as decision-support tools, guidance on measuring risk, public educational material and bibliographies, and reusable empirical data, are designed to support the wide range of stakeholders in data ethics. \r\n\r\nTo meet these goals, this project enables a collaboratory - a virtual center combining data and analytical resources - to collect empirical data on research ethics at diverse scopes and scales. The research includes including attention to multiple ethical issues (privacy, risk, respect, beneficence, justice) as well as the full network of stakeholders involved in research ethics (user communities, computing research communities, technical platforms, and regulations). The project conducts interviews with, and surveys of, 1) user communities, 2) computing researchers, 3) data ethics regulators, and 4) commercial platform providers. The project also gathers numerous shared document sets, including 1) pervasive data research publications, 2) pervasive computing curricula and degree requirements, 3) news articles and public discourse about pervasive data research, 4) a corpus of existing data ethics training, 5) pervasive data grant summaries and data management plans, and 6) corporate ethics guidelines and regulatory documents. The project uses these resources to: discover metrics for assessing and moderating risks to data subjects; document how user attitudes and media reactions shape subjects' willingness to participate in pervasive data research; model user concerns in ways accessible to computational researchers; discover how existing ethical codes can be adapted and adopted for the real-world working conditions of sociotechnical and cyber-human research; determine how the changing practices of academic and corporate regulators impact users and researchers; and illuminate implementable and sustainable best practices for research ethics.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Arvind",
   "pi_last_name": "Narayanan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Arvind Narayanan",
   "pi_email_addr": "arvindn@princeton.edu",
   "nsf_id": "000663233",
   "pi_start_date": "2017-07-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "35 Olden Street",
  "perf_city_name": "Princeton",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442020",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 423045.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-feee69cf-7fff-3c69-ad14-31acd959b934\"> </span></p>\n<p dir=\"ltr\"><span>The PERVADE project answered fundamental empirical questions in data ethics, and created evidence-based decision-support tools for researchers struggling with ethical challenges in big data research. Research focused on five areas: regulation of data use (for example by IRBs); user expectations for data use (including what users know and understand, what users feel is appropriate on various platforms, and how users interact with pervasive data); community norms for data use (including accepted and controversial practices in diverse computing communities); risks of data use (including current and future risks to both individuals and groups); and finally data justice (including fairness and equity). For example, our survey of Facebook users, published in </span><span>Social Media &amp; Society</span><span>, found awareness of research to be the most important factor impacting users&rsquo; perceptions of the appropriateness of research uses of data. Comparative surveys of Instagram, Reddit, and dating app users, published in </span><span>Big Data &amp; Society</span><span>, confirmed our findings about the centrality of awareness. To address the disconnect between user expectations and current data science practice, PERVADE authored a paper with formal recommendations, &ldquo;Excavating awareness and power in data science: a manifesto for trustworthy pervasive data research&rdquo; published in the journal </span><span>Big Data &amp; Society</span><span>. The recommendations draw from the history of another discipline that has struggled with trust and trustworthiness &ndash; anthropology &ndash; to provide an ethical framework for data scientists beyond traditional research ethics principles enforced by IRBs.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>PERVADE findings have established the risks of various kinds of pervasive data research; modeled user concerns to inform computational research; documented emerging community norms and discovering areas of ongoing disagreement in computational research; discovered unfair or unjust research practices; and established best practices for researchers and regulators struggling to define ethical pervasive data practices. PERVADE regularly consulted with SSRC&rsquo;s DataOne on social media research ethics, and we worked with Meta to oversee research ethics concerns for experiments run during the 2020 elections. Impacts for the project so far include 2,929 citations of PERVADE publications in highly interdisciplinary venues. All co-PIs have given talks and keynotes to diverse audiences, including corporate researchers, academic researchers, and IRB staff. We organized numerous workshops with industry and academic stakeholders. The co-PIs led a webinar series that put PERVADE participants into conversation with diverse data scientists, as well as a &ldquo;roadshow&rdquo; to present project findings in booths at influential data science conferences. Finally, one of PERVADE&rsquo;s major outcomes was the development of an open, online data science ethics decision support tool. Two co-PIs also authored CITI Program training modules focused on ethical data science and social media research, which are now available to learners across the U.S.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/29/2023<br>\n\t\t\t\t\tModified by: Arvind&nbsp;Narayanan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThe PERVADE project answered fundamental empirical questions in data ethics, and created evidence-based decision-support tools for researchers struggling with ethical challenges in big data research. Research focused on five areas: regulation of data use (for example by IRBs); user expectations for data use (including what users know and understand, what users feel is appropriate on various platforms, and how users interact with pervasive data); community norms for data use (including accepted and controversial practices in diverse computing communities); risks of data use (including current and future risks to both individuals and groups); and finally data justice (including fairness and equity). For example, our survey of Facebook users, published in Social Media &amp; Society, found awareness of research to be the most important factor impacting users\u2019 perceptions of the appropriateness of research uses of data. Comparative surveys of Instagram, Reddit, and dating app users, published in Big Data &amp; Society, confirmed our findings about the centrality of awareness. To address the disconnect between user expectations and current data science practice, PERVADE authored a paper with formal recommendations, \"Excavating awareness and power in data science: a manifesto for trustworthy pervasive data research\" published in the journal Big Data &amp; Society. The recommendations draw from the history of another discipline that has struggled with trust and trustworthiness &ndash; anthropology &ndash; to provide an ethical framework for data scientists beyond traditional research ethics principles enforced by IRBs.\n\n \nPERVADE findings have established the risks of various kinds of pervasive data research; modeled user concerns to inform computational research; documented emerging community norms and discovering areas of ongoing disagreement in computational research; discovered unfair or unjust research practices; and established best practices for researchers and regulators struggling to define ethical pervasive data practices. PERVADE regularly consulted with SSRC\u2019s DataOne on social media research ethics, and we worked with Meta to oversee research ethics concerns for experiments run during the 2020 elections. Impacts for the project so far include 2,929 citations of PERVADE publications in highly interdisciplinary venues. All co-PIs have given talks and keynotes to diverse audiences, including corporate researchers, academic researchers, and IRB staff. We organized numerous workshops with industry and academic stakeholders. The co-PIs led a webinar series that put PERVADE participants into conversation with diverse data scientists, as well as a \"roadshow\" to present project findings in booths at influential data science conferences. Finally, one of PERVADE\u2019s major outcomes was the development of an open, online data science ethics decision support tool. Two co-PIs also authored CITI Program training modules focused on ethical data science and social media research, which are now available to learners across the U.S.\n\n \n\n\t\t\t\t\tLast Modified: 09/29/2023\n\n\t\t\t\t\tSubmitted by: Arvind Narayanan"
 }
}