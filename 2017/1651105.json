{
 "awd_id": "1651105",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Inside Phonological Learning",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927920",
 "po_email": "jvaldesk@nsf.gov",
 "po_sign_block_name": "Jorge Valdes Kroff",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 242921.0,
 "awd_amount": 242921.0,
 "awd_min_amd_letter_date": "2017-07-11",
 "awd_max_amd_letter_date": "2023-01-03",
 "awd_abstract_narration": "One of the core issues in linguistics is how language is acquired.  Do people learn a language the way a bird learns its song, using special-purpose brain mechanisms?  Or do they learn it the way they learn chess, using general-purpose  intelligence?  The answer to this question is crucial for understanding how people learn a first or second language, how language learning is connected to other kinds of learning, how the brain stores its knowledge of language, and how humans evolved the capacity for language.  The answer might even be different for different aspects of language, such as sounds vs. vocabulary vs. sentence structure.  It is especially important for understanding why language is not always learned successfully, either by children acquiring their first language, or adults learning a second language.  At a broad level, understanding how to improve language learning has positive impacts for a society--improved cultural diplomacy, economic growth, increased communication in an immigrant nation--and for individuals--personal fulfillment and cognitive benefits associated with language study.\r\n\r\nStudies of general-purpose intelligence have identified two separate learning systems which approximately correspond to \"reasoning\" and \"intuition\".  They are activated by different kinds of learning situation, cause different electrical activity in the brain, and are good at learning patterns with different structures.  It is not known how these two systems are involved in language acquisition.  This project asks how reasoning and intuition are involved in the second-language acquisition of the \"sound pattern of a language--that is, how sounds combine to form larger units like syllables and words.  The project also asks whether certain patterns are easier to learn either due to their structure or content.  The researchers will teach people invented languages whose properties can be manipulated, and measure both learning performance and the brain's electrical response to ask whether the language learners show the characteristic signatures of reasoning and intuition found in learning non-linguistic patterns, or whether different mechanisms are being used.  The results will illuminate factors that affect the success of language learning. To foster robust and reliable science in the area of language learning, the investigators will disseminate, for each of the project's experiments, \"replication kits\" that will include all stimulus files, instructions for setting up the experiments on the user's computer, and software scripts for running the experiments and for data analysis.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Elliott",
   "pi_last_name": "Moreton",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Elliott Moreton",
   "pi_email_addr": "moreton@unc.edu",
   "nsf_id": "000354303",
   "pi_start_date": "2017-07-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Katya",
   "pi_last_name": "Pertsova",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Katya Pertsova",
   "pi_email_addr": "pertsova@email.unc.edu",
   "nsf_id": "000614459",
   "pi_start_date": "2017-07-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "",
  "perf_city_name": "Chapel Hill",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275993355",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "040Z",
   "pgm_ref_txt": "Robust and Reliable Science"
  },
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 242921.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>All learning from experience is guided by <em>inductive biases</em>, predispositions in the learner towards discovering some generalizations and against discovering others.&nbsp; Inductive bases are mathematically inescapable, whether in humans, in other animals, or in machines.&nbsp; This project asked whether language learning is subject to the same inductive biases that guide human pattern learning in other areas such as vision or music.&nbsp; The answer is relevant to the larger question of how far language learning relies on dedicated, language-only cognitive processes and neural resources, rather than on general human intelligence ? and <em>that</em> in turn is relevant to practical questions about language teaching and language disorders, as well as to basic questions about how the mind and brain are organized.</p>\n<p>Previous research on non-linguistic pattern learning in humans has found that explicit and implicit learning have different inductive biases; in other words, reasoning and intuition differ as to the kinds of patterns they are good at detecting. This project zeroed in on the question of whether the differences between explicit and implicit learning were the same in phonology (the sound pattern of a language) as in vision and music.</p>\n<p>One difference between explicit and implicit learning that has been repeatedly found in visual pattern learning is that explicit learning is more sensitive to biconditional patterns (e.g., \"green if and only if triangular\"; \"either small or round, but not both\") than to family-resemblance patterns (e.g., \"at least two of green, small, or round\"), while implicit learning is the other way around.&nbsp; In experiments using phonological analogues of the visual patterns (e.g., \"stress on the first syllable if and only if three syllables long\"), we found that explicit and implicit learning differed in the <em>opposite</em> way from what had been found with visual patterns:&nbsp; Switching from explicit to implicit learning made biconditionals <em>easier</em> relative to family-resemblance patterns, rather than harder.</p>\n<p>Another known difference between explicit and implicit learning is that explicit learning requires conscious mental effort, while implicit learning can happen even without an intent to learn.&nbsp; A pattern which can only be detected with effort should therefore be easier to learn explicitly than implicitly.&nbsp; Previous research had shown that some kinds of symmetry can be detected with little effort, while others require much effort; for instance, visually, it is easier to spot left-right symmetry (like in the letter A) than up-down symmetry (like in the letter E), whereas in music, it is easier to spot a repetition (like <em>do-me-fa-do-me-fa</em>) than a reversal (like <em>do-me-fa-fa-me-do</em>).&nbsp; Expecting that spoken language would be like music in that repetitions could be detected with little effort, but reversals would take a lot of effort, we tested participants' ability to learn repetitions and reversals in phonology and in music.&nbsp; The result, in both phonology and music, was that implicit and explicit learners readily induced the repetition pattern, but only explicit learners picked up on the reversal pattern.</p>\n<p>The upshot is that on a larger scale, language learning and non-linguistic learning are alike in that explicit and implicit processes (a) are available for both, and (b) have different inductive biases.&nbsp; On a more detailed level, implicit and explicit learning may differ <em>differently</em> from each other depending on the domain of application (phonology, vision, or music).</p>\n<p>The project supported the training of four MA students at UNC-Chapel Hill, of whom two have finished their degrees and two are expected to finish in 2024.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/18/2023<br>\n\t\t\t\t\tModified by: Elliott&nbsp;Moreton</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAll learning from experience is guided by inductive biases, predispositions in the learner towards discovering some generalizations and against discovering others.  Inductive bases are mathematically inescapable, whether in humans, in other animals, or in machines.  This project asked whether language learning is subject to the same inductive biases that guide human pattern learning in other areas such as vision or music.  The answer is relevant to the larger question of how far language learning relies on dedicated, language-only cognitive processes and neural resources, rather than on general human intelligence ? and that in turn is relevant to practical questions about language teaching and language disorders, as well as to basic questions about how the mind and brain are organized.\n\nPrevious research on non-linguistic pattern learning in humans has found that explicit and implicit learning have different inductive biases; in other words, reasoning and intuition differ as to the kinds of patterns they are good at detecting. This project zeroed in on the question of whether the differences between explicit and implicit learning were the same in phonology (the sound pattern of a language) as in vision and music.\n\nOne difference between explicit and implicit learning that has been repeatedly found in visual pattern learning is that explicit learning is more sensitive to biconditional patterns (e.g., \"green if and only if triangular\"; \"either small or round, but not both\") than to family-resemblance patterns (e.g., \"at least two of green, small, or round\"), while implicit learning is the other way around.  In experiments using phonological analogues of the visual patterns (e.g., \"stress on the first syllable if and only if three syllables long\"), we found that explicit and implicit learning differed in the opposite way from what had been found with visual patterns:  Switching from explicit to implicit learning made biconditionals easier relative to family-resemblance patterns, rather than harder.\n\nAnother known difference between explicit and implicit learning is that explicit learning requires conscious mental effort, while implicit learning can happen even without an intent to learn.  A pattern which can only be detected with effort should therefore be easier to learn explicitly than implicitly.  Previous research had shown that some kinds of symmetry can be detected with little effort, while others require much effort; for instance, visually, it is easier to spot left-right symmetry (like in the letter A) than up-down symmetry (like in the letter E), whereas in music, it is easier to spot a repetition (like do-me-fa-do-me-fa) than a reversal (like do-me-fa-fa-me-do).  Expecting that spoken language would be like music in that repetitions could be detected with little effort, but reversals would take a lot of effort, we tested participants' ability to learn repetitions and reversals in phonology and in music.  The result, in both phonology and music, was that implicit and explicit learners readily induced the repetition pattern, but only explicit learners picked up on the reversal pattern.\n\nThe upshot is that on a larger scale, language learning and non-linguistic learning are alike in that explicit and implicit processes (a) are available for both, and (b) have different inductive biases.  On a more detailed level, implicit and explicit learning may differ differently from each other depending on the domain of application (phonology, vision, or music).\n\nThe project supported the training of four MA students at UNC-Chapel Hill, of whom two have finished their degrees and two are expected to finish in 2024.\n\n\t\t\t\t\tLast Modified: 10/18/2023\n\n\t\t\t\t\tSubmitted by: Elliott Moreton"
 }
}