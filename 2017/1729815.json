{
 "awd_id": "1729815",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Fleeting Decisions and Risks in Pedestrian Road-Crossing Behavior: Building Insight with Next-Generation Data, Models, and Platforms",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032924710",
 "po_email": "clagonza@nsf.gov",
 "po_sign_block_name": "Claudia Gonzalez-Vallejo",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 399383.0,
 "awd_amount": 399383.0,
 "awd_min_amd_letter_date": "2017-07-24",
 "awd_max_amd_letter_date": "2017-07-24",
 "awd_abstract_narration": "In this project, the Principal Investigator will examine road-crossing behavior over very small moments of space and time, by observing and studying real-world road-crossing sites. The conditions observed will then be recreated in a motion capture studio that will allow collection of very detailed data that can be used to build what-if models for training, planning, and design. The decision to cross a road can take mere fractions of a second and centimeters of action, but over this small window of space and time, people are at risk of injury and death in collisions with vehicles. Despite decades of work to design interventions that might promote safe crossing behavior, many people continue to engage in unsafe crossing, among them our most vulnerable - pedestrian youth and seniors. The aim of the project is to uncover the, often cursory, decisions and risks that people invoke when they move at the roadside. The focus on the microcosm of road-crossing will enable identification and measurement of subtle signals from body language, expression, social cues in crowds, gaze behavior, and footfall that can convey both covert and overt insight into crossing intent. These signals and the road-crossing behaviors that they relate to will inform actionable understanding of road-crossing activities that can be used to improve the design of crossing infrastructure, that can be used in training and education, that might enhance signaling schemes, and that can be used to inform Advanced Driver Awareness Systems now being deployed in many vehicles.\r\n\r\nThe project make use of a coupled research instrument that allows for coded real-world observation to be paired with advanced sensor-based instrumentation in motion capture studios, and with what-if modeling based on human automata that can facilitate the exploration, identification, and measurement of subtle signals of pedestrian decision-making and risk-taking while crossing. The technical focus of the project is to identify, capture, measure, and frame human-environment signals of road-crossing behavior in ways that can be used for broader pedestrian sensing and detection. The project will generate a robust library of data, including qualitative observations, sensor data, and model output that can be reused by communities in the socio-behavioral sciences and the computing sciences. These data, and the models they will power, will form the backbone of an immersive Virtual Geographic Environment that can be used for training and education.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Paul",
   "pi_last_name": "Torrens",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Paul M Torrens",
   "pi_email_addr": "torrens@nyu.edu",
   "nsf_id": "000301178",
   "pi_start_date": "2017-07-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "033Y00",
   "pgm_ele_name": "S&CC: Smart & Connected Commun"
  },
  {
   "pgm_ele_code": "132100",
   "pgm_ele_name": "Decision, Risk & Mgmt Sci"
  },
  {
   "pgm_ele_code": "135200",
   "pgm_ele_name": "Geography and Spatial Sciences"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 399383.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>While a person's decision to cross a road may take a few seconds to resolve, a huge amount of information is used by the crosser in that short window of time. Much of this information is critical to the safety of the following movement into and through a road crossing. In this project, we studied how people acquire and act on the information available to them during road-crossing, with the goals of better understanding the types of information that people use to inform their crossing behavior and what influences that information might have on their decisions and actions on streetscapes. To accomplish these goals, we deployed a multi-site survey around New York City to examine real-world road-crossing behavior using coded observation, as well as new forms of automated sensing. We also mirrored some of the observed road crossing events in a motion capture studio, where we were able to collect very high-fidelity and high-resolution data on people?s movement and motion. The resulting set of data was used to build virtual reality representations of common road crossing scenarios, which also support what-if scenario building for situations beyond our original observations. Our work was successful in identifying a range of demographic, cognitive, spatial, space-time, distraction, land use, urban design, group and social, weather, lighting, and body language factors to account for, conceptualize, and in some cases to explain how people use fleeting bundles of ambient information to effect their road crossing actions. In total, we studied 35 road crossing sites in New York City with over 1,400 observations. Further, we included over 30 participants in virtual reality experiments to fine-tune the insight gained from real-world observation. Our findings revealed that people are more prone to engage in risky behavior when crossing as part of a group or crowd, when using their phones, and that risky crossing behavior is more common among younger demographics. These results echo other theoretical and empirical findings from our colleagues in the research and urban planning community. The central contribution of our work has been to match those findings with very high-resolution data, and with support for what-if simulation that can be used to advance study of these phenomena for highly experimental scenarios.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/22/2021<br>\n\t\t\t\t\tModified by: Paul&nbsp;M&nbsp;Torrens</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319185638_Torrens02--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319185638_Torrens02--rgov-800width.jpg\" title=\"Road-crossing in an experimental simulation\"><img src=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319185638_Torrens02--rgov-66x44.jpg\" alt=\"Road-crossing in an experimental simulation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A road crossing simulation is used to examine scenarios that are unusual in occurance in the real world. In this scenario, a road is flooded with a crowd of synthetic pedestrians to test the ability of machine learning to detect salient features of the crossing scene.</div>\n<div class=\"imageCredit\">Paul M. Torrens</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Paul&nbsp;M&nbsp;Torrens</div>\n<div class=\"imageTitle\">Road-crossing in an experimental simulation</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319326811_Torrens03--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319326811_Torrens03--rgov-800width.jpg\" title=\"Motion capture of pedestrian activity\"><img src=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319326811_Torrens03--rgov-66x44.jpg\" alt=\"Motion capture of pedestrian activity\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">To fine-tune our understanding of road crossing behavior, we made use of motion capture technology (mocap) to measure and track body language of pedestrians as they approach an intersection and as they engage in crossing. This enables us to study their locomotion habits in high detail.</div>\n<div class=\"imageCredit\">Paul M. Torrens</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Paul&nbsp;M&nbsp;Torrens</div>\n<div class=\"imageTitle\">Motion capture of pedestrian activity</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319423765_Torrens01--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319423765_Torrens01--rgov-800width.jpg\" title=\"Computer vision census of road crossing scenes\"><img src=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319423765_Torrens01--rgov-66x44.jpg\" alt=\"Computer vision census of road crossing scenes\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We made use of computer vision and machine learning to identify the key features of road crossing scenes, including pedestrians, vehicles, curbs, and crossing signals.</div>\n<div class=\"imageCredit\">Paul M. Torrens</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Paul&nbsp;M&nbsp;Torrens</div>\n<div class=\"imageTitle\">Computer vision census of road crossing scenes</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319520218_Torrens04--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319520218_Torrens04--rgov-800width.jpg\" title=\"Road crossing simulation\"><img src=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319520218_Torrens04--rgov-66x44.jpg\" alt=\"Road crossing simulation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Using data collected from observation and coding of real-world road crossing scenes, we developed a simulation infrastructure that would allow us to experiment with road crossing scenarios using highly realistic but entirely synthetic pedestrians and intersections.</div>\n<div class=\"imageCredit\">Paul M. Torrens</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Paul&nbsp;M&nbsp;Torrens</div>\n<div class=\"imageTitle\">Road crossing simulation</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319677034_Torrens05--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319677034_Torrens05--rgov-800width.jpg\" title=\"LiDAR observation of an urban intersection\"><img src=\"/por/images/Reports/POR/2021/1729815/1729815_10505761_1632319677034_Torrens05--rgov-66x44.jpg\" alt=\"LiDAR observation of an urban intersection\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We made use of LiDAR (light detection and ranging) technology to collect real-time data of busy intersections for road crossing. This enabled us to track the movement of a range of objects through a streetscape, including people and vehicles, against the backdrop of the urban environment.</div>\n<div class=\"imageCredit\">Paul M. Torrens</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Paul&nbsp;M&nbsp;Torrens</div>\n<div class=\"imageTitle\">LiDAR observation of an urban intersection</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nWhile a person's decision to cross a road may take a few seconds to resolve, a huge amount of information is used by the crosser in that short window of time. Much of this information is critical to the safety of the following movement into and through a road crossing. In this project, we studied how people acquire and act on the information available to them during road-crossing, with the goals of better understanding the types of information that people use to inform their crossing behavior and what influences that information might have on their decisions and actions on streetscapes. To accomplish these goals, we deployed a multi-site survey around New York City to examine real-world road-crossing behavior using coded observation, as well as new forms of automated sensing. We also mirrored some of the observed road crossing events in a motion capture studio, where we were able to collect very high-fidelity and high-resolution data on people?s movement and motion. The resulting set of data was used to build virtual reality representations of common road crossing scenarios, which also support what-if scenario building for situations beyond our original observations. Our work was successful in identifying a range of demographic, cognitive, spatial, space-time, distraction, land use, urban design, group and social, weather, lighting, and body language factors to account for, conceptualize, and in some cases to explain how people use fleeting bundles of ambient information to effect their road crossing actions. In total, we studied 35 road crossing sites in New York City with over 1,400 observations. Further, we included over 30 participants in virtual reality experiments to fine-tune the insight gained from real-world observation. Our findings revealed that people are more prone to engage in risky behavior when crossing as part of a group or crowd, when using their phones, and that risky crossing behavior is more common among younger demographics. These results echo other theoretical and empirical findings from our colleagues in the research and urban planning community. The central contribution of our work has been to match those findings with very high-resolution data, and with support for what-if simulation that can be used to advance study of these phenomena for highly experimental scenarios.\n\n\t\t\t\t\tLast Modified: 09/22/2021\n\n\t\t\t\t\tSubmitted by: Paul M Torrens"
 }
}