{
 "awd_id": "1704303",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Large: Collaborative Research: Pervasive Data Ethics for Computational Research",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Bainbridge",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 422315.0,
 "awd_amount": 422315.0,
 "awd_min_amd_letter_date": "2017-07-31",
 "awd_max_amd_letter_date": "2017-07-31",
 "awd_abstract_narration": "This project promotes the progress of science and technology development by providing the empirical knowledge needed to advance fair, just computational research.  Big, pervasive data about people enables fundamentally new computational research, but also raises new ethical challenges, such as accounting for distributed harms at scale, protecting against the risks of unpredictable future uses of data, and ensuring fairness in automated decision-making. National debates have erupted over online experiments, leaked datasets, and the definition of \"public\" data. Investigators struggle to advise students on engaging vulnerable populations or navigating terms of service. Regulators debate how to translate traditional ethical principles into workable policy guidance. Research addressing these challenges has hit roadblocks caused by a lack of empirical knowledge about emerging norms and expectations. This project discovers how diverse stakeholders - big data researchers, platforms, regulators, and user communities - understand their ethical obligations and choices, and how their decisions impact data system design and use. It also compares stakeholder perspectives against the risks and realities of pervasive data itself, answering fundamental questions about the fairness and ethics of such research. Understanding how computing researchers adapt their practices in the big data era, and highlighting points of convergence or conflict with data realities, user expectations, and regulatory practices, will produce concrete guidance for pervasive data ethics. In addition to improving ethical approaches for studying people in computing contexts, this work empowers researchers with actionable information about emergent norms and risks. Outputs, such as decision-support tools, guidance on measuring risk, public educational material and bibliographies, and reusable empirical data, are designed to support the wide range of stakeholders in data ethics. \r\n\r\nTo meet these goals, this project enables a collaboratory - a virtual center combining data and analytical resources - to collect empirical data on research ethics at diverse scopes and scales. The research includes including attention to multiple ethical issues (privacy, risk, respect, beneficence, justice) as well as the full network of stakeholders involved in research ethics (user communities, computing research communities, technical platforms, and regulations). The project conducts interviews with, and surveys of, 1) user communities, 2) computing researchers, 3) data ethics regulators, and 4) commercial platform providers. The project also gathers numerous shared document sets, including 1) pervasive data research publications, 2) pervasive computing curricula and degree requirements, 3) news articles and public discourse about pervasive data research, 4) a corpus of existing data ethics training, 5) pervasive data grant summaries and data management plans, and 6) corporate ethics guidelines and regulatory documents. The project uses these resources to: discover metrics for assessing and moderating risks to data subjects; document how user attitudes and media reactions shape subjects' willingness to participate in pervasive data research; model user concerns in ways accessible to computational researchers; discover how existing ethical codes can be adapted and adopted for the real-world working conditions of sociotechnical and cyber-human research; determine how the changing practices of academic and corporate regulators impact users and researchers; and illuminate implementable and sustainable best practices for research ethics.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Casey",
   "pi_last_name": "Fiesler",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Casey L Fiesler",
   "pi_email_addr": "casey.fiesler@colorado.edu",
   "nsf_id": "000711961",
   "pi_start_date": "2017-07-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Colorado at Boulder",
  "inst_street_address": "3100 MARINE ST",
  "inst_street_address_2": "STE 481 572 UCB",
  "inst_city_name": "Boulder",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "3034926221",
  "inst_zip_code": "803090001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "THE REGENTS OF THE UNIVERSITY OF COLORADO",
  "org_prnt_uei_num": "",
  "org_uei_num": "SPVKK1RC2MZ3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Colorado at Boulder",
  "perf_str_addr": "3100 Marine Street, 572 UCB",
  "perf_city_name": "Boulder",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "803090572",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "760300",
   "pgm_ele_name": "STS-Sci, Tech & Society"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 422315.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-f3f954e9-7fff-6335-3c4d-f15e408657e5\"> </span></p>\n<p dir=\"ltr\"><span>The PERVADE project answered fundamental empirical questions in data ethics, and created evidence-based decision-support tools for researchers struggling with ethical challenges in big data research. Research focused on five areas: regulation of data use (for example by IRBs); user expectations for data use (including what users know and understand, what users feel is appropriate on various platforms, and how users interact with pervasive data); community norms for data use (including accepted and controversial practices in diverse computing communities); risks of data use (including current and future risks to both individuals and groups); and finally data justice (including fairness and equity). PERVADE findings established risks of various kinds of pervasive data research; modeled user concerns to inform computational research; documented emerging community norms and discovered areas of ongoing disagreement in computational research; discovered unfair or unjust research practices; and established best practices for researchers and regulators struggling to define ethical pervasive data practices.&nbsp;</span></p>\n<p dir=\"ltr\"><span>PERVADE authored formal recommendations for researchers, and shared those recommendations through a webinar series, presentations and booths at data science conferences, educational workshops, and the creation of curricula, a textbook, educational games, and research ethics education modules. We also created the openly-accessible PERVADE decision support tool based on these findings to help data science researchers navigate challenging, situationally-specific aspects of awareness and power in their own work, available at </span><a href=\"https://pervade.umd.edu/pervade-data-ethics-tool/\"><span>https://pervade.umd.edu/pervade-data-ethics-tool/</span></a><span>.&nbsp;</span></p>\n<p dir=\"ltr\"><span>PERVADE researchers also contributed findings and best practices to numerous communities working on data ethics. We regularly consulted with SSRC?s DataOne on social media research ethics, and we worked with Meta to oversee research ethics concerns for experiments run during the 2020 elections.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Impacts for the project include 2,929 citations of PERVADE publications in highly interdisciplinary venues. PERVADE researchers have given talks and keynotes to diverse audiences, including Congressional aides, corporate researchers, academic researchers, and IRB staff. We organized numerous workshops with industry and academic stakeholders. A PERVADE webinar series fostered conversation about PERVADE findings with data scientists and data ethics researchers from a variety of disciplines. We also authored CITI Program research ethics education modules focused on ethical data science and social media research, which are now available to learners across the U.S.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/28/2023<br>\n\t\t\t\t\tModified by: Casey&nbsp;L&nbsp;Fiesler</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThe PERVADE project answered fundamental empirical questions in data ethics, and created evidence-based decision-support tools for researchers struggling with ethical challenges in big data research. Research focused on five areas: regulation of data use (for example by IRBs); user expectations for data use (including what users know and understand, what users feel is appropriate on various platforms, and how users interact with pervasive data); community norms for data use (including accepted and controversial practices in diverse computing communities); risks of data use (including current and future risks to both individuals and groups); and finally data justice (including fairness and equity). PERVADE findings established risks of various kinds of pervasive data research; modeled user concerns to inform computational research; documented emerging community norms and discovered areas of ongoing disagreement in computational research; discovered unfair or unjust research practices; and established best practices for researchers and regulators struggling to define ethical pervasive data practices. \nPERVADE authored formal recommendations for researchers, and shared those recommendations through a webinar series, presentations and booths at data science conferences, educational workshops, and the creation of curricula, a textbook, educational games, and research ethics education modules. We also created the openly-accessible PERVADE decision support tool based on these findings to help data science researchers navigate challenging, situationally-specific aspects of awareness and power in their own work, available at https://pervade.umd.edu/pervade-data-ethics-tool/. \nPERVADE researchers also contributed findings and best practices to numerous communities working on data ethics. We regularly consulted with SSRC?s DataOne on social media research ethics, and we worked with Meta to oversee research ethics concerns for experiments run during the 2020 elections. \nImpacts for the project include 2,929 citations of PERVADE publications in highly interdisciplinary venues. PERVADE researchers have given talks and keynotes to diverse audiences, including Congressional aides, corporate researchers, academic researchers, and IRB staff. We organized numerous workshops with industry and academic stakeholders. A PERVADE webinar series fostered conversation about PERVADE findings with data scientists and data ethics researchers from a variety of disciplines. We also authored CITI Program research ethics education modules focused on ethical data science and social media research, which are now available to learners across the U.S.\n\n \n\n\t\t\t\t\tLast Modified: 09/28/2023\n\n\t\t\t\t\tSubmitted by: Casey L Fiesler"
 }
}