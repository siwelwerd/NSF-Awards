{
 "awd_id": "1717680",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Creating Text-to-Speech Synthesis for Low Resource Languages",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2017-07-27",
 "awd_max_amd_letter_date": "2017-07-27",
 "awd_abstract_narration": "Recent advances in speech technology have resulted in wide use of Spoken Dialogue Systems (SDS) such as Siri (iPhone) and Google Assistant (Android).  These systems support major improvements in information access by voice for High Resource Languages (HRLs) such as English, French, Mandarin, Japanese, and Spanish.  For these languages, researchers have built dictionaries, parsers, part-of-speech taggers, language models, search engines, and machine translation engines to support speech technologies.  However, there are ~6500 world languages, including Tagalog, Tamil, Swahili, Vietnamese and Pashto, many of which are spoken by millions of people, but which do not enjoy the computational resources necessary to build SDS. These are termed Low Resource Languages (LRLs). Speakers of LRLs do not benefit from the same communication and search capabilities speakers of HRLs do.   In particular, there is little research and few resources supporting the development of Text-to-Speech Synthesis (TTS) systems to produce Siri-like speech for SDS in these languages.  Furthermore, both commercial and research TTS systems also require large amounts of carefully recorded, single-speaker speech data, creating another major (and expensive) barrier to TTS development for LRLs.  This work will create TTS systems in LRLs and, in the process, create and make available tools for others to create their own systems using \"found\" data - data recorded for other purposes or available on the web.\r\n\r\nNew paradigms for TTS synthesis (parametric synthesis and the use of Deep Neural Nets) are now being developed which make it theoretically possible to build systems quickly and cheaply without recording large, special-purpose speech corpora, instead using data recorded for other purposes such as training speech recognizers.  This work will investigate the use these techniques to produce TTS systems for LRL.   Two major problems will be explored:  1)  What are the best techniques to filter found data (removing data that is too loud, too noisy or disfluent, for example) to obtain intelligible and natural-sounding results? 2) Can basic prosodic features of LRLs such as phrasing and emphasis be identified, using crowdsourcing and tools developed for HRLs?  Pilot studies on English have revealed that more natural and intelligible voices can be created by using subsets of the data selected on features such as pitch variation and level of articulation.  These methods will be tested on LRLs such as Turkish, Amharic, and Telugu.  Evaluations will be made in terms of intelligibility and naturalness both automatically and using crowdsourcing techniques with native speakers of each language.  The ultimate goal of this exploratory work will be to test these techniques on a broad variety of LRLs which have been collected for purposes of developing speech recognizers.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Julia",
   "pi_last_name": "Hirschberg",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Julia B Hirschberg",
   "pi_email_addr": "julia@cs.columbia.edu",
   "nsf_id": "000399629",
   "pi_start_date": "2017-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100276902",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>There are few Text-to-Speech systems (which produce speech from text) that are currently being built in industry for Low-Resource Languages (LRLs), despite the fact that often millions of people speak these languages and, for many, reading text is a challenge.&nbsp;&nbsp;In this project, we developed new methods for creating these TTS systems by using &ldquo;found&rdquo; data, such as news broadcasts, audiobooks, data collected for speech recognition, audio bibles which&nbsp;<strong><em>are</em></strong>&nbsp;widely available in LRLs. &nbsp;We developed and published numerous successful techniques to simplify this process for others, whether individuals or industry.&nbsp;&nbsp;The LRLs we focused on were Amharic, Turkish, Romanian, and multiple languages from India such as Telugu and we recruited native speakers to help produce the systems and to find native speakers who could test them, thus providing many research opportunities for a diverse set of students. &nbsp;When our TTS systems were tested on native speakers they also produced results significantly better than baseline models trained simply on the corpora we used --- but <em><strong>not</strong></em> using our novel strategies.&nbsp;&nbsp;This research provides opportunities for others to build systems to provide important and useful information for LRL speakers who may have lower reading abilities.</span></p>\n<p><span>We have also developed new methods to improve TTS in Standard American English by improving prediction of prosodic information --- where pauses are placed and which words are spoken with more prominence.&nbsp;&nbsp;To do this we built many new Deep Learning models to produce TTS pipelines from prosodically-labeled corpora for both newscast speech and conversational speech.&nbsp;&nbsp;We used a very large number of novel linguistic features which have not been previously employed in TTS systems, including new word and syntactic features, co-reference features, and dialogue act prediction, as well as prosodic prediction systems built in our lab.&nbsp;&nbsp;Results from English-speaking listeners showed that our approach in this part of the project also produced significantly more natural-sounding speech in English.&nbsp;&nbsp;These methods have also been made publicly available so that others may use them to improve their own TTS systems.</span></p>\n<p><span>All our research in this project has involved a very large and diverse number of research project students at all levels: &nbsp;undergraduate, masters students and PhD students. &nbsp;We are particularly focused on providing research experience for students who are diverse in gender, ethnicity, and regional origin. &nbsp;In particular, our work in LRLs involved students from Ethiopia, Turkey, Romania, and India, and our research in English TTS also included students from India, Africa, Argentina, and China. &nbsp;A large number of these on both projects were women and ethnic minorities.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/12/2021<br>\n\t\t\t\t\tModified by: Julia&nbsp;B&nbsp;Hirschberg</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThere are few Text-to-Speech systems (which produce speech from text) that are currently being built in industry for Low-Resource Languages (LRLs), despite the fact that often millions of people speak these languages and, for many, reading text is a challenge.  In this project, we developed new methods for creating these TTS systems by using \"found\" data, such as news broadcasts, audiobooks, data collected for speech recognition, audio bibles which are widely available in LRLs.  We developed and published numerous successful techniques to simplify this process for others, whether individuals or industry.  The LRLs we focused on were Amharic, Turkish, Romanian, and multiple languages from India such as Telugu and we recruited native speakers to help produce the systems and to find native speakers who could test them, thus providing many research opportunities for a diverse set of students.  When our TTS systems were tested on native speakers they also produced results significantly better than baseline models trained simply on the corpora we used --- but not using our novel strategies.  This research provides opportunities for others to build systems to provide important and useful information for LRL speakers who may have lower reading abilities.\n\nWe have also developed new methods to improve TTS in Standard American English by improving prediction of prosodic information --- where pauses are placed and which words are spoken with more prominence.  To do this we built many new Deep Learning models to produce TTS pipelines from prosodically-labeled corpora for both newscast speech and conversational speech.  We used a very large number of novel linguistic features which have not been previously employed in TTS systems, including new word and syntactic features, co-reference features, and dialogue act prediction, as well as prosodic prediction systems built in our lab.  Results from English-speaking listeners showed that our approach in this part of the project also produced significantly more natural-sounding speech in English.  These methods have also been made publicly available so that others may use them to improve their own TTS systems.\n\nAll our research in this project has involved a very large and diverse number of research project students at all levels:  undergraduate, masters students and PhD students.  We are particularly focused on providing research experience for students who are diverse in gender, ethnicity, and regional origin.  In particular, our work in LRLs involved students from Ethiopia, Turkey, Romania, and India, and our research in English TTS also included students from India, Africa, Argentina, and China.  A large number of these on both projects were women and ethnic minorities.\n\n \n\n\t\t\t\t\tLast Modified: 10/12/2021\n\n\t\t\t\t\tSubmitted by: Julia B Hirschberg"
 }
}