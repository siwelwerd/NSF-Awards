{
 "awd_id": "1756892",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ATD: Online Multiscale Algorithms for Geometric Density Estimation in High-Dimensions and Persistent Homology of Data for Improved Threat Detection",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leland Jameson",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 379940.0,
 "awd_amount": 379940.0,
 "awd_min_amd_letter_date": "2017-08-21",
 "awd_max_amd_letter_date": "2017-08-21",
 "awd_abstract_narration": "The investigator and his colleagues develop novel ideas to tackle challenges in threat detection. The starting point are insights from multiscale geometric and topological analysis of high-dimensional data: low-intrinsic dimensionality, manifold structures and/or other types of geometric properties of the data are exploited by their novel approaches for tasks such as density estimation, anomaly detection, dimensionality reduction and classification. This approach has the advantage of being adaptive to the low intrinsic dimensionality of the data, thereby leading to algorithms to perform these tasks efficiently, both in terms of sample size require to learn, and in terms of computational costs, leading to a new generation of results and algorithms. Their research focuses on the detection of chemical attacks, which are one of the most pernicious threats, and in particular on hyperspectral imaging for chemical detection, specifically using atmospheric longwave infrared spectroscopy built into the longwave HSI systems. He and his collaborators apply these techniques to HSI data, in the form of images and streaming HSI movies containing chemical plumes, taking advantage of the speed of the proposed techniques.\r\n\r\nThe input data (images, spectra, etc...) for many threat detection problems is typically large, high-dimensional, corrupted by noise, and often subject to distortions due to environmental conditions. Many threat detection tasks fall into one of the following broad categories: regression, classification, anomaly or outlier detection, and changepoint detection. These tasks face the fundamental curse of dimensionality: to achieve a target level of accuracy, the number of observations required is exponential in the number of dimensions of the data. Such dimension may be the number of pixels in a sub-image of interest or the number of spectral bands in a HyperSpectral Image (HSI) or a spectrometer, and may be very large. This makes the analysis of high-dimensional data hopeless unless we can discover a low-dimensional representation of the data, or at least of those features of the data that are sufficient to perform the task at hand: the PI and his colleagues develop novel techniques for discovering such representations and exploiting them to model the data, and detecting anomalies in evolving data. These constructions and algorithms enhance our capability in threat detection, and are key to advance information technology in the field of analysis of large data sets arising in threat detection.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mauro",
   "pi_last_name": "Maggioni",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mauro Maggioni",
   "pi_email_addr": "mauro.maggioni@jhu.edu",
   "nsf_id": "000398937",
   "pi_start_date": "2017-08-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University Krieger School of Arts and Sciences",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182825",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": null,
 "pgm_ref": [
  {
   "pgm_ref_code": "6877",
   "pgm_ref_txt": "ALGORITHMS IN THREAT DETECTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 379940.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The PI's developed novel techniques for the analysis of data sets, both at the level of novel fundamental construtions and algoirthms with broad applicability, and at the level of specific applications, in particular hyperspectral imaging.</p>\n<p>Large data sets arise in a wide variety of source in daily life, and applications in industry. Many data sets are large, both in terms of number of points, representing individuals/transanction records/images/sounds etc..., and in terms of dimensionality, meaning that each data point is represented by a long list of numbers. For example in a HyperSpectral Image (HSI) each pixel may be considered a data point, and is composed of a long vector of numbers proportional to the number of photons in different frequency bands. While regular cameras may collect photons in 3 bins (roughly speaking) at each pixel, corresponding to RGB, an HSI camera collects photons in as many as 100 bins, or more. Since different materials absorb and reflect photons of different frequencies differently, an HSI is able to discriminate between different materials, at each pixel, much more efficiently than regular cameras. HSI has found many applications in the geosciences, agriculture, monitoring of natural and human-made landscapes, dermatology, and more.</p>\n<p>Within this project, the PI's developed novel techniques for automatically compress and analyze large high-dimensional data sets, such as those arising in HSI. It is often of interest, in order to minimize storage, transmission and processing costs, to be able to efficiently encode, or compress, data. This is achieved by exploiting dependencies between the coordinates of the data. When these depedencies are unknown, algorithms can be designed to discover them and exploit them. The PI's introduced and developed, both theoretically and algorithmically, such an approach, called Geometric Multi-Resolution Analysis (GMRA), which enables provably efficient encodings of data whose coordinates have rather general types of possibly nonlinear dependencies. It also yields an efficient encoding and decoding scheme for compressing and decompressing data, together with guarantees on the performance of learning such representations, the compression factor, and the accuracy of such representations, depending on the amount of data available during the learning phase, the intrinsic dimension of the data (that quantifies the number of independent coordinates) and other factors.</p>\n<p>The PI's also developed methods exploiting GMRA for a variety of data analysis and statistical tasks, such as predicting functions of data. For example one may want to automatically segment a HSI into homogeneous regions, or detected objects in the HSI that are different from either the background or from things seend in the past. These tasks are laborious when performed by hand by experts, and the amount of data is too large to be amenable to hand-labeled. We developed algorithms for automatic segmentation of HSI images, as well as for detecting ``anomalies'' in single HSI images and in HSI movies, for example to detect chemical plumes invisible to the human eye. These algorithms have been benchmarked on a variety of data sets, and against several state-of-art algoirthms: this demonstrates their empirical performance at or above the state-of-art. The techniques developed have been incorporated in software packages that are made freely available on the internet.</p>\n<p>The techniques above were further extended and integrated with topological data analysis techniques, which seek to discover very robust patterns in high-dimensional data, and with compressed-sensing techniques, were instruments themselves measure data directly in a compressed format, with minimal loss of information (under suitable assumptions on the data and the measurements). They have also been extended to the study of time-varying data, and to the problem of inferring interaction rules between agents given only observations of their trajectories.</p>\n<p>Many of the ideas and algorithms developed are not specific to HSI, and we expect them to be useful in a variety of applications were large data sets need to be analyzed, and automatically labelled: the PI's expect that the results of the project will have broader impacts in these disciplines and applications. The PI's have also been collaborating with companies interested in deploying these tools for analyzing data of interest, for example from collections of text documents and images.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/29/2017<br>\n\t\t\t\t\tModified by: Mauro&nbsp;Maggioni</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe PI's developed novel techniques for the analysis of data sets, both at the level of novel fundamental construtions and algoirthms with broad applicability, and at the level of specific applications, in particular hyperspectral imaging.\n\nLarge data sets arise in a wide variety of source in daily life, and applications in industry. Many data sets are large, both in terms of number of points, representing individuals/transanction records/images/sounds etc..., and in terms of dimensionality, meaning that each data point is represented by a long list of numbers. For example in a HyperSpectral Image (HSI) each pixel may be considered a data point, and is composed of a long vector of numbers proportional to the number of photons in different frequency bands. While regular cameras may collect photons in 3 bins (roughly speaking) at each pixel, corresponding to RGB, an HSI camera collects photons in as many as 100 bins, or more. Since different materials absorb and reflect photons of different frequencies differently, an HSI is able to discriminate between different materials, at each pixel, much more efficiently than regular cameras. HSI has found many applications in the geosciences, agriculture, monitoring of natural and human-made landscapes, dermatology, and more.\n\nWithin this project, the PI's developed novel techniques for automatically compress and analyze large high-dimensional data sets, such as those arising in HSI. It is often of interest, in order to minimize storage, transmission and processing costs, to be able to efficiently encode, or compress, data. This is achieved by exploiting dependencies between the coordinates of the data. When these depedencies are unknown, algorithms can be designed to discover them and exploit them. The PI's introduced and developed, both theoretically and algorithmically, such an approach, called Geometric Multi-Resolution Analysis (GMRA), which enables provably efficient encodings of data whose coordinates have rather general types of possibly nonlinear dependencies. It also yields an efficient encoding and decoding scheme for compressing and decompressing data, together with guarantees on the performance of learning such representations, the compression factor, and the accuracy of such representations, depending on the amount of data available during the learning phase, the intrinsic dimension of the data (that quantifies the number of independent coordinates) and other factors.\n\nThe PI's also developed methods exploiting GMRA for a variety of data analysis and statistical tasks, such as predicting functions of data. For example one may want to automatically segment a HSI into homogeneous regions, or detected objects in the HSI that are different from either the background or from things seend in the past. These tasks are laborious when performed by hand by experts, and the amount of data is too large to be amenable to hand-labeled. We developed algorithms for automatic segmentation of HSI images, as well as for detecting ``anomalies'' in single HSI images and in HSI movies, for example to detect chemical plumes invisible to the human eye. These algorithms have been benchmarked on a variety of data sets, and against several state-of-art algoirthms: this demonstrates their empirical performance at or above the state-of-art. The techniques developed have been incorporated in software packages that are made freely available on the internet.\n\nThe techniques above were further extended and integrated with topological data analysis techniques, which seek to discover very robust patterns in high-dimensional data, and with compressed-sensing techniques, were instruments themselves measure data directly in a compressed format, with minimal loss of information (under suitable assumptions on the data and the measurements). They have also been extended to the study of time-varying data, and to the problem of inferring interaction rules between agents given only observations of their trajectories.\n\nMany of the ideas and algorithms developed are not specific to HSI, and we expect them to be useful in a variety of applications were large data sets need to be analyzed, and automatically labelled: the PI's expect that the results of the project will have broader impacts in these disciplines and applications. The PI's have also been collaborating with companies interested in deploying these tools for analyzing data of interest, for example from collections of text documents and images.\n\n\t\t\t\t\tLast Modified: 12/29/2017\n\n\t\t\t\t\tSubmitted by: Mauro Maggioni"
 }
}