{
 "awd_id": "1733558",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Medium: Collaborative Research: Collective Opinion Fraud Detection: Identifying and Integrating Cues from Language, Behavior, and Networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2016-06-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 417100.0,
 "awd_amount": 417100.0,
 "awd_min_amd_letter_date": "2017-03-20",
 "awd_max_amd_letter_date": "2017-03-20",
 "awd_abstract_narration": "Given user reviews on Web sites such as Yelp, Amazon, and TripAdvisor, which ones should one trust? Online reviews have become an important resource for public opinion sharing. They influence our decisions over an extremely wide spectrum of daily and professional activities: e.g., where to eat, where to stay, which products to purchase, which doctors to see, which books to read, which universities to attend, and so on. However, the credibility and trustworthiness of online reviews are at stake. It is well known that a large body of reviews is fabricated -- either by owners, competitors, or entities paid by those -- to create false perception on the actual quality of the products and services. What is more, opinion fraud is prevalent; while credit card fraud is as rare as 0.2% or less, it is estimated that 20-30% of the reviews on well-known service sites could be fake. This poses a serious risk to businesses and the public, from investing on a low-quality product to consulting an incompetent doctor for diagnosis and treatment. Like other kinds of fraud, opinion fraud is a serious legal offense. In fact, it is currently being recognized as a serious issue in law enforcement by policymakers. Thus solving this problem is of great importance to businesses and the general public alike. Accurately spotting opinion fraud will enable site owners to provide trustworthy content, maintain the integrity of their service, and protect the online citizens from unfair (or potentially harmful) products and services. Businesses will also benefit from reviews with reliable feedback. Honest businesses will be indirectly rewarded, as it will no longer be easy for unscrupulous businesses to benefit from fake reviews. The research outcomes will thus contribute significantly to the healthy growth of the Internet commerce. Educational activities include incorporating research findings in graduate level courses, educating public on fraudulent behavior and misinformation, and providing publicly available educational materials including lectures and manuscripts.\r\n\r\nGiven the critical issues of opinion fraud in online communities, how can one identify fake reviews and attribute responsible culprits behind them? By conjoining expertise of the PIs over various modalities of deception footprints ranging over language, user behavior, and relational information, this project presents a research program that will result in much needed solutions to this emergent, prevalent, and socially impactful problem. The ultimate goal is to create a unified detection framework via synergistic integration of multiple information sources; from linguistics, user behavior, and network effects, to obtain the best of all worlds. The main idea is to formulate the problem as a relational inference task on composite heterogeneous networks, providing a principled, extensible approach that can blend and reinforce all the above cues towards effective and robust detection of fraud. From a scientific point of view, the research brings together three disciplines: natural language analysis, behavioral modeling, and graph mining. The outcome is a suite of novel, principled, and scalable techniques and models that will enhance our understanding of the creation and dissemination of opinion fraud and misinformation in general at a large scale. The PIs will collaborate with industry partners such as Yelp, Google, and Amazon, directly solicit online fake reviews, and conduct well-designed user studies for testing and validation of their techniques. The project web site (http://www.andrew.cmu.edu/user/lakoglu/PROJECTS/OPINION_FRAUD/) provides additional information and will include open-source software and datasets.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Leman",
   "pi_last_name": "Akoglu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Leman Akoglu",
   "pi_email_addr": "lakoglu@cs.cmu.edu",
   "nsf_id": "000626991",
   "pi_start_date": "2017-03-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "H. John Heinz III College",
  "perf_str_addr": "5000 Forbes Ave",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 417100.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><br />Given online user reviews on Web sites such as Yelp, Amazon, and TripAdvisor, which ones should one trust? Online reviews have become an important resource for public opinion sharing. They influence our decisions over an extremely wide spectrum of daily and professional activities: e.g., where to eat, where to stay, which products to purchase, which doctors to see, which books to read, which universities to attend, and so on. However, the credibility and trustworthiness of online reviews are at stake.&nbsp;A large body of reviews is fabricated -- either by owners, competitors, or entities paid by those -- to create false perception on the actual quality of the products and services, under strong financial gain incentives.&nbsp;</p>\n<p><br />In this work,&nbsp; we focused on methods to spot such activities, so that on-line companies can safeguard against and neutralize them.&nbsp; The merit of our work is the development of&nbsp; novel, fast algorithms for detecting fraudulent entities; that is fake reviews and the accounts from which those were created. We found that actors behind generating fake reviews are &lsquo;connected&rsquo; in several aspects; making network based methods particularly suitable. To this end, we developed various graph-based solutions for scoring and ranking such entities, and identifying collusive groups or campaigns that they form.&nbsp;<br />The broader impact is that our algorithms are publicly available in the form of documented software packages, and we understand that some of them are in production at FlipKart, Amazon, and possibly more.&nbsp;&nbsp;</p>\n<p><br />With respect to dissemination, this project produced multiple workshops (the 5 series of ODD workshops at KDD between 2013-2018), and tutorials on misbehavior and fake content detection at top data mining venues. The project has also involved several PhD students, undergraduate and MS students, and led to dissertations at Stony Brook as well as at the co-PI institutions, including: Ms. Shebuti Rayana and Mr. Junting Ye.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/22/2020<br>\n\t\t\t\t\tModified by: Leman&nbsp;Akoglu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nGiven online user reviews on Web sites such as Yelp, Amazon, and TripAdvisor, which ones should one trust? Online reviews have become an important resource for public opinion sharing. They influence our decisions over an extremely wide spectrum of daily and professional activities: e.g., where to eat, where to stay, which products to purchase, which doctors to see, which books to read, which universities to attend, and so on. However, the credibility and trustworthiness of online reviews are at stake. A large body of reviews is fabricated -- either by owners, competitors, or entities paid by those -- to create false perception on the actual quality of the products and services, under strong financial gain incentives. \n\n\nIn this work,  we focused on methods to spot such activities, so that on-line companies can safeguard against and neutralize them.  The merit of our work is the development of  novel, fast algorithms for detecting fraudulent entities; that is fake reviews and the accounts from which those were created. We found that actors behind generating fake reviews are \u2018connected\u2019 in several aspects; making network based methods particularly suitable. To this end, we developed various graph-based solutions for scoring and ranking such entities, and identifying collusive groups or campaigns that they form. \nThe broader impact is that our algorithms are publicly available in the form of documented software packages, and we understand that some of them are in production at FlipKart, Amazon, and possibly more.  \n\n\nWith respect to dissemination, this project produced multiple workshops (the 5 series of ODD workshops at KDD between 2013-2018), and tutorials on misbehavior and fake content detection at top data mining venues. The project has also involved several PhD students, undergraduate and MS students, and led to dissertations at Stony Brook as well as at the co-PI institutions, including: Ms. Shebuti Rayana and Mr. Junting Ye.\n\n\t\t\t\t\tLast Modified: 05/22/2020\n\n\t\t\t\t\tSubmitted by: Leman Akoglu"
 }
}