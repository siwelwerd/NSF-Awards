{
 "awd_id": "1723420",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SCH: EAGER: RUI: Collaborative Research: A novel 3D image predictive model for osteoarthritis disease",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2017-09-15",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 208107.0,
 "awd_amount": 208107.0,
 "awd_min_amd_letter_date": "2017-09-05",
 "awd_max_amd_letter_date": "2021-07-20",
 "awd_abstract_narration": "Knee osteoarthritis (OA) affects 10% of older adults and is a major cause of work absence, early retirement and joint replacement. Knee OA is a disease characterized by deterioration of the cartilage in the knee. Using current technology, it is hard to predict how fast or how much deterioration will take place because cartilage loss is a slow and gradual process and can only be detected through medical images. This project will explore a novel 3D image model that can predict the accurate change of knee cartilage, to facilitate early detection and personal treatment for OA. If successful, the project could benefit 35 million people in the United States by reducing the high economic cost related to OA treatment, and improving the quality of life for these people. The PIs plan to disseminate the research to local medical communities and design a new course to involve undergraduate students into the research. The novel 3D image predictive model should have a wide variety of imaging applications.\r\n \r\nThe goal of this project is to explore a novel 3D-information-fusion mechanism for medical imaging and a novel 3D image-to-image predictive model using deep neural networks as the core. The project will integrate cartilage information from MRI sequences. To handle size differences and perform image registration, a universal coordinate system will be defined to form a continuous and complete representation of the cartilage plane. Using the coordinate system, deep neural networks will be trained to learn the underlying correlation between the 3D cartilage maps. Unlike the traditional image-to-single-value prediction, the model will make image-to-image prediction; that is, from a current 3D cartilage map to a future 3D cartilage map, for different lengths of time (2, 4, 6, and 8 years respectively), leveraging a large imaging database. Finally, the team will construct the future 3D knee models from the cartilage maps to display the trajectory of cartilage change in a 3D view.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Juan",
   "pi_last_name": "Shan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Juan Shan",
   "pi_email_addr": "jshan@pace.edu",
   "nsf_id": "000654212",
   "pi_start_date": "2017-09-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pace University New York Campus",
  "inst_street_address": "1 PACE PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2123461200",
  "inst_zip_code": "100381502",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "PACE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "Y738A5L1B3V1"
 },
 "perf_inst": {
  "perf_inst_name": "Pace University",
  "perf_str_addr": "One Pace Plaza",
  "perf_city_name": "NYC",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100381502",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 208107.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Knee osteoarthritis (OA) affects 10% of the population over 55 years old, and is a major cause of work absence, early retirement and joint replacement. It is still unclear what causes the disease and how to treat it effectively. Our project has explored different ways to apply the morden machine learning techniques for knee OA diagnosis and prediction, to save time for doctors and radiologists from time-consuming labeling work and diagnosis process. We have developed machine learning models that can automatically analyze the medical images of knee to detect early signs of the OA disease. These disease indicators are further integrated to provide a diagnosis decision about what if the case is healthy or how severe the case is. The accuracy of our bone segmentation model achieved 0.97 in DICE coefficient (1 is the highest). The bone marrow lesion and effusion segmentation methods achieved DICE coefficient of 0.56 and 0.77 respectively. Particularly, we developed machine learning models that analyzes cartilage damage index (CDI) which measures cartilage thickness at multiple locations for the whole knee. Our model has achieved a high OA classification performance with AUC = 0.903. We also developed end-to-end classifying systems using both X-ray and MRI as input. Our experiment results showed that when one has both X-ray and MRI available, the OA severity diagnosis accuracy of the model is highest. Using the data from the public OAI dataset, taking only X-ray as input, the diagnosis accuracy (classify the case into OA and non-OA) is 77%; taking only MRI as input, the diagnosis accuracy is 83%; taking both as input, the fused model can achieve an accuracy of 86%. By leveraging the transfer learning technique, the accuracy can be further increased to 88%.&nbsp;</p>\n<p class=\"Default\">Our work has shown that machine learning methods have great potential to automate and facilitate the diagnosis of knee OA clinically. The machine learning models can automate the detection of biomarkers, can integrate the biomarkers into a decision-making system, and can also make a diagnosis decision directly based on a patient's medical images and clinical data. The methods can be used to improve the early diagnosis and detection of knee OA, which could potentially benefit the 35 million people in the U.S. who are at risk of OA by taking intervention to slow down the progression. The broader and longer impact includes reducing the high economic cost related to OA treatment, and improving the quality of life for people after retirement.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/19/2022<br>\n\t\t\t\t\tModified by: Juan&nbsp;Shan</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504217922_Fusionmodel--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504217922_Fusionmodel--rgov-800width.jpg\" title=\"fusion model\"><img src=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504217922_Fusionmodel--rgov-66x44.jpg\" alt=\"fusion model\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fusion model that integrates X-ray, MRI, and clinical data for knee OA prediction.</div>\n<div class=\"imageCredit\">1</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Juan&nbsp;Shan</div>\n<div class=\"imageTitle\">fusion model</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504149642_Kneebonesegmentationmodel--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504149642_Kneebonesegmentationmodel--rgov-800width.jpg\" title=\"knee bone segmentation\"><img src=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504149642_Kneebonesegmentationmodel--rgov-66x44.jpg\" alt=\"knee bone segmentation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Flowchart of the knee bone segmentation method</div>\n<div class=\"imageCredit\">1</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Juan&nbsp;Shan</div>\n<div class=\"imageTitle\">knee bone segmentation</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504098191_CDIonkneecartilage--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504098191_CDIonkneecartilage--rgov-800width.jpg\" title=\"CDI\"><img src=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504098191_CDIonkneecartilage--rgov-66x44.jpg\" alt=\"CDI\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">60 Cartilage Damage Index (CDI) locations on knee cartilage</div>\n<div class=\"imageCredit\">1</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Juan&nbsp;Shan</div>\n<div class=\"imageTitle\">CDI</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504644931_fig4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504644931_fig4--rgov-800width.jpg\" title=\"bone segmentation result\"><img src=\"/por/images/Reports/POR/2022/1723420/1723420_10520561_1671504644931_fig4--rgov-66x44.jpg\" alt=\"bone segmentation result\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Examples of automatic knee bone segmentation results.</div>\n<div class=\"imageCredit\">1</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Juan&nbsp;Shan</div>\n<div class=\"imageTitle\">bone segmentation result</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nKnee osteoarthritis (OA) affects 10% of the population over 55 years old, and is a major cause of work absence, early retirement and joint replacement. It is still unclear what causes the disease and how to treat it effectively. Our project has explored different ways to apply the morden machine learning techniques for knee OA diagnosis and prediction, to save time for doctors and radiologists from time-consuming labeling work and diagnosis process. We have developed machine learning models that can automatically analyze the medical images of knee to detect early signs of the OA disease. These disease indicators are further integrated to provide a diagnosis decision about what if the case is healthy or how severe the case is. The accuracy of our bone segmentation model achieved 0.97 in DICE coefficient (1 is the highest). The bone marrow lesion and effusion segmentation methods achieved DICE coefficient of 0.56 and 0.77 respectively. Particularly, we developed machine learning models that analyzes cartilage damage index (CDI) which measures cartilage thickness at multiple locations for the whole knee. Our model has achieved a high OA classification performance with AUC = 0.903. We also developed end-to-end classifying systems using both X-ray and MRI as input. Our experiment results showed that when one has both X-ray and MRI available, the OA severity diagnosis accuracy of the model is highest. Using the data from the public OAI dataset, taking only X-ray as input, the diagnosis accuracy (classify the case into OA and non-OA) is 77%; taking only MRI as input, the diagnosis accuracy is 83%; taking both as input, the fused model can achieve an accuracy of 86%. By leveraging the transfer learning technique, the accuracy can be further increased to 88%. \nOur work has shown that machine learning methods have great potential to automate and facilitate the diagnosis of knee OA clinically. The machine learning models can automate the detection of biomarkers, can integrate the biomarkers into a decision-making system, and can also make a diagnosis decision directly based on a patient's medical images and clinical data. The methods can be used to improve the early diagnosis and detection of knee OA, which could potentially benefit the 35 million people in the U.S. who are at risk of OA by taking intervention to slow down the progression. The broader and longer impact includes reducing the high economic cost related to OA treatment, and improving the quality of life for people after retirement.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/19/2022\n\n\t\t\t\t\tSubmitted by: Juan Shan"
 }
}