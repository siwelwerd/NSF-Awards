{
 "awd_id": "1718051",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Understanding Human Performance Consequences of Using Headworn Displays for Large Assemblies",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Balakrishnan Prabhakaran",
 "awd_eff_date": "2017-08-15",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 499984.0,
 "awd_amount": 499984.0,
 "awd_min_amd_letter_date": "2017-08-04",
 "awd_max_amd_letter_date": "2017-08-04",
 "awd_abstract_narration": "The field of construction is increasingly interested in head worn displays (HWDs) that might provide construction workers with augmented reality (AR) information such as blueprints or overlaid annotations and instructions.  However, these HWDs might not have the desired effects of improved safety and efficiency: they could instead interfere physically or mentally with the job at hand, reducing workers' situational awareness.  This project is about better understanding the design and effects of AR HWDs for common construction tasks such as framing and sheathing.  The team will work with industry partners to understand the needs and risks workers face in order to develop task-specific AR interfaces as well as ways to measure safety, efficiency, awareness, and satisfaction.  They will then evaluate and refine both the interfaces and measures in a series of controlled experiments that evaluate the interfaces in a large motion-capture lab at the PIs' home institution.  The goal is to provide a generally useful suite of tasks, interfaces, measures, and guidelines for AR HWDs in construction and beyond.  The team will also partner with the Building Women in Construction organization to develop AR experiences for middle and high school students that use the technology for outreach and education. \r\n\r\nThe team will start by working with a stakeholder group to develop meaningful metrics of efficiency using interviews and review of stakeholder quality control documents.  Based on preliminary work, and the team's access to motion capture equipment, these are likely to go beyond time taken and errors made and include factors such as tool and material choice, positioning and use, and damage.  They will also develop specific measures of situational awareness, workload, and usability based on existing guidelines and scales, conducting pilot user studies to refine them and ensure that they can be administered in the simulated environment.  The interfaces and experimental testbed will be developed using the motion capture lab facilities and commodity AR HWD devices: developing both conformal and non-conformal AR interfaces at different levels of fidelity and at different scales; simulating the hazards and distractions of a real construction site through including real and simulated objects and noises; and developing methods to track both behavior and object use.  These will be evaluated in a series of controlled experiments using a balanced Latin Squares design, varying the presentation of information (including a control version using paper blueprints) and the scale of the conformal elements relative to the task area.  The team will compute metrics developed in earlier stages and conduct interviews to get at participants' subjective satisfaction, engagement, perceptions of usability, and ideas for improvements.  For the education and outreach portions of the project, they will also develop a smaller-scale AR HWD exercise to support a spaghetti bridge construction task commonly used in schools.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Joseph",
   "pi_last_name": "Gabbard",
   "pi_mid_init": "L",
   "pi_sufx_name": "Jr",
   "pi_full_name": "Joseph L Gabbard",
   "pi_email_addr": "jgabbard@vt.edu",
   "nsf_id": "000356087",
   "pi_start_date": "2017-08-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Tanyel",
   "pi_last_name": "Bulbul",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tanyel Bulbul",
   "pi_email_addr": "tanyel@vt.edu",
   "nsf_id": "000527403",
   "pi_start_date": "2017-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Polytechnic Institute and State University",
  "inst_street_address": "300 TURNER ST NW",
  "inst_street_address_2": "STE 4200",
  "inst_city_name": "BLACKSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "5402315281",
  "inst_zip_code": "240603359",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "VA09",
  "org_lgl_bus_name": "VIRGINIA POLYTECHNIC INSTITUTE & STATE UNIVERSITY",
  "org_prnt_uei_num": "X6KEFGLHSJX7",
  "org_uei_num": "QDE5UHE5XD16"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Polytechnic Institute and State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "240610001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "VA09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 499984.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The major goals of this work were to investigate new connections between augmented reality (AR) information presentation, visual fidelity, construction task performance, constructor worker behavior, mental workload and overall awareness of the construction settings.&nbsp;</p>\n<p>Our work has been disseminated publicly in a few different forms, including scientific publications and conference presentations.&nbsp; We presented a conference paper at the American Society of Civil Engineers&rsquo; Construction Research Congress (one of the prime international conferences in the area of construction engineering and management) describing our initial application of electroencephalogram (EEG) head-worn technology to assess&nbsp;worker&rsquo;s mental workload in real-time while using an AR display. We also published a journal paper in Advanced Engineering Informatics describing our study to understand the impact of different AR information display methods on the scale of assembled wooden walls.&nbsp;</p>\n<p>&nbsp;</p>\n<p>The results from this work have many implications across society. For example:</p>\n<ul>\n<li>Our work has created several new AR testbed for construction as well as for methods for analyzing AR use in construction domains.&nbsp; These scientific outcomes, in turn, afford University researchers additional safety-critical research by students in construction as well as other application domains.&nbsp; For example, students in PI Gabbard&rsquo;s lab are using the behavioral analysis techniques and methods to assess the awareness of the environment to examine AR-enabled human-robot collaboration in search and rescue, emergency response and other industrial domains.</li>\n<li>The methods we developed will help assess the effect of AR user interfaces on worker&rsquo;s mental workload, situational awareness, and behavior (e.g., distance moved, # of crouches, head rotations) and can be applied to many other important work areas where AR is used for extended periods of time in dynamic, potentially hazardous work environments.</li>\n<li>The AR applications we developed for middle school students while them learn bridge building concepts. The AR applications not only exposed the students using cutting edge AR technology, but also taught them an appreciation of science and engineering in the construction domain.</li>\n<li>The project supported two graduate students who upon graduation with PhD degrees, will enter the workforce with specialization in augmented reality for building and construction, and will contribute to future generations of student and worker well-being.</li>\n<li>The construction scenarios we investigated using AR are now being used to frame classroom discussions, where students engaged in semester-long projects can design AR interfaces to support different work settings and take into account worker safety and health.</li>\n</ul>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/13/2022<br>\n\t\t\t\t\tModified by: Joseph&nbsp;L&nbsp;Gabbard</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe major goals of this work were to investigate new connections between augmented reality (AR) information presentation, visual fidelity, construction task performance, constructor worker behavior, mental workload and overall awareness of the construction settings. \n\nOur work has been disseminated publicly in a few different forms, including scientific publications and conference presentations.  We presented a conference paper at the American Society of Civil Engineers\u2019 Construction Research Congress (one of the prime international conferences in the area of construction engineering and management) describing our initial application of electroencephalogram (EEG) head-worn technology to assess worker\u2019s mental workload in real-time while using an AR display. We also published a journal paper in Advanced Engineering Informatics describing our study to understand the impact of different AR information display methods on the scale of assembled wooden walls. \n\n \n\nThe results from this work have many implications across society. For example:\n\nOur work has created several new AR testbed for construction as well as for methods for analyzing AR use in construction domains.  These scientific outcomes, in turn, afford University researchers additional safety-critical research by students in construction as well as other application domains.  For example, students in PI Gabbard\u2019s lab are using the behavioral analysis techniques and methods to assess the awareness of the environment to examine AR-enabled human-robot collaboration in search and rescue, emergency response and other industrial domains.\nThe methods we developed will help assess the effect of AR user interfaces on worker\u2019s mental workload, situational awareness, and behavior (e.g., distance moved, # of crouches, head rotations) and can be applied to many other important work areas where AR is used for extended periods of time in dynamic, potentially hazardous work environments.\nThe AR applications we developed for middle school students while them learn bridge building concepts. The AR applications not only exposed the students using cutting edge AR technology, but also taught them an appreciation of science and engineering in the construction domain.\nThe project supported two graduate students who upon graduation with PhD degrees, will enter the workforce with specialization in augmented reality for building and construction, and will contribute to future generations of student and worker well-being.\nThe construction scenarios we investigated using AR are now being used to frame classroom discussions, where students engaged in semester-long projects can design AR interfaces to support different work settings and take into account worker safety and health.\n\n\n \n\n\t\t\t\t\tLast Modified: 02/13/2022\n\n\t\t\t\t\tSubmitted by: Joseph L Gabbard"
 }
}