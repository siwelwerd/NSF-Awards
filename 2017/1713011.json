{
 "awd_id": "1713011",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Reproducing Kernel Hilbert Space Embedding of Measures: Theory and Applications to Statistical Learning",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 178251.0,
 "awd_amount": 178251.0,
 "awd_min_amd_letter_date": "2017-04-25",
 "awd_max_amd_letter_date": "2019-08-02",
 "awd_abstract_narration": "The statistical estimation and inference questions considered in this project appear in many areas of science and engineering that rely on statistical research. Some of these areas of high societal impact include social and behavioral research, forensic sciences, early detection of covert communications and breaches in data security, early-warning systems for identifying outbreaks of infectious diseases, cognitive development studies in children, and drug discovery, among many others. In many of these areas, commonly-used statistical methods make strong assumptions about the data-generating distribution. Such simplistic approaches may be unjustified; moreover, even if these assumptions make sense, they need to be tested. This research project investigates a powerful alternative to these existing methods and aims to develop a fundamental theoretical understanding of the same, leading to novel statistical applications. Code for algorithms that result from this project will be made publicly available for ready use.\r\n\r\nThe kernel method is a class of statistical methodology that has gained popularity in statistical learning due to its ability to handle both high-dimensional and non-Euclidean data. The core idea of the method is to map observed data to a function space, called the reproducing kernel Hilbert space (RKHS), which allows capture of non-linear relationships in the data. This project concerns theoretical and methodological research on a generalization of this method by embedding probability measures in an RKHS. This generalization has wide applicability in statistical learning problems such as nonparametric hypothesis testing, density estimation, and regression on distributions, which will be explored in this project. On the theoretical front, the characterization of injectivity of kernel embedding will be considered. While such a characterization is well understood for kernels defined on locally compact Abelian groups and compact non-Abelian groups, this project will investigate the injectivity of the kernel embedding for non-standard spaces such as nuclear spaces, the space of graphs, and the positive definite cone. The injectivity of the embedding is known to be related to the richness of the RKHS in approximating a certain class of functions. The research will investigate the rate of this approximation, which turns out to be critical in analyzing the convergence rates of kernel-based regression and density estimators and separation rates in hypothesis testing. An injective embedding induces a metric, called the kernel distance on the space of probabilities, which is defined as the RKHS distance between the kernel embeddings of two probability measures. The investigator will study the relation of kernel distance to other probability metrics such as the energy distance, distance covariance, f-divergence, and integral probability metrics in order to understand the statistical/computational (dis)advantages associated with these distances. These theoretical studies have an applied counterpart, wherein the RKHS embedding plays a critical role in the problems of regression on probability measures and density estimation in infinite dimensional exponential families. For these problems, the investigator plans to develop computationally efficient estimators with theoretical guarantees. Overall, the project aims to develop a comprehensive theory of RKHS embedding of probability measures with applications to problems in statistical learning.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bharath",
   "pi_last_name": "Sriperumbudur",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bharath Sriperumbudur",
   "pi_email_addr": "bks18@psu.edu",
   "nsf_id": "000731475",
   "pi_start_date": "2017-04-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "",
  "perf_city_name": "State College",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168027000",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "PA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 58227.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 59404.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 60620.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>During the project period, in collaboration with graduate students, postdocs and peer-researchers, the PI has contributed to the theory of RKHS embedding of probability measures and applied it to novel statistical methods. Some of the key contributions of this research include kernel (conditional) dependency measures and characterization of independence using tensor product kernels, computational vs. statistical trade-off in kernel principal component analysis, convergence behavior of kernel quadrature rules, nonparametric regression on probability measures, function-on-function and function-on-scalar regression, and random projection in reproducing kernel Hilbert space.&nbsp;Overall, this research makes important contributions to non-parametric estimation, functional data analysis, and statistical machine learning, and impacts all areas of science and engineering that employs statistical tools such as regression and hypothesis testing.</p>\n<p>The outcomes of this research are disseminated through eleven journal articles (few articles still under review), three peer-reviewed conference publications, thirteen invited conference/workshop talks and ten seminars in departmental colloquia across various US and foreign universities.</p>\n<p>The project also provided an opportunity to train two Ph. D. students with some of the research contributing to their Ph. D. disseration, provided student funding for conference participation, and aided to the development of a new advanced graduate level course on nonparametrics and learning theory.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/21/2021<br>\n\t\t\t\t\tModified by: Bharath&nbsp;Sriperumbudur</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDuring the project period, in collaboration with graduate students, postdocs and peer-researchers, the PI has contributed to the theory of RKHS embedding of probability measures and applied it to novel statistical methods. Some of the key contributions of this research include kernel (conditional) dependency measures and characterization of independence using tensor product kernels, computational vs. statistical trade-off in kernel principal component analysis, convergence behavior of kernel quadrature rules, nonparametric regression on probability measures, function-on-function and function-on-scalar regression, and random projection in reproducing kernel Hilbert space. Overall, this research makes important contributions to non-parametric estimation, functional data analysis, and statistical machine learning, and impacts all areas of science and engineering that employs statistical tools such as regression and hypothesis testing.\n\nThe outcomes of this research are disseminated through eleven journal articles (few articles still under review), three peer-reviewed conference publications, thirteen invited conference/workshop talks and ten seminars in departmental colloquia across various US and foreign universities.\n\nThe project also provided an opportunity to train two Ph. D. students with some of the research contributing to their Ph. D. disseration, provided student funding for conference participation, and aided to the development of a new advanced graduate level course on nonparametrics and learning theory.\n\n \n\n\t\t\t\t\tLast Modified: 10/21/2021\n\n\t\t\t\t\tSubmitted by: Bharath Sriperumbudur"
 }
}