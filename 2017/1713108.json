{
 "awd_id": "1713108",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Inference for Dynamic Objects",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 125000.0,
 "awd_amount": 125000.0,
 "awd_min_amd_letter_date": "2017-08-04",
 "awd_max_amd_letter_date": "2019-08-14",
 "awd_abstract_narration": "Modern data collection techniques result in a steady stream of complex data. The field of statistics has an obligation to develop tools for their analysis, allowing users to draw meaningful and correct conclusions. In view of the complexity of the collected data, this is a challenging task. This project will tackle these challenges by not only constructing relevant novel methodologies, but by also analyzing these methods in order to establish a thorough understanding of their strengths and weaknesses. This, in turn, will facilitate an honest evaluation and interpretation of practical data analysis results. One instance of a complex data type considered in this project is network data. A relevant real-world example is the world trade network, consisting of trading indices between pairs of countries. Countries can be grouped into trading blocks, and this project will develop methodology allowing the analysis of the dependence structure between the trading blocks. This will help to identify factors that are driving this dependence, and how they change over time. More generally, the outcomes of this project are expected to impact the field of statistics and various fields of application. This will be achieved by widely disseminating statistical insight, methodologies and theory developed in this project through publications in international statistics journals, presentations at national and international conferences, and by developing relevant software/code to be made available to the community. Moreover, this project will directly contribute to the training of both graduate students and undergraduate students in modern fields of statistics. It is expected that there will be mutual benefits and synergies between this project and the ongoing NSF Research Training Grant in Statistics at UC Davis. \r\n\r\nThis project seeks to develop novel statistical methods for the analysis of dynamic object data, in particular, networks and functional data. More specifically, this project will (i) study dependence structures in hierarchical time-varying block models for stochastic networks, and apply the resulting methodologies to the analysis of economic network data such as trade networks; (ii) develop a class of continuous-time point process models for random networks, allowing for a flexible model and analysis of the corresponding maximum likelihood estimators in these models; (iii) develop empirical likelihood based inference methodology for functional time series. The project aims at developing methodologies that, on the one hand, are flexible enough and computationally feasible to be useful for complex real-world applications, and that, on the other hand, result in methodologies that allow rigorous statistical analyses providing insight into, and understanding of, their behavior.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Wolfgang",
   "pi_last_name": "Polonik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wolfgang Polonik",
   "pi_email_addr": "wpolonik@ucdavis.edu",
   "nsf_id": "000489141",
   "pi_start_date": "2017-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Davis",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956165270",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 40509.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 41654.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 42837.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 1\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>The primary objective of this project was to develop and analyze statistical methodologies for complex data, and to train PhD students in modern statistics.&nbsp;</span></p>\n<p>An explicit example for the type of complex data considered in this project are data describing the activities in a bike share network, telling us when and at which station a bike is being checked out and when and where it is checked back in. The frequency of such events varies over time and one goal is to understand and model the dynamic mechanisms behind these variations. Similar types of complex data are collected in large numbers nowadays, and methodologies for the analysis of these type of data are urgently needed. The challenge is to develop methodologies that on the one hand are flexible enough to be useful for complex real- world applications, and on the other hand still are amenable for a statistical analysis that allows to gain a solid understanding for what these methods are able to accomplish and what they cannot accomplish. Without such understanding, the insight gained by applying the methodology is very limited, opening the door to misinterpretation.</p>\n<p>This project has been deriving models and statistical inference methods for event count data, such as the bike share data described above. In probabilistic terms, the proposed methodology for even type data developed in this project is based on so-called Hawkes point processes. The project resulted in the derivation of corresponding statistical inference methodology (large sample theory for estimators). This was challenging because of the complex nature of the model, and requires a strong understanding of statistical theory.&nbsp; Applications to Capital Bike Share data illustrated the usefulness of the methodology.</p>\n<p><span>Other dynamic models considered in this project include methods based on so-called hill-climbing algorithms, designed to find ridge lines of a function by climbing up the graph of the function until a ridge line is reached.&nbsp;One very popular example is the so called \"Subspace Constrained Mean Shift Algorithm. This project revealed a previously unknown shortcoming of this popular algorithm, designed alternative algorithms and analyzed them, in particular showing that the alternatives are not suffering from the same shortcoming as the mean-shift algorithm, and that the algorithm is guaranteed to converge to a point on the ridge.</span></p>\n<p>Yet another type of complex dynamic (time-varying) data consists of functional time series where each observation is a function. This project has analyzed such type of data by using empirical likelihood methodologies by using, among others, a functional autoregressive model. The target quantity in this model is the kernel of the linear operator governing this model, and this project illustrated that high-dimensional maximum empirical likelihood estimators provide good statistical estimators for this kernel, where the setting has to be appropriately formulated.</p>\n<p>All these findings of the project are all either already published in peer-reviewed international journals, or they have been submitted to such journals. They are also all publicly available on \"arXiv.org\", a popular e-print archive.</p>\n<p>Three graduate students were involved in this project, two male, one female. They all received a solid training in modern statistical theory and methods, and they all have graduated with a PhD degree.</p>\n</div>\n</div>\n</div>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2021<br>\n\t\t\t\t\tModified by: Wolfgang&nbsp;Polonik</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\n\nThe primary objective of this project was to develop and analyze statistical methodologies for complex data, and to train PhD students in modern statistics. \n\nAn explicit example for the type of complex data considered in this project are data describing the activities in a bike share network, telling us when and at which station a bike is being checked out and when and where it is checked back in. The frequency of such events varies over time and one goal is to understand and model the dynamic mechanisms behind these variations. Similar types of complex data are collected in large numbers nowadays, and methodologies for the analysis of these type of data are urgently needed. The challenge is to develop methodologies that on the one hand are flexible enough to be useful for complex real- world applications, and on the other hand still are amenable for a statistical analysis that allows to gain a solid understanding for what these methods are able to accomplish and what they cannot accomplish. Without such understanding, the insight gained by applying the methodology is very limited, opening the door to misinterpretation.\n\nThis project has been deriving models and statistical inference methods for event count data, such as the bike share data described above. In probabilistic terms, the proposed methodology for even type data developed in this project is based on so-called Hawkes point processes. The project resulted in the derivation of corresponding statistical inference methodology (large sample theory for estimators). This was challenging because of the complex nature of the model, and requires a strong understanding of statistical theory.  Applications to Capital Bike Share data illustrated the usefulness of the methodology.\n\nOther dynamic models considered in this project include methods based on so-called hill-climbing algorithms, designed to find ridge lines of a function by climbing up the graph of the function until a ridge line is reached. One very popular example is the so called \"Subspace Constrained Mean Shift Algorithm. This project revealed a previously unknown shortcoming of this popular algorithm, designed alternative algorithms and analyzed them, in particular showing that the alternatives are not suffering from the same shortcoming as the mean-shift algorithm, and that the algorithm is guaranteed to converge to a point on the ridge.\n\nYet another type of complex dynamic (time-varying) data consists of functional time series where each observation is a function. This project has analyzed such type of data by using empirical likelihood methodologies by using, among others, a functional autoregressive model. The target quantity in this model is the kernel of the linear operator governing this model, and this project illustrated that high-dimensional maximum empirical likelihood estimators provide good statistical estimators for this kernel, where the setting has to be appropriately formulated.\n\nAll these findings of the project are all either already published in peer-reviewed international journals, or they have been submitted to such journals. They are also all publicly available on \"arXiv.org\", a popular e-print archive.\n\nThree graduate students were involved in this project, two male, one female. They all received a solid training in modern statistical theory and methods, and they all have graduated with a PhD degree.\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 11/30/2021\n\n\t\t\t\t\tSubmitted by: Wolfgang Polonik"
 }
}