{
 "awd_id": "1652083",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER:  Towards Autonomously Generating Robot Behavior for Coordination with Humans -- Accounting for Effects on Human Actions",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2017-03-01",
 "awd_exp_date": "2023-02-28",
 "tot_intn_awd_amt": 461807.0,
 "awd_amount": 461807.0,
 "awd_min_amd_letter_date": "2017-02-22",
 "awd_max_amd_letter_date": "2020-02-13",
 "awd_abstract_narration": "Robots that interact, collaborate, and come in support of people are inevitable, from autonomous cars, to assistive devices, to collaborative industrial arms, to personal robots in the home. Interactions with people should be natural, fluent, and well-coordinated.  The project aims to move from hand-designed strategies for interaction to algorithms that produce such strategies in a generalizable way, using models of human behavior and how a robot?s actions may affect people?s actions and perceptions of the robot.  The project also addresses educational goals that augment this vision: enabling the next generations of students to define and solve robotics and AI problems through a combination of computational and human-centered perspectives.\r\n\r\nWhile robotics algorithms typically reason about the physical state of the world and how the robot can affect it in useful ways, an important criterion when interacting with people is how the actions affect them and their internal state: what they plan to do, what they think the robot will do, how much they trust the robot. The project will address this by developing planning algorithms that incorporate the internal state of the human agent that is not directly observable. Rather than treating the human as a physical (dynamic) obstacle that needs to be avoided, this project proposes a game-theoretic formulation of interaction, and introduces an approximation to it as an underactuated dynamical system: the robot has direct control over its actions, but its actions affect the human's actions, and so the robot indirectly influences what the human does. Preliminary results in a driving domain suggest that this improves robot efficiency and fluency of coordination with people.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anca",
   "pi_last_name": "Dragan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anca Dragan",
   "pi_email_addr": "anca@berkeley.edu",
   "nsf_id": "000704141",
   "pi_start_date": "2017-02-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "2150 Shattuck Ave.",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947045940",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 79633.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 88544.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 93673.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 199957.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-73048e66-7fff-ad78-318a-c9abd32a0466\"> </span></p>\n<p dir=\"ltr\"><span>We made progress in important aspects of algorithmic human-robot interaction, including game-theoretic modeling, intent estimation, learning human internal state, and coordinating actions in collaborative tasks. We're proud that our work has led to a series of publications, awards, and new algorithmic developments. Moreover, our project has had a meaningful impact on fostering a more inclusive and diverse AI community through the creation and growth of the BAIR AI4ALL Camp.</span></p>\n<p dir=\"ltr\"><span>Our team has advanced in developing solutions for approximating human-robot interaction games, including two-player games and games involving multiple humans. In our initial work, we discovered that the best response assumption works well for short time horizons but models people as ultra-conservative for long time horizons. To tackle this, we created a hierarchical algorithm that simplifies the game at a higher-level state and action space and employs the game value as a heuristic for planning in the low-level control space. We also developed a new approximation for general sum games that scales to multiple humans and produces real-time behavior while maintaining the correct information structure, taking advantage of the ease of solving linear-quadratic games and iteratively solving them.</span></p>\n<p dir=\"ltr\"><span>We've also made headway in the challenging area of estimating confidence in human models for robots. In our project, we aim to integrate computational cognitive models of people, informed by data, into the way robots generate their actions during interaction. However, these models can be misspecified, potentially leading to dangerous situations. To address this, we've enabled robots to detect when their human behavior models are incorrect and lose predictive power. We proposed estimating the apparent rationality of the human, and if the human appears irrational under any rationality model we have, we can infer that we don't have the right set of models. Furthermore, we introduced a framework for multi-human multi-robot coordination, where robots treat each person independently and monitor the accuracy of this assumption online. We also developed a new predictor that balances models learned from data and the control-theoretic perspective of predicting the full forward reachable set of the human, trusting the data-driven model to discard completely unlikely actions but not distinguishing among the somewhat likely ones, resulting in a restricted forward reachable set.</span></p>\n<p dir=\"ltr\"><span>Our team has also made strides in enabling robots to consider human internal state when generating their actions, focusing on collaborative manipulation tasks. We proposed that the robot should think about the human's internal state and adjust its objective function to better align with human preferences. To test our algorithm, we conducted a user study, which showed that our approach leads to improved collaboration both objectively and subjectively. Building on this work, we tackled the challenge of actively estimating human state, where the robot uses its influence on human responses to gather information about the internal human state. We introduced an algorithm that balances optimizing robot reward under the current estimate of human desires and optimizing for expected information gain. We applied this in driving for estimating driving style and human goals and in shared autonomy with the Jaco arm for estimating human target objects for the arm.</span></p>\n<p dir=\"ltr\"><span>Additionally, we focused on collaboration, specifically a special case that cannot be solved by joint/coupled planning due to human deviations from optimality. We proposed a new benchmark for human-robot collaboration using a simplified version of the cooking game Overcooked. Our study demonstrated that self-play agents that assume the human is optimal perform well when paired with themselves, but not with humans. Instead, training a model of the human based on human-human data and using it to compute the optimal robot policy performs significantly better.</span></p>\n<p dir=\"ltr\"><span>A major non-technical achievement of the project has been the establishment and continued success of the BAIR AI4ALL Camp. This initiative has offered high school students from underserved communities the chance to learn about human-centered artificial intelligence through hands-on activities and education. We started this initiative from scratch, reaching out to teachers in underserved East Bay area schools, creating an application form, and evaluating the students. In the first year, we ran a 2-day camp for low-income high school students to teach them about human-centered AI. In the second year, we expanded the camp to a full week and partnered with the Lawrence Hall of Science to run it sustainably long-term. Despite the challenges posed by the pandemic, we held the camp virtually in the final year and had a successful turnout of 25 students. One of the participants wrote a blog post encapsulating the experience and expressing the sentiment that \"AI will change the world. Who will change AI? WE WILL.\" Our ongoing efforts with the BAIR AI4ALL Camp showcase our dedication to promoting diversity and inclusion in the field of AI and empowering the next generation of leaders in the industry.</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/04/2023<br>\n\t\t\t\t\tModified by: Anca&nbsp;Dragan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nWe made progress in important aspects of algorithmic human-robot interaction, including game-theoretic modeling, intent estimation, learning human internal state, and coordinating actions in collaborative tasks. We're proud that our work has led to a series of publications, awards, and new algorithmic developments. Moreover, our project has had a meaningful impact on fostering a more inclusive and diverse AI community through the creation and growth of the BAIR AI4ALL Camp.\nOur team has advanced in developing solutions for approximating human-robot interaction games, including two-player games and games involving multiple humans. In our initial work, we discovered that the best response assumption works well for short time horizons but models people as ultra-conservative for long time horizons. To tackle this, we created a hierarchical algorithm that simplifies the game at a higher-level state and action space and employs the game value as a heuristic for planning in the low-level control space. We also developed a new approximation for general sum games that scales to multiple humans and produces real-time behavior while maintaining the correct information structure, taking advantage of the ease of solving linear-quadratic games and iteratively solving them.\nWe've also made headway in the challenging area of estimating confidence in human models for robots. In our project, we aim to integrate computational cognitive models of people, informed by data, into the way robots generate their actions during interaction. However, these models can be misspecified, potentially leading to dangerous situations. To address this, we've enabled robots to detect when their human behavior models are incorrect and lose predictive power. We proposed estimating the apparent rationality of the human, and if the human appears irrational under any rationality model we have, we can infer that we don't have the right set of models. Furthermore, we introduced a framework for multi-human multi-robot coordination, where robots treat each person independently and monitor the accuracy of this assumption online. We also developed a new predictor that balances models learned from data and the control-theoretic perspective of predicting the full forward reachable set of the human, trusting the data-driven model to discard completely unlikely actions but not distinguishing among the somewhat likely ones, resulting in a restricted forward reachable set.\nOur team has also made strides in enabling robots to consider human internal state when generating their actions, focusing on collaborative manipulation tasks. We proposed that the robot should think about the human's internal state and adjust its objective function to better align with human preferences. To test our algorithm, we conducted a user study, which showed that our approach leads to improved collaboration both objectively and subjectively. Building on this work, we tackled the challenge of actively estimating human state, where the robot uses its influence on human responses to gather information about the internal human state. We introduced an algorithm that balances optimizing robot reward under the current estimate of human desires and optimizing for expected information gain. We applied this in driving for estimating driving style and human goals and in shared autonomy with the Jaco arm for estimating human target objects for the arm.\nAdditionally, we focused on collaboration, specifically a special case that cannot be solved by joint/coupled planning due to human deviations from optimality. We proposed a new benchmark for human-robot collaboration using a simplified version of the cooking game Overcooked. Our study demonstrated that self-play agents that assume the human is optimal perform well when paired with themselves, but not with humans. Instead, training a model of the human based on human-human data and using it to compute the optimal robot policy performs significantly better.\nA major non-technical achievement of the project has been the establishment and continued success of the BAIR AI4ALL Camp. This initiative has offered high school students from underserved communities the chance to learn about human-centered artificial intelligence through hands-on activities and education. We started this initiative from scratch, reaching out to teachers in underserved East Bay area schools, creating an application form, and evaluating the students. In the first year, we ran a 2-day camp for low-income high school students to teach them about human-centered AI. In the second year, we expanded the camp to a full week and partnered with the Lawrence Hall of Science to run it sustainably long-term. Despite the challenges posed by the pandemic, we held the camp virtually in the final year and had a successful turnout of 25 students. One of the participants wrote a blog post encapsulating the experience and expressing the sentiment that \"AI will change the world. Who will change AI? WE WILL.\" Our ongoing efforts with the BAIR AI4ALL Camp showcase our dedication to promoting diversity and inclusion in the field of AI and empowering the next generation of leaders in the industry.\n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 05/04/2023\n\n\t\t\t\t\tSubmitted by: Anca Dragan"
 }
}