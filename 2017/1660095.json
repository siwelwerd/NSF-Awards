{
 "awd_id": "1660095",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase II:  Computational Pipeline and Architecture for Personalized Displays",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2017-04-01",
 "awd_exp_date": "2022-01-31",
 "tot_intn_awd_amt": 750000.0,
 "awd_amount": 1409999.0,
 "awd_min_amd_letter_date": "2017-04-06",
 "awd_max_amd_letter_date": "2019-08-27",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project is in improving the performance of the computational back-end of a display system that delivers personalized information in public spaces. Currently, the primary method for an individual to receive customized information in public spaces is through personal devices. The heavy use of personal devices in public often leads to heads-down, isolating, and even hazardous situations. The delivery of personalized information through infrastructure can significantly improve these issues. However, the bandwidth requirements in doing so have been prohibitively high using standard computational architectures. This project aims to improve the performance of such a system, allowing practical applications that will broadly enhance safety, accessibility, transportation, and other areas.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase II project focuses on creating a scalable computational pipeline and architecture that will allow a display system to direct personalized visual information in real-time to large numbers of people. Technically, this involves computing, transmitting, and displaying image data for large crowds in parallel. The architecture takes advantage of the inherent redundancies in this application to provide a cost-effective solution. The goal of the project is to create a computational back-end capable of driving, in real-time, a system equivalent to thousands of displays.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Paul",
   "pi_last_name": "Dietz",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Paul H Dietz",
   "pi_email_addr": "phd@alum.mit.edu",
   "nsf_id": "000697429",
   "pi_start_date": "2017-04-06",
   "pi_end_date": "2019-07-09"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Albert",
   "pi_last_name": "Ng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Albert Ng",
   "pi_email_addr": "albert@misappliedsciences.com",
   "nsf_id": "000805772",
   "pi_start_date": "2019-07-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Misapplied Sciences, Inc.",
  "inst_street_address": "120 S RAYMOND AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PASADENA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "7326106256",
  "inst_zip_code": "911052013",
  "inst_country_name": "United States",
  "cong_dist_code": "28",
  "st_cong_dist_code": "CA28",
  "org_lgl_bus_name": "MISAPPLIED SCIENCES, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "L6DCGY8GBV47"
 },
 "perf_inst": {
  "perf_inst_name": "Misapplied Sciences, Inc.",
  "perf_str_addr": "16128 NE 87th St",
  "perf_city_name": "Redmond",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "980523505",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "WA01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537300",
   "pgm_ele_name": "SBIR Phase II"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "165E",
   "pgm_ref_txt": "SBIR Phase IIB"
  },
  {
   "pgm_ref_code": "169E",
   "pgm_ref_txt": "SBIR Tech Enhan Partner (TECP)"
  },
  {
   "pgm_ref_code": "5373",
   "pgm_ref_txt": "SMALL BUSINESS PHASE II"
  },
  {
   "pgm_ref_code": "8033",
   "pgm_ref_txt": "Hardware Software Integration"
  },
  {
   "pgm_ref_code": "8240",
   "pgm_ref_txt": "SBIR/STTR CAP"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 750000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 159999.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>With financial assistance and validation from the National Science Foundation's Small Business Innovation Research program, Misapplied Sciences created and is commercializing a technology that enables digital displays in public venues to show personalized content to each individual, even when a hundred people are looking at the same display at the same time. People viewing one of these displays see only their own content, with no hint of what others see. The technology works intuitively for everyone, without special glasses or staring at a smart phone. &nbsp;</span></p>\n<p><span>This achievement is timely because owners and operators of public \"brick and mortar\" spaces struggle to provide the personalized information and entertainment delivered in the digital world on personal devices. In addition, it's long been a goal of venue designers to directly connect with each individual that visits, works, studies, or lives in the environments they create.&nbsp;</span></p>\n<p><span>Misapplied Sciences successfully addressed these challenges with its Parallel Reality<sup>TM</sup>&nbsp;technology. Now, conventional signs, wayfinding directories, information boards, advertising kiosks, marquees, and more can be replaced with digital displays that are fully integrated with the design intent of the space, while providing each individual the content they want, in their preferred language.&nbsp;</span></p>\n<p><span>The realization of this technology necessitated leaps in the fields of optical design, precision spatial calibration, high performance parallel computation, real-time environmental modeling, simplified programming interface design, and integration of next-generation sensor and tracking technologies. Each layer in the technology stack that makes Parallel Reality<sup>TM</sup>&nbsp;technology possible offers benefits to other industries and markets.&nbsp;</span></p>\n<p><span>To ensure broad applicability, societal benefits, adoption, and commercial success, Misapplied Sciences engaged with leaders in target markets such as transportation, entertainment, retail, and advertising. Demonstrations of&nbsp;Parallel Reality<sup>TM</sup>&nbsp;technology&nbsp;to executives and operating teams from these representative markets allowed Misapplied Sciences to test and adjust assumptions, focus development efforts, and build valuable relationships.&nbsp;</span></p>\n<p><span>Parallel Reality<sup>TM</sup>&nbsp;technology is a powerful tool for accessibility and safety. Use cases include language translation so viewers simultaneously looking at the same display can each see content in their preferred language. Directional displays can recommend accessible routes to those in wheelchairs. Captions can appear for hearing impaired viewers. And large, high-contrast fonts can be used for the sight impaired. In emergency situations, each individual can be directed to their optimal evacuation route.&nbsp;</span></p>\n<p><span>Parallel Reality<sup>TM</sup>&nbsp;technology was featured with high publicity in the CES 2020 keynote address and in a 1500 square foot exhibit on the CES show floor, winning numerous Best of CES awards. It is scheduled for a high-profile deployment in 2022 with a world-famous company at a venue visited by tens of millions each year.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/20/2022<br>\n\t\t\t\t\tModified by: Albert&nbsp;Ng</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWith financial assistance and validation from the National Science Foundation's Small Business Innovation Research program, Misapplied Sciences created and is commercializing a technology that enables digital displays in public venues to show personalized content to each individual, even when a hundred people are looking at the same display at the same time. People viewing one of these displays see only their own content, with no hint of what others see. The technology works intuitively for everyone, without special glasses or staring at a smart phone.  \n\nThis achievement is timely because owners and operators of public \"brick and mortar\" spaces struggle to provide the personalized information and entertainment delivered in the digital world on personal devices. In addition, it's long been a goal of venue designers to directly connect with each individual that visits, works, studies, or lives in the environments they create. \n\nMisapplied Sciences successfully addressed these challenges with its Parallel RealityTM technology. Now, conventional signs, wayfinding directories, information boards, advertising kiosks, marquees, and more can be replaced with digital displays that are fully integrated with the design intent of the space, while providing each individual the content they want, in their preferred language. \n\nThe realization of this technology necessitated leaps in the fields of optical design, precision spatial calibration, high performance parallel computation, real-time environmental modeling, simplified programming interface design, and integration of next-generation sensor and tracking technologies. Each layer in the technology stack that makes Parallel RealityTM technology possible offers benefits to other industries and markets. \n\nTo ensure broad applicability, societal benefits, adoption, and commercial success, Misapplied Sciences engaged with leaders in target markets such as transportation, entertainment, retail, and advertising. Demonstrations of Parallel RealityTM technology to executives and operating teams from these representative markets allowed Misapplied Sciences to test and adjust assumptions, focus development efforts, and build valuable relationships. \n\nParallel RealityTM technology is a powerful tool for accessibility and safety. Use cases include language translation so viewers simultaneously looking at the same display can each see content in their preferred language. Directional displays can recommend accessible routes to those in wheelchairs. Captions can appear for hearing impaired viewers. And large, high-contrast fonts can be used for the sight impaired. In emergency situations, each individual can be directed to their optimal evacuation route. \n\nParallel RealityTM technology was featured with high publicity in the CES 2020 keynote address and in a 1500 square foot exhibit on the CES show floor, winning numerous Best of CES awards. It is scheduled for a high-profile deployment in 2022 with a world-famous company at a venue visited by tens of millions each year.\n\n \n\n\t\t\t\t\tLast Modified: 01/20/2022\n\n\t\t\t\t\tSubmitted by: Albert Ng"
 }
}