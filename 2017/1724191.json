{
 "awd_id": "1724191",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "S&AS: FND: COLLAB: Learning Manipulation Skills Using Deep Reinforcement Learning with Domain Transfer",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2017-08-16",
 "awd_max_amd_letter_date": "2017-08-16",
 "awd_abstract_narration": "This project develops new methods of using deep reinforcement learning to solve real world robotics problems. The project focuses on robotic manipulation tasks such as grasping, opening doors, helping out in the home, performing repairs aboard Navy ships, etc. The key operation in all of the above is the ability for the robot to reliably manipulate objects, parts, or tools with its hands in order to perform a task. The project leverages deep reinforcement learning: a new approach to robotic learning that is capable of learning both perceptual features and control policies simultaneously. This project could have important benefits for a variety of practical applications including: explosive ordnance disposal for our military, materials handling aboard Navy ships, dexterous robotic assistants for NASA astronauts in space, assistive technologies that could help seniors age in place longer, better capabilities for handling radioactive materials during nuclear cleanup, assistance for ergonomically challenging tasks in manufacturing, and general assistance in the office and the home.\r\n\r\nThis research investigates novel deep reinforcement learning approaches for robotic grasping and manipulation that work well in previously unseen, unstructured environments and compose end-to-end tasks from simpler sub-task controllers. The research is built on two main results from research team's recent work, the deep learning approach to grasping and domain adaptation methods for deep neural networks. The research is guided by the following three key ideas: 1) learning in simulation and then using domain transfer techniques to adapt the solutions to reality; 2) simplifying learning for visuomotor control by using planning to estimate the value function; and 3) using symbolic task and motion planning to perform end-to-end tasks by sequencing learned controllers and planned arm/hand motions. The research team performs extensive evaluations to ensure that the system is able to perform novel instances of a task, e.g., those in a context that the robot has not seen before.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Platt",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Robert Platt",
   "pi_email_addr": "r.platt@northeastern.edu",
   "nsf_id": "000601686",
   "pi_start_date": "2017-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "039Y00",
   "pgm_ele_name": "S&AS - Smart & Autonomous Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "046Z",
   "pgm_ref_txt": "S&AS - Smart & Autonomous Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><br />This project has had an important and exciting impact on the state of the art in machine learning for robotic manipulation. The main focus was on understanding how to apply new ideas in deep learning to solve challenging problems in robotics. In particular, the key focus was on policy learning, i.e. learning control policies for robotic systems. The project had a number of important impacts including the following. We explored and discovered new methods for using imitation learning (i.e. behavior cloning) to solve robotics problems. We developed new methods of addressing the sim2real gap in robotic learning. We explored a new way of expressing robotics problems in a policy learning framework that facilitated solving long horizon problems. Finally, unexpectedly, we discovered a new approach to leveraging problem symmetries in the context of policy learning to significantly improve the speed of learning, i.e. to improve the sample efficiency of policy learning. All together, this project continues to have significant impacts outside of the specific research directions. First, the project has contributed to the educational and professional development of a significant group of the PI's students. Second, the project has helped develop technologies that are immediately relevant to DoD priorities as well as NASA projects. Finally, we also believe this work has significant commercial potential. Given the significance of AI and robotics to current national priorities, we believe this project was a wise investment by the NSF and exactly the sort of forward looking research that NSF is known for.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/27/2023<br>\n\t\t\t\t\tModified by: Robert&nbsp;Platt</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThis project has had an important and exciting impact on the state of the art in machine learning for robotic manipulation. The main focus was on understanding how to apply new ideas in deep learning to solve challenging problems in robotics. In particular, the key focus was on policy learning, i.e. learning control policies for robotic systems. The project had a number of important impacts including the following. We explored and discovered new methods for using imitation learning (i.e. behavior cloning) to solve robotics problems. We developed new methods of addressing the sim2real gap in robotic learning. We explored a new way of expressing robotics problems in a policy learning framework that facilitated solving long horizon problems. Finally, unexpectedly, we discovered a new approach to leveraging problem symmetries in the context of policy learning to significantly improve the speed of learning, i.e. to improve the sample efficiency of policy learning. All together, this project continues to have significant impacts outside of the specific research directions. First, the project has contributed to the educational and professional development of a significant group of the PI's students. Second, the project has helped develop technologies that are immediately relevant to DoD priorities as well as NASA projects. Finally, we also believe this work has significant commercial potential. Given the significance of AI and robotics to current national priorities, we believe this project was a wise investment by the NSF and exactly the sort of forward looking research that NSF is known for.\n\n\t\t\t\t\tLast Modified: 06/27/2023\n\n\t\t\t\t\tSubmitted by: Robert Platt"
 }
}