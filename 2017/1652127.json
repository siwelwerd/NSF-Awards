{
 "awd_id": "1652127",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Testing models of semantic spaces in the brain",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032924502",
 "po_email": "dkravitz@nsf.gov",
 "po_sign_block_name": "Dwight Kravitz",
 "awd_eff_date": "2017-01-15",
 "awd_exp_date": "2023-12-31",
 "tot_intn_awd_amt": 513772.0,
 "awd_amount": 513772.0,
 "awd_min_amd_letter_date": "2017-01-17",
 "awd_max_amd_letter_date": "2022-04-22",
 "awd_abstract_narration": "Perhaps the most powerful aspect of the human brain, and also the least understood, is its ability to represent and understand language. The present research advances the field by developing mathematical models that try to capture an important aspect of that ability: how the brain represents individual words and how it combines them into phrases and sentences. By extracting measures of meaning from brain activation patterns, this research is of potential relevance to people with neurological language deficits who can represent meaning but who have problems expressing it. Beyond cognitive neuroscience, this work may also have application to improving computers' ability to process natural language, by building and testing more powerful computational models of meaning than are currently available. By bridging between Cognitive Neuroscience, Data Science and Linguistics this work also enables new interdisciplinary training of students.\r\n\r\nTo carry out this work, experimental and theoretical approaches are combined: functional magnetic resonance imaging (fMRI), behavioural testing and computational modeling. These approaches are brought together by using the shared framework of representing word meanings in what are known as \"semantic spaces\". In a semantic space, each word is represented as a vector, i.e. as an ordered list of numbers, where each such number quantifies a specific feature of the word's overall meaning. This sort of representation has structure: words with more similar meanings are closer together. The research uses models of semantic space to decode fMRI data, by finding mappings between the structure of the semantic model and the similarity-structure of distributed neural activation patterns. In particular, the work investigates whether greater understanding of neural representational structure can be achieved by combining two seemingly distinct types of semantic model: those derived from co-occurrence frequencies of words in large bodies of text, and those obtained from people's behaviourally measured ratings of features of a word's meaning. The research addresses this question not only for neural representations of isolated words, but also for adjective-noun phrases and for entire sentences. It also seeks to isolate purely meaning-related aspects of the neural signal by distinguishing between words which often co-occur with each other but which have distinct meanings, such as 'cup' and 'coffee', as opposed to words that have genuinely similar meanings, such as 'cup' and 'mug'. The work takes an additional approach to isolating meaning from lower-level features, by performing neural decoding across speakers of different languages, e.g. Chinese and English, which can represent the same meanings as each other but which differ greatly in their sound patterns and written visual appearance. Collectively, these lines of work enable progress on the fundamental problem of how the human brain understands language, by bringing together computation, psychology and neuroscience in novel ways.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Rajeev",
   "pi_last_name": "Raizada",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rajeev Raizada",
   "pi_email_addr": "rajeev.raizada@gmail.com",
   "nsf_id": "000540784",
   "pi_start_date": "2017-01-17",
   "pi_end_date": "2022-04-22"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Edmund",
   "pi_last_name": "Lalor",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Edmund Lalor",
   "pi_email_addr": "edmund_lalor@urmc.rochester.edu",
   "nsf_id": "000766323",
   "pi_start_date": "2022-04-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146270140",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169900",
   "pgm_ele_name": "Cognitive Neuroscience"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1699",
   "pgm_ref_txt": "COGNEURO"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 407895.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 105877.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>How the brain processes speech and language remains incompletely understood. Much progress has been made in recent years by analyzing human brain recordings while people undertake language experiments. However, the majority of this progress has focused on experiments where people <em>read </em>or<em> hear</em> language. Much less work has been done on the neuroscience of how people <em>produce</em> speech. The goal of this project was to examine language networks in the human brain during speech production. To do this, we asked 10 participants to produce natural speech while inside an MRI scanner. Participants spoke naturally about topics in their life (friendships, vacations) while images of their brain were taken with the MRI scanner. &nbsp;The goal of the analysis is then to assess how activity in different brain regions reflects the motor activity of speech production, the acoustic processing of the person&rsquo;s own voice, and, importantly, the meaning of what the person is saying. To do this, the timing of the MRI activity is related to different features of the produced speech. Expectations are that auditory cortical areas will largely follow the acoustic content of the speech. But, importantly, it is expected that a broader network of regions &ndash; previously identified in research involving reading/listening to language &ndash; will reflect the meaning of the produced speech. This last step involves deriving numerical representation of language meaning &ndash; something that is possible these days with the development of artificial intelligence language models. Data analysis is ongoing.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 04/30/2024<br>\nModified by: Edmund&nbsp;Lalor</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nHow the brain processes speech and language remains incompletely understood. Much progress has been made in recent years by analyzing human brain recordings while people undertake language experiments. However, the majority of this progress has focused on experiments where people read or hear language. Much less work has been done on the neuroscience of how people produce speech. The goal of this project was to examine language networks in the human brain during speech production. To do this, we asked 10 participants to produce natural speech while inside an MRI scanner. Participants spoke naturally about topics in their life (friendships, vacations) while images of their brain were taken with the MRI scanner. The goal of the analysis is then to assess how activity in different brain regions reflects the motor activity of speech production, the acoustic processing of the persons own voice, and, importantly, the meaning of what the person is saying. To do this, the timing of the MRI activity is related to different features of the produced speech. Expectations are that auditory cortical areas will largely follow the acoustic content of the speech. But, importantly, it is expected that a broader network of regions  previously identified in research involving reading/listening to language  will reflect the meaning of the produced speech. This last step involves deriving numerical representation of language meaning  something that is possible these days with the development of artificial intelligence language models. Data analysis is ongoing.\n\n\n\t\t\t\t\tLast Modified: 04/30/2024\n\n\t\t\t\t\tSubmitted by: EdmundLalor\n"
 }
}