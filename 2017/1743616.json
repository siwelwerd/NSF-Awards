{
 "awd_id": "1743616",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Deriving Hearing Knowledge from Speech Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2017-06-15",
 "awd_exp_date": "2019-05-31",
 "tot_intn_awd_amt": 79854.0,
 "awd_amount": 79854.0,
 "awd_min_amd_letter_date": "2017-06-07",
 "awd_max_amd_letter_date": "2017-06-07",
 "awd_abstract_narration": "This EArly Grant for Exploratory Research investigates the hypothesis that speech evolved to exploit human hearing and, therefore, properties of human hearing are imprinted on speech. A support for this hypothesis is sought by optimizing the speech processing on large amounts of speech data for discrimination among speech sounds. The project intends to show that relevant hearing properties, which are consistent with the hypothesis, will emerge in optimized engineering modules. The focus is on modeling higher(cortical) levels of auditory processing, not usually studied in engineering programs. The new created knowledge should be applicable in machine recognition of noisy speech. \r\n\r\nLinguistic messages carried in speech are coded redundantly in time and in frequency. Redundancies, which are introduced in frequency by synchronous tract movements and in time by the tract inertia, are exploited by human cognition in extracting reliable information-carrying elements from noisy speech. In particular, two particular properties of human hearing are employed: 1) the ability to separate elements of speech signal into different frequency channels, and 2) the ability to extract information about temporal dynamics of signals in these channels. In particular, a deep neural net would take an output of auditory-like spectral analysis and would be trained on the data to process this auditory-like spectrum through a bank of learnable two-dimensional cortical-like spectro-temporal filters. Existence of such architecture is supported by current literature on mammalian auditory cortex. Therefore, the progress would be gauged by evaluating similarity of the derived 2-D filters with known properties of mammalian auditory cortical receptive fields and by their effectiveness in extracting information about underlying speech sounds that constitute speech messages.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hynek",
   "pi_last_name": "Hermansky",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hynek Hermansky",
   "pi_email_addr": "hynek@jhu.edu",
   "nsf_id": "000606597",
   "pi_start_date": "2017-06-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "3400 N. Charles St.",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182686",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 79854.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"Body\"><strong>I</strong><strong>ntroduction</strong></p>\n<p class=\"Body\">Human speech is one of the most significant achievements of the humankind. It serves unique means for opening to other human beings the state of one?s mind, one?s beliefs and opinions, history of the past actions, and possible progress in the future. We have no evidence that other biological organisms can match human abilities of communication by speech.&nbsp;</p>\n<p class=\"Body\">In spite of the recent progress in emulating speech communication in machines, the performance of technology is nowhere close to communication among humans. Training machines on very large amounts of noisy speech is a common technique for improving resiliency of recognition in such noises. However, machines can still catastrophically fail even in weak but unpredictable noises. It appears that the current machine learning approaches to speech recognition are missing some very fundamental principles. As shown in Fig. 1, we postulate that the speech evolved while efficiently using properties of existing human hearing. Then we would expect that optimized speech technology should also exhibit human hearing-like properties. We propose that one should start with only minimal constraints prior to a machine design but to find ways to evaluate the properties of the optimized machine. That is the strategy we follow in our research.</p>\n<p class=\"Body\">Current explosive advances in deep neural net based machine learning are further supported by increasing availability of transcribed speech data and developments of hardware for machine learning.</p>\n<p class=\"Body\">As shown in Fig.2, these advances should not only be used for a blind optimization of speech recognition technology but should be applied for verification of knowledge about human speech communication.</p>\n<p class=\"Body\"><strong>Implications for our research</strong></p>\n<p class=\"Body\">Our work is motivated by properties of human hearing. Our prime interest in our current series of experiments was to see whether the training of the appropriately structured deep neural net will yield spectro-temporal properties observed in mammalian auditory cortices. Namely, whether the first processing step in the efficient machine for recognizing speech suggest separating speech components into different frequency channels. This is important since these properties, combined with the human metacognitive ability to select the appropriate architecture for a given situation, are hypothesized to be the key for the robustness of human speech communication in noise.</p>\n<p class=\"Body\"><strong>Our key results</strong></p>\n<p class=\"Body\">One of the key results of our work is that different spectro-temporal filters of our trained system provide for different views of the incoming speech signal, thus in principle enabling subsequent recognition stages to select the most efficient and the lest corrupted views to be applied for the further processing. The second key result is that, in average, the whole bank of the derived spectro-temporal filters enhances the spectral and temporal modulation which are roughly in the range of the modulations enhanced by human hearing.</p>\n<p class=\"Body\"><strong>Implication for speech engineering</strong></p>\n<p class=\"Body\">Some of undisputed properties of hearing are its spectral selectivity and the ability of retaining immediate temporal context of sounds for the sound processing. By imposing an appropriate structure on a system for a nonlinear regression of speech signal on sparse representation of speech sounds and training it on large amounts of labeled speech data, we were asking whether these properties of human hearing would emerge in the trained system. Our results show that the trained regression indeed shows human-like spectro-temporal properties. These results lead to a proposal for a new architecture of systems for machine recognition of speech, shown in Fig. 3.</p>\n<p><strong>Conclusions</strong></p>\n<p>Our research results support a particular model of human speech communication, where the linguistic message in speech, as represented by a string of speech sounds, is coded redundantly in both the time and the frequency domains. Such redundant coding of the message in the signal evolved over millennia of human evolution so that relevant spectral and temporal properties of human hearing can be used in extracting the messages from the noisy speech signal. The parallel processing streams are formed in such a way that typical noises do not simultaneously affect all streams, and the metacognitive performance monitoring could suppress the corrupted streams in the further processing, which could then rely mainly on uncorrupted streams for the information extraction. These finding have important implications for a design of new generation of speech processing technologies.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/13/2019<br>\n\t\t\t\t\tModified by: Hynek&nbsp;Hermansky</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1743616/1743616_10491482_1571004209733_fig1general--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1743616/1743616_10491482_1571004209733_fig1general--rgov-800width.jpg\" title=\"Evolution of speech\"><img src=\"/por/images/Reports/POR/2019/1743616/1743616_10491482_1571004209733_fig1general--rgov-66x44.jpg\" alt=\"Evolution of speech\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 1 On evolutionary scale, human speech came much later than evolution of mammalian hearing. By some estimates, hearing in the air had some 200 million years to evolve to the level on the Homo Sapiens, where the speech communication started to take place and had perhaps 200 thousand years to be a</div>\n<div class=\"imageCredit\">Hynek Hermansky</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Hynek&nbsp;Hermansky</div>\n<div class=\"imageTitle\">Evolution of speech</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1743616/1743616_10491482_1571004344873_fig2general--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1743616/1743616_10491482_1571004344873_fig2general--rgov-800width.jpg\" title=\"Data guided process\"><img src=\"/por/images/Reports/POR/2019/1743616/1743616_10491482_1571004344873_fig2general--rgov-66x44.jpg\" alt=\"Data guided process\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 2 Providing that human speech evolved to effectively use existing properties of human hearing, hearing properties which are relevant for human speech communication should emerge in well optimized speech technology. Once such properties are identified, they should become permanent features of im</div>\n<div class=\"imageCredit\">Hynek Hermansky</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Hynek&nbsp;Hermansky</div>\n<div class=\"imageTitle\">Data guided process</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1743616/1743616_10491482_1571004458565_fig3general--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1743616/1743616_10491482_1571004458565_fig3general--rgov-800width.jpg\" title=\"Multistream ASR\"><img src=\"/por/images/Reports/POR/2019/1743616/1743616_10491482_1571004458565_fig3general--rgov-66x44.jpg\" alt=\"Multistream ASR\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 3 The key results of our research support a particular organization of machine for recognition of speech. First, consistently with the frequency selectivity of hearing, the speech signal is divided into a number of parallel frequency streams. Information about speech messages is derived in each</div>\n<div class=\"imageCredit\">Hynek Hermansky</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Hynek&nbsp;Hermansky</div>\n<div class=\"imageTitle\">Multistream ASR</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "Introduction\nHuman speech is one of the most significant achievements of the humankind. It serves unique means for opening to other human beings the state of one?s mind, one?s beliefs and opinions, history of the past actions, and possible progress in the future. We have no evidence that other biological organisms can match human abilities of communication by speech. \nIn spite of the recent progress in emulating speech communication in machines, the performance of technology is nowhere close to communication among humans. Training machines on very large amounts of noisy speech is a common technique for improving resiliency of recognition in such noises. However, machines can still catastrophically fail even in weak but unpredictable noises. It appears that the current machine learning approaches to speech recognition are missing some very fundamental principles. As shown in Fig. 1, we postulate that the speech evolved while efficiently using properties of existing human hearing. Then we would expect that optimized speech technology should also exhibit human hearing-like properties. We propose that one should start with only minimal constraints prior to a machine design but to find ways to evaluate the properties of the optimized machine. That is the strategy we follow in our research.\nCurrent explosive advances in deep neural net based machine learning are further supported by increasing availability of transcribed speech data and developments of hardware for machine learning.\nAs shown in Fig.2, these advances should not only be used for a blind optimization of speech recognition technology but should be applied for verification of knowledge about human speech communication.\nImplications for our research\nOur work is motivated by properties of human hearing. Our prime interest in our current series of experiments was to see whether the training of the appropriately structured deep neural net will yield spectro-temporal properties observed in mammalian auditory cortices. Namely, whether the first processing step in the efficient machine for recognizing speech suggest separating speech components into different frequency channels. This is important since these properties, combined with the human metacognitive ability to select the appropriate architecture for a given situation, are hypothesized to be the key for the robustness of human speech communication in noise.\nOur key results\nOne of the key results of our work is that different spectro-temporal filters of our trained system provide for different views of the incoming speech signal, thus in principle enabling subsequent recognition stages to select the most efficient and the lest corrupted views to be applied for the further processing. The second key result is that, in average, the whole bank of the derived spectro-temporal filters enhances the spectral and temporal modulation which are roughly in the range of the modulations enhanced by human hearing.\nImplication for speech engineering\nSome of undisputed properties of hearing are its spectral selectivity and the ability of retaining immediate temporal context of sounds for the sound processing. By imposing an appropriate structure on a system for a nonlinear regression of speech signal on sparse representation of speech sounds and training it on large amounts of labeled speech data, we were asking whether these properties of human hearing would emerge in the trained system. Our results show that the trained regression indeed shows human-like spectro-temporal properties. These results lead to a proposal for a new architecture of systems for machine recognition of speech, shown in Fig. 3.\n\nConclusions\n\nOur research results support a particular model of human speech communication, where the linguistic message in speech, as represented by a string of speech sounds, is coded redundantly in both the time and the frequency domains. Such redundant coding of the message in the signal evolved over millennia of human evolution so that relevant spectral and temporal properties of human hearing can be used in extracting the messages from the noisy speech signal. The parallel processing streams are formed in such a way that typical noises do not simultaneously affect all streams, and the metacognitive performance monitoring could suppress the corrupted streams in the further processing, which could then rely mainly on uncorrupted streams for the information extraction. These finding have important implications for a design of new generation of speech processing technologies.\n\n \n\n\t\t\t\t\tLast Modified: 10/13/2019\n\n\t\t\t\t\tSubmitted by: Hynek Hermansky"
 }
}