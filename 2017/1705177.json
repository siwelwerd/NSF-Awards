{
 "awd_id": "1705177",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "PostDoctoral Research Fellowship",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032924878",
 "po_email": "adpollin@nsf.gov",
 "po_sign_block_name": "Andrew Pollington",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2017-03-21",
 "awd_max_amd_letter_date": "2017-03-21",
 "awd_abstract_narration": "This award is made as part of the FY 2017 Mathematical Sciences Postdoctoral Research Fellowships Program. Each of the fellowships supports a research and training project at a host institution in the mathematical sciences, including applications to other disciplines, under the mentorship of a sponsoring scientist. The title of the project for this fellowship to Zarathustra E. Brady is \"Analytic Number Theory and Combinatorial Optimization.\" The host institution for the fellowship is the Massachusetts Institute of Technology, and the sponsoring scientist is Larry Guth.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zarathustra",
   "pi_last_name": "Brady",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Zarathustra E Brady",
   "pi_email_addr": "",
   "nsf_id": "000732464",
   "pi_start_date": "2017-03-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brady                   Zarathustra    E",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "Stanford",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "Brady                   Zarathustra    E",
  "perf_str_addr": null,
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943052004",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "060Y00",
   "pgm_ele_name": "Workforce (MSPRF) MathSciPDFel"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9219",
   "pgm_ref_txt": "POSTDOCTORAL FELLOWSHIPS IN MATH SCIENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project was to apply ideas from combinatorial optimization (a computational subject that studies algorithms for finding the best ways to do things like matching people together, filling knapsacks with expensive objects without going over a weight limit, etc.) to sieve theory (a subject that tries to quantify how far primes are from behaving \"randomly\" - famous unsolved problems in this area are the Goldbach conjecture and the twin primes conjecture). Since the best known techniques in combinatorial optimization are all special cases of a general framework known as \"semidefinite programming\", which is based on studying multivariable quadratic polynomials which never take negative values, I first aimed to see if the best known techniques in sieve theory can be put into the semidefinite programming framework as well. It turned out that two popular sieve theoretic techniques - known as the \"Large Sieve\" and the \"Larger Sieve\" - can be easily put into this framework. I wrote up a draft of a paper on this framework and made it available on my academic website (<a title=\"https://math.mit.edu/~notzeb/sdp-sieve.pdf\" href=\"https://math.mit.edu/~notzeb/sdp-sieve.pdf\">https://math.mit.edu/~notzeb/sdp-sieve.pdf</a>), but I haven't formally published it yet. I also gave a talk about this research at the Palmetto Number Theory Series in December 2018. A few attempts to use the computational framework to prove new bounds for concrete sieve-theoretic questions were made using the CVXPY python library, but the algorithm used too much memory to be practical in the cases where the answers were not already computed by brute force. I think that it should be possible to reduce the memory usage and speed up the algorithm, but it may be necessary to implement specialized algorithms for dealing with positive semidefinite matrices which have constant diagonals.</p>\n<p>I also found an elegant way to rephrase a different sieve-theoretic framework - what I call the \"Linear Framework\", which uses exponentially large systems of linear inequalities - in terms of a more intuitive question about concrete probability distributions. Using this alternate point of view, I was able to give a new explanation of where the famous \"parity problem\" which plagues the linear approach to sieve theory comes from. While the usual explanation of the \"parity problem\" is explained by the fact that the Mobius function (which checks whether a number has an even or odd number of prime factors) behaves pseudorandomly - a fact which is hard to prove - my new explanation for the parity problem comes directly from the fact that permutations (that is, ways to scramble a sequence of numbers, such as 23154 or 52413) can be categorized as \"even\" or \"odd\" in a natural way. This approach also gives a natural explanation for the occurence of the mysterious constant exp(gamma) that occurs in many sieve-theoretic arguments. Again, I made a draft of a paper about this available on my website (<a title=\"https://math.mit.edu/~notzeb/poisson-imitators.pdf\" href=\"https://math.mit.edu/~notzeb/poisson-imitators.pdf\">https://math.mit.edu/~notzeb/poisson-imitators.pdf</a>), but haven't published this work yet. I also talked about this work in a Zoom seminar at UIUC during the pandemic.</p>\n<p>On top of my sieve-theoretic work, I spent a significant amount of my time working on an exciting new area in computer science related to puzzle-solving and combinatorial optimization: the algebraic dichotomy conjecture for constraint satisfaction problems (often abbreviated as CSPs). Roughly speaking, the dichotomy conjecture is the guess that there is a neat categorization of types of puzzles into puzzles that can be solved efficiently, and puzzles which are hard to solve by any method other than brute force. Moreover, the algebraic dichotomy conjecture states that if there is no simple reason for a type of puzzle to be hard, then this type of puzzle has a hidden algebraic structure which can be exploited. The interesting part of the problem is to figure out how to exploit the algebraic structure, which might be very different from the sorts of algebraic structure which most mathematicians have encountered before. In 2017, Andrei Bulatov and Dmitriy Zhuk independently solved this problem, but each of their solutions is technically challenging, and very few people have read and understood their original arguments completely. I organized a two-year learning seminar at MIT about this topic, and have written several hundred pages of expository notes aimed to make the material easier to digest. These notes are freely available online (the most up-to-date version can be found at <a title=\"https://raw.githubusercontent.com/notzeb/all/master/csp-notes.pdf\" href=\"https://raw.githubusercontent.com/notzeb/all/master/csp-notes.pdf\">https://raw.githubusercontent.com/notzeb/all/master/csp-notes.pdf</a>). I also contributed to a joint paper with Libor Barto, Marcin Kozik, Andrei Bulatov, and Dmitry Zhuk about a framework that we hope will be useful for simplifying the proof of the dichotomy conjecture, which is available on the arxiv (<a title=\"https://arxiv.org/abs/2104.11808\" href=\"https://arxiv.org/abs/2104.11808\">https://arxiv.org/abs/2104.11808</a>).</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/05/2021<br>\n\t\t\t\t\tModified by: Zarathustra&nbsp;E&nbsp;Brady</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this project was to apply ideas from combinatorial optimization (a computational subject that studies algorithms for finding the best ways to do things like matching people together, filling knapsacks with expensive objects without going over a weight limit, etc.) to sieve theory (a subject that tries to quantify how far primes are from behaving \"randomly\" - famous unsolved problems in this area are the Goldbach conjecture and the twin primes conjecture). Since the best known techniques in combinatorial optimization are all special cases of a general framework known as \"semidefinite programming\", which is based on studying multivariable quadratic polynomials which never take negative values, I first aimed to see if the best known techniques in sieve theory can be put into the semidefinite programming framework as well. It turned out that two popular sieve theoretic techniques - known as the \"Large Sieve\" and the \"Larger Sieve\" - can be easily put into this framework. I wrote up a draft of a paper on this framework and made it available on my academic website (https://math.mit.edu/~notzeb/sdp-sieve.pdf), but I haven't formally published it yet. I also gave a talk about this research at the Palmetto Number Theory Series in December 2018. A few attempts to use the computational framework to prove new bounds for concrete sieve-theoretic questions were made using the CVXPY python library, but the algorithm used too much memory to be practical in the cases where the answers were not already computed by brute force. I think that it should be possible to reduce the memory usage and speed up the algorithm, but it may be necessary to implement specialized algorithms for dealing with positive semidefinite matrices which have constant diagonals.\n\nI also found an elegant way to rephrase a different sieve-theoretic framework - what I call the \"Linear Framework\", which uses exponentially large systems of linear inequalities - in terms of a more intuitive question about concrete probability distributions. Using this alternate point of view, I was able to give a new explanation of where the famous \"parity problem\" which plagues the linear approach to sieve theory comes from. While the usual explanation of the \"parity problem\" is explained by the fact that the Mobius function (which checks whether a number has an even or odd number of prime factors) behaves pseudorandomly - a fact which is hard to prove - my new explanation for the parity problem comes directly from the fact that permutations (that is, ways to scramble a sequence of numbers, such as 23154 or 52413) can be categorized as \"even\" or \"odd\" in a natural way. This approach also gives a natural explanation for the occurence of the mysterious constant exp(gamma) that occurs in many sieve-theoretic arguments. Again, I made a draft of a paper about this available on my website (https://math.mit.edu/~notzeb/poisson-imitators.pdf), but haven't published this work yet. I also talked about this work in a Zoom seminar at UIUC during the pandemic.\n\nOn top of my sieve-theoretic work, I spent a significant amount of my time working on an exciting new area in computer science related to puzzle-solving and combinatorial optimization: the algebraic dichotomy conjecture for constraint satisfaction problems (often abbreviated as CSPs). Roughly speaking, the dichotomy conjecture is the guess that there is a neat categorization of types of puzzles into puzzles that can be solved efficiently, and puzzles which are hard to solve by any method other than brute force. Moreover, the algebraic dichotomy conjecture states that if there is no simple reason for a type of puzzle to be hard, then this type of puzzle has a hidden algebraic structure which can be exploited. The interesting part of the problem is to figure out how to exploit the algebraic structure, which might be very different from the sorts of algebraic structure which most mathematicians have encountered before. In 2017, Andrei Bulatov and Dmitriy Zhuk independently solved this problem, but each of their solutions is technically challenging, and very few people have read and understood their original arguments completely. I organized a two-year learning seminar at MIT about this topic, and have written several hundred pages of expository notes aimed to make the material easier to digest. These notes are freely available online (the most up-to-date version can be found at https://raw.githubusercontent.com/notzeb/all/master/csp-notes.pdf). I also contributed to a joint paper with Libor Barto, Marcin Kozik, Andrei Bulatov, and Dmitry Zhuk about a framework that we hope will be useful for simplifying the proof of the dichotomy conjecture, which is available on the arxiv (https://arxiv.org/abs/2104.11808).\n\n\t\t\t\t\tLast Modified: 12/05/2021\n\n\t\t\t\t\tSubmitted by: Zarathustra E Brady"
 }
}