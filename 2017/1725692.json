{
 "awd_id": "1725692",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SPX: Collaborative Research: Cross-layer Application-Aware Resilience at Extreme Scale (CAARES)",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2017-08-15",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 266079.0,
 "awd_amount": 266079.0,
 "awd_min_amd_letter_date": "2017-08-09",
 "awd_max_amd_letter_date": "2017-08-09",
 "awd_abstract_narration": "The increasing demands of science and engineering applications push the limits of current large-scale systems, and is expected to achieve exascale (10^18 FLOPS) performance early in the next decade. One of the lesser studied challenge at extreme scales is the reliability of the computing system itself, primarily due to the very large number of cores and components utilized and to the sharp decrease of the Mean Time Between Failures on such systems (in the order of tens of minutes). This project departs from the traditional single component fault management model, and explores how multiple software libraries (and application components) used in the context of a single parallel application can interact to provide the holistic fault management support necessary for parallel applications targeting capability computing. This exploration will not be limited to software developed using a single parallel programming paradigm, but will be extended to encompass the more challenging case where multiple programming paradigms can be combined to achieve a common goal, to simulate a set of large scale scientific applications in use today.\u00a0\r\n\t\r\nThe goal of this project is to depart from the current siloed resilience mechanisms, and propose cross-layer composition solutions that can fundamentally address these resilience challenges at extreme scales.\u00a0This exploration will not be limited to software developed using a single parallel programming paradigm, but will be extended to encompass the more challenging case where multiple programming paradigms can be combined to achieve a common goal, to simulate a set of large scale scientific applications in use today. More specifically, this proposal will address the following research challenges: (1) development of a theoretical foundation for a deeper understanding of the challenges and opportunities arising from combining different resilience models and methodologies; (2) design of a flexible programming abstraction to allow different resilience models and mechanisms to be combined to cooperate and address resilience in a more holistic manner; and (3) development of basic, programming paradigm independent, constructs necessary to implement cross-layer and domain-specific approaches to support resilience and to understand related performance / quality trade-offs. The proposed approach will be validated by exposing these generic abstractions in two different programming paradigms (MPI and OpenSHMEM), by creating and developing specialized concepts for each of these paradigms. This will enable the assessment of the validity of the concepts and the corresponding overheads imposed by the different software layers, using few software frameworks and applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "George",
   "pi_last_name": "Bosilca",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "George M Bosilca",
   "pi_email_addr": "bosilca@icl.utk.edu",
   "nsf_id": "000348594",
   "pi_start_date": "2017-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Tennessee Knoxville",
  "inst_street_address": "201 ANDY HOLT TOWER",
  "inst_street_address_2": "",
  "inst_city_name": "KNOXVILLE",
  "inst_state_code": "TN",
  "inst_state_name": "Tennessee",
  "inst_phone_num": "8659743466",
  "inst_zip_code": "379960001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "TN02",
  "org_lgl_bus_name": "UNIVERSITY OF TENNESSEE",
  "org_prnt_uei_num": "LXG4F9K8YZK5",
  "org_uei_num": "FN2YCS2YAUW3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Tennessee Knoxville",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TN",
  "perf_st_name": "Tennessee",
  "perf_zip_code": "379960003",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "TN02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 266079.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-0c5ba226-7fff-c26f-6c40-2935637e96ae\"> </span></p>\n<p dir=\"ltr\"><span>The increasing demands of science and engineering applications continue to push the limits of current large scale systems. As the HPC community is preparing for the first exascale (10^18 FLOPS) platforms, many challenges are slowing down application readiness. Some of these challenges include programmability and scalability of existing libraries and algorithms, and for the scope of this project the handling of hardware failures and their impact on the platform scientific throughput. Although many of these challenges are well understood and technical solutions are known or are being developed, some still require research and development efforts. One of the lesser understood challenges at extreme scales is the reliability of the computing system itself, primarily due to the very large number of cores and components utilized.</span></p>\n<p dir=\"ltr\"><span>In spite of a rich existing body of work, failures continue to present significant challenges at all execution scales. For example, while existing techniques effectively address the specific failure modes/class they target, they are largely incompatible with each other, operate at distinct software layers, and often implement their own independent and incompatible software stacks. As a result, composing them in the context of a single application is cumbersome, inefficient, and can be an extremely challenging task. Developing solutions for this is critical to get more scientific output from large scale platforms, by facilitating an efficient use of these platforms and avoiding the application waste due to checkpoint/restart solutions traditionally used.&nbsp;&nbsp;</span></p>\n<p dir=\"ltr\"><span>The overarching goal of this research was to depart from the currently siloed resilience mechanisms, and propose cross-layer composition solutions that can fundamentally and more efficiently address most resilience challenges at any scale, but especially at extreme scale. More specifically, the research and development efforts made in this project addressed the following research challenges:</span></p>\n<p dir=\"ltr\"><span>&nbsp;</span>1. The development of a theoretical foundation for a deeper understanding of the challenges and opportunities arising from combining different resilience models and methodologies;</p>\n<p dir=\"ltr\">2. the design of a flexible programming abstraction to allow different resilience models and mechanisms to be combined to cooperate and address resilience in a more holistic manner; and</p>\n<p dir=\"ltr\">3. the development of basic, programming paradigm independent constructs necessary to implement cross-layer and domain-specific approaches to support resilience and to understand related performance / quality trade-offs.</p>\n<p dir=\"ltr\"><span>This project was developed by a team of leading scientists who have made significant contributions towards developing programming paradigms for parallel applications, and promoted high quality research and software development that benefits the NSF-supported community of scientific researchers in the USA. In addition to the software development aspect, the team has also been involved in education outreach related to various aspects of resilience, including synchronous methods (such as coordinated checkpointing) to completely asynchronous methods (such as algorithmic based fault tolerance). Outreach activities included lectures at various universities and tutorials at several conferences. Additionally,&nbsp; peer-reviewed publications in conferences and journals were facilitated to disseminate information to the community.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/05/2021<br>\n\t\t\t\t\tModified by: George&nbsp;M&nbsp;Bosilca</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThe increasing demands of science and engineering applications continue to push the limits of current large scale systems. As the HPC community is preparing for the first exascale (10^18 FLOPS) platforms, many challenges are slowing down application readiness. Some of these challenges include programmability and scalability of existing libraries and algorithms, and for the scope of this project the handling of hardware failures and their impact on the platform scientific throughput. Although many of these challenges are well understood and technical solutions are known or are being developed, some still require research and development efforts. One of the lesser understood challenges at extreme scales is the reliability of the computing system itself, primarily due to the very large number of cores and components utilized.\nIn spite of a rich existing body of work, failures continue to present significant challenges at all execution scales. For example, while existing techniques effectively address the specific failure modes/class they target, they are largely incompatible with each other, operate at distinct software layers, and often implement their own independent and incompatible software stacks. As a result, composing them in the context of a single application is cumbersome, inefficient, and can be an extremely challenging task. Developing solutions for this is critical to get more scientific output from large scale platforms, by facilitating an efficient use of these platforms and avoiding the application waste due to checkpoint/restart solutions traditionally used.  \nThe overarching goal of this research was to depart from the currently siloed resilience mechanisms, and propose cross-layer composition solutions that can fundamentally and more efficiently address most resilience challenges at any scale, but especially at extreme scale. More specifically, the research and development efforts made in this project addressed the following research challenges:\n 1. The development of a theoretical foundation for a deeper understanding of the challenges and opportunities arising from combining different resilience models and methodologies;\n2. the design of a flexible programming abstraction to allow different resilience models and mechanisms to be combined to cooperate and address resilience in a more holistic manner; and\n3. the development of basic, programming paradigm independent constructs necessary to implement cross-layer and domain-specific approaches to support resilience and to understand related performance / quality trade-offs.\nThis project was developed by a team of leading scientists who have made significant contributions towards developing programming paradigms for parallel applications, and promoted high quality research and software development that benefits the NSF-supported community of scientific researchers in the USA. In addition to the software development aspect, the team has also been involved in education outreach related to various aspects of resilience, including synchronous methods (such as coordinated checkpointing) to completely asynchronous methods (such as algorithmic based fault tolerance). Outreach activities included lectures at various universities and tutorials at several conferences. Additionally,  peer-reviewed publications in conferences and journals were facilitated to disseminate information to the community.\n\n \n\n\t\t\t\t\tLast Modified: 10/05/2021\n\n\t\t\t\t\tSubmitted by: George M Bosilca"
 }
}