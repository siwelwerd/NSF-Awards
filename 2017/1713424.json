{
 "awd_id": "1713424",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Streamlining Embedded Assessment to Understand Citizen Scientists' Skill Gains",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Robert Russell",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 1975598.0,
 "awd_amount": 1975598.0,
 "awd_min_amd_letter_date": "2017-08-09",
 "awd_max_amd_letter_date": "2022-10-14",
 "awd_abstract_narration": "As part of its overall strategy to enhance learning in informal environments, the Advancing Informal STEM Learning (AISL) program funds innovative research, approaches and resources for use in a variety of settings. The project will collaboratively design, test and study effective and efficient ways to develop embedded assessments (EAs) of citizen science (CS) volunteer scientific inquiry skills in order to better understand the impact of these CS experiences on volunteer scientific inquiry abilities. EAs are assessment activities that are integrated into the learning experience and allow learners to demonstrate their competencies in an unobtrusive way. The acquisition of scientific inquiry skills is an essential, even defining, characteristic of citizen science experiences that has a direct influence on data quality. Methods for assessing the direct impact of CS on volunteers' scientific inquiry skills are limited. The project will result in EA measures designed for use by diverse CS projects, strategies that CS projects can use to develop EA assessment tools, and research findings that document opportunities, supports and barriers of this innovative method across a range of CS contexts. Findings and initial resources will be shared with the broad array of stakeholders in CS through conferences, workshops, peer-reviewed publication, community websites and other relevant venues. The results of this work also have the potential to generalize to other informal science learning experiences that engage the public in science\r\n\r\nThe project will address two research questions: (1) What processes are useful for developing broadly applicable EA methods or measures? and (2) What can we learn about gains in volunteers' scientific inquiry skills when citizen science organizations use EA? These will be addressed through design-based research focused on two streamlining strategies. For the reframing data validation strategy, six leaders from five established citizen science projects will conduct secondary analyses of their existing databases to uncover the skill gains of CS volunteers that are currently unexplored in their data. For the common measure strategy, ten CS projects will collaborate to create and test common EA measures of select identification-based skills. Data will be gathered through meeting notes, participant interviews and action plans, and volunteer skill gains to capture process and products of each strategy. Data will be analyzed using grounded theory, multiple process techniques, multilevel models, and repeated-measures analysis of variance. The design-based-research framework will significantly expand project impacts by jump-starting evaluation of the participating CS projects and by producing initial resources for two distinct EA strategies that have the potential to dramatically alter practice and impact citizen science efforts to ultimately enable more people to learn by contributing to the science endeavor. The project will directly equip the 15 participating citizen-science projects with authentic performance tools to assess the quality of their programing, which will expand their understanding of CS volunteer skills and help them better recruit and support their varied audiences (including rural, low-income and tribal communities).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cathlyn",
   "pi_last_name": "Davis",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Cathlyn M Davis",
   "pi_email_addr": "Cathlyn.Davis@umces.edu",
   "nsf_id": "000476041",
   "pi_start_date": "2017-08-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Karen",
   "pi_last_name": "Peterman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Karen Peterman",
   "pi_email_addr": "karenpetermanphd@gmail.com",
   "nsf_id": "000556467",
   "pi_start_date": "2017-08-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rachel",
   "pi_last_name": "Becker-Klein",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rachel Becker-Klein",
   "pi_email_addr": "rachel@peerassociates.net",
   "nsf_id": "000614063",
   "pi_start_date": "2017-08-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andrea",
   "pi_last_name": "Grover",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andrea Grover",
   "pi_email_addr": "andreagrover@unomaha.edu",
   "nsf_id": "000669804",
   "pi_start_date": "2017-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland Center for Environmental Sciences",
  "inst_street_address": "2020 HORNS POINT RD",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4102212014",
  "inst_zip_code": "216133368",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MD01",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND CENTER FOR ENVIRONMENTAL SCIENCE",
  "org_prnt_uei_num": "",
  "org_uei_num": "JHTYTGKYWLL9"
 },
 "perf_inst": {
  "perf_inst_name": "UMCES Appalachian Laboratory",
  "perf_str_addr": "301 Braddock Road",
  "perf_city_name": "Frostburg",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "215322307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MD06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725900",
   "pgm_ele_name": "AISL"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0417",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001718DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0419",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001920DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 1155777.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 819821.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-6e333a89-7fff-1479-0f92-2d5423461b5b\"> </span></p>\n<p dir=\"ltr\"><span style=\"text-decoration: underline;\"><strong>Project purpose and design</strong></span></p>\n<p dir=\"ltr\"><span id=\"docs-internal-guid-07f4f9d8-7fff-f121-2d4f-443dec950530\"><span>Embedded assessments (EAs) are ideal for informal science learning settings as they allow learners to demonstrate their competencies in unobtrusive ways; however, developing EAs is time consuming and resource intensive. The Streamline EA project researched the development of effective and efficient EAs to understand and measure individual skill-based outcomes and ultimately to advance citizen science practice and research. The team partnered with the staff of 15 citizen science projects to examine the potential of two strategies for developing broadly applicable EA processes with a focus on scientific environmental and astronomy observations. For the first strategy, the research team supported practitioners from five of these projects in examinations of skill proficiency using existing observation data submitted by their volunteers. For the second strategy, the research team collaborated with practitioners from the remaining 10 projects to co-create and test several \"shared\" EAs that could be used by multiple projects. In addition to these two strategies, the team expanded their collaborative evaluation approach via a small exploratory study that examined community-based outcomes with 12 additional practitioners. Research data for the two strategies and the exploratory study consisted of meeting notes, literature reviews, participant interviews, process artifacts, and results on volunteer skill proficiency.&nbsp;</span></span></p>\n<p dir=\"ltr\"><span style=\"text-decoration: underline;\"><strong>Project findings &nbsp;</strong></span></p>\n<p dir=\"ltr\"><span>The acquisition of science inquiry skills is an essential characteristic of citizen science that has a direct influence on both science research and volunteer learning outcomes. However, while many projects validate volunteer-submitted data for scientific accuracy, direct assessment of volunteers' inquiry skills is uncommon within citizen science. This is a missed opportunity as assessment of skill proficiency can improve design, validate protocols, demonstrate gains, and advance best-practices. Results and reflections from the two EA strategies examined in the Streamline EA project provide multiple insights into evaluation in citizen science. First, citizen science</span><span> leaders often have only broad conceptualizations of volunteers' skills and may maintain faulty assumptions about their volunteers' skill proficiency. Thus, the first step in evaluation is to provide citizen science leaders with time and support to refine these expansive notions into concrete subskills. Second, once these subskills are well defined, both EA strategies can be effective for assessing volunteer proficiency in ways that are performance-based and integrated seamlessly into a citizen science experience. Third, findings from these EAs can advance citizen science efforts and the field overall; indeed, all citizen science leaders in the Streamline EA project used their EA findings in at least one of the following ways: (a) to gain new and deeper understanding of their volunteers and programming, (b) to make critical changes to their programming, (c) to share and promote their achievements with volunteers, staff, funders, and others, and (d) to expand their attitudes and actions with regard to evaluation. Furthermore, when aggregated across multiple citizen science projects, pooled evaluation data provides insights into volunteers' overall science inquiry skills including unevenness in volunteer proficiency and differences in proficiency associated with simple versus complex skills. Fourth, both strategies point to significant challenges associated with EAs including the need for experienced staff to conduct secondary analysis of existing volunteer data or to implement a shared process for creating EAs. Finally, the project also highlighted the value of supporting project leaders in working collaboratively on evaluation, as well as the importance of expanding beyond individual outcomes (such as skill gains) to consider community-level outcomes and associated short-term indicators that seek to improve overall well-being of community members.&nbsp;</span></p>\n<p dir=\"ltr\"><span style=\"text-decoration: underline;\"><strong>Broader Impacts&nbsp;</strong></span></p>\n<p><span>The Streamline EA project expanded understanding of approaches, benefits, and challenges associated with EAs, as well as the understanding of citizen science volunteer skill proficiency. The results were presented at 12 conferences, workshops, and seminars, and were written up in one blog, one conference paper, four published journal articles, and one journal article in development. The Streamline EA project produced and validated two performance-based shared EA measures of specific science inquiry skills (</span><span>record standard observations</span><span> and </span><span>notice relevant features</span><span>), developed a guide for evaluators and practitioners to help them determine if EA is an appropriate tool, and created worksheets on breaking down broad skills into well-defined subskills for evaluation. These products and an introduction to EAs are available on the project website (</span><a href=\"https://tinyurl.com/StreamlineEA\"><span>https://tinyurl.com/StreamlineEA</span></a><span>). Additionally, the Streamline EA project directly equipped leaders from the 15 participating citizen-science efforts with authentic performance tools to assess their volunteers' science skills, and all leaders used their EA efforts to make improvements, share findings, and expand their understanding of assessment approaches. Finally, it provided mentoring and growth for a postdoctoral associate across multiple years, and supported an additional 12 community-science practitioners in reflecting on short- and long-term outcomes relevant at a community level. Overall, this work has helped advance knowledge and practice for informal learning experiences that engage the public in science.</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/29/2023<br>\nModified by: Cathlyn&nbsp;M&nbsp;Davis</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nProject purpose and design\n\n\nEmbedded assessments (EAs) are ideal for informal science learning settings as they allow learners to demonstrate their competencies in unobtrusive ways; however, developing EAs is time consuming and resource intensive. The Streamline EA project researched the development of effective and efficient EAs to understand and measure individual skill-based outcomes and ultimately to advance citizen science practice and research. The team partnered with the staff of 15 citizen science projects to examine the potential of two strategies for developing broadly applicable EA processes with a focus on scientific environmental and astronomy observations. For the first strategy, the research team supported practitioners from five of these projects in examinations of skill proficiency using existing observation data submitted by their volunteers. For the second strategy, the research team collaborated with practitioners from the remaining 10 projects to co-create and test several \"shared\" EAs that could be used by multiple projects. In addition to these two strategies, the team expanded their collaborative evaluation approach via a small exploratory study that examined community-based outcomes with 12 additional practitioners. Research data for the two strategies and the exploratory study consisted of meeting notes, literature reviews, participant interviews, process artifacts, and results on volunteer skill proficiency.\n\n\nProject findings \n\n\nThe acquisition of science inquiry skills is an essential characteristic of citizen science that has a direct influence on both science research and volunteer learning outcomes. However, while many projects validate volunteer-submitted data for scientific accuracy, direct assessment of volunteers' inquiry skills is uncommon within citizen science. This is a missed opportunity as assessment of skill proficiency can improve design, validate protocols, demonstrate gains, and advance best-practices. Results and reflections from the two EA strategies examined in the Streamline EA project provide multiple insights into evaluation in citizen science. First, citizen science leaders often have only broad conceptualizations of volunteers' skills and may maintain faulty assumptions about their volunteers' skill proficiency. Thus, the first step in evaluation is to provide citizen science leaders with time and support to refine these expansive notions into concrete subskills. Second, once these subskills are well defined, both EA strategies can be effective for assessing volunteer proficiency in ways that are performance-based and integrated seamlessly into a citizen science experience. Third, findings from these EAs can advance citizen science efforts and the field overall; indeed, all citizen science leaders in the Streamline EA project used their EA findings in at least one of the following ways: (a) to gain new and deeper understanding of their volunteers and programming, (b) to make critical changes to their programming, (c) to share and promote their achievements with volunteers, staff, funders, and others, and (d) to expand their attitudes and actions with regard to evaluation. Furthermore, when aggregated across multiple citizen science projects, pooled evaluation data provides insights into volunteers' overall science inquiry skills including unevenness in volunteer proficiency and differences in proficiency associated with simple versus complex skills. Fourth, both strategies point to significant challenges associated with EAs including the need for experienced staff to conduct secondary analysis of existing volunteer data or to implement a shared process for creating EAs. Finally, the project also highlighted the value of supporting project leaders in working collaboratively on evaluation, as well as the importance of expanding beyond individual outcomes (such as skill gains) to consider community-level outcomes and associated short-term indicators that seek to improve overall well-being of community members.\n\n\nBroader Impacts\n\n\nThe Streamline EA project expanded understanding of approaches, benefits, and challenges associated with EAs, as well as the understanding of citizen science volunteer skill proficiency. The results were presented at 12 conferences, workshops, and seminars, and were written up in one blog, one conference paper, four published journal articles, and one journal article in development. The Streamline EA project produced and validated two performance-based shared EA measures of specific science inquiry skills (record standard observations and notice relevant features), developed a guide for evaluators and practitioners to help them determine if EA is an appropriate tool, and created worksheets on breaking down broad skills into well-defined subskills for evaluation. These products and an introduction to EAs are available on the project website (https://tinyurl.com/StreamlineEA). Additionally, the Streamline EA project directly equipped leaders from the 15 participating citizen-science efforts with authentic performance tools to assess their volunteers' science skills, and all leaders used their EA efforts to make improvements, share findings, and expand their understanding of assessment approaches. Finally, it provided mentoring and growth for a postdoctoral associate across multiple years, and supported an additional 12 community-science practitioners in reflecting on short- and long-term outcomes relevant at a community level. Overall, this work has helped advance knowledge and practice for informal learning experiences that engage the public in science.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 11/29/2023\n\n\t\t\t\t\tSubmitted by: CathlynMDavis\n"
 }
}