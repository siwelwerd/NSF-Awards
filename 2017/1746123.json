{
 "awd_id": "1746123",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: EAGER: SCIENCE: Systemic Cultivation of Inclusive Equitable Nurturing Classroom Ecology",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928447",
 "po_email": "cshen@nsf.gov",
 "po_sign_block_name": "Chia Shen",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 211001.0,
 "awd_amount": 211001.0,
 "awd_min_amd_letter_date": "2017-08-29",
 "awd_max_amd_letter_date": "2017-08-29",
 "awd_abstract_narration": "In this collaborative proposal, a team of human-computer interaction and learning science researchers will collaborate with science education practitioners to develop and study a novel learning genre that aims to promote equity in science education for 4th-9th graders. The research program targets students with visual impairments (VIs), who face many challenges in the education system, especially in science courses. Unlike subjects in the humanities and social sciences, science education relies heavily on visualizations using charts, diagrams, and images, in addition to print materials. Consequently, students with VIs cannot readily access those visualizations and are burdened with misconceptions of science-related constructs. The proposed learning genre addresses this critical need for equitable access by including innovative  multimodal artifacts and a new pedagogical methodology for science education for both sighted and visually impaired students. These multimodal artifacts called Sensables, the innovation at the center of the learning genre, leverage burgeoning technologies and movements such as maker technology and culture, computer vision, and mobile devices. Sensables are 3D printed models that have \"hotspots\" that respond to a user's touch by playing a media file on a nearby device. These media files can be audio descriptions of the model component, related sounds or images, or even braille annotations. The investigators will study how students learn with these artifacts, and create a web-based sharing and discussion portal, software tools, and instructional resources for teachers to promote broad adoption of the learning genre in the classroom.\r\n\r\nThrough iterative design and engineering, evaluation, and data analysis, this interdisciplinary design-based research program will contribute to both the human-computer interaction and learning science fields. The investigators will conduct a single case design study to evaluate and refine the design of Sensables. The project's output includes new curricular materials and a pedagogical methodology for using Sensables in science education. The study will answer the following research questions: (1) What aspects of the Sensables artifacts and pedagogical methodology afford learning? (2) To what extent do Sensables help students learn material compared to current standards? (3) What type of science content are Sensables best suited for? Similarly, what type of content is not appropriate for learning with Sensables? The investigators will develop and disseminate their research outcome to the academic community as well as education and disability professionals to pave the way for broad use and adoption of this learning technology.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shiri",
   "pi_last_name": "Azenkot",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shiri Azenkot",
   "pi_email_addr": "shiri.azenkot@cornell.edu",
   "nsf_id": "000690878",
   "pi_start_date": "2017-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell Tech",
  "perf_str_addr": "111 8th Ave #302, Cornell tech",
  "perf_city_name": "New york",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100115024",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NY12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 211001.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-d8f611e2-7fff-92cd-612d-945afd56f200\" style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This project studied the use of tactile materials by teachers of students with visual impairments. Tactile teaching materials include tactile graphics, 3D models, and actual objects used for educational purposes. While interactive and tactle models, including 3D printed models, have been used in classrooms for some time, little is known about what makes these models effective. The researchers conducted workshops with teachers of students with visual impairments to understand how they might best be used in classroom settings. This study resulted in a set of guidelines for effective use of interactive 3D models:&nbsp;</span></p>\n<ul style=\"margin-top: 0; margin-bottom: 0;\">\n<li style=\"list-style-type: disc; font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">They should have useful tactile features</span> </li>\n<li style=\"list-style-type: disc; font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">They should utilize both auditory and visual content</span> </li>\n<li style=\"list-style-type: disc; font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">They should consider effective pedagogical methods.</span> </li>\n</ul>\n<ul style=\"margin-top: 0; margin-bottom: 0;\">\n<br />\n</ul>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">These findings informed the creation of a new type of interactive 3D models, including two mobile applications that allow the easy creation and use of these models for use in education of students with visual impairments. </span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">One of these applications was Talkit++, which allows blind or low vision users to interact with a 3D print. This iOS application plays audio and visual content as a user touches parts of a 3D printed model. The app allows students with visual impairments to explore a printed model with their hands, using finger gestures and speech commands to get more information about elements in the model. Talkit++ detects models and gestures using computer vision algorithms and the built-in camera on an iOS device.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Another application created by the research team is Molder, which allows people with any level of vision to annotate a 3D print with multimodal information. The interface is easy-to-use and supports tactile patterns, as well as braille and audio labels. With Molder, model designers can 3D print a draft map, add interactive features, and then create a final model that can be used by students in educational settings. Initial user studies with both blind/low vision and sighted participants showed that Molder is useful for map design. <span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">While Molder is currently unly usable for creating tactile maps, the techniques used for these can be applied to all types of tactile materials in the future.</span></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Making the benefits of this research available to communities of teachers and students has been foundational to the project. Over the course of the project, researchers conducted multiple workshops for teachers of students with visual impairments. At the workshops, teachers were introduced to the use of 3D printed models. They also collaboratively developed the 3D printed model use guidelines mentioned above.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The researchers also created both a website and a mobile app for use by the community. The website, sensables.org, hosts interactive 3D models and allows users to upload new models for use by other community members. The Sensables iOS app brings this functionality to mobile devices. The app is available for download on the Sensables website.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/14/2021<br>\n\t\t\t\t\tModified by: Shiri&nbsp;Azenkot</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1746123/1746123_10519240_1610581369025_molder--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1746123/1746123_10519240_1610581369025_molder--rgov-800width.jpg\" title=\"Molder Demo\"><img src=\"/por/images/Reports/POR/2021/1746123/1746123_10519240_1610581369025_molder--rgov-66x44.jpg\" alt=\"Molder Demo\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A series of images demonstrating the process of creating an interactive tactile map for teaching use.</div>\n<div class=\"imageCredit\">Research Team</div>\n<div class=\"imageSubmitted\">Shiri&nbsp;Azenkot</div>\n<div class=\"imageTitle\">Molder Demo</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1746123/1746123_10519240_1610581278113_plane--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1746123/1746123_10519240_1610581278113_plane--rgov-800width.jpg\" title=\"Talkit Demo\"><img src=\"/por/images/Reports/POR/2021/1746123/1746123_10519240_1610581278113_plane--rgov-66x44.jpg\" alt=\"Talkit Demo\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A student uses the Talkit++ mobile application to learn about the Plane model</div>\n<div class=\"imageCredit\">Research Team</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Shiri&nbsp;Azenkot</div>\n<div class=\"imageTitle\">Talkit Demo</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "This project studied the use of tactile materials by teachers of students with visual impairments. Tactile teaching materials include tactile graphics, 3D models, and actual objects used for educational purposes. While interactive and tactle models, including 3D printed models, have been used in classrooms for some time, little is known about what makes these models effective. The researchers conducted workshops with teachers of students with visual impairments to understand how they might best be used in classroom settings. This study resulted in a set of guidelines for effective use of interactive 3D models: \n\nThey should have useful tactile features \nThey should utilize both auditory and visual content \nThey should consider effective pedagogical methods. \n\n\n\n\n\nThese findings informed the creation of a new type of interactive 3D models, including two mobile applications that allow the easy creation and use of these models for use in education of students with visual impairments. \n\n\nOne of these applications was Talkit++, which allows blind or low vision users to interact with a 3D print. This iOS application plays audio and visual content as a user touches parts of a 3D printed model. The app allows students with visual impairments to explore a printed model with their hands, using finger gestures and speech commands to get more information about elements in the model. Talkit++ detects models and gestures using computer vision algorithms and the built-in camera on an iOS device.\n\n\nAnother application created by the research team is Molder, which allows people with any level of vision to annotate a 3D print with multimodal information. The interface is easy-to-use and supports tactile patterns, as well as braille and audio labels. With Molder, model designers can 3D print a draft map, add interactive features, and then create a final model that can be used by students in educational settings. Initial user studies with both blind/low vision and sighted participants showed that Molder is useful for map design. While Molder is currently unly usable for creating tactile maps, the techniques used for these can be applied to all types of tactile materials in the future.\n\n\nMaking the benefits of this research available to communities of teachers and students has been foundational to the project. Over the course of the project, researchers conducted multiple workshops for teachers of students with visual impairments. At the workshops, teachers were introduced to the use of 3D printed models. They also collaboratively developed the 3D printed model use guidelines mentioned above.\n\n\nThe researchers also created both a website and a mobile app for use by the community. The website, sensables.org, hosts interactive 3D models and allows users to upload new models for use by other community members. The Sensables iOS app brings this functionality to mobile devices. The app is available for download on the Sensables website.\n\n\t\t\t\t\tLast Modified: 01/14/2021\n\n\t\t\t\t\tSubmitted by: Shiri Azenkot"
 }
}