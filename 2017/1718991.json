{
 "awd_id": "1718991",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Extracting and Understanding Sparse Structure in Spatiotemporal Data in Neuroscience and Other Applications",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 449999.0,
 "awd_amount": 449999.0,
 "awd_min_amd_letter_date": "2017-08-16",
 "awd_max_amd_letter_date": "2022-07-25",
 "awd_abstract_narration": "Sparse coding and manifold learning are two methods that, each in its own right, have proven essential for understanding the structure in complex high\u00ad dimensional data. The goal of this project is to combine these two methods to yield a qualitatively more powerful approach to analyze data. The investigators will develop the mathematics of sparse coding of spatiotemporal data and combine it with approaches from manifold learning. The tools emerging from this research will bring benefits to society since they are applicable to many areas of technology and medicine, such as signal processing, image and video coding, medical imaging, neural data analysis,  neuroprosthetics, and can be expected to have implications for understanding information processing in the visual cortex. \r\n\r\nSparse coding is a concept originally developed in neuroscience to account for sensory representations in the brain, which now sees widespread use in many image and signal processing and data analysis tasks. However, there are critical limitations with current approaches to sparse coding. One major issue is that sparse representations can be brittle, changing abruptly over time or in response to small changes in the input, and they can be quite sensitive to parameter settings, initial conditions, and the particular choice of sparse solver. Another limitation is that if the data lie in a low\u00ad dimensional manifold, such as sound waveforms or images, the connection between the sparse codes of the data and the geometry of the underlying low dimensional space is lost. The team conjectures that both of these limitations should be addressed together. Building on previous work and their own preliminary studies, they will develop a theoretical framework for sparse coding to reveal conditions under which the results of sparse coding are unique. Based on these theoretical insights, they will design novel algorithms for robustly revealing persistent sparse structure in spatio\u00adtemporal data. Finally they will develop a new signal transform, called sparse manifold transform, that combines traditional sparse coding with manifold learning.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Friedrich",
   "pi_last_name": "Sommer",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Friedrich T Sommer",
   "pi_email_addr": "fsommer@berkeley.edu",
   "nsf_id": "000490098",
   "pi_start_date": "2017-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Bruno",
   "pi_last_name": "Olshausen",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Bruno A Olshausen",
   "pi_email_addr": "baolshausen@berkeley.edu",
   "nsf_id": "000444415",
   "pi_start_date": "2017-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Saeed",
   "pi_last_name": "Saremi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Saeed Saremi",
   "pi_email_addr": "saeed@berkeley.edu",
   "nsf_id": "000737992",
   "pi_start_date": "2017-08-16",
   "pi_end_date": "2019-11-22"
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947203198",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 449999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project investigated the mathematical foundations of robust sparse coding. Specifically, it explored the u<span>niqueness and stability of dictionaries for sparse representation of noisy signals, the l<span>earning overcomplete, low coherence dictionaries with linear inference, the connection between sparse coding and manifold learning, as well as the introduction of Langevin sampling and group-theoretic concepts (Lie groups) into sparse coding.&nbsp;&nbsp;</span></span></span></p>\n<p>Other research topics included efficient sampling for Unsupervised Learning, a retinal model that captures high-accuity image structure in the presence of fixational eye movements, a new method to detect chaos in electrophysiology data, the development of a generalized perceptron theory that can predict the accuracy of deep neural networks, and Vector Symbolic Architectures,&nbsp;.&nbsp;&nbsp;</p>\n<p>Vector Symbolic Architectures are algebraic frameworks that include a vector product or binding operation to formalize parallel computing with randomized, and often sparse, feature vectors. Specifically, we proposed a novel network model, the resonator network, for efficiently solving the factorization of a given vector into a product of vectors sets of known vectors. We then demonstrated that the neuromorphic implementation of a resonator network can solve problems like visual scene understanding and visual odometry.&nbsp; &nbsp;</p>\n<p>The intellectual merit of the project is advancement of a) the theory and methods of sparse coding, b) a framework for understanding parallel computing that serves neuroscience as well as applications, c) fast sampling methods for improved unsupervised learning, d) new methods for analyzing neuroscience data. e) theoretical understanding of retinal accuity in the presence of fixational eye movements and for visual scene understanding.&nbsp; &nbsp;&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/10/2024<br>\nModified by: Friedrich&nbsp;T&nbsp;Sommer</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project investigated the mathematical foundations of robust sparse coding. Specifically, it explored the uniqueness and stability of dictionaries for sparse representation of noisy signals, the learning overcomplete, low coherence dictionaries with linear inference, the connection between sparse coding and manifold learning, as well as the introduction of Langevin sampling and group-theoretic concepts (Lie groups) into sparse coding.\n\n\nOther research topics included efficient sampling for Unsupervised Learning, a retinal model that captures high-accuity image structure in the presence of fixational eye movements, a new method to detect chaos in electrophysiology data, the development of a generalized perceptron theory that can predict the accuracy of deep neural networks, and Vector Symbolic Architectures,.\n\n\nVector Symbolic Architectures are algebraic frameworks that include a vector product or binding operation to formalize parallel computing with randomized, and often sparse, feature vectors. Specifically, we proposed a novel network model, the resonator network, for efficiently solving the factorization of a given vector into a product of vectors sets of known vectors. We then demonstrated that the neuromorphic implementation of a resonator network can solve problems like visual scene understanding and visual odometry. \n\n\nThe intellectual merit of the project is advancement of a) the theory and methods of sparse coding, b) a framework for understanding parallel computing that serves neuroscience as well as applications, c) fast sampling methods for improved unsupervised learning, d) new methods for analyzing neuroscience data. e) theoretical understanding of retinal accuity in the presence of fixational eye movements and for visual scene understanding. \n\n\n\t\t\t\t\tLast Modified: 03/10/2024\n\n\t\t\t\t\tSubmitted by: FriedrichTSommer\n"
 }
}