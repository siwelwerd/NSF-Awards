{
 "awd_id": "1724157",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "S&AS: INT: Socially-Aware Autonomy for Long-Term Deployment of Always-On Heterogeneous Robot Teams",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 1100000.0,
 "awd_amount": 1116000.0,
 "awd_min_amd_letter_date": "2017-08-24",
 "awd_max_amd_letter_date": "2019-04-24",
 "awd_abstract_narration": "This project studies how best to enable a team of mobile robots to fully integrate into the social fabric of a community of people.  As such, the most important impact of this project is the ongoing development and dissemination of core algorithms that, for the first time, enable robots to be fully integrated in a socially-aware way into a community of people over a long period of time. In addition to many traditional impacts on education, including a curriculum for a project-based course, serving as a platform for graduate and undergraduate research, this research is being used as the basis for extensive public outreach via demonstrations, camps, and short courses, with a particular focus on underrepresented groups such as women in Computer Science and Engineering and Hispanic students.\r\n\r\nThis project focusses on three main technical challenges that are crucial to enabling robots to integrate into the social fabric of a community. First, the project is working towards enabling robots to be cognizant about dynamic social environments.  Second, the project is working towards enabling robots to reason about heterogeneous human-robot capabilities while carrying out specific tasks.  Third, the project is working towards enabling safe, reflective lifelong learning in dynamic environments.  In addition to leading to focussed algorithms designed to address these specific challenges, the project contributions are also being instantiated within a single, coherent multi-robot system capable of long-term autonomy.  A key facilitator of the project's validation plan is a flexible, adaptable, and reusable software and hardware infrastructure that is being developed and expanded at UT Austin under an NSF Computing Research Infrastructure program grant.  The main experimental objective of the project is to demonstrate that these robots can not only operate autonomously for long periods of time, but also be fully integrated into and accepted by the community of people who use the building in which they are situated.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Stone",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Peter H Stone",
   "pi_email_addr": "pstone@cs.utexas.edu",
   "nsf_id": "000156504",
   "pi_start_date": "2017-08-24",
   "pi_end_date": "2017-12-21"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Scott",
   "pi_last_name": "Niekum",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Scott D Niekum",
   "pi_email_addr": "sniekum@cs.umass.edu",
   "nsf_id": "000663218",
   "pi_start_date": "2019-04-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Stone",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Peter H Stone",
   "pi_email_addr": "pstone@cs.utexas.edu",
   "nsf_id": "000156504",
   "pi_start_date": "2019-04-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andrea",
   "pi_last_name": "Thomaz",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Andrea L Thomaz",
   "pi_email_addr": "athomaz@ece.utexas.edu",
   "nsf_id": "000082310",
   "pi_start_date": "2017-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Scott",
   "pi_last_name": "Niekum",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Scott D Niekum",
   "pi_email_addr": "sniekum@cs.umass.edu",
   "nsf_id": "000663218",
   "pi_start_date": "2017-08-24",
   "pi_end_date": "2017-12-21"
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "2317 Speedway, D9500",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121757",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "039Y00",
   "pgm_ele_name": "S&AS - Smart & Autonomous Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "046Z",
   "pgm_ref_txt": "S&AS - Smart & Autonomous Systems"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 1100000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The core objective of this project was to understand how best to enable a team of mobile robots with different capabilities to fully integrate into the social fabric of a community of people. For robots to be useful in both private and public spaces, they must be able to: (1) learn about (and follow) human desires and social norms of spaces; (2) reason about differing capabilities of humans and robots; and (3) learn and adapt their behaviors safely over long periods of time.<br /><br />Towards these goals, we developed new techniques that allow robots to learn from multiple types of social cues that humans may provide, such as facial expressions, language, and eye gaze. This was some of the first work to look into the science of what types of information these types of cues can provide to robots in a social setting, allowing robots to better understand human communication, goals, and desires.<br /><br />Our results also pushed forward the state of the art in safe learning, which is a critical component of getting robots out of the home and workplace in a safe, ethical manner that is vital for the flourishing of the robotics industry. We developed methods that allow robots to only update their behaviors when they have a high degree of confidence that they will not be unsafe or violate other user-specified constraints.<br /><br />Finally, we developed and tested planning algorithms for human-robot cooperation in the real-world and collected valuable publicly-available datasets. We released the first large-scale social navigation dataset consisting of robots navigating in crowded human-populated environments (such as football tailgate parties and passing periods between classes on a University campus), and used this data in part to evaluate the effectiveness of our methods.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/01/2022<br>\n\t\t\t\t\tModified by: Scott&nbsp;D&nbsp;Niekum</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe core objective of this project was to understand how best to enable a team of mobile robots with different capabilities to fully integrate into the social fabric of a community of people. For robots to be useful in both private and public spaces, they must be able to: (1) learn about (and follow) human desires and social norms of spaces; (2) reason about differing capabilities of humans and robots; and (3) learn and adapt their behaviors safely over long periods of time.\n\nTowards these goals, we developed new techniques that allow robots to learn from multiple types of social cues that humans may provide, such as facial expressions, language, and eye gaze. This was some of the first work to look into the science of what types of information these types of cues can provide to robots in a social setting, allowing robots to better understand human communication, goals, and desires.\n\nOur results also pushed forward the state of the art in safe learning, which is a critical component of getting robots out of the home and workplace in a safe, ethical manner that is vital for the flourishing of the robotics industry. We developed methods that allow robots to only update their behaviors when they have a high degree of confidence that they will not be unsafe or violate other user-specified constraints.\n\nFinally, we developed and tested planning algorithms for human-robot cooperation in the real-world and collected valuable publicly-available datasets. We released the first large-scale social navigation dataset consisting of robots navigating in crowded human-populated environments (such as football tailgate parties and passing periods between classes on a University campus), and used this data in part to evaluate the effectiveness of our methods.\n\n\t\t\t\t\tLast Modified: 11/01/2022\n\n\t\t\t\t\tSubmitted by: Scott D Niekum"
 }
}