{
 "awd_id": "1748392",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Large-Scale Real-Time Information Visualization on Immersive Platforms",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2019-09-30",
 "tot_intn_awd_amt": 93230.0,
 "awd_amount": 93230.0,
 "awd_min_amd_letter_date": "2017-09-09",
 "awd_max_amd_letter_date": "2017-09-09",
 "awd_abstract_narration": "This proposal breaks new ground in the rapidly evolving field of Immersive Analytics. Virtual and Augmented Reality technologies are uniquely suited to enable large-scale data analysis that provides global overviews of data landscapes as well as fine-grain control and navigation. The proposed work will implement a scalable development environment for immersive analytics experiences, and evaluate\r\ndifferent methods for authoring and collaboratively exploring very large datasets using Virtual Reality headsets, display walls, and curved immersive displays. The proposed work will pave the way for making immersive large-scale data exploration more accessible to large audiences, opening up possibilities of letting home virtual reality users participate in novel learning experiences. The PI will showcase the resulting immersive visualizations at regular outreach events to attract underrepresented minorities to novel human-computer interaction, and thus STEM research.\r\n\r\nEffective information visualization needs to be able to process and display large amounts of data in real-time to enable interactive analysis. The PI will build direct graphics processing unit (GPU) support into a modern information visualization library design, targeting one to two orders of magnitude acceleration in the rendering of large numbers of graphical elements, compared to current web-based visualization libraries. This computational scalability will enable interactive exploration of very large datasets, either displayed using a single visualization paradigm (e.g. node-link network) or multiple paradigms (e.g., map, network, sensor data, time series, etc.). Immersive information environments have the potential to support more effective capabilities for collaborative analysis than is possible with desktop or web-based platforms by placing groups of stakeholders in the middle of large-scale data visualizations to relate to others' first-person perspectives and interactively and jointly navigate through information spaces and control and highlight different aspects. The PI will design interactive collaborative data navigation and control tools that focus on this potential.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tobias",
   "pi_last_name": "Hollerer",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Tobias H Hollerer",
   "pi_email_addr": "holl@cs.ucsb.edu",
   "nsf_id": "000166428",
   "pi_start_date": "2017-09-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Barbara",
  "inst_street_address": "3227 CHEADLE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA BARBARA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8058934188",
  "inst_zip_code": "931060001",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SANTA BARBARA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G9QBQDH39DF4"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Barbara",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "931065110",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": null,
 "pgm_ref": [
  {
   "pgm_ref_code": "7484",
   "pgm_ref_txt": "IIS SPECIAL PROJECTS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8237",
   "pgm_ref_txt": "CISE Interagency Agreements"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 93230.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project created and evaluated novel tools for large-scale real-time interactive information analysis using immersive platforms such as virtual reality (VR) and augmented reality (AR). &nbsp;Effective information visualization needs to be able to process and display large amounts of data in real-time to enable interactive analysis. A young generation of future data analysts is now growing up trained in interactive experiences through 3D action games and VR applications. Immersive display platforms such as enabled by VR and AR provide an infinite canvas for large-scale data analysis. This project created and evaluated tools for utilizing this potential for large-scale immersive visual analytics.&nbsp;</span></p>\n<p><strong><span>Scalability</span></strong><span>: the project made information visualization scalable for such environments by building direct graphics hardware support into a modern information visualization library design. A novel visualization library, Stardust, provides one to two orders of magnitude acceleration in the rendering of large numbers of graphical elements, compared to current web-based visualization libraries. This computational scalability enables interactive exploration of very large datasets, either displayed using a single visualization paradigm (e.g. node-link network) or multiple paradigms (e.g., map, network, sensor data, time series, etc.). The presented work demonstrated the feasibility of interactive immersive analysis of such large data repositories.&nbsp;&nbsp;</span></p>\n<p><strong><span>Authoring</span></strong><span>: Information visualization needs to be usable by experts in the respective data domains, and these users should not be required to have a background in computer programming. The research team behind this project designed expressive authoring tools that enable information analysts to design, adapt, and control immersive information visualizations directly on the platforms that are going to be used for end-user display and analysis. A newly created authoring language and environment, IdyllMR,&nbsp;allows for the convenient&nbsp;creation of immersive visual data stories.</span></p>\n<p><strong><span>Collaborative Analysis</span></strong><span>: Immersive information environments have the potential to support more effective capabilities for collaborative analysis than is possible with desktop or web-based platforms. Groups of stakeholders can be placed in the middle of large-scale data visualizations and easily relate to each other's first-person perspectives and interactively and jointly navigate through information spaces and control and highlight different aspects. The research team designed interactive collaborative data navigation and control tools that focus on this potential. A novel experimentation platform, XRCreator,&nbsp;enables AR and VR users to jointly author and explore large-scale immersive data landscapes.&nbsp;</span></p>\n<p><span>The PI and research team showcased and evaluated the presented work in several case studies, which also explored the use of tangible spherical interaction devices for controlling the immersive visualizations.&nbsp;</span></p>\n<p><span>This research created novel capabilities for current and future data analysts and also paved the way for making immersive large-scale data exploration more accessible to large audiences. It opened up possibilities of letting home virtual reality users participate in novel learning experiences that are more immediate and memorable than possible using traditional computing equipment. Collaborative hands-on data visualizations like the ones explored in this project can bring tangible educational experiences to populations that cannot regularly afford social learning experiences (such as special lectures or college experiences). Such populations can benefit substantially from collaborative immersive visualizations.&nbsp;</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/27/2020<br>\n\t\t\t\t\tModified by: Tobias&nbsp;H&nbsp;Hollerer</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588000654018_01_XRCreatorCollab--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588000654018_01_XRCreatorCollab--rgov-800width.jpg\" title=\"AR and VR collaboration in XRCreator\"><img src=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588000654018_01_XRCreatorCollab--rgov-66x44.jpg\" alt=\"AR and VR collaboration in XRCreator\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An AR user (first person perspective) and a VR user (depicted) collaborate on the interactive visual analysis of a data story concerning an epidemic outbreak.</div>\n<div class=\"imageCredit\">Tobias Hollerer</div>\n<div class=\"imageSubmitted\">Tobias&nbsp;H&nbsp;Hollerer</div>\n<div class=\"imageTitle\">AR and VR collaboration in XRCreator</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1587999942172_01_StardustScalablePortable--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1587999942172_01_StardustScalablePortable--rgov-800width.jpg\" title=\"Stardust Library Examples\"><img src=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1587999942172_01_StardustScalablePortable--rgov-66x44.jpg\" alt=\"Stardust Library Examples\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Sample visualization created with our scalable Stardust library. Three different display environments run the same code: (a, b) run in browsers with WebGL; (c, d) run in the UCSB AlloSphere?s Allofw framework with OpenGL 3.3; and (d) uses Omnistereo for 360 degree surround immersion</div>\n<div class=\"imageCredit\">Tobias Hollerer</div>\n<div class=\"imageSubmitted\">Tobias&nbsp;H&nbsp;Hollerer</div>\n<div class=\"imageTitle\">Stardust Library Examples</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588001515681_04_IdyllMRCollab--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588001515681_04_IdyllMRCollab--rgov-800width.jpg\" title=\"IdyllMR: authoring interactive immersive visual stories\"><img src=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588001515681_04_IdyllMRCollab--rgov-66x44.jpg\" alt=\"IdyllMR: authoring interactive immersive visual stories\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Dynamic querying of a 3D scatterplot comparing countries' CO2 emissions and average income (data from gapminder.org).</div>\n<div class=\"imageCredit\">Tobias Hollerer</div>\n<div class=\"imageSubmitted\">Tobias&nbsp;H&nbsp;Hollerer</div>\n<div class=\"imageTitle\">IdyllMR: authoring interactive immersive visual stories</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588001983419_05_TangibleEarth--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588001983419_05_TangibleEarth--rgov-800width.jpg\" title=\"Tangible Spherical Proxy for Immersive Visualizations\"><img src=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588001983419_05_TangibleEarth--rgov-66x44.jpg\" alt=\"Tangible Spherical Proxy for Immersive Visualizations\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A tangible spherical object is utilized in VR by tracking an acrylic glass sphere with commercial hardware (image captured with Microsoft Hololens).</div>\n<div class=\"imageCredit\">Tobias Hollerer</div>\n<div class=\"imageSubmitted\">Tobias&nbsp;H&nbsp;Hollerer</div>\n<div class=\"imageTitle\">Tangible Spherical Proxy for Immersive Visualizations</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588002279768_06_SphericalProxyUserStudy--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588002279768_06_SphericalProxyUserStudy--rgov-800width.jpg\" title=\"Object Alignment User Study with Spherical Proxy\"><img src=\"/por/images/Reports/POR/2020/1748392/1748392_10521341_1588002279768_06_SphericalProxyUserStudy--rgov-66x44.jpg\" alt=\"Object Alignment User Study with Spherical Proxy\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A user study participant rotates a physical proxy sphere to align two test shapes in augmented reality</div>\n<div class=\"imageCredit\">Tobias Hollerer</div>\n<div class=\"imageSubmitted\">Tobias&nbsp;H&nbsp;Hollerer</div>\n<div class=\"imageTitle\">Object Alignment User Study with Spherical Proxy</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project created and evaluated novel tools for large-scale real-time interactive information analysis using immersive platforms such as virtual reality (VR) and augmented reality (AR).  Effective information visualization needs to be able to process and display large amounts of data in real-time to enable interactive analysis. A young generation of future data analysts is now growing up trained in interactive experiences through 3D action games and VR applications. Immersive display platforms such as enabled by VR and AR provide an infinite canvas for large-scale data analysis. This project created and evaluated tools for utilizing this potential for large-scale immersive visual analytics. \n\nScalability: the project made information visualization scalable for such environments by building direct graphics hardware support into a modern information visualization library design. A novel visualization library, Stardust, provides one to two orders of magnitude acceleration in the rendering of large numbers of graphical elements, compared to current web-based visualization libraries. This computational scalability enables interactive exploration of very large datasets, either displayed using a single visualization paradigm (e.g. node-link network) or multiple paradigms (e.g., map, network, sensor data, time series, etc.). The presented work demonstrated the feasibility of interactive immersive analysis of such large data repositories.  \n\nAuthoring: Information visualization needs to be usable by experts in the respective data domains, and these users should not be required to have a background in computer programming. The research team behind this project designed expressive authoring tools that enable information analysts to design, adapt, and control immersive information visualizations directly on the platforms that are going to be used for end-user display and analysis. A newly created authoring language and environment, IdyllMR, allows for the convenient creation of immersive visual data stories.\n\nCollaborative Analysis: Immersive information environments have the potential to support more effective capabilities for collaborative analysis than is possible with desktop or web-based platforms. Groups of stakeholders can be placed in the middle of large-scale data visualizations and easily relate to each other's first-person perspectives and interactively and jointly navigate through information spaces and control and highlight different aspects. The research team designed interactive collaborative data navigation and control tools that focus on this potential. A novel experimentation platform, XRCreator, enables AR and VR users to jointly author and explore large-scale immersive data landscapes. \n\nThe PI and research team showcased and evaluated the presented work in several case studies, which also explored the use of tangible spherical interaction devices for controlling the immersive visualizations. \n\nThis research created novel capabilities for current and future data analysts and also paved the way for making immersive large-scale data exploration more accessible to large audiences. It opened up possibilities of letting home virtual reality users participate in novel learning experiences that are more immediate and memorable than possible using traditional computing equipment. Collaborative hands-on data visualizations like the ones explored in this project can bring tangible educational experiences to populations that cannot regularly afford social learning experiences (such as special lectures or college experiences). Such populations can benefit substantially from collaborative immersive visualizations. \n\n \n\n\t\t\t\t\tLast Modified: 04/27/2020\n\n\t\t\t\t\tSubmitted by: Tobias H Hollerer"
 }
}