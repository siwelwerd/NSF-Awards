{
 "awd_id": "1721578",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Reconstructing Consistently Detailed City-Scale Environments From Incomplete 2D and 3D Data",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 224009.0,
 "awd_amount": 224009.0,
 "awd_min_amd_letter_date": "2017-06-28",
 "awd_max_amd_letter_date": "2017-06-28",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will be to make it cheaper and faster for architects, urban planners, and real-estate developers (APDs), as well as many others, to work with detailed models of the real world. Designers in APD fields must visualize and render their projects in the context of the real world. Pictures, videos, 3D printing, and even virtual reality inform the design process and facilitate communication with lay customers and stakeholders. These applications require consistently detailed models of the built world, and this project will automate the generation of these models. We estimate that APDs spend at least $80M annually creating these models by hand; and that at least $300M more is spent on such models for simulations, special effects, and video game design. By algorithmically generating virtual models without human intervention, the significant cost (in time and money) of manual creation will be saved, freeing design professionals to do work they want to be doing.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project will advance the state of the art in reconstructing highly detailed models of the world for diverse commercial applications. The first hurdle is solving the problem of reconstructing surfaces representing the boundaries of real-world solids (buildings) from noisy point cloud data. While surface reconstruction is well-studied in a variety of contexts, it remains an open problem in general, as successful algorithms must be informed by priors on the intended datasets. Using a data-driven approach to segment and classify input point clouds will facilitate the application of different reconstruction techniques to different objects (e.g. trees or buildings). The second hurdle is development of a machine learning algorithm which handles the dual problems of procedural modeling and inverse procedural modeling from a single statistical model, enabling visually realistic predictions about the details of a given building, even when that information is not available from source data (which may be of inconsistent quality across a large geographic area).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Mitchell",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher Mitchell",
   "pi_email_addr": "christopher@geopi.pe",
   "nsf_id": "000738612",
   "pi_start_date": "2017-06-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Geopipe, Inc.",
  "inst_street_address": "1287 MADISON AVE APT 4",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "9176861961",
  "inst_zip_code": "101280573",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "GEOPIPE, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "RVJDFJJLV3U7"
 },
 "perf_inst": {
  "perf_inst_name": "Geopipe, Inc.",
  "perf_str_addr": "19 East 7th Street Apt 2",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100038071",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5371",
   "pgm_ref_txt": "SMALL BUSINESS PHASE I"
  },
  {
   "pgm_ref_code": "8032",
   "pgm_ref_txt": "Software Services and Applications"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 224009.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Virtual models of the real world are a vital component of business in many fields. Billions of dollars are spent every year creating models of real environments, many by hand. These models are required for projects in architecture, urban design, and urban planning, as well as for video games, special effects, training simulations for the military and first responders, and automotive applications. Geopipe's created the company with the vision that computers could be taught to automatically build 3D models of the real world. Geopipe aims to provide 3D models of the real world to each of these verticals. As manually tracing real cities into virtual space does not scale, particularly at high detail and with semantic labeling, this NSF SBIR Phase I project is the first step towards commercializing a product that solves this problem.</p>\n<p>The major goals of this SBIR Phase I proposal were to develop the methods to machine-generate accurate, expansive virtual models of the real world with embedded semantic detail, and to demonstrate preliminary commercialization feasibility. Geopipe's research work centered on using state-of-the-art techniques to turn unstructured, raw data describing real cities into semantic information describing an environment. This labeled dataset could then be taken one step further to produce customizable meshed models of the world, ready for use in existing applications and workflow. The timing of this venture benefits from the plummeting costs of data collection and cloud computing, recent advancements in the relevant machine learning technologies, and significant growth in the scope of the market need for such data and models.</p>\n<p>Geopipe&rsquo;s nascent technology will save creative professionals the thousands of dollars and days to months of work consumed by context modeling the built world. Thus, firms of all sizes will be able to create analyses, visualizations, renderings, videos, and interactive experiences at substantially lower opportunity cost than is now possible: more bids will be won, more thorough impact studies will be conducted, and more compelling presentation media will be created for their own clients. The successful prototype of Geopipe ContextSnap (especially the underlying reconstruction techniques) that was created during this Phase I project is already making a small impact in the architecture, urban planning, and gaming fields, and we anticipate that the impact will significantly increase as the technology matures, more semantic and visual detail is possible, and more geographic areas are covered. Specifically, it is and will be come much cheaper and easier to analyze and visualize the current world or a modified world of tomorrow without expensive, slow manual reconstruction.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/07/2018<br>\n\t\t\t\t\tModified by: Christopher&nbsp;Mitchell</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1721578/1721578_10496867_1537302093111_pa_textured--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1721578/1721578_10496867_1537302093111_pa_textured--rgov-800width.jpg\" title=\"Virtual 3D model of midtown New York City\"><img src=\"/por/images/Reports/POR/2018/1721578/1721578_10496867_1537302093111_pa_textured--rgov-66x44.jpg\" alt=\"Virtual 3D model of midtown New York City\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Virtual models of the real world are a vital component of business across many fields, but remain expensive and slow to create. This SBIR project is a step towards automatic generation of detailed, semantically rich 3D models of cities.</div>\n<div class=\"imageCredit\">Geopipe, Inc.</div>\n<div class=\"imageSubmitted\">Christopher&nbsp;Mitchell</div>\n<div class=\"imageTitle\">Virtual 3D model of midtown New York City</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nVirtual models of the real world are a vital component of business in many fields. Billions of dollars are spent every year creating models of real environments, many by hand. These models are required for projects in architecture, urban design, and urban planning, as well as for video games, special effects, training simulations for the military and first responders, and automotive applications. Geopipe's created the company with the vision that computers could be taught to automatically build 3D models of the real world. Geopipe aims to provide 3D models of the real world to each of these verticals. As manually tracing real cities into virtual space does not scale, particularly at high detail and with semantic labeling, this NSF SBIR Phase I project is the first step towards commercializing a product that solves this problem.\n\nThe major goals of this SBIR Phase I proposal were to develop the methods to machine-generate accurate, expansive virtual models of the real world with embedded semantic detail, and to demonstrate preliminary commercialization feasibility. Geopipe's research work centered on using state-of-the-art techniques to turn unstructured, raw data describing real cities into semantic information describing an environment. This labeled dataset could then be taken one step further to produce customizable meshed models of the world, ready for use in existing applications and workflow. The timing of this venture benefits from the plummeting costs of data collection and cloud computing, recent advancements in the relevant machine learning technologies, and significant growth in the scope of the market need for such data and models.\n\nGeopipe?s nascent technology will save creative professionals the thousands of dollars and days to months of work consumed by context modeling the built world. Thus, firms of all sizes will be able to create analyses, visualizations, renderings, videos, and interactive experiences at substantially lower opportunity cost than is now possible: more bids will be won, more thorough impact studies will be conducted, and more compelling presentation media will be created for their own clients. The successful prototype of Geopipe ContextSnap (especially the underlying reconstruction techniques) that was created during this Phase I project is already making a small impact in the architecture, urban planning, and gaming fields, and we anticipate that the impact will significantly increase as the technology matures, more semantic and visual detail is possible, and more geographic areas are covered. Specifically, it is and will be come much cheaper and easier to analyze and visualize the current world or a modified world of tomorrow without expensive, slow manual reconstruction.\n\n\t\t\t\t\tLast Modified: 11/07/2018\n\n\t\t\t\t\tSubmitted by: Christopher Mitchell"
 }
}