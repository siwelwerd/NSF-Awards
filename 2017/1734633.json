{
 "awd_id": "1734633",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: INT: SCHooL: Scalable Collaborative Human-Robot Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 1374893.0,
 "awd_amount": 1374893.0,
 "awd_min_amd_letter_date": "2017-08-18",
 "awd_max_amd_letter_date": "2017-08-18",
 "awd_abstract_narration": "To be useful in warehouses, homes, and other environments from schools to retail stores, robots will need to learn how to robustly manipulate a wide variety of objects.  For instance, to enhance the productivity of human workers, service and factory robots could keep specified surfaces clear by identifying, grasping, and relocating objects to appropriate locations.  Pre-programming robots to perform such complex manipulation tasks is not feasible; instead this project will investigate scalable robot manipulation, where multiple robots collaboratively learn from multiple humans.  The project will contribute new models, algorithms, software, and experimental data to advance the state-of-the-art in deep learning, human-robot interaction, and cloud robotics.  To broadly convey the results of this research to students and the public, the project will create a book and video with the Lawrence Hall of Science and the African Robotics Network.\r\n \r\nTwo primary gaps in current understanding of co-robotic Learning from Demonstration (LfD) are: 1) the absence of a theoretical framework that encompasses humans and robots to produce cooperative learning behaviors as optimal solutions; and 2) the lack of research linking LfD with deep learning, hierarchical planning, and human-robot interaction. The project addresses those gaps with a unified theoretical framework based on Inverse Reinforcement Learning and game-theoretic models of communication between humans and robots, treating LfD as a scalable co-robotic process in which multiple humans and multiple networked robots work in a distributed set of environments to maximize a collective set of reward functions and humans learn how to become more effective demonstrators for robots. The research can be applied to almost any context where robots can learn from human demonstrations and will be evaluated in \"surface decluttering\" benchmarks of increasing complexity over the course of the project.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ken",
   "pi_last_name": "Goldberg",
   "pi_mid_init": "Y",
   "pi_sufx_name": "",
   "pi_full_name": "Ken Y Goldberg",
   "pi_email_addr": "goldberg@berkeley.edu",
   "nsf_id": "000221423",
   "pi_start_date": "2017-08-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Stuart",
   "pi_last_name": "Russell",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Stuart J Russell",
   "pi_email_addr": "russell@cs.berkeley.edu",
   "nsf_id": "000443080",
   "pi_start_date": "2017-08-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Pieter",
   "pi_last_name": "Abbeel",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pieter Abbeel",
   "pi_email_addr": "pabbeel@cs.berkeley.edu",
   "nsf_id": "000511407",
   "pi_start_date": "2017-08-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Anca",
   "pi_last_name": "Dragan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anca Dragan",
   "pi_email_addr": "anca@berkeley.edu",
   "nsf_id": "000704141",
   "pi_start_date": "2017-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947045940",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 1374893.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-32333e9f-7fff-3142-d368-ecefd0aa08f1\">&nbsp;</span></p>\n<p dir=\"ltr\"><span>This 4-year collaborative research project&nbsp;developed 1) a Formal Framework for Scalable Collaborative IRL (SCIRL), that extended previous work&nbsp; to multi-agent games and collaborative learning in multiple distributed domains; 2) new Deep Learning Representations of Visual Features and Reward Functions to robustly extract, apply, and share deep learning parameters and visual features needed for efficient robot learning; 3) new approaches to Learning Hierarchical Task and Reward Structure to reduce planning horizon by partitioning complex tasks into sub-tasks; and 4) new results in Human&ndash;Robot Communication to scale bi-directional communication between robots and humans to facilitate distributed learning.&nbsp; The project contributed new models, algorithms, software, and experimental data to advance the state-of-the-art in deep learning, robot manipulation, human&ndash;robot interaction, and cloud robotics.&nbsp;</span></p>\n<p dir=\"ltr\">This research was pursued using the integrative application of Surface Decluttering -- keeping specified surfaces clear by identifying, grasping, and relocating selected objects to appropriate locations, which has near-term applications in homes, schools, warehouses, offices, and retail stores. It used the Fetch Robot, an example of an emerging class of robot mobile manipulators being adopted in many warehouses and industrial workplaces. To enable robust manipulation, the project studied how robots can learn from humans rather than having to be programmed explicitly or perform unguided exploration. This project built on emerging research in robot learning, human-robot interaction, and cloud robotics to address the NRI 2.0 themes of Collaboration, Interaction, and Scalability.&nbsp;</p>\n<p dir=\"ltr\"><span>The class of approaches known as Learning from Demonstrations (LfD) often assumes that each robot learns a policy by passively observing one human, and that Inverse Reinforcement Learning (IRL) is a common LfD approach that uses one human&rsquo;s demonstrations to infer the human's reward function, which can lead to more robust, generalizable, and explainable policies. Existing IRL research makes 3 subtle assumptions: (1) that the human always acts according to a reward function, without reasoning about the robot's capability or explicitly trying to teach; (2) that the robot is a passive observer and does not communicate with the human; and (3) that there is only one robot and one human. This project studied how LfD can be a scalable collaborative co-robotic process, in which multiple humans and multiple networked robots work in a distributed set of environments to maximize a collective set of reward functions.&nbsp;</span></p>\n<p>The project produced over 20 peer-reviewed papers and 3 PhD dissertations.</p>\n<p>To broadly convey the results of this research to students and the public, the project created a book and video to encourage interest in robotics and STEM for girls and other under-represented students. &nbsp; How To Train Your Robot. Blooma Goldberg, Ken Goldberg, and Ashley Chase. Illustrated by Dave Clegg. University of California (with support from the National Science Foundation and UC Berkeley Lawrence Hall of Science), Nov 2019.&nbsp; This engaging 24-page book and video for students aged 8-10 tells a story of 4th graders who build a robot to declutter their Razzle-Dazzle Robot Club workshop.&nbsp; When it doesn't work as expected, they visit their local university where they discover new research in Artificial Intelligence and robot learning. The book introduces readers to cutting-edge robotics and AI in a highly accessible way and models authentic engineering practices such as iterative design, testing, and learning through failure. With a diverse cast of characters and colorful, humorous illustrations, How to Train Your Robot continues to inspire girls and members of other under-represented groups to explore engineering, robotics, and coding for themselves.&nbsp; The book is included in the Amplify Science Digital Library, accessible in Fall 2020 to over 2 million US students:&nbsp;&nbsp;<a href=\"https://amplify.com/\">https://amplify.com/</a></p>\n<p>Book with free download:&nbsp;</p>\n<p dir=\"ltr\"><a href=\"http://j.mp/How-to-Train-Your-Robot-book\"><span>http://j.mp/How-to-Train-Your-Robot-book</span></a></p>\n<p>Video, free 15 Minute Video (subtitled in Spanish, Japanese, Hindi, and Chinese (Simplified))</p>\n<p dir=\"ltr\"><a href=\"https://vimeopro.com/citrisproductions/how-to-train-your-robot\"><span>https://vimeopro.com/citrisproductions/how-to-train-your-robot</span></a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/26/2022<br>\n\t\t\t\t\tModified by: Ken&nbsp;Goldberg</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThis 4-year collaborative research project developed 1) a Formal Framework for Scalable Collaborative IRL (SCIRL), that extended previous work  to multi-agent games and collaborative learning in multiple distributed domains; 2) new Deep Learning Representations of Visual Features and Reward Functions to robustly extract, apply, and share deep learning parameters and visual features needed for efficient robot learning; 3) new approaches to Learning Hierarchical Task and Reward Structure to reduce planning horizon by partitioning complex tasks into sub-tasks; and 4) new results in Human&ndash;Robot Communication to scale bi-directional communication between robots and humans to facilitate distributed learning.  The project contributed new models, algorithms, software, and experimental data to advance the state-of-the-art in deep learning, robot manipulation, human&ndash;robot interaction, and cloud robotics. \nThis research was pursued using the integrative application of Surface Decluttering -- keeping specified surfaces clear by identifying, grasping, and relocating selected objects to appropriate locations, which has near-term applications in homes, schools, warehouses, offices, and retail stores. It used the Fetch Robot, an example of an emerging class of robot mobile manipulators being adopted in many warehouses and industrial workplaces. To enable robust manipulation, the project studied how robots can learn from humans rather than having to be programmed explicitly or perform unguided exploration. This project built on emerging research in robot learning, human-robot interaction, and cloud robotics to address the NRI 2.0 themes of Collaboration, Interaction, and Scalability. \nThe class of approaches known as Learning from Demonstrations (LfD) often assumes that each robot learns a policy by passively observing one human, and that Inverse Reinforcement Learning (IRL) is a common LfD approach that uses one human\u2019s demonstrations to infer the human's reward function, which can lead to more robust, generalizable, and explainable policies. Existing IRL research makes 3 subtle assumptions: (1) that the human always acts according to a reward function, without reasoning about the robot's capability or explicitly trying to teach; (2) that the robot is a passive observer and does not communicate with the human; and (3) that there is only one robot and one human. This project studied how LfD can be a scalable collaborative co-robotic process, in which multiple humans and multiple networked robots work in a distributed set of environments to maximize a collective set of reward functions. \n\nThe project produced over 20 peer-reviewed papers and 3 PhD dissertations.\n\nTo broadly convey the results of this research to students and the public, the project created a book and video to encourage interest in robotics and STEM for girls and other under-represented students.   How To Train Your Robot. Blooma Goldberg, Ken Goldberg, and Ashley Chase. Illustrated by Dave Clegg. University of California (with support from the National Science Foundation and UC Berkeley Lawrence Hall of Science), Nov 2019.  This engaging 24-page book and video for students aged 8-10 tells a story of 4th graders who build a robot to declutter their Razzle-Dazzle Robot Club workshop.  When it doesn't work as expected, they visit their local university where they discover new research in Artificial Intelligence and robot learning. The book introduces readers to cutting-edge robotics and AI in a highly accessible way and models authentic engineering practices such as iterative design, testing, and learning through failure. With a diverse cast of characters and colorful, humorous illustrations, How to Train Your Robot continues to inspire girls and members of other under-represented groups to explore engineering, robotics, and coding for themselves.  The book is included in the Amplify Science Digital Library, accessible in Fall 2020 to over 2 million US students:  https://amplify.com/\n\nBook with free download: \nhttp://j.mp/How-to-Train-Your-Robot-book\n\nVideo, free 15 Minute Video (subtitled in Spanish, Japanese, Hindi, and Chinese (Simplified))\nhttps://vimeopro.com/citrisproductions/how-to-train-your-robot\n\n \n\n \n\n\t\t\t\t\tLast Modified: 01/26/2022\n\n\t\t\t\t\tSubmitted by: Ken Goldberg"
 }
}