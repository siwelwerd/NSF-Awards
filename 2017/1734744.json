{
 "awd_id": "1734744",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NCS-FO: Active Listening and Attention in 3D Natural Scenes",
 "cfda_num": "47.076",
 "org_code": "11040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ellen Carpenter",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 948067.0,
 "awd_amount": 1155675.0,
 "awd_min_amd_letter_date": "2017-08-07",
 "awd_max_amd_letter_date": "2022-12-20",
 "awd_abstract_narration": "As humans and other animals move around, the distance and direction between their bodies and objects in their environment are constantly changing.  Judging the position of objects, and readjusting body movements to steer around the objects, requires a constantly updated map of three-dimensional space in the brain.  Generating this map, and keeping it updated during movement, requires dynamic interaction between visual or auditory cues, attention, and behavioral output.  An understanding of how spatial perception is generated in the brain comes from decades of research using visual or auditory stimuli under restricted conditions.  Far less is known about the dynamics of how natural scenes are represented in freely moving animals.  This project will bridge this gap by studying how freely flying bats navigate through their environment using echolocation.  Specifically, a team of engineers and neuroscientists will investigate how the bat brain processes information associated with flight navigation. The project team will provide education and training in engineering and science to public school, undergraduate and graduate students, and to postdoctoral researchers. This research will also contribute to a rich library of materials, including videos and a website, which will be available to educators and scientists working in both the private and public sectors.\r\n\r\nThis project leverages innovative engineering tools, cutting-edge neuroscience methods and neuroethological modeling to pursue a multidisciplinary investigation of dynamic feedback between 3D scene representation, attention and action-selection in freely moving animals engaged in natural tasks. The echolocating bat, the subject of the project's research, actively produces the acoustic signals that it uses to represent natural scenes and therefore provides direct access to the sensory information that guides behavior. The specific goals of the project are to test the hypotheses that 1) natural scene representation operates through the interplay between sensory processing, adaptive motor behaviors, and attentional feedback, 2) spatio-temporal responses to sensory streams across ensembles of neurons sharpen when an animal adapts its behavior to attend to selected targets, and 3) spatio-temporal sharpening of neural responses enables figure-ground segregation in the natural environment. The project integrates 1) novel acoustic measurements and computational analyses to represent the sonar scene based on reconstructions of the bat's sonar transmitter and receiver characteristics, combined with a 3D acoustic model of the environment, 2) quantitative analysis of the echolocating bat's adaptive echolocation and flight behaviors as it negotiates complex environments, 3) multichannel neural telemetry recordings from the midbrain of the free-flying bat as it attends to targets, obstacles and other acoustic signals in its surroundings, and 4) computational modeling of auditory system architecture, attention and working memory mechanisms.  Collectively, this research will deepen the understanding of behavioral modulation of natural scene representation. \r\n\r\nThis project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a multidisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DUE",
 "org_div_long_name": "Division Of Undergraduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cynthia",
   "pi_last_name": "Moss",
   "pi_mid_init": "F",
   "pi_sufx_name": "",
   "pi_full_name": "Cynthia F Moss",
   "pi_email_addr": "cynthia.moss@jhu.edu",
   "nsf_id": "000233746",
   "pi_start_date": "2017-08-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rajat",
   "pi_last_name": "Mittal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rajat Mittal",
   "pi_email_addr": "mittal@jhu.edu",
   "nsf_id": "000484656",
   "pi_start_date": "2017-08-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mounya",
   "pi_last_name": "Elhilali",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mounya Elhilali",
   "pi_email_addr": "mounya@jhu.edu",
   "nsf_id": "000234530",
   "pi_start_date": "2017-08-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Susanne",
   "pi_last_name": "Sterbing-D'Angelo",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Susanne J Sterbing-D'Angelo",
   "pi_email_addr": "ssterbi1@jhu.edu",
   "nsf_id": "000683352",
   "pi_start_date": "2017-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "3400 N. Charles Street",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182686",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "798000",
   "pgm_ele_name": "ECR-EDU Core Research"
  },
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "8551",
   "pgm_ref_txt": "IntgStrat Undst Neurl&Cogn Sys"
  },
  {
   "pgm_ref_code": "8817",
   "pgm_ref_txt": "STEM Learning & Learning Environments"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "04002324DB",
   "fund_name": "NSF STEM Education",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0417",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001718DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0420",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002021DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 948067.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 189608.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 18000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We completed a successful interdisciplinary research project, Active listening and attention in 3D natural scenes, that advances understanding of cognitive and neural processes in realistic, complex environments.&nbsp; This project leveraged innovative engineering tools, cutting-edge neuroscience methods and a neuroethological model system to pursue a multidisciplinary investigation of dynamic feedback between 3D scene representation, attention, and action-selection in freely moving animals engaged in natural tasks. We conducted research that shed light on 1) the interplay between sensory processing, adaptive motor behaviors, and spatial attention in building natural scene perception and 2) attention-evoked changes in the brain?s response to natural sounds.</p>\n<p><strong>Intellectual Merit</strong></p>\n<p>The success of our project emerged from on the team?s broad expertise in systems neuroscience, behavioral biology, acoustics and engineering to investigate the neural underpinning of natural scene representation and attention-guided action.</p>\n<p>1. Our research yielded scientific advances by probing the active sensing system of echolocating bats, animals that perceive the 3D world by processing echo returns from their own sonar calls. The directional aim and temporal patterning of the bat?s echolocation calls provide a quantifiable metric of the animal?s attention to objects in the environment.</p>\n<p>2.&nbsp; Echolocating bats engaged in a variety of natural tasks in complex environments.&nbsp; Our interdisciplinary work revealed the dynamics of neural processing in the context of natural behaviors.</p>\n<p>3.&nbsp; The computational acoustics tools that were developed through this project have direct applications for the analysis of human speech and hearing, bioacoustics, aeroacoustics, architectural acoustics, acoustic device design, environmental noise and even musical acoustics.&nbsp;&nbsp;</p>\n<p><strong>Broader impacts</strong></p>\n<p><strong><em>1.&nbsp;&nbsp;</em></strong><strong>Interdisciplinary Research Training.</strong>&nbsp; Our project provided an interdisciplinary training platform for undergraduate and graduate students, as well as postdoctoral researchers. We involved a diverse group of graduate students and postdocs in the project, which allowed them to acquire new knowledge and a variety of research tools. The graduate students and postdocs also worked together in teams with undergraduate NSF REU students and Amgen Scholars who participated in research over the summer.&nbsp; Many of the NSF REU students were inspired by their research experiences to apply to graduate school in biology, psychology, neuroscience and engineering, veterinary school, and medical school.&nbsp; In addition, three Johns Hopkins students received REU stipends during the academic year to conduct research on one of the following projects: 1) Sonar target tracking in cluttered environments, 2) Target distance representation in the bat hippocampus, and 3) DREADD midbrain inactivation in bats performing a sonar-guided navigation task. These projects harnessed sophisticated behavioral assays, neural recordings and chemogenetic manipulations in bats tracking moving objects and steering around obstacles.&nbsp; Not only did the students become deeply involved in research and learn new skills, but their discoveries advance knowledge of the mechanisms supporting real-world sensorimotor behaviors and can guide development of assistive devices for the elderly and disabled.&nbsp;</p>\n<p><strong><em>2.&nbsp;&nbsp;&nbsp;&nbsp; </em></strong><strong>Education and Outreach</strong></p>\n<p>a.&nbsp; This project's research activities contributed to our library of multimedia materials, which we make available to educators and scientists through our Johns Hopkins University Bat Lab website. &nbsp;&nbsp;</p>\n<p>b.&nbsp; We hosted a Johns Hopkins outreach event in the spring of 2023 that featured a public lecture by Daniel Kish, who is blind since infancy and uses echolocation to navigate. &nbsp;Daniel Kish provided valuable feedback to graduate students and postdocs who participated in a weekend hackathon to develop new devices and other technologies for visually impaired humans.&nbsp; See attached photos.&nbsp; Discoveries emerging from this project have advanced knowledge of the mechanisms supporting real-world sensorimotor behaviors and guide development of assistive devices for the blind.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/16/2023<br>\n\t\t\t\t\tModified by: Cynthia&nbsp;F&nbsp;Moss</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1734744/1734744_10511953_1694901716074_DanielKishwithstudentsatHackathon--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1734744/1734744_10511953_1694901716074_DanielKishwithstudentsatHackathon--rgov-800width.jpg\" title=\"Daniel Kish with students at JHU Hackathon\"><img src=\"/por/images/Reports/POR/2023/1734744/1734744_10511953_1694901716074_DanielKishwithstudentsatHackathon--rgov-66x44.jpg\" alt=\"Daniel Kish with students at JHU Hackathon\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Daniel Kish, blind since infancy, provided feedback at a Johns Hopkins student hackathon to develop new technologies for the blind.</div>\n<div class=\"imageCredit\">Cindy Moss</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Cynthia&nbsp;F&nbsp;Moss</div>\n<div class=\"imageTitle\">Daniel Kish with students at JHU Hackathon</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1734744/1734744_10511953_1694901786245_DanielKishwithwinnersofHackathon--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1734744/1734744_10511953_1694901786245_DanielKishwithwinnersofHackathon--rgov-800width.jpg\" title=\"Daniel Kish with winners of JHU Hackathon\"><img src=\"/por/images/Reports/POR/2023/1734744/1734744_10511953_1694901786245_DanielKishwithwinnersofHackathon--rgov-66x44.jpg\" alt=\"Daniel Kish with winners of JHU Hackathon\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Daniel Kish, blind since infancy, presented awards at a Johns Hopkins student hackathon to develop new technologies for the blind.</div>\n<div class=\"imageCredit\">Cynthia Moss</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Cynthia&nbsp;F&nbsp;Moss</div>\n<div class=\"imageTitle\">Daniel Kish with winners of JHU Hackathon</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nWe completed a successful interdisciplinary research project, Active listening and attention in 3D natural scenes, that advances understanding of cognitive and neural processes in realistic, complex environments.  This project leveraged innovative engineering tools, cutting-edge neuroscience methods and a neuroethological model system to pursue a multidisciplinary investigation of dynamic feedback between 3D scene representation, attention, and action-selection in freely moving animals engaged in natural tasks. We conducted research that shed light on 1) the interplay between sensory processing, adaptive motor behaviors, and spatial attention in building natural scene perception and 2) attention-evoked changes in the brain?s response to natural sounds.\n\nIntellectual Merit\n\nThe success of our project emerged from on the team?s broad expertise in systems neuroscience, behavioral biology, acoustics and engineering to investigate the neural underpinning of natural scene representation and attention-guided action.\n\n1. Our research yielded scientific advances by probing the active sensing system of echolocating bats, animals that perceive the 3D world by processing echo returns from their own sonar calls. The directional aim and temporal patterning of the bat?s echolocation calls provide a quantifiable metric of the animal?s attention to objects in the environment.\n\n2.  Echolocating bats engaged in a variety of natural tasks in complex environments.  Our interdisciplinary work revealed the dynamics of neural processing in the context of natural behaviors.\n\n3.  The computational acoustics tools that were developed through this project have direct applications for the analysis of human speech and hearing, bioacoustics, aeroacoustics, architectural acoustics, acoustic device design, environmental noise and even musical acoustics.  \n\nBroader impacts\n\n1.  Interdisciplinary Research Training.  Our project provided an interdisciplinary training platform for undergraduate and graduate students, as well as postdoctoral researchers. We involved a diverse group of graduate students and postdocs in the project, which allowed them to acquire new knowledge and a variety of research tools. The graduate students and postdocs also worked together in teams with undergraduate NSF REU students and Amgen Scholars who participated in research over the summer.  Many of the NSF REU students were inspired by their research experiences to apply to graduate school in biology, psychology, neuroscience and engineering, veterinary school, and medical school.  In addition, three Johns Hopkins students received REU stipends during the academic year to conduct research on one of the following projects: 1) Sonar target tracking in cluttered environments, 2) Target distance representation in the bat hippocampus, and 3) DREADD midbrain inactivation in bats performing a sonar-guided navigation task. These projects harnessed sophisticated behavioral assays, neural recordings and chemogenetic manipulations in bats tracking moving objects and steering around obstacles.  Not only did the students become deeply involved in research and learn new skills, but their discoveries advance knowledge of the mechanisms supporting real-world sensorimotor behaviors and can guide development of assistive devices for the elderly and disabled. \n\n2.     Education and Outreach\n\na.  This project's research activities contributed to our library of multimedia materials, which we make available to educators and scientists through our Johns Hopkins University Bat Lab website.   \n\nb.  We hosted a Johns Hopkins outreach event in the spring of 2023 that featured a public lecture by Daniel Kish, who is blind since infancy and uses echolocation to navigate.  Daniel Kish provided valuable feedback to graduate students and postdocs who participated in a weekend hackathon to develop new devices and other technologies for visually impaired humans.  See attached photos.  Discoveries emerging from this project have advanced knowledge of the mechanisms supporting real-world sensorimotor behaviors and guide development of assistive devices for the blind. \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 09/16/2023\n\n\t\t\t\t\tSubmitted by: Cynthia F Moss"
 }
}