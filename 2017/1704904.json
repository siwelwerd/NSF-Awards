{
 "awd_id": "1704904",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Medium: Collaborative Research: Sculpting Visualizations: Toward a Practice and Theory of 3D Scientific Visualizations Using Physical Objects and Augmented Reality",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 524590.0,
 "awd_amount": 554030.0,
 "awd_min_amd_letter_date": "2017-06-12",
 "awd_max_amd_letter_date": "2020-08-18",
 "awd_abstract_narration": "Advances in 3D printing, augmented reality (AR), and virtual reality (VR), are creating new possibilities for computing tools that integrate with our physical environment and take advantage of our physical abilities.  This proposal will study how these technologies can support 3D data visualization, an increasingly important and common scientific activity.  The team, which includes computer scientists, artists, neuroscientists, geologists, and oceanologists, will first use 3D printing to develop physical representations of 3D data (\"physical data forms\") that match the needs of specific analysis domains and tasks, and through this develop principles for doing 3D design for visualizations in general.  They will then design hybrid spaces that use AR visual representations along with physical data forms, looking at ways to leverage the strengths of each and developing ways to interact with the data through both the virtual and physical forms.  Finally, they will create tools that leverage these design principles and interaction techniques to allow scientists to create new physical data forms and hybrid visualizations to address outstanding data analysis challenges in brain imaging, geology, and, ultimately, many scientific fields.  The work will support interdisciplinary courses at the intersection of art, science, computing, and data visualization at the PIs' institutions; students will also be trained in research methods and work with the research team to develop public science museum exhibits that raise awareness of both the technology and the science involved. \r\n\r\nTo leverage the possibilities of rapid, creative, artistic iteration and exploration of physical form, the team will develop interfaces and algorithms for capturing and extracting properties of physical forms, along with tools for exploring mappings between these properties and 3D data, a design theory and taxonomy, and a catalog for using physical inputs in visualization processes.  These physical elements will be augmented with colocated digital head-tracked stereoscopic displays that directly incorporate the printed objects into the AR experience, along with touch-based interaction techniques such as touch-sensitive input surfaces or the direct inclusion of physical widgets in the printed objects.  These visualizations will be evaluated through user studies based on existing methodologies for comparing 3D vector field visualization methods.  The team will then develop exploratory visualization tools, using streamlined versions of the catalog and visualizations developed earlier to help manage the complexity of creating new visualizations while teaching visual design processes to scientists through the use of the tools, recasting the scientific task of data exploration as a creative process of visualization design to support learning, engagement, and effective analysis.  These tools will be iteratively developed by teams of art and computer science students in conjunction with domain scientists and used to facilitate data exploration and discovery, as well as to bring science more directly into the public sphere through interactive experiences, such as at science museums.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Francesca",
   "pi_last_name": "Samsel",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Francesca Samsel",
   "pi_email_addr": "fsamsel@tacc.utexas.edu",
   "nsf_id": "000696587",
   "pi_start_date": "2017-06-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin, Center for Agile Technology",
  "perf_str_addr": "4201 W Parmer Lane",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787274109",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "TX37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 388553.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 136037.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 13440.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The intellectual merit of this project comes from exploring the potential of the emerging technologies of Augmented Reality (AR) and digital fabrication (e.g., 3D printing) to combine in a new, more powerful style of 3D visualization which enables expanded vocabularies able to accommodate the expanding complexity of scientific data. Both tracks work in tandem to assist scientists in understanding their multivariate datasets.&nbsp; The research team included both computer scientists and visual artists, enabling a unique methodology.&nbsp;&nbsp;</p>\n<p>In the first phase of the project, visual artists and designers created a sophisticated visual language of colors, textures, and 3D shapes that are expertly designed to convey scientific data.&nbsp; Most computerized 3D data visualizations use a limited visual language of simple shapes (e.g., colored 3D lines, spheres, and cubes).&nbsp; This works well for visualizing small datasets, but there are only a few ways these basic computer graphics shapes may be combined to encode data, so the approach fails when climate scientists or medical researchers need to analyze more complex datasets with many variables.&nbsp; In contrast, artists working without computers (e.g., using traditional physical media such as paint, ink, clay) can create much richer visual languages, for example, sets of dozens of lines that simply through their visual qualities, convey information such as \"powerful\" vs. \"weak\", \"natural\" vs. \"human-made\", or \"plant\" vs. \"animal\".&nbsp; Further, they can accomplish this with a variety of different media and with specific goals in mind (e.g., show a direction, convey expansion or contraction).&nbsp; The project makes it possible for the first time to leverage the full range of artistic skill with traditional media to produce much richer visual languages for depicting scientific data. After digitizing a library of hundreds of visual artifacts carefully designed by artists, computer scientists created novel software to resize, recolor, and place them in virtual spaces in response to data.&nbsp; The software includes a visual interface that makes designing new visualizations fast, and it generates powerful 3D visualizations that can depict many data variables in a single picture.&nbsp; With the software, artists worked together with several teams of scientists who struggle to analyze their multivariate, volumetric, time varying data. The new visualizations created for climate scientists display the terrain and bathymetry, ocean currents and velocities, concentrations of three varieties of nitrates, and concentrations of two varieties of plankton -- all in a single 3D visualization. This could never be accomplished with standard visualization vocabulary. The climate scientists describe the new data visualization capability as \"transformative&rdquo;.</p>\n<p>In Phase Two, the digital data visualizations were combined with physical data visualizations produced with digital fabrication technologies, such as 3D printing and laser cutting.&nbsp; For example, a 3D printed model of the terrain and bathymetry data was combined with digital visualizations of the ocean currents, nitrates, and plankton.&nbsp; Through experimental testing with climate scientists, the researchers found that this style of \"data physicalization\" provided a number of benefits, including an ability to quickly and accurately \"read\" data through a combination of vision and touch.&nbsp; Complementary digital visualizations were displayed using perspective-tracked, stereoscopic AR glasses so that the data could registered with the physical portions of the visualization and appear to \"float in the air\" above.&nbsp; This enabled the display of animated data, such as time-varying ocean with the static physical elements.&nbsp; The researchers invented a multi-touch sensing technique to detect interaction with this new style of hybrid digital+physical visualizations, making it possible to query data by touching the high-resolution physical data printouts and to display the results of the queries interactively in digital form. Climate scientists reported that this interface enabled deeper investigation into the 3D multi-variate data, revealing complexity and relationships not previous exposed.</p>\n<p>In addition, the project contributed new advances to the literature on expanding the vocabulary for scientific visualization to assist in encoding and revealing the complexity and relationships within the data; holistic evaluation methods for data visualization, and design theory for multivariate data visualization; remote computer graphics rendering for virtual reality.</p>\n<p>Broader Impacts include: training Ph.D. students, undergraduate students, and early career scientist, several of whom claim identities recognized by NSF as underrepresented in computing;&nbsp; dissemination of results at venues for design research and earth science ensured that the results reached communities of interest outside of computing; educational opportunities and infrastructure including new curriculum enabling students to use the tools and design libraries developed by artists and scientists.&nbsp; Partnerships with multiple planetariums and other public venues enabled presentation of research results via infrastructure that can also be utilized by future projects.&nbsp; Project results, software, and curriculum were presented annually at: the U-Teach Summit and TACC EPIC program seminars, which provide computer science training High School teachers from rural and unserved populations; local K-12 school groups; and the CODE at TACC seminars which train dozens of, nationally represented, underserved High School students.</p><br>\n<p>\n Last Modified: 12/19/2023<br>\nModified by: Francesca&nbsp;Samsel</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703010383568_TouchInterface1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703010383568_TouchInterface1--rgov-800width.png\" title=\"AR Touch-driven interface, Antarctic water mass data\"><img src=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703010383568_TouchInterface1--rgov-66x44.png\" alt=\"AR Touch-driven interface, Antarctic water mass data\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A direct multi-touch input sensing to a 3D physical printout and perspective-tracked, stereoscopic AR display, creating a hybrid visualization system enabling interactive data exploration of 3D multivariate data in real time. Antarctic  E3SM water mass data is shown here.</div>\n<div class=\"imageCredit\">Bridger Harmon</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Francesca&nbsp;Samsel\n<div class=\"imageTitle\">AR Touch-driven interface, Antarctic water mass data</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703011263346_ABR--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703011263346_ABR--rgov-800width.png\" title=\"The types of data encodings available in ABR shown on simulation data of the Gulf of Mexico\"><img src=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703011263346_ABR--rgov-66x44.png\" alt=\"The types of data encodings available in ABR shown on simulation data of the Gulf of Mexico\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This image is a combination of the types of assets available in Artifact-Based Rendering, (ABR) - artist created lines, textures, glyphs and colormaps all applied to volumetric data in the Gulf of Mexico waters.</div>\n<div class=\"imageCredit\">Francesca Samsel</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Francesca&nbsp;Samsel\n<div class=\"imageTitle\">The types of data encodings available in ABR shown on simulation data of the Gulf of Mexico</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703009564166_Sala--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703009564166_Sala--rgov-800width.png\" title=\"Sala Event Center, ScienceFest\"><img src=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703009564166_Sala--rgov-66x44.png\" alt=\"Sala Event Center, ScienceFest\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">At the Los Alamos 2023 ScienceFest we displayed video of the visualizations produced using Artifact-Based Rendering as well as enabled the public to try out the VR interactive capabilities.</div>\n<div class=\"imageCredit\">Francesca Samsel</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Francesca&nbsp;Samsel\n<div class=\"imageTitle\">Sala Event Center, ScienceFest</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703011581596_Planetarium--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703011581596_Planetarium--rgov-800width.png\" title=\"ABR Antarctic visualization shown in a planetarium\"><img src=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703011581596_Planetarium--rgov-66x44.png\" alt=\"ABR Antarctic visualization shown in a planetarium\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Visualization of E3SM climate model data showing ocean currents in the Southern Ocean displayed in a planetarium as part of our Broader Impact efforts.</div>\n<div class=\"imageCredit\">Francesca Samsel</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Francesca&nbsp;Samsel\n<div class=\"imageTitle\">ABR Antarctic visualization shown in a planetarium</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703010675292_Sculpting_vis_org_website--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703010675292_Sculpting_vis_org_website--rgov-800width.png\" title=\"Our website, Sculpting-vis.org\"><img src=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703010675292_Sculpting_vis_org_website--rgov-66x44.png\" alt=\"Our website, Sculpting-vis.org\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our website Sculpting-Vis.org contains documentation on the software, programs and assets developed, as well as tutorials and related projects.</div>\n<div class=\"imageCredit\">Francesca Samsel</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Francesca&nbsp;Samsel\n<div class=\"imageTitle\">Our website, Sculpting-vis.org</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703009201213_BGC_GoM1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703009201213_BGC_GoM1--rgov-800width.png\" title=\"Artifact-Based Rendering of biogeochemistry data in the Gulf of Mexico\"><img src=\"/por/images/Reports/POR/2023/1704904/1704904_10492331_1703009201213_BGC_GoM1--rgov-66x44.png\" alt=\"Artifact-Based Rendering of biogeochemistry data in the Gulf of Mexico\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Glyph forms included in the Artifact-Based Rendering software were studied for their effective, associative and affective properties. Here, E3SM  biogeochemistry data in the Gulf of Mexico is represented using glyph forms being evaluated for their affective properties.</div>\n<div class=\"imageCredit\">Francesca Samsel</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Francesca&nbsp;Samsel\n<div class=\"imageTitle\">Artifact-Based Rendering of biogeochemistry data in the Gulf of Mexico</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe intellectual merit of this project comes from exploring the potential of the emerging technologies of Augmented Reality (AR) and digital fabrication (e.g., 3D printing) to combine in a new, more powerful style of 3D visualization which enables expanded vocabularies able to accommodate the expanding complexity of scientific data. Both tracks work in tandem to assist scientists in understanding their multivariate datasets. The research team included both computer scientists and visual artists, enabling a unique methodology.\n\n\nIn the first phase of the project, visual artists and designers created a sophisticated visual language of colors, textures, and 3D shapes that are expertly designed to convey scientific data. Most computerized 3D data visualizations use a limited visual language of simple shapes (e.g., colored 3D lines, spheres, and cubes). This works well for visualizing small datasets, but there are only a few ways these basic computer graphics shapes may be combined to encode data, so the approach fails when climate scientists or medical researchers need to analyze more complex datasets with many variables. In contrast, artists working without computers (e.g., using traditional physical media such as paint, ink, clay) can create much richer visual languages, for example, sets of dozens of lines that simply through their visual qualities, convey information such as \"powerful\" vs. \"weak\", \"natural\" vs. \"human-made\", or \"plant\" vs. \"animal\". Further, they can accomplish this with a variety of different media and with specific goals in mind (e.g., show a direction, convey expansion or contraction). The project makes it possible for the first time to leverage the full range of artistic skill with traditional media to produce much richer visual languages for depicting scientific data. After digitizing a library of hundreds of visual artifacts carefully designed by artists, computer scientists created novel software to resize, recolor, and place them in virtual spaces in response to data. The software includes a visual interface that makes designing new visualizations fast, and it generates powerful 3D visualizations that can depict many data variables in a single picture. With the software, artists worked together with several teams of scientists who struggle to analyze their multivariate, volumetric, time varying data. The new visualizations created for climate scientists display the terrain and bathymetry, ocean currents and velocities, concentrations of three varieties of nitrates, and concentrations of two varieties of plankton -- all in a single 3D visualization. This could never be accomplished with standard visualization vocabulary. The climate scientists describe the new data visualization capability as \"transformative.\n\n\nIn Phase Two, the digital data visualizations were combined with physical data visualizations produced with digital fabrication technologies, such as 3D printing and laser cutting. For example, a 3D printed model of the terrain and bathymetry data was combined with digital visualizations of the ocean currents, nitrates, and plankton. Through experimental testing with climate scientists, the researchers found that this style of \"data physicalization\" provided a number of benefits, including an ability to quickly and accurately \"read\" data through a combination of vision and touch. Complementary digital visualizations were displayed using perspective-tracked, stereoscopic AR glasses so that the data could registered with the physical portions of the visualization and appear to \"float in the air\" above. This enabled the display of animated data, such as time-varying ocean with the static physical elements. The researchers invented a multi-touch sensing technique to detect interaction with this new style of hybrid digital+physical visualizations, making it possible to query data by touching the high-resolution physical data printouts and to display the results of the queries interactively in digital form. Climate scientists reported that this interface enabled deeper investigation into the 3D multi-variate data, revealing complexity and relationships not previous exposed.\n\n\nIn addition, the project contributed new advances to the literature on expanding the vocabulary for scientific visualization to assist in encoding and revealing the complexity and relationships within the data; holistic evaluation methods for data visualization, and design theory for multivariate data visualization; remote computer graphics rendering for virtual reality.\n\n\nBroader Impacts include: training Ph.D. students, undergraduate students, and early career scientist, several of whom claim identities recognized by NSF as underrepresented in computing; dissemination of results at venues for design research and earth science ensured that the results reached communities of interest outside of computing; educational opportunities and infrastructure including new curriculum enabling students to use the tools and design libraries developed by artists and scientists. Partnerships with multiple planetariums and other public venues enabled presentation of research results via infrastructure that can also be utilized by future projects. Project results, software, and curriculum were presented annually at: the U-Teach Summit and TACC EPIC program seminars, which provide computer science training High School teachers from rural and unserved populations; local K-12 school groups; and the CODE at TACC seminars which train dozens of, nationally represented, underserved High School students.\t\t\t\t\tLast Modified: 12/19/2023\n\n\t\t\t\t\tSubmitted by: FrancescaSamsel\n"
 }
}