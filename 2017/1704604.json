{
 "awd_id": "1704604",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Medium: Collaborative Research: Sculpting Visualizations: Toward a Practice and Theory of 3D Scientific Visualizations Using Physical Objects and Augmented Reality",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 675000.0,
 "awd_amount": 707000.0,
 "awd_min_amd_letter_date": "2017-06-12",
 "awd_max_amd_letter_date": "2020-08-12",
 "awd_abstract_narration": "Advances in 3D printing, augmented reality (AR), and virtual reality (VR), are creating new possibilities for computing tools that integrate with our physical environment and take advantage of our physical abilities.  This proposal will study how these technologies can support 3D data visualization, an increasingly important and common scientific activity.  The team, which includes computer scientists, artists, neuroscientists, geologists, and oceanologists, will first use 3D printing to develop physical representations of 3D data (\"physical data forms\") that match the needs of specific analysis domains and tasks, and through this develop principles for doing 3D design for visualizations in general.  They will then design hybrid spaces that use AR visual representations along with physical data forms, looking at ways to leverage the strengths of each and developing ways to interact with the data through both the virtual and physical forms.  Finally, they will create tools that leverage these design principles and interaction techniques to allow scientists to create new physical data forms and hybrid visualizations to address outstanding data analysis challenges in brain imaging, geology, and, ultimately, many scientific fields.  The work will support interdisciplinary courses at the intersection of art, science, computing, and data visualization at the PIs' institutions; students will also be trained in research methods and work with the research team to develop public science museum exhibits that raise awareness of both the technology and the science involved. \r\n\r\nTo leverage the possibilities of rapid, creative, artistic iteration and exploration of physical form, the team will develop interfaces and algorithms for capturing and extracting properties of physical forms, along with tools for exploring mappings between these properties and 3D data, a design theory and taxonomy, and a catalog for using physical inputs in visualization processes.  These physical elements will be augmented with colocated digital head-tracked stereoscopic displays that directly incorporate the printed objects into the AR experience, along with touch-based interaction techniques such as touch-sensitive input surfaces or the direct inclusion of physical widgets in the printed objects.  These visualizations will be evaluated through user studies based on existing methodologies for comparing 3D vector field visualization methods.  The team will then develop exploratory visualization tools, using streamlined versions of the catalog and visualizations developed earlier to help manage the complexity of creating new visualizations while teaching visual design processes to scientists through the use of the tools, recasting the scientific task of data exploration as a creative process of visualization design to support learning, engagement, and effective analysis.  These tools will be iteratively developed by teams of art and computer science students in conjunction with domain scientists and used to facilitate data exploration and discovery, as well as to bring science more directly into the public sphere through interactive experiences, such as at science museums.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Keefe",
   "pi_mid_init": "F",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel F Keefe",
   "pi_email_addr": "keefe@cs.umn.edu",
   "nsf_id": "000513431",
   "pi_start_date": "2017-06-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "University of Minnesota-Twin Cities",
  "perf_str_addr": "200 Union Street SE",
  "perf_city_name": "Minneapolis",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "554552070",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MN05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 501957.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 189043.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 0.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-a02b85e9-7fff-d611-275c-1eab8ba1b077\"> </span></p>\n<p dir=\"ltr\"><span>The intellectual merit of this project comes from exploring the potential of the emerging technologies of Augmented Reality (AR) and digital fabrication (e.g., 3D printing) to combine in a new, more powerful style of 3D visualization to assist scientists in understanding their latest datasets.&nbsp; The research team included both computer scientists and visual artists, enabling a unique methodology.&nbsp;&nbsp;</span></p>\n<p dir=\"ltr\"><span>In the first phase of the project, visual artists and designers created a sophisticated visual language of colors, textures, and 3D shapes that are expertly crafted to convey scientific data.&nbsp; Most computerized 3D data visualizations use a limited visual language of simple shapes (e.g., colored 3D lines, spheres, and cubes).&nbsp; This works well for visualizing small datasets, but there are only a few ways these basic computer graphics shapes may be combined to encode data, so the approach fails when climate scientists or medical researchers need to analyze more complex datasets with many variables.&nbsp; In contrast, artists working without computers (e.g., using traditional physical media such as paint, ink, clay) can create much richer visual languages, for example, sets of dozens of lines that simply through their visual qualities, convey information such as \"powerful\" vs. \"weak\", \"natural\" vs. \"human-made\", or \"plant\" vs. \"animal\".&nbsp; Further, they can accomplish this with a variety of different media and with specific goals in mind (e.g., show a direction, convey expansion or contraction).&nbsp; The project makes it possible for the first time to leverage the full range of artistic skill with traditional media to produce much richer visual languages for depicting scientific data. After digitizing a library of hundreds of visual artifacts carefully designed by artists, computer scientists created novel software to resize, recolor, and place them in virtual spaces in response to data.&nbsp; The software includes a visual interface that makes designing new visualizations fast, and it generates powerful 3D visualizations that can depict many data variables in a single picture.&nbsp; With the software, artists worked together with several teams of scientists who struggle to anlyze their data, for example, one group runs supercomputer simulations to study the biogeochemistry of the Gulf of Mexico.&nbsp; The new visualizations created for these scientists display the terrain and bathymetry, ocean currents and velocities, concentrations of three varieties of nitrates, and concentrations of two varieties of plankton -- all in a single 3D visualization. This is something that could never be accomplished with a more limited visual vocabulary, and the climate scientists describe the new data visualization capability as \"transformative\" for their work.</span></p>\n<p dir=\"ltr\"><span>In the second phase of the project, the digital data visualizations were combined with physical data visualizations produced with digital fabrication technologies, such as 3D printing and laser cutting.&nbsp; For example, a 3D printed model of the terrain and bathymetry data was combined with digital visualizations of the ocean currents, nitrates, and plankton.&nbsp; Through experimental testing with climate scientists, the researchers found that this style of \"data physicalization\" provided a number of benefits, including an ability to quickly and accurately \"read\" data through a combination of vision and touch.&nbsp; Complementary digital visualizations were displayed using perspective-tracked, stereoscopic AR glasses so that the data could registered with the physical portions of the visualization and appear to \"float in the air\" above.&nbsp; This provided the benefit of being able to display animated data, such as ocean currents that evolve over time, together with the static physical elements.&nbsp; The researchers invented a multi-touch sensing technique to detect interaction with this new style of hybrid digital+physical visualizations, making it possible to query data by touching the high-resolution physical data printouts and to display the results of the queries interactively in digital form.</span></p>\n<p dir=\"ltr\"><span>In addition to these major results, the project contributed new advances to the literature on remote computer graphics rendering for virtual reality, holistic evaluation methods for data visualization, and design theory for multivariate data visualization.</span></p>\n<p dir=\"ltr\"><span>The broader impacts of the project come in part from training 7 Ph.D. students, 16 undergraduate students, and 1 early career scientist; 14 of these trainees claim identities recognized by NSF as underrepresented in computing.&nbsp; Dissemination of results at venues for design research and earth science ensured that the results reached communities of interest outside of computing.&nbsp; Educational opportunities and infrastructure were created through new curriculum that makes it possible for students to use the tools and design libraries developed by artists and scientists.&nbsp; Partnerships with multiple planetariums make the research results accessible to the public through infrastructure that can also be utilized by future projects.&nbsp; Project results, software, and curriculum were also presented each year to local K-12 school groups and teachers.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/04/2023<br>\n\t\t\t\t\tModified by: Daniel&nbsp;F&nbsp;Keefe</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381994195_vis-design-ui--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381994195_vis-design-ui--rgov-800width.jpg\" title=\"Water masses and currents underneath the Ronne Ice Shelf rendered in Artifact-Based Rendering on the left and the Artifact-Based Rendering UI, designed for artists and designers on the right.\"><img src=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381994195_vis-design-ui--rgov-66x44.jpg\" alt=\"Water masses and currents underneath the Ronne Ice Shelf rendered in Artifact-Based Rendering on the left and the Artifact-Based Rendering UI, designed for artists and designers on the right.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Sophisticated data visualizations, for example, of water masses and currents underneath the Antarctic Ice Shelf (left), are designed using a novel \"puzzle piece\" visual programming language that is accessible to both scientists and artists (right).</div>\n<div class=\"imageCredit\">Sculpting Vis Collaborative</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Daniel&nbsp;F&nbsp;Keefe</div>\n<div class=\"imageTitle\">Water masses and currents underneath the Ronne Ice Shelf rendered in Artifact-Based Rendering on the left and the Artifact-Based Rendering UI, designed for artists and designers on the right.</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381799096_hybrid-ar-displays--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381799096_hybrid-ar-displays--rgov-800width.jpg\" title=\"A touch sensitive topography model of the Antarctic bathymetry below the Filchner-Ronne Ice Shelf with AR rendered data above; diagram of the touch-driven querying system, demonstration of interacting with the AR system and touch interface.\"><img src=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381799096_hybrid-ar-displays--rgov-66x44.jpg\" alt=\"A touch sensitive topography model of the Antarctic bathymetry below the Filchner-Ronne Ice Shelf with AR rendered data above; diagram of the touch-driven querying system, demonstration of interacting with the AR system and touch interface.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">omplementing the use of clay, paint, and other physical inputs, computer-controlled digital fabrication techniques (e.g., 3D printing) mean that the visualizations produced can also include physical components.  When combined with Augmented Reality displays and novel touch sensing techniques, the re</div>\n<div class=\"imageCredit\">Sculpting Vis Collaborative</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Daniel&nbsp;F&nbsp;Keefe</div>\n<div class=\"imageTitle\">A touch sensitive topography model of the Antarctic bathymetry below the Filchner-Ronne Ice Shelf with AR rendered data above; diagram of the touch-driven querying system, demonstration of interacting with the AR system and touch interface.</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381908324_planetariums--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381908324_planetariums--rgov-800width.jpg\" title=\"Visualization rendering ocean currents, ocean water categories and ocean characteristics in the PEEC Planetarium, Los Alamos, NM; interactive Artifact-Based-Rendering Visualization of environmental data displayed the Bell Museum in Minneapolis, MN.\"><img src=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381908324_planetariums--rgov-66x44.jpg\" alt=\"Visualization rendering ocean currents, ocean water categories and ocean characteristics in the PEEC Planetarium, Los Alamos, NM; interactive Artifact-Based-Rendering Visualization of environmental data displayed the Bell Museum in Minneapolis, MN.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Partnerships with multiple science and natural history museums enable broad dissemination of the research, with new planetarium software that highlights the successful collaborations between artists, computer scientists, and climate scientists.</div>\n<div class=\"imageCredit\">Sculpting Vis Collaborative</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Daniel&nbsp;F&nbsp;Keefe</div>\n<div class=\"imageTitle\">Visualization rendering ocean currents, ocean water categories and ocean characteristics in the PEEC Planetarium, Los Alamos, NM; interactive Artifact-Based-Rendering Visualization of environmental data displayed the Bell Museum in Minneapolis, MN.</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381675407_expanded-visual-vocab--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381675407_expanded-visual-vocab--rgov-800width.jpg\" title=\"Artist-created encodings for scientific data - colormaps, textures and glyphs - applied to biogeochemistry in the Gulf of Mexico, showing eddies and nitrate levels.\"><img src=\"/por/images/Reports/POR/2022/1704604/1704604_10492326_1669381675407_expanded-visual-vocab--rgov-66x44.jpg\" alt=\"Artist-created encodings for scientific data - colormaps, textures and glyphs - applied to biogeochemistry in the Gulf of Mexico, showing eddies and nitrate levels.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Visualization by Sculpting makes it possible for artists to aid scientists develop more sophisticated visual languages to understand data.  Handcrafted data glyphs and textures are used to understand the biogeochemistry of the Gulf of Mexico.</div>\n<div class=\"imageCredit\">Sculpting Vis Collaborative</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Daniel&nbsp;F&nbsp;Keefe</div>\n<div class=\"imageTitle\">Artist-created encodings for scientific data - colormaps, textures and glyphs - applied to biogeochemistry in the Gulf of Mexico, showing eddies and nitrate levels.</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nThe intellectual merit of this project comes from exploring the potential of the emerging technologies of Augmented Reality (AR) and digital fabrication (e.g., 3D printing) to combine in a new, more powerful style of 3D visualization to assist scientists in understanding their latest datasets.  The research team included both computer scientists and visual artists, enabling a unique methodology.  \nIn the first phase of the project, visual artists and designers created a sophisticated visual language of colors, textures, and 3D shapes that are expertly crafted to convey scientific data.  Most computerized 3D data visualizations use a limited visual language of simple shapes (e.g., colored 3D lines, spheres, and cubes).  This works well for visualizing small datasets, but there are only a few ways these basic computer graphics shapes may be combined to encode data, so the approach fails when climate scientists or medical researchers need to analyze more complex datasets with many variables.  In contrast, artists working without computers (e.g., using traditional physical media such as paint, ink, clay) can create much richer visual languages, for example, sets of dozens of lines that simply through their visual qualities, convey information such as \"powerful\" vs. \"weak\", \"natural\" vs. \"human-made\", or \"plant\" vs. \"animal\".  Further, they can accomplish this with a variety of different media and with specific goals in mind (e.g., show a direction, convey expansion or contraction).  The project makes it possible for the first time to leverage the full range of artistic skill with traditional media to produce much richer visual languages for depicting scientific data. After digitizing a library of hundreds of visual artifacts carefully designed by artists, computer scientists created novel software to resize, recolor, and place them in virtual spaces in response to data.  The software includes a visual interface that makes designing new visualizations fast, and it generates powerful 3D visualizations that can depict many data variables in a single picture.  With the software, artists worked together with several teams of scientists who struggle to anlyze their data, for example, one group runs supercomputer simulations to study the biogeochemistry of the Gulf of Mexico.  The new visualizations created for these scientists display the terrain and bathymetry, ocean currents and velocities, concentrations of three varieties of nitrates, and concentrations of two varieties of plankton -- all in a single 3D visualization. This is something that could never be accomplished with a more limited visual vocabulary, and the climate scientists describe the new data visualization capability as \"transformative\" for their work.\nIn the second phase of the project, the digital data visualizations were combined with physical data visualizations produced with digital fabrication technologies, such as 3D printing and laser cutting.  For example, a 3D printed model of the terrain and bathymetry data was combined with digital visualizations of the ocean currents, nitrates, and plankton.  Through experimental testing with climate scientists, the researchers found that this style of \"data physicalization\" provided a number of benefits, including an ability to quickly and accurately \"read\" data through a combination of vision and touch.  Complementary digital visualizations were displayed using perspective-tracked, stereoscopic AR glasses so that the data could registered with the physical portions of the visualization and appear to \"float in the air\" above.  This provided the benefit of being able to display animated data, such as ocean currents that evolve over time, together with the static physical elements.  The researchers invented a multi-touch sensing technique to detect interaction with this new style of hybrid digital+physical visualizations, making it possible to query data by touching the high-resolution physical data printouts and to display the results of the queries interactively in digital form.\nIn addition to these major results, the project contributed new advances to the literature on remote computer graphics rendering for virtual reality, holistic evaluation methods for data visualization, and design theory for multivariate data visualization.\nThe broader impacts of the project come in part from training 7 Ph.D. students, 16 undergraduate students, and 1 early career scientist; 14 of these trainees claim identities recognized by NSF as underrepresented in computing.  Dissemination of results at venues for design research and earth science ensured that the results reached communities of interest outside of computing.  Educational opportunities and infrastructure were created through new curriculum that makes it possible for students to use the tools and design libraries developed by artists and scientists.  Partnerships with multiple planetariums make the research results accessible to the public through infrastructure that can also be utilized by future projects.  Project results, software, and curriculum were also presented each year to local K-12 school groups and teachers.\n\n \n\n\t\t\t\t\tLast Modified: 01/04/2023\n\n\t\t\t\t\tSubmitted by: Daniel F Keefe"
 }
}