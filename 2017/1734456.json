{
 "awd_id": "1734456",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: FND: Human-Robot Collaboration with Distributed and Embodied Intelligence",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Frederick Kronz",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 699540.0,
 "awd_amount": 731540.0,
 "awd_min_amd_letter_date": "2017-08-04",
 "awd_max_amd_letter_date": "2020-05-04",
 "awd_abstract_narration": "This award supports research on the issue of intelligence re-embodiment in robots. The fundamental question to be addressed is whether robots should be designed so that different synthetic intelligences can take over. A smart phone can be repurposed to serve different users by swapping chips. Should robots with much higher functionality be designed so that they operate in a suitably similar way? The goal of this project is to answer this question along with a number of related questions including the following. Should robots be designed so different intelligences can take over? Where does the locus of intelligence sit? How does the user understand where it is and who or what is in control? How does re-embodiment impact issues of privacy? To answer these questions, this research effort will adopt a mixed-methods approach including surveys, fieldwork, simulations, and on-site testing of a robot operating system module. The findings of this work are expected to have direct value to robot developers and other researchers. Other impacts include interdisciplinary training of PhD students, and creating research opportunities for undergraduates. Team members plan to use the results of this research to enrich courses on human-robot interactions, and in outreach activities to engage non-academic audiences.\r\n\r\nThis research project uses a variety of methods to study the issue of intelligence re-embodiment in robots. Team members will conduct online surveys to systematically assess factors related to re-embodiment. They will engage in fieldwork to investigate current practices of people working and living in environments with several intelligent systems. These findings will in turn be used to inform a user enactment study that will create simulations of real-world contexts and test participants' reactions to different robot behaviors. Team members will also extract and evaluate a set of generalized interaction principles using a second online study. In addition, they will develop a robot operating system (ROS) module to enable re-embodiment of robots by a cloud-based intelligence; the module will be used to assess reactions of business owners and other stakeholders interacting with these systems. The results of these research components will advance knowledge on how people understand re-embodiment. They will serve to map out a set of design recommendations, design features, and the corresponding interaction patterns that do not yet exist around robot behavior in different contexts. They will also lead to the production of software components that support re-embodiment by remote intelligences. More generally, they will help achieve a vision of fully collaborative, ubiquitous, interconnected co-robot systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Zimmerman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "John Zimmerman",
   "pi_email_addr": "johnz@cs.cmu.edu",
   "nsf_id": "000435917",
   "pi_start_date": "2017-08-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Aaron",
   "pi_last_name": "Steinfeld",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aaron Steinfeld",
   "pi_email_addr": "steinfeld@cmu.edu",
   "nsf_id": "000158622",
   "pi_start_date": "2017-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie Mellon University",
  "perf_str_addr": "5000 Forbes Avenue",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760300",
   "pgm_ele_name": "STS-Sci, Tech & Society"
  },
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 699540.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Acceptance and adoption of robots remains one of the biggest barriers to this technology transitioning out of research labs and into work and homes. For many years, research on social robots (robots that socially interact with people) has worked towards the goal of making robots behave like people. A robot that behaves similarly to people will be easy to understand and make use of. One challenge with this goal is the concern people will overestimate a robot?s capabilities and intelligence, leading to disappointment and rejection of robots.</p>\n<p>This project worked to reframe the untested belief that robots should behave like people. It investigated robot capabilities that would be impossible for people. The project specifically examined the idea of re-embodiment, the ability of a robot to move its social presence from one robot body to another robot body. For example, imagine a person is at home talking to their Alexa. If they get into their car, should Alexa jump into their car and drive the person to work? Would people feel comforted by having the same robot do many things in many different bodies, or would it be better to have different robots for different tasks? The research asks when are their too many different robots and when are their too few?</p>\n<p>One of the first studies showed people really liked the experience of robot re-embodiment. However, it also raised concerns that hinted at barriers to this behavior. People liked a robot that could re-embody within a single service. For example, in the context of the Department of Motor Vehicles, people liked that the robot that checked them in could jump to the next counter, entering a body with a camera in order to take their photo or entering into a body that could give an eye exam. Re-embodiment made people feel taken care of. Interestingly, when the context changed to healthcare, people raised concerns. They did not think that a robot who checked them in for an appointment would be smart enough to run an MRI scan. They seemed to apply a human bias about the intelligence of people who have certain jobs to their expectation of robots.</p>\n<p>A different study probed on how a re-embodying robot might engage with multiple people where the robot needed to access and share private information. This deals with common situations, like what you might say to a friend if someone else you don?t know is also in the social circle. This study revealed a desire for a ?life agent,? a singluar robot presence that could embody different robots in different service contexts (e.g, hotel, doctor?s office, retail store). People really liked the idea of having their own agent that always worked in their own best interest. It raised the issue of people owning the social entity that re-embodied into robots owned by many different companies.</p>\n<p>Another study explored the complexity of having a life agent within an interpersonal space, like a home. Should a family have individual agents for each member, individual agents plus an agent for the whole family, or just one agent everyone shared? Ownership and control of space played a large role in how people reacted to agents and their actions. People felt it was fine for an agent to work in the best interest of an individual family member in a space like a bedroom. For example, a teen could ask an agent in their bedroom to tell them if their sister ?borrowed? their clothes. However, in the more public spaces any agent needed to respect the privacy of other family members. It would not be alright for the Mom?s agent in the kitchen to report that the Dad was cheating on his diet.</p>\n<p>Later studies pushed on the issue of ownership and the growing reality that most agents and social robots would likely be services, something that cannot be owned. People felt ownership of products like smartphones, which they used to access services. However, they did not develop an attachment to the phone, and they could and would easily replace it with a new phone. This makes smartphones different from other material possessions. For example, parents often keep and cherish specific books they read to their children. They would not want a new copy, because their attachment is to the specific possession they held when reading to their children, not to the book?s content. People did feel stronger attachment and a sense of ownership with services that support personalization and user effort. For example, many felt ownership of their Spotify playlists, which they felt represented their self. The implication from these later studies is that robots might gain more acceptance if they were easier to own, and if people could personalize them and maintain the personalization, even if they updated their robot.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2022<br>\n\t\t\t\t\tModified by: John&nbsp;Zimmerman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAcceptance and adoption of robots remains one of the biggest barriers to this technology transitioning out of research labs and into work and homes. For many years, research on social robots (robots that socially interact with people) has worked towards the goal of making robots behave like people. A robot that behaves similarly to people will be easy to understand and make use of. One challenge with this goal is the concern people will overestimate a robot?s capabilities and intelligence, leading to disappointment and rejection of robots.\n\nThis project worked to reframe the untested belief that robots should behave like people. It investigated robot capabilities that would be impossible for people. The project specifically examined the idea of re-embodiment, the ability of a robot to move its social presence from one robot body to another robot body. For example, imagine a person is at home talking to their Alexa. If they get into their car, should Alexa jump into their car and drive the person to work? Would people feel comforted by having the same robot do many things in many different bodies, or would it be better to have different robots for different tasks? The research asks when are their too many different robots and when are their too few?\n\nOne of the first studies showed people really liked the experience of robot re-embodiment. However, it also raised concerns that hinted at barriers to this behavior. People liked a robot that could re-embody within a single service. For example, in the context of the Department of Motor Vehicles, people liked that the robot that checked them in could jump to the next counter, entering a body with a camera in order to take their photo or entering into a body that could give an eye exam. Re-embodiment made people feel taken care of. Interestingly, when the context changed to healthcare, people raised concerns. They did not think that a robot who checked them in for an appointment would be smart enough to run an MRI scan. They seemed to apply a human bias about the intelligence of people who have certain jobs to their expectation of robots.\n\nA different study probed on how a re-embodying robot might engage with multiple people where the robot needed to access and share private information. This deals with common situations, like what you might say to a friend if someone else you don?t know is also in the social circle. This study revealed a desire for a ?life agent,? a singluar robot presence that could embody different robots in different service contexts (e.g, hotel, doctor?s office, retail store). People really liked the idea of having their own agent that always worked in their own best interest. It raised the issue of people owning the social entity that re-embodied into robots owned by many different companies.\n\nAnother study explored the complexity of having a life agent within an interpersonal space, like a home. Should a family have individual agents for each member, individual agents plus an agent for the whole family, or just one agent everyone shared? Ownership and control of space played a large role in how people reacted to agents and their actions. People felt it was fine for an agent to work in the best interest of an individual family member in a space like a bedroom. For example, a teen could ask an agent in their bedroom to tell them if their sister ?borrowed? their clothes. However, in the more public spaces any agent needed to respect the privacy of other family members. It would not be alright for the Mom?s agent in the kitchen to report that the Dad was cheating on his diet.\n\nLater studies pushed on the issue of ownership and the growing reality that most agents and social robots would likely be services, something that cannot be owned. People felt ownership of products like smartphones, which they used to access services. However, they did not develop an attachment to the phone, and they could and would easily replace it with a new phone. This makes smartphones different from other material possessions. For example, parents often keep and cherish specific books they read to their children. They would not want a new copy, because their attachment is to the specific possession they held when reading to their children, not to the book?s content. People did feel stronger attachment and a sense of ownership with services that support personalization and user effort. For example, many felt ownership of their Spotify playlists, which they felt represented their self. The implication from these later studies is that robots might gain more acceptance if they were easier to own, and if people could personalize them and maintain the personalization, even if they updated their robot.\n\n \n\n\t\t\t\t\tLast Modified: 11/30/2022\n\n\t\t\t\t\tSubmitted by: John Zimmerman"
 }
}