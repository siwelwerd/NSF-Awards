{
 "awd_id": "1718481",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Efficient Many-core Execution Models for Cognitive Computing",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2017-08-09",
 "awd_max_amd_letter_date": "2017-08-09",
 "awd_abstract_narration": "Society is increasingly dependent on digital machines due to miniaturization and seamless integration of mobile, cloud and network computing. This project's objective is to develop an understanding of the computational algorithms, and devise novel architectural methods that improve the efficiency of the devices and platforms that will execute cognitive computing problems. Achieving good performance and scalability for concurrent hardware has been widely acknowledged to be a hard and important problem. This project singles out communication as a grand challenge and proposes novel methods for systems ranging from single chips with many \"cores\" or processors, through tightly integrated and increasingly heterogeneous futuristic many-core machines.  The proposed research agenda provides for significant broader impacts related to (1) curriculum development and student training through industry collaborations and integration of cognitive computing in computer architecture curriculum, and (2) outreach through established Research Experiences for Undergraduates (REU) sites and supplement programs.\r\n\r\nA set of auxiliary communication models are proposed to give the programmer new mechanisms based on hardware-supported explicit messaging to exploit fine-grained parallelism in the algorithms that represent cognitive computing problems. The resulting architecture and software concurrency choices are expected to expose many problem-algorithm-input-machine configurations, and solving for a near-optimal configuration in real-time is a hard problem. A novel situationally adaptive execution model is proposed that analyzes and captures this massive search space to pick the right choices in the spatiotemporally changing runtime settings.  The incorporation of auxiliary communication models in futuristic multicore and tightly-coupled many-core processors is timely as it will enable performance scaling trends to continue at ultra-energy efficiency: enterprises and US mission agencies will be able to deploy multicore technology in real-time embedded systems, such as self-driving cars. As a broader impact, better solutions for emerging cognitive computing problems will help improve our cyber infrastructure, healthcare, and manufacturing, all with significant benefits to the US economy and society.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Omer",
   "pi_last_name": "Khan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Omer Khan",
   "pi_email_addr": "khan@uconn.edu",
   "nsf_id": "000595468",
   "pi_start_date": "2017-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Connecticut",
  "inst_street_address": "438 WHITNEY RD EXTENSION UNIT 1133",
  "inst_street_address_2": "",
  "inst_city_name": "STORRS",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "8604863622",
  "inst_zip_code": "062699018",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CT02",
  "org_lgl_bus_name": "UNIVERSITY OF CONNECTICUT",
  "org_prnt_uei_num": "",
  "org_uei_num": "WNTPS995QBM7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Connecticut",
  "perf_str_addr": "371 Fairfield Way, Unit 4157",
  "perf_city_name": "Storrs",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "062691133",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CT02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main goal of this project was to explore future parallel single-chip machine architectures for executing the cognitive computing problems, such as machine learning, graph and data analytics, and database workloads. The project embraced efficient and novel concurrency controls both at the software and hardware level to address the communication bottleneck. The project developed novel software concurrent implementations of the challenge cognitive problems. This project explored both unordered and ordered parallelism in structured as well as unstructured application domains. The main goal was to create a library of cognitive computing algorithms that efficiently map in a situational setting to a heterogeneous set of parallel single-chip machines, such as multicores, GPUs and accelerators. We developed a novel heterogeneous multi-accelerator architecture that is composed of today's and futuristic concurrent machines that expose architectural choices for situational adaptation to the problem being executed. For existing machines, such as multicores and GPUs, this was a hardware auto-tuning effort that characterized the mapping of the right problem at the right time to the right machine with the right architectural configurations. The project also aimed to explore novel architectural mechanisms that can be exposed to the system for hardware concurrency control at realtime. A key mechanism this project explored was the addition of explicit messages between cores on a single chip at the hardware level. The fast in-hardware messages allowed the system to build novel communication models that accelerated thread synchronization and task scheduling/communication beyond traditional mechanisms. One such model this project explored was the moving computation to data (MC2D) model that enabled situational control over exploiting data locality and accelerate communication between hardware threads. We also explored novel mechanisms to incorporate speculative out-of-order execution of tasks under the MC2D model using the hardware messaging capabilities. All these architectural choices were situational and thus exposed as programmable for hardware auto-tuning. We envisioned a library and an API with novel programming primitives that exposed fine-grain hardware concurrency to the software. The design space to explore for the right algorithmic and architectural setting was massive, which was further exacerbated by the real-time and spatiotemporal nature of the problems. The objective was to pick the right software and hardware choices that meet the goal of ultra-efficient computations. We built a concurrency management framework focused on addressing the communication bottleneck. The framework was built with programmer specific constructs, as well as a runtime profiler. The profiler captured the concurrency variations at both software and architecture levels. It was implemented as an intelligent utility that captures and adopts the concurrency variations at runtime, using heuristic and machine learning techniques.<br /><br />All tools including the modified simulator, software, and the benchmarks are released publicly to allow researchers to explore variant architectures and applications. The simulator was also utilized to develop a laboratory kit and modernize the computer architecture and multicore computing curriculum at UConn. We have supported the NSF sponsored REU programs at UConn, and involved undergraduates, specially women and underrepresented minorities, in our research program. Finally, the outcomes of this project have been regularly shared with industry partners through the Semiconductor Research Corporation (SRC) liaisons from Qualcomm, Arm, AMD, NXP, and Intel. The project resulted in two PhD and one MS graduate, while one PhD student is expected to graduate in Summer 2023. The research outcomes have been published in seventeen conference and journal papers.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/24/2023<br>\n\t\t\t\t\tModified by: Omer&nbsp;Khan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe main goal of this project was to explore future parallel single-chip machine architectures for executing the cognitive computing problems, such as machine learning, graph and data analytics, and database workloads. The project embraced efficient and novel concurrency controls both at the software and hardware level to address the communication bottleneck. The project developed novel software concurrent implementations of the challenge cognitive problems. This project explored both unordered and ordered parallelism in structured as well as unstructured application domains. The main goal was to create a library of cognitive computing algorithms that efficiently map in a situational setting to a heterogeneous set of parallel single-chip machines, such as multicores, GPUs and accelerators. We developed a novel heterogeneous multi-accelerator architecture that is composed of today's and futuristic concurrent machines that expose architectural choices for situational adaptation to the problem being executed. For existing machines, such as multicores and GPUs, this was a hardware auto-tuning effort that characterized the mapping of the right problem at the right time to the right machine with the right architectural configurations. The project also aimed to explore novel architectural mechanisms that can be exposed to the system for hardware concurrency control at realtime. A key mechanism this project explored was the addition of explicit messages between cores on a single chip at the hardware level. The fast in-hardware messages allowed the system to build novel communication models that accelerated thread synchronization and task scheduling/communication beyond traditional mechanisms. One such model this project explored was the moving computation to data (MC2D) model that enabled situational control over exploiting data locality and accelerate communication between hardware threads. We also explored novel mechanisms to incorporate speculative out-of-order execution of tasks under the MC2D model using the hardware messaging capabilities. All these architectural choices were situational and thus exposed as programmable for hardware auto-tuning. We envisioned a library and an API with novel programming primitives that exposed fine-grain hardware concurrency to the software. The design space to explore for the right algorithmic and architectural setting was massive, which was further exacerbated by the real-time and spatiotemporal nature of the problems. The objective was to pick the right software and hardware choices that meet the goal of ultra-efficient computations. We built a concurrency management framework focused on addressing the communication bottleneck. The framework was built with programmer specific constructs, as well as a runtime profiler. The profiler captured the concurrency variations at both software and architecture levels. It was implemented as an intelligent utility that captures and adopts the concurrency variations at runtime, using heuristic and machine learning techniques.\n\nAll tools including the modified simulator, software, and the benchmarks are released publicly to allow researchers to explore variant architectures and applications. The simulator was also utilized to develop a laboratory kit and modernize the computer architecture and multicore computing curriculum at UConn. We have supported the NSF sponsored REU programs at UConn, and involved undergraduates, specially women and underrepresented minorities, in our research program. Finally, the outcomes of this project have been regularly shared with industry partners through the Semiconductor Research Corporation (SRC) liaisons from Qualcomm, Arm, AMD, NXP, and Intel. The project resulted in two PhD and one MS graduate, while one PhD student is expected to graduate in Summer 2023. The research outcomes have been published in seventeen conference and journal papers.\n\n\t\t\t\t\tLast Modified: 01/24/2023\n\n\t\t\t\t\tSubmitted by: Omer Khan"
 }
}