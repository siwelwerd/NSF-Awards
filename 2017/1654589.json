{
 "awd_id": "1654589",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER:  Nonparametric function estimation: shape constraints, adaptation, inference and beyond",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2017-03-13",
 "awd_max_amd_letter_date": "2021-07-06",
 "awd_abstract_narration": "Nonparametric statistics is an area of statistics and machine learning that allows one to model and analyze datasets without making strong prior assumptions about the data. Data problems where the techniques of nonparametric statistics are useful come from a wide variety of applied areas including biology, medicine, astronomy, engineering, economics and operations research. In modern complex and large datasets, these methods are especially crucial as they enable the detection of important trends and patterns in the data that may be missed by traditional parametric statistical techniques. However there exist many unresolved issues concerning the theory, methodology and application of nonparametric methods in modern data problems. A systematic study of these issues will be undertaken in this project which will result in (a) an improved understanding (in terms of accuracy and uncertainty quantification) of many existing methods, and (b) novel methods and computational algorithms that will be useful to applied practitioners in the scientific areas mentioned above. Most of the proposed projects are collaborative and involve researchers from a diverse set of universities. The project also contains a well-developed plan of educational activities which will have a major impact on the education and training of undergraduate and graduate students at UC Berkeley in statistical research. In particular, many of the educational activities of the project are aimed towards undergraduate students, a group that is often given less importance at large research universities.\r\n\r\nConcretely, a wide range of nonparametric models will be studied, covering both regression and density estimation. In situations where empirically attractive estimators exist, an elaborate theoretical study is proposed focusing on their adaptive risk properties. In other situations, estimators and efficient computational algorithms are proposed together with an analysis of their accuracy. Important practical problems of inference and uncertainty quantification are also addressed. The specific regression problems that are investigated in this project include (a) multivariate convex regression, univariate trend filtering and additive shape constrained regression where adaptive risk properties of the natural estimators will be established, (b) multivariate trend filtering and quasi-convex regression where new estimators are provided along with efficient computational algorithms, and (c) global and pointwise inference in shape constrained estimation where uncertainty quantification will be addressed. In density estimation, the problems investigated include: (a) log-concave and mixture density estimation where maximum likelihood estimators will be studied, (b) distributionally robust optimization and nongaussian component analysis where novel methodology will be proposed based on shape-constrained density estimation, and (c) robust approaches to shape-constrained inference where new procedures will be developed.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Adityanand",
   "pi_last_name": "Guntuboyina",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Adityanand Guntuboyina",
   "pi_email_addr": "aditya@stat.berkeley.edu",
   "nsf_id": "000632304",
   "pi_start_date": "2017-03-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "423 Evans Hall",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947203860",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  },
  {
   "pgm_ele_code": "804800",
   "pgm_ele_name": "Division Co-Funding: CAREER"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 74717.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 88456.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 91166.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 78966.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 66695.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Regression involves determining the relationship between a variable of interest (the response variable) and a set of related variables (covariates) based on a finite amount of data. Traditional regression methods often assume a specific functional form, such as linearity, which can limit their applicability. In this project, we explored nonparametric regression methods, which make more flexible and broadly applicable assumptions.</span></p>\n<p><span>One key assumption we studied was convexity. Convex regression assumes that the relationship between the response and covariates is convex, a weaker assumption than linearity. We analyzed the fundamental limits of accuracy achievable with finite data sets and examined the performance of the least squares estimator compared to other methods.</span></p>\n<p><span>Another novel assumption we investigated was entire monotonicity, which helps solve regression problems with multiple covariates without falling into the curse of dimensionality. We developed a new regression method based on this assumption, providing a robust alternative for complex data scenarios.</span></p>\n<p><span>For problems involving a single covariate, nonparametric regression often involves constraints on the L_1 norm of an appropriate derivative of the underlying function. Our theoretical analysis offered new insights into the performance of this estimator, enhancing its applicability and effectiveness.</span></p>\n<p><span>In the case of multiple covariates, we developed methodologies based on mixed derivative smoothness assumptions. These methods provide regularization-based alternatives to classical regression procedures such as CART and MARS, often resulting in better performance.</span></p>\n<p><span>We also explored max-affine restrictions, which assume that the regression function is the maximum of several linear functions. These functions are always convex, presenting an improvement over convex regression in higher dimensions. We provided rigorous methods for estimating these functions, enhancing the toolbox for handling complex regression problems.</span></p>\n<p><span>In addition to these regression problems, we tackled the challenge of testing qualitative hypotheses, such as convexity, on the regression function using available data. Our efforts included writing a survey paper that summarized research developments on regression with qualitative shape constraints, providing a comprehensive overview of this emerging field.</span></p>\n<p><span>Beyond regression, we addressed density estimation, which helps visualize data distributions by showing where data points are concentrated. Traditionally, density estimation relied on strong assumptions about the underlying density's form. Our focus was on nonparametric methods, which are more flexible and broadly applicable.</span></p>\n<p><span>We studied mixture models, a standard approach to density estimation, but one that requires selecting the number of components, which can be tricky. By using the nonparametric maximum likelihood estimator (NPMLE) with arbitrary mixing distributions, we overcame estimation issues due to nonconvexity. Our research highlighted the effectiveness of this methodology, resulting in multiple publications.</span></p>\n<p><span>The NPMLE in mixture models is naturally connected to empirical Bayes estimation, which improves estimation by combining data-driven prior estimation with Bayesian inference. Our papers demonstrated the effectiveness of combining empirical Bayes methodology with the NPMLE in mixture models, showcasing the power of this integrated approach.</span></p>\n<p><span>Lastly, we explored log-concave density estimation, a general nonparametric approach that has gained attention in statistics and related fields. We provided rigorous results on the theoretical performance of the log-concave maximum likelihood estimator, offering new insights and enhancing its theoretical foundation.</span></p>\n<p><span>In summary, this project advanced the understanding and application of nonparametric regression and density estimation methods, providing new theoretical insights and practical methodologies for dealing with complex data relationships. Our work offers valuable contributions to the field, improving the tools available for statisticians and researchers tackling challenging data analysis problems.</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 07/25/2024<br>\nModified by: Adityanand&nbsp;Guntuboyina</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nRegression involves determining the relationship between a variable of interest (the response variable) and a set of related variables (covariates) based on a finite amount of data. Traditional regression methods often assume a specific functional form, such as linearity, which can limit their applicability. In this project, we explored nonparametric regression methods, which make more flexible and broadly applicable assumptions.\n\n\nOne key assumption we studied was convexity. Convex regression assumes that the relationship between the response and covariates is convex, a weaker assumption than linearity. We analyzed the fundamental limits of accuracy achievable with finite data sets and examined the performance of the least squares estimator compared to other methods.\n\n\nAnother novel assumption we investigated was entire monotonicity, which helps solve regression problems with multiple covariates without falling into the curse of dimensionality. We developed a new regression method based on this assumption, providing a robust alternative for complex data scenarios.\n\n\nFor problems involving a single covariate, nonparametric regression often involves constraints on the L_1 norm of an appropriate derivative of the underlying function. Our theoretical analysis offered new insights into the performance of this estimator, enhancing its applicability and effectiveness.\n\n\nIn the case of multiple covariates, we developed methodologies based on mixed derivative smoothness assumptions. These methods provide regularization-based alternatives to classical regression procedures such as CART and MARS, often resulting in better performance.\n\n\nWe also explored max-affine restrictions, which assume that the regression function is the maximum of several linear functions. These functions are always convex, presenting an improvement over convex regression in higher dimensions. We provided rigorous methods for estimating these functions, enhancing the toolbox for handling complex regression problems.\n\n\nIn addition to these regression problems, we tackled the challenge of testing qualitative hypotheses, such as convexity, on the regression function using available data. Our efforts included writing a survey paper that summarized research developments on regression with qualitative shape constraints, providing a comprehensive overview of this emerging field.\n\n\nBeyond regression, we addressed density estimation, which helps visualize data distributions by showing where data points are concentrated. Traditionally, density estimation relied on strong assumptions about the underlying density's form. Our focus was on nonparametric methods, which are more flexible and broadly applicable.\n\n\nWe studied mixture models, a standard approach to density estimation, but one that requires selecting the number of components, which can be tricky. By using the nonparametric maximum likelihood estimator (NPMLE) with arbitrary mixing distributions, we overcame estimation issues due to nonconvexity. Our research highlighted the effectiveness of this methodology, resulting in multiple publications.\n\n\nThe NPMLE in mixture models is naturally connected to empirical Bayes estimation, which improves estimation by combining data-driven prior estimation with Bayesian inference. Our papers demonstrated the effectiveness of combining empirical Bayes methodology with the NPMLE in mixture models, showcasing the power of this integrated approach.\n\n\nLastly, we explored log-concave density estimation, a general nonparametric approach that has gained attention in statistics and related fields. We provided rigorous results on the theoretical performance of the log-concave maximum likelihood estimator, offering new insights and enhancing its theoretical foundation.\n\n\nIn summary, this project advanced the understanding and application of nonparametric regression and density estimation methods, providing new theoretical insights and practical methodologies for dealing with complex data relationships. Our work offers valuable contributions to the field, improving the tools available for statisticians and researchers tackling challenging data analysis problems.\n\n\n\t\t\t\t\tLast Modified: 07/25/2024\n\n\t\t\t\t\tSubmitted by: AdityanandGuntuboyina\n"
 }
}