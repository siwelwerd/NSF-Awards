{
 "awd_id": "1720646",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research:  Developing & Evaluating Assessments of Problem Solving",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Finbarr Sloane",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 1543241.0,
 "awd_amount": 1543241.0,
 "awd_min_amd_letter_date": "2017-08-17",
 "awd_max_amd_letter_date": "2020-06-26",
 "awd_abstract_narration": "Current state standards in mathematics are strategically focused on problem-solving skills in both content standards and practice standards. Content standards describe what math students are expected to learn at each grade level while practice standards characterize math behaviors that all students should experience (e.g., perseverance while problem solving and reasoning effectively about real-world situations). Problem solving is found at every grade level. If math teachers are expected to engage students in problem solving during everyday instruction, then students' problem-solving performance must be assessed in a manner that produces meaningful, valid, and reliable scores, without unduly burdening teachers or students. Unfortunately, most problem-solving assessments are generally framed by a set of mathematics expectations that differ from state standards. Thus, results from those assessments are disconnected from the mathematics content that students learn in the classroom. Previously, this research team has built problem-solving measures for grades 6-8, which address this gap in framing and generates meaningful, valid, and reliable scores, and do not have unintended negative consequences on students. The current project, titled Developing and Evaluating Assessments of Problem Solving (DEAP), builds upon the team's prior work by creating problem-solving measures for grades 3-5.  The elementary assessments will be connected to the middle-grades assessments and will be available for use by school districts, researchers, and other education professionals seeking to effectively measure children's problem solving. The Discovery Research K-12 program (DRK-12) seeks to significantly enhance the learning and teaching of science, technology, engineering and mathematics (STEM) by preK-12 students and teachers, through research and development of innovative resources, models and tools (RMTs). Projects in the DRK-12 program build on fundamental research in STEM education and prior research and development efforts that provide theoretical and empirical justification for proposed projects.\r\n\r\nBroadly speaking, the aims of DEAP are (a) to create three new mathematical problem-solving assessments and gather validity evidence for their use, (b) link the problem-solving measures (PSMs) with prior problem-solving measures (i.e., PSM6, PSM7, and PSM8), and (c) develop a meaningful reporting system for the PSMs. The research questions are: (a) What are the psychometric properties of the PSM3, PSM4, and PSM5 as they relate to students' problem-solving performance? (b) How does the evidence support vertical equating (linking) of the PSM3, PSM4, PSM5, PSM6, PSM7, and PSM8? (c) How do the PSM3, PSM4, and PSM5, and their related reporting systems impact teachers' instructional decision making when used formatively? Year 1 focuses on item and test development. The study will conduct cognitive interviews and administer tests with a small group of students to explore how items and tests function. Rasch (1-PL) measurement will be employed, similar to prior PSM development. Year 2 includes further pilot testing and gathering validity evidence through cognitive interviews and test administration. Year 3 has a final round of pilot testing and selection of linking items for vertical equating. Year 4 involves pilot testing the PSM series with linking items and developing a reporting system. DEAP's potential contributions to the field are three-fold. (1) Assessments will be available for use by the public. (2) A set of vertically equated problem-solving measures will allow users the opportunity to explore students' problem-solving performance as they matriculate across grade levels, which is currently not possible at the state or national level. (3) This project fills a need in the field as no set of measures uses vertical equating to assess elementary students' problem-solving performance in a rigorous fashion within the context of state testing.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jonathan",
   "pi_last_name": "Bostic",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Jonathan D Bostic",
   "pi_email_addr": "bosticj@bgsu.edu",
   "nsf_id": "000722184",
   "pi_start_date": "2017-08-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gabriel",
   "pi_last_name": "Matney",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gabriel Matney",
   "pi_email_addr": "gmatney@bgsu.edu",
   "nsf_id": "000659554",
   "pi_start_date": "2017-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Bowling Green State University",
  "inst_street_address": "1851 N RESEARCH DR",
  "inst_street_address_2": "",
  "inst_city_name": "BOWLING GREEN",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "4193722481",
  "inst_zip_code": "434034401",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "OH05",
  "org_lgl_bus_name": "BOWLING GREEN STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "SLT3EB6G3FA9"
 },
 "perf_inst": {
  "perf_inst_name": "Bowling Green State University",
  "perf_str_addr": "529 Education Building",
  "perf_city_name": "Bowling Green",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "434030240",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "OH05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "764500",
   "pgm_ele_name": "Discovery Research K-12"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0417",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001718DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0419",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001920DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0420",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002021DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 307081.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 381239.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 405543.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 449378.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><em>Developing and Evaluating Assessments of Problem-Solving</em>&nbsp;(<em>DEAP</em>) was an NSF funded DRK-12 collaborative research project undertaken and conducted by faculty and graduate students at Bowling Green State University, Drexel University, and MetriKs Am&eacute;rique. Over the course of six years, the DEAP research team worked to fill a gap in the field with the creation of problem-solving measures for elementary students (grades 3-5) that were explicitly aligned with the Common Core State Standards for Mathematics through a rigorous design-based research approach. Specifically, this project achieved three aims: (a) constructed and validated three mathematical problem-solving assessments (PSM3, PSM4, PSM5); (b) linked the PSM3-5 with prior problem-solving measures from grades 6-8 (PSM6, PSM7, PSM8) through vertical equating using Rasch measurement; and (c) developed a meaningful reporting system for PSM growth outcomes to be shared with teachers and districts. Those interested in using the PSMs should contact Dr. Jonathan Bostic (<a href=\"mailto:bosticj@bgsu.edu\">bosticj@bgsu.edu</a>) or Dr. Toni May (<a href=\"mailto:tas365@drexel.edu\">tas365@drexel.edu</a>).</p>\n<p>&nbsp;</p>\n<p>The project included creating and refining an item-writing and development process, field testing items and gathering validity evidence related to their use in educational and research contexts, and creating and revising score reports that assist K-12 teachers and administrators, as well as researchers, interpret and use results from the PSMs. Data were gathered from diverse students including students with specific learning disabilities as well as Multilingual Learners (aka English Language Learners or English Learners). The first result from this project are measures of mathematical problem solving that may be useful for educators and practitioners as well as researchers. The second result is a series of mathematical problem measures that are vertically equated. Students&rsquo; performance from grades 3-8 can be measured along a single scale. Thus, educators and researchers can easily measure growth from year-to-year. The third result is a score report that was comparable to other high-quality formative assessments used in the USA. Educators and researchers confirmed that they found the score report useful, easy to read, and promoted instructional decision making.</p>\n<p>&nbsp;</p>\n<p>In total, 53 conference presentations (2 international) and 32 peer-reviewed publications were produced by the research team of faculty and graduate students including: 1 book chapter, 16 journal articles, and 15 proceedings. Scholarly dissemination of research focused largely on validity evidence related to PSM3-5 (e.g., Bostic et al., 2018; Bostic et al., 2020; Bostic et al., 2021; Bostic et al., 2022; Sondergeld et al., 2019); scoring and reporting practices (e.g., Folger et al., 2021; Kruse et al., 2021; Matney et al., 2022; Sondergeld et al., 2020;); student sensemaking of word problems (e.g., Matney et al., 2021; Matney et al., 2022); and the general advancement of validation studies in STEM educational research (e.g., Sondergeld, 2020).</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/03/2023<br>\n\t\t\t\t\tModified by: Jonathan&nbsp;D&nbsp;Bostic</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDeveloping and Evaluating Assessments of Problem-Solving (DEAP) was an NSF funded DRK-12 collaborative research project undertaken and conducted by faculty and graduate students at Bowling Green State University, Drexel University, and MetriKs Am&eacute;rique. Over the course of six years, the DEAP research team worked to fill a gap in the field with the creation of problem-solving measures for elementary students (grades 3-5) that were explicitly aligned with the Common Core State Standards for Mathematics through a rigorous design-based research approach. Specifically, this project achieved three aims: (a) constructed and validated three mathematical problem-solving assessments (PSM3, PSM4, PSM5); (b) linked the PSM3-5 with prior problem-solving measures from grades 6-8 (PSM6, PSM7, PSM8) through vertical equating using Rasch measurement; and (c) developed a meaningful reporting system for PSM growth outcomes to be shared with teachers and districts. Those interested in using the PSMs should contact Dr. Jonathan Bostic (bosticj@bgsu.edu) or Dr. Toni May (tas365@drexel.edu).\n\n \n\nThe project included creating and refining an item-writing and development process, field testing items and gathering validity evidence related to their use in educational and research contexts, and creating and revising score reports that assist K-12 teachers and administrators, as well as researchers, interpret and use results from the PSMs. Data were gathered from diverse students including students with specific learning disabilities as well as Multilingual Learners (aka English Language Learners or English Learners). The first result from this project are measures of mathematical problem solving that may be useful for educators and practitioners as well as researchers. The second result is a series of mathematical problem measures that are vertically equated. Students\u2019 performance from grades 3-8 can be measured along a single scale. Thus, educators and researchers can easily measure growth from year-to-year. The third result is a score report that was comparable to other high-quality formative assessments used in the USA. Educators and researchers confirmed that they found the score report useful, easy to read, and promoted instructional decision making.\n\n \n\nIn total, 53 conference presentations (2 international) and 32 peer-reviewed publications were produced by the research team of faculty and graduate students including: 1 book chapter, 16 journal articles, and 15 proceedings. Scholarly dissemination of research focused largely on validity evidence related to PSM3-5 (e.g., Bostic et al., 2018; Bostic et al., 2020; Bostic et al., 2021; Bostic et al., 2022; Sondergeld et al., 2019); scoring and reporting practices (e.g., Folger et al., 2021; Kruse et al., 2021; Matney et al., 2022; Sondergeld et al., 2020;); student sensemaking of word problems (e.g., Matney et al., 2021; Matney et al., 2022); and the general advancement of validation studies in STEM educational research (e.g., Sondergeld, 2020).\n\n \n\n\t\t\t\t\tLast Modified: 08/03/2023\n\n\t\t\t\t\tSubmitted by: Jonathan D Bostic"
 }
}