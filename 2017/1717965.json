{
 "awd_id": "1717965",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Collaborative Research: Measuring and Promoting the Quality of Online News Discussions",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Bainbridge",
 "awd_eff_date": "2017-08-15",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 51258.0,
 "awd_amount": 61248.0,
 "awd_min_amd_letter_date": "2017-08-04",
 "awd_max_amd_letter_date": "2021-07-27",
 "awd_abstract_narration": "This project will amplify the efforts of people to bring out the best in other people in online conversations, and will make it easier for people to find high quality online conversations.  There are numerous concerns about the tone and content of online conversations on public affairs at the present time. At its best, everyday online debate can lead people to consider alternative perspectives and even change their minds. This happens in environments where people may disagree, but where they try to inform and convince each other rather than simply yell at each other.  The first goal of the research is to create automated classifiers to measure the quality of everyday online political talk. Classifiers will estimate the quality of online conversations about news articles in public venues such as Twitter, Facebook, Reddit, and the comments sections of news pages. A Conversation Finder tool (a website and a browser extension) will use the automated classifiers to recommend, in real time, venues where particular news articles are being discussed and where the quality scores are high. The second goal of the research is to create a Conversation Coach that helps the general public to improve the quality of conversation spaces they participate in, by helping them craft messages that directly contribute to quality and that indirectly inspire others. It will include a Message Assistant that extracts elements from conversations in order to help people craft messages and a Message Impact Assessor that predicts the likely impact of a draft message on the quality metrics for subsequent conversations.\r\n\r\nQuality of online conversations will be measured in terms of a variety of dimensions that communication scholars have articulated as desirable. Training data for the classifiers will be collected from conversation participants in addition to trained coders, and experiments will be conducted to determine the most effective sequence of requests to make of conversation participants in order to maximize motivation to contribute.  Creation of the Conversation Recommender will lead to several intellectual contributions, including: (1) developing computational assists that help human raters achieve high inter-rater reliability; (2) identifying methods to motivate conversation participants to act as raters; (3) architecting neural-network based classifiers that achieve high prediction accuracy when trained using the collected ratings as training data; (4) developing techniques to make the classifiers produce interpretable results (explanations). Creation of the Conversation Coach will lead to two intellectual contributions: (1) identifying parts of conversations that can be automatically extracted and that writers find relevant and useful when composing messages; (2) architecting a predictive model that accurately estimates the impact of messages on subsequent conversation quality.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Garrett",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Robert K Garrett",
   "pi_email_addr": "garrett.258@osu.edu",
   "nsf_id": "000595334",
   "pi_start_date": "2017-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio State University",
  "inst_street_address": "1960 KENNY RD",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBUS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "6146888735",
  "inst_zip_code": "432101016",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OH03",
  "org_lgl_bus_name": "OHIO STATE UNIVERSITY, THE",
  "org_prnt_uei_num": "MN4MDDMN8529",
  "org_uei_num": "DLWBSLWAJWR1"
 },
 "perf_inst": {
  "perf_inst_name": "Ohio State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "432101016",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OH03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 51258.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 9990.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-e8ab6de4-7fff-b89b-09b7-f4422c989927\"> </span></p>\n<p dir=\"ltr\"><span>This project was devoted to creating processes for assessing and improving the quality of online conversations.</span></p>\n<p>&nbsp;</p>\n<ol>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span><span>We developed and tested a technique for creating &ldquo;explanations&rdquo; for the outputs of automated neural net classifiers that assess where comments contain personal attacks. The explanation consists of highlighting a set of words in the message. </span><span>In contrast to prior attention mechanisms, it highlights all the phrases rather than a minimal phrase that would be sufficient to conclude the presence of a personal attack. It does so through an \"adversarial\" training mechanism. The word selector is optimized to enable the classifier to a good job using only the selected words *and* a bad job using only the unselected words</span>.&nbsp;</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span><span>We developed and applied automated techniques for quantifying at a large-scale the quality of online conversations</span>.</span></p>\n<ol>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span><span>We studied how political subreddits with different norms for civility are able to reproduce those norms despite turnover of members. We somewhat surprisingly found that selection effects are small as is learning after the first post. Instead, norms are sustained due to people who join a subreddit with distinctive civility norms (either much higher lower than other political subreddits) deviating from their own personal patterns in a way that matches the subreddit's pattern, even in their very first comments</span>.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>We quantified the prevalence of political discussion in non-political online communities (about half of all political comments on reddit occur in non-political subreddit) and found that political conversations were less toxic in non-political subreddits.</span></p>\n<p>&nbsp;</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>We quantified the prevalence of cross-partisan commenting on YouTube. Conservatives were much more likely to comment on left-leaning videos than liberals on right-leaning videos. Both groups had similar toxicity levels overall. Cross-partisan replies were more toxic than co-partisan replies on both left-leaning and right-leaning videos, with cross-partisan replies being especially toxic on the replier&rsquo;s home turf.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>We are developing a public dashboard that will quantify on an ongoing basis the prevalence of HOT comments (Hateful, Offensive, Toxic) in conversations about daily news on reddit, Twitter, and Youtube.</span></p>\n</li>\n</ol></li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span><span>We developed tools for improving the consistency of human labeling of content, an important step in training and evaluating automated classifiers</span>.</span></p>\n<ol>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>In a controlled experiment, we found that specific examples were more useful than detailed codebooks for training human raters.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>This prompted the development of a new approach for automatically selecting training examples, based on disagreements among raters.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>In a second experiment, we found that a prompt asking raters to provide free-from text reflections after training examples further improved their effectiveness.</span></p>\n</li>\n</ol></li>\n</ol>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/04/2022<br>\n\t\t\t\t\tModified by: R.&nbsp;K&nbsp;Garrett</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThis project was devoted to creating processes for assessing and improving the quality of online conversations.\n\n \n\n\nWe developed and tested a technique for creating \"explanations\" for the outputs of automated neural net classifiers that assess where comments contain personal attacks. The explanation consists of highlighting a set of words in the message. In contrast to prior attention mechanisms, it highlights all the phrases rather than a minimal phrase that would be sufficient to conclude the presence of a personal attack. It does so through an \"adversarial\" training mechanism. The word selector is optimized to enable the classifier to a good job using only the selected words *and* a bad job using only the unselected words. \n\n\nWe developed and applied automated techniques for quantifying at a large-scale the quality of online conversations.\n\n\nWe studied how political subreddits with different norms for civility are able to reproduce those norms despite turnover of members. We somewhat surprisingly found that selection effects are small as is learning after the first post. Instead, norms are sustained due to people who join a subreddit with distinctive civility norms (either much higher lower than other political subreddits) deviating from their own personal patterns in a way that matches the subreddit's pattern, even in their very first comments.\n\n\nWe quantified the prevalence of political discussion in non-political online communities (about half of all political comments on reddit occur in non-political subreddit) and found that political conversations were less toxic in non-political subreddits.\n\n \n\n\nWe quantified the prevalence of cross-partisan commenting on YouTube. Conservatives were much more likely to comment on left-leaning videos than liberals on right-leaning videos. Both groups had similar toxicity levels overall. Cross-partisan replies were more toxic than co-partisan replies on both left-leaning and right-leaning videos, with cross-partisan replies being especially toxic on the replier\u2019s home turf.\n\n\nWe are developing a public dashboard that will quantify on an ongoing basis the prevalence of HOT comments (Hateful, Offensive, Toxic) in conversations about daily news on reddit, Twitter, and Youtube.\n\n\n\nWe developed tools for improving the consistency of human labeling of content, an important step in training and evaluating automated classifiers.\n\n\nIn a controlled experiment, we found that specific examples were more useful than detailed codebooks for training human raters.\n\n\nThis prompted the development of a new approach for automatically selecting training examples, based on disagreements among raters.\n\n\nIn a second experiment, we found that a prompt asking raters to provide free-from text reflections after training examples further improved their effectiveness.\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 12/04/2022\n\n\t\t\t\t\tSubmitted by: R. K Garrett"
 }
}