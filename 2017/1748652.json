{
 "awd_id": "1748652",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Software-Hardware Co-Design Approaches for Multi-Level Memories",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Erik Brunvand",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2020-09-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2017-09-07",
 "awd_max_amd_letter_date": "2017-09-07",
 "awd_abstract_narration": "The effective solution of big data problems requires computers that have very large memory capacity and that are able to perform very many operations per second. Since providing the required amount of main memory with sufficient bandwidth to achieve the desired throughput is cost prohibitive, vendors have resorted to multi-level memory (MLM) architectures in which main memory comprises two or more levels, with each level having memory with different bandwidth and cost characteristics. The Intel Knights Landing is an example; it has two levels of main memory - 16Gigabytes of high-cost, high-throughput memory, and up to 384Gigabytes of relatively low-cost, low-throughput memory. The Knights Landing also has 72 compute cores capable of performing up to 6 teraflops of single precision or 3 teraflops of double precision operations. This project seeks to demonstrate the effectiveness of multicore MLM architectures in solving big data problems.\r\n\r\nThis project will develop efficient multicore MLM software for representative applications with different workflow characteristics: data parallel, hierarchical, and task parallel. The specific applications being considered are simulation of compressible multiphase turbulence, sparse matrix factorization, and image reconstruction from synthetic aperture radar data. The software will be evaluated on the Knights Landing as well as using MLM simulation software. Techniques for the development of such software and optimal MLM configurations based on workload characterization will be identified.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanjay",
   "pi_last_name": "Ranka",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sanjay Ranka",
   "pi_email_addr": "ranka@cise.ufl.edu",
   "nsf_id": "000381796",
   "pi_start_date": "2017-09-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sartaj",
   "pi_last_name": "Sahni",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Sartaj K Sahni",
   "pi_email_addr": "sahni@cise.ufl.edu",
   "nsf_id": "000126089",
   "pi_start_date": "2017-09-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "",
  "perf_city_name": "Gainesville",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326112002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Observed computer performance is often limited by memory speed. Since memory cost increases&nbsp;rapidly with memory speed, computers are built with multiple levels of memory that differ in capacity and speed. In a computer, the slowest memory has the largest capacity and the fastest has least capacity. Programs typically begin with all data in the slowest memory and data is moved selectively to faster memories as needed. While automated methods to accomplish this required data movement are quite successful on some applications, they do not result in good performance on many others. </span></p>\n<p><span>In this project, we researched a variety of applications and developed methods&nbsp;to orchestrate data movement among the available levels of computer memory to attain significant run time performance improvement over automated methods that have been incorporated into hardware and compilers. For example, using our memory orchestration methods, we were able to reduce the run time of a popular community detection algorithm by up to 75+ percent; a speedup of up to&nbsp; eight was obtained for the value iteration method that is used to solve reinforcement learning problems.</span></p>\n<p>&nbsp;</p>\n<p><span><span>The project trained two PhD students (one male and one female) in the art of developing efficient algorithms for multilevel memories. It is expected that the developed methods will be incorporated&nbsp;into existing courses and through this a larger number of future software engineers will be trained in the efficient orchestration of algorithms across the memory hierarchy.</span><br /></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/23/2021<br>\n\t\t\t\t\tModified by: Sanjay&nbsp;Ranka</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nObserved computer performance is often limited by memory speed. Since memory cost increases rapidly with memory speed, computers are built with multiple levels of memory that differ in capacity and speed. In a computer, the slowest memory has the largest capacity and the fastest has least capacity. Programs typically begin with all data in the slowest memory and data is moved selectively to faster memories as needed. While automated methods to accomplish this required data movement are quite successful on some applications, they do not result in good performance on many others. \n\nIn this project, we researched a variety of applications and developed methods to orchestrate data movement among the available levels of computer memory to attain significant run time performance improvement over automated methods that have been incorporated into hardware and compilers. For example, using our memory orchestration methods, we were able to reduce the run time of a popular community detection algorithm by up to 75+ percent; a speedup of up to  eight was obtained for the value iteration method that is used to solve reinforcement learning problems.\n\n \n\nThe project trained two PhD students (one male and one female) in the art of developing efficient algorithms for multilevel memories. It is expected that the developed methods will be incorporated into existing courses and through this a larger number of future software engineers will be trained in the efficient orchestration of algorithms across the memory hierarchy.\n\n\n\t\t\t\t\tLast Modified: 02/23/2021\n\n\t\t\t\t\tSubmitted by: Sanjay Ranka"
 }
}