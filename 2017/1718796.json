{
 "awd_id": "1718796",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF:Small:Collaborative Research:Distributed Fog Computing for Non-Convex Big-Data Analytics",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2017-06-28",
 "awd_max_amd_letter_date": "2017-06-28",
 "awd_abstract_narration": "In our data-deluge era, massive chunks of information, perpetually collected by pervasive sensors, are communicated and processed by distributed computational architectures. To address emergent big-data computational issues, this project embarks on an ambitious multidisciplinary research effort that aims at advancing the state-of-the-art in-network/distributed big-data processing via a general algorithmic framework for data analytics over massively distributed data sets. The proposed algorithmic framework enables fully distributed and parallel big-data analytics, for a variety of heterogeneous data sets over a wide range of computational architectures. The developed research directions are beneficial also to domains far beyond big-data analytics, such as signal processing, machine learning, next-generation wireless communications, smart-city and smart-grid networks. Research results are distributed through archival publications, courses, undergraduate research opportunities, tutorials and conference presentations.\r\n\r\nThe developed scheme relies on a novel convexification/decomposition technique which accommodates a rich class of non-convex, unstructured and stochastic optimization tasks with non-separable objective functions. Algorithms are designed for settings where data are distributed across a large number of multi-core computational nodes, within a network of arbitrary topology with (possibly) time-varying and even random links. This new class of algorithms addresses shortcomings of current (non-parallel and non-distributed) convexification techniques via (i) full control of the degree of parallelism and distribution of the computation/signaling among processors/network nodes, and (ii) by offering a plethora of convex approximants, regularization terms, step-size rules, and communication protocols. Designed for time-varying or even random network topologies, the advocated framework demonstrates also another desirable attribute for distributed computations: resiliency to (random) network failures.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Konstantinos",
   "pi_last_name": "Slavakis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Konstantinos Slavakis",
   "pi_email_addr": "kslavaki@buffalo.edu",
   "nsf_id": "000637068",
   "pi_start_date": "2017-06-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Buffalo",
  "inst_street_address": "520 LEE ENTRANCE STE 211",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "7166452634",
  "inst_zip_code": "142282577",
  "inst_country_name": "United States",
  "cong_dist_code": "26",
  "st_cong_dist_code": "NY26",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "GMZUKXFDJMA9",
  "org_uei_num": "LMCJKRFW5R81"
 },
 "perf_inst": {
  "perf_inst_name": "University at Buffalo",
  "perf_str_addr": "225 Davis Hall",
  "perf_city_name": "Buffalo",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "142602500",
  "perf_ctry_code": "US",
  "perf_cong_dist": "26",
  "perf_st_cong_dist": "NY26",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>With pervasive sensors continuously collecting massive amounts ofinformation as well as advances in computing, communication, and storage technologies, this is an era of data deluge. The sheer volume of the data to be processed, together with the growing complexity of the data models (possibly non-convex and nonlinear) and the increasingly distributed nature of the data sources present major challenges to the modern big-data analytics.</p>\n<p><br />Aiming at developing scalable as well as online/stochastic learning and processing algorithms to address the dynamic nature of the nowadays high-dimensional data, as well as to combat the often met in data noise and outliers, this project introduced a novel framework that can solve a very wide class of learning tasks which are underpinned by convex composite and affinely constrained optimization problems. The project has established also the extensions of this framework into the stochastic-approximation context with novel directions in non-linear learning tasks and with robustification twists which can also handle outlier-bearing data.</p>\n<p><br />Departing from standard data modeling techniques, a novel framework was also introduced to model data on smooth manifolds which are embedded in spaces of massive, or even infinite dimensionality. The resulting optimization tasks of this novel manifold-learning approach were solved by the non-convex techniques developed in the premises of this project. Moreover, the advocated manifold-learning techniques were applied to the important problem of reconstructing high-fidelity dynamic magnetic resonance imaging data, outperforming state-of-the-art techniques on synthetic and real data.</p>\n<p><br />The results of this project were disseminated via publications in highly-esteemed journals and conferences, while the medical-imaging sub-project has been instrumental in the training and graduation of a PhD student at the Department of Electrical Engineering at the University at Buffalo, the State University of New York.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/02/2020<br>\n\t\t\t\t\tModified by: Konstantinos&nbsp;Slavakis</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWith pervasive sensors continuously collecting massive amounts ofinformation as well as advances in computing, communication, and storage technologies, this is an era of data deluge. The sheer volume of the data to be processed, together with the growing complexity of the data models (possibly non-convex and nonlinear) and the increasingly distributed nature of the data sources present major challenges to the modern big-data analytics.\n\n\nAiming at developing scalable as well as online/stochastic learning and processing algorithms to address the dynamic nature of the nowadays high-dimensional data, as well as to combat the often met in data noise and outliers, this project introduced a novel framework that can solve a very wide class of learning tasks which are underpinned by convex composite and affinely constrained optimization problems. The project has established also the extensions of this framework into the stochastic-approximation context with novel directions in non-linear learning tasks and with robustification twists which can also handle outlier-bearing data.\n\n\nDeparting from standard data modeling techniques, a novel framework was also introduced to model data on smooth manifolds which are embedded in spaces of massive, or even infinite dimensionality. The resulting optimization tasks of this novel manifold-learning approach were solved by the non-convex techniques developed in the premises of this project. Moreover, the advocated manifold-learning techniques were applied to the important problem of reconstructing high-fidelity dynamic magnetic resonance imaging data, outperforming state-of-the-art techniques on synthetic and real data.\n\n\nThe results of this project were disseminated via publications in highly-esteemed journals and conferences, while the medical-imaging sub-project has been instrumental in the training and graduation of a PhD student at the Department of Electrical Engineering at the University at Buffalo, the State University of New York.\n\n\t\t\t\t\tLast Modified: 11/02/2020\n\n\t\t\t\t\tSubmitted by: Konstantinos Slavakis"
 }
}