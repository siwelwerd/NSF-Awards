{
 "awd_id": "1734190",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: INT: COLLAB: Integrated Modeling and Learning for Robust Grasping and Dexterous Manipulation with Adaptive Hands",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928074",
 "po_email": "jdonlon@nsf.gov",
 "po_sign_block_name": "James Donlon",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-02-28",
 "tot_intn_awd_amt": 632500.0,
 "awd_amount": 632500.0,
 "awd_min_amd_letter_date": "2017-07-27",
 "awd_max_amd_letter_date": "2017-07-27",
 "awd_abstract_narration": "Robots need to effectively interact with a large variety of objects\r\nthat appear in warehouses and factories as well as homes and offices.\r\nThis requires robust grasping and dexterous manipulation of everyday\r\nobjects through low cost robots and low complexity solutions.\r\nTraditionally, robots use rigid hands and analytical models for such\r\ntasks, which often fail in the presence of even small errors. New\r\ncompliant hands promise improved performance, while minimizing\r\ncomplexity, and increased robustness. Nevertheless, they are\r\ninherently difficult to sense and model. This project combines ideas\r\nfrom different robotics sub-fields to address this limitation. It\r\nutilizes progress in machine learning and builds on a strong tradition\r\nin robot modeling. The objective is to provide adaptive, compliant\r\nrobots that are better in grasping objects in the presence of multiple\r\nunknown contact points and sliding or rolling objects in-hand. The\r\nbroader impact will be strengthened by the open release of new or\r\nmodified robot hand designs, improved control algorithms and software,\r\nas well as corresponding data sets. Furthermore, academic\r\ndissemination will be accompanied by educational outreach to\r\nundergraduate and high school students.\r\n\r\nTowards the above objective, the first step will be the definition of\r\nnew hybrid models appropriate for adaptive, compliant hands.  This\r\nwill happen by improving analytical solutions and extending them to\r\nallow adaptation based on data via novel, time-efficient learning\r\nmethods. The objective is to capture model uncertainty inherent in\r\nreal-world interactions; a process that suffers from data scarcity.\r\nIn order to reduce the amount of data required for learning, different\r\nmodels will be tailored to specific tasks through an automated\r\ndiscovery of these tasks and of underlying motion primitives for each\r\none of them. This task identification process will operate iteratively\r\nwith learning and utilize improved models to discover new tasks. It\r\ncan also provide feedback for improved hand design. Once these\r\nlearning-based and task-focused models are available, they will be\r\nused to learn and synthesize controllers for grasping and in-hand\r\nmanipulation. To learn controllers, this work will consider a\r\nmodel-based, reinforcement learning approach, which will be evaluated\r\nagainst alternatives. For controller synthesis, existing tools for\r\nthis purpose will be integrated with task planning primitives and\r\nextended through learning processes to identify the preconditions\r\nunder which different controllers can be chained together. The project\r\ninvolves extensive evaluation on a variety of novel adaptive hands and\r\nrobotic arms designed in the PIs' labs. Modern vision-based solutions\r\nwill be used to track grasped objects and provide feedback for\r\nlearning and closed-loop control.  The evaluation will measure whether\r\nthe developed hybrid models can significantly improve robustness of\r\ngrasping and the effectiveness of dexterous manipulation.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aaron",
   "pi_last_name": "Dollar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aaron Dollar",
   "pi_email_addr": "aaron.dollar@yale.edu",
   "nsf_id": "000525237",
   "pi_start_date": "2017-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Yale University",
  "inst_street_address": "150 MUNSON ST",
  "inst_street_address_2": "",
  "inst_city_name": "NEW HAVEN",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "2037854689",
  "inst_zip_code": "065113572",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "CT03",
  "org_lgl_bus_name": "YALE UNIV",
  "org_prnt_uei_num": "FL6GV84CKN57",
  "org_uei_num": "FL6GV84CKN57"
 },
 "perf_inst": {
  "perf_inst_name": "Yale University",
  "perf_str_addr": "15 Prospect Street",
  "perf_city_name": "New Haven",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "065116816",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "CT03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 632500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aimed for robust robotic grasping and dexterous, in-hand manipulation through<br /> the integration and experimental evaluation of: (a) robotic hardware design and analytical models with (b) advanced machine learning tools as well as (c) control and planning methods. The focus was to allow collaborative robots to effectively use adaptive robotic hands that exhibit under-actuation and compliance.</p>\n<p>Our portion of the collaboration primarily focused on mechanics-related issues, including the design of new dexterous hands, and examining how the passive mechanics of those hands can facilitate robots performing even very difficult grasping and manipulation tasks with minimal sensing. One project focused on how utilizing the elastic potential energy in each of the spring-loaded joints allows you to predict where a grasped object will move to for a given set of actuator inputs - a minimum energy location that is irrespective of the size and shape and grasping location of a specific object. This allows for manipulation of objects held in the hands to be done with almost no sensory information about the object, and can even include difficult sliding and rolling motions along fingers. Novel hand designs were optimized, built, and tested to demonstrate this concept.</p>\n<p>A second major result of this work was a concept in which a passively adaptive hand grasping an object can manipulate that object in the fingertips and, through that manipulation, observe with a camera the resulting motions of the object. Without any prior knowledge of the object, the observing of these motions enables a fast and efficient particle filtering based algorithm to come up with a model for controlling the object.</p>\n<p>Other than the 16 peer-reviewed papers that are publicly accessible, we provided a number of additional public products, including (a) open designs and models for adaptive hands (through the Yale OpenHand Project), (b) open-source software for simulating and controlling robotic hands and (c) data sets from the experimental evaluation.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/29/2022<br>\n\t\t\t\t\tModified by: Aaron&nbsp;Dollar</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project aimed for robust robotic grasping and dexterous, in-hand manipulation through\n the integration and experimental evaluation of: (a) robotic hardware design and analytical models with (b) advanced machine learning tools as well as (c) control and planning methods. The focus was to allow collaborative robots to effectively use adaptive robotic hands that exhibit under-actuation and compliance.\n\nOur portion of the collaboration primarily focused on mechanics-related issues, including the design of new dexterous hands, and examining how the passive mechanics of those hands can facilitate robots performing even very difficult grasping and manipulation tasks with minimal sensing. One project focused on how utilizing the elastic potential energy in each of the spring-loaded joints allows you to predict where a grasped object will move to for a given set of actuator inputs - a minimum energy location that is irrespective of the size and shape and grasping location of a specific object. This allows for manipulation of objects held in the hands to be done with almost no sensory information about the object, and can even include difficult sliding and rolling motions along fingers. Novel hand designs were optimized, built, and tested to demonstrate this concept.\n\nA second major result of this work was a concept in which a passively adaptive hand grasping an object can manipulate that object in the fingertips and, through that manipulation, observe with a camera the resulting motions of the object. Without any prior knowledge of the object, the observing of these motions enables a fast and efficient particle filtering based algorithm to come up with a model for controlling the object.\n\nOther than the 16 peer-reviewed papers that are publicly accessible, we provided a number of additional public products, including (a) open designs and models for adaptive hands (through the Yale OpenHand Project), (b) open-source software for simulating and controlling robotic hands and (c) data sets from the experimental evaluation.\n\n\t\t\t\t\tLast Modified: 06/29/2022\n\n\t\t\t\t\tSubmitted by: Aaron Dollar"
 }
}