{
 "awd_id": "1744077",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS: DSD: Collaborative Research: NeoNexus: The Next-generation Information Processing System across Digital and Neuromorphic Computing Domains",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yuanyuan Yang",
 "awd_eff_date": "2017-05-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 189019.0,
 "awd_amount": 189019.0,
 "awd_min_amd_letter_date": "2017-05-23",
 "awd_max_amd_letter_date": "2017-05-23",
 "awd_abstract_narration": "The explosion of \"big data\" applications imposes severe challenges of data processing speed and scalability on traditional computer systems. The performance of traditional Von Neumann machines is greatly hindered by the increasing performance gap between CPU and memory, motivating the active research on new or alternative computing architectures. By imitating brain's naturally massive parallel architecture with closely coupled memory and computing as well as the unique analog domain operations, neuromorphic computing systems are anticipated to deliver superior speed for applications in image recognition and natural language understanding.\r\n\r\nThe objective of this research is to establish the fundamental framework and design methodology for NeoNexus -- the next-generation information processing system inspired by human neocortex. It integrates neuromorphic computing accelerators with conventional computing resources by leveraging large scale inference-based data processing and computing acceleration technique atop memristor crossbar arrays. The computation and data exchange will be carefully coordinated and supported by the innovative interconnect architecture, i.e., a hierarchical network-on-chip (NoC). The software-hardware co-design platform will be developed to address the various design challenges. The project will help computer architecture and high-performance computing communities to overcome the ever-increasing technical challenges of traditional architectures and accelerate the fusion between conventional computing technology and cognitive computing model. It will also promote the applications of artificial intelligence technology advances in modern computer architectures and motivate the inventions at both software and hardware levels. Undergraduate and graduate students involved in this research will be trained for the next-generation semiconductor industry workforce.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hai",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hai Li",
   "pi_email_addr": "hai.li@duke.edu",
   "nsf_id": "000538107",
   "pi_start_date": "2017-05-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277054010",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 189019.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The major goal of this project is to develop an information processing system that combines the flexibility of conventional architecture in logic and scientific computation and the efficiency of neuromorphic architecture for applications in the domain of image recognition and language understanding. Particularly, the research work is conducted from three aspects. Task-1: leverage and integrate large-scale inference-based data processing and computing acceleration technique atop memristor crossbar arrays with conventional computing resources; Task-2: innovate architecture and memory hierarchy to better coordinate and support the computation and data exchange; and Task-3: develop the software-hard co-design platform to address major design challenges.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Our research on Task-1 started with the memristor crossbar based neuromorphic computing system design. In studying the input-output feature of memristor crossbar that employs a memristor at each intersection of horizontal and vertical metal wires, we found this typical array structure can naturally provide the capability of connection matrix storage and matrix-vector multiplication. We exploited the application of the memristor crossbars in neuromorphic hardware design and use the Brain-State-in-a-Box (BSB) model, an auto-associative neural network, to illustrate the potential of memristor crossbars in complex and large scale pattern associations and classifications. During the performance period of the project, we investigated both one-transistor-one-memristor (1T1R) and one-selector-one-memristor (1S1R) crossbar structures in developing neuromorphic ASIC designs.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Furthermore, at the architecture level, we proposed RENO - a highly-efficient reconfigurable neuromorphic computing accelerator with on-chip memristor crossbar arrays as a perceptron network, aiming at the acceleration of neural network computations. RENO adopts a hybrid method in data representation: the computation within the memristor arrays and the signal communications across them are conducted in analog form, while the control information remains as digital signals. Such a memristor-based mixed-signal accelerator speeds up neuromorphic computing and supports the implementations of a variety of neural network topologies.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Our research on Task-2 focuses on the architecture optimization and electronic design automation (EDA) method. We proposed AutoNCS for large-scale hybrid neuromorphic computing systems. Through the connection partition, iterative clustering and customized placement &amp; routing process, AutoNCS can minimize the area and wire-length when implementing a given neural network model. Moreover, in the RENO architecture, we proposed a mixed-signal interconnection network to assist the communication of computational signals among the memristor crossbars. An optimized configuration was discussed and finalized by thoroughly analyzing the impact of various design parameters on neuromorphic system performance and accuracy.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The Task-3 study was divided into two topics. At the beginning of the project, we noticed a large gap exists between the theoretical memristor characteristics and the experimental data obtained from real devices. It raised severe concerns in feasibility of memristor-based hardware design. Thus, we built a stochastic behavior model of TiO2 memristive devices based on the real measurement results to better facilitate the exploration of memristive switches in hardware implementation. The model bypassed material-related parameters while directly linking the device analog behavior to stochastic functions. The usage of macro cells in weight storage unit and stochastic neuron, the two fundamental elements of neuromorphic system, was then demonstrated.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Later, the focus of the study shifted to the classification accuracy improvement for neuromorphic computing systems. For the pure binary (1-level precision) neural networks, we proposed three orthogonal methods of learning 1-level precision synapses and tuning bias to improve image classification accuracy, including distribution-aware quantization, quantization regularization and bias tuning. We also proposed a quantized training method to enhance accuracy of ReRAM-based neuromorphic systems. The key idea is to deal with quantization while training and being aware of available discrete weights candidates. To guarantee the feasibility of quantization process, parameter clipping was adopted in the training process. At the end of the quantized training, a net model with quantized weights can be generated and directly mapped onto ReRAM devices.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp; The PI gave lectures on memristor design and architecture in several courses at ECE department including ECE590-12: Neuromorphic Computing, ECE 2193: Advanced VLSI Design, ECE/CoE 0501: Digital Laboratory, and ECE/CoE 1885: Departmental Seminar. Besides the neural network hardware implementation, the machine learning and DNN algorithms are also an important component for the course. The corresponding course materials and project information become available to the students to encourage the students to practice the memory design and evaluation at device, circuit and architecture levels.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The research has been conducted in close collaboration with our research partners, including HP Labs and AFRL. The outcomes of this research have direct impacts on memristor technology and future computing systems by making the research outcomes publically accessible. The internship or other opportunities provided by our collaborators also offered versatile training for graduate students as well as the ideal initial step of technology transferring.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/15/2018<br>\n\t\t\t\t\tModified by: Hai&nbsp;Li</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n      The major goal of this project is to develop an information processing system that combines the flexibility of conventional architecture in logic and scientific computation and the efficiency of neuromorphic architecture for applications in the domain of image recognition and language understanding. Particularly, the research work is conducted from three aspects. Task-1: leverage and integrate large-scale inference-based data processing and computing acceleration technique atop memristor crossbar arrays with conventional computing resources; Task-2: innovate architecture and memory hierarchy to better coordinate and support the computation and data exchange; and Task-3: develop the software-hard co-design platform to address major design challenges.\n\n      Our research on Task-1 started with the memristor crossbar based neuromorphic computing system design. In studying the input-output feature of memristor crossbar that employs a memristor at each intersection of horizontal and vertical metal wires, we found this typical array structure can naturally provide the capability of connection matrix storage and matrix-vector multiplication. We exploited the application of the memristor crossbars in neuromorphic hardware design and use the Brain-State-in-a-Box (BSB) model, an auto-associative neural network, to illustrate the potential of memristor crossbars in complex and large scale pattern associations and classifications. During the performance period of the project, we investigated both one-transistor-one-memristor (1T1R) and one-selector-one-memristor (1S1R) crossbar structures in developing neuromorphic ASIC designs.\n\n      Furthermore, at the architecture level, we proposed RENO - a highly-efficient reconfigurable neuromorphic computing accelerator with on-chip memristor crossbar arrays as a perceptron network, aiming at the acceleration of neural network computations. RENO adopts a hybrid method in data representation: the computation within the memristor arrays and the signal communications across them are conducted in analog form, while the control information remains as digital signals. Such a memristor-based mixed-signal accelerator speeds up neuromorphic computing and supports the implementations of a variety of neural network topologies.\n\n      Our research on Task-2 focuses on the architecture optimization and electronic design automation (EDA) method. We proposed AutoNCS for large-scale hybrid neuromorphic computing systems. Through the connection partition, iterative clustering and customized placement &amp; routing process, AutoNCS can minimize the area and wire-length when implementing a given neural network model. Moreover, in the RENO architecture, we proposed a mixed-signal interconnection network to assist the communication of computational signals among the memristor crossbars. An optimized configuration was discussed and finalized by thoroughly analyzing the impact of various design parameters on neuromorphic system performance and accuracy.\n\n      The Task-3 study was divided into two topics. At the beginning of the project, we noticed a large gap exists between the theoretical memristor characteristics and the experimental data obtained from real devices. It raised severe concerns in feasibility of memristor-based hardware design. Thus, we built a stochastic behavior model of TiO2 memristive devices based on the real measurement results to better facilitate the exploration of memristive switches in hardware implementation. The model bypassed material-related parameters while directly linking the device analog behavior to stochastic functions. The usage of macro cells in weight storage unit and stochastic neuron, the two fundamental elements of neuromorphic system, was then demonstrated.\n\n      Later, the focus of the study shifted to the classification accuracy improvement for neuromorphic computing systems. For the pure binary (1-level precision) neural networks, we proposed three orthogonal methods of learning 1-level precision synapses and tuning bias to improve image classification accuracy, including distribution-aware quantization, quantization regularization and bias tuning. We also proposed a quantized training method to enhance accuracy of ReRAM-based neuromorphic systems. The key idea is to deal with quantization while training and being aware of available discrete weights candidates. To guarantee the feasibility of quantization process, parameter clipping was adopted in the training process. At the end of the quantized training, a net model with quantized weights can be generated and directly mapped onto ReRAM devices.\n\n     The PI gave lectures on memristor design and architecture in several courses at ECE department including ECE590-12: Neuromorphic Computing, ECE 2193: Advanced VLSI Design, ECE/CoE 0501: Digital Laboratory, and ECE/CoE 1885: Departmental Seminar. Besides the neural network hardware implementation, the machine learning and DNN algorithms are also an important component for the course. The corresponding course materials and project information become available to the students to encourage the students to practice the memory design and evaluation at device, circuit and architecture levels.\n\n      The research has been conducted in close collaboration with our research partners, including HP Labs and AFRL. The outcomes of this research have direct impacts on memristor technology and future computing systems by making the research outcomes publically accessible. The internship or other opportunities provided by our collaborators also offered versatile training for graduate students as well as the ideal initial step of technology transferring.\n\n \n\n\t\t\t\t\tLast Modified: 10/15/2018\n\n\t\t\t\t\tSubmitted by: Hai Li"
 }
}