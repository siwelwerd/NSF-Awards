{
 "awd_id": "1704985",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SaTC: CORE: Large: Collaborative: Accountable Information Use: Privacy and Fairness in Decision-Making Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925177",
 "po_email": "asquicci@nsf.gov",
 "po_sign_block_name": "Anna Squicciarini",
 "awd_eff_date": "2017-06-01",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2017-05-18",
 "awd_max_amd_letter_date": "2021-06-09",
 "awd_abstract_narration": "Increasingly, decisions and actions affecting people's lives are determined by automated systems processing personal data.\u00a0 Excitement about these systems has been accompanied by serious concerns about their opacity and the threats that they pose to privacy, fairness, and other values.\u00a0 Recognizing these concerns, the investigators seek to make real-world automated decision-making systems accountable for privacy and fairness by enabling them to detect and explain violations of these values.\u00a0 The technical work is informed by, and applied to, online advertising, healthcare, and criminal justice, in collaboration with and as advised by domain experts.\u00a0\r\n\r\nAddressing privacy and fairness in decision systems requires providing formal definitional frameworks and practical system designs.\u00a0 The investigators provide new notions of privacy and fairness that deal with both protected information itself and proxies for it, while handling context-dependent, normative definitions of violations.\u00a0 A fundamental tension they address pits the access given to auditors of a system against the system owners' intellectual property protections and the confidentiality of the personal data used by the system.\u00a0 The investigators decompose such auditing into stages, where the level of access granted to an auditor is increased when potential (but not explainable) violations of privacy or fairness are detected. Workshops and public releases of code and data amplify the investigators' interactions with policy makers and other stakeholders.  Their partnerships with outreach organizations encourage diversity.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Tschantz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Tschantz",
   "pi_email_addr": "mct@icsi.berkeley.edu",
   "nsf_id": "000690105",
   "pi_start_date": "2017-05-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "International Computer Science Institute",
  "inst_street_address": "2150 SHATTUCK AVE",
  "inst_street_address_2": "SUITE 250",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106662900",
  "inst_zip_code": "947041345",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "INTERNATIONAL COMPUTER SCIENCE INSTITUTE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GSRMP1QCXU74"
 },
 "perf_inst": {
  "perf_inst_name": "International Computer Science Institute",
  "perf_str_addr": "1947 Center St STE 600",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947044115",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 66038.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 88713.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 96293.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 97282.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 101674.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong id=\"docs-internal-guid-dfb46a43-7fff-cf3e-b714-7bfb2896d2e3\" style=\"font-weight: normal;\"> </strong></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 10pt;\" dir=\"ltr\"><strong id=\"docs-internal-guid-dfb46a43-7fff-cf3e-b714-7bfb2896d2e3\" style=\"font-weight: normal;\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This project explored the privacy and fairness properties currently offered by automated systems processing personal data and which properties these systems could or should offer.&nbsp;</span></strong></p>\n<p><strong id=\"docs-internal-guid-dfb46a43-7fff-cf3e-b714-7bfb2896d2e3\" style=\"font-weight: normal;\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 10pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The project performed an empirical exploration and legal analysis of the liability that online ad networks may face from showing ads in a discriminatory manner.&nbsp; The investigators determined that an advertiser could use Google&rsquo;s ad buying interface to request that ads be shown in obviously discriminatory manners.&nbsp; They determined that in this case, the ad network would be protected from liability by Section 230 of the Communications Decency Act. They enumerated other ways in which discriminatory targeting of ads could arise.&nbsp; These included some in which the ad network would effectively make the decision to show the ad in a discriminatory manner, which may lead it to lose its Section 230 immunity in some cases.</span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 10pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The investigators tested privacy enhancing technologies (PETs) for avoiding involuntary tracking across websites online. They constructed a testing harness for PETs that used a hybrid method combining experimental and observational data. Using this test harness, they showed that most PETs failed to provide much protection against website fingerprinting. At least one PET was improved in response to these findings.</span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 10pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The project produced a test for discrimination that is sensitive to background conditions that could explain why a classifier lacks demographic parity between protected groups. By distinguishing between the true label and the estimated label available for training a machine learning model, and how they may differ, this definition is more nuanced than prior ones that implicitly make assumptions about why differences exist between protected groups.&nbsp; The investigators explored how the test interacts with a notion of utility based on classifier accuracy and a notion of justice based on providing better outcomes to more qualified individuals.</span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 10pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The investigators examined differential privacy, an approach to providing privacy in analyses of survey results.&nbsp; They found that it may be understood as a bound on the causal effect size, a measure commonly used in empirical sciences, of an individual&rsquo;s response on the overall survey results.&nbsp; This viewpoint more clearly explains differential privacy's power than other viewpoints that require making assumptions. The investigator&rsquo;s viewpoint resolves a controversy in the research community over when differential privacy works for people with correlated data, a controversy that arose from some viewing differential privacy as instead being a property about the amount of association or correlation existing between an individual&rsquo;s response and the overall survey results.</span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 10pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Follow-up work used utility functions and methods from causal decision theory to compare variations on differential privacy from the perspective of potential study participants.&nbsp; The investigators found that the nature of the potential participant's utility function can alter whether a participant would require differential privacy to be strictly enforced or would be comfortable with a relaxation of it.</span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 10pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The investigators also leverage their causal view of differential privacy to relate privacy and nondiscrimination at a mathematical level. They showed that privacy and nondiscrimination each come in causal and associative flavors. They found that the causal versions of privacy and nondiscrimination are closely related, and that the associative versions of privacy and nondiscrimination are closely related. In both cases, these versions lead to mathematical restrictions on algorithms that have the same form, although the variables refer to different attributes for privacy than they do for nondiscrimination.&nbsp; This work eases the reuse of methods from one area in the other.</span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 10pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Another activity explored various notions of proxy discrimination, organizing them into a common framework.&nbsp; The framework looks at how each notion breaks down into various associations and various causal relationships, including second-order causation.&nbsp; The investigators surveyed descriptions of proxy discrimination and approaches for addressing it, both in academic articles and regulatory comments.&nbsp; They examined how each proposed approach aligns, or not, with various notions of proxy discrimination.&nbsp; They conclude that many approaches are more aligned with problems associated with proxy discrimination than with proxy discrimination itself, but that this is reasonable given that proxy discrimination functions more as an umbrella term than as the name of a single specific problem.</span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 10pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The project has disseminated these results with academic publications, presentations, and workshops.&nbsp; It has broadened its impact through interdisciplinary research and by presenting the findings to communities outside of the investigators&rsquo; fields.&nbsp; Such presentations included ones to computer scientists working in industry, to law students, and to staff in the Civil Rights Division of the United States Department of Justice.</span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 10pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The principal investigator has provided mentorship to undergraduate students, graduate students, and postdocs drawn from computer science, mathematics, electrical engineering, public policy, information studies, and business programs.&nbsp; The project has broadened participation in computer science by mentoring individuals from underrepresented groups.</span></p>\n</strong></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/29/2023<br>\n\t\t\t\t\tModified by: Michael&nbsp;Tschantz</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThis project explored the privacy and fairness properties currently offered by automated systems processing personal data and which properties these systems could or should offer. \n\n\nThe project performed an empirical exploration and legal analysis of the liability that online ad networks may face from showing ads in a discriminatory manner.  The investigators determined that an advertiser could use Google\u2019s ad buying interface to request that ads be shown in obviously discriminatory manners.  They determined that in this case, the ad network would be protected from liability by Section 230 of the Communications Decency Act. They enumerated other ways in which discriminatory targeting of ads could arise.  These included some in which the ad network would effectively make the decision to show the ad in a discriminatory manner, which may lead it to lose its Section 230 immunity in some cases.\nThe investigators tested privacy enhancing technologies (PETs) for avoiding involuntary tracking across websites online. They constructed a testing harness for PETs that used a hybrid method combining experimental and observational data. Using this test harness, they showed that most PETs failed to provide much protection against website fingerprinting. At least one PET was improved in response to these findings.\nThe project produced a test for discrimination that is sensitive to background conditions that could explain why a classifier lacks demographic parity between protected groups. By distinguishing between the true label and the estimated label available for training a machine learning model, and how they may differ, this definition is more nuanced than prior ones that implicitly make assumptions about why differences exist between protected groups.  The investigators explored how the test interacts with a notion of utility based on classifier accuracy and a notion of justice based on providing better outcomes to more qualified individuals.\nThe investigators examined differential privacy, an approach to providing privacy in analyses of survey results.  They found that it may be understood as a bound on the causal effect size, a measure commonly used in empirical sciences, of an individual\u2019s response on the overall survey results.  This viewpoint more clearly explains differential privacy's power than other viewpoints that require making assumptions. The investigator\u2019s viewpoint resolves a controversy in the research community over when differential privacy works for people with correlated data, a controversy that arose from some viewing differential privacy as instead being a property about the amount of association or correlation existing between an individual\u2019s response and the overall survey results.\nFollow-up work used utility functions and methods from causal decision theory to compare variations on differential privacy from the perspective of potential study participants.  The investigators found that the nature of the potential participant's utility function can alter whether a participant would require differential privacy to be strictly enforced or would be comfortable with a relaxation of it.\nThe investigators also leverage their causal view of differential privacy to relate privacy and nondiscrimination at a mathematical level. They showed that privacy and nondiscrimination each come in causal and associative flavors. They found that the causal versions of privacy and nondiscrimination are closely related, and that the associative versions of privacy and nondiscrimination are closely related. In both cases, these versions lead to mathematical restrictions on algorithms that have the same form, although the variables refer to different attributes for privacy than they do for nondiscrimination.  This work eases the reuse of methods from one area in the other.\nAnother activity explored various notions of proxy discrimination, organizing them into a common framework.  The framework looks at how each notion breaks down into various associations and various causal relationships, including second-order causation.  The investigators surveyed descriptions of proxy discrimination and approaches for addressing it, both in academic articles and regulatory comments.  They examined how each proposed approach aligns, or not, with various notions of proxy discrimination.  They conclude that many approaches are more aligned with problems associated with proxy discrimination than with proxy discrimination itself, but that this is reasonable given that proxy discrimination functions more as an umbrella term than as the name of a single specific problem.\nThe project has disseminated these results with academic publications, presentations, and workshops.  It has broadened its impact through interdisciplinary research and by presenting the findings to communities outside of the investigators\u2019 fields.  Such presentations included ones to computer scientists working in industry, to law students, and to staff in the Civil Rights Division of the United States Department of Justice.\nThe principal investigator has provided mentorship to undergraduate students, graduate students, and postdocs drawn from computer science, mathematics, electrical engineering, public policy, information studies, and business programs.  The project has broadened participation in computer science by mentoring individuals from underrepresented groups.\n\n\n \n\n\t\t\t\t\tLast Modified: 10/29/2023\n\n\t\t\t\t\tSubmitted by: Michael Tschantz"
 }
}