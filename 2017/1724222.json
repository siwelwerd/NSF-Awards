{
 "awd_id": "1724222",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "S&AS: FND: A Stochastic Ethical Decision-Making Framework for Long-Term Autonomy",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 600001.0,
 "awd_amount": 608001.0,
 "awd_min_amd_letter_date": "2017-07-12",
 "awd_max_amd_letter_date": "2018-04-13",
 "awd_abstract_narration": "For robots to effectively collaborate with humans, they must be able to reason about the ethical consequences of their decisions and actions, incorporating societal values, rules, and conventions. Consider, for example, autonomous cars, which are envisioned to become commonplace in 5-10 years. Autonomous cars will provide many advantages for road safety, and they will offer mobility to those with physical challenges. For such cars to be successful, however, multiple ethical problems must be solved. For example, is it allowable for a car to break traffic laws as it is taking a wounded person to a hospital? What should a car do if it recognizes that an accident is unavoidable? How can a car reason in a way that is understandable and acceptable in human society (and courts of law)? Important ethical questions also arise in applications of robotics to areas such as military engagements, law enforcement, and healthcare. To address these issues, the research will provide ways for robots to reason and plan their tasks and make ethically sound decisions. These reasoning procedures will enable robots to learn and adapt over time as laws and social conventions change. \r\n\r\n\r\nThe research approach is based on normative reasoning integrated with Markov Decision Process (MDP) planning to enable the creation of an ethical intelligent Physical System (IPS) that will be evaluated via human experiments.  The research  is innovative in that it will provide:  (a)  an integrated way of reasoning about task performance and ethical behavior in the context of long-term autonomy,  where ethical rules  can be changing and action consequences could  be task and context dependent,  (b) principled ways of  evaluating consequences of  robot actions,  by considering and resolving  conflicts between domain goals and normative goals,  (c)  criteria to determine norm priority in a flexible and context dependent manner, (d) methods to  consider  the whole  life-cycle of norms, namely norm activation, deactivation, contradiction, violation and obsolescence.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Katia",
   "pi_last_name": "Sycara",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Katia P Sycara",
   "pi_email_addr": "sycara@cs.cmu.edu",
   "nsf_id": "000109808",
   "pi_start_date": "2017-07-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "039Y00",
   "pgm_ele_name": "S&AS - Smart & Autonomous Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "046Z",
   "pgm_ref_txt": "S&AS - Smart & Autonomous Systems"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 600001.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this research is to provide a computational framework that integrates robot task planning with &nbsp;&nbsp;reasoning about human norms and also enables the robot &nbsp;to infer norms and actions of others. &nbsp;We believe that such norm-aware agents will be more successful in interacting with humans, more trusted and &nbsp;acceptable. &nbsp;&nbsp;Our research produced the following outcomes.</p>\n<p>We designed,&nbsp; implemented and evaluated a modular normative reasoning model (MNMDP) that &nbsp;has the following advantages. First, it allows for efficient computation of integrated task and normative reasoning at <em>deliberation</em> and <em>run time execution</em>. Second, it allows for efficient <em>addition of norms</em> and tasks over time. Third, it allows reasoning about and evaluation of <em>tradeoffs</em> between performance requirements of executing domain level tasks while complying (or not) with normative decisions, taking into consideration the agent?s preferences and the environmental context.</p>\n<p>We designed a survey on social norms for domestic robot tasks and collected human data on large numbers of MTurk workers from different cultures. &nbsp;&nbsp;Our results show (1) that users expect the robot to be aware of the social and physical environment and behave accordingly, thus making reasoning about social norms important in robot design and development and (2) that there exist &nbsp;<em>cultural differences </em>in people's views and expected social roles of domestic robots.</p>\n<p>Robots interacting with humans must flexibly adapt to changes in the environment and human behavior. Inverse Reinforcement Learning (IRL) can be used by the autonomous agents to learn social norm-compliant behavior demonstrations by experts. However, norms are context-sensitive, i.e. different norms get activated in different contexts. Representing various contexts in the state space of the robot, as well as getting expert demonstrations under all possible tasks and contexts is extremely challenging and computationally expensive.&nbsp; We &nbsp;developed a <em>scalable context-aware inverse reinforcement learning normative&nbsp; model</em> and demonstrated its superiority over state of the art algorithms. We also showed&nbsp; that our model can handle problems with changing context spaces.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2022<br>\n\t\t\t\t\tModified by: Katia&nbsp;P&nbsp;Sycara</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this research is to provide a computational framework that integrates robot task planning with   reasoning about human norms and also enables the robot  to infer norms and actions of others.  We believe that such norm-aware agents will be more successful in interacting with humans, more trusted and  acceptable.   Our research produced the following outcomes.\n\nWe designed,  implemented and evaluated a modular normative reasoning model (MNMDP) that  has the following advantages. First, it allows for efficient computation of integrated task and normative reasoning at deliberation and run time execution. Second, it allows for efficient addition of norms and tasks over time. Third, it allows reasoning about and evaluation of tradeoffs between performance requirements of executing domain level tasks while complying (or not) with normative decisions, taking into consideration the agent?s preferences and the environmental context.\n\nWe designed a survey on social norms for domestic robot tasks and collected human data on large numbers of MTurk workers from different cultures.   Our results show (1) that users expect the robot to be aware of the social and physical environment and behave accordingly, thus making reasoning about social norms important in robot design and development and (2) that there exist  cultural differences in people's views and expected social roles of domestic robots.\n\nRobots interacting with humans must flexibly adapt to changes in the environment and human behavior. Inverse Reinforcement Learning (IRL) can be used by the autonomous agents to learn social norm-compliant behavior demonstrations by experts. However, norms are context-sensitive, i.e. different norms get activated in different contexts. Representing various contexts in the state space of the robot, as well as getting expert demonstrations under all possible tasks and contexts is extremely challenging and computationally expensive.  We  developed a scalable context-aware inverse reinforcement learning normative  model and demonstrated its superiority over state of the art algorithms. We also showed  that our model can handle problems with changing context spaces.\n\n \n\n\t\t\t\t\tLast Modified: 11/29/2022\n\n\t\t\t\t\tSubmitted by: Katia P Sycara"
 }
}