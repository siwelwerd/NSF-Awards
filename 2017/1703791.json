{
 "awd_id": "1703791",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Medium: Collaborative Research: Formal Analysis and Synthesis of Multiagent Systems with Incentives",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922585",
 "po_email": "pprabhak@nsf.gov",
 "po_sign_block_name": "Pavithra Prabhakar",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2017-06-29",
 "awd_max_amd_letter_date": "2017-06-29",
 "awd_abstract_narration": "The project develops automated methods for the tool-aided design and analysis of multi-agent systems with incentives. These systems are natural models for real-world situations in which collections of actors interact with one another in an autonomous and self-interested manner. For example, such a system can model a set of software agents that participate in an internet-based protocol, such as an advertisement auction or crypto currency; a collection of robots that share physical or digital infrastructure; or a set of cells that participate in an evolutionary process. The project combines game-theoretic and logical methods to develop techniques for formal modeling, analysis, verification, and synthesis of such systems. The end objectives of the project include reliable engineering of protocols that govern interactions among autonomous agents, and computer-aided understanding of naturally occurring game-theoretic interactions.\r\n\r\nThe technical approach of the project has three dimensions. The first is the development of new formal models, correctness requirements, and abstraction and reasoning principles for multi-agent systems with incentives. Research directions include richer notions of equilibria in multi-agent systems, and effects of interaction and randomization on equilibria. Second, the project studies algorithmic tools for analysis and verification of multi-agent systems with incentives with respect to desired requirements regarding system behaviors and equilibria. The third direction is to automatically synthesize mechanisms so as to guarantee desired properties. Applications from a range of areas, including financial protocols, robotics, and biology, are used to guide and evaluate the research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rajeev",
   "pi_last_name": "Alur",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rajeev Alur",
   "pi_email_addr": "alur@cis.upenn.edu",
   "nsf_id": "000448124",
   "pi_start_date": "2017-06-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of the University of Pennsylvania",
  "perf_str_addr": "3451 Walnut Street, P-221",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "8206",
   "pgm_ref_txt": "Formal Methods and Verification"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project developed techniques for automated game-theoretic reasoning about multi-agent systems with formally specified incentives. A particular novelty of the results is the integration of techniques from reinforcement learning (RL) developed in the AI community with algorithmic synthesis from logical specifications developed in the formal methods community. The former techniques allow construction of policies when the environment model is not known, while the latter techniques provide correctness guarantees with respect to high-level logical requirements. The project led to a theoretical understanding of tractability of learning from temporal logic specifications, design of composable specification language for specifying robotic tasks, algorithms to train policies to satisfy such specifications, and a prototype implementation and its evaluation on case studies that demonstrate advances over the state of the art in learning for long-horizon tasks. These results have also been extended to the challenging setting of non-cooperative multi-agent systems resulting in an algorithm that can learn policies for different agents that are guaranteed to be in a Nash equilibrium with high social welfare.</p>\n<p>The results of the project open up a new thread of research at the intersection of RL and reactive synthesis. These results have been presented at the premier conferences in machine learning (such as NeurIPS and AISTATS) and formal methods (such as CAV and EMSOFT), and in invited talks, seminars, and tutorials, including a tutorial on \"Specification-guided reinforcement learning\" at the upcoming AI conference AAAI 2023. The project supported a post-doctoral researcher who will soon start as Assistant Professor at Georgia Inst of Technology and a PhD student will defend dissertation on the topic of this grant in Summer 2023.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/12/2022<br>\n\t\t\t\t\tModified by: Rajeev&nbsp;Alur</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project developed techniques for automated game-theoretic reasoning about multi-agent systems with formally specified incentives. A particular novelty of the results is the integration of techniques from reinforcement learning (RL) developed in the AI community with algorithmic synthesis from logical specifications developed in the formal methods community. The former techniques allow construction of policies when the environment model is not known, while the latter techniques provide correctness guarantees with respect to high-level logical requirements. The project led to a theoretical understanding of tractability of learning from temporal logic specifications, design of composable specification language for specifying robotic tasks, algorithms to train policies to satisfy such specifications, and a prototype implementation and its evaluation on case studies that demonstrate advances over the state of the art in learning for long-horizon tasks. These results have also been extended to the challenging setting of non-cooperative multi-agent systems resulting in an algorithm that can learn policies for different agents that are guaranteed to be in a Nash equilibrium with high social welfare.\n\nThe results of the project open up a new thread of research at the intersection of RL and reactive synthesis. These results have been presented at the premier conferences in machine learning (such as NeurIPS and AISTATS) and formal methods (such as CAV and EMSOFT), and in invited talks, seminars, and tutorials, including a tutorial on \"Specification-guided reinforcement learning\" at the upcoming AI conference AAAI 2023. The project supported a post-doctoral researcher who will soon start as Assistant Professor at Georgia Inst of Technology and a PhD student will defend dissertation on the topic of this grant in Summer 2023.\n\n\t\t\t\t\tLast Modified: 12/12/2022\n\n\t\t\t\t\tSubmitted by: Rajeev Alur"
 }
}