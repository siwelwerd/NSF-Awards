{
 "awd_id": "1703454",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Medium: Collaborative: Taming Web Content Through Automated Reduction in Browser Functionality",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032920000",
 "po_email": "doliveir@nsf.gov",
 "po_sign_block_name": "Daniela Oliveira",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-02-28",
 "tot_intn_awd_amt": 387098.0,
 "awd_amount": 387098.0,
 "awd_min_amd_letter_date": "2017-07-05",
 "awd_max_amd_letter_date": "2017-07-05",
 "awd_abstract_narration": "Web-based applications executed via web browsers are ubiquitous in everyday life.  They underlie our banking, communications, shopping, social networking, tax payments, insurance transactions, and health care interactions. Unfortunately, malicious actors can take advantage of vulnerabilities in web browsers to exploit the user's computer.  The consequences of a web browser attack can be severe: web content can execute arbitrary code on the victim's machine. This research project studies how web applications use the features provided by web browsers and how user systems can be protected by restricting unnecessary browser features.\r\n\r\nThis project addresses web browser security by reducing the browser feature footprint, thereby reducing the browser attack surface and mitigating many classes of attacks. The researchers are building a feature-instrumented browser that reports what functionality is used by a web application. Then, they leverage that information to automatically identify when web applications diverge from their expected behavior and attack the user's browser. To enable users to use the most up-to-date browsers, while protecting them from unnecessary and risky browser features, the research team is building a system to decouple features from the browser.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Engin",
   "pi_last_name": "Kirda",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Engin Kirda",
   "pi_email_addr": "ek@ccs.neu.edu",
   "nsf_id": "000572930",
   "pi_start_date": "2017-07-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Avenue",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 387098.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, NEU, ASU, and NCSU investigated techniques for selectively reducing the functionality in modern browsers. Browsers, since their introduction, have started to support a large set of functionality that is accessible by web pages that are being rendered. Unfortunately, this has attracted malicious actors that have started to use security vulnerabilities in all the parts of the browser to successfully launch attacks. Although modern browsers today support many different features, not all of this functionality is always required, or used, by end users.<br />&nbsp;<br />During this project, we published our work in highly &shy;venues, including USENIX, RAID, CCS, IMC, IEEE Security and Privacy, WWW, ISC, and SAC. We also presented our work at the Mozilla Security Research Summit 2019 and Brave Research Summit 2018, communicating this way directly to browser vendors about our recent research results.<br /><br />Specifically, we built a dynamic analysis framework hosted inside Chrome&rsquo;s JavaScript Engine V8, the JS engine of the Chrome browser, that logs native function or property accesses during any JS execution. We call this VisibleV8 (VV8) At less than 600 lines (only 67 of which modify V8&rsquo;s existing behavior), our patches are lightweight and have been maintained from Chrome versions 63 through 72 without difficulty. VV8 consistently outperforms equivalent inline instrumentation, and it intercepts accesses impossible to instrument inline. This comprehensive coverage allows us to isolate and identify 46 JavaScript namespace artifacts used by JS code in the wild to detect automated browsing platforms and to discover that 29% of the Alexa top 50k sites load content which actively probes these artifacts. We released all of our code related to this project here: https://github.com/wspr-ncsu/visiblev8 <br /><br />We used VisibleV8 in a number of follow-up research projects, such as one published at IMC 2021 to study JavaScript obfuscation techniques in the wild. Our work relies on a simple, but powerful observation: if dynamic analysis of a script&rsquo;s behavior (specifically, how it interacts with browser APIs) reveals browser API feature usage that cannot be reconciled with static analysis of the script&rsquo;s source code, then that behavior is obfuscated. To quantify and test this observation, we create a hybrid analysis platform using instrumented Chromium to log all browser API accesses by the scripts executed when a user visits a page. We filter the API access traces from our dynamic analysis through a static analysis tool that we developed in order to quantify how much and what kind of functionality is hidden on the web. When applying this methodology across the Alexa top 100k domains, we discover that 95.90% of the domains we successfully visited contain at least one script which invokes APIs that cannot be resolved from static analysis. <br /><br />We also used VisibleV8 to study the reproducibility of web measurements. At The Web Conference (WWW) 2021 we investigate how key measurements differ when using naive crawling tool defaults vs. careful attempts to match &ldquo;real&rdquo; users across the Tranco top 25k web domains. We find web privacy and security measurements significantly affected by vantage point and browser configuration. We conclude that unless researchers ensure their web measurement tools match real world user experience, the research community is likely missing important signals systematically. For example, we find browser configuration alone causing shifts in 19% of known ad and tracking domains encountered and altering the loading frequency of up to 10% of distinct JavaScript code units executed. We find network vantage points having similar, though less dramatic, effects on the same web metrics. To ensure reproducibility, we carefully document our methodology and publish both our code and collected data.<br /><br />In November 2021, we performed an empirical analysis of browser features evolution and aimed to evaluate browser fingerprintability. By analyzing 33 Google Chrome, 31 Mozilla Firefox, and 33 Opera major browser versions released through 2016 to 2020, we discovered that all of these browsers have unique feature sets which makes them different from each other. By comparing these features to the fingerprinting APIs presented in literature that have appeared in this field, we were able to conclude that all of these browser versions are uniquely fingerprintable. Our results show an alarming trend that browsers are becoming more fingerprintable over time because newer versions contain more fingerprintable APIs compared to older ones.<br /><br />Overall, the results of this research project have made a significant contribution to improving the security of the web. Furthermore, we expect that the results of this research, which were made open-source, will be used by future researchers to continue improving the security of the web for all.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/01/2022<br>\n\t\t\t\t\tModified by: Engin&nbsp;Kirda</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this project, NEU, ASU, and NCSU investigated techniques for selectively reducing the functionality in modern browsers. Browsers, since their introduction, have started to support a large set of functionality that is accessible by web pages that are being rendered. Unfortunately, this has attracted malicious actors that have started to use security vulnerabilities in all the parts of the browser to successfully launch attacks. Although modern browsers today support many different features, not all of this functionality is always required, or used, by end users.\n \nDuring this project, we published our work in highly &shy;venues, including USENIX, RAID, CCS, IMC, IEEE Security and Privacy, WWW, ISC, and SAC. We also presented our work at the Mozilla Security Research Summit 2019 and Brave Research Summit 2018, communicating this way directly to browser vendors about our recent research results.\n\nSpecifically, we built a dynamic analysis framework hosted inside Chrome\u2019s JavaScript Engine V8, the JS engine of the Chrome browser, that logs native function or property accesses during any JS execution. We call this VisibleV8 (VV8) At less than 600 lines (only 67 of which modify V8\u2019s existing behavior), our patches are lightweight and have been maintained from Chrome versions 63 through 72 without difficulty. VV8 consistently outperforms equivalent inline instrumentation, and it intercepts accesses impossible to instrument inline. This comprehensive coverage allows us to isolate and identify 46 JavaScript namespace artifacts used by JS code in the wild to detect automated browsing platforms and to discover that 29% of the Alexa top 50k sites load content which actively probes these artifacts. We released all of our code related to this project here: https://github.com/wspr-ncsu/visiblev8 \n\nWe used VisibleV8 in a number of follow-up research projects, such as one published at IMC 2021 to study JavaScript obfuscation techniques in the wild. Our work relies on a simple, but powerful observation: if dynamic analysis of a script\u2019s behavior (specifically, how it interacts with browser APIs) reveals browser API feature usage that cannot be reconciled with static analysis of the script\u2019s source code, then that behavior is obfuscated. To quantify and test this observation, we create a hybrid analysis platform using instrumented Chromium to log all browser API accesses by the scripts executed when a user visits a page. We filter the API access traces from our dynamic analysis through a static analysis tool that we developed in order to quantify how much and what kind of functionality is hidden on the web. When applying this methodology across the Alexa top 100k domains, we discover that 95.90% of the domains we successfully visited contain at least one script which invokes APIs that cannot be resolved from static analysis. \n\nWe also used VisibleV8 to study the reproducibility of web measurements. At The Web Conference (WWW) 2021 we investigate how key measurements differ when using naive crawling tool defaults vs. careful attempts to match \"real\" users across the Tranco top 25k web domains. We find web privacy and security measurements significantly affected by vantage point and browser configuration. We conclude that unless researchers ensure their web measurement tools match real world user experience, the research community is likely missing important signals systematically. For example, we find browser configuration alone causing shifts in 19% of known ad and tracking domains encountered and altering the loading frequency of up to 10% of distinct JavaScript code units executed. We find network vantage points having similar, though less dramatic, effects on the same web metrics. To ensure reproducibility, we carefully document our methodology and publish both our code and collected data.\n\nIn November 2021, we performed an empirical analysis of browser features evolution and aimed to evaluate browser fingerprintability. By analyzing 33 Google Chrome, 31 Mozilla Firefox, and 33 Opera major browser versions released through 2016 to 2020, we discovered that all of these browsers have unique feature sets which makes them different from each other. By comparing these features to the fingerprinting APIs presented in literature that have appeared in this field, we were able to conclude that all of these browser versions are uniquely fingerprintable. Our results show an alarming trend that browsers are becoming more fingerprintable over time because newer versions contain more fingerprintable APIs compared to older ones.\n\nOverall, the results of this research project have made a significant contribution to improving the security of the web. Furthermore, we expect that the results of this research, which were made open-source, will be used by future researchers to continue improving the security of the web for all.\n\n\t\t\t\t\tLast Modified: 07/01/2022\n\n\t\t\t\t\tSubmitted by: Engin Kirda"
 }
}