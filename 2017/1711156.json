{
 "awd_id": "1711156",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Angle-Sensitive Metasurfaces for Lens-Free Compound-Eye Cameras",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": "7032922980",
 "po_email": "ddagenai@nsf.gov",
 "po_sign_block_name": "Dominique Dagenais",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 379953.0,
 "awd_amount": 379953.0,
 "awd_min_amd_letter_date": "2017-07-07",
 "awd_max_amd_letter_date": "2017-07-07",
 "awd_abstract_narration": "Title: Metasurfaces for Lens-Free Compound-Eye Cameras \r\n\r\nNon-Technical Description:\r\nThis project aims at developing a new camera technology featuring extreme size miniaturization, inspired by the compound-eye vision modality that is commonly found in nature in small invertebrates such as insects and crustaceans. Compound eyes typically consist of a curved array of many imaging elements (including lenses and photoreceptors), each oriented so as to detect light incident along a different direction. The full image of the object being visualized is then reconstructed from the combined inputs of all such elements. The optoelectronic implementation of this vision modality is generally complicated by its curved architecture, since standard optoelectronic devices are based on planar substrates. The compound-eye vision modality represents the optimally adapted solution to provide wide-angle field of view with negligible distortion within the smallest possible package. Furthermore, compound eyes can create focused images of objects at arbitrary distances without the need for any focal-length adjustment, and thus offer nearly infinite depth of field and extremely high acuity to motion. The proposed cameras could therefore provide an enabling technology for a wide range of imaging applications where small size, large field of view, and high temporal resolution are of particular importance. Specific examples include machine vision (e.g., for obstacle avoidance and autonomous navigation), surveillance, and endoscopic medical imaging. The proposed activities will also promote education through the training of graduate and undergraduate students in a wide range of topics within nanophotonics, optoelectronics, and image processing. Related curriculum development efforts will impact students in other disciplines.\r\n\r\nTechnical Description:\r\nThe proposed research will leverage recent advances in nanophotonics and metamaterials to develop a planar lens-free compound-eye camera consisting of a planar array of imaging pixels. The angle selectivity of each pixel is provided by specially designed arrays of metallic nanoparticles (optical metasurfaces) patterned on the surface of each photodetector. The key innovation of the proposed research is the development of metasurfaces that can selectively transmit into their substrate only light incident along a single geometrically tunable direction (within a small range). Light incident along any other direction will be reflected. With this arrangement, lens-free compound-eye cameras can be implemented using existing CMOS or CCD image-sensor arrays. Each pixel will be coated with a different metasurface designed to allow for the detection of light from a different direction. The proposed angle-sensitive photodetectors will be designed via full-wave numerical simulations, fabricated on silicon substrates, and characterized through angle-resolved photocurrent measurements. Arrays of these devices will then be developed for a proof-of-concept demonstration of their imaging capabilities. Advanced computational imaging algorithms will be employed to optimize the image reconstruction from the combined signals of the individual sensors. In addition to the potential technological impact of the proposed cameras, this research will also advance the science and technology of optical metasurfaces through the exploration of novel designs and applications, and will create new research opportunities in the emerging field of computational imaging.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Roberto",
   "pi_last_name": "Paiella",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Roberto Paiella",
   "pi_email_addr": "rpaiella@bu.edu",
   "nsf_id": "000118107",
   "pi_start_date": "2017-07-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Lei",
   "pi_last_name": "Tian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lei Tian",
   "pi_email_addr": "leitian@bu.edu",
   "nsf_id": "000727300",
   "pi_start_date": "2017-07-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Trustees of Boston University",
  "inst_street_address": "1 SILBER WAY",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173534365",
  "inst_zip_code": "022151703",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "TRUSTEES OF BOSTON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "THL6A6JLE1S7"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of Boston University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "022151300",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "151700",
   "pgm_ele_name": "EPMD-ElectrnPhoton&MagnDevices"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "091E",
   "pgm_ref_txt": "Light generation & detection"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 379953.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The compound-eye vision system, which is universally found in nature among the smallest animal species such as insects and crustaceans, consists of a dense array of individual imaging elements (called ommatidia) pointing along different directions.&nbsp; Compared to single-aperture imaging systems, such as the human eye and traditional cameras, this arrangement is particularly attractive for applications that require extreme size miniaturization, wide-angle fields of view, and high sensitivity to motion.&nbsp; Specific examples of high relevance and timeliness include chip-on-the-tip endoscopy, surveillance, wearable and swallowable cameras, and drone autonomous navigation.&nbsp;&nbsp; However, the implementation of cameras directly mimicking the compound eyes of common arthropods has been complicated by their curved geometry, which is not directly compatible with traditional optoelectronic fabrication processes.&nbsp;</p>\n<p>The main outcome of this research project is the demonstration of a radically different approach for the development of artificial compound eyes, based on standard image sensors combined with specially designed metasurfaces in a lensless planar architecture.&nbsp; Metasurfaces in general consist of two-dimensional arrays of optical nanoantennas that can control the flow of incident light according to desired specifications.&nbsp; In the devices developed in this project, the metasurfaces are designed to couple light incident along a specific direction into surface waves (plasmon polaritons), which are then scattered into the underlying photodetector active region where they can be absorbed to produce a photocurrent signal.&nbsp; Light incident along any other direction is instead reflected away from the device.&nbsp; The resulting image sensors are therefore functionally equivalent to the compound-eye ommatidia, while at the same time featuring a flat geometry without any lenses.&nbsp;</p>\n<p>Several devices with different angles of peak photodetection were developed and characterized, showing high angular sensitivity in good agreement with design simulations (Fig. 1).&nbsp; Their compound-eye imaging capabilities were then evaluated via computational imaging simulations based on the measured angle-resolved responsivity maps.&nbsp; The simulation results show that arrays of these directional photodetectors can produce high-quality images of complex scenes over an ultrawide field of view of about 150 degrees (Fig. 2).&nbsp; Importantly, these devices can be integrated on existing CMOS or CCD sensor arrays with standard fabrication processes.&nbsp; Their ability to create an image without any lens also provides additional miniaturization, since the resulting cameras are essentially as thin as their constituent photodetectors.&nbsp; Furthermore, this work also highlights the tremendous opportunities offered by the synergistic combination of metasurface flat optics and computational imaging, as a way to enable entirely new imaging systems with expanded functionalities.&nbsp; Additional project outcomes include the development of similar metasurfaces designed to promote directional light emission, and the initial exploration of new imaging capabilities enabled by angle-sensitive photodetectors.</p>\n<p>These activities have been carried out by six Ph.D. students at Boston University (including a member of an underrepresented minority), thereby contributing to their professional development and progress towards graduation.&nbsp; Several undergraduate students have also participated in related research endeavors, and in the process have gained valuable exposure to state-of-the-art computational imaging simulations and nanophotonics design.&nbsp;&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/03/2022<br>\n\t\t\t\t\tModified by: Roberto&nbsp;Paiella</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1711156/1711156_10499787_1659565270109_PORFig1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1711156/1711156_10499787_1659565270109_PORFig1--rgov-800width.jpg\" title=\"Fig. 1. Plasmonic directional image sensors\"><img src=\"/por/images/Reports/POR/2022/1711156/1711156_10499787_1659565270109_PORFig1--rgov-66x44.jpg\" alt=\"Fig. 1. Plasmonic directional image sensors\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">(a) Schematic device geometry and operation principle. (b)-(d) Optical and scanning-electron-microscopy images of an experimental sample. (e)-(g) Measured photocurrent versus illumination angles of three different devices designed to provide peak response at three different angles.</div>\n<div class=\"imageCredit\">Roberto Paiella and Lei Tian (Boston University)</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Roberto&nbsp;Paiella</div>\n<div class=\"imageTitle\">Fig. 1. Plasmonic directional image sensors</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1711156/1711156_10499787_1659565403480_PORFig2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1711156/1711156_10499787_1659565403480_PORFig2--rgov-800width.jpg\" title=\"Fig. 2. Compound-eye-camera data acquisition and image reconstruction\"><img src=\"/por/images/Reports/POR/2022/1711156/1711156_10499787_1659565403480_PORFig2--rgov-66x44.jpg\" alt=\"Fig. 2. Compound-eye-camera data acquisition and image reconstruction\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">(a) Imaging geometry. (b) Image reconstruction model. (c) Left column: representative objects imaged over an ultrawide field of view of 150 degrees. Middle: images reconstructed based on the calculated angular response maps. Right: images reconstructed based on the measured angular response maps.</div>\n<div class=\"imageCredit\">Roberto Paiella and Lei Tian (Boston University)</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Roberto&nbsp;Paiella</div>\n<div class=\"imageTitle\">Fig. 2. Compound-eye-camera data acquisition and image reconstruction</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe compound-eye vision system, which is universally found in nature among the smallest animal species such as insects and crustaceans, consists of a dense array of individual imaging elements (called ommatidia) pointing along different directions.  Compared to single-aperture imaging systems, such as the human eye and traditional cameras, this arrangement is particularly attractive for applications that require extreme size miniaturization, wide-angle fields of view, and high sensitivity to motion.  Specific examples of high relevance and timeliness include chip-on-the-tip endoscopy, surveillance, wearable and swallowable cameras, and drone autonomous navigation.   However, the implementation of cameras directly mimicking the compound eyes of common arthropods has been complicated by their curved geometry, which is not directly compatible with traditional optoelectronic fabrication processes. \n\nThe main outcome of this research project is the demonstration of a radically different approach for the development of artificial compound eyes, based on standard image sensors combined with specially designed metasurfaces in a lensless planar architecture.  Metasurfaces in general consist of two-dimensional arrays of optical nanoantennas that can control the flow of incident light according to desired specifications.  In the devices developed in this project, the metasurfaces are designed to couple light incident along a specific direction into surface waves (plasmon polaritons), which are then scattered into the underlying photodetector active region where they can be absorbed to produce a photocurrent signal.  Light incident along any other direction is instead reflected away from the device.  The resulting image sensors are therefore functionally equivalent to the compound-eye ommatidia, while at the same time featuring a flat geometry without any lenses. \n\nSeveral devices with different angles of peak photodetection were developed and characterized, showing high angular sensitivity in good agreement with design simulations (Fig. 1).  Their compound-eye imaging capabilities were then evaluated via computational imaging simulations based on the measured angle-resolved responsivity maps.  The simulation results show that arrays of these directional photodetectors can produce high-quality images of complex scenes over an ultrawide field of view of about 150 degrees (Fig. 2).  Importantly, these devices can be integrated on existing CMOS or CCD sensor arrays with standard fabrication processes.  Their ability to create an image without any lens also provides additional miniaturization, since the resulting cameras are essentially as thin as their constituent photodetectors.  Furthermore, this work also highlights the tremendous opportunities offered by the synergistic combination of metasurface flat optics and computational imaging, as a way to enable entirely new imaging systems with expanded functionalities.  Additional project outcomes include the development of similar metasurfaces designed to promote directional light emission, and the initial exploration of new imaging capabilities enabled by angle-sensitive photodetectors.\n\nThese activities have been carried out by six Ph.D. students at Boston University (including a member of an underrepresented minority), thereby contributing to their professional development and progress towards graduation.  Several undergraduate students have also participated in related research endeavors, and in the process have gained valuable exposure to state-of-the-art computational imaging simulations and nanophotonics design.  \n\n \n\n\t\t\t\t\tLast Modified: 08/03/2022\n\n\t\t\t\t\tSubmitted by: Roberto Paiella"
 }
}