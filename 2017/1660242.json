{
 "awd_id": "1660242",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase II:  Closing the Digital Divide: Real-Time Multisensory Learning for Special Education Students",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922174",
 "po_email": "rmehta@nsf.gov",
 "po_sign_block_name": "Rajesh Mehta",
 "awd_eff_date": "2017-03-15",
 "awd_exp_date": "2020-02-29",
 "tot_intn_awd_amt": 742148.0,
 "awd_amount": 752148.0,
 "awd_min_amd_letter_date": "2017-03-14",
 "awd_max_amd_letter_date": "2018-02-28",
 "awd_abstract_narration": "This project creates an educational, touchscreen-based software that translates visual educational content into accessible, multisensory content for students with special needs, and particularly those with blindness and visual impairments. Consider the challenge in the educational landscape today: schools are increasingly adopting digital tools oriented toward creating a more interactive, personalized experience for mainstream students, but at the same time, are struggling to accommodate their diverse student population, particularly, the 6 million students in special education in the U.S. This problem is exaggerated in Science, Technology, Engineering, and Math (STEM), where content is often complex and visual. This project addresses these challenges, building on what we already know about human information processing and haptic interfaces to create software that will automatically convert highly visual content into content that can be seen, heard, and felt in real-time in class. This project supports NSF?s mission ensuring that inclusion of all students is at the forefront of the digital transformation of U.S. classrooms. The societal impacts of this work overcome several barriers impeding students with special needs from being independent and active contributors in the STEM educational experience and ultimately, many STEM professions. ViTAL projects a direct, financial return on investment for taxpayers within three years of operations, generating both revenue and new jobs, with plans to multiply this growth year over year. \r\n\r\n\r\nThe innovation in this project is the creation of methods and algorithms for effective translation of visual content into multimodal content, appropriately down sampled for the nonvisual sensory channels yet effective in conveying the most meaningful information. Such a conversion currently does not exist, which results in high overhead costs to create accessible graphics and is a major pain point in special education, particularly for individuals with visual impairments or blindness. Further, translating graphical content from the visual to the multimodal (visual, auditory, and haptic) space is not a straightforward conversion due to the limited bandwidth of human touch compared to vision and the complexity of features presented in graphical information. This challenge is exaggerated when accounting for the varying types of haptic feedback that can be provided from varying platforms (Android and iOS). This project addresses these challenges, creating a streamlined solution for generating accessible, multisensory content, in real-time, on commercial platforms for K-12 classrooms. The outcomes of this project will (1) create the algorithms needed to provide an automated conversion from the visual to multimodal space, (2) establish a teacher \"dashboard\" to streamline the proposed software?s integration in the classroom, and (3) expand the software to the iOS market while simultaneously uncovering novel haptic effects that leverage Apple?s unique Taptic feedback. Upon completion of the development, the software will be beta tested with partnering schools, and then released on both Android and iOS markets.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Corrine",
   "pi_last_name": "Mueller",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Corrine M Mueller",
   "pi_email_addr": "corrine@vital-ed.com",
   "nsf_id": "000697969",
   "pi_start_date": "2017-03-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "JLG Innovations Inc.",
  "inst_street_address": "920 N 7TH ST",
  "inst_street_address_2": "",
  "inst_city_name": "BREESE",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "6183632323",
  "inst_zip_code": "622301335",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "IL12",
  "org_lgl_bus_name": "JLG INNOVATIONS INC",
  "org_prnt_uei_num": "",
  "org_uei_num": "JQC9MB2MA378"
 },
 "perf_inst": {
  "perf_inst_name": "Lexow Financial Group",
  "perf_str_addr": "60 S State Route 157",
  "perf_city_name": "Edwardsville",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "620253846",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537300",
   "pgm_ele_name": "SBIR Phase II"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5373",
   "pgm_ref_txt": "SMALL BUSINESS PHASE II"
  },
  {
   "pgm_ref_code": "8031",
   "pgm_ref_txt": "Education Products"
  },
  {
   "pgm_ref_code": "8032",
   "pgm_ref_txt": "Software Services and Applications"
  },
  {
   "pgm_ref_code": "8039",
   "pgm_ref_txt": "Information, Communication & Computing"
  },
  {
   "pgm_ref_code": "8240",
   "pgm_ref_txt": "SBIR/STTR CAP"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 742148.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 10000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This SBIR Phase II project created and commercialized an educational software that transforms digital learning materials into interactive learning content that can be displayed on touchscreens. Consider the challenge in the educational landscape today: schools are increasingly adopting electronic tools and digital content to provide a more personalized student experience, but at the same time, are struggling to accommodate their diverse student population. This shift to the digital world is removing the essential hands-on component that is so valuable for all students, while also being largely inaccessible to the six million K-12 special education students in the United States, especially those with blindness and visual impairments (BVI).</p>\n<p>JLG Innovations Inc. (JLG) began the mission to transform learning content from static, visual representations into interactive, multimodal experiences, with a specific focus on making content accessible to learners of all abilities, especially those with BVI. The team carried out both technical and commercial efforts to bring their vision of digital, multimodal graphics to market through the Small Business Innovation Research (SBIR) Phase I, Phase IB and this Phase II project.</p>\n<p>Through the work completed in this Phase II project, JLG developed and released into the marketplace the Vital Software Suite. Vital is composed of three applications: (1) The Content Creator &ndash; web application; (2) Vital Android App &ndash; mobile application; and (3) Vital iOS App &ndash; mobile application. These three interfaces provide a two-part software solution: a teacher-facing creation tool and a student-facing exploration tool. The Content Creator is a teacher tool for creating digital, multisensory graphics. With libraries of haptic and auditory sounds, the teacher chooses the multisensory feedback to add to uploaded images. Teachers have the option to either markup the images manually with semi-automated tools such as Optical Character Recognition (OCR), which automatically finds the text in the image, or the Eye Dropper, which auto-detects parts of the image by color and adds the selected feedback; or teachers can use the Automated Image Wizard for a select number of image types (bar graphs, line graphs, circle graphs/parts of a whole/fractions, and tables) and automatically generate a multisensory image from data input. The Content Creator allows teachers to manage and share content with students via a teacher and student pairing. Students open the shared content either on the Android or iOS mobile app, which is fully functional with TalkBack and VoiceOver for easy navigation for students who are blind and visually impaired (BVI). Students explore the images by feeling vibrations and hearing sonification and audio sounds. This tactile exploration allows a student to build a mental image of the graphic displayed visually on the tablet screen.</p>\n<p>JLG also developed Quick Sketch, a teacher tool included in the Android and iOS apps and a teacher-requested creation method that allows on-the-fly markup of images. Teachers stated that while sitting in class with a student for individualized instruction, they often are given materials in that instance and need to quickly convert the print or digital content into an accessible version. With Quick Sketch, teachers snap a picture of the print image or upload a digital image and add haptic, audio and text feedback with a stylus or their finger. With the touch of the Explore button, the teacher hands the tablet to the student for exploration, and more importantly, participation in class.&nbsp;</p>\n<p>The software solutions developed and commercialized in this SBIR Phase II ensure schools meet federal accessibility mandates while creating the next generation, inclusive classroom.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/29/2020<br>\n\t\t\t\t\tModified by: Corrine&nbsp;M&nbsp;Mueller</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis SBIR Phase II project created and commercialized an educational software that transforms digital learning materials into interactive learning content that can be displayed on touchscreens. Consider the challenge in the educational landscape today: schools are increasingly adopting electronic tools and digital content to provide a more personalized student experience, but at the same time, are struggling to accommodate their diverse student population. This shift to the digital world is removing the essential hands-on component that is so valuable for all students, while also being largely inaccessible to the six million K-12 special education students in the United States, especially those with blindness and visual impairments (BVI).\n\nJLG Innovations Inc. (JLG) began the mission to transform learning content from static, visual representations into interactive, multimodal experiences, with a specific focus on making content accessible to learners of all abilities, especially those with BVI. The team carried out both technical and commercial efforts to bring their vision of digital, multimodal graphics to market through the Small Business Innovation Research (SBIR) Phase I, Phase IB and this Phase II project.\n\nThrough the work completed in this Phase II project, JLG developed and released into the marketplace the Vital Software Suite. Vital is composed of three applications: (1) The Content Creator &ndash; web application; (2) Vital Android App &ndash; mobile application; and (3) Vital iOS App &ndash; mobile application. These three interfaces provide a two-part software solution: a teacher-facing creation tool and a student-facing exploration tool. The Content Creator is a teacher tool for creating digital, multisensory graphics. With libraries of haptic and auditory sounds, the teacher chooses the multisensory feedback to add to uploaded images. Teachers have the option to either markup the images manually with semi-automated tools such as Optical Character Recognition (OCR), which automatically finds the text in the image, or the Eye Dropper, which auto-detects parts of the image by color and adds the selected feedback; or teachers can use the Automated Image Wizard for a select number of image types (bar graphs, line graphs, circle graphs/parts of a whole/fractions, and tables) and automatically generate a multisensory image from data input. The Content Creator allows teachers to manage and share content with students via a teacher and student pairing. Students open the shared content either on the Android or iOS mobile app, which is fully functional with TalkBack and VoiceOver for easy navigation for students who are blind and visually impaired (BVI). Students explore the images by feeling vibrations and hearing sonification and audio sounds. This tactile exploration allows a student to build a mental image of the graphic displayed visually on the tablet screen.\n\nJLG also developed Quick Sketch, a teacher tool included in the Android and iOS apps and a teacher-requested creation method that allows on-the-fly markup of images. Teachers stated that while sitting in class with a student for individualized instruction, they often are given materials in that instance and need to quickly convert the print or digital content into an accessible version. With Quick Sketch, teachers snap a picture of the print image or upload a digital image and add haptic, audio and text feedback with a stylus or their finger. With the touch of the Explore button, the teacher hands the tablet to the student for exploration, and more importantly, participation in class. \n\nThe software solutions developed and commercialized in this SBIR Phase II ensure schools meet federal accessibility mandates while creating the next generation, inclusive classroom.\n\n\t\t\t\t\tLast Modified: 06/29/2020\n\n\t\t\t\t\tSubmitted by: Corrine M Mueller"
 }
}