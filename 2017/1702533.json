{
 "awd_id": "1702533",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "PostDoctoral Research Fellowship",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922599",
 "po_email": "sgdewint@nsf.gov",
 "po_sign_block_name": "Stefaan De Winter",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2017-03-14",
 "awd_max_amd_letter_date": "2017-03-14",
 "awd_abstract_narration": "This award is made as part of the FY 2017 Mathematical Sciences Postdoctoral Research Fellowships Program. Each of the fellowships supports a research and training project at a host institution in the mathematical sciences, including applications to other disciplines, under the mentorship of a sponsoring scientist. The title of the project for this fellowship to Kyle Luh is \"Discrete Random Matrices, Sparse Random Matrices, and Their Applications.\" The host institution for the fellowship is Harvard University, and the sponsoring scientist is Jelani Nelson.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kyle",
   "pi_last_name": "Luh",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Kyle J Luh",
   "pi_email_addr": "",
   "nsf_id": "000731044",
   "pi_start_date": "2017-03-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Luh                     Kyle           J",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "New Haven",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "",
  "inst_zip_code": "065208283",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "CT03",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University",
  "perf_str_addr": null,
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021382901",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "060Y00",
   "pgm_ele_name": "Workforce (MSPRF) MathSciPDFel"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9219",
   "pgm_ref_txt": "POSTDOCTORAL FELLOWSHIPS IN MATH SCIENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Random matrices are now ubiquitous in mathematics and the sciences.&nbsp; As the field progresses and technology evolves, new questions arise.&nbsp; In the digital age, computers deal with noisy inputs and are now asked to store monumental amounts of data.&nbsp; The noise that computers are confronted with are no longer smooth distributions like bell curves that appear in classical error analysis.&nbsp; Rather, the noise is discrete, often flipping a one to a zero or vice versa.&nbsp; Discrete random matrices can be used to model this noise.&nbsp; Large amounts of data are easily stored if they are sparse, meaning most of the entries are zero.&nbsp; Many natural operations such as matrix multiplication are much faster when dealing with sparse matrices.&nbsp; This sparsity occurs naturally in many physical applications and in computer science.&nbsp; They often represent the notion that a complex phenomenon only depends on a few parameters.&nbsp; For example, as refined as our movie selecting tastes may be, it turns out that the preferences of most people can be predicted with only a few parameters.&nbsp; Sparse random matrices arise in these settings.</p>\n<p>The goals of this project were to delve into the behavior of discrete and sparse random matrices.&nbsp; The project resulted in over 10 publications and several more articles that are awaiting responses from journals.&nbsp; The PI made several advances on both discrete and sparse random matrices.&nbsp; Some of the applications include the compression of data, quantum algorithms and high dimensional statistics.&nbsp; Surprisingly, some of the results on random matrices shed light on the controllability of large networks.&nbsp; This roughly translates to the efficient understanding of networks like the internet from only a few measurements.&nbsp; The mathematical ideas generated from the project have spurred activity in pure mathematics and will likely lead to future projects from the PI and the community.</p>\n<p>The PI disseminated the research to mathematicians, physicists and engineers.&nbsp; This led to several productive interdisciplinary projects.&nbsp; Some of them are still ongoing.&nbsp; The PI also invested time in giving expository talks to undergraduates.&nbsp; This introduced the beautiful ideas in random matrix theory to future generations of mathematicians.&nbsp; The PI had the opportunity to mentor several undergraduates and expose them to their first taste of mathematical research.&nbsp; Several of these undergraduates have decided to pursue careers in research.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/25/2020<br>\n\t\t\t\t\tModified by: Kyle&nbsp;J&nbsp;Luh</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nRandom matrices are now ubiquitous in mathematics and the sciences.  As the field progresses and technology evolves, new questions arise.  In the digital age, computers deal with noisy inputs and are now asked to store monumental amounts of data.  The noise that computers are confronted with are no longer smooth distributions like bell curves that appear in classical error analysis.  Rather, the noise is discrete, often flipping a one to a zero or vice versa.  Discrete random matrices can be used to model this noise.  Large amounts of data are easily stored if they are sparse, meaning most of the entries are zero.  Many natural operations such as matrix multiplication are much faster when dealing with sparse matrices.  This sparsity occurs naturally in many physical applications and in computer science.  They often represent the notion that a complex phenomenon only depends on a few parameters.  For example, as refined as our movie selecting tastes may be, it turns out that the preferences of most people can be predicted with only a few parameters.  Sparse random matrices arise in these settings.\n\nThe goals of this project were to delve into the behavior of discrete and sparse random matrices.  The project resulted in over 10 publications and several more articles that are awaiting responses from journals.  The PI made several advances on both discrete and sparse random matrices.  Some of the applications include the compression of data, quantum algorithms and high dimensional statistics.  Surprisingly, some of the results on random matrices shed light on the controllability of large networks.  This roughly translates to the efficient understanding of networks like the internet from only a few measurements.  The mathematical ideas generated from the project have spurred activity in pure mathematics and will likely lead to future projects from the PI and the community.\n\nThe PI disseminated the research to mathematicians, physicists and engineers.  This led to several productive interdisciplinary projects.  Some of them are still ongoing.  The PI also invested time in giving expository talks to undergraduates.  This introduced the beautiful ideas in random matrix theory to future generations of mathematicians.  The PI had the opportunity to mentor several undergraduates and expose them to their first taste of mathematical research.  Several of these undergraduates have decided to pursue careers in research.\n\n \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 07/25/2020\n\n\t\t\t\t\tSubmitted by: Kyle J Luh"
 }
}