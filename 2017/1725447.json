{
 "awd_id": "1725447",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SPX: Collaborative Research: Ula! - An Integrated Deep Neural Network (DNN) Acceleration Framework with Enhanced Unsupervised Learning Capability",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yuanyuan Yang",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 280000.0,
 "awd_amount": 280000.0,
 "awd_min_amd_letter_date": "2017-07-22",
 "awd_max_amd_letter_date": "2017-07-22",
 "awd_abstract_narration": "In light of very recent revolutions of unsupervised learning algorithms (e.g., generative adversarial networks and dual-learning) and the emergence of their applications, three PIs/co-PI from Duke and UCSB form a team to design Ula! - an integrated DNN acceleration framework with enhanced unsupervised learning capability. The project revolutionizes the DNN research by introducing an integrated unsupervised learning computation framework with three vertically-integrated components from the aspects of software (algorithm), hardware (computing), and application (realization). The project echoes the call from the BRAIN Initiative (2013) and the Nanotechnology-Inspired Grand Challenge for Future Computing (2015) from the White House. The research outcomes will benefit both Computational Intelligence (CI) and Computer Architecture (CA) industries at large by introducing a synergy between computing paradigm and artificial intelligence (AI). The corresponding education components\u00a0 enhance existing curricula and pedagogy by introducing interdisciplinary modules on the software/hardware co-design for AI with creative teaching practices, and give special attentions to women and underrepresented minority groups.\r\n\r\nThe project performs three tasks: (1) At the software level, a generalized hierarchical decision-making (GHDM) system is designed to efficiently execute the state-of-the-art unsupervised learning and reinforcement learning processes with substantially reduced computation cost; (2) At the hardware level, a novel DNN computing paradigm is designed with enhanced unsupervised learning supports, based on the novelties in near data computing, GPU architecture, and FGPA + heterogeneous platforms; (3) At the application level, the usage of Ula! is exploited in scenarios that can greatly benefit from unsupervised learning and reinforcement learning. The developed techniques are also demonstrated and evaluated on three representative computing platforms: GPU, FPGA, and emerging nanoscale computing systems, respectively.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yuan",
   "pi_last_name": "Xie",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yuan Xie",
   "pi_email_addr": "yuanxie@ece.ucsb.edu",
   "nsf_id": "000203143",
   "pi_start_date": "2017-07-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Barbara",
  "inst_street_address": "3227 CHEADLE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA BARBARA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8058934188",
  "inst_zip_code": "931060001",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SANTA BARBARA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G9QBQDH39DF4"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Barbara",
  "perf_str_addr": "Electrical & Computer Engr",
  "perf_city_name": "Santa Barbara",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "931069560",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 280000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-cf197ea4-7fff-20bd-ae15-27d1ef8633ea\"> </span></p>\n<p dir=\"ltr\"><span>After almost two decades of stagnation, Artificial Intelligence (AI) now is embracing another peak in its history. The fast-developing deep learning (DL) techniques and their wide deployment serves as the main driving force of this new technology wave. One major challenge in applications of DL is the high demand for computing resources. The training/learning phase is particularly slow and may last a couple of months in some complex applications. In this proposal, we propose to design an integrated deep neural network (DNN) acceleration framework with enhanced unsupervised learning capability. We will explore three vertically-integrated components that cover the aspects of software (algorithm), hardware (computing), and application (realization) of this framework.&nbsp;</span></p>\n<p dir=\"ltr\"><strong>Major research findings: </strong><span>In this research, we first explored efficient DL algorithms like dynamic sparsity in DL training and inference, tensor network. We then looked into the hardware side and proposed several architectures (e.g., near-memory accelerator, dual module architecture) for efficient DL execution. We explored the architectural modeling of DL platforms with new simulation technology and applied DL to the hardware architecture design.&nbsp; We also looked into the DL security problem and proposed several techniques to prevent the memory trojaning attack on DL models.</span></p>\n<p dir=\"ltr\"><strong>Broader impacts: </strong><span>Our research will benefit both Computational Intelligence and Computer Architecture industries at large by introducing a synergy between computing paradigm and AI and echoes the national pride in this direction. The results can further benefit both societies by guiding the software and hardware co-development toward building human-level intelligence for solving complex cognitive problems. We expect that this project will pave the design methodology foundation of the future intelligent computing systems by leveraging integrated innovations from both hardware and software perspectives, and accelerate the commercialization with substantially enhanced learning capability. The education plan will enhance existing curricula and pedagogy by integrating interdisciplinary modules on the software/hardware co-design for AI with creative teaching practices. The materials created in the research were incorporated into two graduate-level courses in UCSB, ECE254A, \"Advanced Computer Architecture\", to help students learn the latest research outcome and help recruit new students.</span></p>\n<p><span>The research funding has enabled graduate student training by supporting three graduate students and two postdoc scholars (including one female postdoc scholar). They have proposed several DL algorithm and hardware architecture techniques targeting various AI application scenarios. 35 research papers have been published at top computer architecture/design automation conferences and journals. The research outcomes are available at </span><a href=\"https://seal.ece.ucsb.edu/\"><span>https://seal.ece.ucsb.edu/</span></a><span> for public access. The students trained in this project and their collaboration with interdisciplinary groups, international partners and industry mentors should well prepare them for the next generation workforce.</span><span><span> </span></span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/28/2022<br>\n\t\t\t\t\tModified by: Yuan&nbsp;Xie</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nAfter almost two decades of stagnation, Artificial Intelligence (AI) now is embracing another peak in its history. The fast-developing deep learning (DL) techniques and their wide deployment serves as the main driving force of this new technology wave. One major challenge in applications of DL is the high demand for computing resources. The training/learning phase is particularly slow and may last a couple of months in some complex applications. In this proposal, we propose to design an integrated deep neural network (DNN) acceleration framework with enhanced unsupervised learning capability. We will explore three vertically-integrated components that cover the aspects of software (algorithm), hardware (computing), and application (realization) of this framework. \nMajor research findings: In this research, we first explored efficient DL algorithms like dynamic sparsity in DL training and inference, tensor network. We then looked into the hardware side and proposed several architectures (e.g., near-memory accelerator, dual module architecture) for efficient DL execution. We explored the architectural modeling of DL platforms with new simulation technology and applied DL to the hardware architecture design.  We also looked into the DL security problem and proposed several techniques to prevent the memory trojaning attack on DL models.\nBroader impacts: Our research will benefit both Computational Intelligence and Computer Architecture industries at large by introducing a synergy between computing paradigm and AI and echoes the national pride in this direction. The results can further benefit both societies by guiding the software and hardware co-development toward building human-level intelligence for solving complex cognitive problems. We expect that this project will pave the design methodology foundation of the future intelligent computing systems by leveraging integrated innovations from both hardware and software perspectives, and accelerate the commercialization with substantially enhanced learning capability. The education plan will enhance existing curricula and pedagogy by integrating interdisciplinary modules on the software/hardware co-design for AI with creative teaching practices. The materials created in the research were incorporated into two graduate-level courses in UCSB, ECE254A, \"Advanced Computer Architecture\", to help students learn the latest research outcome and help recruit new students.\n\nThe research funding has enabled graduate student training by supporting three graduate students and two postdoc scholars (including one female postdoc scholar). They have proposed several DL algorithm and hardware architecture techniques targeting various AI application scenarios. 35 research papers have been published at top computer architecture/design automation conferences and journals. The research outcomes are available at https://seal.ece.ucsb.edu/ for public access. The students trained in this project and their collaboration with interdisciplinary groups, international partners and industry mentors should well prepare them for the next generation workforce. \n\n \n\n \n\n\t\t\t\t\tLast Modified: 01/28/2022\n\n\t\t\t\t\tSubmitted by: Yuan Xie"
 }
}