{
 "awd_id": "1734245",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBE-RCUK: CompCog: Modeling the Development of Phonetic Representations",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 520058.0,
 "awd_amount": 520058.0,
 "awd_min_amd_letter_date": "2017-06-22",
 "awd_max_amd_letter_date": "2017-06-22",
 "awd_abstract_narration": "Listeners' processing of speech is tuned to their native language. For example, Japanese listeners categorizing English [l] and [r] do not rely on the same aspects of the speech signal that native English listeners do. This project uses computational models to investigate how children develop language-specific perceptual strategies. A better understanding of this perceptual learning process could lead to better diagnosis and treatment of developmental language impairments that have a perceptual basis and can provide insight into the difficulties that listeners face when learning a second language in adulthood. Building computational models of how children learn their native language from the speech around them can also lead to improved speech technology for low-resource languages (languages that are not spoken by many people in the world or that lack digital resources such as large-scale, annotated databases), ultimately leading to systems that learn more effectively using little or no transcribed audio. Such systems could become important tools for documenting and analyzing endangered and minority languages and could help make speech technology more universally available.\r\n\r\nA series of simulations tests the hypothesis that children's processing of speech can become specialized for their native language through a process of dimension learning that does not rely on knowledge of sound categories. Two models that use dimension learning are proposed, drawing on representation learning methods that have performed well in low-resource automatic speech recognition, where extensive labeled training data are not available. The first model relies on temporal information as a proxy for sound category knowledge, while the second model relies on top-down information from similar words, which infants have been shown to use. Each model is trained on speech recordings from a particular language and is evaluated on its ability to predict how adults and infants with that language background discriminate sounds. The research will yield new methods for training and testing cognitive models of language with naturalistic speech recordings and has the potential to significantly impact theories of how and when children learn about the sounds of their native language.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Naomi",
   "pi_last_name": "Feldman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Naomi Feldman",
   "pi_email_addr": "nhf@umd.edu",
   "nsf_id": "000622351",
   "pi_start_date": "2017-06-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "1401 Marie Mount Hall",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425141",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  },
  {
   "pgm_ele_code": "169800",
   "pgm_ele_name": "DS -Developmental Sciences"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "003Z",
   "pgm_ref_txt": "SBE-RCUK MOU"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 520058.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-8d1f4ba0-7fff-9344-ca73-0ed2afae3740\" style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Research conducted under this project used computational models to build theories of what infants learn about the sounds in their native language(s) during their first year of life.&nbsp; Several models were built to simulate infant learners.&nbsp; Those models were exposed to natural speech in a more realistic way than previous models, and they were tested on their linguistic knowledge in ways similar to infants.</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The results from these modeling simulations could have a very large impact on theories of infant language learning.&nbsp; Previous theories have interpreted cross-linguistic differences in infants' perception -- for example, English-learning 12-month-olds can discriminate 'r' (as in rock) from 'l' (as in lock) better than Japanese-learning infants can -- as evidence that infants already know which phonetic categories, like 'r' or 'l', are used in their language.&nbsp; Several models built as part of this project showed the same cross-linguistic differences that infants do, but did not have the same type of phonetic category knowledge that had previously been hypothesized.&nbsp; For example, models trained on English speech did not know categories like 'r' or 'l', but were still better than the models trained on Japanese speech at discriminating these sounds.&nbsp; This means that the observed cross-linguistic differences in infants' discrimination are not necessarily evidence that infants know phonetic categories like 'r' and 'l'.&nbsp; That finding could radically impact theories of what infants know at the beginning of their second year of life.</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Building models that learn from natural speech also led to other types of advances.&nbsp; For example, it led to the discovery of new information sources -- present in highly variable natural speech, but absent in the controlled laboratory speech that researchers often study -- that children could use when learning about the speech sounds of their native language(s).&nbsp; It also facilitated the development of new techniques for making robust model-based predictions about how infants are likely to behave in laboratory experiments.&nbsp; Such techniques could increase the scientific impact of any future modeling simulations, by making it easier to test hypotheses about what infants know.&nbsp; Finally, the project led to the development of new techniques for building speech technology without large quantities of annotated speech data.&nbsp; This can potentially lead to improved speech technology for a wider range of languages, including endangered and minority languages, in the future.</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The project has led to enhanced opportunities for student training.&nbsp; Results from the project have already been incorporated into linguistics courses at the University of Maryland.&nbsp; Members of the project team published a \"perspectives\" article in Open Mind, a freely available open access journal, that lays out the new theory in a way that is likely to be accessible to advanced undergraduates, and can be used in courses at other universities.&nbsp; Postdoctoral researchers and students who were directly involved in the project learned new, state-of-the art methods for conducting research in language acquisition using techniques from computer science for working with large-scale data; their expertise has already been helpful in training others in the community to conduct research at the boundary between these disciplines.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/04/2022<br>\n\t\t\t\t\tModified by: Naomi&nbsp;Feldman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Research conducted under this project used computational models to build theories of what infants learn about the sounds in their native language(s) during their first year of life.  Several models were built to simulate infant learners.  Those models were exposed to natural speech in a more realistic way than previous models, and they were tested on their linguistic knowledge in ways similar to infants.\n\n \nThe results from these modeling simulations could have a very large impact on theories of infant language learning.  Previous theories have interpreted cross-linguistic differences in infants' perception -- for example, English-learning 12-month-olds can discriminate 'r' (as in rock) from 'l' (as in lock) better than Japanese-learning infants can -- as evidence that infants already know which phonetic categories, like 'r' or 'l', are used in their language.  Several models built as part of this project showed the same cross-linguistic differences that infants do, but did not have the same type of phonetic category knowledge that had previously been hypothesized.  For example, models trained on English speech did not know categories like 'r' or 'l', but were still better than the models trained on Japanese speech at discriminating these sounds.  This means that the observed cross-linguistic differences in infants' discrimination are not necessarily evidence that infants know phonetic categories like 'r' and 'l'.  That finding could radically impact theories of what infants know at the beginning of their second year of life.\n\n \nBuilding models that learn from natural speech also led to other types of advances.  For example, it led to the discovery of new information sources -- present in highly variable natural speech, but absent in the controlled laboratory speech that researchers often study -- that children could use when learning about the speech sounds of their native language(s).  It also facilitated the development of new techniques for making robust model-based predictions about how infants are likely to behave in laboratory experiments.  Such techniques could increase the scientific impact of any future modeling simulations, by making it easier to test hypotheses about what infants know.  Finally, the project led to the development of new techniques for building speech technology without large quantities of annotated speech data.  This can potentially lead to improved speech technology for a wider range of languages, including endangered and minority languages, in the future.\n\n \nThe project has led to enhanced opportunities for student training.  Results from the project have already been incorporated into linguistics courses at the University of Maryland.  Members of the project team published a \"perspectives\" article in Open Mind, a freely available open access journal, that lays out the new theory in a way that is likely to be accessible to advanced undergraduates, and can be used in courses at other universities.  Postdoctoral researchers and students who were directly involved in the project learned new, state-of-the art methods for conducting research in language acquisition using techniques from computer science for working with large-scale data; their expertise has already been helpful in training others in the community to conduct research at the boundary between these disciplines.\n\n\t\t\t\t\tLast Modified: 01/04/2022\n\n\t\t\t\t\tSubmitted by: Naomi Feldman"
 }
}