{
 "awd_id": "1725663",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SPX: Collaborative Research: Multicore to Wide Area Analytics on Streaming Data",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2017-08-15",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 492000.0,
 "awd_amount": 492000.0,
 "awd_min_amd_letter_date": "2017-08-02",
 "awd_max_amd_letter_date": "2017-08-02",
 "awd_abstract_narration": "In today's big data era, there is an urgent need for methods that can quickly derive analytical insights from large volumes of data that are continuously generated.  Such streaming data include video, audio, activity logs, and sensor data, and are generated on a massive scale all over the world.  The need for real-time streaming analytics can only be fulfilled with the help of appropriately designed parallel and distributed algorithms. However, parallel and distributed computing systems come in a variety of shapes and sizes, and algorithms should be designed to match the characteristics of the underlying system. This project develops methods for analyzing massive streaming data on computing systems ranging from machines with multiple cores sharing memory to geo-distributed data centers communicating over wide-area networks. The results of this research are expected to improve the efficiency, latency, and throughput of streaming analytics.  Due to the foundational nature of the analytical tasks considered, results of this project will impact disciplines that use large-scale machine learning and graph analytics, including cybersecurity, social network analysis, and transportation. Resulting software will be released as toolkits on stream processing platforms, and deployed in a smart-city camera infrastructure. Synergy between the research goals and the teaching goals of the PIs will lead to new instructional material in existing courses as well as development of new courses in data analytics. Individuals from underrepresented groups will be included as a part of the project. The project will benefit from and strengthen collaborations between academia, industry, and national labs on streaming analytics.\r\n \r\nThe first technical thrust of the project is on designing shared memory parallel algorithms for computation on data streams, that can achieve a high throughput and fast convergence for complex analytics tasks. The second thrust is on designing distributed streaming algorithms that can tolerate variable communication delays and adapt to available bandwidth in a wide-area network, through identifying good tradeoffs between freshness of results and volume of communication. These advances will be studied in the context of fundamental graph analytics and machine learning tasks such as subgraph counting, graph connectivity and clustering, matrix factorization, and deep networks. The project will utilize the vast body of theory and techniques developed in the realm of parallel computing in the design of methods for processing streaming data, leading to a toolkit of techniques that can be reused across applications. The project will also lead to advances in sequential streaming and incremental algorithms for certain problems; for instance, problems in machine learning that use iterative convergent methods. Based on the techniques designed, the project will design and build a hierarchical parameter server that operates effectively across the spectrum from multicore machines to data centers to wide-area data sources.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Phillip",
   "pi_last_name": "Gibbons",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Phillip Gibbons",
   "pi_email_addr": "gibbons@cs.cmu.edu",
   "nsf_id": "000270775",
   "pi_start_date": "2017-08-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 492000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Machine learning (ML) pervades our everyday life. The ability of ML models to accurately perform desired tasks is highly dependent on the quantity and quality of the data used to train them. Of particular importance is that ML models are continuously trained as new data arrive (the \"streaming data\" setting), so that model predictions continue to improve, and adapt to any emerging trends. For computational efficiency, the ML model should be updated incrementally as new data arrive, and not retrained from scratch each time.</p>\n<p>A key distinction is whether the latest data reflect a continuing trend or a new trend (called a \"concept drift\"). &nbsp;For a continuing trend, the best prediction accuracy is obtained by training over a sampling of both past and latest data (focusing solely on the latest data would decrease accuracy). On the other hand, after a concept drift, the ML model should be trained only on post-drift data, so that it reflects the new trend.</p>\n<p>In this project, the PIs developed new techniques for incrementally updating ML models as new data arrive. &nbsp;First, for the case with no concept drifts, the PIs devised <em>STRSAGA</em>, which can quickly update an ML model as new data arrive. &nbsp;Using both analysis and experiments, the PIs show that the prediction accuracy of STRSAGA after each batch of arrivals is comparable to that of (costly) algorithms that retrain from scratch each time new data arrive, and significantly better than prior algorithms suited for streaming data.</p>\n<p>Second, for the case with concept drifts, the PIs devised <em>DriftSurf</em>, an adaptive learning algorithm that extends previous drift-detection-based methods by incorporating drift detection into a broader stable-state/reactive-state process. The approach has the advantage of allowing aggressive drift detection in the stable state to achieve a high detection rate, while mitigating the false positive rate of standalone drift detection via a reactive state that reacts quickly to true drifts while eliminating most false positives. The algorithm achieves provably accurate prediction (relative to an \"oracle\" approach that knows exactly when drifts occur) and also outperforms prior approaches experimentally.&nbsp;</p>\n<p>The project also explored compiler and system techniques to greatly speed up parallel and (geo-)distributed ML training/inference for large-sized deep neural networks (DNNs). These include (1) <em>Cortex</em>, a compiler-based approach to generate highly-efficient code for recursive ML models that achieves up to 14x lower inference latency compared to past work; (2) <em>PipeDream</em>, which significantly speeds up DNN training by going beyond&nbsp;intra-batch&nbsp;parallelism of prior approaches to incorporate&nbsp;inter-batch parallelism (i.e.,&nbsp;pipelining&nbsp;of batches of training data through the layers of the DNN); (3) the first detailed experimental study showing that geo-distributed ML training suffers from a tug-of-war problem, arising from the potentially wide differences in training data collected at different geographic locations; (4) <em>SkewScout</em>, an approach to mitigate the tug-of-war problem; (5) <em>Focus</em>, which provides a low-latency, low-cost approach to answering ad hoc queries on streaming video feeds from surveillance and traffic cameras; and (6) <em>Orion</em>, which automatically parallelizes serial imperative ML programs to run on distributed shared memory.</p>\n<p>The project resulted in 9 published papers, including 7 full papers in the top machine learning or system conferences and one monograph. Most of the publications are already highly cited, and one won a best paper award. Three of the papers were joint work with Microsoft, and are having impact within the company.</p>\n<p>Collaborators on the project included 10 PhD students, 12 professors, and 6 industry researchers. The research formed the basis of four PhD dissertations. A data set of 730K real-world geo-tagged images of mammals was curated and released open source, for use in studies of geo-distributed ML.&nbsp;Code was released open source, and presentations were given to over 20 interested companies.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/27/2022<br>\n\t\t\t\t\tModified by: Phillip&nbsp;Gibbons</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMachine learning (ML) pervades our everyday life. The ability of ML models to accurately perform desired tasks is highly dependent on the quantity and quality of the data used to train them. Of particular importance is that ML models are continuously trained as new data arrive (the \"streaming data\" setting), so that model predictions continue to improve, and adapt to any emerging trends. For computational efficiency, the ML model should be updated incrementally as new data arrive, and not retrained from scratch each time.\n\nA key distinction is whether the latest data reflect a continuing trend or a new trend (called a \"concept drift\").  For a continuing trend, the best prediction accuracy is obtained by training over a sampling of both past and latest data (focusing solely on the latest data would decrease accuracy). On the other hand, after a concept drift, the ML model should be trained only on post-drift data, so that it reflects the new trend.\n\nIn this project, the PIs developed new techniques for incrementally updating ML models as new data arrive.  First, for the case with no concept drifts, the PIs devised STRSAGA, which can quickly update an ML model as new data arrive.  Using both analysis and experiments, the PIs show that the prediction accuracy of STRSAGA after each batch of arrivals is comparable to that of (costly) algorithms that retrain from scratch each time new data arrive, and significantly better than prior algorithms suited for streaming data.\n\nSecond, for the case with concept drifts, the PIs devised DriftSurf, an adaptive learning algorithm that extends previous drift-detection-based methods by incorporating drift detection into a broader stable-state/reactive-state process. The approach has the advantage of allowing aggressive drift detection in the stable state to achieve a high detection rate, while mitigating the false positive rate of standalone drift detection via a reactive state that reacts quickly to true drifts while eliminating most false positives. The algorithm achieves provably accurate prediction (relative to an \"oracle\" approach that knows exactly when drifts occur) and also outperforms prior approaches experimentally. \n\nThe project also explored compiler and system techniques to greatly speed up parallel and (geo-)distributed ML training/inference for large-sized deep neural networks (DNNs). These include (1) Cortex, a compiler-based approach to generate highly-efficient code for recursive ML models that achieves up to 14x lower inference latency compared to past work; (2) PipeDream, which significantly speeds up DNN training by going beyond intra-batch parallelism of prior approaches to incorporate inter-batch parallelism (i.e., pipelining of batches of training data through the layers of the DNN); (3) the first detailed experimental study showing that geo-distributed ML training suffers from a tug-of-war problem, arising from the potentially wide differences in training data collected at different geographic locations; (4) SkewScout, an approach to mitigate the tug-of-war problem; (5) Focus, which provides a low-latency, low-cost approach to answering ad hoc queries on streaming video feeds from surveillance and traffic cameras; and (6) Orion, which automatically parallelizes serial imperative ML programs to run on distributed shared memory.\n\nThe project resulted in 9 published papers, including 7 full papers in the top machine learning or system conferences and one monograph. Most of the publications are already highly cited, and one won a best paper award. Three of the papers were joint work with Microsoft, and are having impact within the company.\n\nCollaborators on the project included 10 PhD students, 12 professors, and 6 industry researchers. The research formed the basis of four PhD dissertations. A data set of 730K real-world geo-tagged images of mammals was curated and released open source, for use in studies of geo-distributed ML. Code was released open source, and presentations were given to over 20 interested companies.\n\n \n\n\t\t\t\t\tLast Modified: 05/27/2022\n\n\t\t\t\t\tSubmitted by: Phillip Gibbons"
 }
}