{
 "awd_id": "1734399",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: FND: Collaborative Control for Wearable Robots",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Juan Wachs",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 472209.0,
 "awd_amount": 472209.0,
 "awd_min_amd_letter_date": "2017-08-17",
 "awd_max_amd_letter_date": "2017-08-17",
 "awd_abstract_narration": "There are many applications, including manufacturing, assembly, health care, and construction, where workers may be hampered by not having enough hands to do their job effectively.  While one approach is to have a mobile robot assist the human, our project instead focuses on the augmenting human capabilities by developing a wearable robotic arm. Such augmentation of the human body can enhance a person's power, efficiency, safety, and quality of work. The project aims to make these wearable robots act as collaborative teammates, rather than directly controlled passive tools, making them both intuitive for novices and adaptable to expert users. This will significantly improve the efficiency and acceptance of such robots, and positively affect the work conditions of people interacting with them. The robot arm will be tested with human users performing tasks for which a third arm is useful. \r\n\r\nWhereas wearable robotics is a maturing field, there is almost no research on the human-robot interaction (HRI) aspects of such robots. This project investigates collaborative HRI for wearable robots, in four phases: 1) Collecting wearable collaboration data with a human and a tele-operated robot arm; 2) using this data to design an anticipatory Conditional Random Field (CRF) model for the collaboration; 3) developing a Partially Observable Markov Decision Process (POMDP) controller for the robot; and 4) evaluating the controller in human-robot interaction experiments with a physical wearable robotic arm, using metrics of efficiency, fluency, and usability. By doing so, the project contributes to the state-of-the-art in computational HRI by developing new probabilistic models for human-wearable robotic collaboration. The project also contributes new empirical data on how people interact with wearable co-robots through two human-subject studies. The collected data set on human-wearable-robotic interaction will be released to serve the research community. \r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Guy",
   "pi_last_name": "Hoffman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Guy Hoffman",
   "pi_email_addr": "hoffman@cornell.edu",
   "nsf_id": "000718306",
   "pi_start_date": "2017-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "124 Hoy road",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148537501",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 472209.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project studied the potential of a wearable robotic forearm that can assist its wearer through autonomous behaviors. To achieve the project's goal, we used user-centered design research to develop several prototypes of wearable robotic arms. We then explored a number of engineering aspects of collaborating with such a wearable robot. These aspects included: (1) the forward and inverse kinematics of the robot, (2) predictive controllers that enabled the robot to maintain a position despite disturbances stemming from the human's movement, (3) autonomous behaviors by the robot, such as self-handover and reaching specified positions in space, and finally (4) machine learning algorithms that enabled the robot to autonomously collaborate in real time with the human wearer.&nbsp;&nbsp;</p>\n<p>An autonomous, collaborative, wearable robotic arm (WRA) could benefit humans in many applications at home and in the workplace. For example, a construction worker could have the WRA fetch tools while both of the worker's hands are occupied. Alternatively, a WRA could help brace a car assembly worker if they are in an awkward position, while they use both hands to attach a component to the vehicle. Over the course of the project, we studied the necessary mechanical structures and computational components to enable such a technology.</p>\n<p>First, we ran a user-centered design study to develop various mechanical prototypes of a lightweight wearable robotic arm. We used online surveys to identify acceptable use cases for personal and professional use of a WRA. We found that most people imagine a WRA to be used mainly at work, and not at home or during leisure. We also ran an in-situ observational and interview study with construction workers that helped us identify necessary behaviors of a WRA, including self-handover, stabilization, and repetitive actions. Finally, we ran a lab study that helped us identify design challenges for WRAs, with weight and dexterity being the major issues that were identified in our lab.</p>\n<p>Based on this work, we designed an advanced research prototype of the wearable robotic forearm, which was used in our subsequent studies, and continually improved upon. We then developed new inverse kinematics (IK) formulations, a necessary mathematical tool to be able to control the robot efficiently in real time. Moreover, a kinematic analysis of the WRA showed that it can improve the wearer's workspace by over 240%, while keeping the biomechanical loads on the shoulder and elbow of the wearer within safe limits. This showed the practical promise of a lightweight wearable robotic forearm.&nbsp;</p>\n<p>One of the challenges of a wearable robot is to compensate for the human wearer's movements when controlling the robot. We found that machine-learning algorithms that predicted the human's movement based on past movements enabled the robotic arm to \"plan ahead\" and preemptively overcome disturbances. This resulted in a 26% reduction in the reaching error compared to the error we measured with reactive control.</p>\n<p>Another challenge with wearable robotics is the biomechanical load on the wearer. In this project, we studied a way to improve the robot's planning by taking into account the biomechanical load on the human as part of the planning loss function. When coupled with local optimization, our method reduced simulated forces occurring in the human's muscles up to 23%. This part of the project suggests a promising way to simulate biomechanics loads in order to build safer wearable robots.&nbsp;</p>\n<p>Finally, we used a set of machine learning models to enable the robot to work autonomously when assisting a human on a pick-and-place task. The robot predicted placement locations and timing and pre-empted the human's verbal requests using its predictions. While results from a human-participant study were inconclusive, this was a first demonstration of an autonomous, anticipatory, supernumerary robotic arm, and we hope that it sets the stage for future research.&nbsp;</p>\n<p>Over the course of this project, our research team contributed to our understanding of the design, mechanics, control, and autonomy of supernumerary robotic arms, in particular in the context of collaboration and human interaction, areas in which there is very little existing research on wearable robotics. Further research will help us build wearable robotic tools that might, in the future, have a positive impact on human workplaces, helping out wherever workers might not have enough free hands at their disposal.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/07/2022<br>\n\t\t\t\t\tModified by: Guy&nbsp;Hoffman</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1734399/1734399_10516096_1670351685761_ScreenShot2022-12-06at13.28.07--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1734399/1734399_10516096_1670351685761_ScreenShot2022-12-06at13.28.07--rgov-800width.jpg\" title=\"Usage scenarios for the wearable robotic arm\"><img src=\"/por/images/Reports/POR/2022/1734399/1734399_10516096_1670351685761_ScreenShot2022-12-06at13.28.07--rgov-66x44.jpg\" alt=\"Usage scenarios for the wearable robotic arm\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Four usage scenarios for a wearable robotic arm (from top left): fetching an object; self-handover; handover to other;  and stabilization.</div>\n<div class=\"imageCredit\">Vighnesh Vatsal</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Guy&nbsp;Hoffman</div>\n<div class=\"imageTitle\">Usage scenarios for the wearable robotic arm</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1734399/1734399_10516096_1670351800159_ScreenShot2022-12-06at13.30.45--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1734399/1734399_10516096_1670351800159_ScreenShot2022-12-06at13.30.45--rgov-800width.jpg\" title=\"Joint human-robot kinematic model for wearable robotic forearm\"><img src=\"/por/images/Reports/POR/2022/1734399/1734399_10516096_1670351800159_ScreenShot2022-12-06at13.30.45--rgov-66x44.jpg\" alt=\"Joint human-robot kinematic model for wearable robotic forearm\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Joint human-robot kinematic model for wearable robotics forearm. This model is used, among others, for predictive stabilization using machine learning models.</div>\n<div class=\"imageCredit\">Vighnesh Vatsal</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Guy&nbsp;Hoffman</div>\n<div class=\"imageTitle\">Joint human-robot kinematic model for wearable robotic forearm</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project studied the potential of a wearable robotic forearm that can assist its wearer through autonomous behaviors. To achieve the project's goal, we used user-centered design research to develop several prototypes of wearable robotic arms. We then explored a number of engineering aspects of collaborating with such a wearable robot. These aspects included: (1) the forward and inverse kinematics of the robot, (2) predictive controllers that enabled the robot to maintain a position despite disturbances stemming from the human's movement, (3) autonomous behaviors by the robot, such as self-handover and reaching specified positions in space, and finally (4) machine learning algorithms that enabled the robot to autonomously collaborate in real time with the human wearer.  \n\nAn autonomous, collaborative, wearable robotic arm (WRA) could benefit humans in many applications at home and in the workplace. For example, a construction worker could have the WRA fetch tools while both of the worker's hands are occupied. Alternatively, a WRA could help brace a car assembly worker if they are in an awkward position, while they use both hands to attach a component to the vehicle. Over the course of the project, we studied the necessary mechanical structures and computational components to enable such a technology.\n\nFirst, we ran a user-centered design study to develop various mechanical prototypes of a lightweight wearable robotic arm. We used online surveys to identify acceptable use cases for personal and professional use of a WRA. We found that most people imagine a WRA to be used mainly at work, and not at home or during leisure. We also ran an in-situ observational and interview study with construction workers that helped us identify necessary behaviors of a WRA, including self-handover, stabilization, and repetitive actions. Finally, we ran a lab study that helped us identify design challenges for WRAs, with weight and dexterity being the major issues that were identified in our lab.\n\nBased on this work, we designed an advanced research prototype of the wearable robotic forearm, which was used in our subsequent studies, and continually improved upon. We then developed new inverse kinematics (IK) formulations, a necessary mathematical tool to be able to control the robot efficiently in real time. Moreover, a kinematic analysis of the WRA showed that it can improve the wearer's workspace by over 240%, while keeping the biomechanical loads on the shoulder and elbow of the wearer within safe limits. This showed the practical promise of a lightweight wearable robotic forearm. \n\nOne of the challenges of a wearable robot is to compensate for the human wearer's movements when controlling the robot. We found that machine-learning algorithms that predicted the human's movement based on past movements enabled the robotic arm to \"plan ahead\" and preemptively overcome disturbances. This resulted in a 26% reduction in the reaching error compared to the error we measured with reactive control.\n\nAnother challenge with wearable robotics is the biomechanical load on the wearer. In this project, we studied a way to improve the robot's planning by taking into account the biomechanical load on the human as part of the planning loss function. When coupled with local optimization, our method reduced simulated forces occurring in the human's muscles up to 23%. This part of the project suggests a promising way to simulate biomechanics loads in order to build safer wearable robots. \n\nFinally, we used a set of machine learning models to enable the robot to work autonomously when assisting a human on a pick-and-place task. The robot predicted placement locations and timing and pre-empted the human's verbal requests using its predictions. While results from a human-participant study were inconclusive, this was a first demonstration of an autonomous, anticipatory, supernumerary robotic arm, and we hope that it sets the stage for future research. \n\nOver the course of this project, our research team contributed to our understanding of the design, mechanics, control, and autonomy of supernumerary robotic arms, in particular in the context of collaboration and human interaction, areas in which there is very little existing research on wearable robotics. Further research will help us build wearable robotic tools that might, in the future, have a positive impact on human workplaces, helping out wherever workers might not have enough free hands at their disposal.\n\n\t\t\t\t\tLast Modified: 12/07/2022\n\n\t\t\t\t\tSubmitted by: Guy Hoffman"
 }
}