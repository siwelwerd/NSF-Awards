{
 "awd_id": "1650826",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC: Medium: Collaborative: Know Thy Enemy: Data Mining Meets Networks for Understanding Web-Based Malware Dissemination",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Shannon Beck",
 "awd_eff_date": "2016-06-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 280045.0,
 "awd_amount": 280045.0,
 "awd_min_amd_letter_date": "2016-10-17",
 "awd_max_amd_letter_date": "2016-10-17",
 "awd_abstract_narration": "How does web-based malware spread? We use the term web-based malware to describe malware that is  distributed through websites, and  malicious posts in social networks. We are in an arms race against web-based malware distributors;  and as in any war, knowledge is power.  The more we know about them, the better we can defend ourselves. Our goal is to understand the dissemination of web-based malware by creating \"MalScope\", a suite of methods and tools that uses cutting-edge approaches to build spatiotemporal models, generators and sampling techniques for malware dissemination. From a scientific point of view, this project brings together two disciplines:  Data Mining and Network Security. The outcome is a suite of novel, sophisticated, and scalable techniques and models  that will enhance our understanding of malware dissemination at a large scale. We use two types of  web-based malware dissemination data: (1) user machines accessing dangerous sites and downloading web-based malware; and (2) Facebook users being exposed to malicious posts. We already have and will continue to obtain more data from our industry partners (e.g. Symantec's WINE project), open-access projects, or collect on our own (e.g MyPageKeeper).\r\n\r\nThe broader impact of our  work is that it will  enable the development of security solutions for end-users and  industry.  A 15-minute network outage costs a 200-employee company  about $40K, while identity theft costs about $1,500 per person on average. By knowing the enemy better, security researchers and industry can more effectively stop the interconnected manifestations of Internet threats: identity theft, the creation of botnets, and DoS attacks. The PIs have a track record of technology transfer, with collaborators at industrial labs (Yahoo, MSR, Symantec, AT&T, IBM), national labs (LLNL, Sandia), open-source software (\"Pegasus\"), and spin-off startups (StopTheHacker). Educational impacts include developing a new course, providing publicly available educational material, and open-source software.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tina",
   "pi_last_name": "Eliassi-Rad",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tina Eliassi-Rad",
   "pi_email_addr": "tina@eliassi.org",
   "nsf_id": "000333983",
   "pi_start_date": "2016-10-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Ave",
  "perf_city_name": "Bostonb",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 280045.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Networked representations of physical and social phenomena are ubiquitous. Examples include social and information networks, technological and communication networks, co-purchasing networks, etc. These networks are often incomplete because the phenomena are partially observed. Working with incomplete networks can skew analyses. Acquiring complete data is often unrealistic. For example, obtaining the Twitter Firehose is not viable for most people and institutions. However, one may be able to collect data selectively to enrich the incomplete network. With a limited query budget, which parts of a partially observed network should be examined to give the best (i.e., most complete) view of the entire network? Suppose that one has obtained a sample of a Twitter retweet network from a Web site. The sample was collected for some other purpose (perhaps unbeknownst to us), and so may not contain the most useful structural information for one's purposes. How should one best supplement this sampled data?</p>\n<p>&nbsp;<br />We developed an approach, called NOL-HTR (short for Network Online Learning with Heavy-Tailed Regression) that sequentially reduces the partial observability of an incomplete network. NOL-HTR learns which partially observed node to query next. Concretely, given a partially observed network, the ability to query nodes for their true connections (e.g., by accessing an API), and a budget on the number of such queries, our goal was to learn which nodes to query in order to maximally improve the sample. Given that distributions of structural features and node attributes in networks are often heavy tailed, NOL-HTR is based on recent generalizations of the median of means approach to parameter estimation for linear regression [1]. Extensive experiments on both synthetic and real-world networks show that (a) it is possible to adaptively learn to choose which nodes are best to query in a network, (b) some macroscopic properties of networks, such as the degree distribution and modular structure, impact the potential for learning and the optimal amount of random exploration, and (c) comparing NOL-HTR with previous algorithms, there exist tradeoffs between consistent performance across samples and less consistent, but on average higher, overall performance.</p>\n<p><br />We presented our work at the following scientific venues:<br />* The 9th International Conference on Complex Networks (CompleNet'18), Boston, MA, March 2018<br />* Tutorial at the 2018 SIAM Data Mining Conference (SDM'18), San Diego, CA, May 2018 (tutorial website: http://eliassi.org/sdm18tut.html)<br />* The 2018 International Conference on Network Science (NetSci'18), Paris, France, June 2018&nbsp;<br />* The 14th International Workshop on Mining and Learning with Graphs (held in conjunction with ACM SIGKDD?18), London, United Kingdom, August 2018 (paper website: http://www.mlgworkshop.org/2018/papers/MLG2018_paper_40.pdf)&nbsp;</p>\n<p>This report covers work from 09/01/2017 to 08/31/2018. &nbsp;During this time, the project funded two graduate research assistantships: Timothy LaRock and Timothy Sakharov.&nbsp;</p>\n<p>References<br />[1] D. Hsu and S. Sabato. 2016. Loss Minimization and Parameter Estimation with Heavy Tails. Journal of Machine Learning Research 17 (2016), 1-40.<br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/03/2018<br>\n\t\t\t\t\tModified by: Tina&nbsp;Eliassi-Rad</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1650826/1650826_10268535_1543819972812_eliassi-rad_report_image1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1650826/1650826_10268535_1543819972812_eliassi-rad_report_image1--rgov-800width.jpg\" title=\"Limits of Learning in Incomplete Networks\"><img src=\"/por/images/Reports/POR/2018/1650826/1650826_10268535_1543819972812_eliassi-rad_report_image1--rgov-66x44.jpg\" alt=\"Limits of Learning in Incomplete Networks\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our findings on synthetic and real-world networks showcase when learning is feasible, when it is not, and when one should just use a heuristic (i.e., when learning is unnecessary or redundant).</div>\n<div class=\"imageCredit\">T. LaRock, et al. The 14th International Workshop on Mining and Learning with Graphs (held in conjunction with ACM SIGKDD?18), London, United Kingdom, August 2018.</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Tina&nbsp;Eliassi-Rad</div>\n<div class=\"imageTitle\">Limits of Learning in Incomplete Networks</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nNetworked representations of physical and social phenomena are ubiquitous. Examples include social and information networks, technological and communication networks, co-purchasing networks, etc. These networks are often incomplete because the phenomena are partially observed. Working with incomplete networks can skew analyses. Acquiring complete data is often unrealistic. For example, obtaining the Twitter Firehose is not viable for most people and institutions. However, one may be able to collect data selectively to enrich the incomplete network. With a limited query budget, which parts of a partially observed network should be examined to give the best (i.e., most complete) view of the entire network? Suppose that one has obtained a sample of a Twitter retweet network from a Web site. The sample was collected for some other purpose (perhaps unbeknownst to us), and so may not contain the most useful structural information for one's purposes. How should one best supplement this sampled data?\n\n \nWe developed an approach, called NOL-HTR (short for Network Online Learning with Heavy-Tailed Regression) that sequentially reduces the partial observability of an incomplete network. NOL-HTR learns which partially observed node to query next. Concretely, given a partially observed network, the ability to query nodes for their true connections (e.g., by accessing an API), and a budget on the number of such queries, our goal was to learn which nodes to query in order to maximally improve the sample. Given that distributions of structural features and node attributes in networks are often heavy tailed, NOL-HTR is based on recent generalizations of the median of means approach to parameter estimation for linear regression [1]. Extensive experiments on both synthetic and real-world networks show that (a) it is possible to adaptively learn to choose which nodes are best to query in a network, (b) some macroscopic properties of networks, such as the degree distribution and modular structure, impact the potential for learning and the optimal amount of random exploration, and (c) comparing NOL-HTR with previous algorithms, there exist tradeoffs between consistent performance across samples and less consistent, but on average higher, overall performance.\n\n\nWe presented our work at the following scientific venues:\n* The 9th International Conference on Complex Networks (CompleNet'18), Boston, MA, March 2018\n* Tutorial at the 2018 SIAM Data Mining Conference (SDM'18), San Diego, CA, May 2018 (tutorial website: http://eliassi.org/sdm18tut.html)\n* The 2018 International Conference on Network Science (NetSci'18), Paris, France, June 2018 \n* The 14th International Workshop on Mining and Learning with Graphs (held in conjunction with ACM SIGKDD?18), London, United Kingdom, August 2018 (paper website: http://www.mlgworkshop.org/2018/papers/MLG2018_paper_40.pdf) \n\nThis report covers work from 09/01/2017 to 08/31/2018.  During this time, the project funded two graduate research assistantships: Timothy LaRock and Timothy Sakharov. \n\nReferences\n[1] D. Hsu and S. Sabato. 2016. Loss Minimization and Parameter Estimation with Heavy Tails. Journal of Machine Learning Research 17 (2016), 1-40.\n\n\n\n\t\t\t\t\tLast Modified: 12/03/2018\n\n\t\t\t\t\tSubmitted by: Tina Eliassi-Rad"
 }
}