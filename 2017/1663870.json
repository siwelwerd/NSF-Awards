{
 "awd_id": "1663870",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Collaborative Research: F: Big Data, It's Not So Big: Exploiting Low-Dimensional Geometry for Learning and Inference",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Victor Roytburd",
 "awd_eff_date": "2016-08-22",
 "awd_exp_date": "2019-11-30",
 "tot_intn_awd_amt": 301769.0,
 "awd_amount": 301769.0,
 "awd_min_amd_letter_date": "2017-03-21",
 "awd_max_amd_letter_date": "2017-03-21",
 "awd_abstract_narration": "This research will leverage ideas from algebraic and differential geometry to address core problems in modern high-dimensional and massive data science.  The project will develop statistical methods and numerical tools, grounded in solid mathematical, statistical, and computational foundations, to extract low dimensional geometry from massive data with applications in clustering, data summarization, prediction, dimension reduction, and visualization.  The solutions developed as part of this project can result in fundamental advances in practical applications across fields as diverse as biology, medicine, social sciences, communication networks, and engineering.  In addition to internal validation via statistical and mathematical theory and simulation studies, the methods developed in the project will involve external validation via interdisciplinary applications.  These applications include: (1) inference of population structure from genomic data; (2) document analysis via topic models; and (3) inference of subsets of putative gene networks relevant to drug resistance in melanoma.\r\n\r\nThe research is motivated by the central premise that, even though the amount of data may be massive, a compact model can represent these data.  Specifically, high-dimensional and/or massive data can be reasonably approximated by a mixture of subspaces, for which sparse representations exist.  A mixture of subspaces of potentially different dimensions is a flexible, rich representation of data with nice mathematical properties that can scale to large data.  There are several fundamental challenges in modeling mixtures of subspaces that will be addressed in this research: 1) the subspaces will be of different dimensions, 2) both the subspace parameters and the mixing parameters need to be inferred, 3) efficient algorithms for inference are required for both high-dimensional and massive data.  The central foundational impediment in all of these challenges is that the model is a stratified space (a union of manifolds), and therefore has singularities.  The key insight in this research is that there exist embeddings and representations of the model space that mitigate these singularities.  These ideas are implemented as concrete Bayesian, frequentist, and numerical algorithms and models to address the real world examples listed above.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lizhen",
   "pi_last_name": "Lin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lizhen Lin",
   "pi_email_addr": "lizhen01@umd.edu",
   "nsf_id": "000671759",
   "pi_start_date": "2017-03-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Notre Dame",
  "inst_street_address": "940 GRACE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "NOTRE DAME",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "5746317432",
  "inst_zip_code": "465565708",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "IN02",
  "org_lgl_bus_name": "UNIVERSITY OF NOTRE DAME DU LAC",
  "org_prnt_uei_num": "FPU6XGFXMBE9",
  "org_uei_num": "FPU6XGFXMBE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Notre Dame",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "465565708",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "IN02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 301768.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Over the course of grant period, the PI has completed over ten research papers with many work published in top statistics and machine learning journals including the Annals of Statistics, Journal of the Machine Learning Reserach, &nbsp; NeurIPS, and so on. The PI widely disseminated the work&nbsp; by&nbsp; delivering&nbsp; over fifteen talks in departmental colloquiums or research conferences. The PI has also trained two postdocs and one graduate student.&nbsp;</p>\n<p>To be more specific, some of the research outcomes can be summarized in the following: (1) by levering ideas from geometry,&nbsp; the PI and her collaborators&nbsp; have developed a mixture of subspaces model&nbsp; with varying dimensions for modeling and &nbsp;inference of big data which is backed up by theoretical guarantees and yields reliable and efficient numerical performance.The model explores the intrinsic lower geometry of big data and&nbsp; has practical applications in diverse fields such&nbsp; as biology, medicine, social sciences, communication networks, and engineering; (2) The PI has developed a robust and scalable procedure for Bayesian inference of big data. The procedure is scalable to big data sets while being robust to outliers and contamination of arbitrary nature. The general principle behind the procedure can be applied broadly in big data analysis; (3) The PI has has &nbsp;developed a parallel and robust&nbsp; procedure for model selection; (4)&nbsp; The PI has developed minimax theory&nbsp; and model selection consistency for learning high-dimensional and sparse graphical models; and (5)&nbsp; the PI has developed models and theory for inference of high-dimensional sparse model beyond the simple assumption of Gaussian error. &nbsp;The central theme of the proposed research was to explore the intrinsic structure or geometry of &nbsp;big data for inference. The&nbsp;completed research works have made fundamental advancment in theory, models and algorithms in the general area of big data analysis.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/29/2020<br>\n\t\t\t\t\tModified by: Lizhen&nbsp;Lin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOver the course of grant period, the PI has completed over ten research papers with many work published in top statistics and machine learning journals including the Annals of Statistics, Journal of the Machine Learning Reserach,   NeurIPS, and so on. The PI widely disseminated the work  by  delivering  over fifteen talks in departmental colloquiums or research conferences. The PI has also trained two postdocs and one graduate student. \n\nTo be more specific, some of the research outcomes can be summarized in the following: (1) by levering ideas from geometry,  the PI and her collaborators  have developed a mixture of subspaces model  with varying dimensions for modeling and  inference of big data which is backed up by theoretical guarantees and yields reliable and efficient numerical performance.The model explores the intrinsic lower geometry of big data and  has practical applications in diverse fields such  as biology, medicine, social sciences, communication networks, and engineering; (2) The PI has developed a robust and scalable procedure for Bayesian inference of big data. The procedure is scalable to big data sets while being robust to outliers and contamination of arbitrary nature. The general principle behind the procedure can be applied broadly in big data analysis; (3) The PI has has  developed a parallel and robust  procedure for model selection; (4)  The PI has developed minimax theory  and model selection consistency for learning high-dimensional and sparse graphical models; and (5)  the PI has developed models and theory for inference of high-dimensional sparse model beyond the simple assumption of Gaussian error.  The central theme of the proposed research was to explore the intrinsic structure or geometry of  big data for inference. The completed research works have made fundamental advancment in theory, models and algorithms in the general area of big data analysis.\n\n \n\n\t\t\t\t\tLast Modified: 03/29/2020\n\n\t\t\t\t\tSubmitted by: Lizhen Lin"
 }
}