{
 "awd_id": "1703331",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Medium: Collaborative Research: A Unified and Declarative Approach to Causal Analysis for Big Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2017-08-09",
 "awd_max_amd_letter_date": "2017-08-09",
 "awd_abstract_narration": "Observational data is available today in multi-relational form, often extracted from various sources, and stored in multiple flat and interrelated tables.  Standard statistical methods for conducting causal inference on observational data assume a very simple data model: a single table with independent units.  This research has the potential to significantly impact application domains where differentiating causality from correlation is essential, e.g., education policy and cancer genomics. The HUME project develops techniques for efficient causal analysis using a declarative approach, over complex views, and over large datasets that are integrated from disparate data sources.  HUME uses a SQL-like language and is integrated with a relational database system.\r\n\r\nThe project develops techniques for defining arbitrarily complex units, treatments, outcomes, and covariates, by combining joins, data mapping, and aggregates across multiple tables, and uses a causal network to choose a good set of covariates for causal inference.  The first part of the project develops scalable techniques for sub-classification and matching for large data sets obtained by declaratively integrating multiple data sources.  The second part of the project develops scalable methods for discovering causal relationships among the attributes in the views by constraint-based, search-based, and hybrid discovery processes. Finally, the third part of the project investigates interferences among units arising from the complex views by designing normal forms and automatic inference of underlying assumptions exploiting techniques from database theory.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lise",
   "pi_last_name": "Getoor",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lise Getoor",
   "pi_email_addr": "getoor@soe.ucsc.edu",
   "nsf_id": "000465719",
   "pi_start_date": "2017-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Cruz",
  "inst_street_address": "1156 HIGH ST",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA CRUZ",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8314595278",
  "inst_zip_code": "950641077",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "CA19",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA SANTA CRUZ",
  "org_prnt_uei_num": "",
  "org_uei_num": "VXUFPE4MCZH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Cruz",
  "perf_str_addr": "1156 High St",
  "perf_city_name": "Santa Cruz",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "950641000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "CA19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main goal of the project was to develop declarative approaches to  enable easy and efficient causal analysis by specifying units,  treatment, outcome, and covariates, over the integrated data, and  declaring any underlying assumptions required in causal analysis using  database view definitions.&nbsp; Causality is usually studied over  independent and uniform units.&nbsp; However, in many situations, the units  are connected by relationships; these relationships can be links in a  social network, or author-paper relationships, or employee-employer  relationships.&nbsp; In that case the outcomes for one unit may be affected  through its relationships by the outcomes of other units. &nbsp;&nbsp; This project  has researched techniques and methods to allow causal inference over  relational data, by assuming a much simpler relational representation. &nbsp; The project had three major outcomes.<br /><br />First,  we developed an experimental system, called HypDB, for removing bias  (such as Simpson&rsquo;s paradox) in OLAP queries.&nbsp; A SQL query, can often be  biased and lead to incorrect decisions. HypDB detects, explains, and  resolves bias in decision-support queries. We gave a simple definition  of a biased query, which performs a set of independence tests on the  data to detect bias, proposed a novel technique that explains the bias,  thus assisting an analyst in understanding what goes on, and developed  an automated method for rewriting a biased query into an unbiased query.<br /><br />Second,  we developed Capuchin, a system that applies database repair  techniques, in order to remove bias from training data. Capuchin  discovers a causal model in the training data, reasons about how to  modify that causal model in order to make it conform to a socially  accepted notion of fairness, then repairs the training data by modifying  it as little as possible in order to attain the new, corrected causal  model. We developed the necessary theory based on causality theory and  information theory, proposed two algorithms for database repair, and  evaluated the system on several publicly available datasets, showing  that, when training on the repaired data, the models will make decisions  that are significantly more fair, according to several notions of  fairness, yet achieve almost the same accuracy as models trained on the  raw data.<br /><br />Finally, developed a system of causal inference in  observational relational data. Although causal inference methods for  &ldquo;observed data&rdquo; (not from randomized controlled experiments) have been  studied in Statistics and Artificial Intelligence, they rely on the  critical assumption that the units of study are sampled from a  population of homogeneous units; in other words, the data can be  represented in a single flat table. However, many real-world data are  available in &ldquo;relational&rdquo; form in multiple related tables. Basic notions  used in causal analysis, such as &ldquo;units&rdquo;, no longer readily apply.&nbsp; For  example the treatment may be applied to one table whereas the outcome  may be observed in a different table.&nbsp; This makes causal inference in  relational data more challenging. For this purpose, we developed a  declarative framework, called CaRL (Causal Relational Langauge).&nbsp; The  framework includes a declarative language to represent causal background  knowledge and assumptions, a semantics for complex causal queries, and  an algorithm for answering causal queries from the given relational  data.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/02/2022<br>\n\t\t\t\t\tModified by: Lise&nbsp;Getoor</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe main goal of the project was to develop declarative approaches to  enable easy and efficient causal analysis by specifying units,  treatment, outcome, and covariates, over the integrated data, and  declaring any underlying assumptions required in causal analysis using  database view definitions.  Causality is usually studied over  independent and uniform units.  However, in many situations, the units  are connected by relationships; these relationships can be links in a  social network, or author-paper relationships, or employee-employer  relationships.  In that case the outcomes for one unit may be affected  through its relationships by the outcomes of other units.    This project  has researched techniques and methods to allow causal inference over  relational data, by assuming a much simpler relational representation.   The project had three major outcomes.\n\nFirst,  we developed an experimental system, called HypDB, for removing bias  (such as Simpson\u2019s paradox) in OLAP queries.  A SQL query, can often be  biased and lead to incorrect decisions. HypDB detects, explains, and  resolves bias in decision-support queries. We gave a simple definition  of a biased query, which performs a set of independence tests on the  data to detect bias, proposed a novel technique that explains the bias,  thus assisting an analyst in understanding what goes on, and developed  an automated method for rewriting a biased query into an unbiased query.\n\nSecond,  we developed Capuchin, a system that applies database repair  techniques, in order to remove bias from training data. Capuchin  discovers a causal model in the training data, reasons about how to  modify that causal model in order to make it conform to a socially  accepted notion of fairness, then repairs the training data by modifying  it as little as possible in order to attain the new, corrected causal  model. We developed the necessary theory based on causality theory and  information theory, proposed two algorithms for database repair, and  evaluated the system on several publicly available datasets, showing  that, when training on the repaired data, the models will make decisions  that are significantly more fair, according to several notions of  fairness, yet achieve almost the same accuracy as models trained on the  raw data.\n\nFinally, developed a system of causal inference in  observational relational data. Although causal inference methods for  \"observed data\" (not from randomized controlled experiments) have been  studied in Statistics and Artificial Intelligence, they rely on the  critical assumption that the units of study are sampled from a  population of homogeneous units; in other words, the data can be  represented in a single flat table. However, many real-world data are  available in \"relational\" form in multiple related tables. Basic notions  used in causal analysis, such as \"units\", no longer readily apply.  For  example the treatment may be applied to one table whereas the outcome  may be observed in a different table.  This makes causal inference in  relational data more challenging. For this purpose, we developed a  declarative framework, called CaRL (Causal Relational Langauge).  The  framework includes a declarative language to represent causal background  knowledge and assumptions, a semantics for complex causal queries, and  an algorithm for answering causal queries from the given relational  data.\n\n\t\t\t\t\tLast Modified: 02/02/2022\n\n\t\t\t\t\tSubmitted by: Lise Getoor"
 }
}