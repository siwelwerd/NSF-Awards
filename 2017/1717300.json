{
 "awd_id": "1717300",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: A Theory of Explanation Languages",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 499897.0,
 "awd_amount": 507897.0,
 "awd_min_amd_letter_date": "2017-05-25",
 "awd_max_amd_letter_date": "2020-03-18",
 "awd_abstract_narration": "Trust in a computing system depends on understanding its behavior. When users are confronted with unexpected and unexplained results, they may not be willing to rely on such a system anymore. With computing systems controlling ever-increasing parts of our lives, it is important to ensure that they are accountable and can justify their decisions and actions. For example, we want to know how a decision support system arrived at its suggestion for a particular health-care plan or why a self-driving car could not avoid an accident. Despite this need for understanding computing systems, few systems today explain their behavior to their users. This research explores the nature of explanations and how they can be employed in the creation of computing systems that can explain their behavior to programmers and users.\r\n\r\n Based on an analysis of the nature of explanations and their properties, this research explores operations for the composition and transformation of explanations and the alignment with computations. Part of the research is the development of criteria to judge the quality of explanations and develop guidelines for the design and implementation of explanation languages. Altogether, this research produces a theory of explanation languages. The development of example explanation languages as suggested by the developed theory and their evaluation according to the explanation quality criteria supports the assessment of the research progress. The broader impact of this project includes support for graduate, undergraduate, and high school students who will carry the ideas developed in this project out into the world. Moreover, a theory of explanations and a framework for systematically adding explanations to computing systems empowers software developers to make their products more widely understandable and trustworthy, which ultimately enhances the acceptance of new technologies in society. This research leads to methods and tools that affect the design of future software. Given the importance of software in all aspects of our lives and the growing need for understanding its behaviors, the middle- and long-term practical impact of this research can be enormous.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Martin",
   "pi_last_name": "Erwig",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Martin Erwig",
   "pi_email_addr": "erwig@oregonstate.edu",
   "nsf_id": "000434059",
   "pi_start_date": "2017-05-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Oregon State University",
  "inst_street_address": "1500 SW JEFFERSON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CORVALLIS",
  "inst_state_code": "OR",
  "inst_state_name": "Oregon",
  "inst_phone_num": "5417374933",
  "inst_zip_code": "973318655",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "OR04",
  "org_lgl_bus_name": "OREGON STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "MZ4DYXE1SL98"
 },
 "perf_inst": {
  "perf_inst_name": "Oregon State University",
  "perf_str_addr": "1148 Kelley Engineering Center",
  "perf_city_name": "Corvallis",
  "perf_st_code": "OR",
  "perf_st_name": "Oregon",
  "perf_zip_code": "973315501",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "OR04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 499897.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The most important outcomes of this research are two innovative representations for explaining the dynamic behavior of programs.</p>\n<p><br />First, we have formalized the idea of so-called <em>contrastive explanations</em>, which justify the result of a computation when compared to potential alternatives. A contrastive explanation essentially answers a question of the form <em>Why is the result x and not y?</em>. Our key innovation to producing contrastive explanations is to maintain so-called <em>value decompositions</em>, that is, fine-grained representations of the values transformed by a program, to allow the tracking of details about how program input values influence the output. An important property of value decompositions is that they lead to nimble explanations, since their structure guarantees that only a minimum amount of information has to be reported to prove that a result is better than the purported alternative. We have applied this explanation mechanism directly to a large class of dynamic programming algorithms, and by extending value decomposition to hierarchical structures, we have also applied these explanations to hierarchical forms of multi-attribute decision making, especially, the Hierarchical Analytic Hierarchy Process (AHP).</p>\n<p><br />The second innovation is a new representation for program traces. A prominent feature of this representation is the use of ellipses to dynamically hide unimportant parts of explanations. We have defined a trace query language that allows the definition of filters that can be applied to traces to customize them according to user needs in specific situations. The query language is hidden from end users who can customize traces just by applying filters; the definition of new filters is left to expert users. We have implemented a corresponding web-based GUI that allows end users to generate explanation traces and interactively navigate them, apply filters, etc. As a theoretical contribution of the new trace representation we have developed a new operational semantics, Call-By-Named-Value (CBNV), which stores names with values. The presentation of traces exploits the names of function values to produce smaller and more readable traces. This effect is extremely useful for tracing the execution of higher-order functions where substituting function values for variables that are referenced (potentially multiple times) can render traces effectively unreadable.</p>\n<p><br />The project has supported three high school students for summer internships in the context of Saturday Academy's ASE program. Moreover, four graduate students, one of them female, and two undergraduate students (one as part of the NSF REU program) have been involved in the research for this project. Three of the students have successfully completed their MS degrees, and one student has completed his PhD prelim exam and is on track to completing his PhD degree.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/20/2022<br>\n\t\t\t\t\tModified by: Martin&nbsp;Erwig</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe most important outcomes of this research are two innovative representations for explaining the dynamic behavior of programs.\n\n\nFirst, we have formalized the idea of so-called contrastive explanations, which justify the result of a computation when compared to potential alternatives. A contrastive explanation essentially answers a question of the form Why is the result x and not y?. Our key innovation to producing contrastive explanations is to maintain so-called value decompositions, that is, fine-grained representations of the values transformed by a program, to allow the tracking of details about how program input values influence the output. An important property of value decompositions is that they lead to nimble explanations, since their structure guarantees that only a minimum amount of information has to be reported to prove that a result is better than the purported alternative. We have applied this explanation mechanism directly to a large class of dynamic programming algorithms, and by extending value decomposition to hierarchical structures, we have also applied these explanations to hierarchical forms of multi-attribute decision making, especially, the Hierarchical Analytic Hierarchy Process (AHP).\n\n\nThe second innovation is a new representation for program traces. A prominent feature of this representation is the use of ellipses to dynamically hide unimportant parts of explanations. We have defined a trace query language that allows the definition of filters that can be applied to traces to customize them according to user needs in specific situations. The query language is hidden from end users who can customize traces just by applying filters; the definition of new filters is left to expert users. We have implemented a corresponding web-based GUI that allows end users to generate explanation traces and interactively navigate them, apply filters, etc. As a theoretical contribution of the new trace representation we have developed a new operational semantics, Call-By-Named-Value (CBNV), which stores names with values. The presentation of traces exploits the names of function values to produce smaller and more readable traces. This effect is extremely useful for tracing the execution of higher-order functions where substituting function values for variables that are referenced (potentially multiple times) can render traces effectively unreadable.\n\n\nThe project has supported three high school students for summer internships in the context of Saturday Academy's ASE program. Moreover, four graduate students, one of them female, and two undergraduate students (one as part of the NSF REU program) have been involved in the research for this project. Three of the students have successfully completed their MS degrees, and one student has completed his PhD prelim exam and is on track to completing his PhD degree.\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 10/20/2022\n\n\t\t\t\t\tSubmitted by: Martin Erwig"
 }
}