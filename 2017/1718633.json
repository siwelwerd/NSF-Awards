{
 "awd_id": "1718633",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF:Small:Neuromorphic Architectures for On-line Learning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2017-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 439998.0,
 "awd_amount": 439998.0,
 "awd_min_amd_letter_date": "2017-08-10",
 "awd_max_amd_letter_date": "2022-08-03",
 "awd_abstract_narration": "With the increasingly large volumes of data being generated in all fields, it is difficult to draw meaningful understanding from the information. Deep learning is a collection of new algorithms that have been developed recently to make it easier to understand large volumes of data. These algorithms typically have two phases of operation: training and inference. In the training phase, the algorithms learn how to interpret data, while in the inference phase the trained algorithms process new data based on what they learned earlier. Training generally requires high power computing. This project will develop novel computing systems for training that require low power consumption. This makes them suitable for portable systems, and hence could enable the design of significantly smarter products that learn continuously from their environment and are able to better interact with the environment. The proposed work includes outreach to K-12 students and also training of undergraduate, graduate, and minority students. \r\n\r\nThe novel computing systems to be developed will employ memristor circuits to accelerate the training phase of deep learning algorithms. Memristors are nanoscale resistive memory devices. The PIs will develop and characterize the memristors and then design deep learning circuits for training based on the characterized memristor devices. The PIs will also design computing systems based on the training circuits to be developed. These computing systems will have applications in a broad range of fields, including low power consumer products and high power clusters of computers.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tarek",
   "pi_last_name": "Taha",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Tarek M Taha",
   "pi_email_addr": "ttaha1@udayton.edu",
   "nsf_id": "000287418",
   "pi_start_date": "2017-08-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Guru",
   "pi_last_name": "Subramanyam",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Guru Subramanyam",
   "pi_email_addr": "gSubramanyam1@udayton.edu",
   "nsf_id": "000280972",
   "pi_start_date": "2017-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Dayton",
  "inst_street_address": "300 COLLEGE PARK AVE",
  "inst_street_address_2": "",
  "inst_city_name": "DAYTON",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "9372293232",
  "inst_zip_code": "454690001",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "OH10",
  "org_lgl_bus_name": "UNIVERSITY OF DAYTON",
  "org_prnt_uei_num": "V62NC51F7YV1",
  "org_uei_num": "V62NC51F7YV1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Dayton",
  "perf_str_addr": "300 COLLEGE PARK AVE",
  "perf_city_name": "DAYTON",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "454690104",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "OH10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 439998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we have looked at the design of memristor devices and their use in building ultra efficient computer chips for training artificial intelligence (AI) algorithms. Memristors are nanoscale devices that can have their electrical resistance properties modified through electrical pulses and then retain these modified properties. These can be used to carry out AI algorithm computations extremely efficiently.</p>\n<p>At present the most popular type of AI algorithms (deep learning networks) need to be trained based on examples. If the application environment changes, the networks would perform best if they were retrained in the new environment. As training is a highly energy consuming process, the ultra-efficient training chips designed in this work would have use in situations where re-training of networks is needed in power constrained environments. Examples of such applications include cell phones, medical devices that adapt to the user, fault detection systems (that could be used in infrastructure, such as tracking long term problems with bridges), and satellites.</p>\n<p>Specific outcomes of the project include:</p>\n<p>1. Design and characterization of memristor devices. In particular we looked at GeTe and LiNbO3 devices. These devices have several characteristics that make them well suited to training on the chip.</p>\n<p>2. Low-cost FPGA board based approaches were examined to characterize memristor devices.</p>\n<p>3. We have developed circuits that can use these devices for training deep learning algorithms. These circuits are at least 100-1000 times more efficient than current digital processors for training AI algorithms. Circuits were developed for several types of algorithms, including:</p>\n<p style=\"padding-left: 30px;\">A. Anomaly detection: This is useful for detecting faults, zero-day attacks, and unusual behavior. On-chip training allows the chip to adapt to new long-term behaviors. This would help reduce the number of false positives given out by the system, and thus make it much more useful.</p>\n<p style=\"padding-left: 30px;\">B. Convolutional neural networks: These are used in many areas, including sensor data processing and scientific data processing. Often times, remote systems are exposed to new types of data and being able to train on the system means not having to transmit back the new data acquired (which is very time and energy consuming). Thus being able to train at the remote system enables the system to be more useful.</p>\n<p style=\"padding-left: 30px;\">C. Reinforcement learning: These are used in many robotic systems, including UAVs. Being able to retrain on system allows the robotic system to be more robust.</p>\n<p>4. A model was developed to rapidly examine the design space of training processors to find what chip architecture options would be best for a specific type of algorithm or network. Design space explorations can be very time consuming as they require the design of complex simulators that take a long time to run. Thus a mathematical modeling approach can be millions of times faster and help narrow down the amount of detailed simulation that would be needed later.</p><br>\n<p>\n Last Modified: 07/09/2024<br>\nModified by: Tarek&nbsp;M&nbsp;Taha</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn this project, we have looked at the design of memristor devices and their use in building ultra efficient computer chips for training artificial intelligence (AI) algorithms. Memristors are nanoscale devices that can have their electrical resistance properties modified through electrical pulses and then retain these modified properties. These can be used to carry out AI algorithm computations extremely efficiently.\n\n\nAt present the most popular type of AI algorithms (deep learning networks) need to be trained based on examples. If the application environment changes, the networks would perform best if they were retrained in the new environment. As training is a highly energy consuming process, the ultra-efficient training chips designed in this work would have use in situations where re-training of networks is needed in power constrained environments. Examples of such applications include cell phones, medical devices that adapt to the user, fault detection systems (that could be used in infrastructure, such as tracking long term problems with bridges), and satellites.\n\n\nSpecific outcomes of the project include:\n\n\n1. Design and characterization of memristor devices. In particular we looked at GeTe and LiNbO3 devices. These devices have several characteristics that make them well suited to training on the chip.\n\n\n2. Low-cost FPGA board based approaches were examined to characterize memristor devices.\n\n\n3. We have developed circuits that can use these devices for training deep learning algorithms. These circuits are at least 100-1000 times more efficient than current digital processors for training AI algorithms. Circuits were developed for several types of algorithms, including:\n\n\nA. Anomaly detection: This is useful for detecting faults, zero-day attacks, and unusual behavior. On-chip training allows the chip to adapt to new long-term behaviors. This would help reduce the number of false positives given out by the system, and thus make it much more useful.\n\n\nB. Convolutional neural networks: These are used in many areas, including sensor data processing and scientific data processing. Often times, remote systems are exposed to new types of data and being able to train on the system means not having to transmit back the new data acquired (which is very time and energy consuming). Thus being able to train at the remote system enables the system to be more useful.\n\n\nC. Reinforcement learning: These are used in many robotic systems, including UAVs. Being able to retrain on system allows the robotic system to be more robust.\n\n\n4. A model was developed to rapidly examine the design space of training processors to find what chip architecture options would be best for a specific type of algorithm or network. Design space explorations can be very time consuming as they require the design of complex simulators that take a long time to run. Thus a mathematical modeling approach can be millions of times faster and help narrow down the amount of detailed simulation that would be needed later.\t\t\t\t\tLast Modified: 07/09/2024\n\n\t\t\t\t\tSubmitted by: TarekMTaha\n"
 }
}