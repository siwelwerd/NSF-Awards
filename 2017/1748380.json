{
 "awd_id": "1748380",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Evaluating the Feasibility of Estimating Cognitive Load Using Microsaccadic Eye Motion and Oscillation in Pupil Diameter",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-12-31",
 "tot_intn_awd_amt": 124977.0,
 "awd_amount": 124977.0,
 "awd_min_amd_letter_date": "2017-07-31",
 "awd_max_amd_letter_date": "2022-03-15",
 "awd_abstract_narration": "Systems that can detect and respond to their users' workload have the potential to improve both users' experiences and outcomes in many domains: students and teachers, drivers and pilots, rescue workers and soldiers might all benefit from systems that can detect when their jobs are too hard or easy and dynamically adapt the difficulty.  Key to this promise is the ability to accurately estimate a person's workload without distracting them from their tasks.  A promising, non-invasive approach is to estimate workload from eye movements, which are both known to correlate with cognitive activity and likely to become more widely available to computer systems as gaze tracking tools are developed for both commercial-grade web cameras and for devices that support augmented and virtual reality interfaces.  However, commonly-proposed metrics for estimating workload, notably pupil diameter, have severe practical limitations around head motion, ambient light, and camera angle.  Using a high-speed eye tracker and commonly used cognitive load and visual search tasks, this project will develop mathematical processing techniques to translate tiny eye movements (\"micorsaccades\") and pupil oscillation into workload estimates, then study the feasibility and accuracy of using those measures relative to pupil diameter and other ways of estimating workload.  The work will take place in conjunction with several international partners, provide a student with international research experience, and help inform a future workshop on ubiquitous gaze sensing.\r\n\r\nThe team will first develop and refine multiple candidate measures of cognitive load that focus on pupil motion and change.  The first, Change in Pupil Diameter (relative to a baseline), represents commonly-proposed approaches.  The second, the Index of Pupillary Activity, is based on a prior measure called the Index of Cognitive Activity derived from the oscillation frequency of pupil diameter (\"pupil unrest\").  It is likely to be better than raw pupil diameter, but still suffers from drawbacks around ambient light and off-axis distortion.  The other is a technique based on microsaccadic activity that can be extracted from eye gaze positions rather than pupil diameter, ideally eliminating the drawbacks to diameter-based metrics.  The team has already shown that their current versions of these metrics show promise in fixed-gaze tasks in which participants are asked to focus on a single, centralized fixation point while performing more and less difficult metal calculations.  The next step is to generalize this work to fixed gaze at arbitrary angles, first by adapting the metrics to include techniques for off-axis pupil diameter compensation, then conducting similar workload tasks but where participants focus on one of a number of gaze targets located around the screen.  This experiment to show that gaze can be shifted and off-center then sets up more realistic, unrestricted visual search tasks in which the team will ask participants to locate elevation-based terrain features in simulated maps that allow the team to control the location and workload involved in the search task.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Andrew",
   "pi_last_name": "Duchowski",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Andrew T Duchowski",
   "pi_email_addr": "duchowski@clemson.edu",
   "nsf_id": "000492350",
   "pi_start_date": "2017-07-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Clemson University",
  "inst_street_address": "201 SIKES HALL",
  "inst_street_address_2": "",
  "inst_city_name": "CLEMSON",
  "inst_state_code": "SC",
  "inst_state_name": "South Carolina",
  "inst_phone_num": "8646562424",
  "inst_zip_code": "296340001",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "SC03",
  "org_lgl_bus_name": "CLEMSON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "H2BMNX7DSKU8"
 },
 "perf_inst": {
  "perf_inst_name": "Clemson University",
  "perf_str_addr": "100 McAdams Hall",
  "perf_city_name": "Clemson",
  "perf_st_code": "SC",
  "perf_st_name": "South Carolina",
  "perf_zip_code": "296340001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "SC03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 124977.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project advanced the state-of-the-art measurement of cognitive load through eye-tracking means. An eye tracker is a device that captures images of the human eye and outputs the position of viewer&rsquo;s eye gaze on the scene in front of the viewer as well as of the viewer&rsquo;s pupil diameter.</p>\n<p>Research activities involved: 1. technical development of gaze analytics, including traditional pupillomet- ric measures related to baseline, wavelet analysis, and microsaccadic magnitude and rate; 2. psychometric evaluation of gaze-based cognitive load measures, replicating cognitive load tasks with fixed gaze (central target), cognitive load tasks with dispersed gaze (targets far from center), and basic visual search tasks with unrestricted gaze movement.</p>\n<p>The project showed a link to cognitive load through high-speed measurement of eye gaze position via microsaccade magnitude, but not microsaccade rate. Two pupillometric measures were also developed, namely the IPA (Index of Pupillary Activity) and the LHIPA (Low/High Index of Pupillary Activity). The IPA was found to indicate cognitive load only during fixed-gazed tasks, which is not very ecologically valid, whereas LHIPA showed more robust and promising results, differentiating between baseline and task. Impacts of this project are broad, as they may be applicable to a wide range of applications, including assessment and training of surgeons, visual monitoring of pilots, human-centered design, human cognition modeling, usability, and learning. One limitation of the project is that the metrics developed work mostly offline and are not suitable for real-time implementation. Future research is required to develop real-time versions of these metrics.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/22/2022<br>\n\t\t\t\t\tModified by: Andrew&nbsp;T&nbsp;Duchowski</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project advanced the state-of-the-art measurement of cognitive load through eye-tracking means. An eye tracker is a device that captures images of the human eye and outputs the position of viewer\u2019s eye gaze on the scene in front of the viewer as well as of the viewer\u2019s pupil diameter.\n\nResearch activities involved: 1. technical development of gaze analytics, including traditional pupillomet- ric measures related to baseline, wavelet analysis, and microsaccadic magnitude and rate; 2. psychometric evaluation of gaze-based cognitive load measures, replicating cognitive load tasks with fixed gaze (central target), cognitive load tasks with dispersed gaze (targets far from center), and basic visual search tasks with unrestricted gaze movement.\n\nThe project showed a link to cognitive load through high-speed measurement of eye gaze position via microsaccade magnitude, but not microsaccade rate. Two pupillometric measures were also developed, namely the IPA (Index of Pupillary Activity) and the LHIPA (Low/High Index of Pupillary Activity). The IPA was found to indicate cognitive load only during fixed-gazed tasks, which is not very ecologically valid, whereas LHIPA showed more robust and promising results, differentiating between baseline and task. Impacts of this project are broad, as they may be applicable to a wide range of applications, including assessment and training of surgeons, visual monitoring of pilots, human-centered design, human cognition modeling, usability, and learning. One limitation of the project is that the metrics developed work mostly offline and are not suitable for real-time implementation. Future research is required to develop real-time versions of these metrics.\n\n \n\n\t\t\t\t\tLast Modified: 12/22/2022\n\n\t\t\t\t\tSubmitted by: Andrew T Duchowski"
 }
}