{
 "awd_id": "1705095",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: Medium: Collaborative Research: Data Center Scale Programmable Storage",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Erik Brunvand",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2017-07-05",
 "awd_max_amd_letter_date": "2019-08-08",
 "awd_abstract_narration": "Historically, applications usually interface with persistent storage systems through protocols, abstractions and interfaces. Protocols define a series of actions that can be taken on the storage such as reading, or writing and have an implicit abstraction model such as blocks or objects. Interfaces such as general or dedicated storage networks transport protocol messages. While protocols and interfaces simplify storage system design, both impact performance by the use of abstraction models and limited operations. Emerging storage class memory has low latency and granular operations, greatly increasing the relative impact of the overhead of protocols, abstractions and interfaces. This project is re-imagining the storage interface as programmable storage, where the defined protocol involves sending encapsulated programs to the actual storage where their effect is applied. This will improve the performance of distributed systems as well as storage applications, both of which are central to Internet applications.\r\n\r\nThe intellectual challenge in this project is the design of the new storage abstractions, insuring they are suitable for a variety of new storage media and that security is maintained while performance is improved. We are extending an existing storage system to include features of programmable storage while also supporting emerging consensus on low-level components used by distributed systems, such as persistent logs and transactional operations at the memory level. The project is using existing run-time code generation frameworks to insure that the programmable interface generates portable code that is also efficient. Part of the research effort is developing consensus among industry and academic researchers on the necessity and sufficiency of the storage abstractions we propose and developing educational materials to demonstrate how they should be used.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dirk",
   "pi_last_name": "Grunwald",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Dirk C Grunwald",
   "pi_email_addr": "grunwald@cs.colorado.edu",
   "nsf_id": "000308739",
   "pi_start_date": "2017-07-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Colorado at Boulder",
  "inst_street_address": "3100 MARINE ST",
  "inst_street_address_2": "STE 481 572 UCB",
  "inst_city_name": "Boulder",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "3034926221",
  "inst_zip_code": "803090001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "THE REGENTS OF THE UNIVERSITY OF COLORADO",
  "org_prnt_uei_num": "",
  "org_uei_num": "SPVKK1RC2MZ3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Colorado at Boulder",
  "perf_str_addr": "3100 Marine Street, Room 481",
  "perf_city_name": "Boulder",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "803090572",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 379217.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 120783.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">Datacenter applications are those applications that we use every day that don?t run directly on a laptop or mobile. Applications like email, chat, video services and other datacenter applications depend on a variety of compute storage systems to both store the data used in those applications but also to coordinate the activities of the many computers implementing the application as part of the datacenter</p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p1\">The overarching goal of this project is to improve the performance of the storage systems used in datacenter applications. This was done by two overlapping efforts. The first involved developing software for improving the performance of small storage operations in a datacenter. The other involves allocating storage resources in a ?multi-tenant? datacenter where the performance of different parties need to managed.</p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p1\">Datacenters are unique because they combine general purpose computers and can also involve programmable networking equipment that can be used to accelerate specific applications. Many of those storage applications rely on small amounts of data that are used to index other data or to coordinate the activity of the hundreds of computers involved in each application in that datacenter. We studied the needs of various software systems and developed a software library that enable the development of distributed data structures that are spread across multiple machines for performance and duplicated across yet more machines for reliability. We then examined the trends of datacenter networks to identify that changes to core network switches and ?infrastructure computing devices? used by servers in those networks to accelerate key data and coordination tasks. We studied Paxos, a common coordination algorithm in datacenter applications, and demonstrated that we could separate parts of the application into a ?fast path? and ?slow path?. Then, using software libraries we developed, the ?fast path? for those algorithms were implemented across the network switches and infrastructure competing devices in servers. By taking advantage of ?software defined operating systems? as well as ?software defined networks?, only minor changes were needed to greatly accelerate existing applications. We demonstrated that we could reduce operations latency by an order-of-magnitude with very small required software changes.</p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p1\">We also developed algorithms to allocate storage across multiple ?caching tiers? of a datacenter. We focused on ?multi-tenant? caching where a single storage cache resource is split across multiple applications or tenants. Our storage allocation algorithm is one of the first that can optimize multiple levels of the storage hierarchy quickly and efficiently; prior algorithms could perform the storage allocation but were so slow they needed to be performed ?off line? based on assumptions of the storage access patterns.</p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p1\">During the research project, three graduate students were supported by the award. Two of those students graduated with their Ph.D. degree; one works for Google as a Software Engineer in their datacenter storage group and the other is a Research Scientist at Facebook working on distributed transactional databases. The third student received their MS degree on aspects of this work and is continuing to work on their Ph.D. in a related but different area.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/19/2022<br>\n\t\t\t\t\tModified by: Dirk&nbsp;C&nbsp;Grunwald</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Datacenter applications are those applications that we use every day that don?t run directly on a laptop or mobile. Applications like email, chat, video services and other datacenter applications depend on a variety of compute storage systems to both store the data used in those applications but also to coordinate the activities of the many computers implementing the application as part of the datacenter\n \nThe overarching goal of this project is to improve the performance of the storage systems used in datacenter applications. This was done by two overlapping efforts. The first involved developing software for improving the performance of small storage operations in a datacenter. The other involves allocating storage resources in a ?multi-tenant? datacenter where the performance of different parties need to managed.\n \nDatacenters are unique because they combine general purpose computers and can also involve programmable networking equipment that can be used to accelerate specific applications. Many of those storage applications rely on small amounts of data that are used to index other data or to coordinate the activity of the hundreds of computers involved in each application in that datacenter. We studied the needs of various software systems and developed a software library that enable the development of distributed data structures that are spread across multiple machines for performance and duplicated across yet more machines for reliability. We then examined the trends of datacenter networks to identify that changes to core network switches and ?infrastructure computing devices? used by servers in those networks to accelerate key data and coordination tasks. We studied Paxos, a common coordination algorithm in datacenter applications, and demonstrated that we could separate parts of the application into a ?fast path? and ?slow path?. Then, using software libraries we developed, the ?fast path? for those algorithms were implemented across the network switches and infrastructure competing devices in servers. By taking advantage of ?software defined operating systems? as well as ?software defined networks?, only minor changes were needed to greatly accelerate existing applications. We demonstrated that we could reduce operations latency by an order-of-magnitude with very small required software changes.\n \nWe also developed algorithms to allocate storage across multiple ?caching tiers? of a datacenter. We focused on ?multi-tenant? caching where a single storage cache resource is split across multiple applications or tenants. Our storage allocation algorithm is one of the first that can optimize multiple levels of the storage hierarchy quickly and efficiently; prior algorithms could perform the storage allocation but were so slow they needed to be performed ?off line? based on assumptions of the storage access patterns.\n \nDuring the research project, three graduate students were supported by the award. Two of those students graduated with their Ph.D. degree; one works for Google as a Software Engineer in their datacenter storage group and the other is a Research Scientist at Facebook working on distributed transactional databases. The third student received their MS degree on aspects of this work and is continuing to work on their Ph.D. in a related but different area.\n\n \n\n\t\t\t\t\tLast Modified: 04/19/2022\n\n\t\t\t\t\tSubmitted by: Dirk C Grunwald"
 }
}