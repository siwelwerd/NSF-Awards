{
 "awd_id": "1740197",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "E2CDA: Type I: Collaborative Research: Energy-Efficient Artificial Intelligence with Binary RRAM and Analog Epitaxial Synaptic Arrays",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2017-09-15",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 243618.0,
 "awd_amount": 243618.0,
 "awd_min_amd_letter_date": "2017-09-11",
 "awd_max_amd_letter_date": "2019-08-20",
 "awd_abstract_narration": "In recent years, deep learning and artificial neural networks have been very successful in large-scale recognition and classification tasks, some even surpassing human-level accuracy. However, state-of-the-art deep learning algorithms tend to present very large network models, which poses significant challenges for hardware, especially for memory. Emerging resistive devices have been proposed as an alternative solution for weight storage and parallel neural computing, but severe limitations still exist for applying resistive random access memories (RRAMs) for practical large-scale neural computing. This proposal targets on addressing limitations in resistive device based neural computing through novel device engineering, new bitcell designs, new neuron circuits, energy-aware architecture, and a new circuit-level benchmark simulator. A successful completion of this research is likely to have consequences to our society, enabling wide adoption of dense and energy-efficient intelligent hardware to power-/area-constrained local mobile/wearable devices. Furthermore, a self-learning chip that learns in near real-time and consumes very low-power can be integrated in smart biomedical devices, personalizing healthcare. This project will have a strong effort on integrating the research outcomes with education and outreach through summer outreach programs for high school students, undergraduate/graduate student training, and organization of tutorials and workshops at conferences for knowledge dissemination.\r\n\r\nThe proposal will perform  interdisciplinary research to address many limitations in today's resistive device based neural computing and make a leap progress towards energy-efficient intelligent computing. Severe limitations of applying resistive random access memories (RRAMs) for practical large-scale neural computing include: (1) device-level non-idealities, e.g., non-linearity, variability, selector, and endurance, (2) inefficiency in representing negative weights and neurons, and (3) limited demonstration on simpler networks, instead of cutting-edge convolutional and recurrent neural networks. To address these limitations, novel technologies from devices to architectures will be investigated. First, new bitcell circuits will be designed for today's binary resistive devices, efficiently mapping XNOR functionality with (+1, -1) weights and neurons. Second, a novel epitaxial resistive device (EpiRAM) that exhibits many idealistic properties will be investigated, including linear programming for analog weights, suppressed variability, self-selectivity, and high endurance. Third, new neuron circuits will be explored for integration with new resistive devices for feedforward/feedback deep neural networks. Finally, new data-mapping techniques that efficiently map state-of-the-art deep neural networks onto the hardware framework with RRAM arrays will be developed, and the overall energy-efficiency will be verified with a new benchmark simulator \"NeuroSim\". With innovations across material, device, circuit and architecture,  research needs will be pursued towards energy-efficient processing in ubiquitous resource-constrained hardware systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Saibal",
   "pi_last_name": "Mukhopadhyay",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Saibal Mukhopadhyay",
   "pi_email_addr": "saibal@ece.gatech.edu",
   "nsf_id": "000083185",
   "pi_start_date": "2017-09-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Ave NW",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "015Y00",
   "pgm_ele_name": "Energy Efficient Computing: fr"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 81206.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 81206.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 81206.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Overview:</strong></p>\n<p>The energy-efficient hardware accelerators are essential for deployment of artificial intelligence and machine learning (AI/ML) algorithms, specially, neural networks, in resource-constrained environment. The processing-in-memory (PIM) platforms using resistive random-access memory (RRAM) devices promises orders of magnitudes improvements in energy-efficiency for running neural networks.&nbsp;&nbsp;This collaborative effort has developed methods to address limitations in ReRAM based neural network acceleration through novel device engineering, new bitcell designs, new neuron circuits, energy-aware architecture for RRAM arrays, and a new circuit-level benchmark simulator. The research performed at Georgia Tech has investigated co-design of system architecture and learning algorithms to improve energy-efficiency and robustness of RRAM based AI/ML platforms.</p>\n<p><strong>Outcomes (Intellectual Merit):</strong></p>\n<p>The research has investigated learning algorithms and system architectures to improve energy-efficiency and robustness of RRAM based processing-in-memory (PIM) platforms for acceleration of deep neural network (DNN) computation. The key intellectual outcomes are:</p>\n<p>1)&nbsp;&nbsp;&nbsp; This research has demonstrated a RRAM-based CIM platform acceleration of Recurrent Neural Network (RNN) and showed the feasibility of higher than 10X improvement in energy-efficiency over Central Processing Unit (CPU) or Graphics Processing Unit (GPU) based computation of RNN.&nbsp;</p>\n<p>2)&nbsp;&nbsp;&nbsp; This research has showed that the intrinsic stochastic behavior of RRAM devices, for example, the statistical distribution of device resistance, the set/reset voltage, etc, makes RRAM-based DNN computation error-prone.&nbsp;The research showed that introducing device-variation-aware (DVA) noise in the parameters during training of a DNN, coupled with use of the dynamic-fixed-point data format, enhances robustness of an RRAM-based DNN accelerator.&nbsp;</p>\n<p>3) To further improve the robustness of DNN based PIM, the research has developed a hybrid architecture that couples PIM with standard digital accelerators. The approach uses eigenvalues of the Hessian of the loss function as a metric to identify the most sensitive parameters and protect computations associated with these parameters by mapping them to a digital multiply-and-accumulate engines while the rest of the parameters are mapped to the PIM.&nbsp;The hardware cost-aware selection of a few (&lt;5%) of parameters for protection can significantly limit accuracy degradation even under large device variations.</p>\n<p>4)&nbsp;&nbsp;&nbsp;The research has developed an all-digital processing-in-memory design with flexible bit-precision. The research has also proposed a Genetic Algorithm (GA) based approach for layer-wise quantization of bit-precisions of a DNN, without the need for re-training. The architecture coupled with GA-based precision control improves energy-efficiency of PIM-based DNN accelerators. The research has designed and fabricated a SRAM-based test-chip to demonstrate the key concept of all-digital PIM design.&nbsp;&nbsp;The GA-based approach is extended to mixed-signal PIM to optimize precision while considering the effect of quantization on the energy-dissipation of analog-to-digital converters.&nbsp;</p>\n<p><strong>Outcomes (Broader Impact)</strong>: The outcome from the performed research will facilitate design of intelligent edge devices running embedded artificial intelligence and machine learning models for many applications including industrial, entertainment, military, security, and energy to name a few. The research outcomes have been disseminated via multiple journal and conference publications. The research has involved several graduate students during the course of the project and they have received diverse experience ranging from device analysis, chip design, architecture optimization, and artificial intelligence algorithms. The PI has presented results from this work in his invited talks and discussions at workshops and conferences tau. The educational outcome involved including processing-in-memory design concepts in courses taught by the PI.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/03/2023<br>\n\t\t\t\t\tModified by: Saibal&nbsp;Mukhopadhyay</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOverview:\n\nThe energy-efficient hardware accelerators are essential for deployment of artificial intelligence and machine learning (AI/ML) algorithms, specially, neural networks, in resource-constrained environment. The processing-in-memory (PIM) platforms using resistive random-access memory (RRAM) devices promises orders of magnitudes improvements in energy-efficiency for running neural networks.  This collaborative effort has developed methods to address limitations in ReRAM based neural network acceleration through novel device engineering, new bitcell designs, new neuron circuits, energy-aware architecture for RRAM arrays, and a new circuit-level benchmark simulator. The research performed at Georgia Tech has investigated co-design of system architecture and learning algorithms to improve energy-efficiency and robustness of RRAM based AI/ML platforms.\n\nOutcomes (Intellectual Merit):\n\nThe research has investigated learning algorithms and system architectures to improve energy-efficiency and robustness of RRAM based processing-in-memory (PIM) platforms for acceleration of deep neural network (DNN) computation. The key intellectual outcomes are:\n\n1)    This research has demonstrated a RRAM-based CIM platform acceleration of Recurrent Neural Network (RNN) and showed the feasibility of higher than 10X improvement in energy-efficiency over Central Processing Unit (CPU) or Graphics Processing Unit (GPU) based computation of RNN. \n\n2)    This research has showed that the intrinsic stochastic behavior of RRAM devices, for example, the statistical distribution of device resistance, the set/reset voltage, etc, makes RRAM-based DNN computation error-prone. The research showed that introducing device-variation-aware (DVA) noise in the parameters during training of a DNN, coupled with use of the dynamic-fixed-point data format, enhances robustness of an RRAM-based DNN accelerator. \n\n3) To further improve the robustness of DNN based PIM, the research has developed a hybrid architecture that couples PIM with standard digital accelerators. The approach uses eigenvalues of the Hessian of the loss function as a metric to identify the most sensitive parameters and protect computations associated with these parameters by mapping them to a digital multiply-and-accumulate engines while the rest of the parameters are mapped to the PIM. The hardware cost-aware selection of a few (&lt;5%) of parameters for protection can significantly limit accuracy degradation even under large device variations.\n\n4)   The research has developed an all-digital processing-in-memory design with flexible bit-precision. The research has also proposed a Genetic Algorithm (GA) based approach for layer-wise quantization of bit-precisions of a DNN, without the need for re-training. The architecture coupled with GA-based precision control improves energy-efficiency of PIM-based DNN accelerators. The research has designed and fabricated a SRAM-based test-chip to demonstrate the key concept of all-digital PIM design.  The GA-based approach is extended to mixed-signal PIM to optimize precision while considering the effect of quantization on the energy-dissipation of analog-to-digital converters. \n\nOutcomes (Broader Impact): The outcome from the performed research will facilitate design of intelligent edge devices running embedded artificial intelligence and machine learning models for many applications including industrial, entertainment, military, security, and energy to name a few. The research outcomes have been disseminated via multiple journal and conference publications. The research has involved several graduate students during the course of the project and they have received diverse experience ranging from device analysis, chip design, architecture optimization, and artificial intelligence algorithms. The PI has presented results from this work in his invited talks and discussions at workshops and conferences tau. The educational outcome involved including processing-in-memory design concepts in courses taught by the PI.\n\n \n\n\t\t\t\t\tLast Modified: 02/03/2023\n\n\t\t\t\t\tSubmitted by: Saibal Mukhopadhyay"
 }
}