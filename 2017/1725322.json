{
 "awd_id": "1725322",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SPX: Collaborative Research: Mongo Graph Machine (MGM): A Flash-Based Appliance for Large Graph Analytics",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 279935.0,
 "awd_amount": 279935.0,
 "awd_min_amd_letter_date": "2017-09-12",
 "awd_max_amd_letter_date": "2017-09-12",
 "awd_abstract_narration": "We live in the age of big data. In many problem domains such as data-mining, machine learning, scientific computing, and the study of social networks, the data deals with relationships between pairs of entities, and is represented by a data structure called a graph. Graphs of interest today may have hundreds of billions of entities, and trillions of relationships between these entities. Large-scale graph processing is typically done in data-centers which are huge clusters of power hungry computers. The proposed Mongo Graph Machine (MGM) project will explore a different solution known as out-of-core processing. In this system, graphs will be stored in flash memory, which is much cheaper, denser and cooler than DRAMs, and processed using a combination of specialized circuits called FPGAs in tandem with a conventional processor. A programming system will be developed to hide this complexity from the end-user. The resulting system will be small enough to fit under a desk and dramatically more energy-efficient while providing powerful graph processing capability.\r\n\r\nThe MGM project will address the problem of storing and processing extreme-scale graphs by using in-storage acceleration based on NAND flash chips with an attached FPGA. A single machine can accommodate 1 TB to 16 TBs of flash memory using current NAND technology. This configuration provides the flash storage necessary to store very large graphs and the computational power necessary to saturate the bandwidth of the flash. To address the programming problem for this architecture, the project will develop compiler technology and FPGA accelerators that will permit developers to write applications in the high-level programming model, leaving it to the system to exploit parallelism and optimize memory accesses for the access characteristics of flash storage. The software system will be based on the Galois system, which has been shown to scale to hundreds of processors on large shared-memory machines.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Keshav",
   "pi_last_name": "Pingali",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Keshav Pingali",
   "pi_email_addr": "pingali@cs.utexas.edu",
   "nsf_id": "000101776",
   "pi_start_date": "2017-09-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121229",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 279935.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"tinyMCEContent\">\n<p>Problem domains such as machine learning  and the study of social networks require the analysis of extremely  large, sparse graphs with billions of nodes and hundreds of billions of  edges. At present, two approaches are used to deal with such enormous  graphs: in-memory computing and out-of-core computing. In the in-memory  approach, the entire graph is stored in main memory of the computer for the duration of  the computation; since single machines have limited memory, this  approach requires the use of large numbers of machines. In the out-of-core  approach, the graph is stored in secondary storage such as disk, and  portions of the graph are brought into memory when they are needed for  computation. Out-of-core processing of large graphs avoids some of the  problems of using clusters, but most of the existing work in this area  has focused on hard disk-drives (HDD) which are slow compared to  storage&nbsp; technologies like SSD and Intel's Optane memory.</p>\n<p>This project developed programming  models, systems support and hardware acceleration for fast and  energy-efficient approaches to processing such very large graphs, using  NAND flash memory with FPGA-based in-store accelerators, and Intel's Optane non-volatile storage. A single machine can accommodate 1 TB to 16  TBs of flash memory using current NAND technology, so the need for  large clusters is eliminated. Flash-based machines, however, require  significant extra computation to make efficient use of bandwidth. The project investigated the use of in-store accelerators to reorganize irregular data  accesses into page-granularity data accesses required to use flash  memory. In addition, the project demonstrated how Optane memory can be used for analytics on very large graphs.</p>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/12/2022<br>\n\t\t\t\t\tModified by: Keshav&nbsp;Pingali</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nProblem domains such as machine learning  and the study of social networks require the analysis of extremely  large, sparse graphs with billions of nodes and hundreds of billions of  edges. At present, two approaches are used to deal with such enormous  graphs: in-memory computing and out-of-core computing. In the in-memory  approach, the entire graph is stored in main memory of the computer for the duration of  the computation; since single machines have limited memory, this  approach requires the use of large numbers of machines. In the out-of-core  approach, the graph is stored in secondary storage such as disk, and  portions of the graph are brought into memory when they are needed for  computation. Out-of-core processing of large graphs avoids some of the  problems of using clusters, but most of the existing work in this area  has focused on hard disk-drives (HDD) which are slow compared to  storage  technologies like SSD and Intel's Optane memory.\n\nThis project developed programming  models, systems support and hardware acceleration for fast and  energy-efficient approaches to processing such very large graphs, using  NAND flash memory with FPGA-based in-store accelerators, and Intel's Optane non-volatile storage. A single machine can accommodate 1 TB to 16  TBs of flash memory using current NAND technology, so the need for  large clusters is eliminated. Flash-based machines, however, require  significant extra computation to make efficient use of bandwidth. The project investigated the use of in-store accelerators to reorganize irregular data  accesses into page-granularity data accesses required to use flash  memory. In addition, the project demonstrated how Optane memory can be used for analytics on very large graphs.\n\n\n\t\t\t\t\tLast Modified: 01/12/2022\n\n\t\t\t\t\tSubmitted by: Keshav Pingali"
 }
}