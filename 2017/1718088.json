{
 "awd_id": "1718088",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: Programming Tools for Adaptive Data Analysis",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 224409.0,
 "awd_amount": 224409.0,
 "awd_min_amd_letter_date": "2017-07-07",
 "awd_max_amd_letter_date": "2017-07-07",
 "awd_abstract_narration": "False discovery, or overfitting, occurs when an empirical researcher draws a conclusion based on a dataset that does not generalize to new data.  Although there are many statistical methods for preventing false discovery, most are designed for static data analysis, where a dataset is used only once.  However, modern data analysis is adaptive, and often the same datasets are reused for multiple studies by multiple researchers.  Adaptivity has been identified by statisticians as one cause of non-reproducible research, and this project?s broader significance and importance will be to begin addressing this problem.  Specifically, this project will build a prototype programming tool for preventing false discovery arising from adaptive data analysis.  The intellectual merits are to incorporate and extend recent theoretical advances on this problem into a programming framework that allows researchers to analyze datasets adaptively with robust guarantees that overfitting will not occur.\r\n\r\nThe project builds on a surprising recent connection between differential privacy and false discovery, a robust statistical guarantee that emerged recently to protect the privacy of sensitive data. This line of work shows that when data is analyzed in a differentially private way, then false discoveries cannot occur. Differential privacy is also programmable, and allows complex differentially private algorithms to be built from simple components, so it is an ideal programming framework for adaptive data analysis.  This project is extending existing differentially private programming frameworks to adaptive data analysis.  The PIs are also developing new algorithmic and programming languages tools for adaptive data analysis, and incorporating them into the first prototype system for this application.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jonathan",
   "pi_last_name": "Ullman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jonathan Ullman",
   "pi_email_addr": "jullman@ccs.neu.edu",
   "nsf_id": "000710812",
   "pi_start_date": "2017-07-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 224409.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-70504cd6-7fff-70bc-a186-b4037752516d\">\n<p dir=\"ltr\"><span>A false discovery occurs when a researcher draws a conclusion based on a dataset that does not generalize to new data.&nbsp; Despite decades of research by the statistics community, false discovery remains a source of consternation in the empirical sciences.&nbsp; While there are many sources of false discovery, one that has been receiving increased attention is adaptivity&mdash;most statistical tools are designed for static data analysis, where a dataset is used once, whereas modern data analysis is adaptive, and the same datasets are reused in complex ways that invalidate classical methods for preventing false discovery.&nbsp; Adaptivity has even been blamed for a &ldquo;statistical crisis&rdquo; in science.</span></p>\n<br />\n<p dir=\"ltr\"><span>The outcome of this project was to develop new algorithmic and programming-language tools to ensure statistically sound adaptive data analysis.&nbsp; These tools are based on a recent surprising connection between false discovery and differential privacy, a criterion that emerged for protecting the privacy of sensitive data.&nbsp; This line of work showed that when data is analyzed in a differentially private manner, then false discoveries cannot occur, leading to new methods for preventing false discovery in adaptive data analysis that have greater statistical power than all previous methods.&nbsp; Perhaps most remarkably, these methods are also programmable, allowing complex statistical algorithms to be built from simple &ldquo;queries,&rdquo; so it is an ideal programming framework for adaptive data analysis.&nbsp;</span></p>\n<br />\n<p dir=\"ltr\"><span>The technical core of our project was twofold:&nbsp; to develop practical algorithmic tools for adaptive data analysis and to develop new programming language tools for adaptive data analysis.&nbsp; The PIs are continuing to incorporate these tools into a prototype system to support non-expert users engaging in adaptive data analysis.</span></p>\n<br />\n<p dir=\"ltr\"><span>On the algorithmic side, this project led to many technical advances to the state-of-the-art, namely:</span></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>The first sharp worst-case bounds for adaptive data analysis, showing the limits of all known approaches to mitigating false discovery.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>New minimax optimal stable algorithms for key statistical tasks like mean estimation, covariance estimation, and hypothesis testing</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>New practical estimators for mean and covariance estimation</span></p>\n</li>\n</ul>\n</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/22/2020<br>\n\t\t\t\t\tModified by: Jonathan&nbsp;Ullman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nA false discovery occurs when a researcher draws a conclusion based on a dataset that does not generalize to new data.  Despite decades of research by the statistics community, false discovery remains a source of consternation in the empirical sciences.  While there are many sources of false discovery, one that has been receiving increased attention is adaptivity&mdash;most statistical tools are designed for static data analysis, where a dataset is used once, whereas modern data analysis is adaptive, and the same datasets are reused in complex ways that invalidate classical methods for preventing false discovery.  Adaptivity has even been blamed for a \"statistical crisis\" in science.\n\n\nThe outcome of this project was to develop new algorithmic and programming-language tools to ensure statistically sound adaptive data analysis.  These tools are based on a recent surprising connection between false discovery and differential privacy, a criterion that emerged for protecting the privacy of sensitive data.  This line of work showed that when data is analyzed in a differentially private manner, then false discoveries cannot occur, leading to new methods for preventing false discovery in adaptive data analysis that have greater statistical power than all previous methods.  Perhaps most remarkably, these methods are also programmable, allowing complex statistical algorithms to be built from simple \"queries,\" so it is an ideal programming framework for adaptive data analysis. \n\n\nThe technical core of our project was twofold:  to develop practical algorithmic tools for adaptive data analysis and to develop new programming language tools for adaptive data analysis.  The PIs are continuing to incorporate these tools into a prototype system to support non-expert users engaging in adaptive data analysis.\n\n\nOn the algorithmic side, this project led to many technical advances to the state-of-the-art, namely:\n\n\nThe first sharp worst-case bounds for adaptive data analysis, showing the limits of all known approaches to mitigating false discovery.\n\n\nNew minimax optimal stable algorithms for key statistical tasks like mean estimation, covariance estimation, and hypothesis testing\n\n\nNew practical estimators for mean and covariance estimation\n\n\n\n\n\t\t\t\t\tLast Modified: 11/22/2020\n\n\t\t\t\t\tSubmitted by: Jonathan Ullman"
 }
}