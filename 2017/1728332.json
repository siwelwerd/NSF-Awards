{
 "awd_id": "1728332",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RR: Collaborative Research: Tracking Scientific Progress in Social Psychology",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Steven Breckler",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 324458.0,
 "awd_amount": 324458.0,
 "awd_min_amd_letter_date": "2017-08-03",
 "awd_max_amd_letter_date": "2017-08-03",
 "awd_abstract_narration": "A basic principle of the scientific method is that scientists are expected to update their theories in light of new evidence. Indeed, public investment in science is assumed to produce theoretical advances that lead to real-world changes such as better health care, more efficient technology, and a deeper understanding of human behavior. Recent findings, however, raise concerns about the robustness and reliability of scientific research. Some published findings cannot be replicated by other researchers, and thus fail to meet basic standards of scientific value. To address these concerns, the scientific community needs to (1) collect new evidence, testing and re-testing existing theories, and (2) update theories in response to this evidence. Psychological science has been a leader in initiating the first step, with multiple large-scale replication projects underway to test the robustness of existing theories. The current project complements these efforts by providing a real-world test of the second step, examining whether scientists adjust their theories in response to new evidence. Documenting how scientists respond to new evidence is fundamental to establishing the value of research.\r\n\r\nThis research tracks psychological scientists' beliefs in psychological theories before and after the release of results from two large-scale replication projects: Many Labs 5 (ML5) and Registered Replication Reports (RRRs). These projects offer evidence that reaches the highest standards of scientific rigor: researchers commit to methodology and data analysis strategy ahead of time, data are made available to the public, and results are published regardless of outcome. If psychological science is progressing as it should, this high-quality evidence should lead researchers to update their theories. If such updating is not happening, this project will help to determine why this might be the case and whether some researchers might be better than others in updating their theories. By identifying factors that promote scientific progress, and those that stand in the way, this project should contribute broadly to improving the robustness and reliability of research across all fields of science.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alexa",
   "pi_last_name": "Tullett",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alexa Tullett",
   "pi_email_addr": "atullett@bama.ua.edu",
   "nsf_id": "000649078",
   "pi_start_date": "2017-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Alabama Tuscaloosa",
  "inst_street_address": "801 UNIVERSITY BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "TUSCALOOSA",
  "inst_state_code": "AL",
  "inst_state_name": "Alabama",
  "inst_phone_num": "2053485152",
  "inst_zip_code": "354012029",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "AL07",
  "org_lgl_bus_name": "UNIVERSITY OF ALABAMA",
  "org_prnt_uei_num": "TWJWHYEM8T63",
  "org_uei_num": "RCNJEHZ83EV6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Alabama",
  "perf_str_addr": "505 Hackberry Lane",
  "perf_city_name": "Tuscaloosa",
  "perf_st_code": "AL",
  "perf_st_name": "Alabama",
  "perf_zip_code": "354012029",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "AL07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "133200",
   "pgm_ele_name": "Social Psychology"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "040Z",
   "pgm_ref_txt": "Robust and Reliable Science"
  },
  {
   "pgm_ref_code": "1332",
   "pgm_ref_txt": "SOCIAL PSYCHOLOGY"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 324458.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>In order for scientific progress to occur scientists must adjust their beliefs in light of new evidence. But, does this actually happen in practice?&nbsp;<span>This project was designed to answer three key questions: 1) How much do psychologists update their beliefs in response to new evidence?&nbsp;2) Do psychologists show signs of trying to preserve their pre-existing beliefs?&nbsp;3) What predicts the extent of psychologists' belief updating? </span></span></p>\n<p><span><span>To address these questions, we asked over 1,000 psychological scientists to rate their belief in psychological effects before and after new evidence became available from large scale replication studies.&nbsp;<span>We found that psychologists did update their beliefs; they updated as much as they predicted they would, but not as much as they \"should\" according to a statistical model (which assumes they trust the replication results). We found no evidence that psychologists attempted to preserve their pre-existing beliefs, but they were generally not strongly invested in the findings in the first place. We also found no evidence that experts updated their beliefs more, but people higher on intellectual humility updated their beliefs slightly more.&nbsp;</span></span></span></p>\n<p><span><span>These results have been accepted for publication in the journal Nature Human Behaviour. They have also been presented in talks at both the University of Alabama and the University of California, Davis, and are scheduled to be presented at the global Metascience Conference in September, 2021. The data from these studies are also being used to explore questions about psychologists' perceptions of the field and the accuracy of psychologists' predictions about replication outcomes.</span></span></p>\n<p><span><span>Overall, our results have implications for the National Science Foundation and the research that it funds. Our findings suggest that replication projects can make important contributions to self-correction within psychology, and that their value may currently be underestimated.<br /></span></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/06/2021<br>\n\t\t\t\t\tModified by: Alexa&nbsp;Tullett</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn order for scientific progress to occur scientists must adjust their beliefs in light of new evidence. But, does this actually happen in practice? This project was designed to answer three key questions: 1) How much do psychologists update their beliefs in response to new evidence? 2) Do psychologists show signs of trying to preserve their pre-existing beliefs? 3) What predicts the extent of psychologists' belief updating? \n\nTo address these questions, we asked over 1,000 psychological scientists to rate their belief in psychological effects before and after new evidence became available from large scale replication studies. We found that psychologists did update their beliefs; they updated as much as they predicted they would, but not as much as they \"should\" according to a statistical model (which assumes they trust the replication results). We found no evidence that psychologists attempted to preserve their pre-existing beliefs, but they were generally not strongly invested in the findings in the first place. We also found no evidence that experts updated their beliefs more, but people higher on intellectual humility updated their beliefs slightly more. \n\nThese results have been accepted for publication in the journal Nature Human Behaviour. They have also been presented in talks at both the University of Alabama and the University of California, Davis, and are scheduled to be presented at the global Metascience Conference in September, 2021. The data from these studies are also being used to explore questions about psychologists' perceptions of the field and the accuracy of psychologists' predictions about replication outcomes.\n\nOverall, our results have implications for the National Science Foundation and the research that it funds. Our findings suggest that replication projects can make important contributions to self-correction within psychology, and that their value may currently be underestimated.\n\n\n\t\t\t\t\tLast Modified: 08/06/2021\n\n\t\t\t\t\tSubmitted by: Alexa Tullett"
 }
}