{
 "awd_id": "1717120",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: SMALL: Metric Representations of Network Data",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2017-06-26",
 "awd_max_amd_letter_date": "2017-06-26",
 "awd_abstract_narration": "Network data, defined as one that encodes relationships between elements, is a pervasive component of modern data analytics. The purpose of this project is to advance our capacity to process and understand network data. The contention is that the central difficulty in analyzing large-scale complex networks comes from lack of structure. This loose nature contrasts with the rigidity of a closely related construction: the metric space. If understanding networks is challenging but understanding metric spaces is not, a route to network analysis is to project networks into metric spaces. This motivates the technical goal of designing methods and algorithms to implement these projections. \r\n\r\nThe project builds on preliminary results combining a projection axiom (networks that are already metric remain unchanged after projection) and a dissimilarity-reducing axiom (smaller networks have smaller projections) to establish existence and uniqueness results. Further explorations are pursued in four thrusts: (1) Study of projection methods in symmetric networks. (2) Incorporation of asymmetric networks and asymmetric quasimetric spaces. (3) Metric representations derived from triangle inequalities written in dioid algebras; which albeit metric in an abstract sense are very different from regular metrics. (4) Generalizations to high order networks in which dissimilarities are defined for tuples other than binary. Applications to search, network comparison, and diffusion processes, complement the theoretical research. Broader impacts come through industrial partnerships and an aggressive educational agenda that leverages the University of Pennsylvania's institutional commitment to play a leading role in the education of engineers that are to exploit the opportunities afforded by the ever increasing access to data and the ever broadening scope that networks play in our society.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alejandro",
   "pi_last_name": "Ribeiro",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alejandro Ribeiro",
   "pi_email_addr": "aribeiro@seas.upenn.edu",
   "nsf_id": "000514675",
   "pi_start_date": "2017-06-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "3451 WALNUT STREET",
  "perf_city_name": "PHILADELPHIA",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><h1>Metric Representations of Network Data<span style=\"color: #000000; font-size: 12px;\">&nbsp;</span></h1>\n<p>To a large extent, the continued success of machine learning rests on the development of techniques for processing data with unusual structure. Networks (graphs) and signals supported on networks, belong in this category. Indeed, while the use of convolutional filters and neural networks for processing signals in time and space (images) is well developed, the analogous tools for graphs have a short history.&nbsp;&nbsp;This project has played a central role in the development of the theoretical foundations of machine learning on graphs. These theoretical foundations pertain to the comparative performance of graph convolutional filters and neural networks and provide two interesting insights:</p>\n<p style=\"padding-left: 30px;\"><strong>Stability.</strong>&nbsp;The outputs of graph filters and graph neural networks can be stable to deformations of a graph. However, graph neural networks can better differentiate signals that are characterized by rapid variability with respect to the structure of the graph.</p>\n<p style=\"padding-left: 30px;\"><strong>Transferability.</strong>&nbsp;Graph filters and neural networks can be transferred across networks with different numbers of nodes. This property is key to enable operation in large scale graphs. Similar to stability, graph neural networks have better can better transfer the identification of features that are characterized by rapid variability with respect to the structure of the graph.</p>\n<p>Both properties help explain the success of graph neural networks relative to graph filters. &nbsp;&nbsp;</p>\n<p>This project has also played a central role in the development of the application of machine learning to distributed cyberphysical systems. We have, in particular, being the first to demonstrate the success of training graph neural networks in the following application domains:</p>\n<p style=\"padding-left: 30px;\"><strong>Wireless Communication Networks.</strong>&nbsp;We allocate power and bandwidth in across an interference network. Graph neural networks outperform state of the art heuristics. We also demonstrate that they are stable to network perturbations and that learned policies can be transferred from medium scale networks to large scale networks.</p>\n<p style=\"padding-left: 30px;\"><strong>Distributed Intelligent Systems.&nbsp;</strong>We coordinate a team of intelligent autonomous agents in a collaborative task. Graph neural networks learn policies for complex tasks in which known solutions are centralized. The learned policies succeed at imitating the centralized policy. We demonstrate stability and transferability.</p>\n<p style=\"padding-left: 30px;\"><strong>Power Transmission Grids.&nbsp;</strong>We demonstrate the ability of graph neural networks to approximate the solution of optimal power flow problems with small approximation errors.</p>\n<p>This project has supported the development of a course on graph neural networks at the University of Pennsylvania. This is a popular graduate level course with enrollments varying between 80 and 100 students. The course is made up of recorded lectures that are publicly available. The collection of lectures has an average of 2.2 K visits per month. See gnn.seas.upenn.edu. Two doctoral students that participated in this project are starting faculty positions in the Fall of 2022.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/05/2022<br>\n\t\t\t\t\tModified by: Alejandro&nbsp;Ribeiro</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Metric Representations of Network Data \n\nTo a large extent, the continued success of machine learning rests on the development of techniques for processing data with unusual structure. Networks (graphs) and signals supported on networks, belong in this category. Indeed, while the use of convolutional filters and neural networks for processing signals in time and space (images) is well developed, the analogous tools for graphs have a short history.  This project has played a central role in the development of the theoretical foundations of machine learning on graphs. These theoretical foundations pertain to the comparative performance of graph convolutional filters and neural networks and provide two interesting insights:\nStability. The outputs of graph filters and graph neural networks can be stable to deformations of a graph. However, graph neural networks can better differentiate signals that are characterized by rapid variability with respect to the structure of the graph.\nTransferability. Graph filters and neural networks can be transferred across networks with different numbers of nodes. This property is key to enable operation in large scale graphs. Similar to stability, graph neural networks have better can better transfer the identification of features that are characterized by rapid variability with respect to the structure of the graph.\n\nBoth properties help explain the success of graph neural networks relative to graph filters.   \n\nThis project has also played a central role in the development of the application of machine learning to distributed cyberphysical systems. We have, in particular, being the first to demonstrate the success of training graph neural networks in the following application domains:\nWireless Communication Networks. We allocate power and bandwidth in across an interference network. Graph neural networks outperform state of the art heuristics. We also demonstrate that they are stable to network perturbations and that learned policies can be transferred from medium scale networks to large scale networks.\nDistributed Intelligent Systems. We coordinate a team of intelligent autonomous agents in a collaborative task. Graph neural networks learn policies for complex tasks in which known solutions are centralized. The learned policies succeed at imitating the centralized policy. We demonstrate stability and transferability.\nPower Transmission Grids. We demonstrate the ability of graph neural networks to approximate the solution of optimal power flow problems with small approximation errors.\n\nThis project has supported the development of a course on graph neural networks at the University of Pennsylvania. This is a popular graduate level course with enrollments varying between 80 and 100 students. The course is made up of recorded lectures that are publicly available. The collection of lectures has an average of 2.2 K visits per month. See gnn.seas.upenn.edu. Two doctoral students that participated in this project are starting faculty positions in the Fall of 2022.\n\n \n\n\t\t\t\t\tLast Modified: 07/05/2022\n\n\t\t\t\t\tSubmitted by: Alejandro Ribeiro"
 }
}