{
 "awd_id": "1652617",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Understanding Vision and Natural Motion Statistics Through the Lens of Prediction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2017-03-01",
 "awd_exp_date": "2022-02-28",
 "tot_intn_awd_amt": 549880.0,
 "awd_amount": 549880.0,
 "awd_min_amd_letter_date": "2017-02-17",
 "awd_max_amd_letter_date": "2019-01-28",
 "awd_abstract_narration": "The visual input to the brain is transformed even before signals leave the eye, and these computations produce an efficient representation of the structure of the natural visual world. Previous work by the PI has shown that this processing can include repackaging of information for optimal prediction. This suggests a new approach to neural encoding. While many previous studies have sought to characterize what stimuli in the past gave rise to a subsequent response, this work asks what future stimuli those responses predict. The proposed project will derive the best possible predictor given the way objects move in the outside world and quantify how close the brain gets to this optimum. Viewing the brain through the lens of prediction develops a principle of neural coding and computation that can bridge brain regions, from the retina to higher visual areas. A component of this plan involves measuring and quantifying the predictive components of natural motion. In doing so, a public database of natural motion will be created that will be a lasting tool for the neuroscience and computer vision communities. An associated educational program will bring over 100 local middle school children to campus each year for hands-on neuroscience experiments, and will instill in a large group of graduate students the rewards and responsibilities of science teaching.\r\n\r\nThe research proposed here explores prediction in the visual system in a variety of ways: by computing efficiency bounds on the predictive encoding of complex motion, by developing quantitative methods to test these bounds in neural datasets, by measuring the statistics of motion in natural scenes, and by describing how, mechanistically, the brain achieves this performance. Hypotheses about how the brain performs optimal predictive computations may be constrained by the structure of predictable events in the natural visual world. To measure these statistics, a new natural movie database will be constructed by making high-speed, high-pixel-depth recordings of natural scenes. By quantifying motion in these data, this project will yield statistical and generative models of natural motion that will inform our understanding of the natural world and provide a compact way to recapitulate natural motion in silico. These stimuli will be used to test whether neural systems optimally encode information relevant for prediction. The work will also test what adaptive and otherwise non-linear processing steps underlie optimal prediction in the brain.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Stephanie",
   "pi_last_name": "Palmer",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Stephanie E Palmer",
   "pi_email_addr": "sepalmer@uchicago.edu",
   "nsf_id": "000648940",
   "pi_start_date": "2017-02-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "924 E. 57th Street",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606371548",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 106386.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 440393.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 3101.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 15\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>The work funded by this award brought theoretical and mechanistic understanding to the deep mystery of how the brain drives precise behavior in a complex and ever-changing environment. One key computation for fluid behavior is prediction because of the lags inherent to all neural processing. What we see \"now\" lags significanly behind true current state of the external world. In order to catch prey, evade predators, and interact fluidly with the outside world, an organism must make fast and accurate predictions. Thus, effective prediction is crucial to survival.&nbsp;</span></p>\n<p>We discovered and quantified optimal coding of predictive information in the in the vertebrate retina and in the invertebrate motion sensing system. We showed that such an optimal code 1) is found in the retina of salmanders, rats, and mice, as well as the visual system of flies, 2) can be encoded and read-out with biologically plausible learning rules, and 3) can be tied to complex behaviors in the natural environment.</p>\n<p>We produced and disseminated a public database of natural motion videos that have been downloaded and used by other research groups across the country. From this database, we quantified the statistics of natural motion in a variety of scenes: e.g. flowing water, leaves blowing in the wind, and hives of bees. These movies and their analysis will help create new stimuli for future visual neuroscience experiments.</p>\n<p>We calculated what \"optimal prediction\" would look like in complex natural scenes using tools from information theory, statistical physics, and control theory. This map of how predictive computations are optimally organized allowed us to ask whether the brain achieves this performance in vastly different species with different brain circuitry and living in different ecological niches.&nbsp;</p>\n<p>By combining what we learned about natural scenes and optimal prediction, we were able to show how prediction could help a fly escape from a fast-moving predator, while in flight. This study also used the latest tools from machine learning to tame the complexity of natural inputs and natural behavior and reveal what parts of the fly's neural circuit (gap junctions or \"jumper cables\" between outputs in their vertical motion sensing array) are crucial for this kind of fast prediction.&nbsp;</p>\n<p>In tandem with our research, we expanded our \"Brains!\" hands-on experiment day for 7th grade students. Over the years, we brought over 500 local Chicago Public School students to campus to learn about how their neurons and muscles work. We partnered with education experts at Argonne National Labs to create a curriculum module from these experiments for use by middle school science teachers. We ran two pilot teacher training programs to further refine the module. We are committed to expanding and testing this curriculum module and to making it nationally accessible.&nbsp;&nbsp;</p>\n</div>\n</div>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/29/2022<br>\n\t\t\t\t\tModified by: Stephanie&nbsp;E&nbsp;Palmer</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\n\nThe work funded by this award brought theoretical and mechanistic understanding to the deep mystery of how the brain drives precise behavior in a complex and ever-changing environment. One key computation for fluid behavior is prediction because of the lags inherent to all neural processing. What we see \"now\" lags significanly behind true current state of the external world. In order to catch prey, evade predators, and interact fluidly with the outside world, an organism must make fast and accurate predictions. Thus, effective prediction is crucial to survival. \n\nWe discovered and quantified optimal coding of predictive information in the in the vertebrate retina and in the invertebrate motion sensing system. We showed that such an optimal code 1) is found in the retina of salmanders, rats, and mice, as well as the visual system of flies, 2) can be encoded and read-out with biologically plausible learning rules, and 3) can be tied to complex behaviors in the natural environment.\n\nWe produced and disseminated a public database of natural motion videos that have been downloaded and used by other research groups across the country. From this database, we quantified the statistics of natural motion in a variety of scenes: e.g. flowing water, leaves blowing in the wind, and hives of bees. These movies and their analysis will help create new stimuli for future visual neuroscience experiments.\n\nWe calculated what \"optimal prediction\" would look like in complex natural scenes using tools from information theory, statistical physics, and control theory. This map of how predictive computations are optimally organized allowed us to ask whether the brain achieves this performance in vastly different species with different brain circuitry and living in different ecological niches. \n\nBy combining what we learned about natural scenes and optimal prediction, we were able to show how prediction could help a fly escape from a fast-moving predator, while in flight. This study also used the latest tools from machine learning to tame the complexity of natural inputs and natural behavior and reveal what parts of the fly's neural circuit (gap junctions or \"jumper cables\" between outputs in their vertical motion sensing array) are crucial for this kind of fast prediction. \n\nIn tandem with our research, we expanded our \"Brains!\" hands-on experiment day for 7th grade students. Over the years, we brought over 500 local Chicago Public School students to campus to learn about how their neurons and muscles work. We partnered with education experts at Argonne National Labs to create a curriculum module from these experiments for use by middle school science teachers. We ran two pilot teacher training programs to further refine the module. We are committed to expanding and testing this curriculum module and to making it nationally accessible.  \n\n\n\n\n\t\t\t\t\tLast Modified: 06/29/2022\n\n\t\t\t\t\tSubmitted by: Stephanie E Palmer"
 }
}