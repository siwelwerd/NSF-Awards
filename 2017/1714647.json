{
 "awd_id": "1714647",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Small: Extracting Data and Structure from Charts and Graphs for Analysis, Reuse and Indexing",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 499419.0,
 "awd_amount": 499419.0,
 "awd_min_amd_letter_date": "2017-08-04",
 "awd_max_amd_letter_date": "2017-09-07",
 "awd_abstract_narration": "Charts and graphs are ubiquitous forms of data representations, appearing in scientific papers, textbooks, reports, news articles and webpages. These visualizations leverage human visual processing to efficiently convey large amounts of quantitative information, and to illustrate trends and differences in the data. But, while people can easily interpret data from charts and graphs, machines cannot directly access this data. Today, a vast trove of information is locked inside data visualizations. This proposal will develop techniques for extracting data and structure from such visualizations and thereby enable data further analysis, reuse and new forms of indexing across the collection of existing charts and graphs. Some of the applications will be specifically designed to improve the accessibility of visualizations for visual impaired users. The tools will provide a novel computational infrastructure for knowledge integration and sharing and impact a broad range of users including scientists, journalists, economists, social scientists, and educators. \r\n\r\n Specifically this proposal addresses three main goals. First, it develops computational models for interpreting visualizations to extract the underlying data, graphical marks, and mappings that relate the data to mark attributes. The approach will be informed by recent work on human perception and cognition of visualizations. The aim is to build generalized computational models that can accurately extract data from visualizations and also mimic the way people decode information from visualizations. Second, it supports development of a suite of applications that enable analysis and repurposing of visualizations and data. Third, it applies automated visualization interpretation techniques at Internet scale and develops a search engine that indexes visualizations based on their underlying data and graphical structure. The search engine will accelerate data-driven analysis and discovery by facilitating browsing and retrieval of data that is currently locked in computationally inaccessible visualizations. The project website will include information on the project and provide access to resulting publications, software and datasets.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maneesh",
   "pi_last_name": "Agrawala",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maneesh Agrawala",
   "pi_email_addr": "maneesh@cs.stanford.edu",
   "nsf_id": "000068262",
   "pi_start_date": "2017-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "353 Serra Mall, Gates 364",
  "perf_city_name": "Palo Alto",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943059025",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 499419.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Charts and graphs appear in a wide variety of documents to efficientlyconvey large amounts of numerical information and to reveal trends,differences, outliers and patterns in the data. But, the informationin such visualizations has been largely inaccessible to machines.</p>\n<p><br />This project has developed new computational methods and models thatcan interpret an input visualization, to extract the underlyingnumerical data it depicts, as well as the graphical structure used torepresent the data.&nbsp; Specifically is has led to the creation of toolsfor recovering this information from visualizations created usingD3.js, currently the most popular JavaScript library for creatingvisualizations online, as well as Vega-Lite, a more recent JavaScript visualization library that is used across the Web including inlarge-scale sites like Wikipedia.&nbsp; The project has also developedtools for extracting data tables from PDF documents, essentiallytreating the tables as another form of visualization.&nbsp; Each of thesevisualization deconstruction tools has also involved developing newlarge datasets of input charts, graphs and tables which are being usedby researchers worldwide to further development machine learningtechniques for analyzing such visualizations.</p>\n<p><br />Given the numerical data and the structure of a visualization thisproject has also developed a variety of tools and applications thatfacilitate automatic restyling, optimize visual design, allow largescale search based on graphical structure and that enable interactivereading of visualizations. These applications have demonstrated avariety of ways in which giving a machine access to the data andstructure of a visualization can further support human understandingand reasoning with the data.</p>\n<p><br />In gathering the datasets of real-world visualizations required forthis project the researchers found that most such visualizationsinclude text in the form of titles, captions and body text that serveto describe, provide context for, and emphasize patterns depicted inthe visualization. The project has conducted a variety of experimentsinvestigating how people read the charts together with the textelements that reference parts of it and how such reading can helpreaders form their takeaways about the data.</p>\n<p><br />This project has also led to the development of a tool for visualquestion answering with explanations, in the context of charts andgraphs. Specifically users can specify and visualization and write aquestion about it natural language. Given these inputs that toolapplies modern parsing and machine learning techniques toautomatically compute an answer as well as an natural languageexplanation for how it produced the answer. Human subject experimentshave shown that the explanations serve to increase trust andtransparency in the automated tool.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/03/2021<br>\n\t\t\t\t\tModified by: Maneesh&nbsp;Agrawala</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630700748580_vqae--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630700748580_vqae--rgov-800width.jpg\" title=\"Visual question answering with charts and graphs\"><img src=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630700748580_vqae--rgov-66x44.jpg\" alt=\"Visual question answering with charts and graphs\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Questions about a chart from a Pew research report. Our automatic chart question answering pipeline answers  all 3 questions correctly (markedin green) and gives correct explanations of how it obtained the answer, whereas Sempre, a state-of-the-art table question answering system gets all 3 wrong.</div>\n<div class=\"imageCredit\">Kim, Hoque and Agrawala 2020</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maneesh&nbsp;Agrawala</div>\n<div class=\"imageTitle\">Visual question answering with charts and graphs</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630700965946_tableDocReader--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630700965946_tableDocReader--rgov-800width.jpg\" title=\"Interactive document reader for tables.\"><img src=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630700965946_tableDocReader--rgov-66x44.jpg\" alt=\"Interactive document reader for tables.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our interactive document reader automatically extractsexplicit (left) and implicit (right) references between text and cells of an table for any input PDF document. Readers can click on a sentence to highlight the corresponding table cells and vice versa.</div>\n<div class=\"imageCredit\">Kim, Hoque, Kim and Agrawala 2018</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maneesh&nbsp;Agrawala</div>\n<div class=\"imageTitle\">Interactive document reader for tables.</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630700519123_styleTransfer--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630700519123_styleTransfer--rgov-800width.jpg\" title=\"Deconstructing D3 charts and converting them into style templates\"><img src=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630700519123_styleTransfer--rgov-66x44.jpg\" alt=\"Deconstructing D3 charts and converting them into style templates\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We apply a style template (a) to a source data table (b) to generate the result chart (e).</div>\n<div class=\"imageCredit\">Harper and Agrawala 2018.</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maneesh&nbsp;Agrawala</div>\n<div class=\"imageTitle\">Deconstructing D3 charts and converting them into style templates</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630701088931_searchEngine--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630701088931_searchEngine--rgov-800width.jpg\" title=\"Search engine for D3.js visualizations\"><img src=\"/por/images/Reports/POR/2021/1714647/1714647_10511042_1630701088931_searchEngine--rgov-66x44.jpg\" alt=\"Search engine for D3.js visualizations\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our search interface lets users query for D3.js  visualizations based on the data, the marks and the encodings that describe howvisual attributes of the marks represent the data.</div>\n<div class=\"imageCredit\">Hoque and Agrawala 2019</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maneesh&nbsp;Agrawala</div>\n<div class=\"imageTitle\">Search engine for D3.js visualizations</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nCharts and graphs appear in a wide variety of documents to efficientlyconvey large amounts of numerical information and to reveal trends,differences, outliers and patterns in the data. But, the informationin such visualizations has been largely inaccessible to machines.\n\n\nThis project has developed new computational methods and models thatcan interpret an input visualization, to extract the underlyingnumerical data it depicts, as well as the graphical structure used torepresent the data.  Specifically is has led to the creation of toolsfor recovering this information from visualizations created usingD3.js, currently the most popular JavaScript library for creatingvisualizations online, as well as Vega-Lite, a more recent JavaScript visualization library that is used across the Web including inlarge-scale sites like Wikipedia.  The project has also developedtools for extracting data tables from PDF documents, essentiallytreating the tables as another form of visualization.  Each of thesevisualization deconstruction tools has also involved developing newlarge datasets of input charts, graphs and tables which are being usedby researchers worldwide to further development machine learningtechniques for analyzing such visualizations.\n\n\nGiven the numerical data and the structure of a visualization thisproject has also developed a variety of tools and applications thatfacilitate automatic restyling, optimize visual design, allow largescale search based on graphical structure and that enable interactivereading of visualizations. These applications have demonstrated avariety of ways in which giving a machine access to the data andstructure of a visualization can further support human understandingand reasoning with the data.\n\n\nIn gathering the datasets of real-world visualizations required forthis project the researchers found that most such visualizationsinclude text in the form of titles, captions and body text that serveto describe, provide context for, and emphasize patterns depicted inthe visualization. The project has conducted a variety of experimentsinvestigating how people read the charts together with the textelements that reference parts of it and how such reading can helpreaders form their takeaways about the data.\n\n\nThis project has also led to the development of a tool for visualquestion answering with explanations, in the context of charts andgraphs. Specifically users can specify and visualization and write aquestion about it natural language. Given these inputs that toolapplies modern parsing and machine learning techniques toautomatically compute an answer as well as an natural languageexplanation for how it produced the answer. Human subject experimentshave shown that the explanations serve to increase trust andtransparency in the automated tool.\n\n\t\t\t\t\tLast Modified: 09/03/2021\n\n\t\t\t\t\tSubmitted by: Maneesh Agrawala"
 }
}