{
 "awd_id": "1704860",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "AF: Large: Collaborative Research: Nonconvex Methods and Models for Learning: Toward Algorithms with Provable and Interpretable Guarantees",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922182",
 "po_email": "pbrass@nsf.gov",
 "po_sign_block_name": "Peter Brass",
 "awd_eff_date": "2017-06-01",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 1700000.0,
 "awd_amount": 1721312.0,
 "awd_min_amd_letter_date": "2017-05-16",
 "awd_max_amd_letter_date": "2022-11-29",
 "awd_abstract_narration": "Artificial Intelligence along with Machine Learning are perhaps the most dominant research themes of our times - with far reaching implications for society and our current life style. While the possibilities are many, there are also doubts about how far these methods will go - and what new theoretical foundations may be required to take them to the next level overcoming possible hurdles. Recently, machine learning has undergone a paradigm shift with increasing reliance on  stochastic optimization to train highly non-convex models -- including but not limited to deep nets. Theoretical understanding has lagged behind, primarily because most problems in question are provably intractable on worst-case instances. Furthermore, traditional machine learning theory is mostly concerned with classification, whereas much practical success is driven by unsupervised learning and representation learning. Most past theory of representation learning was focused on simple models such as k-means clustering and PCA, whereas  practical work uses vastly more complicated models like autoencoders, restricted Boltzmann machines and deep generative models. The proposal presents an ambitious agenda for extending theory to embrace and support these practical trends, with hope of influencing practice. Theoretical foundations will be provided for the next generation of machine learning methods and optimization algorithms. \r\n\r\nThe project may end up having significant impact on  practical machine learning, and even cause a cultural change in the field -- theory as well as practice -- with long-term ramifications. Given the ubiquity as well as  economic and scientific implications of machine learning today, such impact will extend into other disciplines, especially in (ongoing) collaborations with researchers in neuroscience. The project will train a new generation of machine learning researchers, through an active teaching and mentoring plan at all levels, from undergrad to postdoc. This new generation will be at ease combining cutting edge theory and applications. There is a pressing need for such people today, and the senior PIs played a role in training/mentoring several existing ones.\r\n \r\nTechnical contributions will include new theoretical models of knowledge representation and semantics, and also frameworks for proving convergence of nonconvex optimization routines. Theory will be developed to explain and exploit the interplay between representation learning and supervised learning that has proved so empirically successful in deep learning, and seems to underlie new learning paradigms such as domain adaptation, transfer learning, and interactive learning. Attempts will be made to replace neural models with models with more \"interpretable\"  attributes and performance curves.  All PIs have a track record of combining theory with practice. They  are also devoted to a heterodox research approach, borrowing from all the past phases of machine learning: interpretable representations from the earlier phases (which relied on logical representations, or probabilistic models), provable guarantees from the middle phase (convex optimization, kernels etc.), and an embrace of nonconvex methods from the latest deep net phase. Such eclecticism is uncommon in machine learning, and may give rise to new paradigms and new kinds of science.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanjeev",
   "pi_last_name": "Arora",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sanjeev Arora",
   "pi_email_addr": "arora@cs.princeton.edu",
   "nsf_id": "000101873",
   "pi_start_date": "2017-05-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Elad",
   "pi_last_name": "Hazan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Elad Hazan",
   "pi_email_addr": "ehazan@cs.princeton.edu",
   "nsf_id": "000674538",
   "pi_start_date": "2017-05-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Yoram",
   "pi_last_name": "Singer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yoram Singer",
   "pi_email_addr": "ysinger@cs.princeton.edu",
   "nsf_id": "000735404",
   "pi_start_date": "2017-05-16",
   "pi_end_date": "2022-11-29"
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "35 Olden Street",
  "perf_city_name": "Princeton",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442020",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7796",
   "pgm_ref_txt": "ALGORITHMIC FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 669782.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 356690.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 358808.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 336032.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-5f6d2649-7fff-c520-8842-7a8f73069356\"> </span></p>\n<p dir=\"ltr\"><span>The main scientific developments that were made as part of this project include the following:</span></p>\n<ol>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Development of a </span><span>new theory for control based on online learning</span><span>, called &ldquo;Online Nonstochastic Control&rdquo;. Control is the scientific and engineering discipline of manipulating physical systems to achieve desired functionality, such as accurate and safe navigation of an autonomous vehicle. The theory of control spans centuries of scientific research, and is rooted in deep mathematical theory of stochastic differential equations. &nbsp; </span><span><br /></span><span>Our </span><span>new approach applies techniques from online convex optimization and convex relaxations to obtain new methods with provable guarantees for classical settings in optimal and robust control.&nbsp; The primary distinction between online nonstochastic control and other frameworks is the objective. In optimal control, robust control, and other control methodologies that assume stochastic noise, the goal is to perform comparably to an offline optimal strategy. In online nonstochastic control, both the cost functions as well as the perturbations from the assumed dynamical model are chosen by an adversary. Thus the optimal policy is not defined a priori. Rather, the target is to attain low regret against the best policy in hindsight from a benchmark class of policies. </span><span><br /></span><span>This objective suggests the use of the decision making framework of online convex optimization as an algorithmic methodology. The resulting methods are based on iterative mathematical optimization algorithms, and are accompanied by finite-time regret and computational complexity guarantees.</span><span><br /></span><span>Our new methods have been tested and benchmarked and shown to outperform all existing methods in a variety of settings. </span><span><br /></span><span>Numerous papers have been published detailing the theoretical and applied aspects of the new methodology, and a new book is in preparation. </span><span><br /><br /></span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Headway into the optimization and generalization aspects of a theory for deep learning. In terms of optimization, results in this category include new algorithms that are more efficient in terms of memory usage, theoretical analysis of stochastic gradient descent with exotic learning rate schedules, second order optimization methods, evidence of the acceleration of nonconvex optimization vs. convex counterpart for some existing models,&nbsp; understanding the edge-of-stability phenomenon, and more. </span><span><br /></span><span>In terms of generalization, results include understanding the implicit bias of stochastic gradient descent algorithms for matrix factorization and deep neural networks training. A new theory for emerging complex skills in language models was put forth, as well as new algorithms for fine tuning large language models based only on forward passes.&nbsp;</span></p>\n</li>\n</ol>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/01/2023<br>\n\t\t\t\t\tModified by: Elad&nbsp;Hazan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThe main scientific developments that were made as part of this project include the following:\n\n\nDevelopment of a new theory for control based on online learning, called \"Online Nonstochastic Control\". Control is the scientific and engineering discipline of manipulating physical systems to achieve desired functionality, such as accurate and safe navigation of an autonomous vehicle. The theory of control spans centuries of scientific research, and is rooted in deep mathematical theory of stochastic differential equations.   \nOur new approach applies techniques from online convex optimization and convex relaxations to obtain new methods with provable guarantees for classical settings in optimal and robust control.  The primary distinction between online nonstochastic control and other frameworks is the objective. In optimal control, robust control, and other control methodologies that assume stochastic noise, the goal is to perform comparably to an offline optimal strategy. In online nonstochastic control, both the cost functions as well as the perturbations from the assumed dynamical model are chosen by an adversary. Thus the optimal policy is not defined a priori. Rather, the target is to attain low regret against the best policy in hindsight from a benchmark class of policies. \nThis objective suggests the use of the decision making framework of online convex optimization as an algorithmic methodology. The resulting methods are based on iterative mathematical optimization algorithms, and are accompanied by finite-time regret and computational complexity guarantees.\nOur new methods have been tested and benchmarked and shown to outperform all existing methods in a variety of settings. \nNumerous papers have been published detailing the theoretical and applied aspects of the new methodology, and a new book is in preparation. \n\n\n\n\nHeadway into the optimization and generalization aspects of a theory for deep learning. In terms of optimization, results in this category include new algorithms that are more efficient in terms of memory usage, theoretical analysis of stochastic gradient descent with exotic learning rate schedules, second order optimization methods, evidence of the acceleration of nonconvex optimization vs. convex counterpart for some existing models,  understanding the edge-of-stability phenomenon, and more. \nIn terms of generalization, results include understanding the implicit bias of stochastic gradient descent algorithms for matrix factorization and deep neural networks training. A new theory for emerging complex skills in language models was put forth, as well as new algorithms for fine tuning large language models based only on forward passes. \n\n\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 09/01/2023\n\n\t\t\t\t\tSubmitted by: Elad Hazan"
 }
}