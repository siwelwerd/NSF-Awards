{
 "awd_id": "1734109",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: FND: Safe and Efficient Robot Collaboration System (SERoCS) for Next Generation Intelligent Industrial Co-Robots",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Bruce Kramer",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 750000.0,
 "awd_amount": 750000.0,
 "awd_min_amd_letter_date": "2017-08-17",
 "awd_max_amd_letter_date": "2017-08-17",
 "awd_abstract_narration": "In current automated factories, humans and robots typically work separately, partly for safety reasons and partly because full robotic automation has been a goal. In recent years, however, it has been recognized that there are tremendous opportunities when robots are brought out of their cages and allowed to collaborate with human workers in a shared workspace.  Such collaboration takes advantage of both the intelligence, adaptability and flexibility of humans and the endurance, strength and reliability of robots. In any collaboration between humans and robots, i.e. co-robots, it is important to consider and ensure both the safety of the humans and the best performance of the robots. This project aims to establish a set of design principles for a safe and efficient robot collaboration system (SERoCS).  Outside of factories, SERoCS may be applied in other settings, such as with mobility assistance of humans by robots and automated driving situations where human-driven vehicles and autonomous vehicles share the same road.\r\n\r\nSERoCS consists of three parts: (1) robust cognition algorithms for environment monitoring, (2) optimal task planning algorithms for safe human-robot collaboration, and (3) safe motion planning and control algorithms for safe human-robot interactions (HRI).  Research on cognition environment monitoring algorithms involves the construction of a cognition model library and the implementation of an algorithm for online prediction and adaptation of human behavior. In addition, task planning algorithms for safe human-robot collaboration require the construction of a motion skill library learned from human demonstrations and its association with an algorithm for online task planning and objective generation using learned skills. The two-layer structure that will be employed for safe motion planning and control algorithms comprises a long-term, efficiency-oriented planning layer and a short-term, safety-oriented control layer for safe HRIs. The SERoCS will signicantly expand the skill sets of the co-robots and prevent and minimize occurrences of human-robot collision and robot-robot collision during operation.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Masayoshi",
   "pi_last_name": "Tomizuka",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Masayoshi Tomizuka",
   "pi_email_addr": "tomizuka@berkeley.edu",
   "nsf_id": "000096673",
   "pi_start_date": "2017-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California, Berkeley",
  "perf_str_addr": "5100B Etcheverry Hall, Mailstop",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947201740",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "030E",
   "pgm_ref_txt": "CONTROL SYSTEMS"
  },
  {
   "pgm_ref_code": "082E",
   "pgm_ref_txt": "MFG MACHINES & METROLOGY"
  },
  {
   "pgm_ref_code": "7632",
   "pgm_ref_txt": "HUMAN-ROBOT INTERACTION"
  },
  {
   "pgm_ref_code": "8013",
   "pgm_ref_txt": "High Risk/Reward Innovative Research"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 750000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-9b6fb682-7fff-538f-2833-92b4206836dc\"> </span></p>\n<p dir=\"ltr\"><strong>Project Summary:</strong></p>\n<p dir=\"ltr\"><span>In factory automation, humans and robots comprise the two major workforces. Traditionally, humans and robots have not physically collaborated with each other during operation, in significant part because full automation with robots was the goal. In recent years, however, it has been recognized that there are tremendous advantages if robots are brought out of their cages and allowed to share the workspace with and collaborate with humans to take advantage of the best of two worlds - on one hand, the reliable execution of tasks by robots without wear handling objects of a wide range of sizes and weights, and on the other hand, the intelligence of humans and their five senses-based adaptabilities and flexibility. For collaboration between humans and robots to be successful, it is a prerequisite to ensure the safety of the humans in such collaboration. At the same time, it is important to ensure that robots collaborate with humans to ensure the best performance possible.&nbsp;</span></p>\n<p dir=\"ltr\"><span>In view of the needs identified above, the goal of this project is to establish a set of design principles for a safe and efficient robot collaboration system (SERoCS) for the next generation co-robots, which consists of the following three building blocks (modules):</span></p>\n<p dir=\"ltr\"><span>1) Environment monitoring with human motion prediction using camera-captured signals.</span></p>\n<p dir=\"ltr\"><span>2) Task planning with a skill library that enables co-robots to deal with challenging tasks.</span></p>\n<p dir=\"ltr\"><span>3) Safe and efficient motion planning and control in real-time.</span></p>\n<p dir=\"ltr\"><span>We evaluate the overall performance of our system and provide some guidance for module and system design principles; therefore, the project includes:</span></p>\n<p dir=\"ltr\"><span>4) Evaluation of the SERoCS by analyses, simulations, and experiments.</span></p>\n<p dir=\"ltr\"><span>In this project, algorithms for multiple modules in the co-robot system have been developed and tested in a computer assembly line scenario. These modules include the prediction, task planning, and motion planning modules. In this scenario, a human worker performs some tasks while the robots (a manipulator and a mobile robot) detect and predict the workers' movements and provide assistance. The high-level plan recognition and task planning module increase the robustness and efficiency of the co-robot system, specifying the intermediate sub-goals for the robots as they collaborate with the human worker. The motion planning modules plan collision-free trajectories for the robots to achieve these sub-goals. The tool insertion skill is also demonstrated in the experiments. These developments can serve as stepping stones toward future developments of a safe and efficient human-robot collaboration system.</span></p>\n<p dir=\"ltr\"><strong>The Significance and Broad Impact:</strong></p>\n<p>&nbsp;</p>\n<p><span id=\"docs-internal-guid-21a79501-7fff-612c-7cdc-6f5f242661d0\"><span>The above technical advancements could provide valuable insights into the design and control of co-robot systems in industrial settings. Industrial production in the future will have more emphasis on mass customization of products as opposed to mass production of identical products. This means that production lines need to be more and more flexible. Moving robots out of cages and employing them in flexible production lines will be an inevitable trend, and future factories are anticipated to be spaces where humans and robots coexist. The proposed SERoCS will lead to safe and efficient human-robot collaboration and safe robot-robot collaboration; both are essential in future factories. The design of the overall system and the individual module and control strategies investigated in this project can serve as stepping stones toward future developments of a safe and efficient human-robot collaboration system. Also, the developed modules can be applied to other disciplines. The perception module can be used in different disciplines that involve human motion capturing, e.g., rehabilitation therapy, sports research, and the animation industry. The prediction module can be used in different disciplines that involve human motion prediction, e.g., autonomous driving. The task planning module can be adapted to other human-robot collaboration settings, e.g., domestic applications. The planning algorithm can be applied to different robot models for various applications.</span></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/04/2022<br>\n\t\t\t\t\tModified by: Masayoshi&nbsp;Tomizuka</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nProject Summary:\nIn factory automation, humans and robots comprise the two major workforces. Traditionally, humans and robots have not physically collaborated with each other during operation, in significant part because full automation with robots was the goal. In recent years, however, it has been recognized that there are tremendous advantages if robots are brought out of their cages and allowed to share the workspace with and collaborate with humans to take advantage of the best of two worlds - on one hand, the reliable execution of tasks by robots without wear handling objects of a wide range of sizes and weights, and on the other hand, the intelligence of humans and their five senses-based adaptabilities and flexibility. For collaboration between humans and robots to be successful, it is a prerequisite to ensure the safety of the humans in such collaboration. At the same time, it is important to ensure that robots collaborate with humans to ensure the best performance possible. \nIn view of the needs identified above, the goal of this project is to establish a set of design principles for a safe and efficient robot collaboration system (SERoCS) for the next generation co-robots, which consists of the following three building blocks (modules):\n1) Environment monitoring with human motion prediction using camera-captured signals.\n2) Task planning with a skill library that enables co-robots to deal with challenging tasks.\n3) Safe and efficient motion planning and control in real-time.\nWe evaluate the overall performance of our system and provide some guidance for module and system design principles; therefore, the project includes:\n4) Evaluation of the SERoCS by analyses, simulations, and experiments.\nIn this project, algorithms for multiple modules in the co-robot system have been developed and tested in a computer assembly line scenario. These modules include the prediction, task planning, and motion planning modules. In this scenario, a human worker performs some tasks while the robots (a manipulator and a mobile robot) detect and predict the workers' movements and provide assistance. The high-level plan recognition and task planning module increase the robustness and efficiency of the co-robot system, specifying the intermediate sub-goals for the robots as they collaborate with the human worker. The motion planning modules plan collision-free trajectories for the robots to achieve these sub-goals. The tool insertion skill is also demonstrated in the experiments. These developments can serve as stepping stones toward future developments of a safe and efficient human-robot collaboration system.\nThe Significance and Broad Impact:\n\n \n\nThe above technical advancements could provide valuable insights into the design and control of co-robot systems in industrial settings. Industrial production in the future will have more emphasis on mass customization of products as opposed to mass production of identical products. This means that production lines need to be more and more flexible. Moving robots out of cages and employing them in flexible production lines will be an inevitable trend, and future factories are anticipated to be spaces where humans and robots coexist. The proposed SERoCS will lead to safe and efficient human-robot collaboration and safe robot-robot collaboration; both are essential in future factories. The design of the overall system and the individual module and control strategies investigated in this project can serve as stepping stones toward future developments of a safe and efficient human-robot collaboration system. Also, the developed modules can be applied to other disciplines. The perception module can be used in different disciplines that involve human motion capturing, e.g., rehabilitation therapy, sports research, and the animation industry. The prediction module can be used in different disciplines that involve human motion prediction, e.g., autonomous driving. The task planning module can be adapted to other human-robot collaboration settings, e.g., domestic applications. The planning algorithm can be applied to different robot models for various applications.\n\n \n\n\t\t\t\t\tLast Modified: 09/04/2022\n\n\t\t\t\t\tSubmitted by: Masayoshi Tomizuka"
 }
}