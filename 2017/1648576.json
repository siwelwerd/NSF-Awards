{
 "awd_id": "1648576",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Energy-Efficient Perception for Autonomous Road Vehicles",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2016-12-15",
 "awd_exp_date": "2017-05-31",
 "tot_intn_awd_amt": 225000.0,
 "awd_amount": 225000.0,
 "awd_min_amd_letter_date": "2016-12-04",
 "awd_max_amd_letter_date": "2016-12-04",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will be to allow consumers to buy vehicles enhanced by Advanced Driver Assistance Systems (ADAS) that are more robust and more accurate. Advanced Driver Assistance Systems in general, and fully autonomous vehicles in particular, promise a number of advantages, such as: (1) reducing the number of traffic fatalities in the US and abroad, (2) enabling humans to spend less time driving and more time on other activities, and (3) reducing fossil-fuel emissions. Practical implementations of Advanced Driver Assistance Systems require a few key elements: sensors, perception systems, motion planning systems, and control/actuation systems. Based on extensive discussions with key individuals at automakers and automotive suppliers, developing robust and accurate perception systems is the biggest obstacle toward developing mass-producible autonomous road vehicles.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project will create perception systems that utilize the rapidly evolving technologies of deep learning for computer vision. Specifically, the company will utilize deep learning to provide perceptual systems that are: 1) more robust in the presence of diverse and rapidly evolving sensor configurations; 2) more accurate due to the early fusion of sensor data; and 3) more accurate due to the application of state-of-the-art deep learning algorithms for computer vision. The company is already engaged in developing partnerships with automotive OEMs and semiconductor suppliers that will enable it to deliver proofs-of-concept of its unique approach.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Forrest",
   "pi_last_name": "Iandola",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Forrest Iandola",
   "pi_email_addr": "forrest@deepscale.ai",
   "nsf_id": "000724046",
   "pi_start_date": "2016-12-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "DeepScale, Inc",
  "inst_street_address": "1232 Royal Crest Dr",
  "inst_street_address_2": "",
  "inst_city_name": "San Jose",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6502000082",
  "inst_zip_code": "951312912",
  "inst_country_name": "United States",
  "cong_dist_code": "17",
  "st_cong_dist_code": "CA17",
  "org_lgl_bus_name": null,
  "org_prnt_uei_num": null,
  "org_uei_num": "NCECLLML62S7"
 },
 "perf_inst": {
  "perf_inst_name": "DeepScale, Inc",
  "perf_str_addr": "1232 Royal Crest Dr.",
  "perf_city_name": "San Jose",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "951312912",
  "perf_ctry_code": "US",
  "perf_cong_dist": "17",
  "perf_st_cong_dist": "CA17",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5371",
   "pgm_ref_txt": "SMALL BUSINESS PHASE I"
  },
  {
   "pgm_ref_code": "8032",
   "pgm_ref_txt": "Software Services and Applications"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 225000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-56686733-a1c3-43b4-1f45-46263132a10c\">\n<p dir=\"ltr\"><span>With the support of the National Science Foundation Small Business Innovative Research program (NSF SBIR), DeepScale, Inc. is using its proprietary </span><span>artificial intelligence (AI) and deep neural network (DNN) based technology</span><span> to develop </span><span>software to power perception systems for advanced driver assistance systems (ADAS) and autonomous vehicles (AV). Our goal is to provide the cost effective, real-time, integrated visual perception system the global automotive industry requires to enable the development of safe, commercially available, fully autonomous passenger cars to the consumer market and the growing e-hailing taxi industry.</span></p>\n<p dir=\"ltr\"><span> </span></p>\n<p dir=\"ltr\"><span>With NSF SBIR Phase I grant funding, DeepScale met our Phase I proposal stated objective to </span><span>explore accuracy/speed/energy-efficiency trade-offs for the use of DNNs in object detection and exceeded our stated goal of reducing energy consumption to 2 Joules/frame. The technical details of our work, accomplished by the DeepScale team under CEO Forrest Iandola in collaboration with DeepScale co-founder Prof. Keutzer&rsquo;s work at UC Berkeley, is summarized in our SqueezeDet publication [Wu 2016]. The DeepScale team is also solely responsible for improvements to and robustification of the energy efficient SqueezeDet object detecting DNN and for the development of a significantly more diverse training data set which advances the DNNs efficacy by encompassing a broader range of driving climates.</span></p>\n<p dir=\"ltr\"><span>The quest for the fully autonomous car is surely one of the most significant technical challenges of our time. &nbsp;Major automakers across the globe are allocating huge budgets to this technological objective. Big name tech giants such as Apple and Google have joined the race. Independent crowd-sourced ride-hailing ventures such as Uber have declared their intention to put fleets of autonomous taxis on the streets in major metropolitan areas in the next few years, and they have mounted their own development efforts as well. Already, autonomous vehicles - albeit provisioned with human safety drivers ready to take the wheel - can be seen cruising city streets in a growing number of localities. And a small handful of recently released passenger cars offer autonomous operation under a set of circumscribed conditions.</span></p>\n<p dir=\"ltr\"><span> </span></p>\n<p dir=\"ltr\"><span>The impact of autonomous driving technology on the auto industry and consumer mobility behavior cannot be overstated. Mckinsey and Company, in a 2016 report suggest that shared mobility (e.g. car sharing and e-hailing services) as well as car connectivity could increase the automotive revenue pool by as much as 30%</span><span>, </span><span>or $1.5 trillion annually, by 2030. Moreover, McKinsey anticipates that such shared mobility solutions and a fit for purpose approach to personal transportation will markedly decrease the centrality of private-car ownership in the coming decades. [Mckinsey&amp;Company2016]</span></p>\n<p dir=\"ltr\"><span> </span></p>\n<p dir=\"ltr\"><span>Autonomous vehicles also promise a variety of meaningful societal benefits, from reduced energy consumption, increased leisure time, decreased traffic congestion to a significant reduction in traffic accidents. &nbsp;Safety will be a critical product characteristic of autonomous vehicles which hold the promise of reducing the 30,000 to 40,000 traffic fatalities, as well as the 2.4 million in injuries and over $200 billion in economic losses, on our nation&rsquo;s roadways each year, as 94% of motor vehicle crashes can be attributed to human error according to a recent National Highway Transportation Safety Administration report. [NHTSA2017]</span></p>\n<p dir=\"ltr\"><span> </span></p>\n<p dir=\"ltr\"><span>The computer perception systems based on state-of-the-art deep learning techniques developed by DeepScale are central to fully realizing the promised benefits of fully autonomous <span id=\"docs-internal-guid-56686733-a1cc-0b7a-0645-105e61be54c5\"><span>vehicles capable of safe, reliable operation</span></span> in all driving environments. &nbsp;Ultimately, the safety and quality of an autonomous driving system is inherently limited by the quality of its sensors and efficacy of its complete perceptual system.</span></p>\n<p dir=\"ltr\"><span> </span></p>\n<p dir=\"ltr\"><span>Our Phase I research achievement of radically reducing energy consumption without sacrificing accuracy is a central and crucial step in the refinement of DeepScale&rsquo;s perception technology. It is an important milestone in the direction of our commitment to deliver software to power a high accuracy, real time perceptual system using commercially-feasible computational hardware and with commercially-feasible energy requirements, and thus provide automakers with one of the key capabilities they require to make competitive entries into the autonomous driving space.</span></p>\n<p dir=\"ltr\"><span>&nbsp;</span>Citations:</p>\n<p dir=\"ltr\"><span> </span></p>\n<p dir=\"ltr\"><span> </span></p>\n<p dir=\"ltr\"><span>[Wu2016] Wu, Bichen, Forrest Iandola, Peter H. Jin, and Kurt Keutzer. \"SqueezeDet: Unified, small, low power fully convolutional neural networks for real-time object detection for autonomous driving.\" arXiv preprint arXiv:1612.01051 (2016). Updated version to appear in Proceedings CVPR Embedded Vision Workshop, &nbsp;July 2017.</span></p>\n<p dir=\"ltr\"><span>[Mckinsey &amp; Company2016] Mckinsey &amp; Company, &ldquo;Disruptive trends that will transform the auto industry,&rdquo; January 2016.</span></p>\n<p dir=\"ltr\"><span>[NHTSA2017] National Highway Transportation Safety Administration, &ldquo;2015 Summary of Motor Vehicle Crashes (Early Edition) Traffic Safety Facts&rdquo;, DOT HS 812375, Feb 2017.</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/02/2017<br>\n\t\t\t\t\tModified by: Forrest&nbsp;Iandola</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nWith the support of the National Science Foundation Small Business Innovative Research program (NSF SBIR), DeepScale, Inc. is using its proprietary artificial intelligence (AI) and deep neural network (DNN) based technology to develop software to power perception systems for advanced driver assistance systems (ADAS) and autonomous vehicles (AV). Our goal is to provide the cost effective, real-time, integrated visual perception system the global automotive industry requires to enable the development of safe, commercially available, fully autonomous passenger cars to the consumer market and the growing e-hailing taxi industry.\n \nWith NSF SBIR Phase I grant funding, DeepScale met our Phase I proposal stated objective to explore accuracy/speed/energy-efficiency trade-offs for the use of DNNs in object detection and exceeded our stated goal of reducing energy consumption to 2 Joules/frame. The technical details of our work, accomplished by the DeepScale team under CEO Forrest Iandola in collaboration with DeepScale co-founder Prof. Keutzer?s work at UC Berkeley, is summarized in our SqueezeDet publication [Wu 2016]. The DeepScale team is also solely responsible for improvements to and robustification of the energy efficient SqueezeDet object detecting DNN and for the development of a significantly more diverse training data set which advances the DNNs efficacy by encompassing a broader range of driving climates.\nThe quest for the fully autonomous car is surely one of the most significant technical challenges of our time.  Major automakers across the globe are allocating huge budgets to this technological objective. Big name tech giants such as Apple and Google have joined the race. Independent crowd-sourced ride-hailing ventures such as Uber have declared their intention to put fleets of autonomous taxis on the streets in major metropolitan areas in the next few years, and they have mounted their own development efforts as well. Already, autonomous vehicles - albeit provisioned with human safety drivers ready to take the wheel - can be seen cruising city streets in a growing number of localities. And a small handful of recently released passenger cars offer autonomous operation under a set of circumscribed conditions.\n \nThe impact of autonomous driving technology on the auto industry and consumer mobility behavior cannot be overstated. Mckinsey and Company, in a 2016 report suggest that shared mobility (e.g. car sharing and e-hailing services) as well as car connectivity could increase the automotive revenue pool by as much as 30%, or $1.5 trillion annually, by 2030. Moreover, McKinsey anticipates that such shared mobility solutions and a fit for purpose approach to personal transportation will markedly decrease the centrality of private-car ownership in the coming decades. [Mckinsey&amp;Company2016]\n \nAutonomous vehicles also promise a variety of meaningful societal benefits, from reduced energy consumption, increased leisure time, decreased traffic congestion to a significant reduction in traffic accidents.  Safety will be a critical product characteristic of autonomous vehicles which hold the promise of reducing the 30,000 to 40,000 traffic fatalities, as well as the 2.4 million in injuries and over $200 billion in economic losses, on our nation?s roadways each year, as 94% of motor vehicle crashes can be attributed to human error according to a recent National Highway Transportation Safety Administration report. [NHTSA2017]\n \nThe computer perception systems based on state-of-the-art deep learning techniques developed by DeepScale are central to fully realizing the promised benefits of fully autonomous vehicles capable of safe, reliable operation in all driving environments.  Ultimately, the safety and quality of an autonomous driving system is inherently limited by the quality of its sensors and efficacy of its complete perceptual system.\n \nOur Phase I research achievement of radically reducing energy consumption without sacrificing accuracy is a central and crucial step in the refinement of DeepScale?s perception technology. It is an important milestone in the direction of our commitment to deliver software to power a high accuracy, real time perceptual system using commercially-feasible computational hardware and with commercially-feasible energy requirements, and thus provide automakers with one of the key capabilities they require to make competitive entries into the autonomous driving space.\n Citations:\n \n \n[Wu2016] Wu, Bichen, Forrest Iandola, Peter H. Jin, and Kurt Keutzer. \"SqueezeDet: Unified, small, low power fully convolutional neural networks for real-time object detection for autonomous driving.\" arXiv preprint arXiv:1612.01051 (2016). Updated version to appear in Proceedings CVPR Embedded Vision Workshop,  July 2017.\n[Mckinsey &amp; Company2016] Mckinsey &amp; Company, \"Disruptive trends that will transform the auto industry,\" January 2016.\n[NHTSA2017] National Highway Transportation Safety Administration, \"2015 Summary of Motor Vehicle Crashes (Early Edition) Traffic Safety Facts\", DOT HS 812375, Feb 2017.\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 08/02/2017\n\n\t\t\t\t\tSubmitted by: Forrest Iandola"
 }
}