{
 "awd_id": "1656905",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: AF: Novel Geometric Algorithms for Certain Data Analysis Problems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rahul Shah",
 "awd_eff_date": "2017-05-15",
 "awd_exp_date": "2019-04-30",
 "tot_intn_awd_amt": 174328.0,
 "awd_amount": 174328.0,
 "awd_min_amd_letter_date": "2017-02-10",
 "awd_max_amd_letter_date": "2018-05-29",
 "awd_abstract_narration": "We can often see trends or clusters in data by graphing or plotting-- giving geometric form to data.   As data increases in volume and complexity, giving it geometric form and then developing computational geometry algorithms is still a fruitful way to approach data analysis. For example, activity data from a smartphone or fitness tracker can be viewed as a point in thousands of dimensions whose coordinates include all positions, heart rates, etc. from an entire sequence of measurements.  For better privacy, we can share summaries (rough position, duration, etc.) as points in tens of dimensions.  Points from many people can be clustered to identify similar patterns, and patterns matched (with unreliable data identified and discarded) to recognize actions that a digital assistant could take to improve quality of life or health outcomes.   \r\n\r\nThis project aims to develop a set of advanced data structures and novel geometric algorithms for three fundamental data analysis problems: (1) constrained clustering in high dimensions, (2) geometric matching under certain transformations, and (3) extracting trustworthy information from unreliable data.  The first two problems are both naturally studied by computational geometry, and the third has a novel formulation as a geometric optimization problem in high dimensions.  The goal is to achieve highly efficient and quality guaranteed solutions for each of these problems. The new geometric insights, advanced data structures, and efficient algorithmic techniques introduced by this project will enrich further development in computational geometry and bring fresh ideas to other areas, including machine learning, computer vision, data mining, and bioinformatics.  \r\n\r\nThis project provides research and educational opportunities in data analysis to both graduate and undergraduate students (including women, minorities, and other underrepresented groups) at Michigan State University.  It also undertakes outreach activities for students in K-12 outreach activities and prepares online materials to benefit more students and teachers. In particular, student evaluations of teacher performance will be one of the data sets used in problem (3), extracting trustworthy information from unreliable data.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Torng",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Eric K Torng",
   "pi_email_addr": "torng@cse.msu.edu",
   "nsf_id": "000124714",
   "pi_start_date": "2018-05-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Hu",
   "pi_last_name": "Ding",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hu Ding",
   "pi_email_addr": "huding@msu.edu",
   "nsf_id": "000703713",
   "pi_start_date": "2017-02-10",
   "pi_end_date": "2018-05-29"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Hu",
   "pi_last_name": "Ding",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hu Ding",
   "pi_email_addr": "huding@msu.edu",
   "nsf_id": "000703713",
   "pi_start_date": "2018-05-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Michigan State University",
  "inst_street_address": "426 AUDITORIUM RD RM 2",
  "inst_street_address_2": "",
  "inst_city_name": "EAST LANSING",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "5173555040",
  "inst_zip_code": "488242600",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MI07",
  "org_lgl_bus_name": "MICHIGAN STATE UNIVERSITY",
  "org_prnt_uei_num": "VJKZC4D1JN36",
  "org_uei_num": "R28EKN92ZTZ9"
 },
 "perf_inst": {
  "perf_inst_name": "Michigan State University",
  "perf_str_addr": "428 S. Shaw Lane, Rm 2140",
  "perf_city_name": "East Lansing",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "488242600",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MI07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "026Y00",
   "pgm_ele_name": "CRII CISE Research Initiation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7796",
   "pgm_ref_txt": "ALGORITHMIC FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7929",
   "pgm_ref_txt": "COMPUTATIONAL GEOMETRY"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 174328.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><!-- p.p1 {margin: 0.0px 0.0px 14.0px 0.0px; font: 14.0px Verdana} p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Verdana} p.p3 {margin: 0.0px 0.0px 14.0px 0.0px; font: 14.0px Verdana; min-height: 17.0px} span.s1 {font-kerning: none} -->\n<p class=\"p1\"><span class=\"s1\">The core of this project is to design novel and efficient geometric techniques for a set of fundamental data analysis problems. We have 7 papers published (or accepted) in prestigious conferences and journals (such as ESA, AAAI, Algorithmica), and 3 papers under review. The main results of this project are briefly described below.<span>&nbsp;</span></span></p>\n<p class=\"p1\"><span class=\"s1\">(1) &nbsp;We study a new geometric optimization problem called ``geometric prototype'' in Euclidean space. Given a set of patterns, the geometric prototype can be viewed as the ``mean pattern'' minimizing the total matching cost to them. As a general model, the problem finds many applications in the areas like machine learning, data mining, computer vision, etc. We first show that a small core-set can be obtained to substantially reduce the data size. Consequently, any existing heuristic or algorithm can run on the core-set to achieve a great improvement on the efficiency.<span>&nbsp;</span></span></p>\n<p class=\"p1\"><span class=\"s1\">(2) We study high dimensional balanced k-center cluster where the size of each cluster is constrained by the given lower and upper bounds. We provide a simple nearly linear time 4-approximation algorithm when the number of clusters k is assumed to be a constant. Comparing with existing method, our algorithm improves the approximation ratio and significantly reduces the time complexity. Moreover, our result can be easily extended to any metric space.</span></p>\n<p class=\"p1\"><span class=\"s1\">(3) Following our previous work in SoCG'16, we continue working on the problem of truth discovery. The running time of our algorithm in SoCG'16 depends on the spread ratio of the input points. This could severely restrict the applicability of the algorithm. To resolve this issue, we propose a new algorithm which yields a (1+\\epsilon)-approximation in near quadratic time for any dataset with constant probability. Our algorithm relies on a data structure called range cover, which is interesting in its own right. The data structure provides a general approach for solving some high dimensional optimization problems by breaking down them into a small number of parametrized cases.</span></p>\n<p class=\"p1\"><span class=\"s1\">(4) In real-world, many problems can be formulated as the alignment between two geometric patterns. Recently, the alignment of geometric patterns in high dimension finds several novel applications, and has attracted more and more attentions. However, the research is still rather limited in terms of algorithms. We propose an effective framework to compress the high dimensional geometric patterns and approximately preserve the alignment quality. As a consequence, existing alignment approach can be applied to the compressed geometric patterns and thus the time complexity is significantly reduced. Our idea is inspired by the observation that high dimensional data often has a low intrinsic dimension.<span>&nbsp;</span></span></p>\n<p class=\"p1\"><span class=\"s1\">(5) We revisit the Minimum Enclosing Ball (MEB) problem and its robust version, MEB with outliers, in Euclidean space. Though the problem has been extensively studied before, most of the existing algorithms need at least linear time to achieve a $(1+\\epsilon)$-approximation. Motivated by some recent developments on beyond worst-case analysis, we introduce the notion of stability for MEB (with outliers), which is natural and easy to understand. Under the stability assumption, we present two sampling algorithms for computing approximate MEB with sample complexities independent of the number of input points. Further, we achieve the first sub-linear time approximation algorithm for MEB with outliers. We also show that our idea can be extended to the general case of MEB with outliers ({\\em i.e.,} without the stability assumption), and obtain a sub-linear time bi-criteria approximation algorithm.<span>&nbsp;</span></span></p>\n<p class=\"p1\"><span class=\"s1\">(6) We study the problem of $k$-center clustering with outliers in arbitrary metrics and Euclidean space. Our idea is inspired by the greedy method, Gonzalez's algorithm, for solving the problem of ordinary $k$-center clustering. Based on some novel observations, we show that this greedy strategy actually can handle $k$-center clustering with outliers efficiently, in terms of clustering quality and time complexity.<span>&nbsp; </span>We further show that the greedy approach yields small coreset for the problem in doubling metrics, so as to reduce the time complexity<span>&nbsp; </span>significantly.<span>&nbsp;</span></span></p>\n<p class=\"p1\"><span class=\"s1\">(7) We propose a practical framework for solving the problems of $k$-center/median/means clustering with outliers. The framework actually is very simple, where we just need to take a small sample from input and run existing approximation algorithm on the sample. However, our analysis is fundamentally different from the previous sampling based ideas. In particular, the size of the sample is independent of the input data size and dimensionality. To explain the effectiveness of random sampling in theory, we introduce a ``significance'' criterion and prove that the performance of our framework<span>&nbsp; </span>depends on the significance degree of the given instance. The result proposed in this paper falls under the umbrella of beyond worst-case analysis in terms of clustering with outliers.<span>&nbsp;</span></span></p>\n<p class=\"p2\"><span class=\"s1\">Two students (including one female) are supported by this grant. Three papers are co-authored by the students. Through this project, the students learned how to do research, find problems, and write research papers.&nbsp;</span></p>\n<p class=\"p3\"><span class=\"s1\">&nbsp;</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/17/2019<br>\n\t\t\t\t\tModified by: Hu&nbsp;Ding</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe core of this project is to design novel and efficient geometric techniques for a set of fundamental data analysis problems. We have 7 papers published (or accepted) in prestigious conferences and journals (such as ESA, AAAI, Algorithmica), and 3 papers under review. The main results of this project are briefly described below. \n(1)  We study a new geometric optimization problem called ``geometric prototype'' in Euclidean space. Given a set of patterns, the geometric prototype can be viewed as the ``mean pattern'' minimizing the total matching cost to them. As a general model, the problem finds many applications in the areas like machine learning, data mining, computer vision, etc. We first show that a small core-set can be obtained to substantially reduce the data size. Consequently, any existing heuristic or algorithm can run on the core-set to achieve a great improvement on the efficiency. \n(2) We study high dimensional balanced k-center cluster where the size of each cluster is constrained by the given lower and upper bounds. We provide a simple nearly linear time 4-approximation algorithm when the number of clusters k is assumed to be a constant. Comparing with existing method, our algorithm improves the approximation ratio and significantly reduces the time complexity. Moreover, our result can be easily extended to any metric space.\n(3) Following our previous work in SoCG'16, we continue working on the problem of truth discovery. The running time of our algorithm in SoCG'16 depends on the spread ratio of the input points. This could severely restrict the applicability of the algorithm. To resolve this issue, we propose a new algorithm which yields a (1+\\epsilon)-approximation in near quadratic time for any dataset with constant probability. Our algorithm relies on a data structure called range cover, which is interesting in its own right. The data structure provides a general approach for solving some high dimensional optimization problems by breaking down them into a small number of parametrized cases.\n(4) In real-world, many problems can be formulated as the alignment between two geometric patterns. Recently, the alignment of geometric patterns in high dimension finds several novel applications, and has attracted more and more attentions. However, the research is still rather limited in terms of algorithms. We propose an effective framework to compress the high dimensional geometric patterns and approximately preserve the alignment quality. As a consequence, existing alignment approach can be applied to the compressed geometric patterns and thus the time complexity is significantly reduced. Our idea is inspired by the observation that high dimensional data often has a low intrinsic dimension. \n(5) We revisit the Minimum Enclosing Ball (MEB) problem and its robust version, MEB with outliers, in Euclidean space. Though the problem has been extensively studied before, most of the existing algorithms need at least linear time to achieve a $(1+\\epsilon)$-approximation. Motivated by some recent developments on beyond worst-case analysis, we introduce the notion of stability for MEB (with outliers), which is natural and easy to understand. Under the stability assumption, we present two sampling algorithms for computing approximate MEB with sample complexities independent of the number of input points. Further, we achieve the first sub-linear time approximation algorithm for MEB with outliers. We also show that our idea can be extended to the general case of MEB with outliers ({\\em i.e.,} without the stability assumption), and obtain a sub-linear time bi-criteria approximation algorithm. \n(6) We study the problem of $k$-center clustering with outliers in arbitrary metrics and Euclidean space. Our idea is inspired by the greedy method, Gonzalez's algorithm, for solving the problem of ordinary $k$-center clustering. Based on some novel observations, we show that this greedy strategy actually can handle $k$-center clustering with outliers efficiently, in terms of clustering quality and time complexity.  We further show that the greedy approach yields small coreset for the problem in doubling metrics, so as to reduce the time complexity  significantly. \n(7) We propose a practical framework for solving the problems of $k$-center/median/means clustering with outliers. The framework actually is very simple, where we just need to take a small sample from input and run existing approximation algorithm on the sample. However, our analysis is fundamentally different from the previous sampling based ideas. In particular, the size of the sample is independent of the input data size and dimensionality. To explain the effectiveness of random sampling in theory, we introduce a ``significance'' criterion and prove that the performance of our framework  depends on the significance degree of the given instance. The result proposed in this paper falls under the umbrella of beyond worst-case analysis in terms of clustering with outliers. \nTwo students (including one female) are supported by this grant. Three papers are co-authored by the students. Through this project, the students learned how to do research, find problems, and write research papers. \n \n\n \n\n\t\t\t\t\tLast Modified: 06/17/2019\n\n\t\t\t\t\tSubmitted by: Hu Ding"
 }
}