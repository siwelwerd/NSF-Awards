{
 "awd_id": "1725672",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SPX: Collaborative Research: Eat your Wheaties: Multi-Grain Compilers for Parallel Builds at Every Scale",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2017-08-15",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2017-08-01",
 "awd_max_amd_letter_date": "2017-08-01",
 "awd_abstract_narration": "Title: SPX: Collaborative Research: Multi-Grain Compilers for Parallel Builds at Every Scale\r\n\r\nModern software development practices at companies such as Google and Facebook have led to compilation -- the process of transforming source programs into executable programs -- becoming a significant, time-consuming,  resource-intensive process.  Unfortunately, even state of the art compilers and build systems do not do a good job of exploiting emerging, high-performance, highly-parallel hardware, so software development is hampered by the still-slow process of compilation.  This project aims to develop new techniques to speed up the process of compilation. The intellectual merits are designing new compiler internals, algorithms, and schedulers to enable compilers to take advantage of modern hardware capabilities. The project's broader significance and importance are that the process of compilation undergirds virtually every aspect of modern software, and hence modern life: speeding up compilation enables any type of software to be developed more quickly, providing new features to users and more quickly squashing potentially catastrophic bugs.\r\n\r\nThe project revolves around three main thrusts. First, the PIs are developing new representations for compiler internals that better fit the memory hierarchy of modern machines, eschewing pointer-based representations for dense representations. We are designing techniques to allow programmers to write their compiler passes at a high level while automatically converting them to use the dense representation. Second, the PIs are designing new algorithms to optimize compiler passes. These are transformations of internal compiler algorithms to promote locality (by combining passes that operate on similar portions of a program) and to enhance parallelism (by eliminating unnecessary synchronization between passes). Finally, the PIs are creating new scheduling techniques to allow the new highly-parallel compiler algorithms to be effectively mapped to the parallel and distributed hardware on which modern build systems execute.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Milind",
   "pi_last_name": "Kulkarni",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Milind Kulkarni",
   "pi_email_addr": "milind@purdue.edu",
   "nsf_id": "000549148",
   "pi_start_date": "2017-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "465 Northwestern Ave.",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072035",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-3ddfcd39-7fff-c424-1107-3122cd3dd352\"> </span></p>\n<p dir=\"ltr\"><span>In this project, we sought to improve software implementation techniques for a class of programs that traverse </span><span>irregular, tree-shaped </span><span>data.&nbsp; Computer software is written by humans and then translated by a </span><span>compiler</span><span> into machine readable code.&nbsp; This project targeted that compilation step and made several advances in compiling tree-traversing programs more efficiently.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>First, our approach demonstrated that a dense, mostly-serialized representation of tree data can be used automatically by the compiler (ECOOP&rsquo;17), and that this not only uses less memory, but makes traversals more than twice as fast.&nbsp; We expanded on the approach by formalizing the language that the compiler manipulates to accomplish this feat (PLDI&rsquo;19A).&nbsp; We built on this advancement by also studying </span><span>fusion </span><span>optimizations that combine multiple, consecutive traversals of the tree data into a single traversal (PLDI&rsquo;19B).&nbsp; We also showed that the approach scales from single-core processors to multi-core parallel processors (ICFP&rsquo;21), still running more than twice as fast as any previously existing approach for compiling tree traversing programs.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>In fact, the compiler itself is a prime example of tree-traversing software as the compiler traverses the abstract syntax tree of the input software (much like a sentence diagram in grammar class).&nbsp; In PLDI&rsquo;19A, and ICFP&rsquo;21, we were able to demonstrate that compilers themselves get much faster using our approach.&nbsp; That enables them to build software faster, which is a of increasing importance as software industry switches to &ldquo;continuous delivery&rdquo; with changes made by software developers being built, tested, and deployed as quickly as possible.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>A full software build consists of many separate compiler invocations on many separate input files. To address the full picture -- including parallelism opportunities at multiple scales -- we not only studied the performance of the &ldquo;innermost&rdquo; tree traversals, but also the larger build systems that contain them.&nbsp; We built a new system for scheduling multiple jobs with dynamic levels of parallelism (HiPC&rsquo;20), as well as a new system for automatically and correctly parallelizing build processes (OOPSLA&lsquo;20, CPP&rsquo;22).</span></p>\n<p><br /><span>Broader impacts</span><span>: We have made all these technologies available via our open source software, if they are gradually adopted by industry, we will see increased software development velocity, which in turn speeds up the other forms of advancement that are enabled by software.</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/07/2022<br>\n\t\t\t\t\tModified by: Milind&nbsp;Kulkarni</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nIn this project, we sought to improve software implementation techniques for a class of programs that traverse irregular, tree-shaped data.  Computer software is written by humans and then translated by a compiler into machine readable code.  This project targeted that compilation step and made several advances in compiling tree-traversing programs more efficiently.\n\n \nFirst, our approach demonstrated that a dense, mostly-serialized representation of tree data can be used automatically by the compiler (ECOOP\u201917), and that this not only uses less memory, but makes traversals more than twice as fast.  We expanded on the approach by formalizing the language that the compiler manipulates to accomplish this feat (PLDI\u201919A).  We built on this advancement by also studying fusion optimizations that combine multiple, consecutive traversals of the tree data into a single traversal (PLDI\u201919B).  We also showed that the approach scales from single-core processors to multi-core parallel processors (ICFP\u201921), still running more than twice as fast as any previously existing approach for compiling tree traversing programs.\n\n \nIn fact, the compiler itself is a prime example of tree-traversing software as the compiler traverses the abstract syntax tree of the input software (much like a sentence diagram in grammar class).  In PLDI\u201919A, and ICFP\u201921, we were able to demonstrate that compilers themselves get much faster using our approach.  That enables them to build software faster, which is a of increasing importance as software industry switches to \"continuous delivery\" with changes made by software developers being built, tested, and deployed as quickly as possible.\n\n \nA full software build consists of many separate compiler invocations on many separate input files. To address the full picture -- including parallelism opportunities at multiple scales -- we not only studied the performance of the \"innermost\" tree traversals, but also the larger build systems that contain them.  We built a new system for scheduling multiple jobs with dynamic levels of parallelism (HiPC\u201920), as well as a new system for automatically and correctly parallelizing build processes (OOPSLA\u201820, CPP\u201922).\n\n\nBroader impacts: We have made all these technologies available via our open source software, if they are gradually adopted by industry, we will see increased software development velocity, which in turn speeds up the other forms of advancement that are enabled by software.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 03/07/2022\n\n\t\t\t\t\tSubmitted by: Milind Kulkarni"
 }
}