{
 "awd_id": "1719155",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Scalable and Practical Detection of Invariants for Software Inspection",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 499999.0,
 "awd_amount": 499999.0,
 "awd_min_amd_letter_date": "2017-05-24",
 "awd_max_amd_letter_date": "2019-07-15",
 "awd_abstract_narration": "Due to the intractability of completely testing software, code review by humans remains an important contributor to software assurance.\u00a0\u00a0Current tools for code review provide relatively simple information, such as a listing of the differences between the current source code and the previous version.\u00a0\u00a0Consequently, many code reviews miss important implications of the differences, such as inadequate testing or a software bug.\u00a0\u00a0This research is investigating richer representations of the difference between two software versions, with the goal of making it easier to spot defects and keep them out of software slated for release.\u00a0\u00a0The approach hinges on using runtime analysis for mining software repositories, making it an exemplar of a \"big data\" approach to quantitative software engineering.\r\n\r\nSpecifically, the research is exploring the promise of a foundational technology called invariant detection, which gathers data from the software's runs and produces a summary of the behavioral properties of its components.\u00a0\u00a0In the context of code review, these properties, if they disagree with expectations, reveal inadequate testing or actual software defects.\u00a0\u00a0Because the properties are not just syntactic, they can highlight the impact of code changes on the behavior of unmodified code.\u00a0\u00a0Because property summaries can be voluminous, they are presented as a difference between the properties of the current software version and the previous one.\u00a0\u00a0The research is also addressing challenges to practical application of the approach.\u00a0\u00a0Novel techniques are being developed for improving test suite adequacy, efficiently acquiring traces, and calculating invariants.\u00a0\u00a0Core to the approach is that the version-to-version changes to software are often incremental and contained, permitting substantial reuse of data from prior runs.\u00a0\u00a0In the course of addressing these challenges, the research is developing and extending a scalable, automated code review infrastructure, enabling practical validation of the approach in both laboratory experiments and case studies.\u00a0\u00a0Ultimately, the research holds the promise to put new tools in the hands of practicing software developers, helping them find bugs and improve their test suites.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Griswold",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "William G Griswold",
   "pi_email_addr": "wgg@cs.ucsd.edu",
   "nsf_id": "000202359",
   "pi_start_date": "2017-05-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Massimiliano",
   "pi_last_name": "Menarini",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Massimiliano Menarini",
   "pi_email_addr": "mmenarini@ucsd.edu",
   "nsf_id": "000722242",
   "pi_start_date": "2017-05-24",
   "pi_end_date": "2019-07-15"
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 Gilman Drive",
  "perf_city_name": "San Diego",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930404",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 499999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Due to the intractability of completely testing software, code review by humans remains an important contributor to software assurance.&nbsp;&nbsp;Current tools for code review provide relatively simple information, such as a listing of the differences between the current source code and the previous version.&nbsp;&nbsp;Consequently, many code reviews miss important implications of the differences, such as inadequate testing or a software bug.</p>\n<p>This project researched the promise of a foundational technology called invariant detection, which gathers data from a software's runs and produces a summary of the behavioral properties of its components in the form of logic formulae.&nbsp;&nbsp;In the context of code review, these properties, if they disagree with expectations, reveal inadequate testing or actual software defects.&nbsp;&nbsp;Because the properties are semantic, not just syntactic, they can highlight the impact of code changes on the behavior of the revised code base.&nbsp;&nbsp;Because property summaries can be voluminous, they are presented as a difference between the properties of the current software version and the previous one.</p>\n<p>The major challenges to employing mined invariants in code review are performance and extracting invariant information that is useful to ordinary developers.&nbsp; There were three significant outcomes from this project regarding these particular challenges, realized through the development of a tool called Getty:</p>\n<ol>\n<li>Three complementary      techniques for effectively mining behavioral information for code review      were developed. The techniques include (a) using impact analysis to scope      invariant mining to the methods related to the current commit, (b)      mitigating memory pressure by tracing one class at a time, and (c)      parallelizing trace gathering and invariant extraction. Experiments on 6      open source projects demonstrated that these techniques enable nearly      arbitrary reductions in running time by parallelizing analyses. Moreover,      renting processors in the cloud makes the approach performant.<br /><br /></li>\n<li>The&nbsp; approach extracts likely invariants and      presents their differences for various combinations of source code      versions and test suite versions. Using the histories of a number of      real-world open-source projects, it was empirically demonstrated how      behavior-change summaries can reveal bugs and inadequate testing earlier      than they were actually discovered by the original reviewers.&nbsp; On the GSON project, two bugs were      discovered that were previously unreported.&nbsp; In a retrospective analysis of GSON and      five other open source projects, it was found that invariant differentials      helped find testing gaps in 32 of 100 selected commits.&nbsp; In a random selection of one known bug      from each of these projects, it was found that invariant differentials      made the bug evident at its point of introduction in 4 out of 6      cases.<br /><br /></li>\n<li>A comparative user study with      18 participants, with backgrounds ranging from computer science      undergraduate to computer science Ph.D. student, revealed how reviewers      perform code review with invariant differentials, as well as how their use      can improve the quality of code reviews by productively focusing code review efforts.</li>\n</ol>\n<p>With regard to broader impacts, the project provided research and mentoring in computer science and engineering area. Through the involvement of underrepresented groups, the project improved the performance, skills, and self-efficacy of members of underrepresented groups, ultimately improving their access to or retention in research, teaching, or other related computer science professions.&nbsp; For example, an undergraduate black woman mentored through this project is now a Ph.D. student at the University of Washington.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/02/2022<br>\n\t\t\t\t\tModified by: William&nbsp;G&nbsp;Griswold</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785227372_ScreenShot2022-07-02at11.01.21AM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785227372_ScreenShot2022-07-02at11.01.21AM--rgov-800width.jpg\" title=\"Example of An Invariant Difference\"><img src=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785227372_ScreenShot2022-07-02at11.01.21AM--rgov-66x44.jpg\" alt=\"Example of An Invariant Difference\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Example of An Invariant Difference Between Two Versions of a Program.  On the left are shown invariants that have been removed (red) or modified (yellow).  On the right are shown invariants that have been added (green) or modified (yellow).</div>\n<div class=\"imageCredit\">William G. Griswold</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">William&nbsp;G&nbsp;Griswold</div>\n<div class=\"imageTitle\">Example of An Invariant Difference</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785577738_ScreenShot2022-07-02at10.25.11AM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785577738_ScreenShot2022-07-02at10.25.11AM--rgov-800width.jpg\" title=\"Average Running Time Versus Number of CPUs\"><img src=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785577738_ScreenShot2022-07-02at10.25.11AM--rgov-66x44.jpg\" alt=\"Average Running Time Versus Number of CPUs\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Average Running Time Versus Number of CPUs. Environment: Intel 2.66 GHz Dual Processor, Quad-Core, 16GB RAM, Ubuntu Server 16.04.</div>\n<div class=\"imageCredit\">Yan Yan</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">William&nbsp;G&nbsp;Griswold</div>\n<div class=\"imageTitle\">Average Running Time Versus Number of CPUs</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785665484_ScreenShot2022-07-02at10.25.25AM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785665484_ScreenShot2022-07-02at10.25.25AM--rgov-800width.jpg\" title=\"Cloud Cost of Getty's Invariant Extraction Plotted Against the Number of CPUs Used\"><img src=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785665484_ScreenShot2022-07-02at10.25.25AM--rgov-66x44.jpg\" alt=\"Cloud Cost of Getty's Invariant Extraction Plotted Against the Number of CPUs Used\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Cloud Cost of Getty's Invariant Extraction Plotted Against the Number of CPUs Used. Each quad-core processor is priced as one independent Amazon EC2 (4 CPU up to 30GHz, 16GB RAM, $0.244/hour for North California, Feb 7, 2017).</div>\n<div class=\"imageCredit\">Yan Yan</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">William&nbsp;G&nbsp;Griswold</div>\n<div class=\"imageTitle\">Cloud Cost of Getty's Invariant Extraction Plotted Against the Number of CPUs Used</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785767093_ScreenShot2022-07-02at10.26.35AM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785767093_ScreenShot2022-07-02at10.26.35AM--rgov-800width.jpg\" title=\"Code Review Process\"><img src=\"/por/images/Reports/POR/2022/1719155/1719155_10489456_1656785767093_ScreenShot2022-07-02at10.26.35AM--rgov-66x44.jpg\" alt=\"Code Review Process\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Code Review Process when Invariants Differences are Available.</div>\n<div class=\"imageCredit\">William G. Griswold</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">William&nbsp;G&nbsp;Griswold</div>\n<div class=\"imageTitle\">Code Review Process</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nDue to the intractability of completely testing software, code review by humans remains an important contributor to software assurance.  Current tools for code review provide relatively simple information, such as a listing of the differences between the current source code and the previous version.  Consequently, many code reviews miss important implications of the differences, such as inadequate testing or a software bug.\n\nThis project researched the promise of a foundational technology called invariant detection, which gathers data from a software's runs and produces a summary of the behavioral properties of its components in the form of logic formulae.  In the context of code review, these properties, if they disagree with expectations, reveal inadequate testing or actual software defects.  Because the properties are semantic, not just syntactic, they can highlight the impact of code changes on the behavior of the revised code base.  Because property summaries can be voluminous, they are presented as a difference between the properties of the current software version and the previous one.\n\nThe major challenges to employing mined invariants in code review are performance and extracting invariant information that is useful to ordinary developers.  There were three significant outcomes from this project regarding these particular challenges, realized through the development of a tool called Getty:\n\nThree complementary      techniques for effectively mining behavioral information for code review      were developed. The techniques include (a) using impact analysis to scope      invariant mining to the methods related to the current commit, (b)      mitigating memory pressure by tracing one class at a time, and (c)      parallelizing trace gathering and invariant extraction. Experiments on 6      open source projects demonstrated that these techniques enable nearly      arbitrary reductions in running time by parallelizing analyses. Moreover,      renting processors in the cloud makes the approach performant.\n\n\nThe  approach extracts likely invariants and      presents their differences for various combinations of source code      versions and test suite versions. Using the histories of a number of      real-world open-source projects, it was empirically demonstrated how      behavior-change summaries can reveal bugs and inadequate testing earlier      than they were actually discovered by the original reviewers.  On the GSON project, two bugs were      discovered that were previously unreported.  In a retrospective analysis of GSON and      five other open source projects, it was found that invariant differentials      helped find testing gaps in 32 of 100 selected commits.  In a random selection of one known bug      from each of these projects, it was found that invariant differentials      made the bug evident at its point of introduction in 4 out of 6      cases.\n\n\nA comparative user study with      18 participants, with backgrounds ranging from computer science      undergraduate to computer science Ph.D. student, revealed how reviewers      perform code review with invariant differentials, as well as how their use      can improve the quality of code reviews by productively focusing code review efforts.\n\n\nWith regard to broader impacts, the project provided research and mentoring in computer science and engineering area. Through the involvement of underrepresented groups, the project improved the performance, skills, and self-efficacy of members of underrepresented groups, ultimately improving their access to or retention in research, teaching, or other related computer science professions.  For example, an undergraduate black woman mentored through this project is now a Ph.D. student at the University of Washington.\n\n\t\t\t\t\tLast Modified: 07/02/2022\n\n\t\t\t\t\tSubmitted by: William G Griswold"
 }
}