{
 "awd_id": "1703276",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: A General Framework for Methodical and Interpretable Anomaly Mining",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Wei Ding",
 "awd_eff_date": "2016-10-15",
 "awd_exp_date": "2022-04-30",
 "tot_intn_awd_amt": 503498.0,
 "awd_amount": 503498.0,
 "awd_min_amd_letter_date": "2016-11-14",
 "awd_max_amd_letter_date": "2019-07-01",
 "awd_abstract_narration": "Anomaly mining is the task of finding irregularities in the data. It finds applications in a plethora of domains, such as security, finance, astronomy, and medicine. Despite its immense popularity, however, it remains an extremely challenging task for many real world applications. For many practitioners, the task is poorly defined and under-specified as existing definitions and solutions are often too simplistic and do not directly correspond to the needs of modern applications. This project takes the essential steps to bridge the gap between research and practice to dramatically improve the usability, effectiveness, and interpretability of anomaly mining techniques, and to ultimately mature the field into a more valuable contributor to the larger world. It promises significant impact on many concrete problems, such as insider threat, tax evasion, and health-care fraud detection, important for the government, industry, and the society. Collaborations with industry and hospital partners aim to shepherd innovations into deployed technology, with tangible impact on security and healthcare.\r\n\r\nThe primary agenda to achieve these goals involves developing a new framework for anomaly mining that utilizes multiple heterogeneous data sources and techniques in a corroborative fashion to fundamentally reframe our understanding and ability to define, detect, and describe real-world anomalies. The project formalizes novel definitions of complex anomalies that fuse multiple data sources, and invents complex anomaly detection algorithms that further present descriptions that provide rationale for the detected anomalies. Research also explores and models anomaly ensembles that systematically harness evidences from multiple detection techniques. Ultimately, this project strives to push the boundaries of anomaly mining as a field through this quest for principled foundations and practices.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Leman",
   "pi_last_name": "Akoglu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Leman Akoglu",
   "pi_email_addr": "lakoglu@cs.cmu.edu",
   "nsf_id": "000626991",
   "pi_start_date": "2016-11-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 Forbes Ave",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 87293.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 100670.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 104271.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 104320.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 106944.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Anomaly mining finds numerous applications in the real world. Some examples include malicious behavior detection on the Web, such as fake reviews, fake news, propaganda, mis- or dis-information, etc., fraud detection in domains such as finance and healthcare, defect detection in manufacturing, host or network level intrusion and insider threat detection in cybersecurity, to name a few applications. As such, a large literature on detection algorithms have been developed in the past and there is no shortage of use cases for those.</p>\n<p>The goals of this NSF-supported project have been centered at 1) expanding the use-cases of anomaly detection, to novel streaming and ensemble settings, and perhaps more importantly 2) going beyond mere detection and study other important aspects post detection, specifically, human-in-the-loop 2i) explanation, 2b) visual exploration, and 2c) interaction for better understanding and improved detection.</p>\n<p>Toward 1), novel detection settings, we have designed new algorithms for streaming outlier detection where the novelty is also accommodating sreaming, new features. In other words, while most past literature focused on streaming instances (rows), we designed detection algorithms also for streaming fields (columns). In addition, we have studied ensemble outlier methods that can accommodate heterogeneous detectors (with varying outlier scales and distributions) as well as heterogeneous data sources. The latter shows up especially in relational settings, where one has graph data as well as behavioral, temporal, and natural language/text data.</p>\n<p>Toward 2), explanation-exploration-interaction, which constitute the key contributions of our project, we have designed new explanation strategies of detected outliers, including feature importances based, visualization based, and group based collective explanations. We have designed interative algorithms that could aid the end user/analyst to explore these explanation to make better sense, troubleshoot and resolve the anomalies. Interaction also enables the analyst to provide feedback to the detection so as to improve its results, specifically by promoting outliers interesting to the domain and \"muting\" outliers that are mere statistical outliers and not semantic anomalies of interest to the domain (i.e. false positives).&nbsp;</p>\n<p>In the later stages of the project, with the emergence of deep learning technologies and the ease of building deep neural network based frameworks, deep outlier models have emerged. Critically, we have identified an important bottleneck for using these methods in practice---that they exhibit many hyperparameters (for architecture, regularization, and optimization), which are nonobvious how to set in the absence of any supervision for fully unsupervised detection. What is more, a large body of new algorithms have emerged, and together with the classical methods, it becomes far from obvious which model to use for any given task, which may be from a variety of different domains. To this end, we started to design a series of approaches for UOMS: unsupervised outlier model selection, mainly driven by ideas from meta-learning. The key concept is to learn from historical detection tasks (with labels) and transfer information and what is learned to a new task (without labels).&nbsp;</p>\n<p>All in all, this project has taken a field that mostly focused on detection, and that mostly for point-cloud data, and expanded it in important fronts to i) detection with multiple heterogeneous data sources, ii) principled ensemble methods, iii) human-in-the-loop strategies to improve downstream tasks, and last but not least iv) systematic unsupervised hyperparameter tuning and algorithm selection. Arguably, the body of work generated by this project have helped shaped the area from being a black-art (which algorithm/hyperparameters to use?) and a black-box (how can users interpret and interact with it?) to a systematic scientific practice and a glass-box that users can look into, explore and alter on demand.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/13/2022<br>\n\t\t\t\t\tModified by: Leman&nbsp;Akoglu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAnomaly mining finds numerous applications in the real world. Some examples include malicious behavior detection on the Web, such as fake reviews, fake news, propaganda, mis- or dis-information, etc., fraud detection in domains such as finance and healthcare, defect detection in manufacturing, host or network level intrusion and insider threat detection in cybersecurity, to name a few applications. As such, a large literature on detection algorithms have been developed in the past and there is no shortage of use cases for those.\n\nThe goals of this NSF-supported project have been centered at 1) expanding the use-cases of anomaly detection, to novel streaming and ensemble settings, and perhaps more importantly 2) going beyond mere detection and study other important aspects post detection, specifically, human-in-the-loop 2i) explanation, 2b) visual exploration, and 2c) interaction for better understanding and improved detection.\n\nToward 1), novel detection settings, we have designed new algorithms for streaming outlier detection where the novelty is also accommodating sreaming, new features. In other words, while most past literature focused on streaming instances (rows), we designed detection algorithms also for streaming fields (columns). In addition, we have studied ensemble outlier methods that can accommodate heterogeneous detectors (with varying outlier scales and distributions) as well as heterogeneous data sources. The latter shows up especially in relational settings, where one has graph data as well as behavioral, temporal, and natural language/text data.\n\nToward 2), explanation-exploration-interaction, which constitute the key contributions of our project, we have designed new explanation strategies of detected outliers, including feature importances based, visualization based, and group based collective explanations. We have designed interative algorithms that could aid the end user/analyst to explore these explanation to make better sense, troubleshoot and resolve the anomalies. Interaction also enables the analyst to provide feedback to the detection so as to improve its results, specifically by promoting outliers interesting to the domain and \"muting\" outliers that are mere statistical outliers and not semantic anomalies of interest to the domain (i.e. false positives). \n\nIn the later stages of the project, with the emergence of deep learning technologies and the ease of building deep neural network based frameworks, deep outlier models have emerged. Critically, we have identified an important bottleneck for using these methods in practice---that they exhibit many hyperparameters (for architecture, regularization, and optimization), which are nonobvious how to set in the absence of any supervision for fully unsupervised detection. What is more, a large body of new algorithms have emerged, and together with the classical methods, it becomes far from obvious which model to use for any given task, which may be from a variety of different domains. To this end, we started to design a series of approaches for UOMS: unsupervised outlier model selection, mainly driven by ideas from meta-learning. The key concept is to learn from historical detection tasks (with labels) and transfer information and what is learned to a new task (without labels). \n\nAll in all, this project has taken a field that mostly focused on detection, and that mostly for point-cloud data, and expanded it in important fronts to i) detection with multiple heterogeneous data sources, ii) principled ensemble methods, iii) human-in-the-loop strategies to improve downstream tasks, and last but not least iv) systematic unsupervised hyperparameter tuning and algorithm selection. Arguably, the body of work generated by this project have helped shaped the area from being a black-art (which algorithm/hyperparameters to use?) and a black-box (how can users interpret and interact with it?) to a systematic scientific practice and a glass-box that users can look into, explore and alter on demand.\n\n\t\t\t\t\tLast Modified: 09/13/2022\n\n\t\t\t\t\tSubmitted by: Leman Akoglu"
 }
}