{
 "awd_id": "1734380",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: INT: COLLAB: Development, Deployment and Evaluation of Personalized Learning Companion Robots for Early Literacy and Language Learning",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032927593",
 "po_email": "wuhe@nsf.gov",
 "po_sign_block_name": "Wu He",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 615646.0,
 "awd_amount": 623646.0,
 "awd_min_amd_letter_date": "2017-08-16",
 "awd_max_amd_letter_date": "2020-04-21",
 "awd_abstract_narration": "This National Robotics Initiative project will develop, deploy and evaluate personalized companion robots to assist kindergarten-age children in learning language and vocabulary skills. The aim is to accelerate the impacts of social robots for early education in schools and at home. The four-year project will advance knowledge in three key areas: (1) automatic speech recognition models for young children; (2) multi-modal student assessment algorithms for early language and literacy skills; and (3) personalization of activities, content, and dialogic question generation to boost learning outcomes. The project will generate new insights for how to develop expressive, socially responsive robots that provide more effective, engaging, and empathetic educational experiences for young children. To evaluate the impacts of long-term interactions on educational outcomes, the project team will conduct a 4-month study with Kindergarten classrooms, as well as a 3-month at-home study. The project will engage teachers and parents to develop key guidelines for best practices for use of social robots in classroom and home settings, and participating undergraduate and graduate students will be trained in the multidisciplinary aspects of social robotics, speech recognition and understanding, human participation studies, interactive machine learning for automatic assessment and personalization tools, and early education research. \r\n\r\nThis research and development project will be implemented in two phases: An initial phase consisting of short pilot deployments to train and continually iterate development of project technologies and systems, followed by longer term deployment of the robot to examine autonomous interactions with social robots in school and home educational settings. During the development stage of individual components (automatic reading and language assessment tools, automatic question-generation algorithm, automatic speech recognition and spoken language understanding system models, and activities with the autonomous social robot learning companion) the project team will collect and analyze data with practical and performance measures, and refine and iterate each component of the system being developed. After development of the individual components, the autonomous social robot storytelling companion will be developed through repeated iterations with children. In the final year of the project, two 4-month studies will be conducted in six Kindergarten classrooms with 15 to 20 students each. This project is expected to result in five key contributions: (1) Development of Automatic Speech Recognition and Spoken Language Understanding systems for young children's speech, (2) Multi-modal automatic assessment algorithms for Kindergarten age children's spoken language and early reading skills; (3) Automatic personalization algorithms for story content customization and dialogic question generation in the context of young children's verbal storytelling; (4) Development of a fully autonomous, collaborative, peer-like social robot system with effective educational activities; and (5) Long-term studies with deployed social robots in schools and homes spanning several months and demonstrating sustained engagement and positive learning outcomes.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Abeer",
   "pi_last_name": "Alwan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Abeer Alwan",
   "pi_email_addr": "alwan@ee.ucla.edu",
   "nsf_id": "000090848",
   "pi_start_date": "2017-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Alison",
   "pi_last_name": "Bailey",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Alison L Bailey",
   "pi_email_addr": "abailey@gseis.ucla.edu",
   "nsf_id": "000099433",
   "pi_start_date": "2017-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles",
  "perf_str_addr": "420 Westwood Plz,66147G, ENG IV",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900951406",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "722700",
   "pgm_ele_name": "ITEST-Inov Tech Exp Stu & Teac"
  },
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "13XX",
   "app_name": "H-1B FUND, EHR, NSF",
   "app_symb_id": "045176",
   "fund_code": "1300XXXXDB",
   "fund_name": "H-1B FUND, EDU, NSF",
   "fund_symb_id": "045176"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 615646.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this National Robotics Initiative project is to develop, deploy and evaluate personalized companion robots to assist kindergarten-age children in learning language and vocabulary skills. The aim is to accelerate the impacts of social robots for early education in schools and at home. The project generated new insights for how to develop expressive, socially responsive robots that provide more effective, engaging, and empathetic educational experiences for young children. It engaged teachers and parents to develop key guidelines for best practices for use of social robots in classroom and home settings. Results indicate the importance of personalized intelligent systems on children's engagement, early literacy, and oral language skill development. Positive results would inform new kinds of early childhood learning interventions and potentially have an impact on the use of AI-based technologies in early childhood education practices.</p>\n<p>This project contributes to the advancement of child-robot conversational systems by providing an automated, personalized robot response in dialogic reading (as opposed to current scripted approaches) and by improving the naturalness of the interaction through turn-taking that is sensitive to the child&rsquo;s interest and confidence.&nbsp;Our work will generate new human factors insights, algorithmic knowledge, and educational assessment and intervention methods for developing engaging and personalized technologies that provide effective, spoken language based educational experiences for young children. Such contributions would ultimately be impactful to the fields of AI, HCI, social robotics, ASR/NLU, and ITS.</p>\n<p><strong>Outcomes: </strong></p>\n<ol>\n<li><strong>A new child speech data set was collected and transcribed (annotated).</strong> The database will be publicly available by the end of 2024. The dataset will benefit future research on child speech in a variety of applications. For example, research on disfluencies and prosodic cues to turn-taking in child speech will add to prior work that has primarily focused on adult speech, potentially leading to new hypotheses about language acquisition that account for conversational speech phenomena. The database can also be helpful in training child speech recognition systems to improve their performance.</li>\n<li><strong>Developed automatic speech recognition systems (ASR) for children: </strong>Child ASR is challenging due to the large intra and inter-speaker variabilities in child speech and the lack of large child speech databases. To deal with the issue of limited transcribed speech corpora, we developed several different approaches that improved the performance of child ASR systems and published these results. Novel normalization and data augmentation techniques were developed to deal with the large variability observed in child speech. One such technique is a novel fundamental frequency (pitch)-based frequency warping technique for use in both frequency normalization and data augmentation. The technique is inspired by a model of human speech perception. In addition, novel self-supervised learning techniques were developed to handle low-resource scenarios.</li>\n<li><strong>Studied disfluencies in Children</strong>. &nbsp;Disfluencies are prevalent in spontaneous speech, as shown in many studies of adult speech. Less is understood about children&rsquo;s speech, especially in pre-school children who are still developing their language skills. We present a novel dataset with annotated disfluencies of spontaneous explanations from 26 children (ages 5&ndash;8), interviewed twice over a year-long period. Our analysis reveals significant differences between children&rsquo;s speech in our corpus and adult spontaneous speech from two corpora (Switchboard and CallHome). Children have higher disfluency and filler rates, tend to use nasal filled pauses more frequently, and on average exhibit longer reparandums than repairs, in contrast to adult speakers. Despite the differences, an automatic disfluency detection system trained on adult (Switchboard) speech transcripts performs reasonably well on children&rsquo;s speech, achieving an F1 score that is 10% higher than the score on an adult out-of-domain dataset.</li>\n</ol>\n<p><strong>Broader Impact:</strong></p>\n<p>We aspire for the results of this Project to benefit early childhood learners, teachers and parents -- to help improve the quality of learning outcomes ultimately in a more scalable, cost-effective, and ethical manner. Ultimately, we hope to engage teachers and parents to develop important guidelines for best practices of social robots in both&nbsp;classroom and home settings. Also, we aspire to make the social robot educational activities available to facilitate dissemination and use by others. Beyond this, more natural conversational systems have potential benefits in education at all levels, for improved information access, and in assistive technologies.</p>\n<p>The project fostered interdisciplinary activities in Electrical and Computer Engineering, Linguistics, and Education Departments at UCLA, and with students and professors at the University of Washington and MIT. The interdisciplinary and multi-university collaboration provided training for graduate and undergraduate students in spoken language technology, educational technologies, and human-robot conversational systems, as well as an appreciation for issues that arise in applying the technology in an educational context.&nbsp; Students also develop important skills in how to conduct research, develop sophisticated computational AI-based systems, and communicate their work to other professionals in various fields.</p>\n<p>Publications have been posted on our webpages and findings were presented at leading conferences and journals in Engineering, Computer Science, and Education.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/01/2024<br>\nModified by: Abeer&nbsp;A&nbsp;Alwan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe goal of this National Robotics Initiative project is to develop, deploy and evaluate personalized companion robots to assist kindergarten-age children in learning language and vocabulary skills. The aim is to accelerate the impacts of social robots for early education in schools and at home. The project generated new insights for how to develop expressive, socially responsive robots that provide more effective, engaging, and empathetic educational experiences for young children. It engaged teachers and parents to develop key guidelines for best practices for use of social robots in classroom and home settings. Results indicate the importance of personalized intelligent systems on children's engagement, early literacy, and oral language skill development. Positive results would inform new kinds of early childhood learning interventions and potentially have an impact on the use of AI-based technologies in early childhood education practices.\n\n\nThis project contributes to the advancement of child-robot conversational systems by providing an automated, personalized robot response in dialogic reading (as opposed to current scripted approaches) and by improving the naturalness of the interaction through turn-taking that is sensitive to the childs interest and confidence.Our work will generate new human factors insights, algorithmic knowledge, and educational assessment and intervention methods for developing engaging and personalized technologies that provide effective, spoken language based educational experiences for young children. Such contributions would ultimately be impactful to the fields of AI, HCI, social robotics, ASR/NLU, and ITS.\n\n\nOutcomes: \n\nA new child speech data set was collected and transcribed (annotated). The database will be publicly available by the end of 2024. The dataset will benefit future research on child speech in a variety of applications. For example, research on disfluencies and prosodic cues to turn-taking in child speech will add to prior work that has primarily focused on adult speech, potentially leading to new hypotheses about language acquisition that account for conversational speech phenomena. The database can also be helpful in training child speech recognition systems to improve their performance.\nDeveloped automatic speech recognition systems (ASR) for children: Child ASR is challenging due to the large intra and inter-speaker variabilities in child speech and the lack of large child speech databases. To deal with the issue of limited transcribed speech corpora, we developed several different approaches that improved the performance of child ASR systems and published these results. Novel normalization and data augmentation techniques were developed to deal with the large variability observed in child speech. One such technique is a novel fundamental frequency (pitch)-based frequency warping technique for use in both frequency normalization and data augmentation. The technique is inspired by a model of human speech perception. In addition, novel self-supervised learning techniques were developed to handle low-resource scenarios.\nStudied disfluencies in Children. Disfluencies are prevalent in spontaneous speech, as shown in many studies of adult speech. Less is understood about childrens speech, especially in pre-school children who are still developing their language skills. We present a novel dataset with annotated disfluencies of spontaneous explanations from 26 children (ages 58), interviewed twice over a year-long period. Our analysis reveals significant differences between childrens speech in our corpus and adult spontaneous speech from two corpora (Switchboard and CallHome). Children have higher disfluency and filler rates, tend to use nasal filled pauses more frequently, and on average exhibit longer reparandums than repairs, in contrast to adult speakers. Despite the differences, an automatic disfluency detection system trained on adult (Switchboard) speech transcripts performs reasonably well on childrens speech, achieving an F1 score that is 10% higher than the score on an adult out-of-domain dataset.\n\n\n\nBroader Impact:\n\n\nWe aspire for the results of this Project to benefit early childhood learners, teachers and parents -- to help improve the quality of learning outcomes ultimately in a more scalable, cost-effective, and ethical manner. Ultimately, we hope to engage teachers and parents to develop important guidelines for best practices of social robots in bothclassroom and home settings. Also, we aspire to make the social robot educational activities available to facilitate dissemination and use by others. Beyond this, more natural conversational systems have potential benefits in education at all levels, for improved information access, and in assistive technologies.\n\n\nThe project fostered interdisciplinary activities in Electrical and Computer Engineering, Linguistics, and Education Departments at UCLA, and with students and professors at the University of Washington and MIT. The interdisciplinary and multi-university collaboration provided training for graduate and undergraduate students in spoken language technology, educational technologies, and human-robot conversational systems, as well as an appreciation for issues that arise in applying the technology in an educational context. Students also develop important skills in how to conduct research, develop sophisticated computational AI-based systems, and communicate their work to other professionals in various fields.\n\n\nPublications have been posted on our webpages and findings were presented at leading conferences and journals in Engineering, Computer Science, and Education.\n\n\n\t\t\t\t\tLast Modified: 03/01/2024\n\n\t\t\t\t\tSubmitted by: AbeerAAlwan\n"
 }
}