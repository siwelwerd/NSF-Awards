{
 "awd_id": "1734443",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: INT: COLLAB: Development, Deployment and Evaluation of Personalized Learning Companion Robots for Early Literacy and Language Learning",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032927593",
 "po_email": "wuhe@nsf.gov",
 "po_sign_block_name": "Wu He",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 882935.0,
 "awd_amount": 882935.0,
 "awd_min_amd_letter_date": "2017-08-16",
 "awd_max_amd_letter_date": "2020-01-29",
 "awd_abstract_narration": "This National Robotics Initiative project will\u00a0develop, deploy and evaluate personalized companion robots to assist kindergarten-age children in learning language and vocabulary skills. The aim is to accelerate the impacts of social robots for early education in schools and at home.  The four-year project will advance knowledge in three key areas: (1) automatic speech recognition models for young children; (2) multi-modal student assessment algorithms for early language and literacy skills; and (3) personalization of activities, content, and dialogic question generation to boost learning outcomes. The project will generate new insights for how to develop expressive, socially responsive robots that provide more effective, engaging, and empathetic educational experiences for young children. To evaluate the impacts of long-term interactions on educational outcomes, the project team will conduct a 4-month study with Kindergarten classrooms, as well as a 3-month at-home study.  The project will engage teachers and parents to develop key guidelines for best practices for use of social robots in classroom and home settings, and participating undergraduate and graduate students will be trained in the multidisciplinary aspects of social robotics, speech recognition and understanding, human participation studies, interactive machine learning for automatic assessment and personalization tools, and early education research.\r\n\r\nThis research and development project will be implemented in two phases:  An initial phase consisting of short pilot deployments to train and continually iterate development of project technologies and systems, followed by longer term deployment of the robot to examine autonomous interactions with social robots in school and home educational settings.  During the development stage of individual components (automatic reading and language assessment tools, automatic question-generation algorithm, automatic speech recognition and spoken language understanding system models, and activities with the autonomous social robot learning companion) the project team will collect and analyze data with practical and performance measures, and refine and iterate each component of the system being developed.  After development of the individual components, the autonomous social robot storytelling companion will be developed through repeated iterations with children.  In the final year of the project, two 4-month studies will be conducted in six Kindergarten classrooms with 15 to 20 students each.  This project is expected to result in five key contributions: (1) Development of Automatic Speech Recognition and Spoken Language Understanding systems for young children's speech, (2) Multi-modal automatic assessment algorithms for Kindergarten age children's spoken language and early reading skills; (3) Automatic personalization algorithms for story content customization and dialogic question generation in the context of young children's verbal storytelling; (4) Development of a fully autonomous, collaborative, peer-like social robot system with effective educational activities; and (5) Long-term studies with deployed social robots in schools and homes spanning several months and demonstrating sustained engagement and positive learning outcomes.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cynthia",
   "pi_last_name": "Breazeal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cynthia Breazeal",
   "pi_email_addr": "cynthiab@media.mit.edu",
   "nsf_id": "000481013",
   "pi_start_date": "2017-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Regina",
   "pi_last_name": "Barzilay",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Regina Barzilay",
   "pi_email_addr": "regina@csail.mit.edu",
   "nsf_id": "000183242",
   "pi_start_date": "2017-08-16",
   "pi_end_date": "2019-09-15"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Hae Won",
   "pi_last_name": "Park",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hae Won Park",
   "pi_email_addr": "haewon@mit.edu",
   "nsf_id": "000797472",
   "pi_start_date": "2020-01-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Ave",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "722700",
   "pgm_ele_name": "ITEST-Inov Tech Exp Stu & Teac"
  },
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "13XX",
   "app_name": "H-1B FUND, EHR, NSF",
   "app_symb_id": "045176",
   "fund_code": "1300XXXXDB",
   "fund_name": "H-1B FUND, EDU, NSF",
   "fund_symb_id": "045176"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 882935.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-e77d0fe0-7fff-9a10-f0d6-f48a82bea635\"> </span></p>\n<p dir=\"ltr\"><span>Pre-pandemic, it was already known that early childhood </span><span>education interventions yield great promise for ending the cycle of low literacy and poverty, and can prevent learning failure in primary school by supporting resources for cognitive, language, and literacy skill developments in children. Given the current achievement gap, exacerbated by COVID-19, there is enhanced urgency for scalable, affordable, effective early literacy interventions and enhanced opportunities for practice that can augment and extend the educational opportunities that teachers provide in the classroom.&nbsp;</span></p>\n<p dir=\"ltr\"><span>We designed, developed, and evaluated a next-generation AI-powered learning companion robot system to foster early childhood literacy and language skills for use in school and home contexts. In our interaction scenario, a child-friendly social robot collaboratively plays educational activities, such as vocabulary and pronunciation skill-building games and interactive storybooks, with kindergarten-age children using a tablet computer as a shared workspace. Under IRB-approved protocols, we captured real-time multi-modal data during these encounters to train novel machine learning models to assess children&rsquo;s performance and to adaptively personalize these activities and the robot&rsquo;s behavior to enhance engagement and learning beyond an established baseline. We advanced three key foundational and applied AI areas. First, we trained robust automatic speech recognition models for young children. We developed an interactive speech data collection and assessment protocol using a social robot to provide an engaging experience for children. We captured and transcribed a longitudinal speech corpus of 100 hours of audio data that we open-sourced to the research community. Second, we reported the validity of the robot-delivered literacy and language assessment by showing that a measure of contextualized vocabulary produced during explanatory discourse with the robot was related to letter recognition and a discrete measure of expressive vocabulary &mdash; important early literacy and literacy-related language skills, respectively. We also developed a novel assessment model for vocabulary acquisition by combining models for estimating the semantic relationships between words with the frequency of exposure to words. This combined model produced more accurate inferences from partial observation of children&rsquo;s expressed vocabulary than prior models. Third, we developed a series of adaptive personalization algorithms that dynamically tailored the content of our curricular activities, as well as the behavior of the social robot, to improve children&rsquo;s learning outcomes and engagement beyond an established baseline. For our interactive storybook activity, we developed a dialog manager to support child-robot dialogic reading. The system used prosodic cues to support improved turn-taking and generated questions as the story context unfolds.&nbsp; We leveraged reinforcement learning frameworks for the robot to personalize its scaffolding behavior to each child. For instance, we demonstrated the ability of the robot to learn personalized policy to support flexible, peer-like interaction during a vocabulary-building game whereby the robot could appropriately switch roles between acting as a tutor (robot teaches the child) or tutee (child teaches the robot). For our interactive storybook activity, we demonstrated the robot&rsquo;s ability to learn an effective exploration-scaffolding behavior to support children&rsquo;s exploration that enhanced their vocabulary learning over children&rsquo;s non-scaffolded exploration. The robot&rsquo;s exploration scaffolding actions also promoted more effective child-driven learning and exploration of the interactive storybook, in general. Finally, we developed a transfer learning method to accelerate multi-task personalization between related games/activities. We analyzed its impact on the efficiency of learning student models as well as the quality/accuracy of those student models. Our multi-task model affirmed that &lsquo;negative transfer&rsquo; was not occurring, and that multi-task personalization can overcome some challenges of long-term, personalized agent interaction. More investigation is warranted.</span></p>\n<p dir=\"ltr\"><span>A series of evaluation studies were performed with kindergarten-age children for the aforementioned computational contributions that have been published in peer-reviewed venues. We also performed longer-term studies in 8 kindergarten classrooms in the Atlanta, GA area and in over 35 homes across the US. Much of this project occurred over social distancing during the COVID-19 pandemic, so new IRB protocols were developed. We successfully field-tested the positive impact of our social robot system on children&rsquo;s learning and engagement outcomes for interventions lasting several weeks and were able to show statistically significant improvements in vocabulary learning, literacy skills such as phonemic awareness, exploratory behavior that supports learning, and overall affective engagement.</span><span> </span><span>Prior to field testing, we engaged parents, teachers, and children in the co-design of our social robot intervention to generate new human factors knowledge and insights for how to incorporate our system into school and home settings. From these findings, we developed onboarding materials for teachers and parents as well as best practices for integrating social robots into school and home settings.</span><span> </span><span>We hope these results will benefit early childhood learners, teachers, and parents -- with the potential to provide additional opportunities for engaging practice in school and at home -- to help improve the quality of early literacy learning outcomes in a more scalable, cost-effective, and responsible manner.</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/23/2022<br>\n\t\t\t\t\tModified by: Cynthia&nbsp;Breazeal</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nPre-pandemic, it was already known that early childhood education interventions yield great promise for ending the cycle of low literacy and poverty, and can prevent learning failure in primary school by supporting resources for cognitive, language, and literacy skill developments in children. Given the current achievement gap, exacerbated by COVID-19, there is enhanced urgency for scalable, affordable, effective early literacy interventions and enhanced opportunities for practice that can augment and extend the educational opportunities that teachers provide in the classroom. \nWe designed, developed, and evaluated a next-generation AI-powered learning companion robot system to foster early childhood literacy and language skills for use in school and home contexts. In our interaction scenario, a child-friendly social robot collaboratively plays educational activities, such as vocabulary and pronunciation skill-building games and interactive storybooks, with kindergarten-age children using a tablet computer as a shared workspace. Under IRB-approved protocols, we captured real-time multi-modal data during these encounters to train novel machine learning models to assess children\u2019s performance and to adaptively personalize these activities and the robot\u2019s behavior to enhance engagement and learning beyond an established baseline. We advanced three key foundational and applied AI areas. First, we trained robust automatic speech recognition models for young children. We developed an interactive speech data collection and assessment protocol using a social robot to provide an engaging experience for children. We captured and transcribed a longitudinal speech corpus of 100 hours of audio data that we open-sourced to the research community. Second, we reported the validity of the robot-delivered literacy and language assessment by showing that a measure of contextualized vocabulary produced during explanatory discourse with the robot was related to letter recognition and a discrete measure of expressive vocabulary &mdash; important early literacy and literacy-related language skills, respectively. We also developed a novel assessment model for vocabulary acquisition by combining models for estimating the semantic relationships between words with the frequency of exposure to words. This combined model produced more accurate inferences from partial observation of children\u2019s expressed vocabulary than prior models. Third, we developed a series of adaptive personalization algorithms that dynamically tailored the content of our curricular activities, as well as the behavior of the social robot, to improve children\u2019s learning outcomes and engagement beyond an established baseline. For our interactive storybook activity, we developed a dialog manager to support child-robot dialogic reading. The system used prosodic cues to support improved turn-taking and generated questions as the story context unfolds.  We leveraged reinforcement learning frameworks for the robot to personalize its scaffolding behavior to each child. For instance, we demonstrated the ability of the robot to learn personalized policy to support flexible, peer-like interaction during a vocabulary-building game whereby the robot could appropriately switch roles between acting as a tutor (robot teaches the child) or tutee (child teaches the robot). For our interactive storybook activity, we demonstrated the robot\u2019s ability to learn an effective exploration-scaffolding behavior to support children\u2019s exploration that enhanced their vocabulary learning over children\u2019s non-scaffolded exploration. The robot\u2019s exploration scaffolding actions also promoted more effective child-driven learning and exploration of the interactive storybook, in general. Finally, we developed a transfer learning method to accelerate multi-task personalization between related games/activities. We analyzed its impact on the efficiency of learning student models as well as the quality/accuracy of those student models. Our multi-task model affirmed that \u2018negative transfer\u2019 was not occurring, and that multi-task personalization can overcome some challenges of long-term, personalized agent interaction. More investigation is warranted.\nA series of evaluation studies were performed with kindergarten-age children for the aforementioned computational contributions that have been published in peer-reviewed venues. We also performed longer-term studies in 8 kindergarten classrooms in the Atlanta, GA area and in over 35 homes across the US. Much of this project occurred over social distancing during the COVID-19 pandemic, so new IRB protocols were developed. We successfully field-tested the positive impact of our social robot system on children\u2019s learning and engagement outcomes for interventions lasting several weeks and were able to show statistically significant improvements in vocabulary learning, literacy skills such as phonemic awareness, exploratory behavior that supports learning, and overall affective engagement. Prior to field testing, we engaged parents, teachers, and children in the co-design of our social robot intervention to generate new human factors knowledge and insights for how to incorporate our system into school and home settings. From these findings, we developed onboarding materials for teachers and parents as well as best practices for integrating social robots into school and home settings. We hope these results will benefit early childhood learners, teachers, and parents -- with the potential to provide additional opportunities for engaging practice in school and at home -- to help improve the quality of early literacy learning outcomes in a more scalable, cost-effective, and responsible manner.\n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/23/2022\n\n\t\t\t\t\tSubmitted by: Cynthia Breazeal"
 }
}