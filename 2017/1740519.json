{
 "awd_id": "1740519",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "AF: Medium: Collaborative Research: Hardness in Polynomial Time",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2017-01-20",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 453050.0,
 "awd_amount": 453050.0,
 "awd_min_amd_letter_date": "2017-04-25",
 "awd_max_amd_letter_date": "2017-08-04",
 "awd_abstract_narration": "A central endeavor of theoretical computer science is to classify computational problems according to the resources (such as running time and storage space) needed to solve them.\u00a0\u00a0Although the field of algorithm design has been highly successful in discovering efficient, polynomial-time algorithms for problems of practical interest, little evidence has been shown for the optimality of most algorithms.\u00a0\u00a0The goal of this project is to build a useful complexity theory for the class of polynomial-time solvable problems (called P), by proving equivalences between problems and proving conditional lower bounds on specific problems, assuming the validity of certain plausible mathematical conjectures.\r\n\r\nKnown lower bounds for specific problems in P are conditioned on some complexity-theoretic assumption such as the (Strong) Exponential Time Hypothesis (concerning the complexity of k-CNF-SAT), the conjecture that dense all-pairs shortest paths (APSP) requires cubic time, or that 3SUM requires quadratic time.\u00a0\u00a0The goals of this project are threefold.\u00a0\u00a0The first goal is to establish conditional lower bounds on problems in diverse areas (such as graph optimization, string matching, geometry, and dynamic data structures) using standard hardness conjectures. The second goal is to search for better hardness conjectures that are both plausible and versatile, and to discover relationships (implications or equivalences) between nominally unrelated conjectures.\u00a0\u00a0The last goal is to investigate the plausibility of these conjectures by attempting to disprove them.\r\n\r\nThe curricular portion of this project involves developing lecture material suitable for introductory algorithms and complexity courses at both the undergraduate and graduate level.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Virginia",
   "pi_last_name": "Williams",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Virginia V Williams",
   "pi_email_addr": "virgito@gmail.com",
   "nsf_id": "000640555",
   "pi_start_date": "2017-04-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Avenue",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 144958.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 308092.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>One of the great successes of theoretical computer science is classifying problems as tractable (traditionally solvable in polynomial time, i.e. in the complexity class P) or intractable (typically NP-hard).&nbsp; In today&rsquo;s world of large data however, even low polynomial time such as cubic or quadratic time may be intractable. A new theory of hardness, fine-grained complexity aims to differentiate problems whose best running times grow as n, n^2, n^3, etc. in terms of the input size n, and to understand the relationships between problems via reductions. The goal of this project is to further develop this theory and to apply it in new ways.<br /> <br /> <br /> This grant supported the organization of two workshops on this topic, Structure and Hardness in P in 2016 and and Fine-Grained Approximation Algorithms and Complexity in 2019, which helped popularize and accelerate research in this exciting field. To further help the research area and expose beginning researchers to the topics, the PI wrote several surveys and lists of open problems, most recently in 2018 and 2019. <br /> <br /></p>\n<p>NP-hardness is based on the widely believed but unproven assumption that P does not equal NP. Similarly, fine-grained complexity lower bounds are based on plausible,<br /> but unproven, assumptions on the hardness of fundamental problems. The main three hardness hypotheses are the 3SUM Hypothesis that the 3SUM problem requires n^{2-o(1)} time, the APSP Hypothesis that All-Pairs Shortest Paths (APSP) requires n^{3-o(1)} time and the Strong Exponential Time Hypothesis (SETH) that Boolean k-Satisfiability requires 2^{n-o(n)} time.</p>\n<p>We have proven that the current fastest algorithms for a variety of basic problems are optimal if one assumes SETH: Deciding whether a given rooted tree is a subtree of another requires n^{2-o(1)} time under SETH, and can also be solved in O(n^2) time. The Longest Common Subsequence (LCS) problem for two n-length sequences, whose O(n^2) time algorithm is taught in undergraduate classes as a classic example of dynamic programming, requires n^{2-o(1)} time under SETH. Computing a 1.5-approximation to the diameter in a sparse n-node graph has an n^{1.5}polylog(n) time algorithm, and this approximation ratio cannot be improved without using significantly more time, nor can the time be improved without incurring a significantly larger error. For some of these problems, such as LCS, we have shown even more powerful hardness results. For instance, even polylogarithmic improvements over the n^2 running time would lead to exciting consequences in complexity theory.</p>\n<p>We investigated the limits of the APSP hypothesis, by showing that on graphs with special structure, APSP can be solved in truly subcubic time. Meanwhile, we also showed that under plausible hardness hypotheses, APSP in m-edge, n-vertex graphs and related problems such as shortest cycle, require mn^{1-o(1)} time, thus extending the plausibility of the APSP hypothesis for a wider range of sparsities. We also investigated the 3SUM hypothesis, showing that it is equivalent to a more plausible sounding hypothesis about the time and space usage of 3SUM algorithms.</p>\n<p>Under a hypothesis about k-Clique finding, we proved hardness results for a variety of problems, from induced pattern detection in graphs, to RNA-Folding, to Context-free Grammar Parsing. The intuition behind some of these hardness results led to improved algorithms. For instance, we were able to develop the first truly subcubic time algorithm for RNA-Folding using fast matrix multiplication.</p>\n<p>We applied fine-grained ideas in many diverse settings, beyond that of static algorithms in the RAM model: We developed hardness results for sensitivity and fault-tolerant problems and for dynamic graph problems. We proved a separation between versions of retroactive data structures based on fine-grained hypotheses. We showed hardness for fixed parameter tractable problems whose running time is a fixed polynomial in the size of the input, and any function of the parameter. We developed fine-grained complexity in the I/O model of computation. We provided fine-grained worst-case to average-case reductions for key problems over natural distributions, and worked on developing fine-grained cryptographic primitives that could lead to a version of cryptography that is still possible, even if P equals NP.</p>\n<p>This grant partially supported several Ph.D. students, three of which have graduated. One is a professor at the Weizmann Institute, and the other two are postdocs at UC Berkeley and Harvard, respectively.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/19/2021<br>\n\t\t\t\t\tModified by: Virginia&nbsp;V&nbsp;Williams</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOne of the great successes of theoretical computer science is classifying problems as tractable (traditionally solvable in polynomial time, i.e. in the complexity class P) or intractable (typically NP-hard).  In today\u2019s world of large data however, even low polynomial time such as cubic or quadratic time may be intractable. A new theory of hardness, fine-grained complexity aims to differentiate problems whose best running times grow as n, n^2, n^3, etc. in terms of the input size n, and to understand the relationships between problems via reductions. The goal of this project is to further develop this theory and to apply it in new ways.\n \n \n This grant supported the organization of two workshops on this topic, Structure and Hardness in P in 2016 and and Fine-Grained Approximation Algorithms and Complexity in 2019, which helped popularize and accelerate research in this exciting field. To further help the research area and expose beginning researchers to the topics, the PI wrote several surveys and lists of open problems, most recently in 2018 and 2019. \n \n\n\nNP-hardness is based on the widely believed but unproven assumption that P does not equal NP. Similarly, fine-grained complexity lower bounds are based on plausible,\n but unproven, assumptions on the hardness of fundamental problems. The main three hardness hypotheses are the 3SUM Hypothesis that the 3SUM problem requires n^{2-o(1)} time, the APSP Hypothesis that All-Pairs Shortest Paths (APSP) requires n^{3-o(1)} time and the Strong Exponential Time Hypothesis (SETH) that Boolean k-Satisfiability requires 2^{n-o(n)} time.\n\nWe have proven that the current fastest algorithms for a variety of basic problems are optimal if one assumes SETH: Deciding whether a given rooted tree is a subtree of another requires n^{2-o(1)} time under SETH, and can also be solved in O(n^2) time. The Longest Common Subsequence (LCS) problem for two n-length sequences, whose O(n^2) time algorithm is taught in undergraduate classes as a classic example of dynamic programming, requires n^{2-o(1)} time under SETH. Computing a 1.5-approximation to the diameter in a sparse n-node graph has an n^{1.5}polylog(n) time algorithm, and this approximation ratio cannot be improved without using significantly more time, nor can the time be improved without incurring a significantly larger error. For some of these problems, such as LCS, we have shown even more powerful hardness results. For instance, even polylogarithmic improvements over the n^2 running time would lead to exciting consequences in complexity theory.\n\nWe investigated the limits of the APSP hypothesis, by showing that on graphs with special structure, APSP can be solved in truly subcubic time. Meanwhile, we also showed that under plausible hardness hypotheses, APSP in m-edge, n-vertex graphs and related problems such as shortest cycle, require mn^{1-o(1)} time, thus extending the plausibility of the APSP hypothesis for a wider range of sparsities. We also investigated the 3SUM hypothesis, showing that it is equivalent to a more plausible sounding hypothesis about the time and space usage of 3SUM algorithms.\n\nUnder a hypothesis about k-Clique finding, we proved hardness results for a variety of problems, from induced pattern detection in graphs, to RNA-Folding, to Context-free Grammar Parsing. The intuition behind some of these hardness results led to improved algorithms. For instance, we were able to develop the first truly subcubic time algorithm for RNA-Folding using fast matrix multiplication.\n\nWe applied fine-grained ideas in many diverse settings, beyond that of static algorithms in the RAM model: We developed hardness results for sensitivity and fault-tolerant problems and for dynamic graph problems. We proved a separation between versions of retroactive data structures based on fine-grained hypotheses. We showed hardness for fixed parameter tractable problems whose running time is a fixed polynomial in the size of the input, and any function of the parameter. We developed fine-grained complexity in the I/O model of computation. We provided fine-grained worst-case to average-case reductions for key problems over natural distributions, and worked on developing fine-grained cryptographic primitives that could lead to a version of cryptography that is still possible, even if P equals NP.\n\nThis grant partially supported several Ph.D. students, three of which have graduated. One is a professor at the Weizmann Institute, and the other two are postdocs at UC Berkeley and Harvard, respectively.\n\n\t\t\t\t\tLast Modified: 04/19/2021\n\n\t\t\t\t\tSubmitted by: Virginia V Williams"
 }
}