{
 "awd_id": "1749501",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "IIS: EAGER: Benchmarks for Autonomous Unmanned Aerial Vehicles in Agriculture Applications",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2017-12-15",
 "awd_exp_date": "2021-11-30",
 "tot_intn_awd_amt": 224993.0,
 "awd_amount": 224993.0,
 "awd_min_amd_letter_date": "2017-09-14",
 "awd_max_amd_letter_date": "2017-09-14",
 "awd_abstract_narration": "Drone technology and aerial imagery can be developed to help farmers meet future demands to increase crop yield and lower costs without using more land.  Access to the technology, to the fields, and to permits to fly and capture imagery can limit the pool of developers, however.  This project devises benchmarks that capture, characterize and share empirical data collected from autonomous unmanned aerial vehicle (AUAV) systems deployed in agricultural settings.  It curates and shares AUAV data on the Ohio State TDA Data Commons which will enable research across disciplines, and will host an Agriculture Analysis in the Cloud workshop which attracts computer scientists, geoscientists, farmers and agricultural engineers.\r\n\r\nA revealing example of application is the task of crop thinning, which prevents competition between plants by applying herbicide selectively to weeds and weak crops. Manual thinning is physically demanding and can cost up to $100 per acre. An autonomous UAV system for crop thinning will need to be able to process imagery to identify crowding in various plant types. If over-crowding is detected, the AUAV can lower and hover to capture hi-res images suitable for classification of strong crops, weak crops and weeds.  This project creates a reference implementation of an AUAV systems that detects crop thinning, capturing both low and high resolution imagery. Researchers can mimic this AUAV system to perform holistic tests with different hardware and software, and use this benchmarked data to explore approaches for on-board or on-line classification of crowding and crop strength without access to farmland for flying AUAVs.  AUAV power can also be recorded, to help explore decisions on charging vs sampling less data.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Stewart",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher Stewart",
   "pi_email_addr": "cstewart@cse.ohio-state.edu",
   "nsf_id": "000534897",
   "pi_start_date": "2017-09-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio State University",
  "inst_street_address": "1960 KENNY RD",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBUS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "6146888735",
  "inst_zip_code": "432101016",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OH03",
  "org_lgl_bus_name": "OHIO STATE UNIVERSITY, THE",
  "org_prnt_uei_num": "MN4MDDMN8529",
  "org_uei_num": "DLWBSLWAJWR1"
 },
 "perf_inst": {
  "perf_inst_name": "Ohio State University",
  "perf_str_addr": "2015 Neil Ave",
  "perf_city_name": "Columbus",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "432101277",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OH03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "039Y00",
   "pgm_ele_name": "S&AS - Smart & Autonomous Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "046Z",
   "pgm_ref_txt": "S&AS - Smart & Autonomous Systems"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 224993.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We developed autonomous drone technology and data-driven processing for aerial images that helps farmers increase crop yield and diagnose crop infections and pest infestations. One of our intellectual contributions was a software package, SoftwarePilot, that simplified the use of reinforcement learning in the design of fully autonomous drones. SoftwarePilot has now been used fly drones over thousands of agricultural acres in multiple countries.&nbsp; Further, the computational workload imposed by SoftwarePilot provides a realistic benchmark that has spurred research on edge-cloud resource management, quality-aware AI, and real time scheduling.&nbsp; Another major contribution was the design of data processing pipelines for aerial imagery.&nbsp; DefoNet proved that low flying drones capture enough details to assess the severity of leaf defoliation (e.g., small, centimeter-scale holes in leaves) in a single pass.&nbsp; To do so, we had developed a novel neural network architecture tailored to this task.&nbsp; Likewise, whole-field reinforcement learning provided a novel approach schedule flight paths in agriculture settings.&nbsp; The code and datasets developed under this project have been released as open source.&nbsp; We have already seen strong evidence that these benchmarks will be used by the broader academic community.&nbsp; In addition, the project provided opportunities for outreach.&nbsp; PI Stewart and lead students Jayson Boubin and Zichen Zhang led outreach events with ACM-W and OSU Translational Data Analytics Institute.&nbsp; In addition, undergraduate students at OSU were introduced to the novel research concepts from this project (such as autonomy cubes) in our databases course.&nbsp; Finally, perhaps one of the most lasting intellectual contributions, was the proposal itself: Using autonomous drones to link agriculture and computer science.&nbsp; An early vision paper published under this project,&nbsp;Autonomic computing challenges in fully autonomous precision agriculture,&nbsp;has attracted a growing research community by showing the computational resource management is a key component to cost-effective digital agriculture.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/08/2022<br>\n\t\t\t\t\tModified by: Christopher&nbsp;Stewart</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWe developed autonomous drone technology and data-driven processing for aerial images that helps farmers increase crop yield and diagnose crop infections and pest infestations. One of our intellectual contributions was a software package, SoftwarePilot, that simplified the use of reinforcement learning in the design of fully autonomous drones. SoftwarePilot has now been used fly drones over thousands of agricultural acres in multiple countries.  Further, the computational workload imposed by SoftwarePilot provides a realistic benchmark that has spurred research on edge-cloud resource management, quality-aware AI, and real time scheduling.  Another major contribution was the design of data processing pipelines for aerial imagery.  DefoNet proved that low flying drones capture enough details to assess the severity of leaf defoliation (e.g., small, centimeter-scale holes in leaves) in a single pass.  To do so, we had developed a novel neural network architecture tailored to this task.  Likewise, whole-field reinforcement learning provided a novel approach schedule flight paths in agriculture settings.  The code and datasets developed under this project have been released as open source.  We have already seen strong evidence that these benchmarks will be used by the broader academic community.  In addition, the project provided opportunities for outreach.  PI Stewart and lead students Jayson Boubin and Zichen Zhang led outreach events with ACM-W and OSU Translational Data Analytics Institute.  In addition, undergraduate students at OSU were introduced to the novel research concepts from this project (such as autonomy cubes) in our databases course.  Finally, perhaps one of the most lasting intellectual contributions, was the proposal itself: Using autonomous drones to link agriculture and computer science.  An early vision paper published under this project, Autonomic computing challenges in fully autonomous precision agriculture, has attracted a growing research community by showing the computational resource management is a key component to cost-effective digital agriculture.\n\n\t\t\t\t\tLast Modified: 03/08/2022\n\n\t\t\t\t\tSubmitted by: Christopher Stewart"
 }
}