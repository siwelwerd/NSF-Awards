{
 "awd_id": "1710009",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SNNnow: Probabilistic Learning for Deep Spiking Neural Networks: Foundations and Hardware Co-Optimization",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": "7032925394",
 "po_email": "rnash@nsf.gov",
 "po_sign_block_name": "Richard Nash",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 380000.0,
 "awd_amount": 380000.0,
 "awd_min_amd_letter_date": "2017-06-15",
 "awd_max_amd_letter_date": "2021-06-16",
 "awd_abstract_narration": "Overview: Deep neural networks (DNN) have become the de-facto standard tool to carry out complex learning\r\ntasks. DNNs belong to the second generation of artificial neural networks (ANNs), which rely on neurons\r\nthat implement memory-less non-linear transformations of the synaptic inputs. Motivated by the biological\r\nanalogy with the behavior of neurons in the brain, the third generation of neural networks, also referred to\r\nas Spiking Neural Networks (SNNs), was introduced in the nineties. In SNNs, synaptic input and neuronal\r\noutput signals are spike trains. This proposal argues that the time for the use of SNNs as machine learning\r\ntools has come, and sets forth a systematic approach for the design and implementation of SNNs as learning\r\nand inference machines.\r\n\r\nIntellectual merit: SNNs have a number of unique advantages as compared to ANNs: (i) They are event-based\r\nsystems with natural sparsity properties, which have the potential to make deep learning machines feasible for\r\nenergy-limited devices; (ii) They are uniquely capable to natively process data that comes in the form of timeencoded\r\nprocesses, for example, from bio-inspired sensors. The main goal of this project is the establishment\r\nof a theoretical framework to enable the design of flexible spike-domain learning algorithms that are tailored\r\nto the solution of supervised and unsupervised cognitive tasks, as well as their co-optimization on nanoscale\r\nhardware architectures. To this end, this project puts forth a principled probabilistic framework based on the\r\ngraphical formalism of Directed Information Graphs.\r\n\r\nBroader impact: The outcome of this research is expected to have a profound impact on the increasing number\r\nof practical applications that are based on the processing of time-encoded signals, including biological sensors\r\nand next-generation communication systems, and/or that require the adoption of computing solutions with a\r\nsignificantly smaller power budget as compared to conventional DNNs. The research methodology is based\r\non a multi-disciplinary approach that integrates machine learning, information theory, probabilistic graphical\r\nmodels, neuromorphic computing and device/system architecture at the nanoscale. The educational plan at\r\nthe home institution targets both undergraduate and graduate students via hands-on learning and experimentation\r\nactivities.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Durgamadhab",
   "pi_last_name": "Misra",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Durgamadhab Misra",
   "pi_email_addr": "dmisra@njit.edu",
   "nsf_id": "000198737",
   "pi_start_date": "2020-03-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Bipin",
   "pi_last_name": "Rajendran",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bipin Rajendran",
   "pi_email_addr": "bipin@njit.edu",
   "nsf_id": "000715580",
   "pi_start_date": "2017-06-15",
   "pi_end_date": "2020-03-20"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Alexander",
   "pi_last_name": "Haimovich",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Alexander M Haimovich",
   "pi_email_addr": "haimovic@njit.edu",
   "nsf_id": "000214081",
   "pi_start_date": "2020-03-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Osvaldo",
   "pi_last_name": "Simeone",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Osvaldo Simeone",
   "pi_email_addr": "osvaldo.simeone@njit.edu",
   "nsf_id": "000502056",
   "pi_start_date": "2017-06-15",
   "pi_end_date": "2019-09-04"
  }
 ],
 "inst": {
  "inst_name": "New Jersey Institute of Technology",
  "inst_street_address": "323 DR MARTIN LUTHER KING JR BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "NEWARK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "9735965275",
  "inst_zip_code": "071021824",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NJ10",
  "org_lgl_bus_name": "NEW JERSEY INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "SGBMHQ7VXNH5"
 },
 "perf_inst": {
  "perf_inst_name": "New Jersey Institute of Technology",
  "perf_str_addr": "323 DOCTOR MARTIN LUTHER",
  "perf_city_name": "Newark",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "071021982",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NJ10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760700",
   "pgm_ele_name": "EPCN-Energy-Power-Ctrl-Netwrks"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1653",
   "pgm_ref_txt": "Adaptive & intelligent systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 380000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Deep neural networks (DNN) have become the de-facto standard tool to carry out complex learning tasks. DNNs belong to the second generation of artificial neural networks (ANNs), which rely on neurons that implement memory-less non-linear transformations of the synaptic inputs. Motivated by the biological analogy with the behavior of neurons in the brain, the third generation of neural networks, also referred to as Spiking Neural Networks (SNNs) where the synaptic input and neuronal output signals are spike trains. We have used SNNs as machine learning tools and followed a systematic approach for the design and implementation of SNNs as learning and inference machines.</p>\n<p>&nbsp;</p>\n<p>Intellectual Merit:</p>\n<p>The intellectual merit of our research led to several new approaches. When trained over noisy ?real? data, the data generated by the spiking generative adversarial network (GAN), a machine learning (ML) model, is still recognizable by an ANN classifier trained on clean real data to the same level of classification accuracy as noisy real data. This suggests that the capacity of the SNN to generate grayscale images is instrumental in enabling a classifier to distinguish the digits from the noise. We also show that on the harder task of generating 10x10 MNIST images, the images generated by the spiking GAN are classified by an ANN classifier with 90.6% accuracy, approaching the baseline test accuracy of 98% when tested on real images.</p>\n<p>&nbsp;</p>\n<p>We demonstrated that a spiking generator trained using the derived conditional spiking adversarial learning rule accurately generates spatio-temporal handwritten digit data in the form of spiking signals that can be used as a neuromorphic dataset for SNN training. When used to train an SNN classifier, this data achieves 82% test accuracy (approaching the baseline accuracy of 85% when trained on rate-encoded data) as compared to 12% accuracy achieved when using data generated by an SNN trained via online maximum-likelihood learning.</p>\n<p>&nbsp;</p>\n<p>We also showed that the spiking GAN under Bayesian learning is able to generate data that emulates burst and tonic spike patterns inspired by observations of biological neuron spiking outputs. The generated burst and tonic data is shown to minimize the van Rossum distance from the real burst and tonic data respectively. In comparison, the standard spiking GAN experiences mode collapse when tasked with generating this temporally diverse data while samples from the maximum likelihood trained SNN exhibit a mixture of the burst and tonic features.</p>\n<p>&nbsp;</p>\n<p>Broader Impact:</p>\n<p>The project has a significant broader impact where we graduated several doctoral students including three female PhD students. The research results can enhance the artificial intelligence (AI) and machine learning (ML) implementations in many machines. Most of the research findings have been incorporated into the advanced undergraduate and graduate courses and new courses are being develop to train more students.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/27/2022<br>\n\t\t\t\t\tModified by: Durgamadhab&nbsp;Misra</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDeep neural networks (DNN) have become the de-facto standard tool to carry out complex learning tasks. DNNs belong to the second generation of artificial neural networks (ANNs), which rely on neurons that implement memory-less non-linear transformations of the synaptic inputs. Motivated by the biological analogy with the behavior of neurons in the brain, the third generation of neural networks, also referred to as Spiking Neural Networks (SNNs) where the synaptic input and neuronal output signals are spike trains. We have used SNNs as machine learning tools and followed a systematic approach for the design and implementation of SNNs as learning and inference machines.\n\n \n\nIntellectual Merit:\n\nThe intellectual merit of our research led to several new approaches. When trained over noisy ?real? data, the data generated by the spiking generative adversarial network (GAN), a machine learning (ML) model, is still recognizable by an ANN classifier trained on clean real data to the same level of classification accuracy as noisy real data. This suggests that the capacity of the SNN to generate grayscale images is instrumental in enabling a classifier to distinguish the digits from the noise. We also show that on the harder task of generating 10x10 MNIST images, the images generated by the spiking GAN are classified by an ANN classifier with 90.6% accuracy, approaching the baseline test accuracy of 98% when tested on real images.\n\n \n\nWe demonstrated that a spiking generator trained using the derived conditional spiking adversarial learning rule accurately generates spatio-temporal handwritten digit data in the form of spiking signals that can be used as a neuromorphic dataset for SNN training. When used to train an SNN classifier, this data achieves 82% test accuracy (approaching the baseline accuracy of 85% when trained on rate-encoded data) as compared to 12% accuracy achieved when using data generated by an SNN trained via online maximum-likelihood learning.\n\n \n\nWe also showed that the spiking GAN under Bayesian learning is able to generate data that emulates burst and tonic spike patterns inspired by observations of biological neuron spiking outputs. The generated burst and tonic data is shown to minimize the van Rossum distance from the real burst and tonic data respectively. In comparison, the standard spiking GAN experiences mode collapse when tasked with generating this temporally diverse data while samples from the maximum likelihood trained SNN exhibit a mixture of the burst and tonic features.\n\n \n\nBroader Impact:\n\nThe project has a significant broader impact where we graduated several doctoral students including three female PhD students. The research results can enhance the artificial intelligence (AI) and machine learning (ML) implementations in many machines. Most of the research findings have been incorporated into the advanced undergraduate and graduate courses and new courses are being develop to train more students.\n\n \n\n\t\t\t\t\tLast Modified: 12/27/2022\n\n\t\t\t\t\tSubmitted by: Durgamadhab Misra"
 }
}