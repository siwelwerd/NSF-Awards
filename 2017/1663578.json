{
 "awd_id": "1663578",
 "agcy_id": "NSF",
 "tran_type": "CoopAgrmnt",
 "awd_istr_txt": "Cooperative Agreement",
 "awd_titl_txt": "Stampede 2:  Operations and Maintenance for the Next Generation of Petascale Computing",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032922247",
 "po_email": "rchadduc@nsf.gov",
 "po_sign_block_name": "Robert Chadduck",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 24000000.0,
 "awd_amount": 36793220.0,
 "awd_min_amd_letter_date": "2017-09-20",
 "awd_max_amd_letter_date": "2024-04-04",
 "awd_abstract_narration": "In 2016, the National Science Foundation funded the acquisition of a large new forward-looking high performance computing (HPC) system, Stampede 2, by the Texas Advanced Computing Center (TACC) at the University of Texas at Austin. In partnership with its lead system vendor (Dell), TACC will deploy the Intel-based system in 2017, doubling the capacity of its predecessor, Stampede, by introducing new memory, processor and interconnect technologies. As Stampede 2 nears its operational deployment, a proposal for operations and maintenance (O&M) of the system was submitted by the University of Texas at Austin.  The system is expected to be used as a national resource by thousands of researchers, educators, and students annually. As a critical component of academic infrastructure, it will advance fundamental knowledge in a wide variety of science and engineering frontiers. In addition to continued partnership with Dell, subawards to Clemson University, The University of Colorado, Cornell University, Indiana University, and Ohio State University will ensure a broad national research of innovative HPC to academia and industry. \r\n\r\nStampede 2 will operate within the larger landscape of the nation's research cyberinfrastructure (CI). It joins the set of large scale computing resources that rely on and benefit from the collaborative user services model of the NSF-funded Extreme Science and Engineering Discovery Environment (XSEDE) project. These accompanying shared services provide for systems allocations, user training, technical interoperability, research and CI community engagement, and access to expertise. Stampede 2 doubles the computing, storage and networking capacity of the current system, Stampede. Delivering on the potential of this complex scientific instrument requires knowledgeable and ongoing operations, which include: robust system maintenance, reliability and availability; security; software configuration and management; efficient utilization; and research workflow optimization. Most significantly, the thousands of users who currently depend on Stampede rely on expert assistance to help in the development of new skills in order to maximize the value of the new technologies in Stampede 2. These technologies represent the future of large-scale computing. \r\n\r\nThe architecture of Stampede 2 reflects community consensus about HPC's exascale future; while specific technologies are in rapid flux, all paths indicate a transition to more explicit parallelism within applications. Today's applications must adapt, and Stampede 2 offers a bridge to exascale systems of tomorrow, providing capabilities for exploring new approaches to multiscale (both temporal and spatial) simulations, many forms of data intensive science, visualization, and data analysis. Stampede 2's operations will also broaden the usage base of HPC, appealing to and supporting a much greater depth and breadth of large-scale computational science for research than any other national system. \r\n\r\nThe Stampede 2 Operations and Maintenance project plan includes world-class operations, user support and training, application tuning and migration, education, outreach, documentation, data management, visualization, analytics-driven application support, and research collaboration. TACC and its team of partners are established CI providers. Collectively the Stampede 2 operations team will leverage a variety of other NSF-supported projects such as XSEDE, Advanced Cyberinfrastructure Research and Education Facilitators (ACI-REF), and a broad array of scientific software activities. With these complementary collaborations, the value of the O&M award is further increased.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Stanzione",
   "pi_mid_init": "",
   "pi_sufx_name": "Jr",
   "pi_full_name": "Daniel Stanzione",
   "pi_email_addr": "dan@tacc.utexas.edu",
   "nsf_id": "000193108",
   "pi_start_date": "2017-09-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kelly",
   "pi_last_name": "Gaither",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Kelly P Gaither",
   "pi_email_addr": "kelly@tacc.utexas.edu",
   "nsf_id": "000356197",
   "pi_start_date": "2017-09-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Tommy",
   "pi_last_name": "Minyard",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Tommy K Minyard",
   "pi_email_addr": "minyard@tacc.utexas.edu",
   "nsf_id": "000371000",
   "pi_start_date": "2017-09-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Barth",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "William L Barth",
   "pi_email_addr": "bbarth@tacc.utexas.edu",
   "nsf_id": "000596862",
   "pi_start_date": "2017-09-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Niall",
   "pi_last_name": "Gaffney",
   "pi_mid_init": "I",
   "pi_sufx_name": "",
   "pi_full_name": "Niall I Gaffney",
   "pi_email_addr": "ngaffney@tacc.utexas.edu",
   "nsf_id": "000668354",
   "pi_start_date": "2017-09-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "101 E. 27th Street, Suite 5.300",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121532",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  },
  {
   "pgm_ele_code": "761900",
   "pgm_ele_name": "Innovative HPC"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 24000000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 6000000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 4793219.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 2000001.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Stampede2 project procured, deployed, and operated a petascale supercomputer for science and engineering at the Texas Advanced Computing Center (TACC), part of the University of Texas at Austin.&nbsp; Deployed in 2017, Stampede 2 operated through the end of 2023, when it retired after six years of production operations.&nbsp; &nbsp;To date, the machine has run more than nine million simulation, AI, and data analysis jobs for more than fifty thousand users.&nbsp; These jobs took more than 10 billion hours of processor time.&nbsp;</p>\r\n<p>Stampede2, in its original configuration,&nbsp; consisted of more than six thousand compute servers made by Dell Technologies, with processors from Intel and storage from the Cray division of Hewlett-Packard Enterprise.&nbsp; &nbsp;The network consisted of a 100Gb high-speed Omnipath fabric, originally provided by Intel, and now supported by Cornelis Networks.&nbsp; The compute servers included 4,204 Intel Xeon Phi \"Knights Landing\" processors, and 1,736 servers with dual Intel&nbsp;<span>Xeon Scalable \"Sky Lake\" processors, for a total of more than 400,000 processors cores,&nbsp;<span>and nearly 20 petaflops of peak performance.&nbsp;</span></span></p>\r\n<p>Since the on-time, on-budget start of production operations in mid-2017, time on Stampede 2 has been allocated quarterly via the XSEDE peer-reveiw process.&nbsp; More than 3,000 projects received allocations on the machine, across virtually all fields of science.&nbsp; Typically, requests for the machine were three to four times the available time.&nbsp; Throughout all four years of operation of the machine, usage has been well over 90% of full capacity, limited only by the complications of scheduling very large simulations of varying size.&nbsp; In the most recent year of allocations, highlights included multiple projects that improve the endurance of batteries, or reduce the need for scarce materials in constructing batteries.&nbsp; Other users identified target materials that would allow solar panels to be constructed without the use of lead.&nbsp; &nbsp;Catalogs of human RNA were produced for the first time through the use of computation on Stampede 2.&nbsp; Stampede 2 also provided computation for drug discovery and epidemiological models in response to the COVID-19 pandemic.&nbsp; Other users made use of Stampede 2 to forecast and respond to natural disasters, including wildfires, hurricanes, and tornadoes.&nbsp; &nbsp;Research in AI has been growing steadily on the machine.&nbsp;&nbsp;</p>\r\n<p>Operations also included signficant training and outreach components.&nbsp; There have been hundreds of thousands of visits to the online \"Virtual Workshop\" for Stampede 2 hosted by project partner Cornell University.&nbsp; Thousands of people have attended online or in-person training, ranging from week long courses and all day conference workshops to shorter webinars.&nbsp; &nbsp;Hundreds of students have participated in outreach events, including the summer \"Code@TACC\" week-long residential events for high school. Students participating in these events were overwhelmingly first generation college students, and tracking data shows attendees enter college in STEM fields at more than 10x the national average.&nbsp;</p>\r\n<p>Stampede 2 has been reliable, accessible, and overwhelmingly impactful to countless NSF researchers.&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/05/2025<br>\nModified by: Daniel&nbsp;Stanzione</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/1663578/1663578_10522637_1738795307565_Stampede2__rgov_214x142--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2025/1663578/1663578_10522637_1738795307565_Stampede2__rgov_214x142--rgov-800width.jpg\" title=\"The Stampede2 Supercomputer\"><img src=\"/por/images/Reports/POR/2025/1663578/1663578_10522637_1738795307565_Stampede2__rgov_214x142--rgov-66x44.jpg\" alt=\"The Stampede2 Supercomputer\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Image of the Stampede2 supercomputer at the Texas Advanced Computing Center in Austin, Texas</div>\n<div class=\"imageCredit\">TACC, UT-Austin</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Daniel&nbsp;Stanzione\n<div class=\"imageTitle\">The Stampede2 Supercomputer</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe Stampede2 project procured, deployed, and operated a petascale supercomputer for science and engineering at the Texas Advanced Computing Center (TACC), part of the University of Texas at Austin. Deployed in 2017, Stampede 2 operated through the end of 2023, when it retired after six years of production operations. To date, the machine has run more than nine million simulation, AI, and data analysis jobs for more than fifty thousand users. These jobs took more than 10 billion hours of processor time.\r\n\n\nStampede2, in its original configuration, consisted of more than six thousand compute servers made by Dell Technologies, with processors from Intel and storage from the Cray division of Hewlett-Packard Enterprise. The network consisted of a 100Gb high-speed Omnipath fabric, originally provided by Intel, and now supported by Cornelis Networks. The compute servers included 4,204 Intel Xeon Phi \"Knights Landing\" processors, and 1,736 servers with dual IntelXeon Scalable \"Sky Lake\" processors, for a total of more than 400,000 processors cores,and nearly 20 petaflops of peak performance.\r\n\n\nSince the on-time, on-budget start of production operations in mid-2017, time on Stampede 2 has been allocated quarterly via the XSEDE peer-reveiw process. More than 3,000 projects received allocations on the machine, across virtually all fields of science. Typically, requests for the machine were three to four times the available time. Throughout all four years of operation of the machine, usage has been well over 90% of full capacity, limited only by the complications of scheduling very large simulations of varying size. In the most recent year of allocations, highlights included multiple projects that improve the endurance of batteries, or reduce the need for scarce materials in constructing batteries. Other users identified target materials that would allow solar panels to be constructed without the use of lead. Catalogs of human RNA were produced for the first time through the use of computation on Stampede 2. Stampede 2 also provided computation for drug discovery and epidemiological models in response to the COVID-19 pandemic. Other users made use of Stampede 2 to forecast and respond to natural disasters, including wildfires, hurricanes, and tornadoes. Research in AI has been growing steadily on the machine.\r\n\n\nOperations also included signficant training and outreach components. There have been hundreds of thousands of visits to the online \"Virtual Workshop\" for Stampede 2 hosted by project partner Cornell University. Thousands of people have attended online or in-person training, ranging from week long courses and all day conference workshops to shorter webinars. Hundreds of students have participated in outreach events, including the summer \"Code@TACC\" week-long residential events for high school. Students participating in these events were overwhelmingly first generation college students, and tracking data shows attendees enter college in STEM fields at more than 10x the national average.\r\n\n\nStampede 2 has been reliable, accessible, and overwhelmingly impactful to countless NSF researchers.\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 02/05/2025\n\n\t\t\t\t\tSubmitted by: DanielStanzione\n"
 }
}