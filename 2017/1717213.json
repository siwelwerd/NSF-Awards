{
 "awd_id": "1717213",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: Massively Scalable Secure Computation Infrastructure Using FPGAs",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032920000",
 "po_email": "doliveir@nsf.gov",
 "po_sign_block_name": "Daniela Oliveira",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 499999.0,
 "awd_amount": 499999.0,
 "awd_min_amd_letter_date": "2017-07-21",
 "awd_max_amd_letter_date": "2017-07-21",
 "awd_abstract_narration": "The statistical analysis of behavioral data collected through clinical trials, surveys, and experimentation, has a long history in academic disciplines like medicine, sociology, and behavioral economics. The privacy risks inherent in such studies are often at odds with the tremendous societal benefits resulting from sharing data among researchers and practitioners. Mining behavioral data at scale is also a ubiquitous practice among Internet companies, giving rise to significant privacy concerns. As the potential benefits to society are enormous, harnessing this data for the better good while protecting privacy is one of the grand challenges faced by our society today. This project addresses this challenge by bringing Secure Function Evaluation (SFE) of practical, real-life data mining and machine learning algorithms into the realm of practicality, through the development of a highly parallel, efficient, scalable computation platform for secure computation operating at a massive scale. \r\n \r\nThe project develops a Massively Scalable Secure computation Infrastructure using FPGAs (MaSSIF), accelerating secure computations over a cluster of FPGAs and leveraging benefits of both hardware acceleration and multi-device parallelism. MaSSIF significantly differs from previous implementations of SFE in that it is the first to accelerate secure computation primitives: specifically, Garbled Circuits (GC) with FPGAs on such a massively parallel scale. The algorithms considered are (a) computationally intensive, (b) non-trivial to parallelize under SFE, and (c) of considerable practical importance.  MaSSIF advances the state of the art both through novel SFE algorithms, as well as in the design and optimization of accelerated, scalable systems for SFE.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Stratis",
   "pi_last_name": "Ioannidis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Stratis Ioannidis",
   "pi_email_addr": "IOANNIDIS@ECE.NEU.EDU",
   "nsf_id": "000711788",
   "pi_start_date": "2017-07-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Miriam",
   "pi_last_name": "Leeser",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Miriam E Leeser",
   "pi_email_addr": "mel@ece.neu.edu",
   "nsf_id": "000194950",
   "pi_start_date": "2017-07-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Avenue",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 499999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-b16157f8-7fff-8f12-0c86-f754318c1d51\">\n<p dir=\"ltr\"><strong>Intellectual Merit</strong></p>\n<br />\n<p dir=\"ltr\"><strong>Secure computational Infrastructure using FPGA Overlays.</strong><span> We&nbsp; implemented secure function evaluation via Yao&rsquo;s garbled circuits (GCs), using&nbsp; overlay architectures on Field Programmable Gate Arrays (FPGAs). This has several important advantages: (a) the FPGA is programmed once for all GC problems, as wiring and instantiation are determined at execution time, (b) the overhead for a new problem is very low, and (c) the same overlay can be reused to compute problems that would not fit in a single FPGA. We tackled different performance bottlenecks in overlay design w.r.t. (a) the number of FPGA overlay cells, (b) host to FPGA communication, and (c) on-chip block memory management. We showed significant speed-up, at a range from 6.21 to 45.78 times faster, over a software implementation of GCs.&nbsp;</span></p>\n<p dir=\"ltr\"><strong>Garbled Circuits in the Cloud using FPGA Enabled Nodes.</strong><span> </span><span>We designed an end-to-end implementation of garbled circuits on Amazon Web Services (AWS) that includes garbler and evaluator implemented on separate nodes. This includes an FPGA implementation of the garbler on an AWS F1 instance that shows a 15 times speedup over software implementations over a large range of sizes of examples. The end-to-end implementation of the garbler, evaluator and the communication between is 3 times faster across a range of size of examples for garbled circuits over software implementations of GCs</span></p>\n<p dir=\"ltr\"><strong>Optimizing the use of different types of memory for FPGAs in High Performance Computing.</strong><span> </span><span>&nbsp;</span><span>Next, we investigated GC execution over the Open Cloud Testbed (OCT), a platform funded by NSF,&nbsp; that uses Xilinx Alveo U280s FPGAs. The Alveo U280s have High Bandwidth Memory (HBM) which provide an opportunity of accelerating memory accesses, which were a bottleneck in our earlier designs.&nbsp; We executed the largest problems garbled to date on FPGA instances, which includes problems that are represented by over twenty six&nbsp; million gates; this represented a 7-fold increase over the size of circuits we could handle before.&nbsp; We also conducted several studies of (a) how different sizes of Block and Ultra Random Access Memory (BRAM and URAM) used in conjunction with HBM change the clock speed of applications, (b) the overall latency for GC executions and how it changes as different types of memory are used and size of the data scales, and (c) provided an analytical approach that predicts the drop in clock speed for an application based on its memory layout.&nbsp;</span></p>\n<p dir=\"ltr\"><strong>Partitioning Garbled Circuits Across Network-Connected FPGAs with High Bandwidth Memory.</strong><span> Finally, we mapped garbled circuits to a network-connected cloud platform of multiple FPGAs. Our use of overlays enables GCs to be mapped to FPGAs that directly communicate with each other through the network, circumventing the hosts on which they are mounted, thereby increasing communication efficiency.&nbsp; We developed different memory allocation policies to efficiently take advantage of different levels of memory hierarchy in this setting, and proposed algorithms for efficiently partitioning the workload and minimizing the communication between FPGAs. We demonstrated that garbled circuits can achieve nearly perfect parallelization by our methods in a cloud computing environment with two FPGAs. This distributed system makes it possible for our FPGA platform to run, and parallelize, large examples that cannot fit into a single FPGA.&nbsp;</span></p>\n<p dir=\"ltr\"><strong>Broader Impacts&nbsp;</strong></p>\n<p dir=\"ltr\"><span>The project resulted in training three PhD students, two of which have graduated and have continued their successful careers in the industry. It also resulted in six journal and conference publications acknowledging the support from the project that appeared in top peer reviewed venues. Additional dissemination efforts included invited seminars and keynotes at academic institutions and companies in the US, the UK, and Ireland.&nbsp; The designs make use of the NSF funded Open Cloud Testbed, and examples of our code will be made available.&nbsp;&nbsp;</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/17/2022<br>\n\t\t\t\t\tModified by: Stratis&nbsp;Ioannidis</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nIntellectual Merit\n\n\nSecure computational Infrastructure using FPGA Overlays. We  implemented secure function evaluation via Yao\u2019s garbled circuits (GCs), using  overlay architectures on Field Programmable Gate Arrays (FPGAs). This has several important advantages: (a) the FPGA is programmed once for all GC problems, as wiring and instantiation are determined at execution time, (b) the overhead for a new problem is very low, and (c) the same overlay can be reused to compute problems that would not fit in a single FPGA. We tackled different performance bottlenecks in overlay design w.r.t. (a) the number of FPGA overlay cells, (b) host to FPGA communication, and (c) on-chip block memory management. We showed significant speed-up, at a range from 6.21 to 45.78 times faster, over a software implementation of GCs. \nGarbled Circuits in the Cloud using FPGA Enabled Nodes. We designed an end-to-end implementation of garbled circuits on Amazon Web Services (AWS) that includes garbler and evaluator implemented on separate nodes. This includes an FPGA implementation of the garbler on an AWS F1 instance that shows a 15 times speedup over software implementations over a large range of sizes of examples. The end-to-end implementation of the garbler, evaluator and the communication between is 3 times faster across a range of size of examples for garbled circuits over software implementations of GCs\nOptimizing the use of different types of memory for FPGAs in High Performance Computing.  Next, we investigated GC execution over the Open Cloud Testbed (OCT), a platform funded by NSF,  that uses Xilinx Alveo U280s FPGAs. The Alveo U280s have High Bandwidth Memory (HBM) which provide an opportunity of accelerating memory accesses, which were a bottleneck in our earlier designs.  We executed the largest problems garbled to date on FPGA instances, which includes problems that are represented by over twenty six  million gates; this represented a 7-fold increase over the size of circuits we could handle before.  We also conducted several studies of (a) how different sizes of Block and Ultra Random Access Memory (BRAM and URAM) used in conjunction with HBM change the clock speed of applications, (b) the overall latency for GC executions and how it changes as different types of memory are used and size of the data scales, and (c) provided an analytical approach that predicts the drop in clock speed for an application based on its memory layout. \nPartitioning Garbled Circuits Across Network-Connected FPGAs with High Bandwidth Memory. Finally, we mapped garbled circuits to a network-connected cloud platform of multiple FPGAs. Our use of overlays enables GCs to be mapped to FPGAs that directly communicate with each other through the network, circumventing the hosts on which they are mounted, thereby increasing communication efficiency.  We developed different memory allocation policies to efficiently take advantage of different levels of memory hierarchy in this setting, and proposed algorithms for efficiently partitioning the workload and minimizing the communication between FPGAs. We demonstrated that garbled circuits can achieve nearly perfect parallelization by our methods in a cloud computing environment with two FPGAs. This distributed system makes it possible for our FPGA platform to run, and parallelize, large examples that cannot fit into a single FPGA. \nBroader Impacts \nThe project resulted in training three PhD students, two of which have graduated and have continued their successful careers in the industry. It also resulted in six journal and conference publications acknowledging the support from the project that appeared in top peer reviewed venues. Additional dissemination efforts included invited seminars and keynotes at academic institutions and companies in the US, the UK, and Ireland.  The designs make use of the NSF funded Open Cloud Testbed, and examples of our code will be made available.  \n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 12/17/2022\n\n\t\t\t\t\tSubmitted by: Stratis Ioannidis"
 }
}