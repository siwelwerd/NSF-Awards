{
 "awd_id": "1718901",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NeTS: Small: Learning-Guided Network Resource Allocation: A Closed-Loop Approach",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927855",
 "po_email": "aabouzei@nsf.gov",
 "po_sign_block_name": "Alhussein Abouzeid",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 479000.0,
 "awd_amount": 479000.0,
 "awd_min_amd_letter_date": "2017-07-11",
 "awd_max_amd_letter_date": "2018-09-06",
 "awd_abstract_narration": "Based on network measurement and user behavior data, much recent work has studied the modeling and prediction of network utility and user experience using machine learning techniques. While it provides important insights, prediction itself is often not the ultimate goal in networks. Ideally, a network could identify users with poor experience and take proper actions to proactively improve the overall performance. To achieve this goal, the project advocates a closed-loop approach that uses learning-aided utility model to explicitly guide resource allocation in networks and uses feedback to (in)validate and improve the learned utility model. This investigation provides important insights in understanding, designing, and analyzing learning-model-aided resource optimization algorithms. Furthermore, because of its generality, this closed-loop approach can be applied in other systems with the following characteristics: 1) the system is too complex to rely on domain knowledge only to build a white-box utility model; 2) there exists sufficient data so that a utility model can be learned; 3) to maximize the overall utility, one can optimize over certain control variables that affect the utility value; and 4) there exists a feedback loop so that the effect of the control can be observed. The outcome of the project can be applied to such systems in different disciplines. \r\n\r\nUtilizing this proposed framework is highly challenging due to the unknown and noisy nature of the network utility function, and in the context of high dimensionality, coupled resource constraints, and non-convex optimization. To address these challenges, the project considers two complementary approaches: a greedy approach and an integrated approach. The greedy approach has much flexibility in applying diverse learning models, which may fit different application scenarios better in practice, but is difficult to analyze. The integrated approach builds upon Gaussian Process (GP) bandits that integrate both the constructed model and model uncertainty in resource allocation decisions. This approach is more amenable to theoretical analysis, although highly challenging. In both approaches, one needs to optimally allocate resource based on the learned models. The contribution of the project comes from solving the corresponding non-convex optimization problems. The last step is to use the closed-loop feedback to build a better or optimal utility model. The integrated approach aims to develop hierarchical GP bandit algorithms for dimensionality reduction, ideally with theoretical performance guarantees. The greedy approach leverages perturbed-exploration schemes for general learning models and strives for practicality and generality.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xin",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xin Liu",
   "pi_email_addr": "liu@cs.ucdavis.edu",
   "nsf_id": "000289050",
   "pi_start_date": "2017-07-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Huasen",
   "pi_last_name": "Wu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Huasen Wu",
   "pi_email_addr": "hswu@ucdavis.edu",
   "nsf_id": "000737394",
   "pi_start_date": "2017-07-11",
   "pi_end_date": "2018-09-06"
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Davis",
  "perf_str_addr": "1850 Research Park Dr., Ste 300",
  "perf_city_name": "Davis",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956186153",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 479000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"Default\">&nbsp;</p>\n<p>Based on network measurement and user behavior data, much recent work has studied the modeling and prediction of network utility and user experience using machine learning techniques. While it provides important insights, prediction itself is often not the ultimate goal in networks. Ideally, a network could identify users with poor experience and take proper actions to proactively improve the overall performance.</p>\n<p>&nbsp;</p>\n<p>To achieve this goal, the project advocates a learning-based approach that uses learned utility functions to guide resource allocation and management in networks. Utilizing this proposed framework is highly challenging due to the unknown and noisy nature of the network utility function, and in the context of high dimensionality, limited exploration constraints, and non-convex optimization. To address these challenges, we have adopted and developed techniques from convex and nonconvex optimizations, multi-armed bandits, reinforcement learning algorithms, as well as heuristic algorithms. We have conducted both theoretical analysis and empirical evaluations on the proposed schemes. Specifically, we have the following outcomes.</p>\n<p>&nbsp;</p>\n<p>Cellular network configuration plays a critical role in network performance. In current practice, network configuration depends heavily on field experience of engineers and often remains static for a long period of time. This practice is far from optimal. To address this limitation, online-learning-based approaches have great potentials to automate and optimize network configuration.&nbsp; However, three major challenges facing learning-based approaches are: 1) learning a highly complex function for each base station; 2) the network has highly limited budget for exploration, and thus imposes significant difficulties in balancing the fundamental exploration-exploitation tradeoff; and 3) the configuration of one cell can interfere the performance of neighboring cells and thus results in complex interactions. To address this challenge, we have developed multiple approaches: 1) a joint-optimization approach based on learned utility functions; 2) kernel-based multi-BS contextual bandit algorithm based on multi-task learning. And 3) propose a collaborative learning approach to leverage data from different cells to boost the learning efficiency and to improve network performance. We evaluate our proposed algorithm via a simulator constructed using real network data and demonstrates faster convergence compared to baselines. More importantly, a live field test is also conducted on a real metropolitan cellular network consisting 1700+ cells to optimize 5 parameters for 2 weeks. Our proposed algorithm shows a significant performance improvement of 20%.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>Motivated by the study of learning algorithms in cellular network configuration, we propose opportunistic contextual bandits - a special case of contextual bandits where the exploration cost varies under different environmental conditions, such as network load variation. When the exploration cost is low, so is the actual regret of pulling a sub-optimal arm (e.g., trying a suboptimal configuration). Therefore, intuitively, we could explore more when the exploration cost is relatively low and exploit more when the exploration cost is relatively high. Inspired by this intuition, for opportunistic contextual bandits with linear payoffs, we propose an Adaptive Upper-Confidence-Bound algorithm (AdaLinUCB) to adaptively balance the exploration-exploitation trade-off for opportunistic learning. We show the superiority of the proposed algorithm theoretically and empirically.</p>\n<p>&nbsp;</p>\n<p>As mobile networks proliferate, we are experiencing a strong diversification of services, which requires greater flexibility from the existing network. Network slicing is proposed as a promising solution for resource utilization in 5G and future networks to address this dire need. In network slicing, dynamic resource orchestration and network slice management are crucial for maximizing resource utilization. Unfortunately, this process is too complex for traditional approaches to be effective due to a lack of accurate models and dynamic hidden structures. We formulate the problem as a Constrained Markov Decision Process (CMDP) without knowing models and hidden structures. Additionally, we propose to solve the problem using CLARA, a Constrained reinforcement LeArning based Resource Allocation algorithm. In particular, we analyze cumulative and instantaneous constraints using adaptive interior-point policy optimization and projection layer, respectively. Evaluations show that CLARA clearly outperforms baselines in resource allocation with service demand guarantees. Motivated by this need, we have also developed constrained reinforcement learning algorithms that is generally applicable to other applications.</p>\n<p>&nbsp;</p>\n<p>Broader Impact:</p>\n<p>&nbsp;</p>\n<p>The PI or her students had presented the work at the multiple international conferences, both in networking field and in machine learning field. Such efforts broaden the participation and interaction between the networking and machine learning community.&nbsp; The PI presented the results to collaborators in academia and industry,&nbsp; including AT&amp;T, Verizon, Intel, and Target, which enhances the interaction between academia and industry.</p>\n<p>This project enabled partially the training of two postdoc researchers, five PhD students, and six undergraduate students. The PI has made a significant effort to recruit and train underrepresented minority students, including five female students and one black student. These trainees have developed important technical skills, communication skills, collaboration skills, and leadership skills. One trainee has joined the academia as a faculty member. &nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/18/2021<br>\n\t\t\t\t\tModified by: Xin&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nBased on network measurement and user behavior data, much recent work has studied the modeling and prediction of network utility and user experience using machine learning techniques. While it provides important insights, prediction itself is often not the ultimate goal in networks. Ideally, a network could identify users with poor experience and take proper actions to proactively improve the overall performance.\n\n \n\nTo achieve this goal, the project advocates a learning-based approach that uses learned utility functions to guide resource allocation and management in networks. Utilizing this proposed framework is highly challenging due to the unknown and noisy nature of the network utility function, and in the context of high dimensionality, limited exploration constraints, and non-convex optimization. To address these challenges, we have adopted and developed techniques from convex and nonconvex optimizations, multi-armed bandits, reinforcement learning algorithms, as well as heuristic algorithms. We have conducted both theoretical analysis and empirical evaluations on the proposed schemes. Specifically, we have the following outcomes.\n\n \n\nCellular network configuration plays a critical role in network performance. In current practice, network configuration depends heavily on field experience of engineers and often remains static for a long period of time. This practice is far from optimal. To address this limitation, online-learning-based approaches have great potentials to automate and optimize network configuration.  However, three major challenges facing learning-based approaches are: 1) learning a highly complex function for each base station; 2) the network has highly limited budget for exploration, and thus imposes significant difficulties in balancing the fundamental exploration-exploitation tradeoff; and 3) the configuration of one cell can interfere the performance of neighboring cells and thus results in complex interactions. To address this challenge, we have developed multiple approaches: 1) a joint-optimization approach based on learned utility functions; 2) kernel-based multi-BS contextual bandit algorithm based on multi-task learning. And 3) propose a collaborative learning approach to leverage data from different cells to boost the learning efficiency and to improve network performance. We evaluate our proposed algorithm via a simulator constructed using real network data and demonstrates faster convergence compared to baselines. More importantly, a live field test is also conducted on a real metropolitan cellular network consisting 1700+ cells to optimize 5 parameters for 2 weeks. Our proposed algorithm shows a significant performance improvement of 20%.\n\n \n\n \n\nMotivated by the study of learning algorithms in cellular network configuration, we propose opportunistic contextual bandits - a special case of contextual bandits where the exploration cost varies under different environmental conditions, such as network load variation. When the exploration cost is low, so is the actual regret of pulling a sub-optimal arm (e.g., trying a suboptimal configuration). Therefore, intuitively, we could explore more when the exploration cost is relatively low and exploit more when the exploration cost is relatively high. Inspired by this intuition, for opportunistic contextual bandits with linear payoffs, we propose an Adaptive Upper-Confidence-Bound algorithm (AdaLinUCB) to adaptively balance the exploration-exploitation trade-off for opportunistic learning. We show the superiority of the proposed algorithm theoretically and empirically.\n\n \n\nAs mobile networks proliferate, we are experiencing a strong diversification of services, which requires greater flexibility from the existing network. Network slicing is proposed as a promising solution for resource utilization in 5G and future networks to address this dire need. In network slicing, dynamic resource orchestration and network slice management are crucial for maximizing resource utilization. Unfortunately, this process is too complex for traditional approaches to be effective due to a lack of accurate models and dynamic hidden structures. We formulate the problem as a Constrained Markov Decision Process (CMDP) without knowing models and hidden structures. Additionally, we propose to solve the problem using CLARA, a Constrained reinforcement LeArning based Resource Allocation algorithm. In particular, we analyze cumulative and instantaneous constraints using adaptive interior-point policy optimization and projection layer, respectively. Evaluations show that CLARA clearly outperforms baselines in resource allocation with service demand guarantees. Motivated by this need, we have also developed constrained reinforcement learning algorithms that is generally applicable to other applications.\n\n \n\nBroader Impact:\n\n \n\nThe PI or her students had presented the work at the multiple international conferences, both in networking field and in machine learning field. Such efforts broaden the participation and interaction between the networking and machine learning community.  The PI presented the results to collaborators in academia and industry,  including AT&amp;T, Verizon, Intel, and Target, which enhances the interaction between academia and industry.\n\nThis project enabled partially the training of two postdoc researchers, five PhD students, and six undergraduate students. The PI has made a significant effort to recruit and train underrepresented minority students, including five female students and one black student. These trainees have developed important technical skills, communication skills, collaboration skills, and leadership skills. One trainee has joined the academia as a faculty member.  \n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/18/2021\n\n\t\t\t\t\tSubmitted by: Xin Liu"
 }
}