{
 "awd_id": "1716609",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Efficient Learning and Inference with Perturbations",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 272979.0,
 "awd_amount": 272979.0,
 "awd_min_amd_letter_date": "2017-08-17",
 "awd_max_amd_letter_date": "2017-08-17",
 "awd_abstract_narration": "Learning and inference drives much of the research in many diverse domains, such as natural language processing, computer vision, speech processing and computational biology. In these fields, complex models are required in order to better represent real-world objects (e.g., sentences, images, speech, proteins). As such, one aims to obtain more representational power by expressing objects as the interaction of a large number of constituent elements. While producing more realistic models, this also increases the computational cost of inferring such objects, as well as of learning such inference models from data. The situation worsens as real-world objects become large scale, which opens the opportunity to investigate the use of randomized algorithms to make learning and inference more computationally efficient. This project will also provide education and outreach opportunities through a Hands-on Learning Theory course, undergraduate involvement in research and workshops at major conferences on the topic of learning and inference.\r\n\r\nThe goal of this project is to develop novel randomized polynomial-time algorithms for learning and inference in large-scale structured prediction problems. The project aims to analyze maximum margin models, maximum a-posteriori perturbation models, latent variable models, and the relationship between regularization and different notions of perturbation. The project makes use of theoretical methods for creating new algorithms with practical advantages over current methods. The project aims to produce algorithms that work in polynomial-time, use a small sufficient and necessary number of training samples, and have a guarantee of small generalization error. All the software produced in this project will be open-sourced, and made available for download.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jean",
   "pi_last_name": "Honorio",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jean Honorio",
   "pi_email_addr": "jhonorio@purdue.edu",
   "nsf_id": "000728563",
   "pi_start_date": "2017-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "305 N University Street",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072107",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 272979.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Learning and inference drives much of the research in several domains (e.g., natural language processing, computer vision, computational biology) where complex models represent real-world objects (e.g., sentences, images, proteins). In several application areas, one aims to obtain more representational power by expressing objects as the interaction of a large number of constituent elements. While producing more realistic models, this also increases the computational and statistical cost of learning and inference.</p>\n<p>The current project studied the theoretical foundations of large-scale structured prediction, from the viewpoint of computational and statistical efficiency. The project results include several algorithms with provable efficiency guarantees. We provided a method for exact inference and studied the technical conditions for its success. We created algorithms for learning and inference with latent variables. We proposed a method for learning maximum-a-posteriori perturbation models. Finally, we studied the information-theoretic limits of learning. In total, the project produced eight manuscripts (five of them accepted to top conferences thus far.)</p>\n<p>Besides supporting graduate students, the project also provided education and outreach opportunities through the involvement of undergraduate students in research (working on some applications of the theoretical results) and a Hands-On Learning Theory course (a highly-selective course that mixes lectures, seminars and research.)</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/11/2020<br>\n\t\t\t\t\tModified by: Jean&nbsp;F&nbsp;Honorio</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nLearning and inference drives much of the research in several domains (e.g., natural language processing, computer vision, computational biology) where complex models represent real-world objects (e.g., sentences, images, proteins). In several application areas, one aims to obtain more representational power by expressing objects as the interaction of a large number of constituent elements. While producing more realistic models, this also increases the computational and statistical cost of learning and inference.\n\nThe current project studied the theoretical foundations of large-scale structured prediction, from the viewpoint of computational and statistical efficiency. The project results include several algorithms with provable efficiency guarantees. We provided a method for exact inference and studied the technical conditions for its success. We created algorithms for learning and inference with latent variables. We proposed a method for learning maximum-a-posteriori perturbation models. Finally, we studied the information-theoretic limits of learning. In total, the project produced eight manuscripts (five of them accepted to top conferences thus far.)\n\nBesides supporting graduate students, the project also provided education and outreach opportunities through the involvement of undergraduate students in research (working on some applications of the theoretical results) and a Hands-On Learning Theory course (a highly-selective course that mixes lectures, seminars and research.)\n\n\t\t\t\t\tLast Modified: 12/11/2020\n\n\t\t\t\t\tSubmitted by: Jean F Honorio"
 }
}