{
 "awd_id": "1719205",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF:Small:Collaborative Research:Distributed Fog Computing for Non-Convex Big-Data Analytics",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 270000.0,
 "awd_amount": 270000.0,
 "awd_min_amd_letter_date": "2017-06-28",
 "awd_max_amd_letter_date": "2017-06-28",
 "awd_abstract_narration": "In our data-deluge era, massive chunks of information, perpetually collected by pervasive sensors, are communicated and processed by distributed computational architectures. To address emergent big-data computational issues, this project embarks on an ambitious multidisciplinary research effort that aims at advancing the state-of-the-art in-network/distributed big-data processing via a general algorithmic framework for data analytics over massively distributed data sets. The proposed algorithmic framework enables fully distributed and parallel big-data analytics, for a variety of heterogeneous data sets over a wide range of computational architectures. The developed research directions are beneficial also to domains far beyond big-data analytics, such as signal processing, machine learning, next-generation wireless communications, smart-city and smart-grid networks. Research results are distributed through archival publications, courses, undergraduate research opportunities, tutorials and conference presentations.\r\n\r\nThe developed scheme relies on a novel convexification/decomposition technique which accommodates a rich class of non-convex, unstructured and stochastic optimization tasks with non-separable objective functions. Algorithms are designed for settings where data are distributed across a large number of multi-core computational nodes, within a network of arbitrary topology with (possibly) time-varying and even random links. This new class of algorithms addresses shortcomings of current (non-parallel and non-distributed) convexification techniques via (i) full control of the degree of parallelism and distribution of the computation/signaling among processors/network nodes, and (ii) by offering a plethora of convex approximants, regularization terms, step-size rules, and communication protocols. Designed for time-varying or even random network topologies, the advocated framework demonstrates also another desirable attribute for distributed computations: resiliency to (random) network failures.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gesualdo",
   "pi_last_name": "Scutari",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gesualdo Scutari",
   "pi_email_addr": "gscutari@purdue.edu",
   "nsf_id": "000610482",
   "pi_start_date": "2017-06-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "315 North Grant Street",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072023",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 270000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project has &nbsp;devised a general algorithmic framework and fog-computing architecture enabling (matrix or tensor-based) non-convex&nbsp; streaming analytics using parallel processors&nbsp; and distributed in-network processing . The crux of the proposed algorithmic design is a novel convexification-decomposition technique&nbsp; for a general class of non-convex unstructured&nbsp; (possibly stochastic ) problems with non-separable&nbsp; objective functions and constraints, coupled with a novel tracking mechanism&nbsp; which aims at dynamically estimating the missing global information from local one. This new class of algorithms addresses the shortcomings of current (non-parallel and non-distributed) convex approximation techniques by enabling full control of the degree of parallelism and distribution of the computation/signaling among processors/network nodes, as well as offering a more flexible selection of convex approximants, regularization terms, step-size schedules and communication protocols. Of particualr interest is the use of surrogate functions beyond linearization (like those yielding gradient methods), which permit exploiting curvature information of the objective functions and data similarity to boost the convergence rate, resulting in the fastest distributed algorithm to the date.&nbsp;</span></p>\n<p><span>The results obtained in the project have demonstrated the flexibility of the developed&nbsp;</span><span> convexification-decomposition </span><span>technique to solve problems as diverse as&nbsp;&nbsp;network information processing, telecommunications, multi-agent control, and machine learning. In particular, it is a key enabler of many emerging nonconvex ``big data'' analytic tasks, including nonlinear least squares, principal/canonical component analysis, low-rank approximation, and matrix completion, just to name a few. In most of the above scenarios, data processing and optimization need to be performed in a distributed but collaborative manner by the agents within the network. For instance, this is the case in data-intensive (e.g., sensor-network) applications wherein the sheer volume and spatial/temporal disparity of scattered data render centralized processing and storage infeasible or inefficient.&nbsp;The </span><span>convexification-decomposition&nbsp;</span><span> framework developed in the project &nbsp;offers new tools to attack nonconvex optimization problems with nonconvex constraints, in asynchronous modus operandi. The framework led to a software package available to the scientific community.</span></p>\n<p><span>Computation-intensive mobile applications are expected to have a transformative impact on society, enabling applications such as collaborative mobile sensing, augmented reality, autonomous navigation, and other AI-related applicaitons. &nbsp;The innovative proposed computational architectures and design are expected to enable the cloud expansion to the network edge, hence i) empowering 5G networks to provide support, at a low operating cost, of multiple services and environments; and ii) embracing the integration of diverse technologies, such as LTE, ?Internet of Things?, Software Defined Radio and Cloud Computing, in a user-transparent,app-oriented, ubiquitous and efficient fashion.</span></p>\n<p><span>One&nbsp; Ph.D. student has graduated under this project and one post-doc has been partially supported (now she is an assistant professor in USA).&nbsp; Undergraduate students have been involved in &nbsp;the&nbsp; implementation of some of the proposed optimization algorithms, motivating them to pursue careers in the IT industry or to continue&nbsp; research own Machine Learning in graduate school. One of the paper, outcome of this project, was awarded by&nbsp; the prestigious 2020 IEEE &nbsp; Signal Processing Society Best Paper Award.&nbsp;&nbsp;</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/10/2022<br>\n\t\t\t\t\tModified by: Gesualdo&nbsp;Scutari</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project has  devised a general algorithmic framework and fog-computing architecture enabling (matrix or tensor-based) non-convex  streaming analytics using parallel processors  and distributed in-network processing . The crux of the proposed algorithmic design is a novel convexification-decomposition technique  for a general class of non-convex unstructured  (possibly stochastic ) problems with non-separable  objective functions and constraints, coupled with a novel tracking mechanism  which aims at dynamically estimating the missing global information from local one. This new class of algorithms addresses the shortcomings of current (non-parallel and non-distributed) convex approximation techniques by enabling full control of the degree of parallelism and distribution of the computation/signaling among processors/network nodes, as well as offering a more flexible selection of convex approximants, regularization terms, step-size schedules and communication protocols. Of particualr interest is the use of surrogate functions beyond linearization (like those yielding gradient methods), which permit exploiting curvature information of the objective functions and data similarity to boost the convergence rate, resulting in the fastest distributed algorithm to the date. \n\nThe results obtained in the project have demonstrated the flexibility of the developed  convexification-decomposition technique to solve problems as diverse as  network information processing, telecommunications, multi-agent control, and machine learning. In particular, it is a key enabler of many emerging nonconvex ``big data'' analytic tasks, including nonlinear least squares, principal/canonical component analysis, low-rank approximation, and matrix completion, just to name a few. In most of the above scenarios, data processing and optimization need to be performed in a distributed but collaborative manner by the agents within the network. For instance, this is the case in data-intensive (e.g., sensor-network) applications wherein the sheer volume and spatial/temporal disparity of scattered data render centralized processing and storage infeasible or inefficient. The convexification-decomposition  framework developed in the project  offers new tools to attack nonconvex optimization problems with nonconvex constraints, in asynchronous modus operandi. The framework led to a software package available to the scientific community.\n\nComputation-intensive mobile applications are expected to have a transformative impact on society, enabling applications such as collaborative mobile sensing, augmented reality, autonomous navigation, and other AI-related applicaitons.  The innovative proposed computational architectures and design are expected to enable the cloud expansion to the network edge, hence i) empowering 5G networks to provide support, at a low operating cost, of multiple services and environments; and ii) embracing the integration of diverse technologies, such as LTE, ?Internet of Things?, Software Defined Radio and Cloud Computing, in a user-transparent,app-oriented, ubiquitous and efficient fashion.\n\nOne  Ph.D. student has graduated under this project and one post-doc has been partially supported (now she is an assistant professor in USA).  Undergraduate students have been involved in  the  implementation of some of the proposed optimization algorithms, motivating them to pursue careers in the IT industry or to continue  research own Machine Learning in graduate school. One of the paper, outcome of this project, was awarded by  the prestigious 2020 IEEE   Signal Processing Society Best Paper Award.  \n\n \n\n\t\t\t\t\tLast Modified: 07/10/2022\n\n\t\t\t\t\tSubmitted by: Gesualdo Scutari"
 }
}