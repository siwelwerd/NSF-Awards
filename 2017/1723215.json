{
 "awd_id": "1723215",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF: Large: Collaborative Research: Exploiting the Naturalness of Software",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 260709.0,
 "awd_amount": 247375.0,
 "awd_min_amd_letter_date": "2017-01-09",
 "awd_max_amd_letter_date": "2021-04-26",
 "awd_abstract_narration": "This inter-disciplinary project has its roots in Natural Language (NL) processing. Languages such as English allow intricate, lovely and complex constructions; yet, everyday, ``natural? speech and writing is simple, prosaic, and repetitive, and thus amenable to statistical modeling. Once large NL corpora became available, computational muscle and algorithmic insight led to rapid advances in the statistical modeling of natural utterances, and revolutionized tasks such as translation, speech recognition, text summarization, etc.  While programming languages, like NL, are flexible and powerful, in theory allowing a great variety of complex programs to be written, we find that ``natural? programs that people actually write are regular, repetitive and predictable. This project will use statistical models to capture and exploit this regularity to create a new generation of software engineering tools to achieve transformative improvements in software quality and productivity. \r\n \r\nThe project will exploit language modeling techniques to capture the regularity in natural programs at the lexical, syntactic, and semantic levels. Statistical modeling will also be used to capture alignment regularities in ``bilingual? corpora such as code with comments, or explanatory text (e.g., Stackoverflow) and in systems developed on two platforms such as Java and C#.  These statistical models will help drive novel, data-driven approaches for applications such as code suggestion and completion, and assistive devices for programmers with movement or visual challenges. These models will also be exploited to correct simple errors in programs. Models of bilingual data will used to build code summarization and code retrieval tools, as well as tools for porting across platforms. Finally, this project will create a large, curated corpus of  software, and code analysis products, as well as a corpus of alignments within software bilingual corpora, to help create and nurture a research community in this area.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tien",
   "pi_last_name": "Nguyen",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Tien N Nguyen",
   "pi_email_addr": "nguyen.n.tien@gmail.com",
   "nsf_id": "000340493",
   "pi_start_date": "2017-01-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Dallas",
  "inst_street_address": "800 WEST CAMPBELL RD.",
  "inst_street_address_2": "SP2.25",
  "inst_city_name": "RICHARDSON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9728832313",
  "inst_zip_code": "750803021",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "TX24",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT DALLAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "EJCVPNN1WFS5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Dallas",
  "perf_str_addr": "800 W. Campbell Rd.",
  "perf_city_name": "Richardson",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "750803021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "TX24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 184525.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 62849.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we have successfully achieved the three major goals.</p>\n<p><span>Traditionally, a language model is aimed to process natural-language texts. For this project, we have intergrated the structure, and semantic information from source code into the new types of language models for source code. The first model, SLAMC, i</span>ncorporates semantic information into code tokens and models the regularities/patterns of such semantic annotations, called sememes, rather than their lexemes. The second one is GRALAN, a graph-based language model.&nbsp;<span>GraLan can learn from a source code corpus and compute the appearance probabilities of any graphs given the observed (sub)graphs. It takes into account the program dependencies to support semantic language models. The third one is Dnn4C, a deep learning-based language model that complements the local context of lexical code elements with both syntactic and type contexts. We designed a context-incorporating method to use with syntactic and type annotations for source code in order to learn to distinguish the lexical tokens in different syntactic and type contexts.</span></p>\n<p>We have also advanced the state-of-the-art code completion in two directions. First, we present a novel API recommendation approach that taps into the predictive power of repetitive code changes to provide relevant API recommendations for developers. Our approach and tool,APIREC, is based on statistical learning from fine-grained code changes and from the context in which those changes were made. Second,&nbsp;we introduce AUTOSC, which combines program analysis and the principle of software naturalness to fill in a partially completed statement. AUTOSC benefits from the strengths of both directions, in which the completed code statement is both frequent and valid.&nbsp;</p>\n<p>We have also advanced the state-of-the-art code migration with statistical modeling. We introduce mppSMT, a divide-and-conquer technique with novel training and migration algorithms using phrase-based SMT in three phases.&nbsp;Such divide-and-conquer and syntax-direction strategies enable phrase-based SMT to adapt well to syntactical structures in source code, thus, improving migration accuracy.</p>\n<p>The research results in this project have enhanced the infrastructure for teaching/research via tools and data sets for use by students and practitioners, and for enhancement by researchers. We provide related learning modules for educators as well. We include outreach activities for undergraduate students, underrepresented groups, minorities, and women in science.&nbsp;Our validation and evaluation involve students and professionals, promoting teaching, training, and learning of both program analysis and machine learning techniques that have wide impacts in industry and academic communities.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/10/2022<br>\n\t\t\t\t\tModified by: Tien&nbsp;N&nbsp;Nguyen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this project, we have successfully achieved the three major goals.\n\nTraditionally, a language model is aimed to process natural-language texts. For this project, we have intergrated the structure, and semantic information from source code into the new types of language models for source code. The first model, SLAMC, incorporates semantic information into code tokens and models the regularities/patterns of such semantic annotations, called sememes, rather than their lexemes. The second one is GRALAN, a graph-based language model. GraLan can learn from a source code corpus and compute the appearance probabilities of any graphs given the observed (sub)graphs. It takes into account the program dependencies to support semantic language models. The third one is Dnn4C, a deep learning-based language model that complements the local context of lexical code elements with both syntactic and type contexts. We designed a context-incorporating method to use with syntactic and type annotations for source code in order to learn to distinguish the lexical tokens in different syntactic and type contexts.\n\nWe have also advanced the state-of-the-art code completion in two directions. First, we present a novel API recommendation approach that taps into the predictive power of repetitive code changes to provide relevant API recommendations for developers. Our approach and tool,APIREC, is based on statistical learning from fine-grained code changes and from the context in which those changes were made. Second, we introduce AUTOSC, which combines program analysis and the principle of software naturalness to fill in a partially completed statement. AUTOSC benefits from the strengths of both directions, in which the completed code statement is both frequent and valid. \n\nWe have also advanced the state-of-the-art code migration with statistical modeling. We introduce mppSMT, a divide-and-conquer technique with novel training and migration algorithms using phrase-based SMT in three phases. Such divide-and-conquer and syntax-direction strategies enable phrase-based SMT to adapt well to syntactical structures in source code, thus, improving migration accuracy.\n\nThe research results in this project have enhanced the infrastructure for teaching/research via tools and data sets for use by students and practitioners, and for enhancement by researchers. We provide related learning modules for educators as well. We include outreach activities for undergraduate students, underrepresented groups, minorities, and women in science. Our validation and evaluation involve students and professionals, promoting teaching, training, and learning of both program analysis and machine learning techniques that have wide impacts in industry and academic communities.\n\n \n\n\t\t\t\t\tLast Modified: 11/10/2022\n\n\t\t\t\t\tSubmitted by: Tien N Nguyen"
 }
}