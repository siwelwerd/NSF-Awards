{
 "awd_id": "1651100",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "What You See Is What You Feel: Sign Language Phonology in a ProTactile World",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927920",
 "po_email": "jvaldesk@nsf.gov",
 "po_sign_block_name": "Jorge Valdes Kroff",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 549277.0,
 "awd_amount": 549277.0,
 "awd_min_amd_letter_date": "2017-09-14",
 "awd_max_amd_letter_date": "2017-09-14",
 "awd_abstract_narration": "Language permeates human existence; it mediates our interactions, influences our patterns of thought, frames our experiences, and is a key mechanism for transmitting knowledge to one another and from generation to generation. Despite the clear and far-reaching significance of language, there are still many things we do not understand about its nature, about how it emerges, and about how it develops. Since the early 1960s, signed languages have offered a new lens for viewing the core properties of language. As a result of this work, linguists have increasingly come to see language as an abstract cognitive system, which can be expressed and perceived through a visual-gestural channel just as it can be expressed and perceived through an oral-aural channel. This insight helps us understand one of the most powerful characteristics of language: its unique flexibility, which allows it to be adapted to different circumstances, populations, and conditions of transmission.\r\n\r\nThis research builds on the past sixty years of sign language research by examining a restructuring of language as it is transferred from a visual-gestural modality to a tactile-proprioceptive modality. The investigators are conducting this research in&#8232;a historically unprecedented moment, when, for the first time, a large, socially organized &#8232;and politically engaged network of DeafBlind language-users are communicating directly with&#8232;one another via reciprocal, tactile and proprioceptive channels. DeafBlind people refer to these communication practices as \"protactile\" (PT). In preliminary research, it has been observed that PT communication practices seem to be leading to systematic changes in the phonological structure of protactile-ASL. In order to analyze these changes, the investigators have developed hypotheses, which will be tested over a five-year period among three groups: PT DeafBlind signers, non-PT DeafBlind signers, and non-PT Deaf signers. Comparing these groups will allow emergent phonological patterns to be distinguished from on-the-fly compensation for sensory loss. The emergence and development of protactile-ASL offers a unique opportunity to understand how human language can be adapted to radically different conditions of transmission and interaction.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Terra",
   "pi_last_name": "Edwards",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Terra Edwards",
   "pi_email_addr": "terraedwards@uchicago.edu",
   "nsf_id": "000655910",
   "pi_start_date": "2017-09-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Diane",
   "pi_last_name": "Brentari",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Diane Brentari",
   "pi_email_addr": "dbrentari@uchicago.edu",
   "nsf_id": "000211416",
   "pi_start_date": "2017-09-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Saint Louis University",
  "inst_street_address": "221 N GRAND BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "SAINT LOUIS",
  "inst_state_code": "MO",
  "inst_state_name": "Missouri",
  "inst_phone_num": "3149773925",
  "inst_zip_code": "631032006",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MO01",
  "org_lgl_bus_name": "SAINT LOUIS UNIVERSITY",
  "org_prnt_uei_num": "JNBLLTBTLLD8",
  "org_uei_num": "JNBLLTBTLLD8"
 },
 "perf_inst": {
  "perf_inst_name": "Saint Louis University",
  "perf_str_addr": "3750 Lindell Blvd.",
  "perf_city_name": "St. Louis",
  "perf_st_code": "MO",
  "perf_st_name": "Missouri",
  "perf_zip_code": "631084006",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "MO01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 549277.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-32238ec7-7fff-dc21-a6a2-7fbc8c46909b\"> </span></p>\n<p dir=\"ltr\"><span>The main goal of this project was to find out how language structure can be re-organized to maximize the potential of the tactile modality. We conducted this research in a historically unprecedented moment, when, for the first time, a large, socially organized and politically engaged network of DeafBlind people were communicating directly with one another via reciprocal, tactile channels. DeafBlind people refer to these communication practices as \"Protactile\" (PT). In order to analyze the emergence of new linguistic structures in PT, we developed three hypotheses, which were tested both cross-sectionally and longitudinally over a five-year period among three groups: PT DeafBlind speakers, non-PT DeafBlind speakers, and non-PT Deaf speakers. Comparing these groups allowed us to distinguish emergent linguistic patterns from on-the-fly compensatory adjustments to sensory change (i.e. becoming deaf-blind). We compare PT with American Sign Language (ASL) because all of the individuals in this particular DeafBlind community grew up as fluent signers, but with very restricted access to speech.</span></p>\n<p dir=\"ltr\"><span><span> </span></span><span><span> </span></span><span><span> </span></span><span><span> </span></span><span><span> </span></span></p>\n<p dir=\"ltr\"><span>Intellectual Merit</span><span>: All languages have a basic set of units for creating meaning and rules for how they can be combined. This level of linguistic structure is called &ldquo;phonology&rdquo;. It was once assumed that phonological organization, and therefore language in general, could only exist in the aural/oral modality. For a form of communication to be considered &ldquo;language&rdquo;, it was thought, it has to be spoken and heard. Since the 1960s, when linguists studying American Sign Language (ASL) demonstrated that phonological structure can also make use of the visual/gestural modality, phonology has begun to be recast as a level of linguistic structure which, at some level of abstraction, is independent of any one modality, and yet, must arise out of, and be rooted in, particular modalities. This research addressed those theoretical debates by studying a new, tactile language, emerging in communities of DeafBlind people in the U.S. The findings reveal that phonological structure can be sustained by touch, just as it can be sustained by vision and hearing. We also gained insight into which areas of the language were optimized to the tactile modality, what order the changes took place in, and the principles that governed those changes.&nbsp;</span></p>\n<p dir=\"ltr\"><span>First, we found that PT optimized the tactile modality by (a) using the hands and arms for purposes of producing and receiving language in ways that are different from ASL and in doing so (b) reconfiguring the traditional speaker-hearer exchange so that two people are required to produce any linguistic expression. Second, we found that the important grammatical differences between ASL and PT began in specific complex structural forms that are used to describe spatial events (i.e. classifier constructions), and not in random ways. Third, we found that over the course of roughly a decade, the principles of organization that emerged in spatial constructions have started to be generalized to create other PT vocabulary that is not derived from ASL, and to change existing foreign forms borrowed from ASL. In languages that are older than PT, it can be hard to tell which aspects of the language came first as the language emerged. Through this research, we have gained insight into the order in which different components of the lexicon can emerge. Finally, in comparing productions of PT DeafBlind, non-PT DeafBlind and non-PT Deaf participants, we have determined that the patterns we have identified among PT speakers are part of an emerging phonological system, which is conventional across a group of speakers, as opposed to on-the-fly interactional adjustments. These findings contribute not only to the field of sign language linguistics, but more broadly, to our understanding of what is possible in human language, and how those possibilities can be realized in a new modality.</span></p>\n<p><span>Broader Impacts</span><span>: A better understanding of the structure of PT is improving the ability of interpreters to communicate with the DeafBlind people they serve through the Protactile Language Interpreting National Education Program, collaborating with ongoing work on this topic (</span><span>DOE</span><span>: H160D160005). Understanding the adult system as a base-line also stands to improve language outcomes for DeafBlind children, via new research on language acquisition and socialization of DeafBlind children (see </span><span>NSF</span><span>: BCS-2038042, BCS-2104555; </span><span>NIH</span><span>: </span><span>1R01EY033761-01</span><span>), and creating new technologies that can be used for remote communication in educational and other settings (see </span><span>NSF</span><span>: CHS-1909121).</span></p><br>\n<p>\n Last Modified: 12/27/2023<br>\nModified by: Terra&nbsp;Edwards</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThe main goal of this project was to find out how language structure can be re-organized to maximize the potential of the tactile modality. We conducted this research in a historically unprecedented moment, when, for the first time, a large, socially organized and politically engaged network of DeafBlind people were communicating directly with one another via reciprocal, tactile channels. DeafBlind people refer to these communication practices as \"Protactile\" (PT). In order to analyze the emergence of new linguistic structures in PT, we developed three hypotheses, which were tested both cross-sectionally and longitudinally over a five-year period among three groups: PT DeafBlind speakers, non-PT DeafBlind speakers, and non-PT Deaf speakers. Comparing these groups allowed us to distinguish emergent linguistic patterns from on-the-fly compensatory adjustments to sensory change (i.e. becoming deaf-blind). We compare PT with American Sign Language (ASL) because all of the individuals in this particular DeafBlind community grew up as fluent signers, but with very restricted access to speech.\n\n\n     \n\n\nIntellectual Merit: All languages have a basic set of units for creating meaning and rules for how they can be combined. This level of linguistic structure is called phonology. It was once assumed that phonological organization, and therefore language in general, could only exist in the aural/oral modality. For a form of communication to be considered language, it was thought, it has to be spoken and heard. Since the 1960s, when linguists studying American Sign Language (ASL) demonstrated that phonological structure can also make use of the visual/gestural modality, phonology has begun to be recast as a level of linguistic structure which, at some level of abstraction, is independent of any one modality, and yet, must arise out of, and be rooted in, particular modalities. This research addressed those theoretical debates by studying a new, tactile language, emerging in communities of DeafBlind people in the U.S. The findings reveal that phonological structure can be sustained by touch, just as it can be sustained by vision and hearing. We also gained insight into which areas of the language were optimized to the tactile modality, what order the changes took place in, and the principles that governed those changes.\n\n\nFirst, we found that PT optimized the tactile modality by (a) using the hands and arms for purposes of producing and receiving language in ways that are different from ASL and in doing so (b) reconfiguring the traditional speaker-hearer exchange so that two people are required to produce any linguistic expression. Second, we found that the important grammatical differences between ASL and PT began in specific complex structural forms that are used to describe spatial events (i.e. classifier constructions), and not in random ways. Third, we found that over the course of roughly a decade, the principles of organization that emerged in spatial constructions have started to be generalized to create other PT vocabulary that is not derived from ASL, and to change existing foreign forms borrowed from ASL. In languages that are older than PT, it can be hard to tell which aspects of the language came first as the language emerged. Through this research, we have gained insight into the order in which different components of the lexicon can emerge. Finally, in comparing productions of PT DeafBlind, non-PT DeafBlind and non-PT Deaf participants, we have determined that the patterns we have identified among PT speakers are part of an emerging phonological system, which is conventional across a group of speakers, as opposed to on-the-fly interactional adjustments. These findings contribute not only to the field of sign language linguistics, but more broadly, to our understanding of what is possible in human language, and how those possibilities can be realized in a new modality.\n\n\nBroader Impacts: A better understanding of the structure of PT is improving the ability of interpreters to communicate with the DeafBlind people they serve through the Protactile Language Interpreting National Education Program, collaborating with ongoing work on this topic (DOE: H160D160005). Understanding the adult system as a base-line also stands to improve language outcomes for DeafBlind children, via new research on language acquisition and socialization of DeafBlind children (see NSF: BCS-2038042, BCS-2104555; NIH: 1R01EY033761-01), and creating new technologies that can be used for remote communication in educational and other settings (see NSF: CHS-1909121).\t\t\t\t\tLast Modified: 12/27/2023\n\n\t\t\t\t\tSubmitted by: TerraEdwards\n"
 }
}