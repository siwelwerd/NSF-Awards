{
 "awd_id": "1723352",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAPA: Collaborative Research: ARION: Taming Heterogeneity with DSLs, Approximation, and Synthesis",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922585",
 "po_email": "pprabhak@nsf.gov",
 "po_sign_block_name": "Pavithra Prabhakar",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 850000.0,
 "awd_amount": 850000.0,
 "awd_min_amd_letter_date": "2017-09-07",
 "awd_max_amd_letter_date": "2017-09-07",
 "awd_abstract_narration": "Specialization and the arrival of new technologies are key forces motivating heterogeneous systems. Heterogeneity is already in use widely, with public clouds offering instances that are heterogeneous in both compute capabilities and storage. This project identifies the following forces that will make systems heterogeneous beyond just compute and storage, complicating programming and compilation beyond the challenges that we face today. This project develops Arion, a system for compiling programs onto heterogeneous platforms based on several unifying ideas. The Arion system will be evaluated on practically relevant workloads ranging from computer vision and virtual reality, to graph computations, machine learning and stream processing. The investigators will work with partners in industry to transfer research results to products, and the tools and software developed by this project will be released as open source.\r\n\r\nThe research in this project relies on four unifying ideas. The first thrust explores schedules and type systems separate a program's specification from its implementation strategy, enabling performance portability because one can select, without changing the program, its parallelism, locality, and hardware mapping. The second thrust uses domain-specific languages to describe not only programs but also artifacts used during compilation, such as schedules, resource-, and memory consistency models. This allows automatic synthesis of these artifacts. The third thrust uses resource models to bring scheduling and synthesis to large programs because the target program need not be scheduled or synthesized all at once. Instead, the compiler makes high-level decisions by estimating performance using a model before committing to low-level decisions. Finally, the investigators will use formal methods to lift programs into, and verify and synthesize programs in our DSLs, providing a high degree of automation. The verifiers and synthesizers are automatically generated from descriptions of DSLs.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rastislav",
   "pi_last_name": "Bodik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rastislav Bodik",
   "pi_email_addr": "bodik@uw.edu",
   "nsf_id": "000207383",
   "pi_start_date": "2017-09-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Luis",
   "pi_last_name": "Ceze",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Luis Ceze",
   "pi_email_addr": "luisceze@cs.washington.edu",
   "nsf_id": "000083036",
   "pi_start_date": "2017-09-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Emina",
   "pi_last_name": "Torlak",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Emina Torlak",
   "pi_email_addr": "emina@cs.washington.edu",
   "nsf_id": "000642956",
   "pi_start_date": "2017-09-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Alvin",
   "pi_last_name": "Cheung",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alvin Cheung",
   "pi_email_addr": "akcheung@cs.berkeley.edu",
   "nsf_id": "000684029",
   "pi_start_date": "2017-09-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "4333 Brooklyn Ave NE",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981950001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "021Z",
   "pgm_ref_txt": "Industry Partnerships"
  },
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "8206",
   "pgm_ref_txt": "Formal Methods and Verification"
  },
  {
   "pgm_ref_code": "8585",
   "pgm_ref_txt": "NSF/Intel Partnership Projects"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 850000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-37e82a97-7fff-3334-0276-66044d7e55bc\">\n<p dir=\"ltr\"><span>Optimizing tensor programs is key to making machine learning (ML) viable at the scale required by the recent foundation models. This project's effort in Apache TVM led the way in compiler-based automated techniques for tensor-program optimizations for new parallel hardware. TVM has influenced many widely used ML compilers like TensorRT, XLA, Glow, etc. Apache TVM grew a community of over 780 contributors and is currently actively used in production by emerging AI chip companies as well as cloud providers.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Image processing programs such as Adobe Photoshop represent another important domain where compilers are crucial in utilizing new hardware. We have built a prototype of Dexter, a new tool that automatically translates image processing functions from a low-level general-purpose language to a high-level domain-specific language (DSL), which then enables such code to leverage cross-platform optimizations enabled by DSLs. Rather than building a classical syntax-driven compiler to do this translation, Dexter leverages recent advances in program synthesis and program verification, along with a new domain-specific synthesis algorithm, to translate C++ image processing code to the Halide DSL, while guaranteeing semantic equivalence. To demonstrate the effectiveness of our approach, we evaluate Dexter using real-world image processing functions from Adobe Photoshop and showed that Dexter can translate 263 out of 353 functions. These translated routines now ship as part of the recent Adobe Photoshop product.&nbsp;</span></p>\n<p dir=\"ltr\"><span>We have also worked on tools for making compilers more powerful, including tools for generating program synthesizers. We have developed the fourth generation Rosette, a system that has been instrumental in allowing synthesis to reach parity with human experts on several programming tasks. Rosette has been used to prototype synthesizers for GPU kernels and SIMD code generators for the Halide compiler.&nbsp;</span></p>\n<br />\n<p dir=\"ltr\"><span>Many of our tools have been released into open source:</span></p>\n<br />\n<p dir=\"ltr\"><span>Casper Compiler- </span><a href=\"http://casper.uwplse.org\"><span>http://casper.uwplse.org</span></a></p>\n<p dir=\"ltr\"><span>Differentiable Halide - </span><a href=\"https://people.csail.mit.edu/tzumao/gradient_halide\"><span>https://people.csail.mit.edu/tzumao/gradient_halide</span></a></p>\n<p dir=\"ltr\"><span>Halide autoscheduler - </span><a href=\"http://halide-lang.org/papers/autoscheduler2019.html\"><span>http://halide-lang.org/papers/autoscheduler2019.html</span></a></p>\n<p dir=\"ltr\"><span>Taichi compiler - </span><a href=\"https://taichi.graphics\"><span>https://taichi.graphics</span></a></p>\n<p dir=\"ltr\"><span>Rosette - </span><a href=\"http://emina.github.io/rosette/\"><span>http://emina.github.io/rosette/</span></a></p>\n<span>Apache TVM - </span><a href=\"http://tvm.ai\"><span>http://tvm.ai</span></a></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/08/2023<br>\n\t\t\t\t\tModified by: Luis&nbsp;Ceze</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nOptimizing tensor programs is key to making machine learning (ML) viable at the scale required by the recent foundation models. This project's effort in Apache TVM led the way in compiler-based automated techniques for tensor-program optimizations for new parallel hardware. TVM has influenced many widely used ML compilers like TensorRT, XLA, Glow, etc. Apache TVM grew a community of over 780 contributors and is currently actively used in production by emerging AI chip companies as well as cloud providers. \nImage processing programs such as Adobe Photoshop represent another important domain where compilers are crucial in utilizing new hardware. We have built a prototype of Dexter, a new tool that automatically translates image processing functions from a low-level general-purpose language to a high-level domain-specific language (DSL), which then enables such code to leverage cross-platform optimizations enabled by DSLs. Rather than building a classical syntax-driven compiler to do this translation, Dexter leverages recent advances in program synthesis and program verification, along with a new domain-specific synthesis algorithm, to translate C++ image processing code to the Halide DSL, while guaranteeing semantic equivalence. To demonstrate the effectiveness of our approach, we evaluate Dexter using real-world image processing functions from Adobe Photoshop and showed that Dexter can translate 263 out of 353 functions. These translated routines now ship as part of the recent Adobe Photoshop product. \nWe have also worked on tools for making compilers more powerful, including tools for generating program synthesizers. We have developed the fourth generation Rosette, a system that has been instrumental in allowing synthesis to reach parity with human experts on several programming tasks. Rosette has been used to prototype synthesizers for GPU kernels and SIMD code generators for the Halide compiler. \n\n\nMany of our tools have been released into open source:\n\n\nCasper Compiler- http://casper.uwplse.org\nDifferentiable Halide - https://people.csail.mit.edu/tzumao/gradient_halide\nHalide autoscheduler - http://halide-lang.org/papers/autoscheduler2019.html\nTaichi compiler - https://taichi.graphics\nRosette - http://emina.github.io/rosette/\nApache TVM - http://tvm.ai\n\n\t\t\t\t\tLast Modified: 02/08/2023\n\n\t\t\t\t\tSubmitted by: Luis Ceze"
 }
}