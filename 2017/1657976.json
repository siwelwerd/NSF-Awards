{
 "awd_id": "1657976",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Workshop on  Architecture and Software for Emerging Applications (WASEA)",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Matt Mutka",
 "awd_eff_date": "2016-11-01",
 "awd_exp_date": "2019-10-31",
 "tot_intn_awd_amt": 49900.0,
 "awd_amount": 49900.0,
 "awd_min_amd_letter_date": "2016-10-25",
 "awd_max_amd_letter_date": "2019-05-16",
 "awd_abstract_narration": "High-valued domain applications in areas such as medicine,\r\nbiology, physics, engineering, and social phenomena demand\r\nboth fast innovation and high execution speed and require\r\nproductive development environments for domain experts who\r\nmay not be computer science experts. This workshop brings together leading researchers in architecture,\r\ncompilers and programming languages, and domain experts to discuss\r\nand debate potential approaches to accelerating progress in such\r\nhigh-valued domains with an emphasis on developing strategies for\r\nexploiting machine learning, including strategies for accelerating\r\nlearning algorithms through parallelism.  The goal is to stimulate\r\nan in-depth discussion of the potential benefits of joint architecture\r\nand compiler approaches.  The workshop will promote broadening\r\nparticipation by including speakers from groups underrepresented\r\nin computing and early career researchers.\r\n\r\nThe workshop will produce a report providing recommendations on:\r\njoint compiler/language and architecture approaches, compiler/language\r\nsupport enabling more aggressive hardware capabilities, architecture\r\nsupport enabling more effective compilers, and applications whose\r\ndevelopment process could benefit by these advances, The report\r\nwill identify research opportunities in the interaction between\r\ndevelopers, and architecture and language/compiler researchers to\r\nenable productive domain application development and highly efficient\r\nand scalable implementation on heterogeneous computing systems.  The\r\nreport will outline promising approaches and the research required for\r\nthese approaches to become usable by the domain application developers.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lawrence",
   "pi_last_name": "Rauchwerger",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lawrence Rauchwerger",
   "pi_email_addr": "rwerger@illinois.edu",
   "nsf_id": "000468621",
   "pi_start_date": "2016-10-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Nancy",
   "pi_last_name": "Amato",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Nancy M Amato",
   "pi_email_addr": "namato@illinois.edu",
   "nsf_id": "000430397",
   "pi_start_date": "2016-10-25",
   "pi_end_date": "2019-05-16"
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M Engineering Experiment Station",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "",
  "perf_st_name": "RI REQUIRED",
  "perf_zip_code": "",
  "perf_ctry_code": "IS",
  "perf_cong_dist": "",
  "perf_st_cong_dist": "",
  "perf_ctry_name": "Israel",
  "perf_ctry_flag": "0"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 49900.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-00965d71-7fff-8ce8-d93a-5eacd7f51853\">&nbsp;</span></p>\n<div class=\"page\" title=\"Page 4\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>Intellectual Merit </span></p>\n<p><span>Bringing together some of best researchers to discuss domain specific applications and their software and architecture environment may lead to new approaches to solving this difficult problem. The development of faster, more capable machine learning environments as well as better and faster graph processing capabilities may greatly increase our capabilities to study and optimize problems in a wide range: from physics and engineering to social phenomena. </span></p>\n<p><span>Broader Impact </span></p>\n<p><span>The development of better tools for using machine learning and graph algorithms can affect such areas as medicine, biology, social studies, etc. It can grant us access to a wealth of data that is being collected but it is not being used yet.</span></p>\n<p><span>Outcome</span></p>\n</div>\n</div>\n</div>\n<p dir=\"ltr\"><span>High-valued domain applications such as image recognition demand both fast innovation and high execution speed. For example, the methods for image recognition using deep neural networks evolve very quickly and require productive development environments for domain experts who may not be computer science experts. Geoffrey Hinton&rsquo;s team won the 2012 ImageNet competition by training a deep neural network with 1.2 million images. Since then, many new algorithm innovations have been proposed for significant improvement over the version from Hinton&rsquo;s team. Furthermore, the success in applying deep neural networks to image recognition has ignited a lot of research on applying deep neural networks to other areas such as speech recognition and natural language process, where traditional approaches have not been successful for decades.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>At the same time, the research process for these methods require fast turnaround time of experiments that involve training deep neural networks using millions of images. Training of deep convolution neural networks involves fine-grained parallel computation within each layer but is constrained by data dependencies from one layer to the next. This is why traditional scale-out schemes based on clusters have not been successful. The best hardware for the training process has been tightly coupled multi-GPU systems that support extremely fast synchronization among a very large number of cooperating fine grained threads. Even with these systems, each such experiment can take weeks to complete. The creation of an effective algorithm can take many rounds of experiments. Dramatically more efficient implementation of candidate algorithms and thus much faster turnaround time of experiments can have a significant impact on the progress of the field.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>The state of the art in developing and implementing high-valued domain applications is based on application frameworks. For example, in machine learning, developers typically build on library frameworks such as Caffe, Torch, and TensorFlow. The library functions of these frameworks are implemented for CPUs, GPUs, and other accelerators. However, in the current practice, it takes tremendous amount of effort and time to bring up the implementation of an existing training method for a new compute device. It takes even more effort and latency to introduce a new method that needs to be implemented for the existing devices.&nbsp; Individual kernels in each method needs to be hand-optimized for a new architecture. Efficient arrangement of the execution of kernels with respect to each other in a methods to take advantage of the memory hierarchy and interconnect capabilities requires even more effort.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>Experience from the CUDA and Heterogeneous System Architecture (HSA) shows that architecture support can significantly reduce the cost of implementing application functions on heterogeneous parallel devices. Unified address space, user-level command queues, re-optimizable intermediate representations, and coherent shared memory are among the frequently cited system architecture features that reduce the barrier of implementation. However, little has been done in the architecture of the compute devices to explicitly lower the barrier of implementation.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>On the compiler side, much progress has been made in C++ and OpenCL compilation to provide efficient code optimization, scheduling, and generation for a given algorithm. However, there has been little work on the support of specifying alternative algorithms that can achieve the&nbsp; same application-level results but different levels of efficiency on different hardware types and hierarchies. Some recent work on DSL have shown promise in image processing. However, one needs to wrestle with the burden on the developers to learn multiple languages. A more generic extension to the existing C++ or Python language to allow more compiler support may be a more realistic long-term solution.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>The idea of the workshop is to bring together architecture and compiler researchers to discuss and debate on the potential approaches to accelerating the innovation in high-valued domain applications. The goal is to stimulate an in-depth discussion of what each can potentially achieve and how much more joint architecture and compiler approaches could accomplish. The product of the workshop is a report on the recommendations on each approach based on in-depth discussions of leading researchers from compilers, architecture, and important application domains.</span></p>\n<p dir=\"ltr\"><span>&nbsp;&nbsp;</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/27/2020<br>\n\t\t\t\t\tModified by: Lawrence&nbsp;Rauchwerger</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \n\n\n\n\nIntellectual Merit \n\nBringing together some of best researchers to discuss domain specific applications and their software and architecture environment may lead to new approaches to solving this difficult problem. The development of faster, more capable machine learning environments as well as better and faster graph processing capabilities may greatly increase our capabilities to study and optimize problems in a wide range: from physics and engineering to social phenomena. \n\nBroader Impact \n\nThe development of better tools for using machine learning and graph algorithms can affect such areas as medicine, biology, social studies, etc. It can grant us access to a wealth of data that is being collected but it is not being used yet.\n\nOutcome\n\n\n\nHigh-valued domain applications such as image recognition demand both fast innovation and high execution speed. For example, the methods for image recognition using deep neural networks evolve very quickly and require productive development environments for domain experts who may not be computer science experts. Geoffrey Hinton\u2019s team won the 2012 ImageNet competition by training a deep neural network with 1.2 million images. Since then, many new algorithm innovations have been proposed for significant improvement over the version from Hinton\u2019s team. Furthermore, the success in applying deep neural networks to image recognition has ignited a lot of research on applying deep neural networks to other areas such as speech recognition and natural language process, where traditional approaches have not been successful for decades.\n\n \nAt the same time, the research process for these methods require fast turnaround time of experiments that involve training deep neural networks using millions of images. Training of deep convolution neural networks involves fine-grained parallel computation within each layer but is constrained by data dependencies from one layer to the next. This is why traditional scale-out schemes based on clusters have not been successful. The best hardware for the training process has been tightly coupled multi-GPU systems that support extremely fast synchronization among a very large number of cooperating fine grained threads. Even with these systems, each such experiment can take weeks to complete. The creation of an effective algorithm can take many rounds of experiments. Dramatically more efficient implementation of candidate algorithms and thus much faster turnaround time of experiments can have a significant impact on the progress of the field. \n\n \nThe state of the art in developing and implementing high-valued domain applications is based on application frameworks. For example, in machine learning, developers typically build on library frameworks such as Caffe, Torch, and TensorFlow. The library functions of these frameworks are implemented for CPUs, GPUs, and other accelerators. However, in the current practice, it takes tremendous amount of effort and time to bring up the implementation of an existing training method for a new compute device. It takes even more effort and latency to introduce a new method that needs to be implemented for the existing devices.  Individual kernels in each method needs to be hand-optimized for a new architecture. Efficient arrangement of the execution of kernels with respect to each other in a methods to take advantage of the memory hierarchy and interconnect capabilities requires even more effort.\n\n \nExperience from the CUDA and Heterogeneous System Architecture (HSA) shows that architecture support can significantly reduce the cost of implementing application functions on heterogeneous parallel devices. Unified address space, user-level command queues, re-optimizable intermediate representations, and coherent shared memory are among the frequently cited system architecture features that reduce the barrier of implementation. However, little has been done in the architecture of the compute devices to explicitly lower the barrier of implementation.\n\n \nOn the compiler side, much progress has been made in C++ and OpenCL compilation to provide efficient code optimization, scheduling, and generation for a given algorithm. However, there has been little work on the support of specifying alternative algorithms that can achieve the  same application-level results but different levels of efficiency on different hardware types and hierarchies. Some recent work on DSL have shown promise in image processing. However, one needs to wrestle with the burden on the developers to learn multiple languages. A more generic extension to the existing C++ or Python language to allow more compiler support may be a more realistic long-term solution. \n\n \nThe idea of the workshop is to bring together architecture and compiler researchers to discuss and debate on the potential approaches to accelerating the innovation in high-valued domain applications. The goal is to stimulate an in-depth discussion of what each can potentially achieve and how much more joint architecture and compiler approaches could accomplish. The product of the workshop is a report on the recommendations on each approach based on in-depth discussions of leading researchers from compilers, architecture, and important application domains.\n  \n\n\t\t\t\t\tLast Modified: 03/27/2020\n\n\t\t\t\t\tSubmitted by: Lawrence Rauchwerger"
 }
}