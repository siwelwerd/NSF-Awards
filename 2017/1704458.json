{
 "awd_id": "1704458",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Medium: Non-Convex Methods for Discovering High-Dimensional Structures in Big and Corrupted Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 1150000.0,
 "awd_amount": 1150000.0,
 "awd_min_amd_letter_date": "2017-07-27",
 "awd_max_amd_letter_date": "2023-02-24",
 "awd_abstract_narration": "Discovering structure in high-dimensional data, such as images, videos and 3D point clouds, has become an essential part of scientific discovery in many disciplines, including machine learning, computer vision, pattern recognition, and signal processing. This has motivated extraordinary advances in the past decade, including various sparse and low-rank modeling methods based on convex optimization with provable theoretical guarantees of correct recovery. However, existing theory and algorithms rely on the assumption that high-dimensional data can be well approximated by low-dimensional structures. While this assumption is adequate for some datasets, e.g., images of faces under varying illumination, it may be violated in many emerging datasets, e.g., 3D point clouds. The goal of this project is to develop a mathematical modeling framework and associated non-convex optimization tools for discovering high-dimensional structures in big and corrupted data.\r\n\r\nThis project will develop provably correct and scalable optimization algorithms for learning a union of high-dimensional subspaces from big and corrupted data. The proposed algorithms will be based on a novel framework called Dual Principal Component Pursuit that, instead of learning a basis for each subspace, seeks to learn a basis for their orthogonal complements. In sharp contrast with existing sparse and low-rank methods, which require both the dimensions of the subspaces and the percentage of outliers to be sufficiently small, the proposed framework will lead to results where even subspaces of the highest possible dimension (i.e., hyperplanes) can be correctly recovered from highly corrupted data. This will be achieved by solving a family of non-convex sparse representation problems whose analysis will require the development of novel theoretical results to guarantee the correct recovery of the subspaces from corrupted data. The project will also develop scalable algorithms for solving these non-convex optimization problems and study conditions for their convergence to the global optimum. These algorithms will be evaluated in two major applications in computer vision: segmentation of point clouds and clustering of image categorization datasets.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rene",
   "pi_last_name": "Vidal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rene Vidal",
   "pi_email_addr": "vidalr@upenn.edu",
   "nsf_id": "000486258",
   "pi_start_date": "2017-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Robinson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel Robinson",
   "pi_email_addr": "dpr219@lehigh.edu",
   "nsf_id": "000607397",
   "pi_start_date": "2017-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "3400 N Charles St.",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182608",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 1150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Discovering structure in high-dimensional data, such as images, videos and 3D point clouds, has become an essential part of scientific discovery in many disciplines, including machine learning, computer vision, pattern recognition, and signal processing. This has motivated extraordinary advances in the past decade, including various sparse and low-rank modeling methods based on convex optimization with provable theoretical guarantees of correct recovery. However, existing theory and algorithms rely on the assumption that high-dimensional data can be well approximated by low-dimensional structures. While this assumption is adequate for some datasets, e.g., images of faces under varying illumination, it may be violated in many emerging datasets, e.g., 3D point clouds.</p>\n<p>This project developed a mathematical modeling framework and associated non-convex optimization tools for discovering high-dimensional structures in big and corrupted data. In particular, this project developed provably correct and scalable optimization algorithms for learning a union of high-dimensional subspaces from big and corrupted data. The proposed algorithms were based on a novel framework called Dual Principal Component Pursuit (DPCP) that, instead of learning a basis for each subspace, learns a basis for their orthogonal complements. In sharp contrast with prior sparse and low-rank methods, which require both the dimensions of the subspaces and the percentage of outliers to be sufficiently small, DPCP can correctly recover subspaces of the highest possible dimension (i.e., hyperplanes) from highly corrupted data. This is achieved by solving a family of non-convex sparse representation problems whose analysis required the development of novel theoretical results to guarantee the correct recovery of the subspaces from corrupted data. The project also developed scalable algorithms for solving these non-convex optimization problems and studied conditions for their convergence to the global optimum. These algorithms were evaluated in two major applications in computer vision: segmentation of point clouds and clustering of image categorization datasets.</p><br>\n<p>\n Last Modified: 08/23/2024<br>\nModified by: Rene&nbsp;Vidal</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nDiscovering structure in high-dimensional data, such as images, videos and 3D point clouds, has become an essential part of scientific discovery in many disciplines, including machine learning, computer vision, pattern recognition, and signal processing. This has motivated extraordinary advances in the past decade, including various sparse and low-rank modeling methods based on convex optimization with provable theoretical guarantees of correct recovery. However, existing theory and algorithms rely on the assumption that high-dimensional data can be well approximated by low-dimensional structures. While this assumption is adequate for some datasets, e.g., images of faces under varying illumination, it may be violated in many emerging datasets, e.g., 3D point clouds.\n\n\nThis project developed a mathematical modeling framework and associated non-convex optimization tools for discovering high-dimensional structures in big and corrupted data. In particular, this project developed provably correct and scalable optimization algorithms for learning a union of high-dimensional subspaces from big and corrupted data. The proposed algorithms were based on a novel framework called Dual Principal Component Pursuit (DPCP) that, instead of learning a basis for each subspace, learns a basis for their orthogonal complements. In sharp contrast with prior sparse and low-rank methods, which require both the dimensions of the subspaces and the percentage of outliers to be sufficiently small, DPCP can correctly recover subspaces of the highest possible dimension (i.e., hyperplanes) from highly corrupted data. This is achieved by solving a family of non-convex sparse representation problems whose analysis required the development of novel theoretical results to guarantee the correct recovery of the subspaces from corrupted data. The project also developed scalable algorithms for solving these non-convex optimization problems and studied conditions for their convergence to the global optimum. These algorithms were evaluated in two major applications in computer vision: segmentation of point clouds and clustering of image categorization datasets.\t\t\t\t\tLast Modified: 08/23/2024\n\n\t\t\t\t\tSubmitted by: ReneVidal\n"
 }
}