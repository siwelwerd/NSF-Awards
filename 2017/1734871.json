{
 "awd_id": "1734871",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NCS-FO: Collaborative Research: A Neurally-Inspired, Event-Based Computer Vision Pipeline",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2019-09-30",
 "tot_intn_awd_amt": 110000.0,
 "awd_amount": 110000.0,
 "awd_min_amd_letter_date": "2017-08-07",
 "awd_max_amd_letter_date": "2017-08-07",
 "awd_abstract_narration": "The goal of this research is to make machines more intelligent by more closely mimicking biology, specifically, harnessing the information present in event-driven input along with top-down and lateral feedback.  Although computers continue to make inroads into everyday life, they still cannot perform many tasks that are readily performed by humans and other animals, or lag far behind their biological counterparts.  For example, on publically available datasets designed to measure performance on object detection tasks, the best computer software running on the fastest available hardware fails to locate between 20-40% of the human-annotated targets.  No animal would long survive, at least not in the wild, if its visual system made so many errors.  This project therefore will investigate how information processing strategies used by biological neural systems can be exploited to design more powerful computer hardware and software.   The project will have impact on training in neurally-inspired approaches to computer design, and technological leadership in neuromorphic computing for both defense and commercial uses.\r\n\r\nThe project will investigate processing mechanisms that are ubiquitous in biology but typically are not found in computer software and hardware.  The first of these mechanisms is event-driven input.  The retina sends visual information to the brain in the form of discrete pulses that propagate down the optic nerve.  Likewise, the cochlea encodes sound as action potentials or spikes that propagate along the auditory nerve.  In both cases, the precise time at which a spike occurs in a given nerve fiber, relative to the time at which spikes occur in other nerve fibers, can encode information that is critical to subsequent processing by the brain.  In the case of the retina, relative spike timing may help to separate foreground from background regions or even help us to read more quickly the words on this page.  In the cochlea, relative timing can be used to distinguish one sound source from another, which in turn allows us to hear what our companion is saying even while in a noisy room.  In contrast, the types of artificial neural networks most commonly used today do not employ event-driven input.  This research will test the hypothesis that event-driven input can be used to improve the performance of artificial neural networks on image and audio segmentation tasks.  The second biological processing mechanism to be investigated is top-down feedback.  Whereas most artificial neural networks studied today are strictly feed-forward, the vast preponderance of synapses in the brain arise from top-down and lateral feedback connections.  A mathematically tractable model of top-down and lateral feedback will be used to test the hypothesis that such connections can be used to improve the performance of artificial neural networks on object localization tasks.  Whether such feedback can reduce the susceptibility of networks to adversarial training will also be explored.  Finally, the project will explore whether a new type of neuromorphic chip that self-organizes in response to environmental input can learn more powerful representation from event-driven input, and develop strategies for combining such chips into hierarchical networks with lateral and top-down feedback.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Flynn",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Flynn",
   "pi_email_addr": "mpflynn@umich.edu",
   "nsf_id": "000218306",
   "pi_start_date": "2017-08-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Wei",
   "pi_last_name": "Lu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wei Lu",
   "pi_email_addr": "wluee@eecs.umich.edu",
   "nsf_id": "000492897",
   "pi_start_date": "2017-08-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Zhengya",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zhengya Zhang",
   "pi_email_addr": "zhengya@eecs.umich.edu",
   "nsf_id": "000542768",
   "pi_start_date": "2017-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "1301 Beal Ave",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092122",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "8551",
   "pgm_ref_txt": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 110000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Machine learning has generated tremendous interest from industrial and academic researchers and has delivered performance approaching or exceeding human-level performance in object recognition, speech recognition, and complex strategic games. These achievements have been made possible thanks to advances in computer hardware and the development of new algorithms. However, continued improvements in hardware performance face several challenges. Although processing&nbsp;performance and storage capacity have historically&nbsp;improved through scaling according to the Moore?s Law, such scaling has slowed significantly due to fundamental limits of physics. Additionally, current hardware implementations based on the Von Neumann architecture suffer from severe throughput and energy penalties due to the frequent data movement between the main memory and the processor, especially in data-intensive applications such as machine learning tasks.&nbsp;</p>\n<p>As a promising alternative, the&nbsp;memristor crossbar is very efficient at performing vector-matrix multiplication, since the values of the matrix can be stored as&nbsp;conductances of&nbsp;the&nbsp;analog&nbsp;device of the crossbar array. When an input vector is applied as voltage pulses with different pulse amplitudes or different pulse widths to the rows of the crossbar, the currents or charges collected at the columns of the crossbar correspond to the resulting VMM outputs, following Ohm's law and Kirchhoff's current law. This approach makes it possible to execute direct compute of this data-intensive task both in-memory and in parallel in a single step.</p>\n<p>For the implementation of the memristor crossbar hardware for efficient multiply-accumulate (MAC) operations, efficient DACs and ADCs are essential. DACs and ADCs&nbsp;are needed to send the input and collect the output from the memristor array. Controllers are required to convert the input signals to pulse amplitude or width. To reduce latency and power consumption, all these components need to be integrated together with the crossbar array on a single chip, instead of using discrete components on a board. Integrating a processor on chip also allows the neuron functions and network structures to be reprogrammed though simple software changes, enabling different models to be mapped on the same hardware platform.&nbsp;</p>\n<p>Neuromorphic computing systems, which mimic the function and structure of the human brain, are a promising approach to overcome the limitations of conventional computing systems (i.e. the Von Neumann bottleneck). Recently, memristors and memristor crossbars have been extensively studied in neuromorphic systems due to the ability of memristors to emulate biological synapses, providing advantages such as energy efficient operation and massive parallelism.</p>\n<p>During this project, we developed a fully-integrated, functional, reprogrammable memristor-based neuromorphic chip. The device includes a passive memristor crossbar array directly integrated with all necessary interface circuitry, digital buses and an OpenRISC processor to form a complete hardware system-on-chip. Thanks to the re-programmability of the memristor crossbar and the integrated CMOS circuitry, the system is highly flexible and can be programmed to implement different computing models and network structures. Results from two widely used models ? a perceptron network and a bilayer principal component analysis (PCA) system with an unsupervised feature extraction layer and a supervised classification layer, along with a bio-inspired sparse-coding algorithm, have been successfully implemented on the neuromorphic computing system.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/03/2020<br>\n\t\t\t\t\tModified by: Michael&nbsp;Flynn</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1734871/1734871_10512039_1578088228876_Fig1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1734871/1734871_10512039_1578088228876_Fig1--rgov-800width.jpg\" title=\"Fully-integrated memristor/CMOS chip\"><img src=\"/por/images/Reports/POR/2020/1734871/1734871_10512039_1578088228876_Fig1--rgov-66x44.jpg\" alt=\"Fully-integrated memristor/CMOS chip\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fully-integrated memristor/CMOS chip</div>\n<div class=\"imageCredit\">Fuxi Cai</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Michael&nbsp;Flynn</div>\n<div class=\"imageTitle\">Fully-integrated memristor/CMOS chip</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nMachine learning has generated tremendous interest from industrial and academic researchers and has delivered performance approaching or exceeding human-level performance in object recognition, speech recognition, and complex strategic games. These achievements have been made possible thanks to advances in computer hardware and the development of new algorithms. However, continued improvements in hardware performance face several challenges. Although processing performance and storage capacity have historically improved through scaling according to the Moore?s Law, such scaling has slowed significantly due to fundamental limits of physics. Additionally, current hardware implementations based on the Von Neumann architecture suffer from severe throughput and energy penalties due to the frequent data movement between the main memory and the processor, especially in data-intensive applications such as machine learning tasks. \n\nAs a promising alternative, the memristor crossbar is very efficient at performing vector-matrix multiplication, since the values of the matrix can be stored as conductances of the analog device of the crossbar array. When an input vector is applied as voltage pulses with different pulse amplitudes or different pulse widths to the rows of the crossbar, the currents or charges collected at the columns of the crossbar correspond to the resulting VMM outputs, following Ohm's law and Kirchhoff's current law. This approach makes it possible to execute direct compute of this data-intensive task both in-memory and in parallel in a single step.\n\nFor the implementation of the memristor crossbar hardware for efficient multiply-accumulate (MAC) operations, efficient DACs and ADCs are essential. DACs and ADCs are needed to send the input and collect the output from the memristor array. Controllers are required to convert the input signals to pulse amplitude or width. To reduce latency and power consumption, all these components need to be integrated together with the crossbar array on a single chip, instead of using discrete components on a board. Integrating a processor on chip also allows the neuron functions and network structures to be reprogrammed though simple software changes, enabling different models to be mapped on the same hardware platform. \n\nNeuromorphic computing systems, which mimic the function and structure of the human brain, are a promising approach to overcome the limitations of conventional computing systems (i.e. the Von Neumann bottleneck). Recently, memristors and memristor crossbars have been extensively studied in neuromorphic systems due to the ability of memristors to emulate biological synapses, providing advantages such as energy efficient operation and massive parallelism.\n\nDuring this project, we developed a fully-integrated, functional, reprogrammable memristor-based neuromorphic chip. The device includes a passive memristor crossbar array directly integrated with all necessary interface circuitry, digital buses and an OpenRISC processor to form a complete hardware system-on-chip. Thanks to the re-programmability of the memristor crossbar and the integrated CMOS circuitry, the system is highly flexible and can be programmed to implement different computing models and network structures. Results from two widely used models ? a perceptron network and a bilayer principal component analysis (PCA) system with an unsupervised feature extraction layer and a supervised classification layer, along with a bio-inspired sparse-coding algorithm, have been successfully implemented on the neuromorphic computing system.\n\n \n\n\t\t\t\t\tLast Modified: 01/03/2020\n\n\t\t\t\t\tSubmitted by: Michael Flynn"
 }
}