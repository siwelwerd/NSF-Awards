{
 "awd_id": "1718470",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF:Small:Towards practical coded caching",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 449996.0,
 "awd_amount": 449996.0,
 "awd_min_amd_letter_date": "2017-06-26",
 "awd_max_amd_letter_date": "2017-06-26",
 "awd_abstract_narration": "Content caching plays an important role in facilitating large scale content distribution over the Internet. Traditional caching techniques typically store relatively popular content in the local memory (or cache) available at the users, or at the edge of the network. If a given user request can be serviced from the cache (instead of the server), the overall network traffic is reduced. This research will investigate practical issues in the deployment of coded caching, which is a technique that promises huge reductions in caching network traffic, albeit under potentially restrictive assumptions. This will pave the way for the adoption of coded caching in large scale video and audio streaming websites thus improving the efficiency of the national network infrastructure.\r\n\r\nMinimizing per-user delays is one of the main aims of caching. For example, a given video-on-demand user wants his/her video playback to start as soon as possible. Moreover, it is not reasonable to expect that several users want to watch videos at the same time. The investigator will study practical algorithms that a server can use for responding to asynchronous user requests. The algorithms will continue to leverage the rate reductions of coded caching while meeting user-specified deadlines.\r\n\r\nAnother issue with coded caching is that it assumes that the files at the server can be subdivided into a large number of sub-files. Specifically, this number grows exponentially with the number of users and is impractically large even for systems with fifty users. The investigator will study the of design coded caching schemes where the subpacketization level is manageable, yet significant rate reductions are possible as compared to conventional schemes.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aditya",
   "pi_last_name": "Ramamoorthy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aditya Ramamoorthy",
   "pi_email_addr": "adityar@iastate.edu",
   "nsf_id": "000305890",
   "pi_start_date": "2017-06-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Iowa State University",
  "inst_street_address": "1350 BEARDSHEAR HALL",
  "inst_street_address_2": "515 MORRILL ROAD",
  "inst_city_name": "AMES",
  "inst_state_code": "IA",
  "inst_state_name": "Iowa",
  "inst_phone_num": "5152945225",
  "inst_zip_code": "500112103",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IA04",
  "org_lgl_bus_name": "IOWA STATE UNIVERSITY OF SCIENCE AND TECHNOLOGY",
  "org_prnt_uei_num": "DQDBM7FGJPC5",
  "org_uei_num": "DQDBM7FGJPC5"
 },
 "perf_inst": {
  "perf_inst_name": "Iowa State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IA",
  "perf_st_name": "Iowa",
  "perf_zip_code": "500112207",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "IA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 449996.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Content caching plays an important role in facilitating large scale content distribution over the Internet. Traditional caching techniques typically store relatively popular content in the local memory (or cache) available at the users, or at the edge of the network.&nbsp; If a given user request can be serviced from the cache (instead of the server), the overall network traffic is reduced.</p>\n<p>Coded caching is a technique that uses ideas of information theory to significantly reduce the induced network traffic within caching networks. The basic idea is to judiciously combine information from different files to satisfy the requirement of different users. In theory, coded caching allows for huge reductions in the network traffic in caching networks. Nevertheless, there are several important practical issues that need to be addressed before the promised gains of coded caching can be realized in real-world scenarios.</p>\n<p>For instance, the original proposals assume that all users request the content synchronously, i.e., at the same time. We note here that minimizing end user delays is one of the main aims of caching. For example, a given online video-on-demand user wants his/her video playback to start as soon as possible. Thus, expecting this user to wait for other users to also request content from the server is not a reasonable assumption. The first part of our work provides provably efficient algorithms that take the asynchronism in the users into account. The algorithms minimize the induced network traffic while ensuring that the delay constraints of each user are met.</p>\n<p>Another important issue with current coded caching proposals is that they are only applicable in the limit of very large files. The second part of our work provides judicious designs that address this issue. Our schemes leverage much of the gains of coded caching even for typical video files (around 10 GB). Furthermore, our work uncovers a deep relationship between this problem and combinatorial design theory which is branch of mathematics. The synergy between these fields has resulted in very interesting findings.</p>\n<p>This project has supported the graduate education of several students who have gone on to successful careers in industry and academia, thus enhancing the workforce of the United States of America.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/07/2021<br>\n\t\t\t\t\tModified by: Aditya&nbsp;Ramamoorthy</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nContent caching plays an important role in facilitating large scale content distribution over the Internet. Traditional caching techniques typically store relatively popular content in the local memory (or cache) available at the users, or at the edge of the network.  If a given user request can be serviced from the cache (instead of the server), the overall network traffic is reduced.\n\nCoded caching is a technique that uses ideas of information theory to significantly reduce the induced network traffic within caching networks. The basic idea is to judiciously combine information from different files to satisfy the requirement of different users. In theory, coded caching allows for huge reductions in the network traffic in caching networks. Nevertheless, there are several important practical issues that need to be addressed before the promised gains of coded caching can be realized in real-world scenarios.\n\nFor instance, the original proposals assume that all users request the content synchronously, i.e., at the same time. We note here that minimizing end user delays is one of the main aims of caching. For example, a given online video-on-demand user wants his/her video playback to start as soon as possible. Thus, expecting this user to wait for other users to also request content from the server is not a reasonable assumption. The first part of our work provides provably efficient algorithms that take the asynchronism in the users into account. The algorithms minimize the induced network traffic while ensuring that the delay constraints of each user are met.\n\nAnother important issue with current coded caching proposals is that they are only applicable in the limit of very large files. The second part of our work provides judicious designs that address this issue. Our schemes leverage much of the gains of coded caching even for typical video files (around 10 GB). Furthermore, our work uncovers a deep relationship between this problem and combinatorial design theory which is branch of mathematics. The synergy between these fields has resulted in very interesting findings.\n\nThis project has supported the graduate education of several students who have gone on to successful careers in industry and academia, thus enhancing the workforce of the United States of America.\n\n\t\t\t\t\tLast Modified: 11/07/2021\n\n\t\t\t\t\tSubmitted by: Aditya Ramamoorthy"
 }
}