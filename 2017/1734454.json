{
 "awd_id": "1734454",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: INT: COLLAB: Robust, Scalable, Distributed Semantic Mapping for Search-and-Rescue and Manufacturing Co-Robots",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928074",
 "po_email": "jdonlon@nsf.gov",
 "po_sign_block_name": "James Donlon",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 395035.0,
 "awd_amount": 395035.0,
 "awd_min_amd_letter_date": "2017-08-03",
 "awd_max_amd_letter_date": "2017-08-03",
 "awd_abstract_narration": "The goal of this project is to enable multiple co-robots to map and understand the environment they are in to efficiently collaborate among themselves and with human operators in education, medical assistance, agriculture, and manufacturing applications. The first distinctive characteristic of this project is that the environment will be modeled semantically, that is, it will contain human-interpretable labels (e.g., object category names) in addition to geometric data. This will be achieved through a novel, robust integration of methods from both computer vision and robotics, allowing easier communications between robots and humans in the field. The second distinctive characteristic of this project is that the increased computation load due to the addition of human-interpretable information will be handled by judiciously approximating and spreading the computations across the entire network. The novel developed methods will be evaluated by emulating real-world scenarios in manufacturing and for search-and-rescue operations, leading to potential benefits for large segments of the society. The project will include opportunities for training students at the high-school, undergraduate, and graduate levels by promoting the development of marketable skills.\r\n\r\nThe project will advance the state of the art in robust semantic mapping from multiple robots by 1) developing a new optimization framework that can handle large, dynamic, uncertain environments under significant measurement errors, 2) explicitly allowing and studying interactions and information exchanges with humans with an hybrid discrete-continuous extension of the optimization framework, and 3) allowing an intelligent use and sharing of the limited computational resources possessed by the network of co-robots as a whole by enabling approximations and balancing of the computations. These developments will be driven by two particular case studies: a job-shop (small factory) scenario, where robots and fixed cameras are used to track and assist human workers during production and assembly of parts; and a classic search-and-rescue scenario, where operators use an heterogeneous team of robots to quickly assess damages and to discover survivors. These two applications, when considered together, highlight all the limitations of the currently prevalent geometric mapping solutions, and will be used as benchmarks for the project's results.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Roberto",
   "pi_last_name": "Tron",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Roberto Tron",
   "pi_email_addr": "tronroberto@gmail.com",
   "nsf_id": "000705272",
   "pi_start_date": "2017-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Trustees of Boston University",
  "inst_street_address": "1 SILBER WAY",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173534365",
  "inst_zip_code": "022151703",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "TRUSTEES OF BOSTON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "THL6A6JLE1S7"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of Boston University",
  "perf_str_addr": "881 Commonwealth Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "022151300",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 395035.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our project advanced the state of the art in building 3-D maps of environments while using semantic information and multiple robots. In particular, a large part of the project focused on how to use semantic information and the structure of the problem to identify and correct errors in the measurements, thus making our methods more robust and scalable.<br /><br />This general goal was specifically implemented in the following directions:</p>\n<ol>\n<li>We used automatic object detections to improve the recognition of situations where a robot re-visits a portion of the environment (this situation is called a loop closure).</li>\n<li>We provided new algorithms that identify multiple outliers using the natural redundancy of the measurements. When a robot revisits a location, this creates a loop (cycle) in the measurements. In this case, we can use the fact that the measurements along a loop should \"close\" (i.e., we know that the measurements, when accumulated along a loop, should indicate that the robot is near where it started); by considering this type of constraint along multiple loop, our algorithm infers whether any measurement along any of the loops is clearly wrong.</li>\n<li>In some situations, if there are not enough loop closures, it might be mathematically impossible to exactly identify outliers (e.g., if there are no loops, then our algorithm does not have any information that it could use). In our more theoretical work, we derived, for the first time, a method to analytically compute when (under some simplifying assumptions) outliers can be exactly identified, without knowing in advance where the outliers exactly are.</li>\n</ol>\n<p><br />We have also developed new techniques for coordinating the motion of multiple robots (e.g., drones) using images from on-board cameras.<br />In particular, we developed:</p>\n<ol>\n<li>Algorithms to detect other robots in camera images in real time.</li>\n<li>New ways to maneuver the robots into a cohesive formation while relying only on image detections and under a restricted field of view.</li>\n</ol>\n<p>Such teams of robots can be used to more efficiently collect the measurements that are then used in the map reconstruction algorithms developed in this project.<br /><br />Finally, we lay the foundations for further work on using machine learning in mapping by:</p>\n<ol>\n<li>Learning how to explore and environment while balancing the completeness and accuracy of the entire map.</li>\n<li>Predict an environment from partial incomplete measurements to move more directly toward specific goals (e.g., find an exit door in the minimum amount of time).</li>\n</ol>\n<p><br />The work above is complementary to the one performed by our collaborator Prof. Dario Pompili at Rutgers University (Award #1734362), with whom we developed new algorithms that use the maps and objects for interaction between humans and robots (where humans can place signs to direct the motion of the robots), and explore the environment to find targets of interest, by using adaptive computations and machine learning.<br /><br />In terms of educational impact, this project has involved two graduate students, three master students, and, in ancillary activities, three undergraduate students and a high school student. As part of this grant, PI Tron has introduced a new class \"Introduction to Robotics\" in the BU curriculum.<br />As broader impacts, the algorithms developed here have the potential of providing mapping solutions that are much more robust and can be therefore used at an industrial level. In particular, we have produced a new software package for mapping (pySLAM-D) that is currently being used by a company (Greensight Ltd., https://www.greensightag.com/) for their own projects.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/31/2021<br>\n\t\t\t\t\tModified by: Roberto&nbsp;Tron</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOur project advanced the state of the art in building 3-D maps of environments while using semantic information and multiple robots. In particular, a large part of the project focused on how to use semantic information and the structure of the problem to identify and correct errors in the measurements, thus making our methods more robust and scalable.\n\nThis general goal was specifically implemented in the following directions:\n\nWe used automatic object detections to improve the recognition of situations where a robot re-visits a portion of the environment (this situation is called a loop closure).\nWe provided new algorithms that identify multiple outliers using the natural redundancy of the measurements. When a robot revisits a location, this creates a loop (cycle) in the measurements. In this case, we can use the fact that the measurements along a loop should \"close\" (i.e., we know that the measurements, when accumulated along a loop, should indicate that the robot is near where it started); by considering this type of constraint along multiple loop, our algorithm infers whether any measurement along any of the loops is clearly wrong.\nIn some situations, if there are not enough loop closures, it might be mathematically impossible to exactly identify outliers (e.g., if there are no loops, then our algorithm does not have any information that it could use). In our more theoretical work, we derived, for the first time, a method to analytically compute when (under some simplifying assumptions) outliers can be exactly identified, without knowing in advance where the outliers exactly are.\n\n\n\nWe have also developed new techniques for coordinating the motion of multiple robots (e.g., drones) using images from on-board cameras.\nIn particular, we developed:\n\nAlgorithms to detect other robots in camera images in real time.\nNew ways to maneuver the robots into a cohesive formation while relying only on image detections and under a restricted field of view.\n\n\nSuch teams of robots can be used to more efficiently collect the measurements that are then used in the map reconstruction algorithms developed in this project.\n\nFinally, we lay the foundations for further work on using machine learning in mapping by:\n\nLearning how to explore and environment while balancing the completeness and accuracy of the entire map.\nPredict an environment from partial incomplete measurements to move more directly toward specific goals (e.g., find an exit door in the minimum amount of time).\n\n\n\nThe work above is complementary to the one performed by our collaborator Prof. Dario Pompili at Rutgers University (Award #1734362), with whom we developed new algorithms that use the maps and objects for interaction between humans and robots (where humans can place signs to direct the motion of the robots), and explore the environment to find targets of interest, by using adaptive computations and machine learning.\n\nIn terms of educational impact, this project has involved two graduate students, three master students, and, in ancillary activities, three undergraduate students and a high school student. As part of this grant, PI Tron has introduced a new class \"Introduction to Robotics\" in the BU curriculum.\nAs broader impacts, the algorithms developed here have the potential of providing mapping solutions that are much more robust and can be therefore used at an industrial level. In particular, we have produced a new software package for mapping (pySLAM-D) that is currently being used by a company (Greensight Ltd., https://www.greensightag.com/) for their own projects.\n\n\t\t\t\t\tLast Modified: 12/31/2021\n\n\t\t\t\t\tSubmitted by: Roberto Tron"
 }
}