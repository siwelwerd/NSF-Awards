{
 "awd_id": "1703281",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Medium: Collaborative Research: A Unified and Declarative Approach to Causal Analysis for Big Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 408000.0,
 "awd_amount": 408000.0,
 "awd_min_amd_letter_date": "2017-08-09",
 "awd_max_amd_letter_date": "2017-08-09",
 "awd_abstract_narration": "Observational data is available today in multi-relational form, often extracted from various sources, and stored in multiple flat and interrelated tables.  Standard statistical methods for conducting causal inference on observational data assume a very simple data model: a single table with independent units.  This research has the potential to significantly impact application domains where differentiating causality from correlation is essential, e.g., education policy and cancer genomics. The HUME project develops techniques for efficient causal analysis using a declarative approach, over complex views, and over large datasets that are integrated from disparate data sources.  HUME uses a SQL-like language and is integrated with a relational database system.\r\n\r\nThe project develops techniques for defining arbitrarily complex units, treatments, outcomes, and covariates, by combining joins, data mapping, and aggregates across multiple tables, and uses a causal network to choose a good set of covariates for causal inference.  The first part of the project develops scalable techniques for sub-classification and matching for large data sets obtained by declaratively integrating multiple data sources.  The second part of the project develops scalable methods for discovering causal relationships among the attributes in the views by constraint-based, search-based, and hybrid discovery processes. Finally, the third part of the project investigates interferences among units arising from the complex views by designing normal forms and automatic inference of underlying assumptions exploiting techniques from database theory.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dan",
   "pi_last_name": "Suciu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dan Suciu",
   "pi_email_addr": "suciu@cs.washington.edu",
   "nsf_id": "000218785",
   "pi_start_date": "2017-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981952350",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 408000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main goal of the project was to develop declarative approaches to enable easy and efficient causal analysis by specifying units, treatment, outcome, and covariates, over the integrated data, and declaring any underlying assumptions required in causal analysis using database view definitions.&nbsp; Causality is usually studied over independent and uniform units.&nbsp; However, in many situations, the units are connected by relationships; these relationships can be links in a social network, or author-paper relationships, or employee-employer relationships.&nbsp; In that case the outcomes for one unit may be affected through its relationships by the outcomes of other units.&nbsp; &nbsp;Figure 1 illustrates a collection of units and their relationships.&nbsp; This project has researched techniques and methods to allow causal inference over relational data, by assuming a much simpler relational representation, as suggested&nbsp; in Figure 2.&nbsp; &nbsp;The project had three major outcomes.</p>\n<p><br />First, we developed an experimental system, called HypDB, for removing bias (such as Simpson?s paradox) in OLAP queries.&nbsp; A SQL query, can often be biased and lead to incorrect decisions. HypDB detects, explains, and resolves bias in decision-support queries. We gave a simple definition of a biased query, which performs a set of independence tests on the data to detect bias, proposed a novel technique that explains the bias, thus assisting an analyst in understanding what goes on, and developed an automated method for rewriting a biased query into an unbiased query.</p>\n<p><br />Second, we developed Capuchin, a system that applies database repair techniques, in order to remove bias from training data. Capuchin discovers a causal model in the training data, reasons about how to modify that causal model in order to make it conform to a socially accepted notion of fairness, then repairs the training data by modifying it as little as possible in order to attain the new, corrected causal model. We developed the necessary theory based on causality theory and information theory, proposed two algorithms for database repair, and evaluated the system on several publicly available datasets, showing that, when training on the repaired data, the models will make decisions that are significantly more fair, according to several notions of fairness, yet achieve almost the same accuracy as models trained on the raw data.</p>\n<p><br />Finally, developed a system of causal inference in observational relational data. Although causal inference methods for ?observed data? (not from randomized controlled experiments) have been studied in Statistics and Artificial Intelligence, they rely on the critical assumption that the units of study are sampled from a population of homogeneous units; in other words, the data can be represented in a single flat table. However, many real-world data are available in ?relational? form in multiple related tables. Basic notions used in causal analysis, such as ?units?, no longer readily apply.&nbsp; For example the treatment may be applied to one table whereas the outcome may be observed in a different table.&nbsp; This makes causal inference in relational data more challenging. For this purpose, we developed a declarative framework, called CaRL (Causal Relational Langauge).&nbsp; The framework includes a declarative language to represent causal background knowledge and assumptions, a semantics for complex causal queries, and an algorithm for answering causal queries from the given relational data.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/18/2021<br>\n\t\t\t\t\tModified by: Dan&nbsp;Suciu</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1703281/1703281_10512901_1636419102816_dag-grounded--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1703281/1703281_10512901_1636419102816_dag-grounded--rgov-800width.jpg\" title=\"Fig 1: A grounded causal DAG\"><img src=\"/por/images/Reports/POR/2021/1703281/1703281_10512901_1636419102816_dag-grounded--rgov-66x44.jpg\" alt=\"Fig 1: A grounded causal DAG\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The outcomes of some units may affect the outcome of some other units.</div>\n<div class=\"imageCredit\">Salimi et al, Causal Relational Learning, 2020</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Dan&nbsp;Suciu</div>\n<div class=\"imageTitle\">Fig 1: A grounded causal DAG</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1703281/1703281_10512901_1636419220106_dag-relational--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1703281/1703281_10512901_1636419220106_dag-relational--rgov-800width.jpg\" title=\"Fig 2: A relational causal DAG\"><img src=\"/por/images/Reports/POR/2021/1703281/1703281_10512901_1636419220106_dag-relational--rgov-66x44.jpg\" alt=\"Fig 2: A relational causal DAG\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The relational causal DAG concisely describes multiple units and their interactions.</div>\n<div class=\"imageCredit\">Salimi et al, Causal Relational Learning, 2020</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Dan&nbsp;Suciu</div>\n<div class=\"imageTitle\">Fig 2: A relational causal DAG</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe main goal of the project was to develop declarative approaches to enable easy and efficient causal analysis by specifying units, treatment, outcome, and covariates, over the integrated data, and declaring any underlying assumptions required in causal analysis using database view definitions.  Causality is usually studied over independent and uniform units.  However, in many situations, the units are connected by relationships; these relationships can be links in a social network, or author-paper relationships, or employee-employer relationships.  In that case the outcomes for one unit may be affected through its relationships by the outcomes of other units.   Figure 1 illustrates a collection of units and their relationships.  This project has researched techniques and methods to allow causal inference over relational data, by assuming a much simpler relational representation, as suggested  in Figure 2.   The project had three major outcomes.\n\n\nFirst, we developed an experimental system, called HypDB, for removing bias (such as Simpson?s paradox) in OLAP queries.  A SQL query, can often be biased and lead to incorrect decisions. HypDB detects, explains, and resolves bias in decision-support queries. We gave a simple definition of a biased query, which performs a set of independence tests on the data to detect bias, proposed a novel technique that explains the bias, thus assisting an analyst in understanding what goes on, and developed an automated method for rewriting a biased query into an unbiased query.\n\n\nSecond, we developed Capuchin, a system that applies database repair techniques, in order to remove bias from training data. Capuchin discovers a causal model in the training data, reasons about how to modify that causal model in order to make it conform to a socially accepted notion of fairness, then repairs the training data by modifying it as little as possible in order to attain the new, corrected causal model. We developed the necessary theory based on causality theory and information theory, proposed two algorithms for database repair, and evaluated the system on several publicly available datasets, showing that, when training on the repaired data, the models will make decisions that are significantly more fair, according to several notions of fairness, yet achieve almost the same accuracy as models trained on the raw data.\n\n\nFinally, developed a system of causal inference in observational relational data. Although causal inference methods for ?observed data? (not from randomized controlled experiments) have been studied in Statistics and Artificial Intelligence, they rely on the critical assumption that the units of study are sampled from a population of homogeneous units; in other words, the data can be represented in a single flat table. However, many real-world data are available in ?relational? form in multiple related tables. Basic notions used in causal analysis, such as ?units?, no longer readily apply.  For example the treatment may be applied to one table whereas the outcome may be observed in a different table.  This makes causal inference in relational data more challenging. For this purpose, we developed a declarative framework, called CaRL (Causal Relational Langauge).  The framework includes a declarative language to represent causal background knowledge and assumptions, a semantics for complex causal queries, and an algorithm for answering causal queries from the given relational data.\n\n \n\n\t\t\t\t\tLast Modified: 11/18/2021\n\n\t\t\t\t\tSubmitted by: Dan Suciu"
 }
}