{
 "awd_id": "1718085",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Collaborative Research: 3D Audio Augmentation for Limited Field of View Augmented Reality Systems for Medical Training",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2024-02-29",
 "tot_intn_awd_amt": 299686.0,
 "awd_amount": 359605.0,
 "awd_min_amd_letter_date": "2017-08-29",
 "awd_max_amd_letter_date": "2023-03-08",
 "awd_abstract_narration": "Medical task simulators can provide a safe, affordable, and repeatable environment in which practitioners can rehearse procedures without impacting patient safety.  Augmented reality (AR) is therefore the ideal display technology in this field, allowing the user to directly interact and practice skills within a natural environment.  But current AR displays typically have a narrow field of view (FOV), which makes it difficult for users to immediately attend to an object outside of their periphery.  This research will employ 3D audio to overcome that challenge.  As a benefit to other AR and medical researchers, the system itself and other materials created for the present work (design, implementation, and tutorials) will be openly available on the project's website for all to use, modify, and contribute, and an open-source community will be created to link users and researchers who have similar interests as the present work.  Undergraduate, women, and minority students will be engaged in all project activities through the Distributed Research Experiences for Undergraduates (DREU) program of the NSF-funded iAAMCS (Institute for African-American Mentoring in Computing Sciences), as well as the PI's courses on 3D sound design.  Results will also be disseminated at relevant conference venues.  The present work will advance research relating to the use of 3D audio for cueing in narrow FOV contexts, thereby improving interaction in large AR environments, and will create generalizable best-practices that lead to successful experiences when using AR devices.  &#8232;\r\n\r\nThis research will develop the tools, methods, and infrastructure to evaluate how 3D sound can be used to enhance AR.  This area of research is increasingly important, because as virtual reality (VR) and AR systems become more commonplace, it is imperative to design tools to overcome device limitations.  The practical application of the proposed work will be realized through the evaluation of an AR-based prostate biopsy training procedure that will capture and reconstruct a full surgical procedure, with at least 3 dynamic participants in very close proximity.  The project will pursue three main themes: (1) Infrastructure Development - The PIs and team will develop an extensible open-source software system that allows users to test their desired sound mappings; (2) Sound Mapping Quantification - Although sound has been used to convey spatial information in numerous contexts, the appropriate strategy for mapping periphery information to spatial sound attributes has not yet been determined, so the PIs propose a series of user studies to determine the mappings that most successfully help a user to attend to a target outside of their FOV;  (3) Practical Application - To assess how well the proposed solution mitigates the challenge of a narrow FOV, a user study will be conducted to determine how the addition of 3D audio affects participants learning to perform the steps of a prostate biopsy procedure.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kyla",
   "pi_last_name": "McMullen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kyla McMullen",
   "pi_email_addr": "kyla@cise.ufl.edu",
   "nsf_id": "000634976",
   "pi_start_date": "2017-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326110001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 299686.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 59919.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-0d004c84-7fff-567a-070b-4625cb9e0224\"> </span></p>\n<p dir=\"ltr\"><span>This project makes contributions in three areas of interest to the public.&nbsp; The first contribution is the development of a novel means of classifying digital display systems, such as mixed and virtual reality systems.&nbsp; The taxonomy provides a visual means of classifying such digital display systems and can be easily interpreted by both consumers of electronics and researchers.&nbsp; It provides a reader with a way of understanding the expected visual experience if they were to use the system first hand.&nbsp; This gives increased understanding to consumers and a means of better advertising systems to companies. The second contribution is a means of improving psychological testing of spatial memory through the development of a &ldquo;holographic&rdquo; means of deploying spatial memory tests.&nbsp; This form of testing can improve researchers ability to understand and share test results, as well as improve the user interfaces of current and future applications by better understanding how well such interfaces impact retention of location information.&nbsp; The final area of contribution is the development of a &ldquo;holographic&rdquo; medical learning application for instructing students on how to perform an abdominal exam.&nbsp; Such an application serves as both an educational tool and a means to expand training to healthcare professionals.&nbsp; Such a tool can be used to improve patient outcomes and reduce training costs.</span></p><br>\n<p>\n Last Modified: 06/28/2024<br>\nModified by: Kyla&nbsp;Mcmullen</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1718085/1718085_10519156_1719596797398_MedAppPrototype--rgov-214x142.PNG\" original=\"/por/images/Reports/POR/2024/1718085/1718085_10519156_1719596797398_MedAppPrototype--rgov-800width.PNG\" title=\"Medical Application Prototype\"><img src=\"/por/images/Reports/POR/2024/1718085/1718085_10519156_1719596797398_MedAppPrototype--rgov-66x44.PNG\" alt=\"Medical Application Prototype\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Medical examination as viewed by user in the Hololens interface</div>\n<div class=\"imageCredit\">Dr. Terek Arce</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Kyla&nbsp;Mcmullen\n<div class=\"imageTitle\">Medical Application Prototype</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1718085/1718085_10519156_1719596937521_MR_CBT--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1718085/1718085_10519156_1719596937521_MR_CBT--rgov-800width.png\" title=\"Mixed-Reality Corsi Block Test\"><img src=\"/por/images/Reports/POR/2024/1718085/1718085_10519156_1719596937521_MR_CBT--rgov-66x44.png\" alt=\"Mixed-Reality Corsi Block Test\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Mixed Reality version of the Physical Corsi Block Test</div>\n<div class=\"imageCredit\">Dr. Terek Arce</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">Kyla&nbsp;Mcmullen\n<div class=\"imageTitle\">Mixed-Reality Corsi Block Test</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThis project makes contributions in three areas of interest to the public. The first contribution is the development of a novel means of classifying digital display systems, such as mixed and virtual reality systems. The taxonomy provides a visual means of classifying such digital display systems and can be easily interpreted by both consumers of electronics and researchers. It provides a reader with a way of understanding the expected visual experience if they were to use the system first hand. This gives increased understanding to consumers and a means of better advertising systems to companies. The second contribution is a means of improving psychological testing of spatial memory through the development of a holographic means of deploying spatial memory tests. This form of testing can improve researchers ability to understand and share test results, as well as improve the user interfaces of current and future applications by better understanding how well such interfaces impact retention of location information. The final area of contribution is the development of a holographic medical learning application for instructing students on how to perform an abdominal exam. Such an application serves as both an educational tool and a means to expand training to healthcare professionals. Such a tool can be used to improve patient outcomes and reduce training costs.\t\t\t\t\tLast Modified: 06/28/2024\n\n\t\t\t\t\tSubmitted by: KylaMcmullen\n"
 }
}