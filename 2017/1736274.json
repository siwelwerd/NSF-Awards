{
 "awd_id": "1736274",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: RUI: Uncovering the Neural Dynamics of Scene Categorization through Electroencephalography, Machine Learning, and Neuromodulation",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jonathan Fritz",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 304266.0,
 "awd_amount": 304266.0,
 "awd_min_amd_letter_date": "2017-06-29",
 "awd_max_amd_letter_date": "2017-06-29",
 "awd_abstract_narration": "A long-standing problem in cognitive neuroscience is understanding how we can categorize a novel scene in about the same amount of time that it takes to blink one's eyes. Categorization aids both identifying objects and locating them in cluttered scenes, and thus allows for intelligent action in the world. How do we derive semantically meaningful categories from the raw image pixels? Currently, there is experimental support for multiple mechanisms supporting scene categorization, such as through recognizing the scene's objects or other visual features such as spatial layout, color, or texture. Crucially, substantial correlations exist between all of these proposed features. This make it difficult to disentangle their relative contributions to categorization. For example, if two scenes share an object, they will often also share the texture features associated with that object. In this work, the PI (Dr. Bruce C Hansen, Colgate University) and co-PI (Dr. Michelle R Greene, Bates College) seek to disentangle the contribution of such features, and also to determine when these features become available for use, and how they combine to support scene categorization. By understanding the temporal dynamics of the brain activity related to scene categorization, it will be possible to obtain critical insights into how people rapidly but flexibly extract information from the environment. This work forms a bridge across several disciplines including psychology, cognitive neuroscience, computer vision, and machine learning. As such, the project will engage undergraduate students in truly interdisciplinary training that is at the cutting edge of multiple fields.\r\n\r\nThis project will make use of high-density EEG combined with machine learning, computational modeling behavioral measures, and advanced neuromodulation to determine how and when the behaviorally relevant features support scene categorization. First, the work will link the encoding of these features to visual event related potentials (vERPs) and also to category information using multivariate classification techniques from machine learning. Taken together, these techniques will allow the PIs to determine the unique contributions of each feature to category-related brain activity over time. A hallmark of intelligent action is flexibility. Therefore, the project will also investigate the flexibility of feature use by manipulating the diagnosticity of information available to observers. These studies will provide insights regarding feature space usage as a function of task demands, as well as the impact of such demands on the time course of feature space availability as indexed by vERPs. Lastly, the project will test for a potential causal role of vERPs to categorization through the use of advanced neuromodulation techniques.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michelle",
   "pi_last_name": "Greene",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Michelle R Greene",
   "pi_email_addr": "mgreene@barnard.edu",
   "nsf_id": "000742245",
   "pi_start_date": "2017-06-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Bates College",
  "inst_street_address": "2 ANDREWS ROAD",
  "inst_street_address_2": "",
  "inst_city_name": "LEWISTON",
  "inst_state_code": "ME",
  "inst_state_name": "Maine",
  "inst_phone_num": "2077868375",
  "inst_zip_code": "042406030",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "ME02",
  "org_lgl_bus_name": "PRESIDENT AND TRUSTEES OF BATES COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "D77HU977E973"
 },
 "perf_inst": {
  "perf_inst_name": "Bates College",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "ME",
  "perf_st_name": "Maine",
  "perf_zip_code": "042406030",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "ME02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169900",
   "pgm_ele_name": "Cognitive Neuroscience"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1699",
   "pgm_ref_txt": "COGNEURO"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9229",
   "pgm_ref_txt": "RES IN UNDERGRAD INST-RESEARCH"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 304266.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>A long-standing problem in cognitive neuroscience is in understanding how we can categorize a novel scene in about the same amount of time that it takes to blink one's eyes. Categorization aids both object recognition and visual search, and thus allows for intelligent action in the world. How do we go from the uninformative pixels of an image to a semantically meaningful category? In an ideal world, we would examine all possible hypothesized features, mapping them to brain activity over time. In practice, this is difficult because some features are strongly related to one another, making it difficult to assess each feature&rsquo;s contribution to brain activity. In this work, we solved this problem statistically, using a matrix whitening procedure. This allows us to decorrelate features while still retaining their original interpretations. We found that categorization proceeds from relatively low-level features that are computable from images to high-level features that require human supervision. Critically, only the high-level features were also correlated with subsequent human behavior. Finally, we found that changing both the observer&rsquo;s task and the local experimental context also changed feature usage. Thus, were able to test <em>when</em> these features become available for use and <em>how</em> they combine to support scene categorization. By understanding the temporal dynamics of the brain activity related to scene categorization, we gain insights into how we rapidly but flexibly extract information from the environment. This work forms a natural bridge across several disciplines including psychology, cognitive neuroscience, computer vision, and machine learning. As such it provided critical 21<sup>st</sup> century training for undergraduate students in neuroscience, computer science, and cognitive psychology.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/28/2022<br>\n\t\t\t\t\tModified by: Michelle&nbsp;R&nbsp;Greene</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nA long-standing problem in cognitive neuroscience is in understanding how we can categorize a novel scene in about the same amount of time that it takes to blink one's eyes. Categorization aids both object recognition and visual search, and thus allows for intelligent action in the world. How do we go from the uninformative pixels of an image to a semantically meaningful category? In an ideal world, we would examine all possible hypothesized features, mapping them to brain activity over time. In practice, this is difficult because some features are strongly related to one another, making it difficult to assess each feature\u2019s contribution to brain activity. In this work, we solved this problem statistically, using a matrix whitening procedure. This allows us to decorrelate features while still retaining their original interpretations. We found that categorization proceeds from relatively low-level features that are computable from images to high-level features that require human supervision. Critically, only the high-level features were also correlated with subsequent human behavior. Finally, we found that changing both the observer\u2019s task and the local experimental context also changed feature usage. Thus, were able to test when these features become available for use and how they combine to support scene categorization. By understanding the temporal dynamics of the brain activity related to scene categorization, we gain insights into how we rapidly but flexibly extract information from the environment. This work forms a natural bridge across several disciplines including psychology, cognitive neuroscience, computer vision, and machine learning. As such it provided critical 21st century training for undergraduate students in neuroscience, computer science, and cognitive psychology.\n\n\t\t\t\t\tLast Modified: 11/28/2022\n\n\t\t\t\t\tSubmitted by: Michelle R Greene"
 }
}