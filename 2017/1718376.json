{
 "awd_id": "1718376",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: RUI: Benchmarks and Algorithms for Mobile Image Matching",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 299968.0,
 "awd_amount": 299968.0,
 "awd_min_amd_letter_date": "2017-07-25",
 "awd_max_amd_letter_date": "2017-07-25",
 "awd_abstract_narration": "This project will provide both new benchmarks and new algorithms for the mobile image matching domain.  In order to drive and focus new research on mobile image matching, the existing Middlebury benchmarks will be augmented with new datasets of calibrated multiview and video sequences acquired with mobile devices, together with ground-truth geometry. The project will also contribute novel algorithmic approaches for robust and scalable image matching. Undergraduate students will be actively involved in all components of this project, in particular in the data acquisition and testing stages, as well as the authoring of online evaluation tools. The project will have several broader impacts.  First, challenging benchmarks will serve as catalysts for new research.  High-quality datasets are also useful beyond benchmarking in that they can aid algorithm design and enable learning approaches.  Second, scalable and robust matching techniques tailored for mobile devices will enable a host of new applications with broad impacts on the population at large, including interactive 3D modeling of objects and people for social media, online commerce, and augmented and virtual reality.  Finally, the project will expose undergraduates at a liberal-arts college in rural Vermont to the world of research, experimentation, and discovery.\r\n\r\nThis project will augment the existing Middlebury datasets with calibrated multi-view and video sequences acquired with mobile devices from a robot arm, of challenging scenes with known geometry, derived using structured lighting.  Datasets will include IMU data and flash/no-flash image pairs.  The project will also explore novel evaluation metrics as well as the utilization of high-quality synthetic image sequences.  A subset of the new datasets will be employed in new benchmarks for mobile 3D reconstructions tasks. The algorithmic work will contribute novel approaches for robust and scalable image matching.  While the current trend in the community is to learn general models from large sets of labeled training data, this project will instead aim to learn data terms from the images at hand during the matching process.  Such self-adjusting data terms will model radiometric and geometric distortions rather than being invariant to them.  Another focus will be on memory-efficient approaches that avoid an exhaustive search of the full matching space while explicitly reasoning about occlusion, reflections, and transparency.  Additional algorithmic techniques will include layer-based image matching algorithms, novel smoothness terms suitable for fast and scalable image matching, and novel strategies for dealing with completely textureless scenes.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Scharstein",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel Scharstein",
   "pi_email_addr": "schar@middlebury.edu",
   "nsf_id": "000122299",
   "pi_start_date": "2017-07-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Middlebury College",
  "inst_street_address": "9 OLD CHAPEL RD",
  "inst_street_address_2": "",
  "inst_city_name": "MIDDLEBURY",
  "inst_state_code": "VT",
  "inst_state_name": "Vermont",
  "inst_phone_num": "8024435000",
  "inst_zip_code": "057536000",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "VT00",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF MIDDLEBURY COLLEGE",
  "org_prnt_uei_num": "N1ACHB9PNN93",
  "org_uei_num": "N1ACHB9PNN93"
 },
 "perf_inst": {
  "perf_inst_name": "Middlebury College",
  "perf_str_addr": "Dept of Computer Science",
  "perf_city_name": "Middlebury",
  "perf_st_code": "VT",
  "perf_st_name": "Vermont",
  "perf_zip_code": "057536000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "VT00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 299968.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The \"mobile revolution\" has vastly changed both the computational landscape and the image acquisition paradigm, allowing us to take high-quality, high-resolution images with mobile phones that offer significant computing power.&nbsp; The goal of this project was to advance stereo vision research by creating new datasets for mobile image matching and developing novel algorithms for robust and scalable image matching.&nbsp; The project was highly successful and has yielded both novel datasets and algorithms.<br /> <br /> The intellectual merits of the project include novel techniques for dataset creation and novel stereo algorithms.&nbsp; Broader impacts include the catalytic effect of new datasets on stereo research, the improved applicability of stereo methods for real-world applications benefiting the population at large, and exposing undergraduates at a liberal-arts college in rural Vermont to the world of research.<br /> <br /> One major contribution of the project is a new collection of mobile stereo datasets taken captured with a mobile device mounted on a robot arm.&nbsp; The custom capturing system was built by undergraduate researchers.&nbsp; The new datasets consist of 11 scenes observed from 1-3 viewing directions, for a total of 24 stereo datasets.&nbsp; Each dataset includes floating-point ground-truth disparity maps obtained using structured lighting.&nbsp; All input images are available with multiple different exposure and lighting settings, including flash and \"torch\" illumination by the phone, to allow the evaluation of radiometric changes, low-light scenarios, and flash / no-flash approaches.<br /> <br /> As part of a sabbatical collaboration with researchers at the Max Planck Institute Tuebingen, Germany, the project also contributed to a new multiview dataset depicting humans interacting with real environments, including posed 3D body meshes with scene contact labels and accurate laser scans of the scene geometry.<br /> <br /> The project contributed also novel algorithms for robust online stereo calibration as well as a multi-frame stereo algorithm employing edges, planes, and superpixels.<br /> <br /> The stereo vision research projects conducted as part of this project have had a vital impact on undergraduate computer science education at Middlebury, and have further contributed to the development of human resources in science and engineering.&nbsp; Six undergraduates were funded as research assistants to work on various components of the project.&nbsp; The Universal UR5 robot arm purchased for this project is a significant new resource for future courses and student projects.<br /> <br /> In summary, the project was highly successful.&nbsp; Its intellectual merit spans dataset creation and algorithmic contributions.&nbsp; The project also had significant broader impact along several avenues.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/28/2021<br>\n\t\t\t\t\tModified by: Daniel&nbsp;Scharstein</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe \"mobile revolution\" has vastly changed both the computational landscape and the image acquisition paradigm, allowing us to take high-quality, high-resolution images with mobile phones that offer significant computing power.  The goal of this project was to advance stereo vision research by creating new datasets for mobile image matching and developing novel algorithms for robust and scalable image matching.  The project was highly successful and has yielded both novel datasets and algorithms.\n \n The intellectual merits of the project include novel techniques for dataset creation and novel stereo algorithms.  Broader impacts include the catalytic effect of new datasets on stereo research, the improved applicability of stereo methods for real-world applications benefiting the population at large, and exposing undergraduates at a liberal-arts college in rural Vermont to the world of research.\n \n One major contribution of the project is a new collection of mobile stereo datasets taken captured with a mobile device mounted on a robot arm.  The custom capturing system was built by undergraduate researchers.  The new datasets consist of 11 scenes observed from 1-3 viewing directions, for a total of 24 stereo datasets.  Each dataset includes floating-point ground-truth disparity maps obtained using structured lighting.  All input images are available with multiple different exposure and lighting settings, including flash and \"torch\" illumination by the phone, to allow the evaluation of radiometric changes, low-light scenarios, and flash / no-flash approaches.\n \n As part of a sabbatical collaboration with researchers at the Max Planck Institute Tuebingen, Germany, the project also contributed to a new multiview dataset depicting humans interacting with real environments, including posed 3D body meshes with scene contact labels and accurate laser scans of the scene geometry.\n \n The project contributed also novel algorithms for robust online stereo calibration as well as a multi-frame stereo algorithm employing edges, planes, and superpixels.\n \n The stereo vision research projects conducted as part of this project have had a vital impact on undergraduate computer science education at Middlebury, and have further contributed to the development of human resources in science and engineering.  Six undergraduates were funded as research assistants to work on various components of the project.  The Universal UR5 robot arm purchased for this project is a significant new resource for future courses and student projects.\n \n In summary, the project was highly successful.  Its intellectual merit spans dataset creation and algorithmic contributions.  The project also had significant broader impact along several avenues.\n\n \n\n\t\t\t\t\tLast Modified: 11/28/2021\n\n\t\t\t\t\tSubmitted by: Daniel Scharstein"
 }
}