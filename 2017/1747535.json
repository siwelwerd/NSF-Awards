{
 "awd_id": "1747535",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Exploratory Research on Deriving Flight Information from Drone Imagery for Safety Compliance",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2018-01-01",
 "awd_exp_date": "2020-12-31",
 "tot_intn_awd_amt": 199373.0,
 "awd_amount": 205373.0,
 "awd_min_amd_letter_date": "2017-08-13",
 "awd_max_amd_letter_date": "2019-06-17",
 "awd_abstract_narration": "Recreational drone use is increasing rapidly in the United States. The Federal Aviation Administration (FAA) has established safety regulations such as flying too high, too fast, in restricted areas, etc. but there is no way to detect violations on a large scale. Further, drone users are unaware of or unconcerned about the regulations since they are self-enforced.  Drone users upload large amounts of imagery to the Internet including that from flights which violate the safety regulations. This imagery is often the only evidence of the flights and so an interesting research question is whether image analysis can be used to detect violations from the flight imagery alone. The overarching goal of this project is an automated method to identify specific instances of violations in the large amounts of drone imagery available on the Internet. This would provide valuable information regarding the extent to which the regulations are being violated. It could also be used to pursue specific violators. The project will be done in collaboration with the University of California Center of Excellence on Unmanned Aerial Systems (UAS) Safety (http://uassafety.ucmerced.edu/). This Center provides expertise, support, and training for regulatory compliance, risk management, and the safe operation of UAS across the ten campus UC system.\r\n\r\nDetecting whether a flight is above the 400 ft limit specified by the FAA will serve as a proof-of-concept. A two-step process will first estimate the spatial resolution (i.e., meters per pixel) of the imagery and then use knowledge or estimates of the camera specifications to compute the height. If successful, the proof-of-concept can be extended to other violations such as flying too fast, above crowds, in poor visibility, etc. Estimating the spatial resolution and height of overhead imagery are novel problems, and the proposed approach is novel, challenging and risky. The project stands to make significant gains. There is currently no way to detect violations on a large scale and so this would be the first solution to this increasingly important problem. And, a broad range of drone image analysis problems beyond height estimation would benefit from knowing the spatial resolution.  Results, datasets, and other project artifacts will be made available through the project website.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shawn",
   "pi_last_name": "Newsam",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shawn Newsam",
   "pi_email_addr": "snewsam@ucmerced.edu",
   "nsf_id": "000458548",
   "pi_start_date": "2017-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California - Merced",
  "inst_street_address": "5200 N LAKE RD",
  "inst_street_address_2": "",
  "inst_city_name": "MERCED",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2092012039",
  "inst_zip_code": "953435001",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "CA13",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, MERCED",
  "org_prnt_uei_num": "",
  "org_uei_num": "FFM7VPAG8P92"
 },
 "perf_inst": {
  "perf_inst_name": "University of California - Merced",
  "perf_str_addr": "5200 North Lake Road",
  "perf_city_name": "Merced",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "953435001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "CA13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 199373.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 6000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Recreational drone use is increasing rapidly in the United States. The Federal Aviation Administration (FAA) has established safety regulations such as flying too high, too fast, in restricted areas, etc. but there is no way to detect violations on a large scale. Oftentimes, images acquired during a flight are the only artifacts remaining and so this exploratory project investigates ways to automatically extract information from the images that could help understand whether drones are following safety regulations. One key property of overhead images that can help with a number of downstream tasks is the spatial resolution of the image (the distance spanned on the ground spanned by a pixel). While this is generally known for standard overhead imagery, acquired for example from satellites, it is usually not known for drone images. Knowing the spatial resolution can inform tasks such as estimating the height that the image was taken from, detecting objects towards understanding if the drone was flying over crowds, and others.</p>\n<p>The project developed two approaches to estimating the spatial resolution of overhead images. A bottom-up approach in which the relationship between spatial resolution and general image patterns is learned from a training set. The second approach is top-down and uses an existing object detector to find objects with approximately known size (such as cars) and uses the size of the detections to derive the spatial resolution. The project involved acquiring images by flying a drone at known heights. This turned out to present some logistical challenges since there are still a lot of restrictions on drone usage.</p>\n<p>Automatically estimating the spatial resolution of overhead imagery is a novel problem and this project was the first to investigate it. The framework has applications beyond drone image analysis. Collections of historical overhead imagery often do not have meta-data including as spatial resolution. Automatically deriving this meta-data can help with the automated analysis of these collections. And, overhead images are often made available on the internet without meta-data.</p>\n<p>The project had significant educational benefits for a PhD student and an undergraduate student. The PhD student developed research skills such as paper writing and giving presentations. This has helped prepare the student to contribute to the scientific and research enterprise of the Nation after they graduate. The undergraduate student was from an underrepresented group in STEM. The project helped this student prepare for a career in the computer industry.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/28/2021<br>\n\t\t\t\t\tModified by: Shawn&nbsp;Newsam</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nRecreational drone use is increasing rapidly in the United States. The Federal Aviation Administration (FAA) has established safety regulations such as flying too high, too fast, in restricted areas, etc. but there is no way to detect violations on a large scale. Oftentimes, images acquired during a flight are the only artifacts remaining and so this exploratory project investigates ways to automatically extract information from the images that could help understand whether drones are following safety regulations. One key property of overhead images that can help with a number of downstream tasks is the spatial resolution of the image (the distance spanned on the ground spanned by a pixel). While this is generally known for standard overhead imagery, acquired for example from satellites, it is usually not known for drone images. Knowing the spatial resolution can inform tasks such as estimating the height that the image was taken from, detecting objects towards understanding if the drone was flying over crowds, and others.\n\nThe project developed two approaches to estimating the spatial resolution of overhead images. A bottom-up approach in which the relationship between spatial resolution and general image patterns is learned from a training set. The second approach is top-down and uses an existing object detector to find objects with approximately known size (such as cars) and uses the size of the detections to derive the spatial resolution. The project involved acquiring images by flying a drone at known heights. This turned out to present some logistical challenges since there are still a lot of restrictions on drone usage.\n\nAutomatically estimating the spatial resolution of overhead imagery is a novel problem and this project was the first to investigate it. The framework has applications beyond drone image analysis. Collections of historical overhead imagery often do not have meta-data including as spatial resolution. Automatically deriving this meta-data can help with the automated analysis of these collections. And, overhead images are often made available on the internet without meta-data.\n\nThe project had significant educational benefits for a PhD student and an undergraduate student. The PhD student developed research skills such as paper writing and giving presentations. This has helped prepare the student to contribute to the scientific and research enterprise of the Nation after they graduate. The undergraduate student was from an underrepresented group in STEM. The project helped this student prepare for a career in the computer industry.\n\n\t\t\t\t\tLast Modified: 04/28/2021\n\n\t\t\t\t\tSubmitted by: Shawn Newsam"
 }
}