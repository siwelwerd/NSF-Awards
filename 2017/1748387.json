{
 "awd_id": "1748387",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Leveraging Synthetic Data for Visual Reasoning and Representation Learning with Minimal Human Supervision",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2017-08-15",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2017-08-15",
 "awd_max_amd_letter_date": "2017-08-15",
 "awd_abstract_narration": "This project investigates how synthetic data created using computer graphics can be used for developing algorithms that understand visual data. Synthetic data provides flexibility that is difficult to obtain with real-world imagery, and enables opportunities to explore problems that would be difficult to solve with real-world imagery alone. This project develops new algorithms for reasoning about object occlusions, and for self-supervised representation learning, in which useful image features are developed without the aid of human-annotated semantic labels. The project provides new algorithms that have the potential to benefit applications in autonomous systems and security. In addition to scientific impact, the project performs complementary educational and outreach activities that engage students in research and STEM.\r\n\r\nThis research explores novel algorithms that learn from synthetic data for visual reasoning and representation learning. While the use of synthetic data has a long history in computer vision, it has mainly been used to complement natural image data to solve standard tasks. In contrast, this project uses synthetic data to make advances in relatively unexplored problems, in which ground-truth is difficult to obtain given real-world imagery. The project consists of three major thrusts, each of which exploits the fact that a user has full control of everything that happens in a synthetic dataset. In Thrust I, it investigates a novel approach to representation learning using synthetic data, and in Thrust II, it extends the algorithm to disentangle task-specific and general-purpose features. Finally, in Thrust III, it explores a novel approach for reasoning about object occlusions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yong Jae",
   "pi_last_name": "Lee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yong Jae Lee",
   "pi_email_addr": "yongjaelee@cs.wisc.edu",
   "nsf_id": "000678292",
   "pi_start_date": "2017-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Davis",
  "perf_str_addr": "One Shields Ave",
  "perf_city_name": "Davis",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956165200",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this research project was to explore the use of synthetic visual data for visual scene understanding. In synthetic data, the various properties of objects, scenes, lighting, physics, etc. are fully controllable. The main idea was to create algorithms that can leverage this property for improved visual recognition. As part of this goal, we investigated novel discriminative approaches for leveraging synthetic data to learn robust visual representations,&nbsp;and novel generative approaches for generating realistic synthetic image and video data.</p>\n<p>In terms of intellectual merit, there are three key areas of technical contributions. The first is the development of novel generative models that can learn disentangled representations with minimal supervision; specifically, learning to disentangle background, object shape, appearance, and pose for controllable synthetic image generation. The second is the development of novel weakly-supervised&nbsp;visual learning approaches that leverage synthetic data and external&nbsp;knowledge bases for representation learning and object detection.&nbsp;The third is the development of new approaches for privacy and security applications,&nbsp;including a video anonymizer and fake credit card synthesis and analysis method.&nbsp;<span>The work produced 10 peer reviewed papers in top-tier computer vision, machine learning, and security conferences, and new</span><span>&nbsp;publicly available codebases for the algorithms which are linked from&nbsp;</span>https://www.cs.ucdavis.edu/~yjlee/<span>. The research results were also regularly presented by the PI at international meetings and university seminars.</span></p>\n<p>In terms of broader impact, the main project outcomes are graduate and undergraduate student mentorship and training, outreach activities to promote wider participation of young students in CS and STEM education, and broad scientific impact of the algorithms. In particular, the project helped train PhD, MS, and undergraduate students in conducting and presenting&nbsp;research in the topics of this project. One PhD student completed his PhD and four non-student researchers accepted new PhD and research industry positions. The project's outreach component contributed to efforts that widen&nbsp;middle school and high school student participation in STEM.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/27/2020<br>\n\t\t\t\t\tModified by: Yong Jae&nbsp;Lee</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this research project was to explore the use of synthetic visual data for visual scene understanding. In synthetic data, the various properties of objects, scenes, lighting, physics, etc. are fully controllable. The main idea was to create algorithms that can leverage this property for improved visual recognition. As part of this goal, we investigated novel discriminative approaches for leveraging synthetic data to learn robust visual representations, and novel generative approaches for generating realistic synthetic image and video data.\n\nIn terms of intellectual merit, there are three key areas of technical contributions. The first is the development of novel generative models that can learn disentangled representations with minimal supervision; specifically, learning to disentangle background, object shape, appearance, and pose for controllable synthetic image generation. The second is the development of novel weakly-supervised visual learning approaches that leverage synthetic data and external knowledge bases for representation learning and object detection. The third is the development of new approaches for privacy and security applications, including a video anonymizer and fake credit card synthesis and analysis method. The work produced 10 peer reviewed papers in top-tier computer vision, machine learning, and security conferences, and new publicly available codebases for the algorithms which are linked from https://www.cs.ucdavis.edu/~yjlee/. The research results were also regularly presented by the PI at international meetings and university seminars.\n\nIn terms of broader impact, the main project outcomes are graduate and undergraduate student mentorship and training, outreach activities to promote wider participation of young students in CS and STEM education, and broad scientific impact of the algorithms. In particular, the project helped train PhD, MS, and undergraduate students in conducting and presenting research in the topics of this project. One PhD student completed his PhD and four non-student researchers accepted new PhD and research industry positions. The project's outreach component contributed to efforts that widen middle school and high school student participation in STEM.\n\n \n\n\t\t\t\t\tLast Modified: 11/27/2020\n\n\t\t\t\t\tSubmitted by: Yong Jae Lee"
 }
}