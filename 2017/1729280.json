{
 "awd_id": "1729280",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Econometric Methods for Models with Covariate Adaptive Randomization and Partial Identification",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927280",
 "po_email": "nlutz@nsf.gov",
 "po_sign_block_name": "Nancy Lutz",
 "awd_eff_date": "2017-08-15",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 163770.0,
 "awd_amount": 163770.0,
 "awd_min_amd_letter_date": "2017-06-19",
 "awd_max_amd_letter_date": "2017-07-25",
 "awd_abstract_narration": "This research develops new econometric methods to address two types of problems recently faced by applied researchers in several areas of economics and other social sciences. First, development economists often employ randomized control experiments using covariate adaptive randomization to \"balance\" the impact of the underlying observed covariates. Standard inference methods are typically used in this setting, but they can produce invalid results. In light of this, the first part of the research develops novel inference methods that are both valid and easy to implement. Second, partially identified models have been widely used in labor economics and industrial organization to incorporate missing data or multiplicity of equilibria, but the literature has not adequately addressed how to test the validity of a subset of the moment conditions. The second part of the research thus develops a new method to address this problem. In particular, the hypothesis test considered in this project can be also used to evaluate whether a certain instrumental variable is valid or not in a model with moment equalities and inequalities.\r\n\r\nThis research develops new theories and methods for analyzing two econometric models. The first two projects study inference on the average treatment effect in randomized control experiments that use covariate adaptive randomization. The first project considers experiments in which there are multiple treatments, and the assignment is not necessarily evenly distributed among the control and the treatment groups. The project proposes regression-based inference methods that are shown to be valid, to have excellent power properties, and to be easy to implement. The second project considers experiments with assignment occurring at a group or cluster level, e.g., classroom, village, etc. The statistical dependence among individuals within each group requires developing new methodologies. Finally, the third project considers an inference problem in a partially identified model defined by moment equalities and inequalities. In this context, the goal is to test the validity of a subset of the moment conditions, while maintaining the validity of the remaining ones. This project develops a new bootstrap-based method that is shown to be valid and has good power properties.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Federico",
   "pi_last_name": "Bugni",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Federico Bugni",
   "pi_email_addr": "federico.bugni@northwestern.edu",
   "nsf_id": "000571420",
   "pi_start_date": "2017-06-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "419 Chapel Dr",
  "perf_city_name": "Durham",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277080097",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132000",
   "pgm_ele_name": "Economics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1320",
   "pgm_ref_txt": "ECONOMICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 163770.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this grant was to develop new theories and methods for analyzing two econometric models: (i) randomized control experiments that use covariate adaptive randomization and (ii) partially identified models defined by moment equalities and inequalities. As a natural evolution of my research agenda, I have expanded my research scope to other frameworks in economics, such as dynamic discrete choice models.</p>\n<p>The first set of projects in this grant considers inference in randomized control experiments (RCEs) that use covariate adaptive randomization (CAR). RCEs are routinely used in development economics to study the treatment effect of a certain policy intervention (e.g., a cash transfer, a dietary supplement, etc.) on the individuals in the economy. Before randomly assigning individuals to either treatment or control, researchers typically collect extensive information on these individuals, such as age, ethnicity, etc. To control the effect of these covariates, researchers routinely use CAR, i.e., a treatment assignment mechanism that randomizes individuals into treatment or control groups taking into account their underlying covariate information. Once the experiment is completed, the researcher runs linear regressions to estimate the policy's average treatment effect. The objective of my research projects in this area is to understand the impact of using CAR on the standard errors of the estimated coefficients in these regressions.</p>\n<p>In &ldquo;Inference under Covariate-Adaptive Randomization with Multiple Treatments&rdquo;, joint with Ivan Canay and Azeem Shaikh, we investigate RCEs with CAR in which there are multiple possible treatments, which is common in applications. We show that the estimated standard errors typically used in practice can be inconsistent, and we provide new estimated standard errors that correct this problem. As a result, our paper provides simple regression-based methods to conduct inference in these settings. In &ldquo;Inference under Covariate-Adaptive Randomization with Imperfect Compliance&rdquo;, joint with Mengsi Gao, we consider RCEs with CAR in which individuals who participate in the experiment may choose not to comply with the treatment assigned by the researcher. This is also common in some experiments, as the individuals who participate in these experiments can often decide whether or not to accept a proposed treatment. This paper studies how the combination of CAR and imperfect compliance affects the standard errors of the estimated coefficients in the regressions described earlier. As in the previous project, we confirm that the estimated standard errors that are often used in practice can be inconsistent, and we provide new estimated standard errors that fix this issue. Both papers described in this paragraph are complemented by software that implements the new proposed standard errors.</p>\n<p>The next project in this grant considers inference in a partially identified model. A model is partially identified when the sampling process and the maintained assumptions restrict the value of the parameter of interest to a set, called the identified set, which is smaller than the logical range of the parameter but potentially larger than a single value. Partially identified models arise naturally in economic models when strong assumptions are traded by weaker ones. Since their introduction, partially identified models have become increasingly popular in several areas in economics, such as industrial organization, trade, and labor economics, as well as in other social sciences.</p>\n<p>The standard framework for partially identified models in economics is the so-called moment (in)equality model. In this model, the parameter vector of interest is constrained by a collection of moment inequalities and equalities. This is the framework used in &ldquo;Subvector Inference in Partially Identified Models with Many Moment Inequalities&rdquo;, joint with Alexandre Belloni and Victor Chernozhukov. As the title suggests, this paper considers two important challenges that appear in empirical applications. First, we allow for the number of moment conditions to be very large, possibly larger than the sample size. Second, we consider a researcher interested in learning about a single coordinate of the unknown parameter vector, perhaps related to a treatment effect or a policy variable of interest. This is known in the literature as the &ldquo;subvector inference problem&rdquo;. In our paper, we propose confidence sets that result from comparing a profiled &ldquo;MinMax&rdquo; test statistic with either bootstrap-based or self-normalized critical values. The bootstrap-based critical value is more challenging to compute than the self-normalized one, but leads to a higher statistical power. Using novel approximation arguments, we show that our proposed confidence sets are uniformly valid for a large class of data generating processes.</p>\n<p>The research projects covered in this grant pertain to two different econometric models with distinct empirical applications. The common thread in these projects is that they provide new econometric tools to address practical problems currently faced by applied researchers in economics and other social sciences. The results related to this grant have been presented in numerous seminars and conferences. Finally, these projects have influenced the research of several graduate students at Duke University and other institutions.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/10/2020<br>\n\t\t\t\t\tModified by: Federico&nbsp;Bugni</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this grant was to develop new theories and methods for analyzing two econometric models: (i) randomized control experiments that use covariate adaptive randomization and (ii) partially identified models defined by moment equalities and inequalities. As a natural evolution of my research agenda, I have expanded my research scope to other frameworks in economics, such as dynamic discrete choice models.\n\nThe first set of projects in this grant considers inference in randomized control experiments (RCEs) that use covariate adaptive randomization (CAR). RCEs are routinely used in development economics to study the treatment effect of a certain policy intervention (e.g., a cash transfer, a dietary supplement, etc.) on the individuals in the economy. Before randomly assigning individuals to either treatment or control, researchers typically collect extensive information on these individuals, such as age, ethnicity, etc. To control the effect of these covariates, researchers routinely use CAR, i.e., a treatment assignment mechanism that randomizes individuals into treatment or control groups taking into account their underlying covariate information. Once the experiment is completed, the researcher runs linear regressions to estimate the policy's average treatment effect. The objective of my research projects in this area is to understand the impact of using CAR on the standard errors of the estimated coefficients in these regressions.\n\nIn \"Inference under Covariate-Adaptive Randomization with Multiple Treatments\", joint with Ivan Canay and Azeem Shaikh, we investigate RCEs with CAR in which there are multiple possible treatments, which is common in applications. We show that the estimated standard errors typically used in practice can be inconsistent, and we provide new estimated standard errors that correct this problem. As a result, our paper provides simple regression-based methods to conduct inference in these settings. In \"Inference under Covariate-Adaptive Randomization with Imperfect Compliance\", joint with Mengsi Gao, we consider RCEs with CAR in which individuals who participate in the experiment may choose not to comply with the treatment assigned by the researcher. This is also common in some experiments, as the individuals who participate in these experiments can often decide whether or not to accept a proposed treatment. This paper studies how the combination of CAR and imperfect compliance affects the standard errors of the estimated coefficients in the regressions described earlier. As in the previous project, we confirm that the estimated standard errors that are often used in practice can be inconsistent, and we provide new estimated standard errors that fix this issue. Both papers described in this paragraph are complemented by software that implements the new proposed standard errors.\n\nThe next project in this grant considers inference in a partially identified model. A model is partially identified when the sampling process and the maintained assumptions restrict the value of the parameter of interest to a set, called the identified set, which is smaller than the logical range of the parameter but potentially larger than a single value. Partially identified models arise naturally in economic models when strong assumptions are traded by weaker ones. Since their introduction, partially identified models have become increasingly popular in several areas in economics, such as industrial organization, trade, and labor economics, as well as in other social sciences.\n\nThe standard framework for partially identified models in economics is the so-called moment (in)equality model. In this model, the parameter vector of interest is constrained by a collection of moment inequalities and equalities. This is the framework used in \"Subvector Inference in Partially Identified Models with Many Moment Inequalities\", joint with Alexandre Belloni and Victor Chernozhukov. As the title suggests, this paper considers two important challenges that appear in empirical applications. First, we allow for the number of moment conditions to be very large, possibly larger than the sample size. Second, we consider a researcher interested in learning about a single coordinate of the unknown parameter vector, perhaps related to a treatment effect or a policy variable of interest. This is known in the literature as the \"subvector inference problem\". In our paper, we propose confidence sets that result from comparing a profiled \"MinMax\" test statistic with either bootstrap-based or self-normalized critical values. The bootstrap-based critical value is more challenging to compute than the self-normalized one, but leads to a higher statistical power. Using novel approximation arguments, we show that our proposed confidence sets are uniformly valid for a large class of data generating processes.\n\nThe research projects covered in this grant pertain to two different econometric models with distinct empirical applications. The common thread in these projects is that they provide new econometric tools to address practical problems currently faced by applied researchers in economics and other social sciences. The results related to this grant have been presented in numerous seminars and conferences. Finally, these projects have influenced the research of several graduate students at Duke University and other institutions.\n\n\t\t\t\t\tLast Modified: 10/10/2020\n\n\t\t\t\t\tSubmitted by: Federico Bugni"
 }
}