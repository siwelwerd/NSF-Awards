{
 "awd_id": "1665151",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Auditing Algorithms: Adding Accountability to Automated Authority",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Bainbridge",
 "awd_eff_date": "2017-03-15",
 "awd_exp_date": "2020-02-29",
 "tot_intn_awd_amt": 49998.0,
 "awd_amount": 49998.0,
 "awd_min_amd_letter_date": "2017-03-09",
 "awd_max_amd_letter_date": "2019-03-13",
 "awd_abstract_narration": "This grant supports a workshop to coordinate the emerging research community developing \"algorithm auditing,\" a research design that has shown promise in diagnosing the unwanted consequences of algorithmic systems. Automated software-based systems in finance, media, information, transportation, or any application of computing can easily create outcomes that are unforeseeable by their designers, so algorithm auditing has the potential to improve the design of these systems. Auditing in this sense takes its name from the social scientific \"audit study\" where one feature is manipulated in a field experiment. This workshop proposes to coalesce this new area of inquiry and to produce a report characterizing the state of the art and potential future directions. The topic of algorithm auditing brings together computer science, information science, and social science in novel combinations.  Participants will have opportunities to articulate challenges that they face, to present existing methods for auditing, and to propose research agendas that can provide new insights that advance science and benefit society.  \r\n\r\nThe scientific issues addressed by this workshop are key economic and social impediments to the adoption and development of fundamental advances in information and communication technologies. How humans think about complex algorithms is a fundamental problem in human-computer interaction and cognitive science. There is industrial interest in third-party algorithm auditing as a way to address user dissatisfaction with algorithmic systems and to forestall future problems. Recent research suggests that algorithmic decision-making using \"big data\" may increase unfairness and structural inequality.  Algorithmic systems form a new avenue for the maintenance and transmission of social stratification, and may fuel cumulative disadvantage. Unwanted behavior by algorithmic systems contributes to major societal challenges such as anti-competitive behavior, fraud, unlawful discrimination, and economic and social inequality.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christian",
   "pi_last_name": "Sandvig",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christian Sandvig",
   "pi_email_addr": "csandvig@umich.edu",
   "nsf_id": "000486088",
   "pi_start_date": "2017-03-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Casey",
   "pi_last_name": "Pierce",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Casey S Pierce",
   "pi_email_addr": "cbspierc@umich.edu",
   "nsf_id": "000727067",
   "pi_start_date": "2017-03-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "Room 4201,426 Thompson Street",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481061248",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 49998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>New research suggests that algorithmic decision-making using \"big data\" may increase unjust discrimination, unfairness, and structural inequality in society. \"Black-boxed\" automated systems in finance, media, information, transportation, or any application of computing can easily create outcomes that are unforeseeable by their designers; indeed, well-known algorithmic platforms operated by Google, Facebook, Airbnb, and Uber have recently encountered well-publicized problems.</p>\n<p>Unwanted algorithmic discrimination is part of the study of social structure itself. Algorithmic systems are a new dimension of the maintenance and transmission of social stratification and this permit new insights into cumulative disadvantage. Methodologically, audits must confront difficult basic questions of fairness, private property, and research ethics. This also centrally engages the concerns of social researchers who have long been investigating with the introduction, adoption, and development of technological systems. How humans think about complex algorithms is a fundamental problem in human-computer interaction and cognitive science.</p>\n<p>The Auditing Algorithms Workshop focused on algorithm auditing, a new research design that has shown promise in diagnosing these unwanted consequences of algorithmic systems. Auditing in this sense takes its name from the social scientific \"audit study\" where one feature is manipulated in a field experiment. The workshop sought to coordinate a new research community that crosses different disciplines, including experts in social and computational research, human-computer interaction, interface design, machine learning, data mining, social stratification, social inequality and disparities, organizational behavior, technology law and policy, audit study methodology, research ethics, science and technology studies, information theory, and game theory. Bringing together an interdisciplinary workshop group created opportunities for different experts who otherwise articulate challenges in algorithm auditing, present existing methods for auditing, and to propose research agendas that can provide new insights that advance science and benefit society.</p>\n<p>The social problems addressed by this workshop are key economic and social impediments to the adoption and development of fundamental advances in information and communication technologies (ICTs). Algorithm auditing is an area of research recently identified by the White House as \"essential\" for the development of big data technologies. There is also industrial interest in third-party auditing as a way to address user dissatisfaction with algorithmic systems and forestall future problems. Unwanted behavior by algorithmic systems contributes to major societal challenges such as crime (fraud, anti-competitive behavior, unlawful discrimination), economic and social inequality, racial segregation, and the effective development of ICTs.</p>\n<p>The workshop culminated in a 3-day event that included public talks, roundtable discussions, and working sessions. The public talks and roundtable discussions included: &nbsp;<em>Governing Human and Machine Behavior in an Experimenting Society;</em> <em>Online Discrimination by Algorithmic Systems;</em> <em>Research Social Media, Online Platforms, and Algorithmic Systems</em>. The working sessions discussed future work and research related to topics focused on metrics, people and design of algorithmic systems. Specifically, those working sessions included: <em>What is Measurable Fairness and Privacy</em> (metrics)<em>; Representing, Visualizing, and Reporting on Algorithms</em> (people)<em>; and Easily Auditable Systems</em> (design). The workshop public website (<a href=\"https://auditingalgorithms.science/\">https://auditingalgorithms.science/</a>) also summarizes workshop details, scientific and educational materials on the state-of-the-art and future directions concerning auditing algorithms.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/22/2021<br>\n\t\t\t\t\tModified by: Casey&nbsp;Pierce</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nNew research suggests that algorithmic decision-making using \"big data\" may increase unjust discrimination, unfairness, and structural inequality in society. \"Black-boxed\" automated systems in finance, media, information, transportation, or any application of computing can easily create outcomes that are unforeseeable by their designers; indeed, well-known algorithmic platforms operated by Google, Facebook, Airbnb, and Uber have recently encountered well-publicized problems.\n\nUnwanted algorithmic discrimination is part of the study of social structure itself. Algorithmic systems are a new dimension of the maintenance and transmission of social stratification and this permit new insights into cumulative disadvantage. Methodologically, audits must confront difficult basic questions of fairness, private property, and research ethics. This also centrally engages the concerns of social researchers who have long been investigating with the introduction, adoption, and development of technological systems. How humans think about complex algorithms is a fundamental problem in human-computer interaction and cognitive science.\n\nThe Auditing Algorithms Workshop focused on algorithm auditing, a new research design that has shown promise in diagnosing these unwanted consequences of algorithmic systems. Auditing in this sense takes its name from the social scientific \"audit study\" where one feature is manipulated in a field experiment. The workshop sought to coordinate a new research community that crosses different disciplines, including experts in social and computational research, human-computer interaction, interface design, machine learning, data mining, social stratification, social inequality and disparities, organizational behavior, technology law and policy, audit study methodology, research ethics, science and technology studies, information theory, and game theory. Bringing together an interdisciplinary workshop group created opportunities for different experts who otherwise articulate challenges in algorithm auditing, present existing methods for auditing, and to propose research agendas that can provide new insights that advance science and benefit society.\n\nThe social problems addressed by this workshop are key economic and social impediments to the adoption and development of fundamental advances in information and communication technologies (ICTs). Algorithm auditing is an area of research recently identified by the White House as \"essential\" for the development of big data technologies. There is also industrial interest in third-party auditing as a way to address user dissatisfaction with algorithmic systems and forestall future problems. Unwanted behavior by algorithmic systems contributes to major societal challenges such as crime (fraud, anti-competitive behavior, unlawful discrimination), economic and social inequality, racial segregation, and the effective development of ICTs.\n\nThe workshop culminated in a 3-day event that included public talks, roundtable discussions, and working sessions. The public talks and roundtable discussions included:  Governing Human and Machine Behavior in an Experimenting Society; Online Discrimination by Algorithmic Systems; Research Social Media, Online Platforms, and Algorithmic Systems. The working sessions discussed future work and research related to topics focused on metrics, people and design of algorithmic systems. Specifically, those working sessions included: What is Measurable Fairness and Privacy (metrics); Representing, Visualizing, and Reporting on Algorithms (people); and Easily Auditable Systems (design). The workshop public website (https://auditingalgorithms.science/) also summarizes workshop details, scientific and educational materials on the state-of-the-art and future directions concerning auditing algorithms.\n\n\t\t\t\t\tLast Modified: 04/22/2021\n\n\t\t\t\t\tSubmitted by: Casey Pierce"
 }
}