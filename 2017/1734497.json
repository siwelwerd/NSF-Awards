{
 "awd_id": "1734497",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: FND: COLLAB: Coordinating Human-Robot Teams in Uncertain Environments",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928074",
 "po_email": "jdonlon@nsf.gov",
 "po_sign_block_name": "James Donlon",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 374939.0,
 "awd_amount": 382939.0,
 "awd_min_amd_letter_date": "2017-08-23",
 "awd_max_amd_letter_date": "2019-03-07",
 "awd_abstract_narration": "The decreasing cost and increasing sophistication of robot hardware is creating new opportunities for teams of robots to be deployed in combination with skilled humans to support and augment labor-intensive and/or dangerous manual work. The vision is for robots to free up time of skilled workers so they can focus on the tasks that they are skilled at (complex problem solving, dextrous manipulation, customer service, etc.) and robots can help with the distracting and frustrating parts of working, such as delivering materials or fetching supplies. This vision is being realized across many sectors of the US economy and abroad, such as in warehouse management, assembly manufacturing, and disaster response. However, progress in this area is being stymied by current methods that are rigid and inflexible, and rely on unrealistic models of human-robot interaction. This project seeks to overcome these problems by proposing new models and methods for teams robots to coordinate with teams humans to complete complex problems. \r\n\r\nIn particular, this project will create and solve realistic models for coordinating teams of humans and robots in uncertain environments. The PIs will investigate innovative approaches to this research area, and will make the following contributions: 1) Enable a transformative re-conceptualization of multi-human multi-robot teamwork the accurately reflects the strengths and limitations of the team, as situated within a temporally dynamic, stochastic environment, 2) develop realistic and general models of human-robot teamwork that consider uncertainty and partial observability, and 3) Contribute innovative and scalable techniques for planning and learning in these models. This research will build off of methods that have been successful in single-robot problems under uncertainty and partially observability: partially observable Markov decision processes (POMDPs). POMDPs model robots and environments, but not humans. However, explicitly including people in these models will be critical in almost all real-world applications.  By extending POMDPs to multiple robots interacting with teams of humans, complex and realistic problems with mixed human and robot teams can be represented. The solution methods developed in this project will allow the robots to reason about the uncertainty about the domain and their human teammates, while optimizing their behavior. The methods are broadly applicable to human-robot collaboration domains, but they will be evaluated in an emergency department, an environment with a large amount of uncertainty and many delivery and supply tasks during high-volume times. A team of robots can assist in these tasks. Experiments will take place in simulation and in the UC San Diego Simulation and Training Center with various numbers of humans and robots. The results of this project have the potential to transform the way human-robot coordination is performed.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Amato",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher Amato",
   "pi_email_addr": "c.amato@northeastern.edu",
   "nsf_id": "000677651",
   "pi_start_date": "2017-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Avenue",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 374939.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-4bc11b71-7fff-a204-09cc-74a44ab1c64a\"> </span></p>\n<p dir=\"ltr\"><span>The decreasing cost and increasing sophistication of robot hardware are creating new opportunities for teams of robots to be deployed in combination with skilled humans to support and augment labor-intensive and/or dangerous manual work. The vision is for robots to free up the time of skilled workers so they can focus on the tasks that they are skilled at (complex problem solving, dextrous manipulation, customer service, etc.) and robots can help with the distracting and frustrating parts of working, such as delivering materials or fetching supplies.</span></p>\n<p dir=\"ltr\"><span>This project developed methods to help achieve this goal of coordinating teams of humans and robots. In particular, we developed novel methods for modeling human intention under uncertainty, new approaches for novel-object recognition and group detection, efficient learning methods that can learn from humans with few interactions, and scalable solution methods that can coordinate teams of robots.&nbsp;</span></p>\n<p dir=\"ltr\"><span>In particular, we advanced new methods for modeling human intention, particularly during uncertainty.&nbsp; This included creating new deep learning methods for non-visual activity modeling which can detect both fine and gross motor movements; our methods significantly outperformed the state-of-the-art classifiers.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Furthermore, we developed several new methods for supporting robots to engage in real-time novel object recognition (e.g., to enable robots to recognize objects they&rsquo;ve never seen before). Our methods surpassed leading methods in terms of performance and accuracy across noisy, real-world datasets. Finally, we developed new methods for group detection and tracking, which is a key element for robots that work with groups of people. We validated our methods using real-world data and found they outperformed the state of the art.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Ideally, we would like the robots to learn how to adjust their actions by interacting with humans, but current (reinforcement) learning methods require large amounts of data. Therefore, we developed efficient methods that are able to learn from only a small number of interactions while scaling to large domains with noisy and incomplete data (e.g., just observing a human&rsquo;s behavior).&nbsp;</span></p>\n<p dir=\"ltr\"><span>Coordinating teams of robots (with or without humans) is hard and current methods cannot typically scale to large, realistic domains. Therefore, we developed new methods that can leverage predefined controllers for simple tasks (e.g., navigating or grasping an object) and then perform deep reinforcement learning to sequence the controllers. The resulting methods can scale to large domains and allow the robots to learn and execute in an asynchronous manner.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Collectively, this work will advance the ability of robots to team with people under uncertainty by informing the design systems that are robust and able to quickly make decisions given complex, real-world data.&nbsp;</span></p>\n<p dir=\"ltr\"><span>The proposed methods could find broad industry-wide application as teams of humans and robots become more common. Examples include medical and manufacturing settings, disaster response, and autonomous vehicles. To date, our research has been broadly disseminated in publications, presentations, and publicly available software via the PIs' respective websites.&nbsp; The PIs also engaged in activities to broaden participation in computing by recruiting and mentoring students underrepresented in robotics research as part of this project.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/13/2022<br>\n\t\t\t\t\tModified by: Christopher&nbsp;Amato</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1734497/1734497_10517808_1642094735386_unnamed4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1734497/1734497_10517808_1642094735386_unnamed4--rgov-800width.jpg\" title=\"MacDec-POMDP\"><img src=\"/por/images/Reports/POR/2022/1734497/1734497_10517808_1642094735386_unnamed4--rgov-66x44.jpg\" alt=\"MacDec-POMDP\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Coordinating teams of robots to interact with humans using partially observable reinforcement learning.</div>\n<div class=\"imageCredit\">Yuchen Xiao</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Christopher&nbsp;Amato</div>\n<div class=\"imageTitle\">MacDec-POMDP</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1734497/1734497_10517808_1642094511326_unnamed3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1734497/1734497_10517808_1642094511326_unnamed3--rgov-800width.jpg\" title=\"UFO\"><img src=\"/por/images/Reports/POR/2022/1734497/1734497_10517808_1642094511326_unnamed3--rgov-66x44.jpg\" alt=\"UFO\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our unsupervised object discovery framework, UFO, is composed of six processes: a) object proposal generation, b) saliency scoring , c) non-maximumsuppression (NMS), d) feature extraction, e) sliding window graph update, f) path selection, and g) object proposal prediction.</div>\n<div class=\"imageCredit\">Laurel Riek group</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Christopher&nbsp;Amato</div>\n<div class=\"imageTitle\">UFO</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1734497/1734497_10517808_1642094415203_unnamed--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1734497/1734497_10517808_1642094415203_unnamed--rgov-800width.jpg\" title=\"RoboGEM\"><img src=\"/por/images/Reports/POR/2022/1734497/1734497_10517808_1642094415203_unnamed--rgov-66x44.jpg\" alt=\"RoboGEM\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This figuredemonstrates RoboGEM detecting groups while both the robot and pedestrians in the environment are inmotion.</div>\n<div class=\"imageCredit\">Laurel Riek group</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Christopher&nbsp;Amato</div>\n<div class=\"imageTitle\">RoboGEM</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nThe decreasing cost and increasing sophistication of robot hardware are creating new opportunities for teams of robots to be deployed in combination with skilled humans to support and augment labor-intensive and/or dangerous manual work. The vision is for robots to free up the time of skilled workers so they can focus on the tasks that they are skilled at (complex problem solving, dextrous manipulation, customer service, etc.) and robots can help with the distracting and frustrating parts of working, such as delivering materials or fetching supplies.\nThis project developed methods to help achieve this goal of coordinating teams of humans and robots. In particular, we developed novel methods for modeling human intention under uncertainty, new approaches for novel-object recognition and group detection, efficient learning methods that can learn from humans with few interactions, and scalable solution methods that can coordinate teams of robots. \nIn particular, we advanced new methods for modeling human intention, particularly during uncertainty.  This included creating new deep learning methods for non-visual activity modeling which can detect both fine and gross motor movements; our methods significantly outperformed the state-of-the-art classifiers. \nFurthermore, we developed several new methods for supporting robots to engage in real-time novel object recognition (e.g., to enable robots to recognize objects they\u2019ve never seen before). Our methods surpassed leading methods in terms of performance and accuracy across noisy, real-world datasets. Finally, we developed new methods for group detection and tracking, which is a key element for robots that work with groups of people. We validated our methods using real-world data and found they outperformed the state of the art. \nIdeally, we would like the robots to learn how to adjust their actions by interacting with humans, but current (reinforcement) learning methods require large amounts of data. Therefore, we developed efficient methods that are able to learn from only a small number of interactions while scaling to large domains with noisy and incomplete data (e.g., just observing a human\u2019s behavior). \nCoordinating teams of robots (with or without humans) is hard and current methods cannot typically scale to large, realistic domains. Therefore, we developed new methods that can leverage predefined controllers for simple tasks (e.g., navigating or grasping an object) and then perform deep reinforcement learning to sequence the controllers. The resulting methods can scale to large domains and allow the robots to learn and execute in an asynchronous manner. \nCollectively, this work will advance the ability of robots to team with people under uncertainty by informing the design systems that are robust and able to quickly make decisions given complex, real-world data. \nThe proposed methods could find broad industry-wide application as teams of humans and robots become more common. Examples include medical and manufacturing settings, disaster response, and autonomous vehicles. To date, our research has been broadly disseminated in publications, presentations, and publicly available software via the PIs' respective websites.  The PIs also engaged in activities to broaden participation in computing by recruiting and mentoring students underrepresented in robotics research as part of this project.\n\n \n\n\t\t\t\t\tLast Modified: 01/13/2022\n\n\t\t\t\t\tSubmitted by: Christopher Amato"
 }
}