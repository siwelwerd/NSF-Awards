{
 "awd_id": "1718680",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Small: Index Sharding and Query Routing in Distributed Search Engines",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 499994.0,
 "awd_amount": 515994.0,
 "awd_min_amd_letter_date": "2017-07-27",
 "awd_max_amd_letter_date": "2018-06-07",
 "awd_abstract_narration": "Large web search engines now receive billions of search requests per day that are evaluated over hundreds of billions of documents, leading to significant advertising revenue for the engines and many benefits for the overall economy. To process these queries with sub-second latencies, search engines deploy millions of computing cores housed in multiple large and geographically distributed data centers. This project will propose and investigate new techniques for partitioning and replicating document and index data across such systems, and for routing search requests to the data, with the goal of improving query processing efficiency and reducing hardware and energy costs. The work will result in a better understanding of the basic data partitioning and load balancing problems in such systems, and also has the potential to lead to significant economic benefits for existing and future search systems in terms of reduced hardware and energy costs. In addition, the project will support the training of a number of graduate and undergraduate students in search engine technology, a critical expertise sought by many employers. \r\n\r\nThe planned research activities can be divided into two parts. The first part will focus on index sharding and tiering techniques, i.e., how to assign documents and index data to shards and tiers using clustering and index reordering techniques, and how to route queries to shards and tiers for efficient query processing. Here the goal is to minimize overall average query processing costs, without considering issues such as load balancing between machines, queuing delays, and resulting query latencies. The second part will focus on shard assignment and replication and on query routing, i.e., how to assign and replicate shards over machines, and how to adaptively route queries to shard replicas, in order to achieve increased query throughput across a range of realistic service level agreements (SLAs) on query latencies and result quality. Here the focus is on studying the basic load balancing problems arising in large search architectures, and on performing an end-to-end evaluation of the new index sharding and tiering techniques from the first part, to show that they can satisfy realistic latency and quality constraints with state-of-the-art load balancing methods.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Torsten",
   "pi_last_name": "Suel",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Torsten Suel",
   "pi_email_addr": "torsten.suel@nyu.edu",
   "nsf_id": "000493079",
   "pi_start_date": "2017-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "10 MetroTech Center",
  "perf_city_name": "Brooklyn",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "112012901",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "NY07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 499994.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project focused on the efficiency of large distributed search engines, where the document collection is partitioned into subsets called shards that are assigned and replicated across a large number of machines in a data center. Queries in such systems are processed by routing the query to machines holding the needed shard replicas, processing the query locally in the machines, and finally aggregating the results supplied by the different machines into a result page returned to the user.</span></p>\n<p><span>Our work focused on three aspects that determine the efficiency of the overall system:&nbsp;</span></p>\n<ul>\n<li>How to efficiently process queries on individual machines and shards.</li>\n<li>How to partition documents over shards and tiers, and how to select shards and tiers for an incoming query.</li>\n<li>How to route queries to shard replicas to balance load between machines while allowing for node failures and limiting tail latencies.</li>\n</ul>\n<p>Our main research contributions obtained are as follows:</p>\n<ol>\n<li><span><strong>Faster early-termination for disjunctive top-k queries on simple ranking function.</strong> The first step in single-node query processing is candidate generation, where we select a large initial set of possible results that are subsequently reranked and narrowed down to the top results returned to the user. This is often modeled as a disjunctive top-k query on a simple ranking function. We proposed two new approaches for this problem, one based on block-filtering that can skip documents that cannot contain top-k results, and that exploits the SIMD capabilities of current CPUs, and one that decomposes a disjunctive query into several single-term and conjunctive subqueries. We achieve reductions in processing times ranging from up to 50% for the first to about 20% for the second method. Both methods rely on good estimations of the k-th highest score of a query (top-k threshold), another problem studied in the project.</span></li>\n<li><span><strong>Sparse learned indexing. </strong>Recent years have seen significant increases in search quality based on deep neural networks. However, these advances also bring significant efficiency challenges due to their cost.</span>&nbsp;Our approach, called DeepImpact, uses deep neural networks to learn an optimized sparse inverted index that approximates the result quality of a given deep neural ranker. Experiments show that the approach significantly outperforms traditional simple rankers such as BM25, and almost matches the retrieval quality of more complex approaches such as Colbert and Splade. Further work archieved additional speedups for query processing on the resulting indexes using guided traversal.</li>\n<li><strong>Selective Search and Index Tiering.</strong> Large distributed search systems often use selective search and index tiering to improve efficiency. Selective search is an approach that assigns documents to shards based on topical similarity, and routes incoming query to the shards deemed most relevant to the query. Selective search can lead to significant increases in efficiency, and allows trading off quality and efficiency during peak times. Index tiering partitions the collection into several tiers based on document quality, and then routes most queries only to top tiers. We proposed an approach that combines selective search with ideas from tiering, and also studied several different tiering policies and the resulting quality-efficiency trade-offs.</li>\n<li><strong>Load Balancing and Query Routing.</strong>&nbsp;We studied methods for routing queries to shards and machines in distributed search architectures. The goal is to achieve low latency while balancing load between machines and adjusting to machine slowdowns and failures. We performed simulations using the DESMO-J discrete event simulator to evaluate routing policies and shard replica schemes. We also studied reissue policies (hedging) in data centers, where the problem is to decide when to reissue a request to another shard if the initial request has not been answered. We proposed several classes of reissue policies and studied their complexities and relative powers in a formal framework.</li>\n<li><strong>Software Infrastructure</strong>. The project lead to the creation of significant free open-source software. Many of our query processing algorithms were implemented and included in the PISA (Performant Indexing and Search for Academia)<span>&nbsp;toolkit for indexing and query processing initiated by PhD student Antonio Mallia. PISA provides a simple platform for experimenting with new ideas in indexing and query processing, with focus on search-engine efficiency research. PISA has already been used by several other research groups. Other significant software artifacts produced under this project are the DeepImpact sparse neural indexer, and the Common Index File Format (CIFF)</span>&nbsp;for inverted indexes that allows different search engine prototypes to exchange index data.&nbsp;</li>\n</ol>\n<p>This research has the potential to improve the efficiency of existing commercial search engines, an industry with tens of billions of dollars of economic impact per year in the US, and to help new companies entering this and related fields. The project supported the training of 4 PhD students, 2 MS Thesis students, and almost a dozen undergraduate and MS students who participated in research. Results were published in many peer-reviewed publication venues and have already resulted in significant follow-up work by other researchers.</p><br>\n<p>\n Last Modified: 07/31/2024<br>\nModified by: Torsten&nbsp;Suel</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project focused on the efficiency of large distributed search engines, where the document collection is partitioned into subsets called shards that are assigned and replicated across a large number of machines in a data center. Queries in such systems are processed by routing the query to machines holding the needed shard replicas, processing the query locally in the machines, and finally aggregating the results supplied by the different machines into a result page returned to the user.\n\n\nOur work focused on three aspects that determine the efficiency of the overall system:\n\nHow to efficiently process queries on individual machines and shards.\nHow to partition documents over shards and tiers, and how to select shards and tiers for an incoming query.\nHow to route queries to shard replicas to balance load between machines while allowing for node failures and limiting tail latencies.\n\n\n\nOur main research contributions obtained are as follows:\n\nFaster early-termination for disjunctive top-k queries on simple ranking function. The first step in single-node query processing is candidate generation, where we select a large initial set of possible results that are subsequently reranked and narrowed down to the top results returned to the user. This is often modeled as a disjunctive top-k query on a simple ranking function. We proposed two new approaches for this problem, one based on block-filtering that can skip documents that cannot contain top-k results, and that exploits the SIMD capabilities of current CPUs, and one that decomposes a disjunctive query into several single-term and conjunctive subqueries. We achieve reductions in processing times ranging from up to 50% for the first to about 20% for the second method. Both methods rely on good estimations of the k-th highest score of a query (top-k threshold), another problem studied in the project.\nSparse learned indexing. Recent years have seen significant increases in search quality based on deep neural networks. However, these advances also bring significant efficiency challenges due to their cost.Our approach, called DeepImpact, uses deep neural networks to learn an optimized sparse inverted index that approximates the result quality of a given deep neural ranker. Experiments show that the approach significantly outperforms traditional simple rankers such as BM25, and almost matches the retrieval quality of more complex approaches such as Colbert and Splade. Further work archieved additional speedups for query processing on the resulting indexes using guided traversal.\nSelective Search and Index Tiering. Large distributed search systems often use selective search and index tiering to improve efficiency. Selective search is an approach that assigns documents to shards based on topical similarity, and routes incoming query to the shards deemed most relevant to the query. Selective search can lead to significant increases in efficiency, and allows trading off quality and efficiency during peak times. Index tiering partitions the collection into several tiers based on document quality, and then routes most queries only to top tiers. We proposed an approach that combines selective search with ideas from tiering, and also studied several different tiering policies and the resulting quality-efficiency trade-offs.\nLoad Balancing and Query Routing.We studied methods for routing queries to shards and machines in distributed search architectures. The goal is to achieve low latency while balancing load between machines and adjusting to machine slowdowns and failures. We performed simulations using the DESMO-J discrete event simulator to evaluate routing policies and shard replica schemes. We also studied reissue policies (hedging) in data centers, where the problem is to decide when to reissue a request to another shard if the initial request has not been answered. We proposed several classes of reissue policies and studied their complexities and relative powers in a formal framework.\nSoftware Infrastructure. The project lead to the creation of significant free open-source software. Many of our query processing algorithms were implemented and included in the PISA (Performant Indexing and Search for Academia)toolkit for indexing and query processing initiated by PhD student Antonio Mallia. PISA provides a simple platform for experimenting with new ideas in indexing and query processing, with focus on search-engine efficiency research. PISA has already been used by several other research groups. Other significant software artifacts produced under this project are the DeepImpact sparse neural indexer, and the Common Index File Format (CIFF)for inverted indexes that allows different search engine prototypes to exchange index data.\n\n\n\nThis research has the potential to improve the efficiency of existing commercial search engines, an industry with tens of billions of dollars of economic impact per year in the US, and to help new companies entering this and related fields. The project supported the training of 4 PhD students, 2 MS Thesis students, and almost a dozen undergraduate and MS students who participated in research. Results were published in many peer-reviewed publication venues and have already resulted in significant follow-up work by other researchers.\t\t\t\t\tLast Modified: 07/31/2024\n\n\t\t\t\t\tSubmitted by: TorstenSuel\n"
 }
}