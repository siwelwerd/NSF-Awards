{
 "awd_id": "1717473",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Collaborative Research: Understanding and Improving Implicit Coordination in Peer Production Networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Bainbridge",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 363783.0,
 "awd_amount": 363783.0,
 "awd_min_amd_letter_date": "2017-08-14",
 "awd_max_amd_letter_date": "2017-08-14",
 "awd_abstract_narration": "This research will apply knowledge about coordination mechanisms that was gained in biology to better understand and to improve coordination in peer production using information and communication technologies. Peer production has emerged as an important economic force. It produces knowledge infrastructure that underlies many aspects of educational and research institutions. Thus, ways of furthering peer production may have broad impacts on the infrastructure that supports invention, and in turn on the economy. More generally, collaborative editing is used in most industries that manage knowledge, and so progress on this front may have impacts in corporations, partnerships, non-profits, and government institutions. The research will not only seek an increased understanding of peer production but also will build tools and interfaces that seek to improve the collective creativity of online communities. Models, data sets, and accompanying simulations will be built for two purposes: as explicit forms of knowledge for reuse by other researchers, and as materials for education.\r\n \r\nThe investigation will proceed through a set of observational studies and experiments, to explore how coordination mechanisms that have been discovered through studies in the field of biology may provide useful insights into human behavior. Recent studies have indicated that coordination in open source and peer production networks can be explained at least in part by stigmergy, a process discovered by biologists in which the traces of work become conditions or signals that generate more work.  Peer production is described as being stigmergic because coordination often happens not through explicit planning conversations, but through interactions triggered by previous interactions, all centered on the primary technical artifact, some form of text or source code.  The work will proceed in three phases: (1) performing studies that examine how interaction rates affect productivity in peer production networks such as Wikipedia; (2) applying dynamic models from mathematical biology to peer production, first through an observational study and then through an experiment, and (3) testing alternative interfaces for peer production and applying the findings to other collaborative editing environments.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeffrey",
   "pi_last_name": "Nickerson",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Jeffrey V Nickerson",
   "pi_email_addr": "jnickerson@stevens.edu",
   "nsf_id": "000108449",
   "pi_start_date": "2017-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stevens Institute of Technology",
  "inst_street_address": "ONE CASTLE POINT ON HUDSON",
  "inst_street_address_2": "",
  "inst_city_name": "HOBOKEN",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "2012168762",
  "inst_zip_code": "070305906",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "NJ08",
  "org_lgl_bus_name": "THE TRUSTEES OF THE STEVENS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJ6CN5Y5A2R5"
 },
 "perf_inst": {
  "perf_inst_name": "Stevens Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "Hoboken",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "070305991",
  "perf_ctry_code": "US",
  "perf_cong_dist": "08",
  "perf_st_cong_dist": "NJ08",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 363783.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project sought to understand how peer production happens and how it can be improved. As part of this project, all of the bots on Wikipedia were analyzed, to understand how they were created, what contributions they made to articles, and how bots affected human editors. One finding of the project was that bots play recognizable roles in peer production: part of the contribution of this project is a systematic way, using machine learning, of discovering and classifying the roles of automated technologies used in knowledge production. Another finding of this project is that human editors in Wikipedia are influenced by the level of activity of other editors: that is, editing is a process that excites other editing. The implication of this work is that activity might be primed by paying attention to, or creating, bursts of activity that channel joint effort toward a common goal. A third finding of this project relates to how institutions may govern machine learning. Machine learning may in some cases do the wrong thing - in the context of Wikipedia, it may revert legitimate edits, which reduces productivity and drives away human editors. This kind of false positive can have deleterious effects on an organization. In the case of Wikipedia, a governance strategy was adopted: the false positive rate of the machine learning classifier was set to a low enough number that the machine learning would be tolerated even when it made mistakes. Once the threshold was set, the machine learning process improved false negative rates, and helped in the overall project of producing quality articles. This tactical move provides a template for other organizations who wish to manage machine learning in a way that allows for both the machines and humans in the organization to be more productive and also learn as part of the process. These findings were the result of a collaboration between investigators in different disciplines, notably between biology and information systems. Biology provided a variety of techniques for analyzing knowledge production as a kind of ecosystem, including tools that looked at rates of activity and noticed changes in rates. Information systems provided techniques for analyzing human processes and the digital traces they leave. The research converged on a view of organizational governance that includes both human and machine learning.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/04/2022<br>\n\t\t\t\t\tModified by: Jeffrey&nbsp;V&nbsp;Nickerson</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1717473/1717473_10514690_1641261310343_Wikidatadiagramv2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1717473/1717473_10514690_1641261310343_Wikidatadiagramv2--rgov-800width.jpg\" title=\"Knowledge production by humans and machines\"><img src=\"/por/images/Reports/POR/2022/1717473/1717473_10514690_1641261310343_Wikidatadiagramv2--rgov-66x44.jpg\" alt=\"Knowledge production by humans and machines\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Increasingly, knowledge production communities such as Wikipedia enlist bots to help generate, synthesize, index, and protect knowledge. Machines learn at different rates than humans. Governance processes now include setting the parameters of classifiers, in particular their false positive rates.</div>\n<div class=\"imageCredit\">Jeffrey Nickerson</div>\n<div class=\"imageSubmitted\">Jeffrey&nbsp;V&nbsp;Nickerson</div>\n<div class=\"imageTitle\">Knowledge production by humans and machines</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project sought to understand how peer production happens and how it can be improved. As part of this project, all of the bots on Wikipedia were analyzed, to understand how they were created, what contributions they made to articles, and how bots affected human editors. One finding of the project was that bots play recognizable roles in peer production: part of the contribution of this project is a systematic way, using machine learning, of discovering and classifying the roles of automated technologies used in knowledge production. Another finding of this project is that human editors in Wikipedia are influenced by the level of activity of other editors: that is, editing is a process that excites other editing. The implication of this work is that activity might be primed by paying attention to, or creating, bursts of activity that channel joint effort toward a common goal. A third finding of this project relates to how institutions may govern machine learning. Machine learning may in some cases do the wrong thing - in the context of Wikipedia, it may revert legitimate edits, which reduces productivity and drives away human editors. This kind of false positive can have deleterious effects on an organization. In the case of Wikipedia, a governance strategy was adopted: the false positive rate of the machine learning classifier was set to a low enough number that the machine learning would be tolerated even when it made mistakes. Once the threshold was set, the machine learning process improved false negative rates, and helped in the overall project of producing quality articles. This tactical move provides a template for other organizations who wish to manage machine learning in a way that allows for both the machines and humans in the organization to be more productive and also learn as part of the process. These findings were the result of a collaboration between investigators in different disciplines, notably between biology and information systems. Biology provided a variety of techniques for analyzing knowledge production as a kind of ecosystem, including tools that looked at rates of activity and noticed changes in rates. Information systems provided techniques for analyzing human processes and the digital traces they leave. The research converged on a view of organizational governance that includes both human and machine learning. \n\n\t\t\t\t\tLast Modified: 01/04/2022\n\n\t\t\t\t\tSubmitted by: Jeffrey V Nickerson"
 }
}