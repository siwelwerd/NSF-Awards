{
 "awd_id": "1720297",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Optimal Convergence Rates for Adaptive Finite Element Techniques",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922113",
 "po_email": "ygorb@nsf.gov",
 "po_sign_block_name": "Yuliya Gorb",
 "awd_eff_date": "2017-06-15",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 275000.0,
 "awd_amount": 275000.0,
 "awd_min_amd_letter_date": "2017-06-23",
 "awd_max_amd_letter_date": "2017-06-23",
 "awd_abstract_narration": "Numerical simulation is an indispensable tool for acquiring deeper and more quantitative insight into increasingly complex scientific and technological processes. Despite the ever-increasing power of digital computing facilities, numerical simulation technology is somewhat of a weak link. This research project aims to develop improved adaptive numerical algorithms, which have the ability to optimally allocate computational resources -- viz. degrees of freedom -- in the course of the solution process based on information gathered so far. Economizing as much as possible the number of degrees of freedom with the aid of adaptive solution techniques while still accurately capturing the structures of interest remains central to large-scale simulation and a fundamental prerequisite for ultimately further advancing the frontiers of computability. While large-scale scientific computation usually takes place in a highly interdisciplinary arena, the design of adaptive algorithms with rigorously-founded certifiable performance guarantees is an inherently mathematical task that is pursued in this project.  The many conceptual facets of this research project additionally offer unique opportunities for talented young researchers to develop their potential.\r\n\r\nThis project aims at developing and analyzing hp-adaptive approximations through a process of locally distributing the degrees of freedom through a coarse-to-fine procedure based on local error estimators. The challenges in accomplishing the goals of the project have two major sources. On the one hand, the type of the partial differential equation to which such methods are to be applied, of course, matters very much. On the other hand, there are several fundamental problem aspects that are independent of the particular application and are primarily of approximation-theoretic nature. Even when restricting the problem to a fixed mesh refinement depth and a largest allowable polynomial degree, finding the optimal degree distribution in conjunction with an adequately locally-refined partition is an NP-hard problem. In particular, when progressing from coarse to successively refined meshes seemingly good degree assignments could turn out at a much later stage to prevent near-optimal results. It is therefore of crucial importance to address such core approximation theoretic issues and understand to what extent they are affected by the particular type of partial differential equation. For instance, when using conforming methods for the important class of elliptic boundary value problems, trial functions need to be globally continuous, which severely impedes the analysis of local refinements due to \"smoothness pollution,\" particularly in the multivariate case. To address these aspects and build a solid footing for future specifications to different application areas is the primary goal of this project. Some of the envisaged theoretical results are expected to be of asymptotic nature. Therefore, the theoretical investigations will be accompanied by implementing the strategies for model problems that shed light on the quantitative behavior of the methods. A high level of adaptivity interferes with parallelization, opening yet another direction of research, especially regarding modern processor technologies.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Binev",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Peter Binev",
   "pi_email_addr": "binev@math.sc.edu",
   "nsf_id": "000482290",
   "pi_start_date": "2017-06-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Wolfgang",
   "pi_last_name": "Dahmen",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Wolfgang A Dahmen",
   "pi_email_addr": "dahmen@math.sc.edu",
   "nsf_id": "000520191",
   "pi_start_date": "2017-06-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of South Carolina at Columbia",
  "inst_street_address": "1600 HAMPTON ST",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBIA",
  "inst_state_code": "SC",
  "inst_state_name": "South Carolina",
  "inst_phone_num": "8037777093",
  "inst_zip_code": "292083403",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "SC06",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTH CAROLINA",
  "org_prnt_uei_num": "Q93ZDA59ZAR5",
  "org_uei_num": "J22LNTMEDP73"
 },
 "perf_inst": {
  "perf_inst_name": "University of South Carolina at Columbia",
  "perf_str_addr": "",
  "perf_city_name": "Columbia",
  "perf_st_code": "SC",
  "perf_st_name": "South Carolina",
  "perf_zip_code": "292080001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "SC06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 275000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Many practical problems are described mathematically through partial differential equations (PDEs). Solving them numerically often requires adjustments of the approach to keep the optimality of the procedure. Adaptive finite element methods (AFEM) for solving PDEs provide these adjustments most often through refining the mesh on which the solution is calculated. This is known as h-adaptivity. Depending on the problem and the PDE, it is often more efficient to also adjust the degrees of the polynomials of some finite elements. This more involved approach is known as hp-adaptivity. The main goal of this research project was to provide a thorough understanding of hp-adaptivity and how it should be designed to ensure optimal performance of the AFEM algorithms. The PIs and their collaborators made several theoretical advancements that include results about the optimal design in terms of performance and convergence rates of h- and hp-adaptive algorithms on general meshes and h-adaptive algorithms on conforming meshes. These results give insights about the ways to distribute the degrees of freedom used in AFEM and provide new ideas about the design of practical algorithms.&nbsp;</p>\n<p>A focus area of this project has been the advancement of adaptive methodologies for solving a variety of problems involving different types of PDEs. In particular, the PIs and their collaborators derived reliable and efficient a posteriori error bounds used in the design of the AFEM for linear transport PDEs and proposed using random training sets for a very efficient greedy selection of reduced set of basic functions describing the solutions. They developed and justified a new approach to the numerical solution of radiative transfer PDEs with certified a posteriori error bounds using adaptive source term iteration.&nbsp;</p>\n<p>Another focus area was the investigation of different problems related to state estimation and introducing optimality criteria that delineate intrinsic information limits and highlight the role of reduced models for developing efficient computational strategies. The project also considered an adaptive low-rank approximation for operator equations establishing accuracy control and computational complexity for the proposed approach.&nbsp;</p>\n<p>The research under this project produced a result related to the problem of learning a function from data. Under the assumption that the function belongs to a given model class, it establishes a mathematical framework of an optimal performance procedure for learning an approximation of the function from the given data. This includes quantitative bounds for how much over-parameterization needs to be employed in the process and how the penalization needs to be scaled in order to guarantee a near optimal recovery.</p>\n<p>The project supported the research training of two female undergraduate students and a male graduate student. One of them, Kelsey Larkin, defended her senior thesis \"Improved Filtering of Electron Tomography EDX Data\" in 2020. It introduces a new adaptive methodology for processing spectral data from electron microscopy. The students' research projects helped in their development as future scientists.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/22/2022<br>\n\t\t\t\t\tModified by: Peter&nbsp;Binev</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMany practical problems are described mathematically through partial differential equations (PDEs). Solving them numerically often requires adjustments of the approach to keep the optimality of the procedure. Adaptive finite element methods (AFEM) for solving PDEs provide these adjustments most often through refining the mesh on which the solution is calculated. This is known as h-adaptivity. Depending on the problem and the PDE, it is often more efficient to also adjust the degrees of the polynomials of some finite elements. This more involved approach is known as hp-adaptivity. The main goal of this research project was to provide a thorough understanding of hp-adaptivity and how it should be designed to ensure optimal performance of the AFEM algorithms. The PIs and their collaborators made several theoretical advancements that include results about the optimal design in terms of performance and convergence rates of h- and hp-adaptive algorithms on general meshes and h-adaptive algorithms on conforming meshes. These results give insights about the ways to distribute the degrees of freedom used in AFEM and provide new ideas about the design of practical algorithms. \n\nA focus area of this project has been the advancement of adaptive methodologies for solving a variety of problems involving different types of PDEs. In particular, the PIs and their collaborators derived reliable and efficient a posteriori error bounds used in the design of the AFEM for linear transport PDEs and proposed using random training sets for a very efficient greedy selection of reduced set of basic functions describing the solutions. They developed and justified a new approach to the numerical solution of radiative transfer PDEs with certified a posteriori error bounds using adaptive source term iteration. \n\nAnother focus area was the investigation of different problems related to state estimation and introducing optimality criteria that delineate intrinsic information limits and highlight the role of reduced models for developing efficient computational strategies. The project also considered an adaptive low-rank approximation for operator equations establishing accuracy control and computational complexity for the proposed approach. \n\nThe research under this project produced a result related to the problem of learning a function from data. Under the assumption that the function belongs to a given model class, it establishes a mathematical framework of an optimal performance procedure for learning an approximation of the function from the given data. This includes quantitative bounds for how much over-parameterization needs to be employed in the process and how the penalization needs to be scaled in order to guarantee a near optimal recovery.\n\nThe project supported the research training of two female undergraduate students and a male graduate student. One of them, Kelsey Larkin, defended her senior thesis \"Improved Filtering of Electron Tomography EDX Data\" in 2020. It introduces a new adaptive methodology for processing spectral data from electron microscopy. The students' research projects helped in their development as future scientists. \n\n \n\n \n\n\t\t\t\t\tLast Modified: 09/22/2022\n\n\t\t\t\t\tSubmitted by: Peter Binev"
 }
}