{
 "awd_id": "1730183",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRI II-NEW: IIS: Omniview Multi-modal Sensor Laboratory for Understanding Human Interactions in Ubiquitous Environments",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2017-06-01",
 "awd_exp_date": "2021-05-31",
 "tot_intn_awd_amt": 746916.0,
 "awd_amount": 746916.0,
 "awd_min_amd_letter_date": "2017-04-28",
 "awd_max_amd_letter_date": "2017-04-28",
 "awd_abstract_narration": "Understanding how people interact with objects and with each other is an important research area in human-computer interaction, particularly in contexts where phones, cameras, sensors, voice assistants, robots, and other computing devices help people accomplish their goals.  To study these interactions, this project will equip a lab with state of the art equipment for capturing human activity that doesn't require attaching markers, wires, or sensors to people, and develop software to manage the large amounts of captured data and interfaces that help researchers and designers make use of the data.  Much of the envisioned fundamental research will focus on how age, gender, physical ability, and experience level affect the way people interact with objects, as well as on using social cues such as emotions, inter-person distances, and gestures to understand how people interact with each other.  A number of researchers at the lead investigators' institution will use the lab for related projects around people- and object-aware technologies, including assistive robotics, self-driving vehicles, teams and collaboration, and smart environments.  The lab will also provide training for a postdoctoral researcher and research opportunities for undergraduates, support a number of courses taught at the PIs' institution, and provide new opportunities for interdisciplinary research.\r\n\r\nThe PIs will develop a temporally synchronized and spatially calibrated sensor system that includes force plates, microphones, RGB and infrared cameras, and Kinect sensors, and deploy it in 20x20x12 foot lab.  Data will be synchronized using linear time codes (LTCs), including custom hardware previously developed by the PIs to add LTC data to Kinects, and managed by a large cluster of computers and network attached storage devices.  The infrastructure will use computer vision and sound reconstruction algorithms on the raw sensor data to reconstruct 3D spatiotemporal data that provides a full range 3D visualization of human interactions.  By combining data from multiple sensor modalities in 3D, the infrastructure enables research in strengthening recognition of gestures and emotions of people engaged in interactions by analysis of prosody changes, face points, body skeletons, spatiotemporal motions, linguistics, heat signatures, and emotion- or task-driven physical impact.  Further, the PIs will develop large repositories of omniview multi-modal 3D spatiotemporal data, and conduct research on tying these repositories to sensors on next-generation ubiquitous devices to make them people- and object-aware.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sean",
   "pi_last_name": "Banerjee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sean Banerjee",
   "pi_email_addr": "sean.banerjee@wright.edu",
   "nsf_id": "000703063",
   "pi_start_date": "2017-04-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Natasha",
   "pi_last_name": "Banerjee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Natasha Banerjee",
   "pi_email_addr": "natasha.banerjee@wright.edu",
   "nsf_id": "000703066",
   "pi_start_date": "2017-04-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Clarkson University",
  "inst_street_address": "8 CLARKSON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "POTSDAM",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "3152686475",
  "inst_zip_code": "136761401",
  "inst_country_name": "United States",
  "cong_dist_code": "21",
  "st_cong_dist_code": "NY21",
  "org_lgl_bus_name": "CLARKSON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "SL2PF6R7MRN1"
 },
 "perf_inst": {
  "perf_inst_name": "Clarkson University",
  "perf_str_addr": "8 Clarkson Avenue",
  "perf_city_name": "Potsdam",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "136761401",
  "perf_ctry_code": "US",
  "perf_cong_dist": "21",
  "perf_st_cong_dist": "NY21",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 746916.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project developed the first multi-view, mulit-modal, and multi-person sensing space at Clarkson University. The sensing space consists of 16 Microsoft Azure Kinects to capture color and depth data, 16 Sierra Olympic Viento-G cameras to capture thermal data, 16 Delsys Trigno surface electromyography (sEMG) sensors to capture biomechanical data, 240 Point Grey BlackFly S high-speed cameras to capture color data, and 5 virtual reality headsets to visualize captured multi-view multi-modal data.<br /><br />The research grant resulted in 17 publications, with the following novel contributions:<br />1) The grant enabled the creation of the first approaches to perform real-time, within-system, and cross-system virtual reality (VR) authentication using motion trajectories of users as they performed tasks in VR by interacting with VR headsets and hand controllers. 5 publications at the International Conference on Multimedia Modeling (MMM 2019 -- Best Paper Candidate), IEEE Conference on Artificial Intelligence and Virtual Reality (AIVR 2019 -- 2 papers, 1 paper was Best Student Paper), IEEE Workshop on Everyday Virtual Reality (WEVR 2020), and IEEE Conference on Virtual Reality and 3D User Interfaces (VR 2021) were generated spanning research on automated authentication using nearest-neighbor matching, perceptrons, and Siamese neural networks. The work involved 2 graduate students and 3 undergraduate students, including 1 student completing their senior year of high school as their first year of college through Clarkson School. The Clarkson School student won the Goldwater Scholarship and the Best Student Paper Award at the AIVR 2019.<br />2) Using RGB-D sensors, a new approach was provided to detect if older adults have undertaken cognitive tasks by classifying the variance in 25 body joint movements that resulted in a publication at the 2019 International Conference on eHealth, Telemedicine, and Social Medicine (eTELEMED). The first and second authors on the paper were female undergraduate students. The first author was a Goldwater nominee.<br />3) The work resulted in a publication at the 2018 IEEE International Conference on Multimedia and Expo (ICME) on a novel hardware synchronization approach of multiple Microsoft Kinect v2 sensors and microphones using timecode. The work involved one graduate and one undergraduate student who performed the research while in Clarkson School. The student won the Goldwater Scholarship as a result. The grant generated a second publication by one undergraduate student at the 2018 International Conference on Multimedia Modeling on visualizing 3D spatiotemporal data using VR headsets. <br />4) The grant infrastructure enabled the generation of the first user-independent detection of hard and soft swipes on natural surfaces using thermal imagery, published at the 2018 IEEE International Workshop on Multimedia Signal Processing (MMSP). The first author on the publication was an undergraduate student and was awarded the Top 5% Paper Award at the workshop. The student was awarded the Goldwater Scholarship.<br />5) The grant also enabled the first approach for user-independent material prediction, such as concrete, wood, and paper, by analyzing thermal swipe signatures on the material surface. The work was published at MMM 2020. The student authors on the paper were undergraduate students, and the second author was a McNair Scholar from Cornell University. The students were supervised by the grant-supported post-doctoral associate, who is now a faculty member at Clarkson University.<br />6) The grant resulted in the first approach to perform smooth 3D printed restorations to broken objects by using mesh completion and optimization techniques for smooth projection. The work greatly expands the scope of object repair, enabling reduction in waste, repair in remote locations, and restoration of objects of cultural value. The work was published at the 2019 ACM Symposium on Computational Fabrication (SCF). The first author was an undergraduate student who was awarded an NSF Graduate Research Fellowship (GRF), the first for the Department of Computer Science at Clarkson University. The student was also the first computer science student to receive the Clarkson University Arts and Sciences Award, which is given to a student who combines elements from both arts and sciences in their research.<br />7) The grant enabled publication of work on detection of human hold on cups using thermal imprint of human contact on objects at ICME Workshops 2019. The research involved 1 PhD student. <br />8) The grant facilitated 2 papers at MMM 2018 on capture of food aging, 1 paper on detection of food readiness at ICME Workshops 2018, and 1 paper on food depletion at the MMM 2019. The research involved 2 graduate students and 5 undergraduate students. <br />9) Infrastructure provided by the grant enabled the GRF winner to publish one paper at MMM 2018 while an undergraduate on creating modular 3D printed actuatable items such as a camera-based 3D scanner.<br /><br />The sensing space has generated collaborations with faculty from the Departments of Mechanical Engineering and Physical Therapy at Clarkson University and the Crane School of Music at SUNY Potsdam. The research grant supported 26 undergraduates, including 9 female, 2 URMs, and 1 LGBTQIA+ students, with 12 students publishing conference papers.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/28/2021<br>\n\t\t\t\t\tModified by: Sean&nbsp;Banerjee</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873532059_image--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873532059_image--rgov-800width.jpg\" title=\"Dense multi-modal capture system\"><img src=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873532059_image--rgov-66x44.jpg\" alt=\"Dense multi-modal capture system\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The grant has resulted in the creation of a dense multi-modal capture space with 16 depth cameras, 16 thermal cameras, 16 sEMG sensors, and 240 high-speed color cameras.</div>\n<div class=\"imageCredit\">S. Banerjee</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Sean&nbsp;Banerjee</div>\n<div class=\"imageTitle\">Dense multi-modal capture system</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873393254_im21small--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873393254_im21small--rgov-800width.jpg\" title=\"3D scanner and multi-camera system for food aging\"><img src=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873393254_im21small--rgov-66x44.jpg\" alt=\"3D scanner and multi-camera system for food aging\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The grant has supported research on creating modular actuated 3D printable structures such as a 3D scanner, and multi-camera systems to model spatiotemporal events such as food aging.</div>\n<div class=\"imageCredit\">S. Banerjee</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Sean&nbsp;Banerjee</div>\n<div class=\"imageTitle\">3D scanner and multi-camera system for food aging</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873632423_cups1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873632423_cups1--rgov-800width.jpg\" title=\"Detection of hand hold on cups\"><img src=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873632423_cups1--rgov-66x44.jpg\" alt=\"Detection of hand hold on cups\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The grant has enabled work on detecting human hand hold on cups from depth images by using ground truth data provided through thermal images.</div>\n<div class=\"imageCredit\">N. Banerjee</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Sean&nbsp;Banerjee</div>\n<div class=\"imageTitle\">Detection of hand hold on cups</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873765440_filmstrip--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873765440_filmstrip--rgov-800width.jpg\" title=\"Multimodal capture of object lifting\"><img src=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873765440_filmstrip--rgov-66x44.jpg\" alt=\"Multimodal capture of object lifting\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The infrastructure has enabled the team to conduct research on analyzing how people perceive heavy lifting activities for as-needed intervention in home and work environments</div>\n<div class=\"imageCredit\">S. Banerjee</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Sean&nbsp;Banerjee</div>\n<div class=\"imageTitle\">Multimodal capture of object lifting</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873903797_broken1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873903797_broken1--rgov-800width.jpg\" title=\"Restoring damaged objects\"><img src=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632873903797_broken1--rgov-66x44.jpg\" alt=\"Restoring damaged objects\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The grant has enabled the first-of-its-kind work on automated restoration of broken objects using 3D printing.</div>\n<div class=\"imageCredit\">N. Lamb</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Sean&nbsp;Banerjee</div>\n<div class=\"imageTitle\">Restoring damaged objects</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632874017889_olderadults1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632874017889_olderadults1--rgov-800width.jpg\" title=\"Analyzing cognitive task performance in older adults from postural sway\"><img src=\"/por/images/Reports/POR/2021/1730183/1730183_10484293_1632874017889_olderadults1--rgov-66x44.jpg\" alt=\"Analyzing cognitive task performance in older adults from postural sway\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The grant has generated research on detecting if older adults have engaged in performance of cognitive tasks by analyzing variance in their body posture.</div>\n<div class=\"imageCredit\">S. Banerjee</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Sean&nbsp;Banerjee</div>\n<div class=\"imageTitle\">Analyzing cognitive task performance in older adults from postural sway</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe project developed the first multi-view, mulit-modal, and multi-person sensing space at Clarkson University. The sensing space consists of 16 Microsoft Azure Kinects to capture color and depth data, 16 Sierra Olympic Viento-G cameras to capture thermal data, 16 Delsys Trigno surface electromyography (sEMG) sensors to capture biomechanical data, 240 Point Grey BlackFly S high-speed cameras to capture color data, and 5 virtual reality headsets to visualize captured multi-view multi-modal data.\n\nThe research grant resulted in 17 publications, with the following novel contributions:\n1) The grant enabled the creation of the first approaches to perform real-time, within-system, and cross-system virtual reality (VR) authentication using motion trajectories of users as they performed tasks in VR by interacting with VR headsets and hand controllers. 5 publications at the International Conference on Multimedia Modeling (MMM 2019 -- Best Paper Candidate), IEEE Conference on Artificial Intelligence and Virtual Reality (AIVR 2019 -- 2 papers, 1 paper was Best Student Paper), IEEE Workshop on Everyday Virtual Reality (WEVR 2020), and IEEE Conference on Virtual Reality and 3D User Interfaces (VR 2021) were generated spanning research on automated authentication using nearest-neighbor matching, perceptrons, and Siamese neural networks. The work involved 2 graduate students and 3 undergraduate students, including 1 student completing their senior year of high school as their first year of college through Clarkson School. The Clarkson School student won the Goldwater Scholarship and the Best Student Paper Award at the AIVR 2019.\n2) Using RGB-D sensors, a new approach was provided to detect if older adults have undertaken cognitive tasks by classifying the variance in 25 body joint movements that resulted in a publication at the 2019 International Conference on eHealth, Telemedicine, and Social Medicine (eTELEMED). The first and second authors on the paper were female undergraduate students. The first author was a Goldwater nominee.\n3) The work resulted in a publication at the 2018 IEEE International Conference on Multimedia and Expo (ICME) on a novel hardware synchronization approach of multiple Microsoft Kinect v2 sensors and microphones using timecode. The work involved one graduate and one undergraduate student who performed the research while in Clarkson School. The student won the Goldwater Scholarship as a result. The grant generated a second publication by one undergraduate student at the 2018 International Conference on Multimedia Modeling on visualizing 3D spatiotemporal data using VR headsets. \n4) The grant infrastructure enabled the generation of the first user-independent detection of hard and soft swipes on natural surfaces using thermal imagery, published at the 2018 IEEE International Workshop on Multimedia Signal Processing (MMSP). The first author on the publication was an undergraduate student and was awarded the Top 5% Paper Award at the workshop. The student was awarded the Goldwater Scholarship.\n5) The grant also enabled the first approach for user-independent material prediction, such as concrete, wood, and paper, by analyzing thermal swipe signatures on the material surface. The work was published at MMM 2020. The student authors on the paper were undergraduate students, and the second author was a McNair Scholar from Cornell University. The students were supervised by the grant-supported post-doctoral associate, who is now a faculty member at Clarkson University.\n6) The grant resulted in the first approach to perform smooth 3D printed restorations to broken objects by using mesh completion and optimization techniques for smooth projection. The work greatly expands the scope of object repair, enabling reduction in waste, repair in remote locations, and restoration of objects of cultural value. The work was published at the 2019 ACM Symposium on Computational Fabrication (SCF). The first author was an undergraduate student who was awarded an NSF Graduate Research Fellowship (GRF), the first for the Department of Computer Science at Clarkson University. The student was also the first computer science student to receive the Clarkson University Arts and Sciences Award, which is given to a student who combines elements from both arts and sciences in their research.\n7) The grant enabled publication of work on detection of human hold on cups using thermal imprint of human contact on objects at ICME Workshops 2019. The research involved 1 PhD student. \n8) The grant facilitated 2 papers at MMM 2018 on capture of food aging, 1 paper on detection of food readiness at ICME Workshops 2018, and 1 paper on food depletion at the MMM 2019. The research involved 2 graduate students and 5 undergraduate students. \n9) Infrastructure provided by the grant enabled the GRF winner to publish one paper at MMM 2018 while an undergraduate on creating modular 3D printed actuatable items such as a camera-based 3D scanner.\n\nThe sensing space has generated collaborations with faculty from the Departments of Mechanical Engineering and Physical Therapy at Clarkson University and the Crane School of Music at SUNY Potsdam. The research grant supported 26 undergraduates, including 9 female, 2 URMs, and 1 LGBTQIA+ students, with 12 students publishing conference papers.\n\n\t\t\t\t\tLast Modified: 09/28/2021\n\n\t\t\t\t\tSubmitted by: Sean Banerjee"
 }
}