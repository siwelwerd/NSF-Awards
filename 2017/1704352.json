{
 "awd_id": "1704352",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Medium: Collaborative Research: Causal Inference: Identification, Learning, and Decision-Making",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 260169.0,
 "awd_amount": 260169.0,
 "awd_min_amd_letter_date": "2017-07-27",
 "awd_max_amd_letter_date": "2017-07-27",
 "awd_abstract_narration": "Understanding the causal mechanisms underlying an observed phenomenon is one of the primary goals of science. The realization that statistical associations in themselves are insufficient for elucidating those mechanisms has led researchers to enrich traditional statistical analysis with techniques based on \"causal inference\". Most of the recent advances in the field, however, operate under overly optimistic assumptions, which are often not met in practical, large-scale situations. This project seeks to develop a sound and general causal inference theory to cover those situations. The goal is to design a framework for decision-making of intelligent systems, including (1) learning a causal representation of the data-generating environment (learning), (2) performing efficient inference leveraging the learned model (planning/inference), and (3) using the new inferred representation, based on (1) and (2), to decide how to act next (decision-making). The new finding will benefit investigators in every area of the empirical sciences, including artificial intelligence, machine learning, statistics, economics, and the health and social sciences. The research is expected to fundamentally change the practice of data science in areas where the standard causal assumptions are violated (i.e., missing data, selection bias, and confounding bias). The work on decision-making is expected to pave the way toward the design of an \"automated scientist\", i.e., a program that combines both observational and experimental data, conducts its own experiments, and decides on the best choices of actions and policies. The project will also help to disseminate the principles of causal inference throughout the sciences by (1) engaging in the establishment of new \"data science\" curriculum where causal inference plays a central role, and (2) developing new educational materials for students and the general public explaining the practice of causal inference (e.g., book). Furthermore, the project supports the causal inference community by fostering a number of educational initiatives such as forums, workshops, and the creation of new incentives for the development of educational material (e.g., a \"Causality Education Award\").\r\n\r\nMaking claims about the existence of causal connections (structural learning), the magnitude of causal effects (identification), and designing optimal interventions (decision-making) are some of the most important tasks found throughout data-driven fields. This project will study identification, learning, and decision-making settings where (1) data are missing not at random, (2) non-parametric estimation is not feasible, and (3) aggregated behavior does not translate into guidance for individual-level decision-making. Specifically, the project will consider the problem when measurements are systematically distorted (missing data), which has received an enormous amount of attention in the statistical literature, but has not essentially been investigated in the context of causal inference when data are missing not at random. The project will further aim to leverage the special properties of linear models, the most common first approximation to non-parametric causal inference, to elucidate causal relationships in data, and to facilitate sensitivity analysis in such models.  Finally, the project will consider the fundamental problem on how causal and counterfactual knowledge can speed-up experimentation and support principled decision-making. The goal is to develop a complete algorithmic theory to determine when a particular causal effect can be learned from data and how to incorporate causal knowledge learned (possibly by experimentation) so that it can be amortized over new environmental conditions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jin",
   "pi_last_name": "Tian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jin Tian",
   "pi_email_addr": "jtian@iastate.edu",
   "nsf_id": "000487934",
   "pi_start_date": "2017-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Iowa State University",
  "inst_street_address": "1350 BEARDSHEAR HALL",
  "inst_street_address_2": "515 MORRILL ROAD",
  "inst_city_name": "AMES",
  "inst_state_code": "IA",
  "inst_state_name": "Iowa",
  "inst_phone_num": "5152945225",
  "inst_zip_code": "500112103",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IA04",
  "org_lgl_bus_name": "IOWA STATE UNIVERSITY OF SCIENCE AND TECHNOLOGY",
  "org_prnt_uei_num": "DQDBM7FGJPC5",
  "org_uei_num": "DQDBM7FGJPC5"
 },
 "perf_inst": {
  "perf_inst_name": "Iowa State University",
  "perf_str_addr": "1138 Pearson Hall",
  "perf_city_name": "Ames",
  "perf_st_code": "IA",
  "perf_st_name": "Iowa",
  "perf_zip_code": "500112207",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "IA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 260169.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Understanding the causal mechanisms underlying an observed phenomenon is one of the primary goals of science, for example, the effect of a drug on curing diabetes, a fertilizer on growing agricultural products, or an advertisement on the success of a political party. Inferring cause-and-effect relations from observational data, however, is a challenging task. In this project, we have developed new methods and tools to address some of the most common impediments to this task, including confounding bias, missing data, selection bias, transportability, and the finitude of the observed samples.</p>\n<ul>\n<li> Confounding bias arises from the lack of control over the effect of spurious variables on the outcome, i.e., correlation does not imply causation. Determining the identifiability of causal effects under confounding bias is well-understood in theory. In practice, however, it remains a challenge to apply the identification theory to estimating the identified causal functionals from finite samples. We have developed new methods and practical learning algorithms for estimating causal effects from finite samples that are computationally and statistically attractive. These results offer new tools for data scientists to be able to estimate causal effects more reliably in practical settings that the existing methods are not applicable.</li>\n<li>Missing data occur when some variable values are missing from recorded observations. It is a common problem across empirical sciences. We have developed new methods for determining whether a target probability distribution or causal effect is estimable from observed data with missing values. These results significantly advance the existing work and should be useful in a broad range of data-intensive applications.</li>\n<li>Selection bias is caused by the preferential exclusion of units from the samples and represents a major obstacle to valid causal and statistical inferences. It is a common problem across empirical disciplines. We have developed new general algorithms for identifying causal effects from selection biased data.&nbsp; The methods should help scientists to understand and alleviate the selection bias problem in a broad range of data-intensive applications.</li>\n<li>Transportability concerns with generalizing causal effects from a controlled experiment to settings beyond the particular study population - an important task found in empirical sciences. For instance, in medicine, some of the most important pharmaceutical discoveries were first developed and tested using rats as subjects, while the goal was to use the results to treat humans. In psychology, college students are usually the subject of experimentation, so as to answer questions about human cognition, which include subjects with and without exposure to higher education. While a proper design and careful execution of the experiment would support the validity of inferences about the population in which the experiment was conducted, extrapolation of the results to a broader or different population is much involved. We have investigated the assumptions and developed new machinery to generalize experimental data to infer causal effects across domains. The work will be helpful for data scientists to understand, model, and solve the challenging issues of generalizability of experimental findings across disparate settings as experiments are, almost invariably, performed with the intent of being used outside the ?laboratory? setting.</li>\n</ul>\n<p>The results developed in this project will impact a broad range of data-driven disciplines that concern with estimating causal effects from observational data, including artificial intelligence, statistics, economics, and the health and social sciences, helping scientists to understand, formalize, and alleviate the most common impediments to causal effects estimation including confounding bias, missing data, selection bias, transportability, and the finitude of the observed samples, and providing tools for scientists to be able to estimate causal effects reliably in practical settings.</p>\n<p>The project has provided research training and opportunities for Ph.D. students including a female. The results of the project have been disseminated through talks and publications in the major AI and machine learning conferences, a causal inference workshop, and tutorials in summer schools. New educational materials have been developed for teaching undergraduate and graduate AI and machine learning courses.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/05/2020<br>\n\t\t\t\t\tModified by: Jin&nbsp;Tian</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nUnderstanding the causal mechanisms underlying an observed phenomenon is one of the primary goals of science, for example, the effect of a drug on curing diabetes, a fertilizer on growing agricultural products, or an advertisement on the success of a political party. Inferring cause-and-effect relations from observational data, however, is a challenging task. In this project, we have developed new methods and tools to address some of the most common impediments to this task, including confounding bias, missing data, selection bias, transportability, and the finitude of the observed samples.\n\n Confounding bias arises from the lack of control over the effect of spurious variables on the outcome, i.e., correlation does not imply causation. Determining the identifiability of causal effects under confounding bias is well-understood in theory. In practice, however, it remains a challenge to apply the identification theory to estimating the identified causal functionals from finite samples. We have developed new methods and practical learning algorithms for estimating causal effects from finite samples that are computationally and statistically attractive. These results offer new tools for data scientists to be able to estimate causal effects more reliably in practical settings that the existing methods are not applicable.\nMissing data occur when some variable values are missing from recorded observations. It is a common problem across empirical sciences. We have developed new methods for determining whether a target probability distribution or causal effect is estimable from observed data with missing values. These results significantly advance the existing work and should be useful in a broad range of data-intensive applications.\nSelection bias is caused by the preferential exclusion of units from the samples and represents a major obstacle to valid causal and statistical inferences. It is a common problem across empirical disciplines. We have developed new general algorithms for identifying causal effects from selection biased data.  The methods should help scientists to understand and alleviate the selection bias problem in a broad range of data-intensive applications.\nTransportability concerns with generalizing causal effects from a controlled experiment to settings beyond the particular study population - an important task found in empirical sciences. For instance, in medicine, some of the most important pharmaceutical discoveries were first developed and tested using rats as subjects, while the goal was to use the results to treat humans. In psychology, college students are usually the subject of experimentation, so as to answer questions about human cognition, which include subjects with and without exposure to higher education. While a proper design and careful execution of the experiment would support the validity of inferences about the population in which the experiment was conducted, extrapolation of the results to a broader or different population is much involved. We have investigated the assumptions and developed new machinery to generalize experimental data to infer causal effects across domains. The work will be helpful for data scientists to understand, model, and solve the challenging issues of generalizability of experimental findings across disparate settings as experiments are, almost invariably, performed with the intent of being used outside the ?laboratory? setting.\n\n\nThe results developed in this project will impact a broad range of data-driven disciplines that concern with estimating causal effects from observational data, including artificial intelligence, statistics, economics, and the health and social sciences, helping scientists to understand, formalize, and alleviate the most common impediments to causal effects estimation including confounding bias, missing data, selection bias, transportability, and the finitude of the observed samples, and providing tools for scientists to be able to estimate causal effects reliably in practical settings.\n\nThe project has provided research training and opportunities for Ph.D. students including a female. The results of the project have been disseminated through talks and publications in the major AI and machine learning conferences, a causal inference workshop, and tutorials in summer schools. New educational materials have been developed for teaching undergraduate and graduate AI and machine learning courses.\n\n \n\n\t\t\t\t\tLast Modified: 10/05/2020\n\n\t\t\t\t\tSubmitted by: Jin Tian"
 }
}