{
 "awd_id": "1714617",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Bayesian Inverse Problems and Model Uncertainties",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Pedro Embid",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 216634.0,
 "awd_amount": 216634.0,
 "awd_min_amd_letter_date": "2017-07-31",
 "awd_max_amd_letter_date": "2017-07-31",
 "awd_abstract_narration": "The traditional and very natural paradigm in science is to build predictive mathematical models that move from causes to consequences. However, it often happens that observations of consequences are available, and one needs to identify the causes that made the observations possible. The latter type of problems are known as inverse problems. Inverse problems are characterized by their high sensitivity to errors in the measurements and the models used, the existence of not just one but several possible solutions, and their computational complexity. This project focuses on one particular but central aspect in inverse problems: Assume that a very detailed and complex predictive model exists, known to be able to produce predictions that match well with observations. Furthermore, assume that the model is computationally very demanding, and it contains numerous parameters whose values are unknown or poorly known. To solve the inverse problem in the required time frame, it may be that a simplified, or reduced model, needs to be used. Given that inverse problems are sensitive to errors in the model, it typically happens that the model reduction introduces an uncontrolled error, or discrepancy between the model and reality, that may render the solution of the inverse problem completely useless. The investigator and his colleagues have proposed a general methodology to handle the modeling error problem in the statistical framework, and in this project, the aim is to develop the methodology further so that it allows a reliable way to find a useful solution with limited computational resources, and to quantify the reliability of such solution. The main applications in this project are in the field of medicine, including mapping of the brain activity, identification and localization of stroke using a portable equipment, and development of fast and portable computing tools to model blood flow, but the results also have applications beyond medical applications. \r\n\r\nThe technical difficulty in handling the modeling error in an inverse problem is that it depends on the unknown cause that the inverse problem is seeking. However, the Bayesian statistical paradigm provides a very natural solution to this problem. In the Bayesian context, the unknown of primary interest is described as a random variable that has an a priori probability distribution, and therefore, it is possible to estimate a probability distribution of the modeling error and include it as part of the likelihood model. This basic observation has been shown to lead to algorithms that dramatically improve the estimates compared to results that ignore the modeling error. In this project, the methodology will be developed further, by carefully following how the inclusion of the modeling error distribution affects the Bayesian posterior distribution of the unknown, and conversely, how the modeling error distribution can be updated after the data is used to update the prior density of the unknown. Such tracking will hopefully lead to a computationally efficient way of quantifying uncertainties in the inverse solutions in the presence of modeling errors.  One family of problems the project addresses is multi-scale inverse problems, in which the unknowns of primary interest are describing fine-scale behavior of the system, while the observation represents a macroscopic, coarse scale quantity. These types of problems often appear in biological applications, where the high-fidelity microscopic models are often stochastic in nature, and cannot be handled directly in the standard Bayesian framework.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Erkki",
   "pi_last_name": "Somersalo",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Erkki J Somersalo",
   "pi_email_addr": "ejs49@case.edu",
   "nsf_id": "000277541",
   "pi_start_date": "2017-07-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Case Western Reserve University",
  "inst_street_address": "10900 EUCLID AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CLEVELAND",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "2163684510",
  "inst_zip_code": "441064901",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "OH11",
  "org_lgl_bus_name": "CASE WESTERN RESERVE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJMKEF7EJW69"
 },
 "perf_inst": {
  "perf_inst_name": "Case Western Reserve University",
  "perf_str_addr": "Nord Hall suite 615",
  "perf_city_name": "Cleveland",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "441064901",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "OH11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126600",
   "pgm_ele_name": "APPLIED MATHEMATICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 216634.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Inverse problems aim at retrieving information about unknowns that cannot be directly observed by means of measuring some observable quantities that are related to the quantity of interest through a mathematical model. Inverse problems are characterized by their ill-posedness, which means that small errors in the data may propagate to huge errors in the estimated quantity. Errors in the observations are usually understood as measuring imprecisions, however, one potential source of error is the model itself: It is well understood that a mathematical model at best is an approximation of the reality, and since the data come from the reality, the difference between the model prediction and reality must be treated as an error in data. Failure to properly model this error may lead to flawed and possibly useless solutions of the inverse problem. The main topic of this project was to develop techniques to tackle this problem, with particular applications in mind from medical imaging to modeling brain functions. The methodology was also applied to epidemiology models and Covid-19 spread prediction from infection count data.</p>\n<p>The overaching methodology in this project is the Bayesian approach to inverse problems, in which lack of information is modeled by using random variables, and the associated uncertainty is encoded in the probability distributions of the random variables. The Bayesian framework provides a versatile environment to tackle the modeling error problem, because it allows to consider the model predictions without knowing in advance the value of the unknown of interest. In the Bayesian setting, all information about the unknown that is available before the experiment is encoded in the prior probability distribution. Prior information about the unknown is often given in a non-quantitative way, and a significant part of this project was devoted to the development of sophisticated prior models that correspond to certain types of prior information, as well as to computational tools to solve the inverse problems using these priors. One important class of priors considered in this project is sparsity promoting priors, expressing the prior belief that the unknown quantity allows a characterization in terms of few, but not specified, degrees of freedom. The project led to new breakthoughs in showing that certain heuristic methods used in engineering applications allow a rigorous mathematical interpretation, and the importance of this finding was demonstrated by improved algorithms, e.g., in brain imaging. In particular, new connections between the concepts of sparsity, sensitivity, and exchangeability were established. The ideas developed for inverse problems can be used also in data science applications such as dictionary learning. Important new results were also obtained in the area of discretizing inverse problems based on partial differential equations or integral equations, establishing new connections between classical error estimation methods, inverse problems, and modeling errors.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/07/2021<br>\n\t\t\t\t\tModified by: Erkki&nbsp;J&nbsp;Somersalo</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nInverse problems aim at retrieving information about unknowns that cannot be directly observed by means of measuring some observable quantities that are related to the quantity of interest through a mathematical model. Inverse problems are characterized by their ill-posedness, which means that small errors in the data may propagate to huge errors in the estimated quantity. Errors in the observations are usually understood as measuring imprecisions, however, one potential source of error is the model itself: It is well understood that a mathematical model at best is an approximation of the reality, and since the data come from the reality, the difference between the model prediction and reality must be treated as an error in data. Failure to properly model this error may lead to flawed and possibly useless solutions of the inverse problem. The main topic of this project was to develop techniques to tackle this problem, with particular applications in mind from medical imaging to modeling brain functions. The methodology was also applied to epidemiology models and Covid-19 spread prediction from infection count data.\n\nThe overaching methodology in this project is the Bayesian approach to inverse problems, in which lack of information is modeled by using random variables, and the associated uncertainty is encoded in the probability distributions of the random variables. The Bayesian framework provides a versatile environment to tackle the modeling error problem, because it allows to consider the model predictions without knowing in advance the value of the unknown of interest. In the Bayesian setting, all information about the unknown that is available before the experiment is encoded in the prior probability distribution. Prior information about the unknown is often given in a non-quantitative way, and a significant part of this project was devoted to the development of sophisticated prior models that correspond to certain types of prior information, as well as to computational tools to solve the inverse problems using these priors. One important class of priors considered in this project is sparsity promoting priors, expressing the prior belief that the unknown quantity allows a characterization in terms of few, but not specified, degrees of freedom. The project led to new breakthoughs in showing that certain heuristic methods used in engineering applications allow a rigorous mathematical interpretation, and the importance of this finding was demonstrated by improved algorithms, e.g., in brain imaging. In particular, new connections between the concepts of sparsity, sensitivity, and exchangeability were established. The ideas developed for inverse problems can be used also in data science applications such as dictionary learning. Important new results were also obtained in the area of discretizing inverse problems based on partial differential equations or integral equations, establishing new connections between classical error estimation methods, inverse problems, and modeling errors.\n\n\t\t\t\t\tLast Modified: 09/07/2021\n\n\t\t\t\t\tSubmitted by: Erkki J Somersalo"
 }
}