{
 "awd_id": "1723476",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAPA: Collaborative Research: Lightweight Abstract Memory Features",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2017-08-31",
 "awd_max_amd_letter_date": "2017-08-31",
 "awd_abstract_narration": "The memory subsystem of modern computing systems has seen tremendous innovations, incorporating new features to aid programmers in creating fast, secure, correct, and power-efficient software.  Unfortunately, harnessing these features is a challenge, as programming languages do not expose advanced abilities of the memory subsystem to programmers.  This project focuses on the interface between programming languages and memory hardware. The intellectual merits include the creation of a rigorous semantics for memory features, so that programmers can reason about individual features and their composition; and the creation of compilation tools and run-time systems that allow programmers to use new memory features, in isolation or combination, for maximum gain.  The project's broader significance and importance are its impact on the software and hardware industry, by facilitating rapid adoption of new memory features; the education and training of graduate students; and the creation of a tutorial to aid in dissemination and adoption of the developed tools and techniques.\r\n\r\nHardware implementations of memory features are typically fast but limited by physical capacity, and the precise semantics of features are often vendor-specific.  The theoretical portion of the work will create rigorous semantics for memory features, which transcend individual implementation and allow programmers and static analysis tools to reason about a program's interaction with memory.  The research will construct virtualized run-time systems to overcome hardware constraints, and to emulate features when they are not present.  Its implementations will employ run-time adaptivity to fine-tune themselves to a given system's feature availability, support for composition of features, and hardware/workload characteristics.  A custom compiler infrastructure, built atop the LLVM system, will provide a lightweight syntax through which programmers can easily add support for memory features to their existing codes.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aviral",
   "pi_last_name": "Shrivastava",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aviral Shrivastava",
   "pi_email_addr": "aviral.shrivastava@asu.edu",
   "nsf_id": "000490268",
   "pi_start_date": "2017-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852816011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "021Z",
   "pgm_ref_txt": "Industry Partnerships"
  },
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  },
  {
   "pgm_ref_code": "8585",
   "pgm_ref_txt": "NSF/Intel Partnership Projects"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The recently completed NSF &ldquo;CAPA: Lightweight Abstract Memory Features&rdquo;, has had numerous and significant impact in terms of intellectual innovation, personnel training and community impact.</p>\n<p>&nbsp;</p>\n<p>The interface between the CPU and Memory is a driver of innovation in modern computing systems. Examples include secure memory, scratchpad memory, persistent memory, and transactional memory. A significant challenge that faces both implementors and researchers is that each novel memory feature appears to require a different interface, different instrumentation, and different compiler support. This problem is taken to the extreme in accelerator design, where both the time-to-market and efficiency of the design are vitally important. This project developed several tools and techniques to elevate the level of abstraction of accelerator design and programming. As a part of this project, several techniques that makes programming accelerators easier were developed, thus paving the way to including code generation effects in the evaluation of accelerator design &ndash; resulting in much more efficient and quicker accelerator design.</p>\n<p>This project has resulted in 12 publications at venues including Proceedings of IEEE (PIEEE), Design Automation Conference (DAC), ACM Transactions on Architecture and Code Optimization (TACO), IPDPS, IEEE TCAD, ACM TECS, ICASSP and VTS. These publications already have more than 50 citations. These works are now being heavily cited. This project has resulted in 2 granted US patents, and 1 more is pending. This project has supported the research of 5 Ph.D. students and 3 M.S. students. The students who were working on this project have been hired by Apple, Google, Intel, nVIDIA, ARM, and Qualcomm.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/08/2022<br>\n\t\t\t\t\tModified by: Aviral&nbsp;Shrivastava</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe recently completed NSF \"CAPA: Lightweight Abstract Memory Features\", has had numerous and significant impact in terms of intellectual innovation, personnel training and community impact.\n\n \n\nThe interface between the CPU and Memory is a driver of innovation in modern computing systems. Examples include secure memory, scratchpad memory, persistent memory, and transactional memory. A significant challenge that faces both implementors and researchers is that each novel memory feature appears to require a different interface, different instrumentation, and different compiler support. This problem is taken to the extreme in accelerator design, where both the time-to-market and efficiency of the design are vitally important. This project developed several tools and techniques to elevate the level of abstraction of accelerator design and programming. As a part of this project, several techniques that makes programming accelerators easier were developed, thus paving the way to including code generation effects in the evaluation of accelerator design &ndash; resulting in much more efficient and quicker accelerator design.\n\nThis project has resulted in 12 publications at venues including Proceedings of IEEE (PIEEE), Design Automation Conference (DAC), ACM Transactions on Architecture and Code Optimization (TACO), IPDPS, IEEE TCAD, ACM TECS, ICASSP and VTS. These publications already have more than 50 citations. These works are now being heavily cited. This project has resulted in 2 granted US patents, and 1 more is pending. This project has supported the research of 5 Ph.D. students and 3 M.S. students. The students who were working on this project have been hired by Apple, Google, Intel, nVIDIA, ARM, and Qualcomm.\n\n \n\n\t\t\t\t\tLast Modified: 05/08/2022\n\n\t\t\t\t\tSubmitted by: Aviral Shrivastava"
 }
}