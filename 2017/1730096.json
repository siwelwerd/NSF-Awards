{
 "awd_id": "1730096",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "II-New: Laboratory for Studying Next Generation Computer-Mediated Teamwork",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2017-06-01",
 "awd_exp_date": "2020-05-31",
 "tot_intn_awd_amt": 225010.0,
 "awd_amount": 225010.0,
 "awd_min_amd_letter_date": "2017-05-16",
 "awd_max_amd_letter_date": "2019-10-31",
 "awd_abstract_narration": "The goal of this project is to provide Cornell researchers with equipment that tracks people's physiological responses, eye gaze and body movements as they use communication and collaboration tools.  This equipment can help researchers better understand how the use of these tools affects people's stress levels and task performance and will lead to the design of future tools that help people work more effectively. The proposed infrastructure will enhance education at Cornell and other locations.  Cornell professors will be able to integrate the equipment into their classes to create novel and engaging learning experiences, and students will be able to use the equipment to explore their own ideas in class projects.   The infrastructure will also be used as part of outreach activities aimed at increasing diversity in STEM disciplines, including two programs for junior and senior high school girls. The results of studies using this equipment will help businesses and organizations make informed decisions about what communication and collaboration tools will best support their mission.  The results will also lead to new tools that individuals can use to manage their own stress levels and maximize their performance.\r\n\r\nThis project will develop a laboratory for research on next generation computer-mediated and computer-enhanced teamwork and group interaction that will allow investigators to capture complex relationships among technology, individual cognitive and affective states, and team dynamics.  The infrastructure will support a broad range of forward-looking research activities by Cornell faculty and students working in areas such as human computer interaction, computer-mediated communication, computer-supported cooperative work, virtual and augmented reality, social computing, and human-robot interaction.  The infrastructure will support both the fine-grained measurement of human responses (e.g., heart rate, eye gaze, body movement) and the development and evaluation of new social computing tools that draw on these fine grained measures, such as 'just in time' interventions.  It will allow investigators to ask new research questions that can only be answered by capturing complex interrelationships among technology, individual cognitive and affective states, and team dynamics. Investigators will also be able to design and test new types of computational tools that draw on the psychophysiological, gaze and body position data provided by the infrastructure.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Susan",
   "pi_last_name": "Fussell",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Susan Fussell",
   "pi_email_addr": "sfussell@cornell.edu",
   "nsf_id": "000209199",
   "pi_start_date": "2017-05-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Geraldine",
   "pi_last_name": "Gay",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Geraldine K Gay",
   "pi_email_addr": "gkg1@cornell.edu",
   "nsf_id": "000087893",
   "pi_start_date": "2017-05-16",
   "pi_end_date": "2019-10-31"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Natalya",
   "pi_last_name": "Bazarova",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Natalya N Bazarova",
   "pi_email_addr": "nnb8@cornell.edu",
   "nsf_id": "000596425",
   "pi_start_date": "2017-05-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Malte",
   "pi_last_name": "Jung",
   "pi_mid_init": "F",
   "pi_sufx_name": "",
   "pi_full_name": "Malte F Jung",
   "pi_email_addr": "mfj28@cornell.edu",
   "nsf_id": "000654925",
   "pi_start_date": "2017-05-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andrea",
   "pi_last_name": "Won",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Andrea S Won",
   "pi_email_addr": "a.s.won@cornell.edu",
   "nsf_id": "000727233",
   "pi_start_date": "2017-05-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "493E Mann Library Building",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148534301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 225010.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The purpose of this award was to develop a laboratory for cutting edge research on computer-mediated communication, human-computer interaction, human-robot interaction, virtual and augmented reality, and social computing. The laboratory allows researchers to capture complex relationships among technology, individual cognitive and affective states, and team dynamics.&nbsp;</p>\n<p><strong>Intellectual Merit:</strong></p>\n<p>The laboratory equipment consists of (a) Biopac mobile and stationary sensors that can be used to collect a wide range of psychophysiological data and (b) Tobii mobile and stationary eye trackers. Specific Biopac equipment purchased included sensors for cardiac activity (ECG), respiration (RSP),&nbsp;muscle activity&nbsp;(EMG), electrodermal activity (EDA or GSR), and brain wave (EEG).</p>\n<p>This combination of equipment allows researchers to measure people?s levels of stress, cognitive load, and other variables as they are interacting with websites, software, robots, and other computing technologies. When combined with eye-tracking, researchers can pinpoint precisely where on the screen or in the environment a participant is looking and match this gaze to their psychophysiological responses. These sophisticated analyses will allow researchers to better understand how technology affects people?s social and cognitive processes, to design better and easier to use interfaces, and to develop new tools that draw on gaze and psychophysiological measures, such as ?just in time? interventions or adaptive tutoring.</p>\n<p>The primary activities covered by this award include the purchase and integration of the equipment, the development of training materials (user manual, slide deck, and videos), and the creation of classroom demonstrations that allow students to try out the mobile eye trackers and biosensors and learn more about how they operate.</p>\n<p><strong>Broader Impacts:</strong></p>\n<p>The project had broader impacts in several ways.&nbsp; First, specific activities and training sessions helped educators at Cornell integrate the infrastructure into their classes and research projects. The equipment was also made available to students working on class projects.&nbsp; Second, several undergraduate and master?s students gained expertise using sophisticated biosensor and eye-tracking equipment by working in the lab for class credit. Third, the award created infrastructure that can be used by many researchers to investigate important questions about the relationships among people?s interactions with computing technology and their cognitive, affective, and social responses.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/29/2021<br>\n\t\t\t\t\tModified by: Susan&nbsp;Fussell</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe purpose of this award was to develop a laboratory for cutting edge research on computer-mediated communication, human-computer interaction, human-robot interaction, virtual and augmented reality, and social computing. The laboratory allows researchers to capture complex relationships among technology, individual cognitive and affective states, and team dynamics. \n\nIntellectual Merit:\n\nThe laboratory equipment consists of (a) Biopac mobile and stationary sensors that can be used to collect a wide range of psychophysiological data and (b) Tobii mobile and stationary eye trackers. Specific Biopac equipment purchased included sensors for cardiac activity (ECG), respiration (RSP), muscle activity (EMG), electrodermal activity (EDA or GSR), and brain wave (EEG).\n\nThis combination of equipment allows researchers to measure people?s levels of stress, cognitive load, and other variables as they are interacting with websites, software, robots, and other computing technologies. When combined with eye-tracking, researchers can pinpoint precisely where on the screen or in the environment a participant is looking and match this gaze to their psychophysiological responses. These sophisticated analyses will allow researchers to better understand how technology affects people?s social and cognitive processes, to design better and easier to use interfaces, and to develop new tools that draw on gaze and psychophysiological measures, such as ?just in time? interventions or adaptive tutoring.\n\nThe primary activities covered by this award include the purchase and integration of the equipment, the development of training materials (user manual, slide deck, and videos), and the creation of classroom demonstrations that allow students to try out the mobile eye trackers and biosensors and learn more about how they operate.\n\nBroader Impacts:\n\nThe project had broader impacts in several ways.  First, specific activities and training sessions helped educators at Cornell integrate the infrastructure into their classes and research projects. The equipment was also made available to students working on class projects.  Second, several undergraduate and master?s students gained expertise using sophisticated biosensor and eye-tracking equipment by working in the lab for class credit. Third, the award created infrastructure that can be used by many researchers to investigate important questions about the relationships among people?s interactions with computing technology and their cognitive, affective, and social responses.\n\n \n\n\t\t\t\t\tLast Modified: 03/29/2021\n\n\t\t\t\t\tSubmitted by: Susan Fussell"
 }
}