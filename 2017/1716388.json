{
 "awd_id": "1716388",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Approximate Message Passing Algorithms and Networks",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 499570.0,
 "awd_amount": 499570.0,
 "awd_min_amd_letter_date": "2017-06-28",
 "awd_max_amd_letter_date": "2017-06-28",
 "awd_abstract_narration": "A problem of paramount importance in engineering, science, and medicine is that of recovering information signals from high-dimensional measurements.  This problem manifests in many forms, e.g., reconstructing a high-quality image from a few noisy Fourier projections, determining which features in patient data are most likely associated with a given disease, or classifying which objects are present within an image.  Until recently, the dominant approach to signal recovery was algorithmic.  But nowadays, algorithms are increasingly being replaced by deep neural networks (DNNs), which can learn optimal inference strategies directly from the data.  This project researches algorithmic as well as deep-neural-network (DNN) approaches to high-dimensional signal recovery, leveraging connections between them to make advances in both.\r\n\r\nOn the algorithmic front, this project investigates the vector approximate message passing (VAMP) algorithm.  Like the original AMP algorithm of Donoho, Maleki, and Montanari, the VAMP algorithm enjoys low complexity and a scalar state-evolution that rigorously and concisely characterizes its behavior.  However, VAMP is applicable to a much larger class of problems than AMP.  On the DNN front, this project investigates DNNs whose architecture is inspired by the processing steps within VAMP.  The resulting DNNs are highly interpretable and, for some simple applications, statistical optimal.  This project aims to develop this VAMP-based DNN design framework to work with more complex applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Philip",
   "pi_last_name": "Schniter",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Philip Schniter",
   "pi_email_addr": "schniter@ece.osu.edu",
   "nsf_id": "000297419",
   "pi_start_date": "2017-06-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio State University",
  "inst_street_address": "1960 KENNY RD",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBUS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "6146888735",
  "inst_zip_code": "432101016",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OH03",
  "org_lgl_bus_name": "OHIO STATE UNIVERSITY, THE",
  "org_prnt_uei_num": "MN4MDDMN8529",
  "org_uei_num": "DLWBSLWAJWR1"
 },
 "perf_inst": {
  "perf_inst_name": "Department of Electrical and Computer Engineering",
  "perf_str_addr": "2015 Neil Ave",
  "perf_city_name": "Columbus",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "432101241",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OH03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 499570.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research focused on the problem of designing and analyzing signal recovery algorithms that leverage the recently proposed approximate message passing (AMP) framework together with deep neural networks (DNNs).&nbsp;</p>\n<p>For example, the research proved fundamental theorems about the performance and convergence of the vector AMP (VAMP) algorithm when used with non-separable Lipschitz denoisers, such as those implemented by DNNs.&nbsp; In particular, it proved that if VAMP's forward operator has a right singular vector matrix that is Haar (i.e., uniformly distributed over the group of orthogonal matrices) then, as the matrix dimensions grow to infinity, the macroscopic behavior of the algorithm can be perfectly predicted by a scalar state evolution (SE).&nbsp; Furthermore, when the denoiser is MMSE and the SE has a unique fixed point, nonseparable VAMP converges to the MMSE solution of the corresponding linear inverse problem.&nbsp; An extension of the non-separable VAMP algorithm was proposed to solve the joint calibration and recovery problem, where the forward operator is imperfectly known.<br /><br />The research also proposed the multi-layer(ML)-VAMP framework, which extends the VAMP framework from inference in linear models to inference in multi-layer generative models, which include generalized linear models as a special case.&nbsp; Like with non-separable VAMP, we proved that, for a class of randomized problems, the macroscopic behavior of ML-VAMP is characterized by an SE in the large-system limit, and that SE guarantees MMSE optimal inference performance under certain conditions.<br /><br />In addition to the aforementioned AMP-based methods, the research also investigated the closely related \"plug-and-play\" family of algorithms, which do not assume randomization.&nbsp; In particular, the regularization-by-denoising (RED) framework was analyzed, where a lack of correspondence between the RED criteria and RED algorithms was established, which prompted a reinterpretation of RED algorithms as \"score-matching by denoising.\" Furthermore, state-of-the-art RED algorithms with provable convergence were proposed.&nbsp; In addition, an auto-tuning primal-dual plug-and-play algorithm was proposed to solve noisy linear inverse problems.<br /><br />Finally, various applications of the aforementioned algorithms were investigated, such as to short-burst wireless communication, image recovery, compressive learning, and phase retrieval.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/03/2021<br>\n\t\t\t\t\tModified by: Philip&nbsp;Schniter</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis research focused on the problem of designing and analyzing signal recovery algorithms that leverage the recently proposed approximate message passing (AMP) framework together with deep neural networks (DNNs). \n\nFor example, the research proved fundamental theorems about the performance and convergence of the vector AMP (VAMP) algorithm when used with non-separable Lipschitz denoisers, such as those implemented by DNNs.  In particular, it proved that if VAMP's forward operator has a right singular vector matrix that is Haar (i.e., uniformly distributed over the group of orthogonal matrices) then, as the matrix dimensions grow to infinity, the macroscopic behavior of the algorithm can be perfectly predicted by a scalar state evolution (SE).  Furthermore, when the denoiser is MMSE and the SE has a unique fixed point, nonseparable VAMP converges to the MMSE solution of the corresponding linear inverse problem.  An extension of the non-separable VAMP algorithm was proposed to solve the joint calibration and recovery problem, where the forward operator is imperfectly known.\n\nThe research also proposed the multi-layer(ML)-VAMP framework, which extends the VAMP framework from inference in linear models to inference in multi-layer generative models, which include generalized linear models as a special case.  Like with non-separable VAMP, we proved that, for a class of randomized problems, the macroscopic behavior of ML-VAMP is characterized by an SE in the large-system limit, and that SE guarantees MMSE optimal inference performance under certain conditions.\n\nIn addition to the aforementioned AMP-based methods, the research also investigated the closely related \"plug-and-play\" family of algorithms, which do not assume randomization.  In particular, the regularization-by-denoising (RED) framework was analyzed, where a lack of correspondence between the RED criteria and RED algorithms was established, which prompted a reinterpretation of RED algorithms as \"score-matching by denoising.\" Furthermore, state-of-the-art RED algorithms with provable convergence were proposed.  In addition, an auto-tuning primal-dual plug-and-play algorithm was proposed to solve noisy linear inverse problems.\n\nFinally, various applications of the aforementioned algorithms were investigated, such as to short-burst wireless communication, image recovery, compressive learning, and phase retrieval.\n\n\t\t\t\t\tLast Modified: 12/03/2021\n\n\t\t\t\t\tSubmitted by: Philip Schniter"
 }
}