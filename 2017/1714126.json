{
 "awd_id": "1714126",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: Using Stories to Improve Computer Security Decision Making",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2017-08-15",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 515987.0,
 "awd_amount": 531987.0,
 "awd_min_amd_letter_date": "2017-07-18",
 "awd_max_amd_letter_date": "2019-08-01",
 "awd_abstract_narration": "People regularly need to make security and privacy decisions; however, they often don't realize they are making these decisions, and when they do, they often lack the experience and ability to make good choices.  Based on studies of how people make decisions \"in the wild\", this project looks to improve people's security education, training, and awareness (SETA) by (1) using short stories about regular users' security behaviors, rather than expert advice, facts, and warnings, to raise awareness of and suggest responses to security risks, and (2) deliver those stories at exactly the times people might need them, rather than as a separate training program divorced from people's regular use and needs around security.  Through a series of interviews the project team will learn more about how experts versus non-experts make security-related decisions in the moment.  Using these insights and theories of decision-making, the team will develop and test a set of story-based training materials for common security decisions including selecting passwords, ignoring phishing emails that lure people to download malware or give personal information to fake websites, and avoiding sites that present invalid security credentials.  These experiments will increase knowledge of how people make security decisions and how to design materials to support SETA, as well as directly improving security at the lead researcher's institution through live testing with students and staff.  The PI will also involve both undergraduate students and people from underrepresented groups in the research and publicly release the materials the team develops.\r\n \r\nThe project seeks to test the hypothesis that telling end users stories about security incidents can better train them to resist semantic attacks than traditional facts-and-advice training.  The researchers will first develop a detailed understanding of how people make everyday in-the-moment security decisions, using Critical Decision Method and Experience Sampling Method-based approaches that focus on specific past attacks.  The team will interview both experts and non-experts to learn what features they use to recognize attacks and how they identify actions to take; comparing expert to non-expert behavior will help identify vulnerabilities and inform both effective training goals and materials.  These insights will be used in developing a set of story-based training materials that emphasize important constructs suggested by the theory of Naturalistic Decision Making including incident typicality, social norms around responses, causality (linking responses to outcomes), and empowerment and efficacy in security decision-making.  Through a series of field experiments in collaboration with security mangers at the lead researcher's institution, the team will iteratively improve the training materials while developing theoretical knowledge of how stories about security incidents can support security decision-making in naturalistic settings.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Wash",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Richard Wash",
   "pi_email_addr": "wash@msu.edu",
   "nsf_id": "000575042",
   "pi_start_date": "2017-07-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Michigan State University",
  "inst_street_address": "426 AUDITORIUM RD RM 2",
  "inst_street_address_2": "",
  "inst_city_name": "EAST LANSING",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "5173555040",
  "inst_zip_code": "488242600",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MI07",
  "org_lgl_bus_name": "MICHIGAN STATE UNIVERSITY",
  "org_prnt_uei_num": "VJKZC4D1JN36",
  "org_uei_num": "R28EKN92ZTZ9"
 },
 "perf_inst": {
  "perf_inst_name": "Michigan State University/Communication Arts & Sciences",
  "perf_str_addr": "404 Wilson Road",
  "perf_city_name": "East Lansing",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "488242600",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MI07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 515987.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In the summer of 2016, both former Secretary of State Colin Powell, and presidential candidate Hillary Clinton's campaign manager John Podesta had the contents of their email stolen and published on Wikileaks. Neither theft exploited technical vulnerabilities; instead, the attacker simply sent an email to their targets pretending to be from Google (their email provider) asking for their username and password. These attacks are ``phishing'' attacks. They target and exploit the way that the humans assign meaning to information and make decisions about their use of computing systems.&nbsp;<br /><br /><br />The most common method of addressing these attacks is security education and training: providing facts and advice about these attacks to non-expert computer users. This project proposed a new approach to training: providing users with a wide variety of experiences vicariously by sharing stories of attacks and incidents. These stories have the potential to train end users to do three things that facts and advice do not: 1) help end users recognize features that are typical of legitimate content, and features that are typical of attacks; 2) quickly identify reasonable actions that can be taken; and 3) understand cause-and-effect for these attacks to aid in reasoning.<br /><br /><br />This project developed a detailed understanding of how both experts and non-experts make everyday in-the-moment security decisions about phishing emails. We now are able to describe in detail the process that security experts use when they successfully detect phishing emails. &nbsp;This is more than just recognizing problems with the email, but also involves building anxiety about not understanding the email, remembering phishing as an alternative explanation for those problems, and investigating the email to figure out whether phishing is a good explanation. &nbsp; We are also able to describe the same process in non-experts, and ways that the process fails.<br /><br /><br />We found that contrary to the the assumptions in most phishing training, most people are able to identify problems with emails. &nbsp; It is in the other stages -- building anxiety, recognizing phishing as a potential explanation, and investigating the email -- that failures usually happen. &nbsp; More factual training about problems isn't helpful. &nbsp;However, we found that non-experts have a lot of knowledge and capabilities that make them uniquely able to contribute to phishing detection. &nbsp; They have more situational information than computers or experts, and they naturally use that when detecting phishing. &nbsp; They also are able to delay responding to emails and to use their social connections to ask for help or to contact the purported sender for more information. &nbsp; This knowledge and capabilities means that even non-experts are key, critical parts of phishing detection.<br /><br /><br />We also found that people are much more able to use stories about past phishing incidents to help them detect new fraudulent emails than they are the facts and advice normally found in phishing training.<br /><br /><br />As part of this project, we provided phishing training to thousands of people, mostly affiliated with the university. &nbsp;This training included new methods for helping people detect phishing, and was evaluated to be effective. &nbsp;We also helped improve the cybersecurity workforce by providing education for a number of students at the undergraduate, graduate, and post-doctoral levels who have since gone on to jobs in cybersecurity in major corporations.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/29/2021<br>\n\t\t\t\t\tModified by: Richard&nbsp;Wash</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn the summer of 2016, both former Secretary of State Colin Powell, and presidential candidate Hillary Clinton's campaign manager John Podesta had the contents of their email stolen and published on Wikileaks. Neither theft exploited technical vulnerabilities; instead, the attacker simply sent an email to their targets pretending to be from Google (their email provider) asking for their username and password. These attacks are ``phishing'' attacks. They target and exploit the way that the humans assign meaning to information and make decisions about their use of computing systems. \n\n\nThe most common method of addressing these attacks is security education and training: providing facts and advice about these attacks to non-expert computer users. This project proposed a new approach to training: providing users with a wide variety of experiences vicariously by sharing stories of attacks and incidents. These stories have the potential to train end users to do three things that facts and advice do not: 1) help end users recognize features that are typical of legitimate content, and features that are typical of attacks; 2) quickly identify reasonable actions that can be taken; and 3) understand cause-and-effect for these attacks to aid in reasoning.\n\n\nThis project developed a detailed understanding of how both experts and non-experts make everyday in-the-moment security decisions about phishing emails. We now are able to describe in detail the process that security experts use when they successfully detect phishing emails.  This is more than just recognizing problems with the email, but also involves building anxiety about not understanding the email, remembering phishing as an alternative explanation for those problems, and investigating the email to figure out whether phishing is a good explanation.   We are also able to describe the same process in non-experts, and ways that the process fails.\n\n\nWe found that contrary to the the assumptions in most phishing training, most people are able to identify problems with emails.   It is in the other stages -- building anxiety, recognizing phishing as a potential explanation, and investigating the email -- that failures usually happen.   More factual training about problems isn't helpful.  However, we found that non-experts have a lot of knowledge and capabilities that make them uniquely able to contribute to phishing detection.   They have more situational information than computers or experts, and they naturally use that when detecting phishing.   They also are able to delay responding to emails and to use their social connections to ask for help or to contact the purported sender for more information.   This knowledge and capabilities means that even non-experts are key, critical parts of phishing detection.\n\n\nWe also found that people are much more able to use stories about past phishing incidents to help them detect new fraudulent emails than they are the facts and advice normally found in phishing training.\n\n\nAs part of this project, we provided phishing training to thousands of people, mostly affiliated with the university.  This training included new methods for helping people detect phishing, and was evaluated to be effective.  We also helped improve the cybersecurity workforce by providing education for a number of students at the undergraduate, graduate, and post-doctoral levels who have since gone on to jobs in cybersecurity in major corporations.\n\n\t\t\t\t\tLast Modified: 09/29/2021\n\n\t\t\t\t\tSubmitted by: Richard Wash"
 }
}