{
 "awd_id": "1717431",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI:Small: Unsupervised Discriminatively-Generative Learning:",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2017-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2017-07-27",
 "awd_max_amd_letter_date": "2017-07-27",
 "awd_abstract_narration": "Great success has been achieved in obtaining powerful discriminative classifiers via supervised training where humans provide manual annotations to the training data. Unsupervised learning, in which the input data is not accompanied with task-specific annotations, is of great importance since a large number of tasks have no to little supervision. However, it still remains to be one of the most difficult problems in machine learning. A typical unsupervised learning task learns effective generative representations for highly structured data such as images, videos, speech, and text. Existing generative models for unsupervised learning are often constrained by their simplified assumptions, while existing discriminative models for supervised learning are of limited generation capabilities. This project develops a new introspective machine learning framework that greatly enhances and expands the power of both generation and discrimination for a single model. The outcome of the project, introspective generative/discriminative learning, significantly improves the learning capabilities of the existing algorithms by building stronger computational models for a wide range of fields including computer vision, machine learning, cognitive science, computational linguistics, and data mining. \r\n\r\nThis research investigates a new machine learning framework, introspective generative/discriminative learning (IGDL), which attains a single generator/discriminator capable of performing both generation and classification.  The IGDL generator is itself a discriminator, capable of introspection --- being able to self-evaluate the difference between its generated samples and the given training data. When followed by iterative discriminative learning, desirable properties of modern discriminative classifiers such as convolutional neural networks (CNN) can be directly inherited by the IGDL generator. Moreover, the discriminator aspect of IGDL also produces competitive results in fully supervised classification by using self-generated new data (called pseudo-negatives) to enhance the classification performance against adversarial samples. The training process of IGDL is carried out using a two-step synthesis-by-classification algorithm via efficient backpropagation. Effective stochastic gradient descent Monte Carlo sampling processes for IGDL training are studied. Across three key areas in machine learning including unsupervised, semi-supervised, and fully-supervised learning, IGDL produces competitive results in a wide range of applications including texture synthesis, object modeling, and image classification.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zhuowen",
   "pi_last_name": "Tu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zhuowen Tu",
   "pi_email_addr": "ztu@ucsd.edu",
   "nsf_id": "000083010",
   "pi_start_date": "2017-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 Gilman Drive",
  "perf_city_name": "La Jolla",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930515",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Under the support of this award, the PI's group at UC San Diego has been developing new deep learning representations/algorithms, particularly along the line of learning a single convolutional neural network architecture that is simultaneously generative and discriminative.</p>\n<p><br />We have developed a unique line of generative models, Introspective Neural Networks (INN), by a series of efforts that are energy-based models attaining strong results in image classification and generation with added robustness against adversarial signals. In this project we aim to build a single convolutional network model that is simultaneously generative and discriminative. This is achieved by turning standard convolutional neural networks (CNN) into a generic generator using stochastic gradient descent (SGD) Langevin sampling through backpropagation. When followed by iterative discriminative learning, desirable properties of modern discriminative classifiers are directly inherited by the generator. The learned generative model/discriminative classifier is capable of introspection: being able to self-evaluate the difference between its generated samples and the given training data. On the discriminative classification side, INN achieves strong classification results, with particular advantages in achieving robustness against adversarial samples; on the generative modeling side, appealing images are generated for a series of tasks including texture modeling , object modeling, and image generation.</p>\n<p><br />In addition, we have also developed Dual Contradistinctive Generative Autoencoder (DC-VAE) where discriminative loss for both instance-level and set-level fidelity has been enforced to improve the generative image modeling capability of the variational autoencoder (VAE) model.</p>\n<p>In terms of visual representation learning, we have developed a new vision Transformer model, Co-Scale Conv-Attentional Image Transformers (CoaT), that adopts cross-scale attention and depthwise convolution to the existing vision Transformer architectures. CoaT attains state-of-the-art results on image classification and object detection for relatively small-size models. In addition, we have developed methods for geometric structure extraction such as line segments and object instance boundaries that take particular advantages of Transformer by avoiding the intermediate grouping processes.</p>\n<p>&nbsp;</p>\n<p>Overall, this project has made a strong impact in the computer vision, machine learning, and deep learning community by developing algorithms to tackle the fundamental problem of energy-based generative models with adversarial training. We have also developed Transformer-based algorithms for image classification, object detection, instance segmentation, and geometric structure extraction. The impact includes research and educational for training students. The proposed activities have strengthened the educational and research program in the Department of Cognitive Science and Department of Computer Science and Engineering at University of California San Diego.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/14/2023<br>\n\t\t\t\t\tModified by: Zhuowen&nbsp;Tu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nUnder the support of this award, the PI's group at UC San Diego has been developing new deep learning representations/algorithms, particularly along the line of learning a single convolutional neural network architecture that is simultaneously generative and discriminative.\n\n\nWe have developed a unique line of generative models, Introspective Neural Networks (INN), by a series of efforts that are energy-based models attaining strong results in image classification and generation with added robustness against adversarial signals. In this project we aim to build a single convolutional network model that is simultaneously generative and discriminative. This is achieved by turning standard convolutional neural networks (CNN) into a generic generator using stochastic gradient descent (SGD) Langevin sampling through backpropagation. When followed by iterative discriminative learning, desirable properties of modern discriminative classifiers are directly inherited by the generator. The learned generative model/discriminative classifier is capable of introspection: being able to self-evaluate the difference between its generated samples and the given training data. On the discriminative classification side, INN achieves strong classification results, with particular advantages in achieving robustness against adversarial samples; on the generative modeling side, appealing images are generated for a series of tasks including texture modeling , object modeling, and image generation.\n\n\nIn addition, we have also developed Dual Contradistinctive Generative Autoencoder (DC-VAE) where discriminative loss for both instance-level and set-level fidelity has been enforced to improve the generative image modeling capability of the variational autoencoder (VAE) model.\n\nIn terms of visual representation learning, we have developed a new vision Transformer model, Co-Scale Conv-Attentional Image Transformers (CoaT), that adopts cross-scale attention and depthwise convolution to the existing vision Transformer architectures. CoaT attains state-of-the-art results on image classification and object detection for relatively small-size models. In addition, we have developed methods for geometric structure extraction such as line segments and object instance boundaries that take particular advantages of Transformer by avoiding the intermediate grouping processes.\n\n \n\nOverall, this project has made a strong impact in the computer vision, machine learning, and deep learning community by developing algorithms to tackle the fundamental problem of energy-based generative models with adversarial training. We have also developed Transformer-based algorithms for image classification, object detection, instance segmentation, and geometric structure extraction. The impact includes research and educational for training students. The proposed activities have strengthened the educational and research program in the Department of Cognitive Science and Department of Computer Science and Engineering at University of California San Diego. \n\n\t\t\t\t\tLast Modified: 03/14/2023\n\n\t\t\t\t\tSubmitted by: Zhuowen Tu"
 }
}