{
 "awd_id": "1605226",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Desktop Co-robotic Assistant for Graphics and Text Access and Creation for Individuals who are Blind or Visually Impaired",
 "cfda_num": "47.041",
 "org_code": "07020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Grace Hwang",
 "awd_eff_date": "2017-02-01",
 "awd_exp_date": "2022-01-31",
 "tot_intn_awd_amt": 303004.0,
 "awd_amount": 322004.0,
 "awd_min_amd_letter_date": "2017-01-18",
 "awd_max_amd_letter_date": "2021-07-07",
 "awd_abstract_narration": "1605226 - Pawluk\r\n\r\nIn the U.S. alone, there are approximately 8 million individuals who are blind or visually impaired. In order for these individuals to reach their potential and be competitive with their peers, it is important that they have equivalent access to information to ensure timely completion of education and work tasks. Computers have become essential in these environments, creating information and collaborating with others, whether in the same room or remotely over the web. A lot of this interaction is highly spatial in nature, whether in the use and creation of graphics, interacting with others through a mouse or cursor, or searching for information in the spatial layout of text on a web page. For individuals who are blind or visually impaired, this spatial information is largely inaccessible. This project is intended to address this issue by developing a robotic assistant to provide haptic and Braille input and output to a computer, as well as aid an individual in exploration of the computer window.\r\n\r\nThe main goal of this grant is to provide a coherent haptic system that provides effective input and output of graphics and Braille on a full haptic page/window through a single device that can be used in a single hand posture. The objectives are to first develop a desktop co-robot to provide shared control with the user over a haptic interface to aid in exploring graphical and full page Braille information.  A mouse-shaped tactile input/output component will be mounted on the co-robot to provide spatially distributed tactile feedback to the second and third fingers of the hand.  Combined with a stationary version of the mouse, this will also allow simultaneous input of Braille text through button inputs and, in the future, the creation of graphical information.  In developing this system, we will use a Participatory Action Design approach involving all stakeholders. The created system will then be validated in accessing graphical and full page text information, as well as editing full page text compared to current commercial and/or research devices.  In addition, this system will be furthered by the development of techniques to effectively communicate the focus of attention between the user and collaborators.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CBET",
 "org_div_long_name": "Division of Chemical, Bioengineering, Environmental, and Transport Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dianne",
   "pi_last_name": "Pawluk",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dianne Pawluk",
   "pi_email_addr": "dtpawluk@vcu.edu",
   "nsf_id": "000090237",
   "pi_start_date": "2017-01-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Commonwealth University",
  "inst_street_address": "910 WEST FRANKLIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "RICHMOND",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "8048286772",
  "inst_zip_code": "232849005",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "VA04",
  "org_lgl_bus_name": "VIRGINIA COMMONWEALTH UNIVERSITY",
  "org_prnt_uei_num": "WXQLZ1PA6XP3",
  "org_uei_num": "MLQFL4JSSAA9"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Commonwealth University Department of Biomedical Engin",
  "perf_str_addr": "401 West Main Street",
  "perf_city_name": "Richmond",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "232843067",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "VA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "534200",
   "pgm_ele_name": "Disability & Rehab Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "010E",
   "pgm_ref_txt": "DISABILITY RES & HOMECARE TECH"
  },
  {
   "pgm_ref_code": "093Z",
   "pgm_ref_txt": "AI Education/Workforce Develop"
  },
  {
   "pgm_ref_code": "5342",
   "pgm_ref_txt": "RESEARCH TO AID THE DISABLED"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 319004.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 3000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The use of diagrams is an important tool in education, work and everyday living tasks. Individuals who are blind or visually impaired typically access this information through physical tactile diagrams, which require a slow, expensive process to create. Devices have been proposed to present refreshable tactile graphics, although there are a variety of limitations to many of these methods. Previous work in the <span>PI's</span> laboratory found that spatially distributed tactile displays presenting textured graphics conveyed the information effectively, but the use of these displays was slow and cognitively demanding. The performed work is part of a larger project to improve access to tactile diagrams for individuals who are blind or visually impaired focusing on decreasing exploration time and cognitive demand. This will allow blind and visually impaired users to focus on the content of the diagram rather than how the diagram fits together.</span></p>\n<p>The funded project successfully developed a working prototype (see Figure: Device Prototype) that adds the potential for a guidance algorithm to intervene during a user&rsquo;s exploration of a tactile diagram with a spatially distributed tactile display. This was achieved by combining a two-finger multi-pin display, providing spatially distributed tactile feedback, with a mobile robot base, for which the control of its movement is shared between the user and an internal algorithm (see Figure: Block Diagram). Improved performance is expected as, although hypothesis driven free exploration by a user is important for diagram interpretation, sometimes during the exploration process external assistance is beneficial. The developed prototype provides a platform for researchers to explore how to best combine the two dynamically during exploration.&nbsp; The prototype can also provide shared control between a blind or visually impaired user and a remotely located teacher or colleague, allowing them to communicate remotely more effectively when diagrams are used.</p>\n<p>Significant aspects of the resulting prototype are: (1) low-cost (as many blind and visually impaired users live below the poverty line), (2) small size, portability (as it would be useful in a variety of environments, including home, work and school), (3) large, potentially infinite, display size (although practically, keeping the display within the workspace of a user's arm is most practical), (4) the unique combination of spatially distributed tactile feedback within and across fingers combined with the use of&nbsp; a shared control strategy, (5) ease of interaction (due to multiple design components, including: size and weight of the device, ability to move smoothly in arbitrary directions due to the omni wheels, ergonomic design of the grasping surface and responsiveness to the user in shared control due to measurement of the applied force of the user and the shared, admittance control algorithm), (6) the use of a novel algorithm using an <span style=\"background-color: #ffffff;\">IMU</span> and optical mouse sensor to determine sufficiently accurate position and orientation of the robot base.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/22/2022<br>\n\t\t\t\t\tModified by: Dianne&nbsp;Pawluk</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1605226/1605226_10469669_1655305005722_Figure1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1605226/1605226_10469669_1655305005722_Figure1--rgov-800width.jpg\" title=\"Block Diagram\"><img src=\"/por/images/Reports/POR/2022/1605226/1605226_10469669_1655305005722_Figure1--rgov-66x44.jpg\" alt=\"Block Diagram\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Contains a block diagram of the interaction between the functional components of the system.</div>\n<div class=\"imageCredit\">Satinder Gill and Dianne Pawluk</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Dianne&nbsp;Pawluk</div>\n<div class=\"imageTitle\">Block Diagram</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1605226/1605226_10469669_1655305219439_Figure2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1605226/1605226_10469669_1655305219439_Figure2--rgov-800width.jpg\" title=\"Device Prototype\"><img src=\"/por/images/Reports/POR/2022/1605226/1605226_10469669_1655305219439_Figure2--rgov-66x44.jpg\" alt=\"Device Prototype\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Photo of the Device Prototype from the top view. The top cap is attached to the robot base with a MicroJoystick.</div>\n<div class=\"imageCredit\">Satinder Gill and Dianne Pawluk</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Dianne&nbsp;Pawluk</div>\n<div class=\"imageTitle\">Device Prototype</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1605226/1605226_10469669_1655305393222_DiagramExploration--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1605226/1605226_10469669_1655305393222_DiagramExploration--rgov-800width.jpg\" title=\"Diagram Exploration\"><img src=\"/por/images/Reports/POR/2022/1605226/1605226_10469669_1655305393222_DiagramExploration--rgov-66x44.jpg\" alt=\"Diagram Exploration\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Example of diagram exploration by a user.  The circles indicate the exploration path of the user moving the device.</div>\n<div class=\"imageCredit\">Satinder Gill and Dianne Pawluk</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Dianne&nbsp;Pawluk</div>\n<div class=\"imageTitle\">Diagram Exploration</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe use of diagrams is an important tool in education, work and everyday living tasks. Individuals who are blind or visually impaired typically access this information through physical tactile diagrams, which require a slow, expensive process to create. Devices have been proposed to present refreshable tactile graphics, although there are a variety of limitations to many of these methods. Previous work in the PI's laboratory found that spatially distributed tactile displays presenting textured graphics conveyed the information effectively, but the use of these displays was slow and cognitively demanding. The performed work is part of a larger project to improve access to tactile diagrams for individuals who are blind or visually impaired focusing on decreasing exploration time and cognitive demand. This will allow blind and visually impaired users to focus on the content of the diagram rather than how the diagram fits together.\n\nThe funded project successfully developed a working prototype (see Figure: Device Prototype) that adds the potential for a guidance algorithm to intervene during a user\u2019s exploration of a tactile diagram with a spatially distributed tactile display. This was achieved by combining a two-finger multi-pin display, providing spatially distributed tactile feedback, with a mobile robot base, for which the control of its movement is shared between the user and an internal algorithm (see Figure: Block Diagram). Improved performance is expected as, although hypothesis driven free exploration by a user is important for diagram interpretation, sometimes during the exploration process external assistance is beneficial. The developed prototype provides a platform for researchers to explore how to best combine the two dynamically during exploration.  The prototype can also provide shared control between a blind or visually impaired user and a remotely located teacher or colleague, allowing them to communicate remotely more effectively when diagrams are used.\n\nSignificant aspects of the resulting prototype are: (1) low-cost (as many blind and visually impaired users live below the poverty line), (2) small size, portability (as it would be useful in a variety of environments, including home, work and school), (3) large, potentially infinite, display size (although practically, keeping the display within the workspace of a user's arm is most practical), (4) the unique combination of spatially distributed tactile feedback within and across fingers combined with the use of  a shared control strategy, (5) ease of interaction (due to multiple design components, including: size and weight of the device, ability to move smoothly in arbitrary directions due to the omni wheels, ergonomic design of the grasping surface and responsiveness to the user in shared control due to measurement of the applied force of the user and the shared, admittance control algorithm), (6) the use of a novel algorithm using an IMU and optical mouse sensor to determine sufficiently accurate position and orientation of the robot base. \n\n \n\n\t\t\t\t\tLast Modified: 06/22/2022\n\n\t\t\t\t\tSubmitted by: Dianne Pawluk"
 }
}