{
 "awd_id": "1704309",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Medium: Collaborative Research: Understanding and Editing Visual Sentiment",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 485688.0,
 "awd_amount": 485688.0,
 "awd_min_amd_letter_date": "2017-06-21",
 "awd_max_amd_letter_date": "2022-06-06",
 "awd_abstract_narration": "The project develops computer vision and pattern recognition technologies for visual sentiment understanding and visual sentiment editing. The interdisciplinary research team investigates the problem of understanding how images and video convey emotion. The project develops methods to infer, edit, and synthesize visual sentimental content in image/videos, in addition to their semantic contents. The project applies developed technologies to reduce violence from multimedia materials for children, and negative psychological impacts from social media for posttraumatic stress disorder (PTSD) patients. The project integrates research and education by creating new interdisciplinary courses and training graduate students.  The project builds connection with the veteran academic resource center on the campus to help PTSD patients to recover from mental health problems. The research team also shares collected data with research communities.\r\n\r\nThis research develops visual sentiment understanding algorithms through joint extraction of sentiments and semantics, in order to advance the understanding of how semantic entities substantiate and carry sentiments at a fine-grained object or pixel level. Computer vision algorithms and psychometric assessment techniques are combined to automatically analyze visual and recognize sentiments and emotions from multimedia materials and social media contents posted and shared by veterans. The research also explores methods of visual sentiment editing to reduce violence from multimedia materials and social media contents. The research can help (1) to protect children from accessing violent multimedia materials, and (2) to provide appropriate social media contents for applications of automatically detecting violent contents from veteran-shared multimedia.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Liqiang",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Liqiang Wang",
   "pi_email_addr": "lwang@cs.ucf.edu",
   "nsf_id": "000248300",
   "pi_start_date": "2020-06-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "GuoJun",
   "pi_last_name": "Qi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "GuoJun Qi",
   "pi_email_addr": "guojunq@gmail.com",
   "nsf_id": "000677701",
   "pi_start_date": "2017-06-21",
   "pi_end_date": "2020-06-03"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Wei",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wei Wang",
   "pi_email_addr": "wwang@gc.cuny.edu",
   "nsf_id": "000714052",
   "pi_start_date": "2017-06-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "The University of Central Florida Board of Trustees",
  "inst_street_address": "4000 CENTRAL FLORIDA BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "ORLANDO",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "4078230387",
  "inst_zip_code": "328168005",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "FL10",
  "org_lgl_bus_name": "THE UNIVERSITY OF CENTRAL FLORIDA BOARD OF TRUSTEES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RD7MXJV7DKT9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Central Florida",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "328168005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "FL10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 485688.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>With support from the NSF, our team has developed multiple deep learning techniques, enhancing the accuracy, robustness, and security of neural network models. At UCF, we have contributed 28 research papers to prestigious journals and conferences. This grant has partly supported 4 Ph.D. students, all of whom have now earned their degrees: Ehsan Kazemi and Yifan Ding in Spring 2023, Yandong Li in Spring 2021, and Liheng Zhang in Spring 2020.</p>\n<p>We've also open-sourced 5 research projects, making significant contributions to the field of deep learning. These include: (1) On Calibrating Semantic Segmentation Models: Analyses and An Algorithm (CVPR 2023) https://github.com/dwang181/selectivecal ; (2) Neural networks are more productive teachers than human raters: Active mixup for data-efficient knowledge distillation from a blackbox model (CVPR 2020) <a href=\"https://github.com/dwang181/active-mixup\">https://github.com/dwang181/active-mixup</a>; (3) NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks (ICML 2019), <a href=\"https://github.com/Cold-Winter/Nattack\">https://github.com/Cold-Winter/Nattack</a>; (4) BachGAN: High-Resolution Image Synthesis from Salient Object Layout (CVPR 2020), <a href=\"https://github.com/Cold-Winter/BachGAN\">https://github.com/Cold-Winter/BachGAN</a>; (5) AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data (CVPR 2019) <a href=\"https://github.com/maple-research-lab/AET\">https://github.com/maple-research-lab/AET</a>.</p>\n<p>The insights gained from our research have been incorporated into one undergraduate courses (Artificial Intelligence, CAP 4630) and two graduate courses (Machine Learning, CAP 5610; Parallel and Cloud Computing, CAP 6526). This integration includes new homework assignments and projects inspired by our research findings.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 04/04/2024<br>\nModified by: Liqiang&nbsp;Wang</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nWith support from the NSF, our team has developed multiple deep learning techniques, enhancing the accuracy, robustness, and security of neural network models. At UCF, we have contributed 28 research papers to prestigious journals and conferences. This grant has partly supported 4 Ph.D. students, all of whom have now earned their degrees: Ehsan Kazemi and Yifan Ding in Spring 2023, Yandong Li in Spring 2021, and Liheng Zhang in Spring 2020.\n\n\nWe've also open-sourced 5 research projects, making significant contributions to the field of deep learning. These include: (1) On Calibrating Semantic Segmentation Models: Analyses and An Algorithm (CVPR 2023) https://github.com/dwang181/selectivecal ; (2) Neural networks are more productive teachers than human raters: Active mixup for data-efficient knowledge distillation from a blackbox model (CVPR 2020) https://github.com/dwang181/active-mixup; (3) NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks (ICML 2019), https://github.com/Cold-Winter/Nattack; (4) BachGAN: High-Resolution Image Synthesis from Salient Object Layout (CVPR 2020), https://github.com/Cold-Winter/BachGAN; (5) AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data (CVPR 2019) https://github.com/maple-research-lab/AET.\n\n\nThe insights gained from our research have been incorporated into one undergraduate courses (Artificial Intelligence, CAP 4630) and two graduate courses (Machine Learning, CAP 5610; Parallel and Cloud Computing, CAP 6526). This integration includes new homework assignments and projects inspired by our research findings.\n\n\n\t\t\t\t\tLast Modified: 04/04/2024\n\n\t\t\t\t\tSubmitted by: LiqiangWang\n"
 }
}