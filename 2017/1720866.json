{
 "awd_id": "1720866",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Developing and Validating a Scalable, Classroom-focused Measure of Usable Knowledge for Teaching Mathematics: The Classroom Video Analysis Instrument",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Finbarr Sloane",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 2000537.0,
 "awd_amount": 2000537.0,
 "awd_min_amd_letter_date": "2017-08-22",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "There is widespread agreement that for teachers to effectively teach their students having lots of knowledge is important, but not enough. To benefit instruction and student learning, teachers need to be able to access and flexibly use their knowledge in the classroom in actual teaching situations and teaching tasks. Yet, measures to assess teachers' usable knowledge have remained scarce. We still know little about how the knowledge teachers acquire as part of teacher preparation courses and professional development becomes usable, how it develops over time, and how teachers use it in the process of teaching. To address both assessment needs in this project, The project will develop a set of scalable, classroom-focused measures of usable mathematics teaching knowledge that are aligned with state standards. The new measures will extend the classroom video analysis approach, which is based on teachers' ability to analyze and respond to teaching episodes shown in short video clips of authentic classroom instruction, by aligning video clips and assessment tasks to standards. The new measures, which will be made available online, will be a valuable tool for researchers, policy makers, and school districts to monitor teacher knowledge over time and to gauge teacher preparedness for implementing state standards in mathematics. The measures will also provide new insights into usable knowledge and knowledge use and advance a much-needed theory of teacher knowledge. Finally, the project extends and refines a promising assessment methodology that can be adapted to any future content frameworks or standards and that can also be used for instrument development in other practice-based knowledge domains. The Discovery Research K-12 program (DRK-12) seeks to significantly enhance the learning and teaching of science, technology, engineering and mathematics (STEM) by preK-12 students and teachers, through research and development of innovative resources, models and tools (RMTs). Projects in the DRK-12 program build on fundamental research in STEM education and prior research and development efforts that provide theoretical and empirical justification for proposed projects. This project is also supported by NSF's EHR Core Research (ECR) program. The ECR program emphasizes fundamental STEM education research that generates foundational knowledge in the field.\r\n\r\nThe project will develop a scalable, classroom-focused measure of usable mathematics teaching knowledge that is aligned with the state standards through a classroom video analysis measure (CVA-M)) in three content areas: (a) fractions for grades 4 and 5, (b) ratio and proportions for grades 6 and 7; and (c) variables, expressions, and equations for grades 6 and 7. The project will examine the psychometric properties of the new items and scales, including the reliability of scores, and collect evidence on content, substantive, structural, and external aspects of validity to evaluate the overall construct validity of the CVA-M. The project builds on an innovative and promising assessment methodology that uses video clips of authentic classroom instruction that teachers are asked to view and analyze to elicit their usable knowledge. Teachers analyze the teaching episodes shown in the video clips from different assessment tasks that reflect authentic teaching tasks, such as diagnosing student thinking, generating mathematically targeted teacher question, or relating specific content and mathematical practices to teaching episodes shown in the clips. To develop each of the three scales, video clips will be mapped to state level content and mathematical practice standards. Assessment tasks and rubrics will also be aligned with these standards.  To create items, video clips will be combined with analysis prompts that ask for a written answer, multiple-choice or rating scales. To make the constructed response items, which need to be scored by trained raters, easier to use at scale, computational approaches will be employed to develop classifiers to automate scoring. Using responses from large samples of teachers, the psychometric properties of the new CVA-M items and scales will be analyzed using factor analysis, classical test theory and item response theory. A series of validity investigations will be conducted. Teachers' scores on the new CVA-M scales will be compared to their scores on another measure of teacher knowledge, the Mathematics Knowledge for Teaching (MKT) instrument, and each scale's predictive validity will be explored vis-a-vis student learning by relating teachers' CVA-M scores to their students' learning as measured by a pre-post quiz and by students' standardized test scores.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nicole",
   "pi_last_name": "Kersting",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nicole Kersting",
   "pi_email_addr": "nickik@email.arizona.edu",
   "nsf_id": "000071971",
   "pi_start_date": "2017-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Arizona",
  "inst_street_address": "845 N PARK AVE RM 538",
  "inst_street_address_2": "",
  "inst_city_name": "TUCSON",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "5206266000",
  "inst_zip_code": "85721",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "AZ07",
  "org_lgl_bus_name": "UNIVERSITY OF ARIZONA",
  "org_prnt_uei_num": "",
  "org_uei_num": "ED44Y3W6P7B9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Arizona",
  "perf_str_addr": "PO Box 210158, Rom 510",
  "perf_city_name": "Tucson",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "857210158",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "AZ07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "764500",
   "pgm_ele_name": "Discovery Research K-12"
  },
  {
   "pgm_ele_code": "798000",
   "pgm_ele_name": "ECR-EDU Core Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8817",
   "pgm_ref_txt": "STEM Learning & Learning Environments"
  }
 ],
 "app_fund": [
  {
   "app_code": "0417",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001718DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0419",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001920DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0420",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002021DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 1073586.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 539128.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 387823.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Developing reliable and valid measures of teachers&rsquo; usable Common Core aligned mathematics knowledge for teaching</strong></p>\n<p><strong>Usable knowledge</strong>: Teaching involves processing incoming information (&ldquo;<em>What is pertinent in this classroom situation?</em>&rdquo;), which leads to a decision (&ldquo;<em>What should I do next?</em>&rdquo;), the outcome of which creates a new situation (&ldquo;<em>How well did this work and what is pertinent now?</em>&rdquo;) and so forth. It makes sense that the knowledge teachers are able to use in the moment has an impact on this process: What teachers perceive, the decisions they make, and how they evaluate the outcome of their decision. Yet, developing measures of teachers&rsquo; usable knowledge has remained a challenge. Under this project we developed items and scales of teachers&rsquo; usable Common Core-aligned mathematics knowledge for teaching in three content areas: (1) Fractions, (2) Ratio and Proportions, and (3) Variables, Expressions, and Equations and explored the functioning of our items and scales.</p>\n<p><strong>Approximating as much as possible an actual classroom situation</strong>: To design items that could elicit teachers&rsquo; usable knowledge in concrete teaching situations, we selected short video clips of authentic mathematics instruction as stimuli. We paired the video clips with different prompts that engage teachers in authentic teaching tasks. Prompts asked teachers to generate a question to improve the students&rsquo; understanding, to generate an extension question that would extend or deepen the students understanding, to make suggestions for improving the teaching situation, to analyze what the student does and does not understand, and how to move a student toward a specific mathematical idea contained in the Common Core state standards. Large samples of participating teachers in grades 5 through 7, viewed and responded in writing to the items on the <a href=\"http://www.teknoclips.org\">www.teknoclips.org</a> interface.</p>\n<p><strong>Developing Scoring Rubrics</strong>: To score teachers&rsquo; written responses that contained their usable knowledge, we developed rubrics in alignment with math ideas contained in the Common Core to reflect differences in the quality of responses. Responses were scored as 0, 1, or 2, depending on mathematical specificity and on how targeted the response was to the teaching episodes in the video clips. That is, responses that were mathematically specific and targeted to the teaching episode shown in the video, received a score of 2 and represented more usable knowledge than a response that contained mathematical knowledge that was secondary to the teaching episode in the video clips (a score of 1).</p>\n<p><strong>Item and scale functioning</strong>: Across all three content areas, items and scales functioned well.&nbsp; Items were moderately difficult to difficult, differentiated well among participating teachers, and teachers&rsquo; total scores were sufficiently reliable.</p>\n<p><strong>Evidence that items and scales measure teachers&rsquo; usable Common Core aligned usable mathematics knowledge for teaching: </strong>Teachers&rsquo; total scores on all three scales correlated positively and moderately with topic-matched scales measuring teachers&rsquo; mathematics knowledge for teaching. The moderate correlations provide evidence that the knowledge measured by both instruments is related. The moderate correlations also suggest that the newly developed scales measure knowledge or characteristics of knowledge not captured by the mathematics knowledge for teaching scales. Teachers&rsquo; total scores on all three scales have positive effect on student learning. Teachers with higher scores on the new scales have students who learn more when analyzing students&rsquo; standardized test scores (predicting end of year scores controlling for previous years scores).&nbsp; Effects of teachers&rsquo; usable knowledge scores on student learning were statistically significant for the fraction and ratio and proportion scale, and not statistically significant for the variables, expression, and equations scale (p = 0. 06). We obtained additional evidence for the relationship between teachers&rsquo; scores on the new scales and student learning from quizzes teachers administered to their students prior to and after teaching the respective content area. Taken together, our results provide preliminary evidence that the new items and scales measure teachers&rsquo; usable Common Core aligned mathematics knowledge for teaching.</p>\n<p><strong>Automated scoring: </strong>Scoring teachers&rsquo; written responses reliably requires trained raters, which limits the feasibility of use of the new items and scales. We used neural networks models and already scored responses for training to produce computer-generated scores. Accuracy of computer-generated scores across the three scales was about twice as good as chance (.33), total scores based on rater assigned scores and computer-generated scores correlated highly indicating that computer-based total scores are sufficiently valid to be used in statistical analyses.</p>\n<p><strong>Conclusion: </strong>This project has produced three reliable and valid scales of teachers&rsquo; usable Common Core aligned mathematics knowledge for teaching. To promote the wider use of these measures we implemented the automated scoring functionality on the <a href=\"http://www.teknoclips.org\">www.teknoclips.org</a> website where the items and automated scoring is available for researchers upon request.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/28/2023<br>\nModified by: Nicole&nbsp;Kersting</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nDeveloping reliable and valid measures of teachers usable Common Core aligned mathematics knowledge for teaching\n\n\nUsable knowledge: Teaching involves processing incoming information (What is pertinent in this classroom situation?), which leads to a decision (What should I do next?), the outcome of which creates a new situation (How well did this work and what is pertinent now?) and so forth. It makes sense that the knowledge teachers are able to use in the moment has an impact on this process: What teachers perceive, the decisions they make, and how they evaluate the outcome of their decision. Yet, developing measures of teachers usable knowledge has remained a challenge. Under this project we developed items and scales of teachers usable Common Core-aligned mathematics knowledge for teaching in three content areas: (1) Fractions, (2) Ratio and Proportions, and (3) Variables, Expressions, and Equations and explored the functioning of our items and scales.\n\n\nApproximating as much as possible an actual classroom situation: To design items that could elicit teachers usable knowledge in concrete teaching situations, we selected short video clips of authentic mathematics instruction as stimuli. We paired the video clips with different prompts that engage teachers in authentic teaching tasks. Prompts asked teachers to generate a question to improve the students understanding, to generate an extension question that would extend or deepen the students understanding, to make suggestions for improving the teaching situation, to analyze what the student does and does not understand, and how to move a student toward a specific mathematical idea contained in the Common Core state standards. Large samples of participating teachers in grades 5 through 7, viewed and responded in writing to the items on the www.teknoclips.org interface.\n\n\nDeveloping Scoring Rubrics: To score teachers written responses that contained their usable knowledge, we developed rubrics in alignment with math ideas contained in the Common Core to reflect differences in the quality of responses. Responses were scored as 0, 1, or 2, depending on mathematical specificity and on how targeted the response was to the teaching episodes in the video clips. That is, responses that were mathematically specific and targeted to the teaching episode shown in the video, received a score of 2 and represented more usable knowledge than a response that contained mathematical knowledge that was secondary to the teaching episode in the video clips (a score of 1).\n\n\nItem and scale functioning: Across all three content areas, items and scales functioned well. Items were moderately difficult to difficult, differentiated well among participating teachers, and teachers total scores were sufficiently reliable.\n\n\nEvidence that items and scales measure teachers usable Common Core aligned usable mathematics knowledge for teaching: Teachers total scores on all three scales correlated positively and moderately with topic-matched scales measuring teachers mathematics knowledge for teaching. The moderate correlations provide evidence that the knowledge measured by both instruments is related. The moderate correlations also suggest that the newly developed scales measure knowledge or characteristics of knowledge not captured by the mathematics knowledge for teaching scales. Teachers total scores on all three scales have positive effect on student learning. Teachers with higher scores on the new scales have students who learn more when analyzing students standardized test scores (predicting end of year scores controlling for previous years scores). Effects of teachers usable knowledge scores on student learning were statistically significant for the fraction and ratio and proportion scale, and not statistically significant for the variables, expression, and equations scale (p = 0. 06). We obtained additional evidence for the relationship between teachers scores on the new scales and student learning from quizzes teachers administered to their students prior to and after teaching the respective content area. Taken together, our results provide preliminary evidence that the new items and scales measure teachers usable Common Core aligned mathematics knowledge for teaching.\n\n\nAutomated scoring: Scoring teachers written responses reliably requires trained raters, which limits the feasibility of use of the new items and scales. We used neural networks models and already scored responses for training to produce computer-generated scores. Accuracy of computer-generated scores across the three scales was about twice as good as chance (.33), total scores based on rater assigned scores and computer-generated scores correlated highly indicating that computer-based total scores are sufficiently valid to be used in statistical analyses.\n\n\nConclusion: This project has produced three reliable and valid scales of teachers usable Common Core aligned mathematics knowledge for teaching. To promote the wider use of these measures we implemented the automated scoring functionality on the www.teknoclips.org website where the items and automated scoring is available for researchers upon request.\n\n\n\t\t\t\t\tLast Modified: 11/28/2023\n\n\t\t\t\t\tSubmitted by: NicoleKersting\n"
 }
}