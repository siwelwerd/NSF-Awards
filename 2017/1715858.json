{
 "awd_id": "1715858",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Collaborative Research:  EEG-Guided Electrical Stimulation for Immersive Virtual Reality",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2017-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 142000.0,
 "awd_amount": 142000.0,
 "awd_min_amd_letter_date": "2017-08-24",
 "awd_max_amd_letter_date": "2017-08-24",
 "awd_abstract_narration": "Spatial presence, in Virtual Reality (VR) terminology, refers to the perception (or illusion) of being physically present in a simulated environment.  VR strives to create interactive environments that provide experiences of spatial presence through accurate delivery and perception of multimodal sensory stimuli.  Research in VR spans fields ranging from neuroscience and medicine to gaming.   While the computing and gaming industries have generated tremendous advances in hardware and software for graphics processing and 3D display technologies, VR systems still lack capabilities for providing users with haptic feedback (a sense of touch), which is crucial for generating truly immersive, real-world experiences.   It is known that an increase in the feeling of spatial presence manifests itself in the form of increased brain activity.   This research aims to achieve the control of haptic sensory stimulation adaptively, based on the changes in brain activity associated with perceptual responses elicited by sensory stimulation in VR environments.  Project outcomes will include novel scientific discoveries and engineering enhancements that will make significant contributions to other areas of interest, such as prosthetic limbs, augmented reality, and telepresence applications.  The project will help train a new generation of engineers skilled in addressing multidisciplinary challenges, while through outreach activities STEM careers will be promoted at the K-12 level.\r\n\r\nThe research objective is to identify and analyze brain activity associated with the increased feeling of haptic spatial presence elicited by electro-tactile stimulation and measured through EEG, and to investigate closed-loop techniques to control electro-tactile stimulation for enhanced haptic presence in VR environments.  Specifically, the project will: (1) develop an electrical haptic stimulation framework; (2) design analysis techniques to identify markers of haptic inputs in EEG; (3) establish control policies for adaptive electrical stimulation; and (4) evaluate and refine EEG-guided adaptive stimuli control framework in VR environments.  In particular, the proposition to actuate haptic feedback through electrical stimulation is novel, while formulating design principles for model-based optimal EEG-guided closed-loop haptic feedback for immersive spatial presence is transformative.  Additional innovative propositions to advance adaptive control under uncertainty and psychophysical investigations are unique; these present a potentially game-changing opportunity for VR system development and perhaps for general human-computer interaction.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Deniz",
   "pi_last_name": "Erdogmus",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Deniz Erdogmus",
   "pi_email_addr": "erdogmus@ece.neu.edu",
   "nsf_id": "000483728",
   "pi_start_date": "2017-08-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 142000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Intellectual merit of this project is to identify and analyze brain activity associated with increased feeling of haptic spatial presence elicited by electro-tactile stimulation measured and guided through electroencephalography (EEG).&nbsp; The outcomes of this research may extend to other areas of interest such as providing haptic sensation through prosthetic limbs, increased haptic presence in virtual and/or augmented reality environments. This project supported 3 PhD students at the University of Pittsburgh with different level of support between October 2017 and September 2021. The performed research resulted in a total of 12 refereed articles (8 journal and 4 conference articles). &nbsp;In this report, we present the highlights of our research findings. &nbsp;EEG data were collected through experiments from 23 human participants during the lifetime of this project. EEG data collection experiments included: (i) human participants touching with their right-hand index fingertips to surfaces with different textures, specifically rough, medium rough and smooth surfaces, and (ii) application of electrical stimulation with different amplitudes and frequencies to the participants? right-hand index fingertips, see Figure 1. We utilized the EEG data collected in above step (i), and we showed that brain activity measured through EEG changed in response to touching surfaces with different textures and based only on EEG data we could identify which surfaces the participants touched. We specifically identified the brain activity frequency ranges and brain locations that are most informative in response to touching surfaces with different textures: EEG frequency ranges 8-15 Hz (Mu band) and 16-30 Hz (Beta band), and sensorimotor regions of the brain (EEG electrode locations C1, C3 and C5), see Figure 2.&nbsp; The brain activity measured around the sensorimotor regions may also be affected by the movement type (rub or tap) or movement speed (fast or slow) especially when participants are actively touching the surfaces.&nbsp; Therefore, we also developed a machine learning method using adversarial invariant representation learning neural network architecture that performs EEG-based classification of different textured surfaces, while simultaneously minimizing the discriminability of motor movement conditions (i.e., rub or tap, slow vs fast). Results showed that the proposed approach could discriminate among three different textured surfaces with accuracies up to 70%, while suppressing movement related variability from the learned representations while participants actively touched the surfaces through different touching types and speeds (active touching conditions), see Figure 3.&nbsp; We also recorded brain activity measured through EEG and contact force measured through a force transducer during passive touch conditions. To achieve passive touch conditions, we built a Lego robot which moved the surfaces to achieve rub and tap conditions with different speeds while the participants? right-hand fingertips were fastened securely in a fixed position, see Figure 4 for the Lego robot. &nbsp;We developed a machine learning approach to distinguish/classify among the surfaces with three different textures, and our results showed that based only on the EEG data, we could achieve separation accuracies of around 70% (chance level 33%), in addition to EEG if also the contact force was also used for this classification the accuracies significantly increased to the level of around 95%.&nbsp; During the electrical stimulation experiments, the main purpose of using different electrical stimulation waveforms with different frequencies and different intensities was to increase the number of participating neurons which adds up on the synaptic regions and thus generate the nerve impulse or the action potentials which appears as an evoked potential in the EEG generated signals. Therefore, we had two experimental protocols while we collected EEG data during electrical stimulation parameters, the first was by varying the pulse rate and fixing the electrical stimulation amplitude and the second by fixing the rate and by varying the amplitude.&nbsp; We then developed a machine learning method to separate four electrical stimulation conditions based on the brain activity recorded through EEG, we specifically considered the following classes: (C1) low frequency, (C2) high frequency, (C3) low amplitude, (C4) high amplitude. When one vs. the rest classification (i.e., C1 vs others) was considered through stratified cross validation our average accuracy was around 92% (chance level for this classification was identified as around 50% after permutation tests). On the other hand, when we considered four-class classification, the accuracy was around 65% which is still way above the chance level (25%).&nbsp; Finally, we showed that using the brain activity recorded through EEG, we could generate brain activity by applying electrical stimulation to the right-hand fingertips similar to the brain activity recorded in response to actively touching surfaces with different textures. To achieve this, our approach used the force profiles measured through a force transducer, recorded EEG data, and utilized electrical stimulation parameters.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/21/2022<br>\n\t\t\t\t\tModified by: Deniz&nbsp;Erdogmus</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1715858/1715858_10518630_1647918538318_Figure1_withoutCaptions--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1715858/1715858_10518630_1647918538318_Figure1_withoutCaptions--rgov-800width.jpg\" title=\"Illustration of Experimental Setup\"><img src=\"/por/images/Reports/POR/2022/1715858/1715858_10518630_1647918538318_Figure1_withoutCaptions--rgov-66x44.jpg\" alt=\"Illustration of Experimental Setup\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 1: (Left) Illustration of the experimental setup during a trial where the participant is instructed to tap on the texture mounted on the force transducer. (Right) Printed medium rough 3D texture mounted on the force transducer.</div>\n<div class=\"imageCredit\">Murat Akcakaya</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Deniz&nbsp;Erdogmus</div>\n<div class=\"imageTitle\">Illustration of Experimental Setup</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1715858/1715858_10518630_1647918591421_Figure2_withoutCaption_Redacted--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1715858/1715858_10518630_1647918591421_Figure2_withoutCaption_Redacted--rgov-800width.jpg\" title=\"Scalp topoplots of accuracy\"><img src=\"/por/images/Reports/POR/2022/1715858/1715858_10518630_1647918591421_Figure2_withoutCaption_Redacted--rgov-66x44.jpg\" alt=\"Scalp topoplots of accuracy\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 2: Scalp topography for the average accuracy across all participants. I: rub at fast movement frequency, II: rub at medium movement frequency, III: rub at slow movement frequency, IV: tap at fast movement frequency, V: tap at medium movement frequency, VI: tap at slow movement frequency</div>\n<div class=\"imageCredit\">Murat Akcakaya</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Deniz&nbsp;Erdogmus</div>\n<div class=\"imageTitle\">Scalp topoplots of accuracy</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1715858/1715858_10518630_1647918667771_Figure3_withoutcaption--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1715858/1715858_10518630_1647918667771_Figure3_withoutcaption--rgov-800width.jpg\" title=\"Adversarial training\"><img src=\"/por/images/Reports/POR/2022/1715858/1715858_10518630_1647918667771_Figure3_withoutcaption--rgov-66x44.jpg\" alt=\"Adversarial training\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 3: Classifier versus adversary accuracies for each subject. For each colored box,center marks denote the means across 5 training folds and 10 repetitions, and box widths denote 1 standard deviation intervals in both dimensions. Black dashed lines denote chance level.</div>\n<div class=\"imageCredit\">Murat Akcakaya</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Deniz&nbsp;Erdogmus</div>\n<div class=\"imageTitle\">Adversarial training</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nIntellectual merit of this project is to identify and analyze brain activity associated with increased feeling of haptic spatial presence elicited by electro-tactile stimulation measured and guided through electroencephalography (EEG).  The outcomes of this research may extend to other areas of interest such as providing haptic sensation through prosthetic limbs, increased haptic presence in virtual and/or augmented reality environments. This project supported 3 PhD students at the University of Pittsburgh with different level of support between October 2017 and September 2021. The performed research resulted in a total of 12 refereed articles (8 journal and 4 conference articles).  In this report, we present the highlights of our research findings.  EEG data were collected through experiments from 23 human participants during the lifetime of this project. EEG data collection experiments included: (i) human participants touching with their right-hand index fingertips to surfaces with different textures, specifically rough, medium rough and smooth surfaces, and (ii) application of electrical stimulation with different amplitudes and frequencies to the participants? right-hand index fingertips, see Figure 1. We utilized the EEG data collected in above step (i), and we showed that brain activity measured through EEG changed in response to touching surfaces with different textures and based only on EEG data we could identify which surfaces the participants touched. We specifically identified the brain activity frequency ranges and brain locations that are most informative in response to touching surfaces with different textures: EEG frequency ranges 8-15 Hz (Mu band) and 16-30 Hz (Beta band), and sensorimotor regions of the brain (EEG electrode locations C1, C3 and C5), see Figure 2.  The brain activity measured around the sensorimotor regions may also be affected by the movement type (rub or tap) or movement speed (fast or slow) especially when participants are actively touching the surfaces.  Therefore, we also developed a machine learning method using adversarial invariant representation learning neural network architecture that performs EEG-based classification of different textured surfaces, while simultaneously minimizing the discriminability of motor movement conditions (i.e., rub or tap, slow vs fast). Results showed that the proposed approach could discriminate among three different textured surfaces with accuracies up to 70%, while suppressing movement related variability from the learned representations while participants actively touched the surfaces through different touching types and speeds (active touching conditions), see Figure 3.  We also recorded brain activity measured through EEG and contact force measured through a force transducer during passive touch conditions. To achieve passive touch conditions, we built a Lego robot which moved the surfaces to achieve rub and tap conditions with different speeds while the participants? right-hand fingertips were fastened securely in a fixed position, see Figure 4 for the Lego robot.  We developed a machine learning approach to distinguish/classify among the surfaces with three different textures, and our results showed that based only on the EEG data, we could achieve separation accuracies of around 70% (chance level 33%), in addition to EEG if also the contact force was also used for this classification the accuracies significantly increased to the level of around 95%.  During the electrical stimulation experiments, the main purpose of using different electrical stimulation waveforms with different frequencies and different intensities was to increase the number of participating neurons which adds up on the synaptic regions and thus generate the nerve impulse or the action potentials which appears as an evoked potential in the EEG generated signals. Therefore, we had two experimental protocols while we collected EEG data during electrical stimulation parameters, the first was by varying the pulse rate and fixing the electrical stimulation amplitude and the second by fixing the rate and by varying the amplitude.  We then developed a machine learning method to separate four electrical stimulation conditions based on the brain activity recorded through EEG, we specifically considered the following classes: (C1) low frequency, (C2) high frequency, (C3) low amplitude, (C4) high amplitude. When one vs. the rest classification (i.e., C1 vs others) was considered through stratified cross validation our average accuracy was around 92% (chance level for this classification was identified as around 50% after permutation tests). On the other hand, when we considered four-class classification, the accuracy was around 65% which is still way above the chance level (25%).  Finally, we showed that using the brain activity recorded through EEG, we could generate brain activity by applying electrical stimulation to the right-hand fingertips similar to the brain activity recorded in response to actively touching surfaces with different textures. To achieve this, our approach used the force profiles measured through a force transducer, recorded EEG data, and utilized electrical stimulation parameters.\n\n\t\t\t\t\tLast Modified: 03/21/2022\n\n\t\t\t\t\tSubmitted by: Deniz Erdogmus"
 }
}