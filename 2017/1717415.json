{
 "awd_id": "1717415",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: Discerning and Recommending Context-Specific Best Practices in DevOps-Oriented Software Development",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 309999.0,
 "awd_amount": 335351.0,
 "awd_min_amd_letter_date": "2017-05-31",
 "awd_max_amd_letter_date": "2020-06-02",
 "awd_abstract_narration": "This project is a scientific study of modern software development practices, which has become known as DevOps. The DevOps culture seeks to bring changes into software production as quickly as possible without compromising software quality, primarily by automating the processes of building, testing, and deploying software. In practice, DevOps engineers can choose between a multitude of tools, including configuration management, cloud-based continuous integration, and automated deployment. Often individual tools are used without much guidance on how they fit in the big picture, and questions about best practices abound in online forums. However, existing answers are typically generic rules of thumb or dated advice, mostly based on third-party experiences, often non-applicable to the specific context. In fact, current empirical evidence on the effectiveness of DevOps practices is much fragmented and incomplete. State-of-the-art decision-making support, based on hard data and informed advice, can help DevOps engineers discern the best choices and practices for their tasks.\u00a0\r\n\r\nThe proposed research is grounded in contingency theory, where the emphasis is on task context when reasoning about the effectiveness of practices. The goal of this project is to learn and convey structured, context-dependent analytics on best practices in DevOps environments, by mining and analyzing data from the collaborative coding platform GitHub. Using established and novel qualitative and quantitative techniques, this research will: (1) identify clusters of software projects that share similar context variables; and (2) within a context of interest, discern the conditions under which DevOps practices such as continuous integration are most (and least) effective. This will result in actionable knowledge and tool support for DevOps teams, to customize efficient project practices to their environment, as well as advance the theory and practice of software engineering, especially as it relates to distributed, fast paced, automation-heavy environments.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bogdan",
   "pi_last_name": "Vasilescu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bogdan Vasilescu",
   "pi_email_addr": "vasilescu@cmu.edu",
   "nsf_id": "000692194",
   "pi_start_date": "2017-05-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie Mellon University",
  "perf_str_addr": "5000 Forbes Ave",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 309999.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 9352.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-7e65ecfd-7fff-651d-19e0-18872bb998dc\"> </span></p>\n<p dir=\"ltr\"><span>This project explored the interplay between project context and the applicability and effectiveness of DevOps automation practices, including continuous integration and continuous deployment.&nbsp;</span></p>\n<p dir=\"ltr\"><span>The DevOps software development culture seeks to bring changes into production as quickly as possible without compromising software quality, primarily by automating the processes of building, testing, and deploying software. In practice, DevOps is supported by a multitude of tools and practices, often combined into a multi-step </span><span>pipeline</span><span>. Software engineers need to make decisions about their DevOps pipelines constantly, for example when to do what, when not to do it, and in what order it is best to do it. This project filled a gap in the decision-making support available to DevOps practitioners, by providing much needed empirical evidence on the factors associated with the adoption decision and outcomes of using different DevOps practices and tools in different contexts.</span></p>\n<p dir=\"ltr\"><span>Ultimately, we carried out a series of mixed-methods empirical studies of DevOps tools and practices related to automated testing, cloud-based continuous integration, automated deployment, feature flagging, dependency management, and others. We studied how adopting continuous integration impacts other software development practices such as code review, how context factors and social diffusion mechanisms impact the adoption of quality assurance automation tools, what are some fundamental trade-offs between competing tools and between continuous deployment pipeline configurations, and how the emerging practice of feature flagging is changing software engineering practice.</span></p>\n<p dir=\"ltr\"><span>Typically, when answering a set of research questions we interviewed and surveyed practitioners about their use cases and reasons for adoption or abandonment of different practices, or we qualitatively analyzed public traces from open-source software projects where these decisions were discussed. This way, we derived hypotheses about factors that influence the adoption and configuration of DevOps pipelines in the wild, and hypotheses about how different configurations might lead to different outcomes in terms of developer productivity and software quality, taking project context into account. Next, we collected large amounts of trace data from open-source projects, and used existing and novel operationalizations to measure the different relevant variables. Finally, following a quasi-experimental design, we estimated statistical models to test our hypotheses, including causal inference interrupted time-series analysis models.</span></p>\n<p dir=\"ltr\"><span>The work resulting from this project has been well-received. We published research papers frequently in major software engineering venues, including the ICSE, ESEC/FSE, and ASE conferences. We also delivered invited talks and keynotes presenting some of our results at open source and industry practitioner venues. Our data collection infrastructure, datasets, and statistical models remain available as open-source tools.</span></p>\n<p dir=\"ltr\"><span>This project also received contributions from a total of N students, including M undergraduate REU students, who received unique training in DevOps and open-source software development domain-specific aspects, research design and empirical research methods, writing technical reports, and designing technical presentations.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/03/2021<br>\n\t\t\t\t\tModified by: Bogdan&nbsp;Vasilescu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThis project explored the interplay between project context and the applicability and effectiveness of DevOps automation practices, including continuous integration and continuous deployment. \nThe DevOps software development culture seeks to bring changes into production as quickly as possible without compromising software quality, primarily by automating the processes of building, testing, and deploying software. In practice, DevOps is supported by a multitude of tools and practices, often combined into a multi-step pipeline. Software engineers need to make decisions about their DevOps pipelines constantly, for example when to do what, when not to do it, and in what order it is best to do it. This project filled a gap in the decision-making support available to DevOps practitioners, by providing much needed empirical evidence on the factors associated with the adoption decision and outcomes of using different DevOps practices and tools in different contexts.\nUltimately, we carried out a series of mixed-methods empirical studies of DevOps tools and practices related to automated testing, cloud-based continuous integration, automated deployment, feature flagging, dependency management, and others. We studied how adopting continuous integration impacts other software development practices such as code review, how context factors and social diffusion mechanisms impact the adoption of quality assurance automation tools, what are some fundamental trade-offs between competing tools and between continuous deployment pipeline configurations, and how the emerging practice of feature flagging is changing software engineering practice.\nTypically, when answering a set of research questions we interviewed and surveyed practitioners about their use cases and reasons for adoption or abandonment of different practices, or we qualitatively analyzed public traces from open-source software projects where these decisions were discussed. This way, we derived hypotheses about factors that influence the adoption and configuration of DevOps pipelines in the wild, and hypotheses about how different configurations might lead to different outcomes in terms of developer productivity and software quality, taking project context into account. Next, we collected large amounts of trace data from open-source projects, and used existing and novel operationalizations to measure the different relevant variables. Finally, following a quasi-experimental design, we estimated statistical models to test our hypotheses, including causal inference interrupted time-series analysis models.\nThe work resulting from this project has been well-received. We published research papers frequently in major software engineering venues, including the ICSE, ESEC/FSE, and ASE conferences. We also delivered invited talks and keynotes presenting some of our results at open source and industry practitioner venues. Our data collection infrastructure, datasets, and statistical models remain available as open-source tools.\nThis project also received contributions from a total of N students, including M undergraduate REU students, who received unique training in DevOps and open-source software development domain-specific aspects, research design and empirical research methods, writing technical reports, and designing technical presentations.\n\n \n\n\t\t\t\t\tLast Modified: 11/03/2021\n\n\t\t\t\t\tSubmitted by: Bogdan Vasilescu"
 }
}