{
 "awd_id": "1659403",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CC* Integration: SANDIE: SDN-Assisted NDN for Data Intensive Experiments",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032922935",
 "po_email": "dmedhi@nsf.gov",
 "po_sign_block_name": "Deepankar Medhi",
 "awd_eff_date": "2017-07-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 1000000.0,
 "awd_amount": 1000000.0,
 "awd_min_amd_letter_date": "2017-06-19",
 "awd_max_amd_letter_date": "2017-06-19",
 "awd_abstract_narration": "Advancing discovery in many scientific fields depends crucially on our ability\r\nto extract the wealth of knowledge buried in massive datasets whose scale and complexity continue\r\nto grow exponentially with time. In order to address this fundamental challenge, this project will\r\ndevelop and deploy SANDIE, a Named Data Networking (NDN) architecture supported by advanced\r\nSoftware Defined Network services for Data Intensive Science, with the Large Hadron Collider (LHC) high energy\r\nphysics program as the leading use case. \r\n\r\nThe implementation of SANDIE will leverage two state of the art testbeds: the NDN testbed hosted and serving the climate\r\nscience community at Colorado State, and the SDN testbed hosted at Caltech. Building on these facilities, and the support for SDN services\r\nFrom multiple advanced Research & Education network partners,\r\nwe will deploy a set of ten high performance, relatively low cost NDN edge caches with SSDs\r\nand 40G or 100G network interfaces at six participating sites: Caltech, Northeastern, UCSD,\r\nUniversity of Florida, MIT and CERN, together with an existing cache at CSU.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Edmund",
   "pi_last_name": "Yeh",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Edmund M Yeh",
   "pi_email_addr": "eyeh@ece.neu.edu",
   "nsf_id": "000413920",
   "pi_start_date": "2017-06-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Harvey",
   "pi_last_name": "Newman",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Harvey B Newman",
   "pi_email_addr": "newman@hep.caltech.edu",
   "nsf_id": "000171318",
   "pi_start_date": "2017-06-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Christos",
   "pi_last_name": "Papadopoulos",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christos Papadopoulos",
   "pi_email_addr": "christos.papadopoulos@memphis.edu",
   "nsf_id": "000394271",
   "pi_start_date": "2017-06-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Avenue",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "289000",
   "pgm_ele_name": "CISE Research Resources"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 1000000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The world's largest data- and network-intensive science programs at the forefront of making fundamental discoveries face unprecedented challenges: in global data distribution, processing, access and analysis, and in the coordinated use of massive but still limited computing, storage and network resources. &nbsp;This project has made fundamental contributions in meeting these challenges, by designing and implementing a new, highly efficient system for data access and distribution for the Large Hadron Collider (LHC) high energy physics (HEP) network.&nbsp; The system is based on the Named Data Networking (NDN) architecture and supported by advanced Software Defined Network (SDN) services.&nbsp;</p>\n<p>Outcomes in the intellectual merit area include (1) detailed analysis of workflow, data placement and resource distribution in the LHC Compact Muon Solenoid (CMS) network, including CMS Elasticsearch, analytics service of CMS, Phedex and DBS systems; (2) development of hierarchical NDN naming scheme for CMS data; (3) implementation of the XRootD NDN based OSS (Open Storage System) plugin, with an embedded NDN consumer (which translates file system calls into NDN Interest Packets and send them over the network with the help of an NDN forwarder) along with an NDN producer; (4) implementation, optimization, and experimentation (in a local testbed) of joint caching and forwarding algorithms with the NDN Forwarding Daemon (NFD); (5) implementation, optimization, and experimentation (in local and wide-area-network testbeds) of joint caching and forwarding algorithms with the NDN-DPDK forwarder developed by National Institute of Standards (NIST), for improved performance in throughput, delay, and cache hit rates; (6) development of new consumer and producer applications based on the NDNgo library developed at NIST, to enable NDN-based applications interfacing with the NDN-DPDK forwarder to achieve throughputs higher than 1 Gbps; (7) development of new NDN library offering a set of APIs on which developers can base their applications to communicate with a local NDN-DPDK forwarders using memif, a shared memory packet interface that provides high performance packet transmission; (8) updating of joint caching and forwarding algorithms to be compatible with new versions of NDN-DPDK forwarder based on the NDNgo library and using the memif interface; (9) implementation of NDN applications inside Docker containers, enabling deployment on different computing platforms; (10) demonstration that XRootD NDN based OSS plugin using NFD forwarder yields better performance for CMSSW jobs than existing solutions in use at CERN; (11) establishment of a SANDIE wide-area-network (WAN) testbed to support transfer rates up to 100 Gbps, with servers at Northeastern, Caltech, and Colorado State University; (12) planning, coordination, deployment and management of stable, high-performance virtual LANs (VLANs) for the SANDIE WAN testbed, in collaboration with campus network administrators, regional network operators, Internet2, STARLIGHT, ESnet, CENIC and SCinet; &nbsp;(13) establishment of expanded 100 Gbps WAN testbed with nodes at Northeastern (MGHPCC), Caltech, STARLIGHT Chicago, UCLA and Tennessee Tech;&nbsp; (14) first demonstration of feasibility and performance of the NDN-based SANDIE data distribution platform over a WAN at Supercomputing (SC) 2018 conference; (15) demonstration at SC 2019 conference that NDN-based SANDIE data distribution platform can deliver LHC HEP data over a transcontinental layer-2 WAN testbed at over 6.7 Gbps over a single thread, and that optimized joint caching and forwarding can decrease download times by a factor of 10.</p>\n<p>Outcomes in the broader impact area include (1) establishment of the NDN paradigm for agile and efficient network operations in support of data-intensive sciences, including name-based data access, distribution and caching, together with the SDN-driven \"consistent operations\" paradigm in which science programs can use stable large flows directed along optimally chosen load-balanced paths up to high water marks compatible with other traffic; (2) acceleration of progress to the next round of data-intensive science discoveries, with initial focus on CMS and the other LHC experiments, and future application of developed methods and tools to other major science areas including future astrophysical sky surveys, genomics, bioinformatics, climate, and earth observation; (3) the design, optimization, and deployment of high-performance NDN-based protocols, algorithms, and systems in mainstream data distribution and analysis settings at regional, continental and intercontinental scales, with broad-based impact across many data-intensive science and engineering fields; (4) the establishment and maintenance of a persistent high-throughput wide area network testbed for experimentation of advanced NDN and SDN-based protocols, algorithms, and systems; (5) research and educational training for supported graduate students in data-centric networking for large-scale data-intensive science applications; (6) training of a new generation of scientists and engineers in several leading edge technology areas, including NDN as a candidate future network architecture, data intensive applications using NDN, its field deployment across the present ensemble of research and education IP networks, federated data access and analysis, and optimization of globally distributed systems.<em>&nbsp;</em></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/18/2022<br>\n\t\t\t\t\tModified by: Edmund&nbsp;M&nbsp;Yeh</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe world's largest data- and network-intensive science programs at the forefront of making fundamental discoveries face unprecedented challenges: in global data distribution, processing, access and analysis, and in the coordinated use of massive but still limited computing, storage and network resources.  This project has made fundamental contributions in meeting these challenges, by designing and implementing a new, highly efficient system for data access and distribution for the Large Hadron Collider (LHC) high energy physics (HEP) network.  The system is based on the Named Data Networking (NDN) architecture and supported by advanced Software Defined Network (SDN) services. \n\nOutcomes in the intellectual merit area include (1) detailed analysis of workflow, data placement and resource distribution in the LHC Compact Muon Solenoid (CMS) network, including CMS Elasticsearch, analytics service of CMS, Phedex and DBS systems; (2) development of hierarchical NDN naming scheme for CMS data; (3) implementation of the XRootD NDN based OSS (Open Storage System) plugin, with an embedded NDN consumer (which translates file system calls into NDN Interest Packets and send them over the network with the help of an NDN forwarder) along with an NDN producer; (4) implementation, optimization, and experimentation (in a local testbed) of joint caching and forwarding algorithms with the NDN Forwarding Daemon (NFD); (5) implementation, optimization, and experimentation (in local and wide-area-network testbeds) of joint caching and forwarding algorithms with the NDN-DPDK forwarder developed by National Institute of Standards (NIST), for improved performance in throughput, delay, and cache hit rates; (6) development of new consumer and producer applications based on the NDNgo library developed at NIST, to enable NDN-based applications interfacing with the NDN-DPDK forwarder to achieve throughputs higher than 1 Gbps; (7) development of new NDN library offering a set of APIs on which developers can base their applications to communicate with a local NDN-DPDK forwarders using memif, a shared memory packet interface that provides high performance packet transmission; (8) updating of joint caching and forwarding algorithms to be compatible with new versions of NDN-DPDK forwarder based on the NDNgo library and using the memif interface; (9) implementation of NDN applications inside Docker containers, enabling deployment on different computing platforms; (10) demonstration that XRootD NDN based OSS plugin using NFD forwarder yields better performance for CMSSW jobs than existing solutions in use at CERN; (11) establishment of a SANDIE wide-area-network (WAN) testbed to support transfer rates up to 100 Gbps, with servers at Northeastern, Caltech, and Colorado State University; (12) planning, coordination, deployment and management of stable, high-performance virtual LANs (VLANs) for the SANDIE WAN testbed, in collaboration with campus network administrators, regional network operators, Internet2, STARLIGHT, ESnet, CENIC and SCinet;  (13) establishment of expanded 100 Gbps WAN testbed with nodes at Northeastern (MGHPCC), Caltech, STARLIGHT Chicago, UCLA and Tennessee Tech;  (14) first demonstration of feasibility and performance of the NDN-based SANDIE data distribution platform over a WAN at Supercomputing (SC) 2018 conference; (15) demonstration at SC 2019 conference that NDN-based SANDIE data distribution platform can deliver LHC HEP data over a transcontinental layer-2 WAN testbed at over 6.7 Gbps over a single thread, and that optimized joint caching and forwarding can decrease download times by a factor of 10.\n\nOutcomes in the broader impact area include (1) establishment of the NDN paradigm for agile and efficient network operations in support of data-intensive sciences, including name-based data access, distribution and caching, together with the SDN-driven \"consistent operations\" paradigm in which science programs can use stable large flows directed along optimally chosen load-balanced paths up to high water marks compatible with other traffic; (2) acceleration of progress to the next round of data-intensive science discoveries, with initial focus on CMS and the other LHC experiments, and future application of developed methods and tools to other major science areas including future astrophysical sky surveys, genomics, bioinformatics, climate, and earth observation; (3) the design, optimization, and deployment of high-performance NDN-based protocols, algorithms, and systems in mainstream data distribution and analysis settings at regional, continental and intercontinental scales, with broad-based impact across many data-intensive science and engineering fields; (4) the establishment and maintenance of a persistent high-throughput wide area network testbed for experimentation of advanced NDN and SDN-based protocols, algorithms, and systems; (5) research and educational training for supported graduate students in data-centric networking for large-scale data-intensive science applications; (6) training of a new generation of scientists and engineers in several leading edge technology areas, including NDN as a candidate future network architecture, data intensive applications using NDN, its field deployment across the present ensemble of research and education IP networks, federated data access and analysis, and optimization of globally distributed systems. \n\n\t\t\t\t\tLast Modified: 05/18/2022\n\n\t\t\t\t\tSubmitted by: Edmund M Yeh"
 }
}