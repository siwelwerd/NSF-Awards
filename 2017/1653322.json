{
 "awd_id": "1653322",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SCH: CAREER:  Co-Robotic Ultrasound Sensing in Bioengineering",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2023-04-30",
 "tot_intn_awd_amt": 419902.0,
 "awd_amount": 419902.0,
 "awd_min_amd_letter_date": "2017-07-22",
 "awd_max_amd_letter_date": "2017-07-22",
 "awd_abstract_narration": "Ultrasound imaging, while frequently used in heathcare, remains challenged by three important issues. First, a very significant percentage of ultrasonographers (63-91%) develop musculoskeletal disorders due to effort required to perform imaging tasks. Second, ultrasound imaging is limited by loss of resolution at increasing depths (e.g., in imaging of obese patients), significantly limiting imaging value with conventional ultrasound imaging. Finally, ultrasound imaging is most commonly qualitative in nature, and quantitative imaging (e.g., measurement of the speed of the ultrasounds signal) has been limited. There is significant gap and need for more accurate imaging of various organs and diseases. All these issues hinder unleashing the potential benefit of ultrasound technology serving a wider sector of patients in hospitals and most importantly outside hospitals, including point-of-cares and homes. All these seemingly distinct issues can be tackled and addressed via a co-robotic and multi-wave ultrasound framework. The objective of this proposal is to characterize fundamental principles at the intersection of robotics, ultrasound physics, signal processing, machine learning and bioengineering, which will enable a new generation of advanced ultrasound imaging technologies capable of providing cost-effective precise interventional guidance and high-quality quantitative diagnostic imaging to a wider sector of people at hospitals, points-of-care, and homes. Additionally, this proposal emphasizes the following educational objectives: (1) create hands-on robotic imaging undergraduate/graduate training curriculum relying on the MUSiiC toolkit; (2) bring research results to local schools including Centennial High School and involve their students in research; and (3) deploy low-cost wireless ultrasound systems and light-weight and human-safe robots in high schools and university classrooms. \r\n\r\n\r\nThe research objective of this proposal is to characterize fundamental principles at the intersection of robotics, ultrasound physics, signal processing, machine learning and bioengineering, which will enable a new generation of advanced ultrasound imaging technologies capable of providing cost-effective precise interventional guidance and high-quality quantitative diagnostic imaging to a wider sector of people at hospitals, points-of-care, and homes. To achieve this objective, this proposal includes an integrated research-education plan consisting of three complementary and interconnected research thrusts. Thrust 1: Novel Multi-wave Ultrasonic and Robotic Imaging Devices focuses on novel multi-wave ultrasound imaging architectures and physics-based simulations that describe their performance under variable calibration and robot tracking accuracies, and beam-width and geometry limitations of ultrasound sensors.  Specifically, the project proposes ultrasonically smart tools, co-robotic multi-wave ultrasound systems, and active calibration platform and validation. Thrust 2: Robust Sensing and Co-Robotic Imaging focuses on using models, architectures and devices from Thrust 1 to endow surgical and interventional guidance with robust sensing and to devise and enable new imaging algorithms with both robust sensing and co-robotic intelligence. Specifically, the project uses a novel thermal imaging algorithm leveraging the unique multi-wave ultrasound architecture described in Thrust 1. Additionally, we explore co-robotic imaging to substantially enhance ultrasound resolution utilizing synthetic aperture reconstruction guided by the robot's precise and accurate motion trajectory.  Thrust 3: Education focuses on integrating research results into education at the high school, undergraduate, and graduate levels, while emphasizing participation by an underrepresented individuals (African American and women) in Biomedical Sciences and Engineering. The proposal will also bring research results to local schools including Centennial High School and involve their students in research. This can easily achieve this by relying on the team's Medical UltraSound Imaging and Intervention Collaboratory (MUSiiC) software toolkit and enabling smart phone and tablets to control ultrasound systems. The plan also includes deployment of a number of low-cost wireless ultrasound systems, along with light-weight and human-safe robots, to high school and university classrooms. The results from all three thrusts will be applied to systems for three clinical testbed setups, including cancer intervention, catheterization, and diagnostic imaging.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Emad",
   "pi_last_name": "Boctor",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Emad M Boctor",
   "pi_email_addr": "eboctor1@jhmi.edu",
   "nsf_id": "000344690",
   "pi_start_date": "2017-07-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "3400 N CHARLES ST",
  "perf_city_name": "BALTIMORE",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182608",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  },
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 419902.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Project Outcomes Report</strong></p>\r\n<p>This NSF CAREER project&nbsp;was&nbsp;dedicated&nbsp;to&nbsp;advancements in&nbsp;ultrasound imaging by integrating <strong>robotics</strong>, <strong>ultrasound physics</strong>, and <strong>artificial intelligence</strong> to&nbsp;reach&nbsp;higher levels of&nbsp;diagnostic precision and medical interventions. The research&nbsp;develops&nbsp;<strong>co-robotic ultrasound technologies</strong> that&nbsp;will&nbsp;improve&nbsp;not only&nbsp;imaging accuracy&nbsp;but&nbsp;also&nbsp;extend&nbsp;accessibility to non-invasive, cost-effective solutions. The&nbsp;two major thrusts&nbsp;were&nbsp;the development of <strong>innovative ultrasound imaging devices</strong>&nbsp;such&nbsp;as&nbsp;<em>ultrasonically smart tools</em>,&nbsp;designed for real-time surgical guidance,&nbsp;and <em>wearable ultrasound systems</em>&nbsp;for&nbsp;continuous patient monitoring;&nbsp;and&nbsp;the creation of <strong>advanced sensing and imaging algorithms</strong>&nbsp;exploiting&nbsp;<em>deep learning</em>, <em>multi-wave imaging</em>, and <em>photoacoustic techniques</em>&nbsp;in order&nbsp;to enhance diagnostic capabilities&nbsp;with&nbsp;reduced&nbsp;reliance&nbsp;on ionizing radiation modalities such as X-ray and CT scans.&nbsp;These research efforts&nbsp;knit&nbsp;together&nbsp;state-of-the-art&nbsp;advances&nbsp;in robotic ultrasound imaging, real-time surgical navigation, cancer detection, and neuroimaging&nbsp;during&nbsp;the&nbsp;five-year&nbsp;duration and form a basis&nbsp;for transformative applications&nbsp;both&nbsp;in&nbsp;the&nbsp;clinical and research&nbsp;realms.</p>\r\n<p><strong>Intellectual Merit.</strong> The&nbsp;major&nbsp;contributions&nbsp;of&nbsp;the&nbsp;project&nbsp;were several&nbsp;significant breakthroughs&nbsp;in&nbsp;the fields of&nbsp;Co-robotic Ultrasound, Real-time Imaging, and&nbsp;AI-driven Diagnostics.&nbsp;We design new imaging systems&nbsp;by leveraging robotics and ultrasound physics&nbsp;to&nbsp;enhance&nbsp;precision in minimally invasive&nbsp;surgery&nbsp;and&nbsp;unlock&nbsp;new capabilities for point-of-care diagnostics.<strong>&nbsp;</strong></p>\r\n<p><strong>Co-Robotic Ultrasound and Surgical Guidance.</strong> This&nbsp;study&nbsp;introduced robot-assisted ultrasound imaging techniques&nbsp;that&nbsp;allow for&nbsp;real-time scanning with higher precision,&nbsp;reducing operator dependency.&nbsp;Such&nbsp;innovation&nbsp;has&nbsp;significant potential to &nbsp;enhance&nbsp;procedures such as lumbar punctures and prostate cancer surgery, ensuring safer and more effective interventions.&nbsp;In addition, wearable ultrasound devices were developed to&nbsp;enable&nbsp;continuous monitoring of fetal health, neonatal stroke detection, and vascular conditions.<br /> <strong>Advanced Photoacoustic Imaging.</strong> This&nbsp;represented&nbsp;a major&nbsp;advance&nbsp;of&nbsp;the&nbsp;project&nbsp;since&nbsp;photoacoustic imaging&nbsp;provided&nbsp;high&nbsp;contrast&nbsp;toward&nbsp;cancer detection.&nbsp;Using targeted molecular markers,&nbsp;real-time visualization of prostate tumors&nbsp;could&nbsp;be possible to enhance&nbsp;diagnostic&nbsp;and treatment planning.&nbsp;The&nbsp;work&nbsp;also&nbsp;pioneered&nbsp;the&nbsp;techniques&nbsp;of&nbsp;noninvasive&nbsp;neural imaging&nbsp;using&nbsp;monitoring&nbsp;of&nbsp;brain activity through intact scalp tissues&nbsp;potentially&nbsp;to&nbsp;enable&nbsp;new&nbsp;ways of diagnostics for&nbsp;stroke and neurovascular&nbsp;conditions.<br /> <strong>Smart Interventional Ultrasound Tools.</strong> The project&nbsp;developed&nbsp;active ultrasound phantoms that&nbsp;improve&nbsp;calibration precision, making robotic ultrasound imaging more accessible and reliable&nbsp;to improve imaging accuracy and procedural guidance. We&nbsp;have&nbsp;also developed a dual-robotic ultrasound system that synchronizes abdominal and endoluminal imaging-assisted&nbsp;improved diagnostics for prostate cancer.<br /> <strong>AI-Powered Imaging and Sensing.</strong> Artificial intelligence played a&nbsp;key&nbsp;role in refining&nbsp;diagnostics&nbsp;based&nbsp;on ultrasound.&nbsp;Incorporating&nbsp;deep learning models&nbsp;significantly&nbsp;enhances&nbsp;thermal monitoring&nbsp;while&nbsp;guiding ablative therapies.&nbsp;An automated ultrasound navigation system was&nbsp;used&nbsp;to assist&nbsp;the&nbsp;physician&nbsp;in&nbsp;performing&nbsp;real-time imaging&nbsp;with&nbsp;less&nbsp;variability and&nbsp;increased&nbsp;precision&nbsp;in diagnosis.</p>\r\n<p><strong>Broader Impacts.</strong> This project has contributed to advancements in medical imaging, workforce training, and technology development, with broader applications in healthcare and biomedical engineering.</p>\r\n<p><strong>Medical Imaging and Patient Care.</strong> This project contributed to the democratization of high-quality imaging by reducing dependence on expensive and radiation-based techniques such as X-ray and MRI. By enabling real-time surgical guidance and expanding the capabilities of wearable ultrasound systems, this research has provided new avenues for remote patient monitoring and emergency diagnostics, particularly in rural and low-resource settings.</p>\r\n<p><strong>Training the Next Generation of Scientists and Engineers. </strong>Over the course of the project, numerous Ph.D., Master&rsquo;s, and undergraduate students participated in cutting-edge research, resulting in impactful dissertations, publications, and technical advancements. High school students were also engaged in medical imaging projects, fostering early interest in biomedical engineering. Beyond direct mentorship, the project hosted workshops, lectures, and international collaborations, expanding public awareness and knowledge-sharing in robotic ultrasound technology.<strong>&nbsp;</strong></p>\r\n<p><strong>Technology Transfer and Industry Collaborations.</strong> The technological advancements developed in this research have spurred multiple industry partnerships. Companies such as Clear Guide Medical, Intuitive Surgical, Kitware, and Analog Devices Inc. have collaborated to explore commercialization pathways.</p>\r\n<p><strong>Societal Impact: Expanding Access to Affordable Medical Imaging. </strong>Through the development of cost-effective, portable ultrasound solutions, this project has expanded access to high-quality imaging technologies. Additionally, advancements in photoacoustic imaging have contributed to non-invasive cancer detection techniques. Further work in retinal stimulation research has opened new possibilities for vision restoration using photoacoustic neural stimulation, with the potential to transform treatments for blindness and neural disorders</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/11/2025<br>\nModified by: Emad&nbsp;M&nbsp;Boctor</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nProject Outcomes Report\r\n\n\nThis NSF CAREER projectwasdedicatedtoadvancements inultrasound imaging by integrating robotics, ultrasound physics, and artificial intelligence toreachhigher levels ofdiagnostic precision and medical interventions. The researchdevelopsco-robotic ultrasound technologies thatwillimprovenot onlyimaging accuracybutalsoextendaccessibility to non-invasive, cost-effective solutions. Thetwo major thrustswerethe development of innovative ultrasound imaging devicessuchasultrasonically smart tools,designed for real-time surgical guidance,and wearable ultrasound systemsforcontinuous patient monitoring;andthe creation of advanced sensing and imaging algorithmsexploitingdeep learning, multi-wave imaging, and photoacoustic techniquesin orderto enhance diagnostic capabilitieswithreducedrelianceon ionizing radiation modalities such as X-ray and CT scans.These research effortsknittogetherstate-of-the-artadvancesin robotic ultrasound imaging, real-time surgical navigation, cancer detection, and neuroimagingduringthefive-yearduration and form a basisfor transformative applicationsbothintheclinical and researchrealms.\r\n\n\nIntellectual Merit. Themajorcontributionsoftheprojectwere severalsignificant breakthroughsinthe fields ofCo-robotic Ultrasound, Real-time Imaging, andAI-driven Diagnostics.We design new imaging systemsby leveraging robotics and ultrasound physicstoenhanceprecision in minimally invasivesurgeryandunlocknew capabilities for point-of-care diagnostics.\r\n\n\nCo-Robotic Ultrasound and Surgical Guidance. Thisstudyintroduced robot-assisted ultrasound imaging techniquesthatallow forreal-time scanning with higher precision,reducing operator dependency.Suchinnovationhassignificant potential to enhanceprocedures such as lumbar punctures and prostate cancer surgery, ensuring safer and more effective interventions.In addition, wearable ultrasound devices were developed toenablecontinuous monitoring of fetal health, neonatal stroke detection, and vascular conditions.\n Advanced Photoacoustic Imaging. Thisrepresenteda majoradvanceoftheprojectsincephotoacoustic imagingprovidedhighcontrasttowardcancer detection.Using targeted molecular markers,real-time visualization of prostate tumorscouldbe possible to enhancediagnosticand treatment planning.Theworkalsopioneeredthetechniquesofnoninvasiveneural imagingusingmonitoringofbrain activity through intact scalp tissuespotentiallytoenablenewways of diagnostics forstroke and neurovascularconditions.\n Smart Interventional Ultrasound Tools. The projectdevelopedactive ultrasound phantoms thatimprovecalibration precision, making robotic ultrasound imaging more accessible and reliableto improve imaging accuracy and procedural guidance. Wehavealso developed a dual-robotic ultrasound system that synchronizes abdominal and endoluminal imaging-assistedimproved diagnostics for prostate cancer.\n AI-Powered Imaging and Sensing. Artificial intelligence played akeyrole in refiningdiagnosticsbasedon ultrasound.Incorporatingdeep learning modelssignificantlyenhancesthermal monitoringwhileguiding ablative therapies.An automated ultrasound navigation system wasusedto assistthephysicianinperformingreal-time imagingwithlessvariability andincreasedprecisionin diagnosis.\r\n\n\nBroader Impacts. This project has contributed to advancements in medical imaging, workforce training, and technology development, with broader applications in healthcare and biomedical engineering.\r\n\n\nMedical Imaging and Patient Care. This project contributed to the democratization of high-quality imaging by reducing dependence on expensive and radiation-based techniques such as X-ray and MRI. By enabling real-time surgical guidance and expanding the capabilities of wearable ultrasound systems, this research has provided new avenues for remote patient monitoring and emergency diagnostics, particularly in rural and low-resource settings.\r\n\n\nTraining the Next Generation of Scientists and Engineers. Over the course of the project, numerous Ph.D., Masters, and undergraduate students participated in cutting-edge research, resulting in impactful dissertations, publications, and technical advancements. High school students were also engaged in medical imaging projects, fostering early interest in biomedical engineering. Beyond direct mentorship, the project hosted workshops, lectures, and international collaborations, expanding public awareness and knowledge-sharing in robotic ultrasound technology.\r\n\n\nTechnology Transfer and Industry Collaborations. The technological advancements developed in this research have spurred multiple industry partnerships. Companies such as Clear Guide Medical, Intuitive Surgical, Kitware, and Analog Devices Inc. have collaborated to explore commercialization pathways.\r\n\n\nSocietal Impact: Expanding Access to Affordable Medical Imaging. Through the development of cost-effective, portable ultrasound solutions, this project has expanded access to high-quality imaging technologies. Additionally, advancements in photoacoustic imaging have contributed to non-invasive cancer detection techniques. Further work in retinal stimulation research has opened new possibilities for vision restoration using photoacoustic neural stimulation, with the potential to transform treatments for blindness and neural disorders\r\n\n\n\t\t\t\t\tLast Modified: 02/11/2025\n\n\t\t\t\t\tSubmitted by: EmadMBoctor\n"
 }
}