{
 "awd_id": "1734068",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative research: role of the motor system in phonological and phonetic processing",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 336640.0,
 "awd_amount": 336640.0,
 "awd_min_amd_letter_date": "2017-06-13",
 "awd_max_amd_letter_date": "2019-02-25",
 "awd_abstract_narration": "Across the world's languages, certain sound combinations occur more frequently than others.  However, the basis of these regularities is unknown. Some researchers have suggested that combinations such as \"lbog\" are rare because they require more complex articulatory gestures than combinations like  \"blog.\"  Another possibility is that combinations such as \"lbog\" tend to be avoided because they violate much more abstract linguistic constraints on allowable syllable structures. The investigators will evaluate these possibilities by examining the role of the articulatory motor system in speech perception using both noninvasive brain stimulation and behavioral methods.  Clarifying the relative contributions of speech motor processes and linguistic knowledge is critical to the diagnosis and treatment of speech language disorders, to first- and second-language acquisition, and to reading. \r\n\r\nThis research explores the role of embodiment and abstraction in speech perception. It proposes that speech is represented at multiple levels (embodied phonetics and abstract phonological rules) with different susceptibility to motor simulation, depending on (a) the level of analysis and (b) a speaker's linguistic experience. The proposed experiments test this hypothesis by combining brain stimulation and behavioral experiments. Using MRI-guided Transcranial Magnetic Stimulation (TMS), the research team will disrupt activity in brain regions linked to motor action (the cortical representation of the left orbicularis oris muscle in BA4) and brain regions linked to combinatorial phonological operations (left pars triangularis, PTr, BA 45), and assess the impact on two tasks that rely differentially on phonetic processing or the putatively abstract phonological computation of syllable structure. While it is unlikely that either task or brain region is selective to a single level of analysis, these experiments gauge whether they differ in their degree of participation. If phonetic categorization requires motor simulation, then disruption of BA4 should affect phonetic categorization more than it affects the computation of syllable structure. Alternatively, if the computation of syllable structure relies on disembodied processes effected by the PTr, then the disruption of BA45 should produce a stronger effect on syllable structure than on phonetic categorization. Projects 1 and 2 examine these predictions with speakers of English and Russian (languages that contrast in their syllabic inventory). The group comparison evaluates experience-dependent plasticity or uniformity in the engagement of the motor system across tasks. Projects 3 and 4 suppress articulation mechanically. If the greater contribution of BA4 to phonetic categorization reflects its role in motor simulation, then results from disruption of the orbicularis oris muscle by TMS and mechanical suppression  should converge.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Alvaro",
   "pi_last_name": "Pascual-Leone",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alvaro Pascual-Leone",
   "pi_email_addr": "apleone@bidmc.harvard.edu",
   "nsf_id": "000691876",
   "pi_start_date": "2017-06-13",
   "pi_end_date": "2019-02-25"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Fried",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Peter J Fried",
   "pi_email_addr": "pfried@bidmc.harvard.edu",
   "nsf_id": "000717089",
   "pi_start_date": "2019-02-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Albert",
   "pi_last_name": "Galaburda",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Albert M Galaburda",
   "pi_email_addr": "",
   "nsf_id": "000161810",
   "pi_start_date": "2017-06-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Alvaro",
   "pi_last_name": "Pascual-Leone",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alvaro Pascual-Leone",
   "pi_email_addr": "apleone@bidmc.harvard.edu",
   "nsf_id": "000691876",
   "pi_start_date": "2019-02-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Beth Israel Deaconess Medical Center",
  "inst_street_address": "330 BROOKLINE AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6176671803",
  "inst_zip_code": "022155400",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "BETH ISRAEL DEACONESS MEDICAL CENTER, INC.",
  "org_prnt_uei_num": "XZ1GSK7SH5D5",
  "org_uei_num": "C1CPANL3EWK4"
 },
 "perf_inst": {
  "perf_inst_name": "Beth Israel Deaconess Medical Center",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "022155491",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 336640.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>What is the basis of the human capacity for language? For example, why is it that English speakers&nbsp;<em>blog</em>, but not&nbsp;<em>lbog</em>? Laypeople often believe that the answer relies in talking:&nbsp;<em>blog&nbsp;</em>is easy to articulate, whereas&nbsp;<em>lbog&nbsp;</em>isn?t.</p>\n<p>Research in linguistics, however, suggests a different answer. In this view, the brain of every English speaker includes a set of abstract rules that are tacit?they operate entirely ?under the hood?, even in young children and infants. Those rules ban structures like&nbsp;<em>lbog</em>. So, in this second view,&nbsp;<em>lbog&nbsp;</em>sounds ?bad? because it violates abstract rules of language.&nbsp;</p>\n<p>So, who is right?is&nbsp;<em>lbog&nbsp;</em>?bad? because it?s hard on talking, or because of abstract rules?&nbsp;</p>\n<p>Scientist have been debating this question. This debate has been hard to settle because other results suggest that hearing speech&nbsp;<em>does</em>&nbsp;in fact require tacit ?talking?.&nbsp;</p>\n<p>For example, there is evidence that merely hearing&nbsp;<em>ba&nbsp;</em>activates the motor area of the brain that controls the lips (which are used to produce the&nbsp;<em>b&nbsp;</em>sound), whereas hearing&nbsp;<em>da&nbsp;</em>activates the brain area that controls the tongue (which controls the&nbsp;<em>d</em>&nbsp;sound).&nbsp;&nbsp;So ?tacit talking? clearly plays a role in hearing speech.</p>\n<p>Still, these results don?t quite solve the puzzle. Past findings have only shown that ?tacit talking? plays a role when we perceive individual sounds (such as&nbsp;<em>b</em>,&nbsp;<em>d</em>), whereas the contrast between&nbsp;<em>blog/lbog</em>&nbsp;concerns the&nbsp;<strong><em>combination</em></strong>&nbsp;of different sounds to form syllables. And what?s true of individual sounds may not necessarily ?scale up? to sound-combinations. &nbsp;</p>\n<p>So, what is the role of ?talking? in perceiving speech: Do we rely on ?tacit talking? (that is, action) across the board?in identifying individual sounds&nbsp;<em>and&nbsp;</em>in grasping their combinations? Or does our ability to grasp sound-combinations invoke knowledge of abstract rules?&nbsp;</p>\n<p>To find out, this NSF-funded research examined the role of ?tacit talking? in two distinct levels of speech perception: (a) the identification of individual sounds (e.g.,&nbsp;<em>b/p</em>); and (b) grasping the combination of speech sounds (e.g.,&nbsp;<em>blog/lbog</em>).&nbsp;</p>\n<p>To examine the role of ?talking?, we disrupted the articulatory motor system in two distinct ways. One set of experiments had people engage their lips or tongues, and in so doing, prevented them from moving these articulators. Another set of experiments stimulated the brain motor system that controls the lips using a technique known as&nbsp;<a href=\"https://en.wikipedia.org/wiki/Transcranial_magnetic_stimulation\">Transcranial Magnetic Stimulation</a>&nbsp;(TMS).&nbsp;</p>\n<p>When we examined individual speech sounds, like&nbsp;<em>b</em>&nbsp;or&nbsp;<em>d</em>&nbsp;?talking? played a role. Consequently, when motor activity was disrupted, speech perception was altered in specific ways. For example, stimulating the lips specifically changed the perception of&nbsp;<em>b</em>&nbsp;(a sound produced by the lips) more than&nbsp;<em>d</em>&nbsp;(a sound produced by the tongue). All this is in line with previous research.</p>\n<p>Interestingly, when participants attempted to grasp sound combinations?that is, to contrast syllables like&nbsp;<em>blog&nbsp;</em>and&nbsp;<em>lbog</em>, here, perception was relatively unaffected by the stimulation of the articulatory motor system. Instead, we found that sound-combination relies on Broca?s area?one of the main language hubs in the brain.</p>\n<p>Altogether, then, then the results of this project offer several major conclusions.&nbsp;&nbsp;First, hearing individual speech sounds relies on talking. To determine whether you hear the sound&nbsp;<em>b</em>, your tacitly brain simulates what it would be to&nbsp;<em>say&nbsp;</em>this sound (using your lips). But when you grasp how sounds combine together to form syllables (like&nbsp;<em>blog</em>), here, you seem to invoke more abstract knowledge, possibly, knowledge of abstract rules. So, when your brain perceives speech, it relies on two different tricks (rather than one)?talking and abstract knowledge. Talking helps perceive individual sounds; abstract knowledge helps you grasp their combination.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/22/2022<br>\n\t\t\t\t\tModified by: Peter&nbsp;J&nbsp;Fried</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1734068/1734068_10492591_1671739875312_NSFFigureforProjectOutcomesReport2022-12-22--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1734068/1734068_10492591_1671739875312_NSFFigureforProjectOutcomesReport2022-12-22--rgov-800width.jpg\" title=\"Figure 1\"><img src=\"/por/images/Reports/POR/2022/1734068/1734068_10492591_1671739875312_NSFFigureforProjectOutcomesReport2022-12-22--rgov-66x44.jpg\" alt=\"Figure 1\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The two core ingredients of language. Panel A illustrates the aspects of speech perception: the categorization of individual speech sounds (e.g., did I hear d or g?) and the combination into syllables (e.g., as dog or god). Panel B illustrates how these two functions were gauged in our TMS studies.</div>\n<div class=\"imageCredit\">Iris Berent</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Peter&nbsp;J&nbsp;Fried</div>\n<div class=\"imageTitle\">Figure 1</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nWhat is the basis of the human capacity for language? For example, why is it that English speakers blog, but not lbog? Laypeople often believe that the answer relies in talking: blog is easy to articulate, whereas lbog isn?t.\n\nResearch in linguistics, however, suggests a different answer. In this view, the brain of every English speaker includes a set of abstract rules that are tacit?they operate entirely ?under the hood?, even in young children and infants. Those rules ban structures like lbog. So, in this second view, lbog sounds ?bad? because it violates abstract rules of language. \n\nSo, who is right?is lbog ?bad? because it?s hard on talking, or because of abstract rules? \n\nScientist have been debating this question. This debate has been hard to settle because other results suggest that hearing speech does in fact require tacit ?talking?. \n\nFor example, there is evidence that merely hearing ba activates the motor area of the brain that controls the lips (which are used to produce the b sound), whereas hearing da activates the brain area that controls the tongue (which controls the d sound).  So ?tacit talking? clearly plays a role in hearing speech.\n\nStill, these results don?t quite solve the puzzle. Past findings have only shown that ?tacit talking? plays a role when we perceive individual sounds (such as b, d), whereas the contrast between blog/lbog concerns the combination of different sounds to form syllables. And what?s true of individual sounds may not necessarily ?scale up? to sound-combinations.  \n\nSo, what is the role of ?talking? in perceiving speech: Do we rely on ?tacit talking? (that is, action) across the board?in identifying individual sounds and in grasping their combinations? Or does our ability to grasp sound-combinations invoke knowledge of abstract rules? \n\nTo find out, this NSF-funded research examined the role of ?tacit talking? in two distinct levels of speech perception: (a) the identification of individual sounds (e.g., b/p); and (b) grasping the combination of speech sounds (e.g., blog/lbog). \n\nTo examine the role of ?talking?, we disrupted the articulatory motor system in two distinct ways. One set of experiments had people engage their lips or tongues, and in so doing, prevented them from moving these articulators. Another set of experiments stimulated the brain motor system that controls the lips using a technique known as Transcranial Magnetic Stimulation (TMS). \n\nWhen we examined individual speech sounds, like b or d ?talking? played a role. Consequently, when motor activity was disrupted, speech perception was altered in specific ways. For example, stimulating the lips specifically changed the perception of b (a sound produced by the lips) more than d (a sound produced by the tongue). All this is in line with previous research.\n\nInterestingly, when participants attempted to grasp sound combinations?that is, to contrast syllables like blog and lbog, here, perception was relatively unaffected by the stimulation of the articulatory motor system. Instead, we found that sound-combination relies on Broca?s area?one of the main language hubs in the brain.\n\nAltogether, then, then the results of this project offer several major conclusions.  First, hearing individual speech sounds relies on talking. To determine whether you hear the sound b, your tacitly brain simulates what it would be to say this sound (using your lips). But when you grasp how sounds combine together to form syllables (like blog), here, you seem to invoke more abstract knowledge, possibly, knowledge of abstract rules. So, when your brain perceives speech, it relies on two different tricks (rather than one)?talking and abstract knowledge. Talking helps perceive individual sounds; abstract knowledge helps you grasp their combination. \n\n \n\n\t\t\t\t\tLast Modified: 12/22/2022\n\n\t\t\t\t\tSubmitted by: Peter J Fried"
 }
}