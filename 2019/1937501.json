{
 "awd_id": "1937501",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RTML: Large: Co-design of Hardware and Algorithms for Energy-efficient Robot Learning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 1000000.0,
 "awd_amount": 1000000.0,
 "awd_min_amd_letter_date": "2019-08-29",
 "awd_max_amd_letter_date": "2019-08-29",
 "awd_abstract_narration": "Miniature low-energy autonomous robotic vehicles, ranging from insect-size flyers to palm- size satellites, hold the potential for tremendous impact in a diverse set of industries, including consumer electronics, high-bandwidth communications, search and rescue operations, and space exploration, just to name a few. Next-generation low-energy computing hardware that will enable these applications must be adaptable, i.e., recognizing new environments on the fly, learning their characteristic features in real time, and adapting its computing strategy to minimize the energy consumption required for computing task. This project will help realize vehicles that are able to improve the accuracy of their perception and decision making algorithms, simply by experimenting with obtaining a diverse set of viewpoints of the environment and utilizing the knowledge of its motion to ground and improve its observation via machine learning. The project also seeks to develop new graduate and undergraduate courses at MIT, it will enable outreach for high school students, involve women and underrepresented groups, thus helping train the future US workforce. \r\n\r\nThis project will develop real-time robot learning algorithms and hardware focusing on three core areas. Firstly, the project will develop real-time continuous robot learning systems that improve performance of robot perception and decision making by rapid learning in new environments. Secondly, the project will develop real-time active robot learning systems to efficiently decide the balance between improving accuracy of perception and decision making algorithms and focusing on accomplishing the task at hand. Thirdly, the project will develop real-time adaptable robot learning systems for energy scalable perception and decision making, where the design allows for efficient accuracy-energy tradeoffs. The project will help develop new hardware and algorithms for real-time robot learning, by enabling new low-energy robotic systems. The project will also collaborate with a synergistic DARPA program for related hardware development.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sertac",
   "pi_last_name": "Karaman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sertac Karaman",
   "pi_email_addr": "sertac@MIT.EDU",
   "nsf_id": "000635500",
   "pi_start_date": "2019-08-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Vivienne",
   "pi_last_name": "Sze",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Vivienne Sze",
   "pi_email_addr": "sze@mit.edu",
   "nsf_id": "000667275",
   "pi_start_date": "2019-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "082Z",
   "pgm_ref_txt": "RTML-Real Time Machine Learning"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 1000000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-7b038e29-7fff-2f66-2573-eed7a5e798a6\">\n<p dir=\"ltr\"><span>Miniature low-energy autonomous robotic vehicles, ranging from insect-size flyers to palm- size satellites, hold the potential for tremendous impact in a diverse set of industries, including consumer electronics, high-bandwidth communications, search and rescue operations, and space exploration, just to name a few. Next-generation computing hardware for autonomous robotic vehicles must be adaptable, i.e., recognizing new environments on the fly, learning their characteristic features in real time, and adapting its computing strategy to minimize the energy consumption required for computing tasks. The major goal of this project is the co-design of algorithms and hardware for robot learning to rapidly adapt to new environments. Specifically, we envision vehicles that are able to improve the accuracy of their perception and decision making algorithms,simply by experimenting with obtaining a diverse set of viewpoints of the environment and utilizing the knowledge of its motion to ground and improve its observation via machine learning.&nbsp; To achieve this goal, in this project we explored three key directions: memory-efficient mapping using gaussians, efficient computing of uncertainty for monocular depth estimation using deep neural networks</span><span>, and model carbon footprint due to computing in autonomous vehicles.</span></p>\n<br />\n<p dir=\"ltr\"><span>Energy consumption of memory accesses dominates the compute energy in energy-constrained robots which require a compact 3D map of the environment to achieve autonomy. Recent mapping frameworks only focused on reducing the map size while incurring significant memory usage during map construction due to the multi-pass processing of each depth image. In this work, we present a memory-efficient continuous occupancy map, named GMMap, that accurately models the 3D environment using a Gaussian Mixture Model (GMM). Memory-efficient GMMap construction is enabled by the single-pass compression of depth images into local GMMs which are directly fused into a globally-consistent map. By extending Gaussian Mixture Regression to model unexplored regions, occupancy probability is directly computed from Gaussians. GMMap enables real-time 3D mapping on energy-constrained robots.&nbsp;</span></p>\n<br />\n<p dir=\"ltr\"><span>Deployment of deep neural networks (DNNs) for monocular depth estimation in safety-critical scenarios on resource-constrained platforms requires well-calibrated and efficient uncertainty estimates. However, many popular uncertainty estimation techniques, including state-of-the-art ensembles and popular sampling-based methods, require multiple inferences per input, making them difficult to deploy in latencyconstrained or energy-constrained scenarios. We propose a new algorithm, called Uncertainty from Motion (UfM), that requires only one inference per input. UfM exploits the temporal redundancy in video inputs by merging incrementally the per-pixel depth prediction and per-pixel aleatoric uncertainty prediction of points that are seen in multiple views in the video sequence. When UfM is applied to ensembles, we show that UfM can retain the uncertainty quality of ensembles at a fraction of the energy by running only a single ensemble member at each frame and fusing the uncertainty over the sequence of frames. In a set of representative experiments using FCDenseNet and eight indistribution and out-of-distribution video sequences, UfM offers comparable uncertainty quality to an ensemble of size 10 while consuming only 11.3% of the ensemble&rsquo;s energy and running 6.4&times; faster on a single Nvidia RTX 2080 Ti GPU, enabling near ensemble uncertainty quality for resource-constrained, real-time scenarios.</span></p>\n<br />\n<p dir=\"ltr\"><span>While much attention has been paid to data centers&rsquo; greenhouse gas emissions, less attention has been paid to autonomous vehicles&rsquo; (AVs) potential emissions. In this work, we introduce a framework to probabilistically model the emissions from computing onboard a global fleet of AVs and show that the emissions have the potential to make a non-negligible impact on global emissions, comparable to that of all data centers today. Based on current trends, a widespread AV adoption scenario where approximately 95% of all vehicles are autonomous requires computer power to be less than 1.2 kW for emissions from computing on AVs to be less than emissions from all data centers in 2018 in 90% of modeled scenarios. Anticipating a future scenario with high adoption of AVs, business-as-usual decarbonization, and workloads doubling every three years, hardware efficiency must double every 1.1 years for emissions in 2050 to equal 2018 data center emissions. The rate of increase in hardware efficiency needed in many scenarios to contain emissions is faster than the current rate. We discuss several avenues of future research unique to AVs to further analyze and potentially reduce the carbon footprint of AVs.</span><span>&nbsp;</span></p>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/11/2024<br>\nModified by: Sertac&nbsp;Karaman</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\nMiniature low-energy autonomous robotic vehicles, ranging from insect-size flyers to palm- size satellites, hold the potential for tremendous impact in a diverse set of industries, including consumer electronics, high-bandwidth communications, search and rescue operations, and space exploration, just to name a few. Next-generation computing hardware for autonomous robotic vehicles must be adaptable, i.e., recognizing new environments on the fly, learning their characteristic features in real time, and adapting its computing strategy to minimize the energy consumption required for computing tasks. The major goal of this project is the co-design of algorithms and hardware for robot learning to rapidly adapt to new environments. Specifically, we envision vehicles that are able to improve the accuracy of their perception and decision making algorithms,simply by experimenting with obtaining a diverse set of viewpoints of the environment and utilizing the knowledge of its motion to ground and improve its observation via machine learning. To achieve this goal, in this project we explored three key directions: memory-efficient mapping using gaussians, efficient computing of uncertainty for monocular depth estimation using deep neural networks, and model carbon footprint due to computing in autonomous vehicles.\n\n\n\n\nEnergy consumption of memory accesses dominates the compute energy in energy-constrained robots which require a compact 3D map of the environment to achieve autonomy. Recent mapping frameworks only focused on reducing the map size while incurring significant memory usage during map construction due to the multi-pass processing of each depth image. In this work, we present a memory-efficient continuous occupancy map, named GMMap, that accurately models the 3D environment using a Gaussian Mixture Model (GMM). Memory-efficient GMMap construction is enabled by the single-pass compression of depth images into local GMMs which are directly fused into a globally-consistent map. By extending Gaussian Mixture Regression to model unexplored regions, occupancy probability is directly computed from Gaussians. GMMap enables real-time 3D mapping on energy-constrained robots.\n\n\n\n\nDeployment of deep neural networks (DNNs) for monocular depth estimation in safety-critical scenarios on resource-constrained platforms requires well-calibrated and efficient uncertainty estimates. However, many popular uncertainty estimation techniques, including state-of-the-art ensembles and popular sampling-based methods, require multiple inferences per input, making them difficult to deploy in latencyconstrained or energy-constrained scenarios. We propose a new algorithm, called Uncertainty from Motion (UfM), that requires only one inference per input. UfM exploits the temporal redundancy in video inputs by merging incrementally the per-pixel depth prediction and per-pixel aleatoric uncertainty prediction of points that are seen in multiple views in the video sequence. When UfM is applied to ensembles, we show that UfM can retain the uncertainty quality of ensembles at a fraction of the energy by running only a single ensemble member at each frame and fusing the uncertainty over the sequence of frames. In a set of representative experiments using FCDenseNet and eight indistribution and out-of-distribution video sequences, UfM offers comparable uncertainty quality to an ensemble of size 10 while consuming only 11.3% of the ensembles energy and running 6.4 faster on a single Nvidia RTX 2080 Ti GPU, enabling near ensemble uncertainty quality for resource-constrained, real-time scenarios.\n\n\n\n\nWhile much attention has been paid to data centers greenhouse gas emissions, less attention has been paid to autonomous vehicles (AVs) potential emissions. In this work, we introduce a framework to probabilistically model the emissions from computing onboard a global fleet of AVs and show that the emissions have the potential to make a non-negligible impact on global emissions, comparable to that of all data centers today. Based on current trends, a widespread AV adoption scenario where approximately 95% of all vehicles are autonomous requires computer power to be less than 1.2 kW for emissions from computing on AVs to be less than emissions from all data centers in 2018 in 90% of modeled scenarios. Anticipating a future scenario with high adoption of AVs, business-as-usual decarbonization, and workloads doubling every three years, hardware efficiency must double every 1.1 years for emissions in 2050 to equal 2018 data center emissions. The rate of increase in hardware efficiency needed in many scenarios to contain emissions is faster than the current rate. We discuss several avenues of future research unique to AVs to further analyze and potentially reduce the carbon footprint of AVs.\n\n\n\n\t\t\t\t\tLast Modified: 03/11/2024\n\n\t\t\t\t\tSubmitted by: SertacKaraman\n"
 }
}