{
 "awd_id": "1853014",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase II:  Automatically Generating Domain Specific Structured Ontologies for Video",
 "cfda_num": "47.041, 47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2019-06-01",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 749926.0,
 "awd_amount": 1362960.0,
 "awd_min_amd_letter_date": "2019-05-20",
 "awd_max_amd_letter_date": "2021-11-10",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project will be to enable more specific and granular search through a large array of different types of video content, unlocking the information within the world's video archives and live stream video content. Countless hours and productivity in corporations are lost when employees search for a small, specific video clip within a larger video asset to meet their business needs, costing institutions valuable time and money.  Through the enhanced discoverability within videos that the results of this project will provide, many industries such as education, media, online gaming, and others will benefit from enhanced efficiencies in publishing and video search results better reflecting user intent.  The benefits of this project are not confined to enterprises.  Society at large can benefit from a greater accessibility of video within archives that were previously unavailable, which can be used to create a society better-informed on world events and develop education and skills as the world's video archives that were once undiscoverable by the general public are made accessible.  \r\n\r\nThis Small Business Innovation Research (SBIR) Phase II project develops a video understanding framework and knowledge graph to better enable video search and discovery for enterprise video archives and live stream video. Leveraging multimodal data and domain specific structured ontologies provided by content creators and data maintainers, this project proposes to develop four new machine learning and computer vision technologies.  Firstly, a webly supervised content-based retrieval system for video will be created in order to build classifiers without being provided annotated training data, effectively solving the video classification data cold start problem. Second, the project will build a multimodal ontology mapping system to enable mapping semantic concepts external and novel to our current technologies. Furthermore, to provide the ability to understand and formalize object relationships temporally, an Allen interval algebra module for video will be developed; combining it with knowledge relational learning in order to learn temporal relationships between objects that comprise its knowledge graph. Finally, to qualify the action relationships between people/objects in the developed knowledge graph, a holistic video modeling approach will be developed and applied to action/event recognition and other tasks, such as captioning or titling, expanding a key recognition capability to complete the knowledge graph.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Joe",
   "pi_last_name": "Ellis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Joe Ellis",
   "pi_email_addr": "joe.ellis@vidrovr.com",
   "nsf_id": "000725404",
   "pi_start_date": "2019-05-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Vidrovr Inc.",
  "inst_street_address": "745 5TH AVE STE 500",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "4156522388",
  "inst_zip_code": "101510099",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NY12",
  "org_lgl_bus_name": "VIDROVR INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "J7MHSLJPEDJ7"
 },
 "perf_inst": {
  "perf_inst_name": "Vidrovr Inc.",
  "perf_str_addr": "30 West 26th Street, 7th Floor",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100102072",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NY12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537300",
   "pgm_ele_name": "SBIR Phase II"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "165E",
   "pgm_ref_txt": "SBIR Phase IIB"
  },
  {
   "pgm_ref_code": "169E",
   "pgm_ref_txt": "SBIR Tech Enhan Partner (TECP)"
  },
  {
   "pgm_ref_code": "5373",
   "pgm_ref_txt": "SMALL BUSINESS PHASE II"
  },
  {
   "pgm_ref_code": "8032",
   "pgm_ref_txt": "Software Services and Applications"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 749926.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 149984.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 463050.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-52eb1dee-7fff-65ca-2566-6e173655b26c\"> </span></p>\n<p dir=\"ltr\"><span>During the NSF SBIR Phase II project, Vidrovr Inc. improved the </span><em>Vidrovr Platform and Media Processing Pipeline (MPP)</em><span>, a system for indexing and analyzing massive amounts of video content in a multimodal way to provide the most in-depth and granular information extracted from video to meet business needs.&nbsp; During this project, Vidrovr was able to increase the speed at which process videos by an order of magnitude to be able to analyze videos in near real-time, and extended their capability and throughput of video to analyze 1000?s of hours of video a week, from all over the world in multiple languages.&nbsp; With the help of the NSF Award, not only was the company able to improve throughput and speed, but also increase accuracy.&nbsp; Today, many of the world?s leading broadcasters and media companies rely on Vidrovr to provide detailed time-aligned rundowns of their live television and social media video feeds, which in turn allow them to more efficiently monetize and distribute their programming.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>Since the inception of Vidrovr, the company has processed over 25 Billion video frames, and monitored over 1,000,000 hours of video content, which is a major increase over the 5,200 hours processed at the end of the NSF Phase I Award.&nbsp; During this award timeframe, Vidrovr has grown revenue by 800%.&nbsp;&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>As the amount of video has increased dramatically during the reporting period of this NSF Phase II award, it?s become clear that extracting information from video will be imperative for us to better understand and organize tomorrow?s information.&nbsp; Vidrovr?s Platform and MPP are now used to make sense of millions of hours of video content, helping to provide a way for businesses and enterprises to use the information in video to make the most efficient decisions and enable new products.&nbsp;&nbsp;</span></p>\n<p><br /><br /></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/29/2023<br>\n\t\t\t\t\tModified by: Joe&nbsp;Ellis</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1853014/1853014_10606165_1693257376075_vidrovr_logo--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1853014/1853014_10606165_1693257376075_vidrovr_logo--rgov-800width.jpg\" title=\"Vidrovr Logo\"><img src=\"/por/images/Reports/POR/2023/1853014/1853014_10606165_1693257376075_vidrovr_logo--rgov-66x44.jpg\" alt=\"Vidrovr Logo\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Vidrovr Logo</div>\n<div class=\"imageCredit\">Vidrovr Inc</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Joe&nbsp;Ellis</div>\n<div class=\"imageTitle\">Vidrovr Logo</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nDuring the NSF SBIR Phase II project, Vidrovr Inc. improved the Vidrovr Platform and Media Processing Pipeline (MPP), a system for indexing and analyzing massive amounts of video content in a multimodal way to provide the most in-depth and granular information extracted from video to meet business needs.  During this project, Vidrovr was able to increase the speed at which process videos by an order of magnitude to be able to analyze videos in near real-time, and extended their capability and throughput of video to analyze 1000?s of hours of video a week, from all over the world in multiple languages.  With the help of the NSF Award, not only was the company able to improve throughput and speed, but also increase accuracy.  Today, many of the world?s leading broadcasters and media companies rely on Vidrovr to provide detailed time-aligned rundowns of their live television and social media video feeds, which in turn allow them to more efficiently monetize and distribute their programming. \n\n \nSince the inception of Vidrovr, the company has processed over 25 Billion video frames, and monitored over 1,000,000 hours of video content, which is a major increase over the 5,200 hours processed at the end of the NSF Phase I Award.  During this award timeframe, Vidrovr has grown revenue by 800%.  \n\n \nAs the amount of video has increased dramatically during the reporting period of this NSF Phase II award, it?s become clear that extracting information from video will be imperative for us to better understand and organize tomorrow?s information.  Vidrovr?s Platform and MPP are now used to make sense of millions of hours of video content, helping to provide a way for businesses and enterprises to use the information in video to make the most efficient decisions and enable new products.  \n\n\n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 08/29/2023\n\n\t\t\t\t\tSubmitted by: Joe Ellis"
 }
}