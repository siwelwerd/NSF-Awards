{
 "awd_id": "1846431",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Towards the Design of Models and Systems for Efficient Prediction",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2019-06-15",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 450648.0,
 "awd_amount": 450648.0,
 "awd_min_amd_letter_date": "2019-06-11",
 "awd_max_amd_letter_date": "2023-07-26",
 "awd_abstract_narration": "Advances in artificial intelligence (AI) are enabling new services and applications including voice-enabled digital assistants, machine translation, personalized medicine, fraud detection, and autonomous vehicles.  This new class of intelligent services and applications are critical to the economy and transforming century-old industries ranging from commerce and banking to transportation and healthcare.  \r\n\r\nIn this research, the problem of deploying advanced machine learning models and prediction pipelines is studied.  A holistic approach is taken for the design of the computer systems needed to render predictions and the models and algorithms that they run.   Models are developed that can scale their complexity to avoid overthinking and thereby reduce the energy required to make predictions along with algorithms and systems to automatically configure complex prediction pipelines to simplify model deployment while also improving efficiency and reliability.  This research will also produce and promote open-source software systems that can be used across industries.  \r\n\r\nBuilding these new AI-powered applications will also require new skills and education.  A key part of this proposal is open-source course development.  A new Data Science major is being designed and this grant will fund new open modules in the data science courses.  These courses are taken by students in engineering as well as across the entire campus and provide the fundamental skills needed to understand how machine learning can be used to solve real-world problems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Joseph",
   "pi_last_name": "Gonzalez",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Joseph Gonzalez",
   "pi_email_addr": "jegonzal@eecs.berkeley.edu",
   "nsf_id": "000743048",
   "pi_start_date": "2019-06-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "773 Soda Hall",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947201770",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0123",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 74399.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 79467.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 92554.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 97263.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 106965.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>\n<div>\n<div>\n<div>\n<div><span>This NSF CAREER Award helped define the state-of-the-art in how we deploy machine learning and contemporary AI across the cloud and the edge. This project studied the design of systems and models that enable efficient inference and prediction serving.&nbsp;</span></div>\n<br />\n<div><span>This project made significant contributions to neural network design. It introduced new test-time dynamic computation techniques like IDK prediction cascades and Skip Networks that reduce the cost of rendering predictions by only using the full network when necessary. This project studied how to optimize models for GPU hardware like Shifted convolutions and FBNet.&nbsp;</span></div>\n<br />\n<div><span>This NSF CAREER Award studied the fundamental tradeoff between latency and inference when serving predictions. With the Clipper project, we developed the first general-purpose prediction serving platform. This platform introduced new techniques like dynamic batching and online model personalization and demonstrated that these techniques can be lifted above the underlying machine learning frameworks. We then extended this platform to serve prediction pipelines on heterogeneous hardware (InferLine). We open-sourced this project and it ultimately became the Ray Serve prediction serving system.</span></div>\n<br />\n<div><span>This NSF CAREER Award explored how to optimize tensor programs (Ansor) and distributed inference systems (Alpa Serve) to improve prediction efficiency and leverage statistical multiplexing to reduce serving costs. This research was a precursor to the incredibly successful vLLM project.&nbsp;</span></div>\n<br />\n<div><span>With the explosion in large language models (LLMs), we quickly developed a new serving platform (vLLM). The vLLM platform pioneered the PagedAttention memory management technique to significantly improve throughput and reduce the cost of serving LLMs. The PagedAttention technique is now standard on all LLM serving systems and the vLLM project is now the industry standard approach to serving open-source LLMs. If you use an open-source model on most major clouds you are using vLLM. The vLLM project is so successful that most major hardware vendors and model developers work with us to ensure compatibility with vLLM.&nbsp;</span></div>\n<br />\n<div><span>This award helped support pioneering research in software systems for autonomous driving and studied how to maximize safety when serving on-vehicle prediction pipelines. Surprisingly, there had been very little research studying the software used to run prediction pipelines on vehicles. Through this award, we demonstrated the need to manage time dynamically and showed that the prior approach of using hard real-time systems is actually less safe. We then extended this work to explore how the cloud can be used to augment driving capabilities even with limited network connectivity.&nbsp;</span></div>\n<br />\n<div><span>Towards the end of the award period, we used the technology developed as part of this research to launch the ChatBot Arena which is now one of the most widely used platforms to evaluate commercial and open-source AI. We have used this platform to study how to improve the efficiency of AI systems and also gain insights into how people use LLM technology.&nbsp;</span></div>\n<br />\n<div><span>This award helped support the development of the undergraduate data science program and build the largest data science class at UC Berkeley (Data100).&nbsp; Finally, students involved in this research have launched several startups that have raised 10s of millions of dollars to help further commercialize this research.</span></div>\n<br /><br /></div>\n</div>\n</div>\n</p><br>\n<p>\n Last Modified: 11/05/2024<br>\nModified by: Joseph&nbsp;Gonzalez</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\n\nThis NSF CAREER Award helped define the state-of-the-art in how we deploy machine learning and contemporary AI across the cloud and the edge. This project studied the design of systems and models that enable efficient inference and prediction serving.\n\n\nThis project made significant contributions to neural network design. It introduced new test-time dynamic computation techniques like IDK prediction cascades and Skip Networks that reduce the cost of rendering predictions by only using the full network when necessary. This project studied how to optimize models for GPU hardware like Shifted convolutions and FBNet.\n\n\nThis NSF CAREER Award studied the fundamental tradeoff between latency and inference when serving predictions. With the Clipper project, we developed the first general-purpose prediction serving platform. This platform introduced new techniques like dynamic batching and online model personalization and demonstrated that these techniques can be lifted above the underlying machine learning frameworks. We then extended this platform to serve prediction pipelines on heterogeneous hardware (InferLine). We open-sourced this project and it ultimately became the Ray Serve prediction serving system.\n\n\nThis NSF CAREER Award explored how to optimize tensor programs (Ansor) and distributed inference systems (Alpa Serve) to improve prediction efficiency and leverage statistical multiplexing to reduce serving costs. This research was a precursor to the incredibly successful vLLM project.\n\n\nWith the explosion in large language models (LLMs), we quickly developed a new serving platform (vLLM). The vLLM platform pioneered the PagedAttention memory management technique to significantly improve throughput and reduce the cost of serving LLMs. The PagedAttention technique is now standard on all LLM serving systems and the vLLM project is now the industry standard approach to serving open-source LLMs. If you use an open-source model on most major clouds you are using vLLM. The vLLM project is so successful that most major hardware vendors and model developers work with us to ensure compatibility with vLLM.\n\n\nThis award helped support pioneering research in software systems for autonomous driving and studied how to maximize safety when serving on-vehicle prediction pipelines. Surprisingly, there had been very little research studying the software used to run prediction pipelines on vehicles. Through this award, we demonstrated the need to manage time dynamically and showed that the prior approach of using hard real-time systems is actually less safe. We then extended this work to explore how the cloud can be used to augment driving capabilities even with limited network connectivity.\n\n\nTowards the end of the award period, we used the technology developed as part of this research to launch the ChatBot Arena which is now one of the most widely used platforms to evaluate commercial and open-source AI. We have used this platform to study how to improve the efficiency of AI systems and also gain insights into how people use LLM technology.\n\n\nThis award helped support the development of the undergraduate data science program and build the largest data science class at UC Berkeley (Data100). Finally, students involved in this research have launched several startups that have raised 10s of millions of dollars to help further commercialize this research.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 11/05/2024\n\n\t\t\t\t\tSubmitted by: JosephGonzalez\n"
 }
}