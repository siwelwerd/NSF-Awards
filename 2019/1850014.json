{
 "awd_id": "1850014",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: SaTC: Moderating Effects of Automation on Information Transmission in Social Forums",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2019-06-01",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 174910.0,
 "awd_amount": 190770.0,
 "awd_min_amd_letter_date": "2019-03-04",
 "awd_max_amd_letter_date": "2020-05-28",
 "awd_abstract_narration": "This project aims to develop and deploy an information veracity evaluation system to support online discourse moderation and human comprehension of online information.  Understanding information's nature can help users to identify essential products and services, and even potentially help to inform democratic participation.  The project will help individual users navigate an environment where the views of their online peers may be difficult to interpret, or where it may not be clear whether other users are human or covert social bots (e.g., for social engineering to obtain personal information).  The research project develops capacities for identifying social bots and evaluating their stances towards claims on forums to underpin a system that will provide automated veracity evaluation of web content and analysis to support forum moderators.  These projects will shed light on the use of social bots at affecting reader perceptions of information, bringing awareness to dangers of automation in the infosphere and ultimately, support for vigilance and anticipation of automation attacks. \r\n\r\nThis project aims to produce an open-source, automated social information veracity evaluation system that can support moderation of, and ultimately, user navigation in online discourse environments.  This system will be developed with auxiliary foci on detecting social bots and evaluating social support, making it capable of filtering out covert autonomous agents while assessing their roles in the support or denial of content claims.  A veracity-annotated dataset of unprecedented size that integrates online content and associated reader commentary with social bot annotations will be extended and enriched with reader support annotations.  These will be used to develop machine learning tools that can indicate 1) users' authenticity as human commenters and 2) their stances towards claims, in order to 3) support the evaluation of their discussed content's veracity.  A platform and server-to-server applications will be built to support implementation for forum moderation, providing moderators live analytics, alerts, and an interactive visual dashboard, in addition to a public display of summarized results.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jake",
   "pi_last_name": "Williams",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Jake R Williams",
   "pi_email_addr": "jw3477@drexel.edu",
   "nsf_id": "000745347",
   "pi_start_date": "2019-03-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Drexel University",
  "inst_street_address": "3141 CHESTNUT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158956342",
  "inst_zip_code": "191042875",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "DREXEL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "XF3XM9642N96"
 },
 "perf_inst": {
  "perf_inst_name": "Drexel University",
  "perf_str_addr": "30 N. 33rd Street",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191042875",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "026Y00",
   "pgm_ele_name": "CRII CISE Research Initiation"
  },
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "065Z",
   "pgm_ref_txt": "Human factors for security research"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 174910.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 15860.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This CRII project's focus on developing forum moderation technologies has produced outcomes that have the strong potential to immediately impact how AI-based technologies will be engineered, which once fully adopted will have large impacts to the experience of the content consumers and producers of social and news media platforms. <br /><br />In early phases, the project 1) built a potent data filtration system based around the journalistic practice of social media embedding in the news. A study of these data 2) elucidated how journalist-driven social media sourcing in the news creates a content clustering signal that can be extended to a stream of news articles and provide ranking information. This ultimately led to the final design of a news content navigation system capable of aggregating and ranking articles within stories, and intersecting them with the social conversations that journalists connect to them via their discovery and reporting of newsworthy social media content. This new navigation system will ultimately be connected to the project's other early product, 3) a Python module for the navigation and analysis of threaded conversational content (Pyconversations).<br /><br />With its data discoveries and backend defining the project's information environment and the subjects of its analysis, an REU-driven supplement then catalyzed the CRII's investigation into developing a 4) generalized a machine learning (ML) task for the generation of predictive moderation features. This will be referred to as character-reference prediction, and will train AIs to label entities in text found to be 'named' both positively and negatively by other social authors, i.e., name-calling events. These features are intended to explore how users can be supported, and how moderation can be affected by the illustration of 'ad hominem' logical fallacies in argumentative environments. <br /><br />For prediction, the project's complex features required developing natural language processing (NLP)-based tools, which to the extent possible must be free from the bias of external pre-training data. Thus, for prediction in the news-social media ecosystem 5) the project developed a hyper-efficient 'deep' NLP framework based on a novel (gradient descent-free) optimization strategy. Developing this strategy?whose software framework is being released after the project's close?has resolved the CRII's final design around cost-effective ML technology whose optimization allows the localizable training of moderation tools, i.e., based strictly on internal data/subjects of prediction data, thus free from unintended/external biases. This final outcome will likewise have downstream effects within commercialization and on access to NLP technologies, particularly for low-resource communities (since fewer resources are needed). Once released, the main point of distribution for this software will be here: https://github.com/jakerylandwilliams/IaMaN/<br /><br />The performance of this project's work directly defined and supported two undergraduate theses in computer science and physics (respectively), as well as one doctoral dissertation in information science. Numerous other training opportunities were provided both directly through other research corollary to the project's planned activities, as well as through instruction focused on learning opportunities afforded from materials derived from project research outcomes.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/29/2022<br>\n\t\t\t\t\tModified by: Jake&nbsp;R&nbsp;Williams</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis CRII project's focus on developing forum moderation technologies has produced outcomes that have the strong potential to immediately impact how AI-based technologies will be engineered, which once fully adopted will have large impacts to the experience of the content consumers and producers of social and news media platforms. \n\nIn early phases, the project 1) built a potent data filtration system based around the journalistic practice of social media embedding in the news. A study of these data 2) elucidated how journalist-driven social media sourcing in the news creates a content clustering signal that can be extended to a stream of news articles and provide ranking information. This ultimately led to the final design of a news content navigation system capable of aggregating and ranking articles within stories, and intersecting them with the social conversations that journalists connect to them via their discovery and reporting of newsworthy social media content. This new navigation system will ultimately be connected to the project's other early product, 3) a Python module for the navigation and analysis of threaded conversational content (Pyconversations).\n\nWith its data discoveries and backend defining the project's information environment and the subjects of its analysis, an REU-driven supplement then catalyzed the CRII's investigation into developing a 4) generalized a machine learning (ML) task for the generation of predictive moderation features. This will be referred to as character-reference prediction, and will train AIs to label entities in text found to be 'named' both positively and negatively by other social authors, i.e., name-calling events. These features are intended to explore how users can be supported, and how moderation can be affected by the illustration of 'ad hominem' logical fallacies in argumentative environments. \n\nFor prediction, the project's complex features required developing natural language processing (NLP)-based tools, which to the extent possible must be free from the bias of external pre-training data. Thus, for prediction in the news-social media ecosystem 5) the project developed a hyper-efficient 'deep' NLP framework based on a novel (gradient descent-free) optimization strategy. Developing this strategy?whose software framework is being released after the project's close?has resolved the CRII's final design around cost-effective ML technology whose optimization allows the localizable training of moderation tools, i.e., based strictly on internal data/subjects of prediction data, thus free from unintended/external biases. This final outcome will likewise have downstream effects within commercialization and on access to NLP technologies, particularly for low-resource communities (since fewer resources are needed). Once released, the main point of distribution for this software will be here: https://github.com/jakerylandwilliams/IaMaN/\n\nThe performance of this project's work directly defined and supported two undergraduate theses in computer science and physics (respectively), as well as one doctoral dissertation in information science. Numerous other training opportunities were provided both directly through other research corollary to the project's planned activities, as well as through instruction focused on learning opportunities afforded from materials derived from project research outcomes.\n\n\t\t\t\t\tLast Modified: 09/29/2022\n\n\t\t\t\t\tSubmitted by: Jake R Williams"
 }
}