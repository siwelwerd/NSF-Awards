{
 "awd_id": "1925371",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: INT: COLLAB: Muscle Ultrasound Sensing for Intuitive Control of Robotic Leg Prostheses",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032922633",
 "po_email": "aleoness@nsf.gov",
 "po_sign_block_name": "Alex Leonessa",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 600987.0,
 "awd_amount": 600987.0,
 "awd_min_amd_letter_date": "2019-08-20",
 "awd_max_amd_letter_date": "2019-08-20",
 "awd_abstract_narration": "The research objective of this project is to enable volitional control over lower-limb prostheses through the integration of sonomyographic sensing - the ultrasound imaging of amputated (i.e., residual) limb muscle morphology - to control the Utah Lightweight Leg. This powered prosthetic leg is comprised of powered ankle and knee modules, and is roughly half the weight of contemporary technologies. The project team will use sonomyographic sensors in combination with mechanical sensors to infer the user's intent in anticipation of ambulation mode or joint motion, for example locomotor transitions from walking over level ground to ramps or stairs. The team will then perform human subject experiments comparing the ability of participants with transfemoral amputation to ambulate with and without various sonomyographic control algorithms enabled. If successful, the project will have positive impact on national health and welfare by improving the lives of individuals with amputation in terms of their independence and ambulation abilities, and by mitigating undesirable secondary effects of amputation such as a fear of falling and long-term joint health. Additional broader impacts of the work include enhanced undergraduate and graduate research experiences for veterans and underrepresented minorities, as well as outreach activities to K-12 students.\r\n\r\nRobotic leg prostheses can overcome the limitations of conventional passive prostheses by generating net-positive energy during the gait cycle and actively regulating joint motion. However, scientific barriers must be overcome for robotic leg prosthesis to safely and effectively operate in real-world settings. The goal of this project is to fill the knowledge gap regarding the integration of the user's volition in the control of lightweight robotic ankle and knee prostheses. The research team will measure muscle contractions of the user's residual limb using wearable ultrasound probes. Specific objectives of this project are: 1) to identify optimal design guidelines to integrate sonomyographic sensing into state-of-the-art powered knee-ankle prostheses; 2) to determine specific algorithms that best anticipate the user's intention to perform different ambulation modes in a timely, accurate, and reliable manner; and 3) to understand how to optimally combine information gathered from sonomyography and mechanical sensors to control a robotic leg prosthesis within specific ambulation modes. Algorithms will be implemented on a lightweight robotic ankle and knee prosthesis to evaluate the hypothesis that providing users with anticipatory volitional control will lead to enhanced performance in complex and uncertain environments, thereby fostering seamless integration of robotic prostheses with human users.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tommaso",
   "pi_last_name": "Lenzi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tommaso Lenzi",
   "pi_email_addr": "t.lenzi@utah.edu",
   "nsf_id": "000784161",
   "pi_start_date": "2019-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "1550 MEK (1495 E 100 S.), office",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841120030",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8013",
   "pgm_ref_txt": "High Risk/Reward Innovative Research"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 600987.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project improved <strong>robotic prosthetic legs </strong>by allowing users to control them more naturally using signals from their own muscles and nerves. Our work focused on people with above-knee amputations, helping them move more smoothly and intuitively improving their mobilty and quality of life.</p>\r\n<p>To achieve this, we created a new type of controller that blends the user&rsquo;s own movement intentions with robotic assistance. This controller was tested using electromyography (EMG), a method that measures tiny electrical signals in muscles. Initially, the system allowed users to adjust the robotic leg&rsquo;s support only when their foot was on the ground&mdash;such as when standing up from a chair or squatting. Over time, we improved the technology so users could also control movements while their leg was in the air, like during walking. Our research showed that this controller helped people with amputations climb stairs more naturally, even while carrying a backpack. It also allowed them to smoothly switch between activities like walking, stair climbing, and sitting down, providing better functionality than previous prosthetic controllers.</p>\r\n<p>To further improve how well the system detects user intentions, we explored <strong>sonomyography</strong>, a technique that uses ultrasound (sound waves) to monitor muscle movements. We tested two types of ultrasound technology&mdash;A-mode and B-mode&mdash;and found that while B-mode provides more detailed images, but it is also more complex and expensive. Since our goal was to create a practical system that can be used in real life, we developed a lightweight, battery-powered A-mode ultrasound device that works in real-time. With this system, we collected extensive data from individuals with above-knee amputations as they performed tasks like walking and climbing stairs using passive prosthetic legs. Using this data, we trained artificial intelligence (AI) models to predict how the robotic knee and ankle should move based on the user&rsquo;s muscle activity. Our results showed that a person with an above-knee amputation could successfully control the speed of a robotic knee just by using muscle signals detected through ultrasound&mdash;without needing additional sensors or external controls. This was the first successful demonstration of direct neural control of a robotic prosthesis using AI, paving the way for more natural and intuitive prosthetic limb technology.</p>\r\n<p>This project also played a role in education and workforce development. It supported three PhD students and two master&rsquo;s students, all U.S. citizens. Additionally, it provided research opportunities for undergraduate students through senior design projects and summer internships focused on prosthetics and robotics.</p><br>\n<p>\n Last Modified: 03/11/2025<br>\nModified by: Tommaso&nbsp;Lenzi</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/1925371/1925371_10636114_1741741421174_Picture1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1925371/1925371_10636114_1741741421174_Picture1--rgov-800width.png\" title=\"Integrated Sonomyography System\"><img src=\"/por/images/Reports/POR/2025/1925371/1925371_10636114_1741741421174_Picture1--rgov-66x44.png\" alt=\"Integrated Sonomyography System\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Direct neural control through artificial intelligence and muscle ultrasound provides a more intuitive and responsive robotic limb technology for individuals with leg amputations.</div>\n<div class=\"imageCredit\">HGN Lab for Bionic Engineering</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Tommaso&nbsp;Lenzi\n<div class=\"imageTitle\">Integrated Sonomyography System</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project improved robotic prosthetic legs by allowing users to control them more naturally using signals from their own muscles and nerves. Our work focused on people with above-knee amputations, helping them move more smoothly and intuitively improving their mobilty and quality of life.\r\n\n\nTo achieve this, we created a new type of controller that blends the users own movement intentions with robotic assistance. This controller was tested using electromyography (EMG), a method that measures tiny electrical signals in muscles. Initially, the system allowed users to adjust the robotic legs support only when their foot was on the groundsuch as when standing up from a chair or squatting. Over time, we improved the technology so users could also control movements while their leg was in the air, like during walking. Our research showed that this controller helped people with amputations climb stairs more naturally, even while carrying a backpack. It also allowed them to smoothly switch between activities like walking, stair climbing, and sitting down, providing better functionality than previous prosthetic controllers.\r\n\n\nTo further improve how well the system detects user intentions, we explored sonomyography, a technique that uses ultrasound (sound waves) to monitor muscle movements. We tested two types of ultrasound technologyA-mode and B-modeand found that while B-mode provides more detailed images, but it is also more complex and expensive. Since our goal was to create a practical system that can be used in real life, we developed a lightweight, battery-powered A-mode ultrasound device that works in real-time. With this system, we collected extensive data from individuals with above-knee amputations as they performed tasks like walking and climbing stairs using passive prosthetic legs. Using this data, we trained artificial intelligence (AI) models to predict how the robotic knee and ankle should move based on the users muscle activity. Our results showed that a person with an above-knee amputation could successfully control the speed of a robotic knee just by using muscle signals detected through ultrasoundwithout needing additional sensors or external controls. This was the first successful demonstration of direct neural control of a robotic prosthesis using AI, paving the way for more natural and intuitive prosthetic limb technology.\r\n\n\nThis project also played a role in education and workforce development. It supported three PhD students and two masters students, all U.S. citizens. Additionally, it provided research opportunities for undergraduate students through senior design projects and summer internships focused on prosthetics and robotics.\t\t\t\t\tLast Modified: 03/11/2025\n\n\t\t\t\t\tSubmitted by: TommasoLenzi\n"
 }
}