{
 "awd_id": "1907399",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Small: Collaborative Research: Representing and Learning Visualization Design Knowledge",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2019-08-14",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "This project contributes new methods and software tools for creating data-driven visualizations that improve the clarity and effectiveness of visual analysis and communication of data. Many visualization design guidelines, like \"avoid highly saturated colors\", or \"start bars in a bar chart at 0\", stem from empirical studies of how well people can read visualizations of various types. However, these guidelines are often stated informally in books or articles. In designing a visualization, an author may have to make decisions that prioritize one design guideline over another, yet the informal nature of such principles does not provide sufficient guidance for how to do this. Even when visualization researchers and system designers represent design guidelines in more formal \"knowledge bases\" that an authoring system can use to guide visualization authors towards more effective graphs, the guidelines are based on a person carefully summarizing the empirical results, an error-prone process. This project addresses these challenges to formulating and applying visualization design knowledge by creating new methods to identify, aggregate, edit, test, and search visualization design knowledge. This research will also address gaps in existing visualization design knowledge, applying novel methods to formulate and assess design guidelines for creating effective \"multiple-view\" visualizations (such as analysis dashboards or sequential presentations), visualizing very large datasets, and visually expressing uncertainty or error in data. We will create knowledge bases containing guidelines for these types of visualizations as well as an authoring tool to help authors manage competing design considerations between single and multiple views when designing visualizations like dashboards. All experimental results, knowledge bases, and authoring tools developed in this research will be made freely and publicly available.\r\n\r\nTo meet these goals, this project develops a set of methods for identifying and evaluating visualization design guidelines from empirical research on visualization perception and interpretation. To do this, the team will develop ways to re-express existing results from relevant experimental literature on graphical perception and cognition as constraints, and create new methods and tools for directly eliciting design guidelines from visualization experts such as skilled designers or researchers. The project will also produce automated methods for generating visualizations and collecting task-specific visualization judgments in order to learn appropriate priority weights for a given set of design constraints. By developing representations and models for capturing empirical results that can account for the uncertainty that is inherent in results from human subjects experiments, the project stands to synthesize and clarify existing empirical knowledge about visualization design. The research will also advance the state of the art in visualization design knowledge by contributing fundamental methods for (1) identifying and learning guidelines for large dataset visualizations, multiple view visualizations like dashboards, and uncertainty visualizations, and (2) exploring effective interface designs for browsing, editing, and testing visualization knowledge bases.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeffrey",
   "pi_last_name": "Heer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jeffrey Heer",
   "pi_email_addr": "jheer@cs.washington.edu",
   "nsf_id": "000519467",
   "pi_start_date": "2019-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "University of Washington, Comput",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981950001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 83744.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 166256.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-fff2bbe7-7fff-a155-8993-9ac42d6376e0\" style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">While visualizations can enable us to see and understand data, creating effective visualizations requires both design and technical expertise. Towards this goal, the investigators developed methods to encode design knowledge in a manner that computers can act on to automatically generate and recommend visualizations. A key idea is to represent design knowledge as constraints or \"rules\" that a design should respect, along with a corresponding cost or penalty for violating a constraint. In this scheme, a \"better\" chart is one with a lower cost, for example by violating fewer constraints. A collection of such constraints and costs forms a \"knowledge base\" for informing design, which algorithms can use to search a space of visualizations and find the most promising designs. We can determine costs from the results of perception experiments (for example, how quickly and accurately people extract information from charts), and use machine learning methods to determine costs that balance design trade-offs to match the preferences implied by experimental results.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The investigators used this formulation to develop new systems and applications for visualization design assistance. For example, sometimes a person may have only a partial idea for a chart they want to create. The Dziban library allows users to provide a data set and a minimal set of \"hints\" for the type of chart they'd like to see. A backing knowledge base is used to generate a chart in response. A user can iterate on their design by adding more \"hints\", so Dziban also models what the user saw before to prevent unwanted, dramatic shifts in suggested charts, using a technique called \"anchored recommendations\". To achieve this, the investigators extended visualization knowledge bases to also reason about chart similarity and sequence.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Visualization designers also often wish to animate changes between charts shown in sequence. Effective animated transitions involve careful choices of timing and staging (which elements change in what order) to help viewers follow changes between related visualizations. The investigators&rsquo; Gemini system defines transition steps in terms of high-level visual components (marks, axes, legends) and composition rules to synchronize or sequence steps. It then generates a number of candidate animation designs, and scores them using a cost function derived from perceptual studies. In evaluations, Gemini was able to express and recommend expert designers' choices and also matched the preferences of a more general audience.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">A different \"multi-view\" challenge is responsive visualization: adapting a design to different display platforms, such as desktop, tablet, or mobile phones. However, relatively little design guidance or tooling was available to support authors. To encode design knowledge for responsive design, the investigators first built up a design space by analyzing pairs of large and small screen visualizations from published articles or reports. Using human rankings of small screen alternative visualizations, they then fit a model to reason about what information to preserve while adjusting designs from large to small screen sizes, and thereby enable recommendations using a constraint-based knowledge base. The investigators instantiated these results by extending visualization languages to support responsive design (in Cicero, an extension of Vega-Lite) and building a design tool (Dupo) that enables interactive authoring of responsive designs supported by automatic design recommendations.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Finally, to support exploration and gain more details-on-demand, visualizations can be interactive. A chart viewer may want to see tooltips for more information about a data point; pan, zoom, or filter a display; or have selections in one chart filter or highlight content in another. However, effective interactions can be technically challenging to implement, and many popular tools (including ggplot2, Matplotlib, and Excel) do not provide interaction support. To enable interaction and also make a larger array of visualizations &ldquo;in the wild&rdquo; amenable to formal analysis, the DIVI project analyzes the visual output of a chart (in the form of vector graphics) and infers corresponding chart structures such as graphical marks, axes, legends, and scale mappings. It then uses this information to automatically add interactions to otherwise static charts, including cross-view linking. To support dynamic interaction without prior specification, the investigators developed a logical model that formalizes the space of standard interactions by chart element, interaction type, and input event. By decoupling interaction from visual specification, interactions can extend and compose freely across different tools, chart types, and analysis goals.</span></p><br>\n<p>\n Last Modified: 11/14/2023<br>\nModified by: Jeffrey&nbsp;Heer</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nWhile visualizations can enable us to see and understand data, creating effective visualizations requires both design and technical expertise. Towards this goal, the investigators developed methods to encode design knowledge in a manner that computers can act on to automatically generate and recommend visualizations. A key idea is to represent design knowledge as constraints or \"rules\" that a design should respect, along with a corresponding cost or penalty for violating a constraint. In this scheme, a \"better\" chart is one with a lower cost, for example by violating fewer constraints. A collection of such constraints and costs forms a \"knowledge base\" for informing design, which algorithms can use to search a space of visualizations and find the most promising designs. We can determine costs from the results of perception experiments (for example, how quickly and accurately people extract information from charts), and use machine learning methods to determine costs that balance design trade-offs to match the preferences implied by experimental results.\n\n\n\n\n\nThe investigators used this formulation to develop new systems and applications for visualization design assistance. For example, sometimes a person may have only a partial idea for a chart they want to create. The Dziban library allows users to provide a data set and a minimal set of \"hints\" for the type of chart they'd like to see. A backing knowledge base is used to generate a chart in response. A user can iterate on their design by adding more \"hints\", so Dziban also models what the user saw before to prevent unwanted, dramatic shifts in suggested charts, using a technique called \"anchored recommendations\". To achieve this, the investigators extended visualization knowledge bases to also reason about chart similarity and sequence.\n\n\n\n\n\nVisualization designers also often wish to animate changes between charts shown in sequence. Effective animated transitions involve careful choices of timing and staging (which elements change in what order) to help viewers follow changes between related visualizations. The investigators Gemini system defines transition steps in terms of high-level visual components (marks, axes, legends) and composition rules to synchronize or sequence steps. It then generates a number of candidate animation designs, and scores them using a cost function derived from perceptual studies. In evaluations, Gemini was able to express and recommend expert designers' choices and also matched the preferences of a more general audience.\n\n\n\n\n\nA different \"multi-view\" challenge is responsive visualization: adapting a design to different display platforms, such as desktop, tablet, or mobile phones. However, relatively little design guidance or tooling was available to support authors. To encode design knowledge for responsive design, the investigators first built up a design space by analyzing pairs of large and small screen visualizations from published articles or reports. Using human rankings of small screen alternative visualizations, they then fit a model to reason about what information to preserve while adjusting designs from large to small screen sizes, and thereby enable recommendations using a constraint-based knowledge base. The investigators instantiated these results by extending visualization languages to support responsive design (in Cicero, an extension of Vega-Lite) and building a design tool (Dupo) that enables interactive authoring of responsive designs supported by automatic design recommendations.\n\n\n\n\n\nFinally, to support exploration and gain more details-on-demand, visualizations can be interactive. A chart viewer may want to see tooltips for more information about a data point; pan, zoom, or filter a display; or have selections in one chart filter or highlight content in another. However, effective interactions can be technically challenging to implement, and many popular tools (including ggplot2, Matplotlib, and Excel) do not provide interaction support. To enable interaction and also make a larger array of visualizations in the wild amenable to formal analysis, the DIVI project analyzes the visual output of a chart (in the form of vector graphics) and infers corresponding chart structures such as graphical marks, axes, legends, and scale mappings. It then uses this information to automatically add interactions to otherwise static charts, including cross-view linking. To support dynamic interaction without prior specification, the investigators developed a logical model that formalizes the space of standard interactions by chart element, interaction type, and input event. By decoupling interaction from visual specification, interactions can extend and compose freely across different tools, chart types, and analysis goals.\t\t\t\t\tLast Modified: 11/14/2023\n\n\t\t\t\t\tSubmitted by: JeffreyHeer\n"
 }
}