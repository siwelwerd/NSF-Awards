{
 "awd_id": "1931867",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: Small: Robust and Efficient Perception System for Autonomous Vehicles (REPAVE)",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928950",
 "po_email": "rwachter@nsf.gov",
 "po_sign_block_name": "Ralph Wachter",
 "awd_eff_date": "2019-11-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 499990.0,
 "awd_amount": 514190.0,
 "awd_min_amd_letter_date": "2019-09-10",
 "awd_max_amd_letter_date": "2022-08-12",
 "awd_abstract_narration": "The goal of this project is to advance the science of designing efficient and robust perception systems for complex cyber-physical systems such as autonomous vehicles (AV). Industries in the US, especially AV-related industries, must be competitive in terms of innovations in computer vision and security issues related to deep learning models deployed in complex cyber-physical systems. This project provides these innovations and prepares new generations of computer scientists that can join the industry workforce. The solutions created in this project will ensure safer operations of autonomous systems which benefit the society overall. Finally, hands-on training sessions will be organized at top computer vision conferences to provide opportunities to members of underrepresented groups. \r\n\r\nThis project explores innovative solutions for efficient deep learning models in computer vision which  are suitable for resource constrained devices and smarter sensors which can improve the robustness of the perception systems in complex cyber-physical systems. First, a more robust deep learning based perception system utilizing a combination of a color camera and cheaper sensors with lower cost but with better accuracy and efficiency will be created. Second, autonomous systems typically operate under dynamic environments.  A more robust decision making module which utilizes context information involving interactions among nearby moving agents to make quick and accurate predictions of their future movements will also be designed. Complex cyber-physical systems are subjected to cyberattacks, and smarter sensors with unique signatures will be designed to allow such perception systems to be more resilient.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mooi-Choo",
   "pi_last_name": "Chuah",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mooi-Choo Chuah",
   "pi_email_addr": "chuah@cse.lehigh.edu",
   "nsf_id": "000097670",
   "pi_start_date": "2019-09-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Lehigh University",
  "inst_street_address": "526 BRODHEAD AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BETHLEHEM",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "6107583021",
  "inst_zip_code": "180153008",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "PA07",
  "org_lgl_bus_name": "LEHIGH UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "E13MDBKHLDB5"
 },
 "perf_inst": {
  "perf_inst_name": "Lehigh University",
  "perf_str_addr": "113 Research Drive BC317",
  "perf_city_name": "Bethlehem",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "180153005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "PA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "791800",
   "pgm_ele_name": "CPS-Cyber-Physical Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 499990.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 14200.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Intellectual Merits:</p>\n<p>1. Design Goal-based Local Behavior Guided Trajectory Prediction model that outperforms SOTA methods using 2 popular datasets, namely nuscene and argoverse</p>\n<p>2. Design BEV-TP, e2e differentiable visual based joint perception and trajectory prediction model that uses multicamera, multiframe video frames that outperform SOTA methods using nuscene.</p>\n<p>3. Evalaute robustness of&nbsp; context-map trajectory prediction models under a new map-based attack that we propose and propose mitigation methods against such attacks.</p>\n<p>4. Create a new light-dark scene dataset LDiS that other researchers can use to conduct low light image enhancement and segmentation related research. Also propose depthAux that uses depth information to help in low light image segmentation task.</p>\n<p>5. Design SRNEt- spatial relation network for efficient single-stage instance segmentation in videos</p>\n<p>6. Design weakly supervised object represenation learning for few shot semantic segmentation.</p>\n<p>5. Construct a simple 3 robotic cars testbed to evaluate object detection and simple attacks on perception system.</p>\n<p>Broader Impacts:</p>\n<p>&nbsp;</p>\n<div>&bull;Research outputs on semantic segmentation and instance segmentation on images and videos have been shared with industry (Qualcomm) and computer vision research community.</div>\n<div>&bull;Research outputs on visual-based trajectory prediction have also been shared with industry (FORD) and computer vision research community.</div>\n<div>&bull;Graduated 2 PHD students who are currently working in industry, currently training 3 more students in doing computer vision related research</div>\n<div>&bull;PI Chuah and Senior Personnel Montella trained undergraduate students in doing robotic related research through advising CS capstone projects and Lehigh Summer STEM institute project and REUSite projects. A few students decided to go to graduate schools.</div>\n<div>&bull;PI Chuah created a Slack channel for Lehigh CS minority students and organized online meetings for them to meet industry professionals who are also minority.</div>\n<div>&bull;Dr. Montella also trained 57 (over summer courses from 2020-22) undergraduate students on Foundations of Robotics.</div>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/11/2023<br>\n\t\t\t\t\tModified by: Mooi-Choo&nbsp;Chuah</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1931867/1931867_10641129_1696946908588_Goal-based-LBP--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1931867/1931867_10641129_1696946908588_Goal-based-LBP--rgov-800width.jpg\" title=\"Goal-Based LBP Model\"><img src=\"/por/images/Reports/POR/2023/1931867/1931867_10641129_1696946908588_Goal-based-LBP--rgov-66x44.jpg\" alt=\"Goal-Based LBP Model\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Goal-based Local Behavior Guided Trajectory Prediction Model</div>\n<div class=\"imageCredit\">Lehigh</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Mooi-Choo&nbsp;Chuah</div>\n<div class=\"imageTitle\">Goal-Based LBP Model</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1931867/1931867_10641129_1696946977553_robotic-car--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1931867/1931867_10641129_1696946977553_robotic-car--rgov-800width.jpg\" title=\"Robotic Car Testbed\"><img src=\"/por/images/Reports/POR/2023/1931867/1931867_10641129_1696946977553_robotic-car--rgov-66x44.jpg\" alt=\"Robotic Car Testbed\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Robotic Car Testbed</div>\n<div class=\"imageCredit\">Lehigh</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Mooi-Choo&nbsp;Chuah</div>\n<div class=\"imageTitle\">Robotic Car Testbed</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1931867/1931867_10641129_1696947073808_BEV-TP--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1931867/1931867_10641129_1696947073808_BEV-TP--rgov-800width.jpg\" title=\"BEV-TP Model\"><img src=\"/por/images/Reports/POR/2023/1931867/1931867_10641129_1696947073808_BEV-TP--rgov-66x44.jpg\" alt=\"BEV-TP Model\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">E2E differentiable visual-based joint perception and trajectory prediction model</div>\n<div class=\"imageCredit\">Lehigh</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Mooi-Choo&nbsp;Chuah</div>\n<div class=\"imageTitle\">BEV-TP Model</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nIntellectual Merits:\n\n1. Design Goal-based Local Behavior Guided Trajectory Prediction model that outperforms SOTA methods using 2 popular datasets, namely nuscene and argoverse\n\n2. Design BEV-TP, e2e differentiable visual based joint perception and trajectory prediction model that uses multicamera, multiframe video frames that outperform SOTA methods using nuscene.\n\n3. Evalaute robustness of  context-map trajectory prediction models under a new map-based attack that we propose and propose mitigation methods against such attacks.\n\n4. Create a new light-dark scene dataset LDiS that other researchers can use to conduct low light image enhancement and segmentation related research. Also propose depthAux that uses depth information to help in low light image segmentation task.\n\n5. Design SRNEt- spatial relation network for efficient single-stage instance segmentation in videos\n\n6. Design weakly supervised object represenation learning for few shot semantic segmentation.\n\n5. Construct a simple 3 robotic cars testbed to evaluate object detection and simple attacks on perception system.\n\nBroader Impacts:\n\n \n&bull;Research outputs on semantic segmentation and instance segmentation on images and videos have been shared with industry (Qualcomm) and computer vision research community.\n&bull;Research outputs on visual-based trajectory prediction have also been shared with industry (FORD) and computer vision research community.\n&bull;Graduated 2 PHD students who are currently working in industry, currently training 3 more students in doing computer vision related research\n&bull;PI Chuah and Senior Personnel Montella trained undergraduate students in doing robotic related research through advising CS capstone projects and Lehigh Summer STEM institute project and REUSite projects. A few students decided to go to graduate schools.\n&bull;PI Chuah created a Slack channel for Lehigh CS minority students and organized online meetings for them to meet industry professionals who are also minority.\n&bull;Dr. Montella also trained 57 (over summer courses from 2020-22) undergraduate students on Foundations of Robotics.\n\n \n\n\t\t\t\t\tLast Modified: 10/11/2023\n\n\t\t\t\t\tSubmitted by: Mooi-Choo Chuah"
 }
}