{
 "awd_id": "1908079",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: Efficient Memory Persistency for GPUs",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Danella Zhao",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2019-07-27",
 "awd_max_amd_letter_date": "2019-07-27",
 "awd_abstract_narration": "Scientific progress often depends on computer technology providing ever faster computers  capable of processing ever increasing amounts of data. The growth in memory capacity and density of current computer systems, however, is in peril as Dynamic Random Access Memory (DRAM), the current dominant main memory technology, faces serious roadblocks in scaling. Non-volatile memory or persistent memory is an emerging alternative technology that offers high integration density, speed similar to current main memory, byte addressability similar to current main memory, and lower standby power than current main memory. Hence, persistent memory is expected to increasingly augment or replace DRAM as main memory, and such a change is also expected to happen in Graphics Processing Unit (GPU) based computing systems which are the dominant accelerators for high performance computing. However, in order to fully realize its potential, research on persistency models on GPUs is needed. This project investigates integrated software and hardware techniques to enable GPUs to make efficient use of non-volatile memory. Successful outcomes of this project will lead to faster access to data by reducing overheads involved with file access. The software produced (persistent GPU benchmarks, compiler, and tuner) and prototyping platform will be made available to other researchers. Education and outreach activities in this project seek to train the next generation of programmers in this discipline.\r\n\r\nThe research in this project answers the question: on a GPU system, what architecture supports are needed to achieve efficient persistency programming on GPUs with persistent memory (PM) as their device memory? The research contributions include:  (1) an open-source GPU PM benchmark suite that is representative of various application domains; (2) an exploration of persistency models in GPUs and Instruction Set Architecture support; (3) optimizations on the persistency models by removing the need for logging; (4) a compiler pass and performance tuner to automatically determine the best-performing memory persistency and recovery model, and transform the code accordingly.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yan",
   "pi_last_name": "Solihin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yan Solihin",
   "pi_email_addr": "yan.solihin@ucf.edu",
   "nsf_id": "000299551",
   "pi_start_date": "2019-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "The University of Central Florida Board of Trustees",
  "inst_street_address": "4000 CENTRAL FLORIDA BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "ORLANDO",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "4078230387",
  "inst_zip_code": "328168005",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "FL10",
  "org_lgl_bus_name": "THE UNIVERSITY OF CENTRAL FLORIDA BOARD OF TRUSTEES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RD7MXJV7DKT9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Central Florida",
  "perf_str_addr": "4353 Scorpius St",
  "perf_city_name": "Orlando",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "328160120",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "FL10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><br />Scientific progress often depends on computer technology providing ever faster computers capable of processing ever increasing amounts of data. The growth in memory capacity and density of current computer systems, however, is in peril as Dynamic Random Access Memory (DRAM), the current dominant main memory technology, faces serious roadblocks in scaling. &nbsp;Non-volatile memory or persistent memory (PM) is an emerging alternative technology that offers high integration density, byte addressability, and lower standby power than current main memory. Persistent memory is expected to increasingly augment or extend DRAM as main memory in cloud servers, including ones with Graphics Processing Unit (GPU). We envision GPU will make use of PM in the future due to the increasing demand for memory capacity in emerging workloads, including artificial intelligence model training and inferences.&nbsp;</p>\n<p><br />This project investigated new techniques to enable GPUs to make efficient use of non-volatile memory. One finding is that CPU memory persistency needs to be re-architected for GPUs, because of differences in workload characteristics and execution behavior, memory-intensive kernels in GPUs are &nbsp;typically bandwidth- (instead of latency-) sensitive, making durable write-pending queues (WPQs) at the memory controller less effective. GPU's multiple memory partitions made it necessary for persistence to be broadcasted to all MCs to flush all their WPQs.&nbsp;</p>\n<p><br />The project investigated re-architecting GPUs to support efficient persistency. First, to provide both simplicity and flexibility to use the persistency models, we found that it was &nbsp;necessary to provide {\\sf pragmas} for programmers to specify their choice of persistency model and code region, allowing the compiler to automatically generate GPU persistency code.&nbsp;</p>\n<p><br />Second, we found that it was important to provide new instructions to implement GPU-friendly strict persistency and relaxed (epoch) persistency. We consider and compare GPU alternatives: store write-through \"store.wt\" and \"l2wb\" to flush all dirty blocks in the L2 cache. Furthermore, some existing instructions that support parallel reduction are important for persistence performance.</p>\n<p>&nbsp;<br />Third, there are some algorithm changes that are warranted. For example, based on the characteristics of a kernel, three epoch granularities may be needed: kernel level, CTA (cooperative thread array) level, and loop level. Also, we found that the reliance on &nbsp;logging, which increases memory bandwidth pressure, is needed. We found that adopting lazy persistency techniques were beneficial for persistence performance and scalability.&nbsp;</p>\n<p><br />Finally, we re-architected GPUs for secure execution environment. We found that memory encryption, which is important to have in persistent memory due to data remanence, created a new performance bottleneck problem in GPUs. We designed GPUs with two separate approaches: hardware-only design, and software-only design. Both were found to be effective in keeping memory encryption overhead low.&nbsp;</p>\n<p>Multiple students were involved and trained in the research, and the research outcome was added into a course at UCF.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/15/2023<br>\nModified by: Yan&nbsp;Solihin</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\nScientific progress often depends on computer technology providing ever faster computers capable of processing ever increasing amounts of data. The growth in memory capacity and density of current computer systems, however, is in peril as Dynamic Random Access Memory (DRAM), the current dominant main memory technology, faces serious roadblocks in scaling. Non-volatile memory or persistent memory (PM) is an emerging alternative technology that offers high integration density, byte addressability, and lower standby power than current main memory. Persistent memory is expected to increasingly augment or extend DRAM as main memory in cloud servers, including ones with Graphics Processing Unit (GPU). We envision GPU will make use of PM in the future due to the increasing demand for memory capacity in emerging workloads, including artificial intelligence model training and inferences.\n\n\n\nThis project investigated new techniques to enable GPUs to make efficient use of non-volatile memory. One finding is that CPU memory persistency needs to be re-architected for GPUs, because of differences in workload characteristics and execution behavior, memory-intensive kernels in GPUs are typically bandwidth- (instead of latency-) sensitive, making durable write-pending queues (WPQs) at the memory controller less effective. GPU's multiple memory partitions made it necessary for persistence to be broadcasted to all MCs to flush all their WPQs.\n\n\n\nThe project investigated re-architecting GPUs to support efficient persistency. First, to provide both simplicity and flexibility to use the persistency models, we found that it was necessary to provide {\\sf pragmas} for programmers to specify their choice of persistency model and code region, allowing the compiler to automatically generate GPU persistency code.\n\n\n\nSecond, we found that it was important to provide new instructions to implement GPU-friendly strict persistency and relaxed (epoch) persistency. We consider and compare GPU alternatives: store write-through \"store.wt\" and \"l2wb\" to flush all dirty blocks in the L2 cache. Furthermore, some existing instructions that support parallel reduction are important for persistence performance.\n\n\n\nThird, there are some algorithm changes that are warranted. For example, based on the characteristics of a kernel, three epoch granularities may be needed: kernel level, CTA (cooperative thread array) level, and loop level. Also, we found that the reliance on logging, which increases memory bandwidth pressure, is needed. We found that adopting lazy persistency techniques were beneficial for persistence performance and scalability.\n\n\n\nFinally, we re-architected GPUs for secure execution environment. We found that memory encryption, which is important to have in persistent memory due to data remanence, created a new performance bottleneck problem in GPUs. We designed GPUs with two separate approaches: hardware-only design, and software-only design. Both were found to be effective in keeping memory encryption overhead low.\n\n\nMultiple students were involved and trained in the research, and the research outcome was added into a course at UCF.\n\n\n\t\t\t\t\tLast Modified: 12/15/2023\n\n\t\t\t\t\tSubmitted by: YanSolihin\n"
 }
}