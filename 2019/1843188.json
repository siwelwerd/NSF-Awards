{
 "awd_id": "1843188",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Whole-body 3D perception for human-safe collaborative robots",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Muralidharan Nair",
 "awd_eff_date": "2019-02-01",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 225000.0,
 "awd_amount": 225000.0,
 "awd_min_amd_letter_date": "2019-01-29",
 "awd_max_amd_letter_date": "2019-01-29",
 "awd_abstract_narration": "The broader impact/commercial potential of this project is to enable a new generation of collaborative robots that are capable and safe. Collaborative robotics is poised to revolutionize manufacturing where they will enable better utilization of factory space and machines, reduce energy cost, and mitigate labor shortages. Safe operation is a critical factor for successful operation of collaborative robotics, especially if they are mobile. The proposed project will demonstrate that tactile sensing skins can make robots safer, more collaborative, and manufactured at reasonable cost. The proposed task will also contribute to workforce development and enhance scientific understanding in the critical fields of robotics, soft robotics, and artificial intelligence, as well as providing opportunities for local students.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project will investigate a novel type of tactile sensing skin to improve robot safety and its ability to interact with human users. Unlike previous work, the proposed skin can detect obstacles from a distance of up to 20cm, as well as measuring contact and force. Also, the ability to detect user gestures such as tapping, rubbing or poking, opens new avenues for human-robot interaction and will enable the study of truly collaborative robots. The proposed research and development project will overcome the following key challenges that stand in the way of commercializing the technology: scaling from single patches to full-body sensing skins, fusing proximity data collected from the skin with those provided by conventional 3D sensors, and demonstrating its benefits in a series of real-world use cases.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nicolaus",
   "pi_last_name": "Correll",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Nicolaus J Correll",
   "pi_email_addr": "ncorrell@colorado.edu",
   "nsf_id": "000546404",
   "pi_start_date": "2019-01-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Robotic Materials Inc",
  "inst_street_address": "3080 VALMONT RD # 100",
  "inst_street_address_2": "",
  "inst_city_name": "BOULDER",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "3037171436",
  "inst_zip_code": "803012152",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "ROBOTIC MATERIALS INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "DAVKSDE6BGW4"
 },
 "perf_inst": {
  "perf_inst_name": "Robotic Materials Inc",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "803012620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5371",
   "pgm_ref_txt": "SMALL BUSINESS PHASE I"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  },
  {
   "pgm_ref_code": "8035",
   "pgm_ref_txt": "Hardware Devices"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 225000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has led to a novel full-body sensor skin for robotic arms, exemplarly for the Universal Robot UR5e, which enable the robot to detect objects in its surrounding before a collision occurs and indicate potential collisions to a user via a dense array of light emitting diodes. This extends the paradigmn of \"collaborative robots\", which internally limit velocities and torques to minimize damage upon contact with the environment and humans, to being able to actively avoid collisions with their environment and interact with their users via optical information and gestures. The intellectual merit of this research is a novel mechatronic design that provides complete coverage of the entire robot's surface to detect objects as small as one millimeter in diameter and as far as one meter away, a communication bus architecture that distributes computation between the individual sensing modules and a host computer, and a suite of algorithms to fuse the resulting information with other 3D perception devices and detect self-collisions. The broader impact of this research is a new generation of collaborative robot manipulators that can safely operate at high speed and perform autonomous exploration of their environment with minimal risk of colliding with their environment. These robots can work closer to humans as ever before, enabling true collaboration for assembly, item picking, or lifting heavy items, paving the way for autonomous robots to extend beyond manufacturing into other commercial spaces, caring facilities and the home.&nbsp;&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/22/2020<br>\n\t\t\t\t\tModified by: Nicolaus&nbsp;J&nbsp;Correll</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project has led to a novel full-body sensor skin for robotic arms, exemplarly for the Universal Robot UR5e, which enable the robot to detect objects in its surrounding before a collision occurs and indicate potential collisions to a user via a dense array of light emitting diodes. This extends the paradigmn of \"collaborative robots\", which internally limit velocities and torques to minimize damage upon contact with the environment and humans, to being able to actively avoid collisions with their environment and interact with their users via optical information and gestures. The intellectual merit of this research is a novel mechatronic design that provides complete coverage of the entire robot's surface to detect objects as small as one millimeter in diameter and as far as one meter away, a communication bus architecture that distributes computation between the individual sensing modules and a host computer, and a suite of algorithms to fuse the resulting information with other 3D perception devices and detect self-collisions. The broader impact of this research is a new generation of collaborative robot manipulators that can safely operate at high speed and perform autonomous exploration of their environment with minimal risk of colliding with their environment. These robots can work closer to humans as ever before, enabling true collaboration for assembly, item picking, or lifting heavy items, paving the way for autonomous robots to extend beyond manufacturing into other commercial spaces, caring facilities and the home.  \n\n\t\t\t\t\tLast Modified: 01/22/2020\n\n\t\t\t\t\tSubmitted by: Nicolaus J Correll"
 }
}