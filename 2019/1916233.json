{
 "awd_id": "1916233",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Innovations for Bayesian Tree Ensemble Methodology",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2019-07-15",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 159997.0,
 "awd_amount": 159997.0,
 "awd_min_amd_letter_date": "2019-07-10",
 "awd_max_amd_letter_date": "2019-07-10",
 "awd_abstract_narration": "An essential goal of modern statistical analyses across many disciplines is to gain insight into the behavior of real-world processes both to identify important correlates of variation and to obtain improved predictions.  For example in marketing, the statistician may be interested in learning the purchasing behavior of consumers from an analysis of a database of consumer transactions that includes various consumer descriptors (e.g. age, income level, geographic location) as well as  purchase amounts. The statistician would then typically attempt to build a mathematical model that characterizes the relationship between the consumer descriptors and the expenditure amount.  In doing so, however, certain issues bear strongly on the model's value and effectiveness.  First, the validity of a model may strongly depend on prior assumptions about the nature of the modeled process, information that can be difficult to ascertain. For instance, a consumer behavior model which builds in a simple assumption that consumers with higher income levels are always expected to purchase more, may be inadvertently ignoring subtleties that violate this assumption when other factors are simultaneously taken into account.  Second, sometimes even a valid and effective model may be such a complicated object that the extraction of meaningful information can itself be very challenging.  For example, after establishing particular set of predictors as important drivers of consumer purchasing power, it will still be of key interest how to best measure their relative importance in the model.  Focusing on the powerful and flexible approach of Bayesian regression tree ensemble modeling, the main thrust of this project will be to innovate this methodology to address these and other modeling avenues.  This new methodology will enable practitioners to address their research questions in an assumption-lean framework that allows the ensemble models to make use of their data to adaptively and flexibly incorporate contextual modeling assumptions. To greatly enhance interpretability, it will also provide automatic, information based summaries of variable importance to help the practitioner understand and interpret the available descriptor information.  In addition to these and further methodological contributions, the project will develop software for the implementation of this methodology as a freely available R package, enabling practitioners to more easily leverage our developments in their practical work. This is where the graduate student supported by this award will help. \r\n\r\n\r\nThe research will focus on three general innovations to Bayesian ensemble modeling to further enhance its ability to extract meaning from complex data within an assumption lean framework.    The first contribution will develop theoretically valid measures of variable importance.  These measures will provide computationally efficient calculation of indices which meaningfully gauge the relative importance of predictor variables, both marginally and in terms of interactions.  The second contribution will provide an approach to monotone shape constrained inference which does not require any prior assumption of monotonicity.  This multidimensional nonparametric regression approach will enable the discovery and estimation of any and all the monotone components of the regression function, and to do so with no constraint assumptions whatsoever.  The third contribution will vastly extend the applicability of Bayesian ensemble modeling by developing a generalization of BART for arbitrary response data distributions, such as dichotomous responses and count data.  This major technical innovation will be based on a conjugacy-free formulation that will extend the reach of BART to many new application areas and problem types than were previously possible.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "McCulloch",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Robert E McCulloch",
   "pi_email_addr": "remccul1@asu.edu",
   "nsf_id": "000766793",
   "pi_start_date": "2019-07-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "School of Mathematical and Statistical Sciences",
  "perf_str_addr": "P.O. Box 871804",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852871804",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 159997.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Research completed during the time of the award.</p>\n<p><br />Influential Observations in Bayesian Regression Tree ModelsM. T. Pratola, E. I. George, and R. E. McCullochPublication date 2024/1/2Journal of Computational and Graphical StatisticsBCART (Bayesian Classification and Regression Trees) and BART (Bayesian AdditiveRegression Trees) are popular Bayesian regression models widely applicable in modern re-gression problems. Their popularity is intimately tied to the ability to flexibly model complexresponses depending on high-dimensional inputs while simultaneously being able to quantifyuncertainties. This ability to quantify uncertainties is key, as it allows researchers to performappropriate inferential analyses in settings that have generally been too difficult to handleusing the Bayesian approach. However, surprisingly little work has been done to evaluatethe sensitivity of these modern regression models to violations of modeling assumptions. Inparticular, we will consider influential observations, which one reasonably would imagine tobe common &ndash; or at least a concern &ndash; in the big-data setting. In this paper, we consider boththe problem of detecting influential observations and adjusting predictions to not be undulyaffected by such potentially problematic data. We consider three detection diagnostics forBayesian tree models, one an analogue of Cook&rsquo;s distance and the others taking the form ofa divergence measure and a conditional predictive density metric, and then propose an im-portance sampling algorithm to re-weight previously sampled posterior draws so as to removethe effects of influential data in a computationally efficient manner.</p>\n<p><br />Nonparametric failure time: Time&#8208;to&#8208;event machine learning with heteroskedastic&nbsp;Bayesian additive regression trees and low information omnibus Dirichlet process mixturesRodney A Sparapani, Brent R Logan, Martin J Maiers, Purushottam W Laud, Robert E McCullochPublication date 2023/12, Journal Biometrics, Volume 79, Issue 4, Pages 3023-3037Many popular survival models rely on restrictive parametric or semiparametric assumptions that may lead to incor-rect inference or survival predictions when the effects of covariates are complex. Modern advances in computationalhardware has led to increasing interest in flexible Bayesian nonparametric methods for time-to-event data such as thatprovided by Bayesian additive regression trees (BART). We propose a novel approach, called nonparametric failuretime (NFT) BART, that incorporates flexibility in Accelerated Failure Time (AFT) models in three ways: 1) a BARTcomponent for the mean function of the natural logarithm with time&rsquo;s distribution; 2) a heteroskedastic BARTcomponent to handle a covariate dependent variance function; and 3) a flexible nonparametric error distributionusing Dirichlet Process Mixtures (DPM). Our proposed approach can be scaled up to large sample sizes, and canbe seamlessly employed for variable selection. We provide convenient, user-friendly, computer software that is freelyavailable as a reference implementation. Simulations demonstrate that NFT BART maintains excellent performanceeven when AFT assumptions are violated. We illustrate the proposed model on a real data example of hematopoieticstem cell transplantation as a treatment for blood-borne cancers.</p><br>\n<p>\n Last Modified: 10/17/2024<br>\nModified by: Robert&nbsp;E&nbsp;Mcculloch</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nResearch completed during the time of the award.\n\n\n\nInfluential Observations in Bayesian Regression Tree ModelsM. T. Pratola, E. I. George, and R. E. McCullochPublication date 2024/1/2Journal of Computational and Graphical StatisticsBCART (Bayesian Classification and Regression Trees) and BART (Bayesian AdditiveRegression Trees) are popular Bayesian regression models widely applicable in modern re-gression problems. Their popularity is intimately tied to the ability to flexibly model complexresponses depending on high-dimensional inputs while simultaneously being able to quantifyuncertainties. This ability to quantify uncertainties is key, as it allows researchers to performappropriate inferential analyses in settings that have generally been too difficult to handleusing the Bayesian approach. However, surprisingly little work has been done to evaluatethe sensitivity of these modern regression models to violations of modeling assumptions. Inparticular, we will consider influential observations, which one reasonably would imagine tobe common  or at least a concern  in the big-data setting. In this paper, we consider boththe problem of detecting influential observations and adjusting predictions to not be undulyaffected by such potentially problematic data. We consider three detection diagnostics forBayesian tree models, one an analogue of Cooks distance and the others taking the form ofa divergence measure and a conditional predictive density metric, and then propose an im-portance sampling algorithm to re-weight previously sampled posterior draws so as to removethe effects of influential data in a computationally efficient manner.\n\n\n\nNonparametric failure time: Time&#8208;to&#8208;event machine learning with heteroskedasticBayesian additive regression trees and low information omnibus Dirichlet process mixturesRodney A Sparapani, Brent R Logan, Martin J Maiers, Purushottam W Laud, Robert E McCullochPublication date 2023/12, Journal Biometrics, Volume 79, Issue 4, Pages 3023-3037Many popular survival models rely on restrictive parametric or semiparametric assumptions that may lead to incor-rect inference or survival predictions when the effects of covariates are complex. Modern advances in computationalhardware has led to increasing interest in flexible Bayesian nonparametric methods for time-to-event data such as thatprovided by Bayesian additive regression trees (BART). We propose a novel approach, called nonparametric failuretime (NFT) BART, that incorporates flexibility in Accelerated Failure Time (AFT) models in three ways: 1) a BARTcomponent for the mean function of the natural logarithm with times distribution; 2) a heteroskedastic BARTcomponent to handle a covariate dependent variance function; and 3) a flexible nonparametric error distributionusing Dirichlet Process Mixtures (DPM). Our proposed approach can be scaled up to large sample sizes, and canbe seamlessly employed for variable selection. We provide convenient, user-friendly, computer software that is freelyavailable as a reference implementation. Simulations demonstrate that NFT BART maintains excellent performanceeven when AFT assumptions are violated. We illustrate the proposed model on a real data example of hematopoieticstem cell transplantation as a treatment for blood-borne cancers.\t\t\t\t\tLast Modified: 10/17/2024\n\n\t\t\t\t\tSubmitted by: RobertEMcculloch\n"
 }
}