{
 "awd_id": "1923789",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SpecEES: DISCOVER: Device Identification for Spectrum-optimization using COnVolutional nEural netwoRks",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Murat Torlak",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 750000.0,
 "awd_amount": 750000.0,
 "awd_min_amd_letter_date": "2019-09-08",
 "awd_max_amd_letter_date": "2019-09-08",
 "awd_abstract_narration": "The research objective of this project, called DISCOVER, is to harness the power of deep machine learning (ML) algorithms to communicate wirelessly with high spectral efficiency and low power consumption. The techniques will result in advanced networking protocols that consume minimal resources by securely identifying the devices that are active in the surrounding environment without (or with minimal) control signaling. Apart from learning channel usage and device activity, DISCOVER will allow for rapidly deploying these algorithms in hardware, so that real-time inferences can be made. Thus, DISCOVER is directly aligned with the US President's executive order from February 2019 'Maintaining American Leadership in Artificial Intelligence' that seeks to prioritize research and development of America's artificial intelligence (AI) capabilities. DISCOVER aims to bring together industry, academia and government stakeholders through collaborative workshops towards identifying high priority challenges, limitations of available data sources, and identify a list of candidate machine learning solutions that will shape the next generation of wireless technologies. The open source release of signal datasets and simulation code will foster new interactions of wireless researchers with core machine learning domain experts.\r\n\r\nDISCOVER has three goals for optimizing spectrum utilization with overlapping interests of either energy saving or resilience to identity spoofing through the use of deep learning architectures: \r\n1. It aims to explore deep convolutional neural network (CNN) architectures that will allow highly accurate device classification and demonstrate how to eliminate identifier-related protocol fields. This approach of reducing packet headers will achieve quantifiable spectrum utilization improvements, especially for large-scale deployment of the Internet of Things (IoT). \r\n2. It aims to demonstrate the first learning-in-the-loop radio frequency (RF) system where spectrum-driven decisions are enabled through real-time deep learning algorithms implemented directly on the device hardware. This will result in significant energy savings for embedded IoT devices. \r\n3. The emulation engine developed in the project will empower users to create custom-signals to train ML algorithms. Furthermore, it will create community RF signal datasets that will ensure means of standardized validation for the larger research community.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kaushik",
   "pi_last_name": "Chowdhury",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Kaushik R Chowdhury",
   "pi_email_addr": "kaushik@utexas.edu",
   "nsf_id": "000541186",
   "pi_start_date": "2019-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Tommaso",
   "pi_last_name": "Melodia",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tommaso Melodia",
   "pi_email_addr": "melodia@northeastern.edu",
   "nsf_id": "000676111",
   "pi_start_date": "2019-09-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "059Y00",
   "pgm_ele_name": "SpecEES Spectrum Efficiency, E"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 750000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project resulted in several foundational advancements in the use machine learning (ML) for wireless communications at the physical layer of the protocol stack. &nbsp;</p>\n<p><strong>ML for Optimizing Beamforming. </strong>The PIs studied how millimeter-wave band beamforming could be enhanced through ML. For this, the team first explored how to use ML for estimating the channel state information, which can then be used to appropriately set the weights of the antenna array for directional beams. However, this approach required coordination between the transmitter and receiver side. The PIs enhanced this work by designing a method that does not require pilot sequences from the transmitter, nor any beam sweeping or synchronization from the receiver-side. This is achieved by inferring (i) the angle at which signals arrive at the receiver and (ii) the actual beam being used by the transmitter through waveform-level deep learning on ongoing transmissions between the transmitter to other receivers.&nbsp;</p>\n<p><strong>ML for Wireless Signal Sensing Classification.</strong> The PIs proposed methods for classifying waveforms under different environmental conditions. In one instance, the team applied tiny modifications to the waveform to strengthen its features according to the current channel conditions, thus maximizing the detection accuracy at the receiver side. In another instance, the team created time-frequency spectrograms from the received signals and then trained well-known object detection models for detecting weak or overlapping signals that are present under a stronger signal. The PIs demonstrated how radar signals could be detected under regular cellular signals in this work. Furthermore, they studied how to identify a specific emitter through deep learning methods that analyze subtle alterations introduced in the transmitted signals due to process variations during manufacturing. They showed how to apply these methods for identifying specific unmanned aerial systems and wireless base stations by conducting experiments over the NSF PAWR platforms. Finally, this research direction also resulted in methods where intentional and subtle distortions introduced to the pilot signals could be detected at the receiver side, thus allowing a low-bandwidth control channel that is otherwise undetectable. &nbsp;</p>\n<p><strong>AI-native Receivers.</strong> There is an increasing trend towards swapping traditional signal processing blocks within the wireless received with their ML counterparts. The project showed how to compose a receiver architecture by specialized designed channel estimator, demapper, and error corrector (decoder) neural networks. Using both simulated and over-the-air datasets, this work showed that these neural networks perform better than their non-ML counterparts. The PIs also explored methods to compress these models using different pruning and quantization methods, and then implemented them on Field Programmable Gate Arrays (FPGA) to demonstrate reduced computational complexity during real-time operation. A major outcome is that this prototype design can be implemented in small form-factor FPGAs that may be present in IoT devices, or it can be used to design a custom chip for specific IoT applications.</p>\n<p><strong>ML enabled Open Radio Access Network (O-RAN): </strong>The PIs studied the optimization of the O-RAN architecture using ML applications running on the O-RAN intelligent controllers and extended them to the use case of applications running on the centralized unit/distributed unit of the base station directly. Then, they leveraged orchestration and virtualization techniques to study the intelligent instantiation of O-RAN components on a shared infrastructure and on digital twins for O-RAN, as well as energy efficiency issues, also open-sourcing tools for Open RAN experimentation. This was done by combining traditional optimization techniques that are leveraged to deploy ML applications using different agent architectures. Finally, they studied the impact of different security mechanisms on the O-RAN architecture, interfaces, and messaging procedures by evaluating the tradeoffs of various encryption techniques on metrics such as throughput and latency.</p>\n<p><strong>Broader Impacts: </strong>Seven Ph.D. students were involved in the project during its duration. Research findings were disseminated in 12 conference and 20 journal publications (three under review). Results were further disseminated through invited seminars and keynotes at academic institutions in the US as well as internationally. Our code was made publicly available and shared via github repositories.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/29/2024<br>\nModified by: Kaushik&nbsp;R&nbsp;Chowdhury</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe project resulted in several foundational advancements in the use machine learning (ML) for wireless communications at the physical layer of the protocol stack. \n\n\nML for Optimizing Beamforming. The PIs studied how millimeter-wave band beamforming could be enhanced through ML. For this, the team first explored how to use ML for estimating the channel state information, which can then be used to appropriately set the weights of the antenna array for directional beams. However, this approach required coordination between the transmitter and receiver side. The PIs enhanced this work by designing a method that does not require pilot sequences from the transmitter, nor any beam sweeping or synchronization from the receiver-side. This is achieved by inferring (i) the angle at which signals arrive at the receiver and (ii) the actual beam being used by the transmitter through waveform-level deep learning on ongoing transmissions between the transmitter to other receivers.\n\n\nML for Wireless Signal Sensing Classification. The PIs proposed methods for classifying waveforms under different environmental conditions. In one instance, the team applied tiny modifications to the waveform to strengthen its features according to the current channel conditions, thus maximizing the detection accuracy at the receiver side. In another instance, the team created time-frequency spectrograms from the received signals and then trained well-known object detection models for detecting weak or overlapping signals that are present under a stronger signal. The PIs demonstrated how radar signals could be detected under regular cellular signals in this work. Furthermore, they studied how to identify a specific emitter through deep learning methods that analyze subtle alterations introduced in the transmitted signals due to process variations during manufacturing. They showed how to apply these methods for identifying specific unmanned aerial systems and wireless base stations by conducting experiments over the NSF PAWR platforms. Finally, this research direction also resulted in methods where intentional and subtle distortions introduced to the pilot signals could be detected at the receiver side, thus allowing a low-bandwidth control channel that is otherwise undetectable. \n\n\nAI-native Receivers. There is an increasing trend towards swapping traditional signal processing blocks within the wireless received with their ML counterparts. The project showed how to compose a receiver architecture by specialized designed channel estimator, demapper, and error corrector (decoder) neural networks. Using both simulated and over-the-air datasets, this work showed that these neural networks perform better than their non-ML counterparts. The PIs also explored methods to compress these models using different pruning and quantization methods, and then implemented them on Field Programmable Gate Arrays (FPGA) to demonstrate reduced computational complexity during real-time operation. A major outcome is that this prototype design can be implemented in small form-factor FPGAs that may be present in IoT devices, or it can be used to design a custom chip for specific IoT applications.\n\n\nML enabled Open Radio Access Network (O-RAN): The PIs studied the optimization of the O-RAN architecture using ML applications running on the O-RAN intelligent controllers and extended them to the use case of applications running on the centralized unit/distributed unit of the base station directly. Then, they leveraged orchestration and virtualization techniques to study the intelligent instantiation of O-RAN components on a shared infrastructure and on digital twins for O-RAN, as well as energy efficiency issues, also open-sourcing tools for Open RAN experimentation. This was done by combining traditional optimization techniques that are leveraged to deploy ML applications using different agent architectures. Finally, they studied the impact of different security mechanisms on the O-RAN architecture, interfaces, and messaging procedures by evaluating the tradeoffs of various encryption techniques on metrics such as throughput and latency.\n\n\nBroader Impacts: Seven Ph.D. students were involved in the project during its duration. Research findings were disseminated in 12 conference and 20 journal publications (three under review). Results were further disseminated through invited seminars and keynotes at academic institutions in the US as well as internationally. Our code was made publicly available and shared via github repositories.\n\n\n\t\t\t\t\tLast Modified: 01/29/2024\n\n\t\t\t\t\tSubmitted by: KaushikRChowdhury\n"
 }
}