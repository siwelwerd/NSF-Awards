{
 "awd_id": "1928434",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FW-HTF-RM: Collaborative Research: Augmenting Social Media Content Moderation",
 "cfda_num": "47.041, 47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 347685.0,
 "awd_amount": 417039.0,
 "awd_min_amd_letter_date": "2019-09-04",
 "awd_max_amd_letter_date": "2023-07-20",
 "awd_abstract_narration": "Around the world, users of social media platforms generate millions of comments, videos, and photos per day. Within this content is dangerous material such as child pornography, sex trafficking, and terrorist propaganda. Though platforms leverage algorithmic systems to facilitate detection and removal of problematic content, decisions about whether to remove content, whether it's as benign as an off-topic comment or as dangerous as self-harm or abuse videos, are often made by humans. Companies are hiring moderators by the thousands and tens of thousands work as volunteer moderators. This work involves economic, emotional, and often physical safety risks. With social media content moderation as the focus of work and the content moderators as the workers, this project facilitates the human-technology partnership by designing new technologies to augment moderator performance. The project will improve moderators' quality of life, augment their capabilities, and help society understand how moderation decisions are made and how to support the workers who help keep the internet open and enjoyable. These advances will enable moderation efforts to keep pace with user-generated content and ensure that problematic content does not overwhelm internet users. The project includes outreach and engagement activities with academic, industry, policy-makers, and the public that ensure the project's findings and tools support broad stakeholders impacted by user-generated content and its moderation.\r\n\r\nSpecifically, the project involves five main research objectives that will be met through qualitative, historical, experimental, and computational research approaches. First, the project will improve understanding of human-in-the-loop decision making practices and mental models of moderation by conducting interviews and observations with moderators across different content domains. Second, it will assess the socioeconomic impact of technology-augmented moderation through industry personnel interviews. Third, the project will test interventions to decrease the emotional toll on human moderators and optimize their performance through a series of experiments utilizing theories of stress alleviation. Fourth, the project will design, develop, and test a suite of cognitive assistance tools for live streaming moderators. These tools will focus on removing easy decisions and helping moderators dynamically manage their emotional and cognitive capabilities. Finally, the project will employ a historical perspective to analyze companies' content moderation policies to inform legal and platform policies.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Libby",
   "pi_last_name": "Hemphill",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Libby Hemphill",
   "pi_email_addr": "libbyh@umich.edu",
   "nsf_id": "000579722",
   "pi_start_date": "2019-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "3003 South State Street",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091274",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "103Y00",
   "pgm_ele_name": "FW-HTF Futr Wrk Hum-Tech Frntr"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 347685.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 69354.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-e2467a74-7fff-1fe5-89f1-3c441d2f8aa7\">\r\n<p dir=\"ltr\"><span>Our goal was to create tools for online content moderators that would reduce their cognitive load and overall workload. We were especially interested in helping moderators who are volunteers. We focused on their workloads, not on the content or communities they were responsible for moderating. We interviewed Reddit moderators and worked with them to develop AppealMod, a bot that helps moderators address bans and ban appeals. Moderators can set up AppealMod on any subreddit they moderate. In our field experiments, we found that the AppealMod process reduces moderator workloads by 70% without impacting the decisions made or negatively impacting the community. The code for AppealMod is open-source, and any moderator can sign up to use it at </span><a href=\"http://appealmod.com\"><span>http://appealmod.com</span></a><span>. We traveled to conferences that moderators attend to advertise the tool and get more feedback about how to improve it.</span></p>\r\n<p dir=\"ltr\"><span><span><img src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXckIm5N1UefIBzFaw9hX5kI--xMSVbd3Lth4Suo0Xd_LwKsMJkYKhFM9SyILDQfCwlrC3mKi0UFvuZ1H-Pud6fS-2tx1JP03krOxz6joR7BK0H6_4rrESYAdFkNt0qfaEtykqIO?key=brwPJtkZqznzxG7u2ijgVFxd\" alt=\"\" width=\"639\" height=\"345\" /></span></span></p>\r\n<p dir=\"ltr\"><span>We also studied Twitch chats to understand how moderator behavior and other users&rsquo; behavior impacts other users. Our goal was to identify opportunities to build assistants for Twitch moderators. We found that people using Twitch chat emulate moderator behaviors. We also found that users &ldquo;pay it forward&rdquo; and give one another gifts when they receive them. This suggests assistants could help moderators model the kind of behavior they want to see in the chat.&nbsp;</span></p>\r\n<p dir=\"ltr\"><span>Our project provided PhD students opportunities to learn new research methods, to participate in professional conferences, and to improve their independent research skills.</span></p>\r\n</span></p><br>\n<p>\n Last Modified: 01/27/2025<br>\nModified by: Libby&nbsp;Hemphill</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\r\n\n\nOur goal was to create tools for online content moderators that would reduce their cognitive load and overall workload. We were especially interested in helping moderators who are volunteers. We focused on their workloads, not on the content or communities they were responsible for moderating. We interviewed Reddit moderators and worked with them to develop AppealMod, a bot that helps moderators address bans and ban appeals. Moderators can set up AppealMod on any subreddit they moderate. In our field experiments, we found that the AppealMod process reduces moderator workloads by 70% without impacting the decisions made or negatively impacting the community. The code for AppealMod is open-source, and any moderator can sign up to use it at http://appealmod.com. We traveled to conferences that moderators attend to advertise the tool and get more feedback about how to improve it.\r\n\n\n\r\n\n\nWe also studied Twitch chats to understand how moderator behavior and other users behavior impacts other users. Our goal was to identify opportunities to build assistants for Twitch moderators. We found that people using Twitch chat emulate moderator behaviors. We also found that users pay it forward and give one another gifts when they receive them. This suggests assistants could help moderators model the kind of behavior they want to see in the chat.\r\n\n\nOur project provided PhD students opportunities to learn new research methods, to participate in professional conferences, and to improve their independent research skills.\r\n\t\t\t\t\tLast Modified: 01/27/2025\n\n\t\t\t\t\tSubmitted by: LibbyHemphill\n"
 }
}