{
 "awd_id": "1854737",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: LDPD-Net: A Framework for Accelerated Architectures for Low-Density Permuted-Diagonal Deep Neural Networks",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2018-08-15",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 224997.0,
 "awd_amount": 224997.0,
 "awd_min_amd_letter_date": "2018-10-25",
 "awd_max_amd_letter_date": "2018-10-25",
 "awd_abstract_narration": "Deep learning has emerged as an important form of machine-learning where multiple layers of neural networks can learn the system function from available input-output data. Deep learning has outperformed traditional machine-learning algorithms based on feature engineering in fields such as image recognition, healthcare, and autonomous vehicles. These are widely used in cloud computing where large amount of computational resources are available. Deep neural networks are typically trained using graphic processing units (GPUs) or tensor processing units (TPUs). The training time and energy consumption grow with the complexity of the neural network. This project attempts to impose sparsity and regularity as constraints on the structure of the deep neural networks to reduce complexity and energy consumption by orders of magnitude, possibly at the expense of a slight degradation in the performance. The impacts lie in the formulation of a new family of structures for neural networks referred to as Low-Density Permuted Diagonal Network or LDPD-Net. The approach will enable the deployment of deep neural networks in energy-constrained and resource-constrained embedded platforms for inference tasks, including, but not limited to, unmanned vehicles/aerial systems, personalized healthcare, wearable and implantable devices, and mobile intelligent systems. In addition, the design methodology/techniques developed in this project can facilitate investigation of efficient computing of other matrix/tensor-based big data processing and analysis approaches. These approaches may also find applications in data-driven neuroscience and data-driven signal processing. In addition to graduate students, the project will involve undergraduates via senior design projects and research experiences for undergraduates. The results of the project will be disseminated to the broader community by publications, presentations, talks at various industries and other academic institutions. \r\n\r\nThe main barriers to wide adoption of deep learning networks include computational resource constraints and energy consumption constraints. These barriers can be relaxed by imposing sparsity and regularity among different layers of the deep neural network. The proposed low-density permuted-diagonal (LDPD) network can lead to orders of magnitude reduction in computation complexity, storage space and energy consumption. The LDPD-Net will not be retrained by first training a regular network and then only retaining the weights corresponding to the LDPD-Net. Instead, the proposed network will be trained from scratch. The proposed LDPD-Net can enable scaling of the network for a specified computational platform. The proposed research has three thrusts: 1) develop novel resource-constrained and energy-constrained inference and training systems;  2) develop novel efficient hardware architectures that can fully exploit the advantages of the LDPD-Net to achieve high performance; and 3) perform novel software and hardware co-design and co-optimization to explore the design space of the LDPD-Net. Using these, the efficacy of the proposed LDPD-net will be validated and evaluated, via software implementations on high-performance systems, low-power embedded systems, and a hardware prototype on FPGA development boards.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bo",
   "pi_last_name": "Yuan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bo Yuan",
   "pi_email_addr": "bo.yuan@soe.rutgers.edu",
   "nsf_id": "000704451",
   "pi_start_date": "2018-10-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088543925",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 224997.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This award has brought the research outcomes on both algorithm and hardware sides and across different domains. On the algorithm side, new low-cost deep neural network architecture, together with the corresponding inference and training approaches, are developed. These approaches brings low memory cost and computational burden, thereby making the execution of the originally expensive deep neural networks much faster and affordable. On the hardware side, new deep neural network hardware accelerator is developed and implemented. This new computing hardware is specifically customized to support the proposed new neural network model, and it can fully leverage the algorithmic benefits provided by the model to maximize hardware performance, in terms of energy efficiency, throughput, area efficiency. As a result, such algorithm and hardware co-design framework brings very significant improvement on the operational efficiency of the state-of-the-art deep neural network. The execution of powerful AI technique can be now realized in a more economic, greener and affordable way, on many low-end embedded and mobile devices, thereby further promoting the democratic deployment of AI. This award also promotes the STEM education and workforce in United States. Several graduate students are supported and trained by this award. Their research outcomes are published and disseminated in top AI and hardware conferences and journals, which further attract more students to participate in the AI and semiconductor research activities. &nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/06/2022<br>\n\t\t\t\t\tModified by: Bo&nbsp;Yuan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis award has brought the research outcomes on both algorithm and hardware sides and across different domains. On the algorithm side, new low-cost deep neural network architecture, together with the corresponding inference and training approaches, are developed. These approaches brings low memory cost and computational burden, thereby making the execution of the originally expensive deep neural networks much faster and affordable. On the hardware side, new deep neural network hardware accelerator is developed and implemented. This new computing hardware is specifically customized to support the proposed new neural network model, and it can fully leverage the algorithmic benefits provided by the model to maximize hardware performance, in terms of energy efficiency, throughput, area efficiency. As a result, such algorithm and hardware co-design framework brings very significant improvement on the operational efficiency of the state-of-the-art deep neural network. The execution of powerful AI technique can be now realized in a more economic, greener and affordable way, on many low-end embedded and mobile devices, thereby further promoting the democratic deployment of AI. This award also promotes the STEM education and workforce in United States. Several graduate students are supported and trained by this award. Their research outcomes are published and disseminated in top AI and hardware conferences and journals, which further attract more students to participate in the AI and semiconductor research activities.  \n\n \n\n\t\t\t\t\tLast Modified: 02/06/2022\n\n\t\t\t\t\tSubmitted by: Bo Yuan"
 }
}