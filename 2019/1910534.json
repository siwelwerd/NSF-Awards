{
 "awd_id": "1910534",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Threshold Functions--Derandomization, Testing and Applications",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922095",
 "po_email": "kwimmer@nsf.gov",
 "po_sign_block_name": "Karl Wimmer",
 "awd_eff_date": "2020-01-01",
 "awd_exp_date": "2024-12-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2019-05-17",
 "awd_max_amd_letter_date": "2019-05-17",
 "awd_abstract_narration": "Binary classification rules (or Boolean functions) are a standard way to get a single binary (i.e., yes / no) decision from a large number of inputs -- an example is when each voter casts an up / down vote  and the outcome is up / down depending on which motion receives a majority of the votes. A slightly more involved example is when the function is not symmetric to all its inputs -- as an example, in the European Union, each country is assigned a different \"weight\" and a motion passes or fails depending on whether or not the \"weighted majority\" votes yes or no. Such a classification rule (or Boolean function) is called a linear threshold function (LTF) in mathematics and appears frequently in a diverse range of areas including machine learning, computational complexity theory, electrical engineering, mathematics, voting theory and even neuroscience (where they were first studied as a way to model neurons in the human brain). While simple and intuitive from a definitional point of view, LTFs are sometimes inadequate to model more complicated types of classification rules (useful in areas such as machine learning). In this project, the investigator will study two natural generalizations of LTFs which are significantly more expressive than LTFs and overcome this barrier; on the other hand, their definitional proximity to LTFs make them amenable to rigorous mathematical analysis. Aside from studying these functions through the lens of computational complexity theory, this project will also explore applications of these functions to areas such as machine learning, quantum computing and information theory (i.e., the mathematical theory of communication). The project will train graduate students who will achieve fluency in complexity theory and one or more of these application areas. In addition, several of these topics will also be incorporated in a new graduate course on Boolean functions taught by the investigator at the University of Pennsylvania. \r\n \r\n\r\nThe first generalization is a so-called \"Polynomial threshold function\" (or PTF) which, roughly speaking, allows us to model \"higher order effects\" (as opposed to LTFs which only allow for \"linear effects\" of the inputs). The second generalization is a so-called \"Intersection of LTFs\" which is a Boolean function obtained by applying several LTFs at once.  Intersection of LTFs are also a special case of convex bodies, a widely studied object in computer science and mathematics. Jointly referred to as threshold functions, these function classes admit simple geometric interpretations but remain poorly understood from a complexity theoretic point of view. The investigator will study these functions from three distinct vantage points: (i) Derandomization -- i.e., design of efficient deterministic algorithms to compute the probability that a random input satisfies a given threshold function. (ii) Property testing -- i.e., given black-box access to a function, design of an efficient algorithm to test the hypothesis that the given function is a threshold function (either a PTF or an intersection of LTFs). (iii) Harnessing the incredible expressivity of these functions towards applications in information theory and quantum complexity theory.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anindya",
   "pi_last_name": "De",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anindya De",
   "pi_email_addr": "de.anindya@gmail.com",
   "nsf_id": "000726648",
   "pi_start_date": "2019-05-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of the University of Pennsylvania",
  "perf_str_addr": "3451 Walnut St; 5th fl",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7927",
   "pgm_ref_txt": "COMPLEXITY & CRYPTOGRAPHY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-733e8367-7fff-9657-9a52-6a0ceb4abfab\">\r\n<p dir=\"ltr\"><span>The PI and his collaborators successfully studied the fundamental class of threshold functions which are a generalization of linear functions and are intended to model non-linear effects of the input variables on the output (as opposed to linear functions which only allow for modeling of linear effects). The PI studied both (i) polynomial threshold functions (PTFs) (which model non-linear low-order effects) and (ii) intersection of halfspaces, aka convex sets (which model the effect of multiple linear constraints at once). These functions have been widely studied in theoretical computer science, machine learning as well as convex geometry, probability theory and statistics. These functions were studied from three different vantage points &ndash; (i) derandomization &ndash; where the goal is to design efficient algorithms for a basic estimation task, namely decide if a given randomly chosen input satisfies the threshold function; (ii) property testing &ndash; where given access to a statistical model, decide if it is either exactly or approximately a threshold function; (iii) harness the expressivity of threshold functions for applications in other areas such as information theory, probability theory and machine learning.&nbsp;</span></p>\r\n<br /><br />\r\n<p dir=\"ltr\"><span>With his collaborators, the PI initiated the study of approximation of convex sets by convex sets with small facet complexity. For the Gaussian distribution, the PI obtained&nbsp; tight upper and lower bounds on the quality of such approximations.&nbsp; These approximations have direct implications on algorithms for derandomization, property testing and learnability of convex sets. Motivated by applications in machine learning, the PI and his collaborators also initiated a new line of work in property testing &ndash; called relative error property testing &ndash; where the goal is to model hypothesis testing in applications where the target data is very sparse in the ambient space. </span><span>In addition, the PIs worked on several other problems in statistical inference where the goal is to do hypothesis testing in presence of noise &ndash; this includes problems like &ldquo;testability of sparse linear equations&rdquo; and &ldquo;sparse Fourier transform&rdquo; which are motivated by problems in signal processing. </span><span>The project has led to a number of research publications which have been disseminated by presentations in conferences and seminars. The resulting manuscripts are available publicly on ArXiV.&nbsp;</span></p>\r\n<p dir=\"ltr\"><span>&nbsp;</span></p>\r\n<p dir=\"ltr\"><span>In terms of broader impacts, besides the scientific impact of the work, this award contributed to the development of human resources for the STEM and academic workforce.&nbsp; A number of Ph.D. students at University of Pennsylvania received partial funding support and research training as a result of this award. </span></p>\r\n<div><span><br /></span></div>\r\n</span></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 04/22/2025<br>\nModified by: Anindya&nbsp;De</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\r\n\n\nThe PI and his collaborators successfully studied the fundamental class of threshold functions which are a generalization of linear functions and are intended to model non-linear effects of the input variables on the output (as opposed to linear functions which only allow for modeling of linear effects). The PI studied both (i) polynomial threshold functions (PTFs) (which model non-linear low-order effects) and (ii) intersection of halfspaces, aka convex sets (which model the effect of multiple linear constraints at once). These functions have been widely studied in theoretical computer science, machine learning as well as convex geometry, probability theory and statistics. These functions were studied from three different vantage points  (i) derandomization  where the goal is to design efficient algorithms for a basic estimation task, namely decide if a given randomly chosen input satisfies the threshold function; (ii) property testing  where given access to a statistical model, decide if it is either exactly or approximately a threshold function; (iii) harness the expressivity of threshold functions for applications in other areas such as information theory, probability theory and machine learning.\r\n\n\n\r\n\n\nWith his collaborators, the PI initiated the study of approximation of convex sets by convex sets with small facet complexity. For the Gaussian distribution, the PI obtained tight upper and lower bounds on the quality of such approximations. These approximations have direct implications on algorithms for derandomization, property testing and learnability of convex sets. Motivated by applications in machine learning, the PI and his collaborators also initiated a new line of work in property testing  called relative error property testing  where the goal is to model hypothesis testing in applications where the target data is very sparse in the ambient space. In addition, the PIs worked on several other problems in statistical inference where the goal is to do hypothesis testing in presence of noise  this includes problems like testability of sparse linear equations and sparse Fourier transform which are motivated by problems in signal processing. The project has led to a number of research publications which have been disseminated by presentations in conferences and seminars. The resulting manuscripts are available publicly on ArXiV.\r\n\n\n\r\n\n\nIn terms of broader impacts, besides the scientific impact of the work, this award contributed to the development of human resources for the STEM and academic workforce. A number of Ph.D. students at University of Pennsylvania received partial funding support and research training as a result of this award. \r\n\n\r\n\r\n\n\n\t\t\t\t\tLast Modified: 04/22/2025\n\n\t\t\t\t\tSubmitted by: AnindyaDe\n"
 }
}