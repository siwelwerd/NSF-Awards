{
 "awd_id": "1911235",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF:Small:RUI: Optimizing Compiler Instruction Scheduling Using GPU-Accelerated Intelligent Search",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 293277.0,
 "awd_amount": 293277.0,
 "awd_min_amd_letter_date": "2019-06-14",
 "awd_max_amd_letter_date": "2019-06-14",
 "awd_abstract_narration": "A compiler translates a program written in a programming language into machine code. In addition to performing the translation, the compiler also performs optimizations that improve the quality of the generated code by increasing its performance and reducing its energy consumption. In this research project, the investigators will use a combination of intelligent search techniques and parallel computing to develop enhanced compiler-optimization algorithms that will improve the performance of a wide range of programs running on the Central Processing Unit (CPU) and/or the Graphics Processing Unit (GPU). The GPU's parallel computing power is widely used to accelerate the implementations of certain Artificial Intelligence (AI) algorithms. The project's novelties are using intelligent search techniques to generate more efficient code for both CPUs and GPUs, and taking advantage of modern parallel computing to maximize the speed of these intelligent search techniques. The project's impacts are developing algorithms for parallelizing intelligent search techniques and using these algorithms to optimize the performance of a wide range of applications running on the CPU and/or the GPU.     \r\n \r\nMore specifically, this research project addresses pre-allocation instruction scheduling, which is a long-standing and fundamentally important problem in compiler optimizations. Current production compilers solve this problem using heuristic approaches. Experimental evaluation has shown that existing heuristics may produce poor-quality code in terms of both performance and energy consumption, especially in compiling for the GPU. This project uses today's powerful parallel computing to apply two specific intelligent search techniques, namely Branch-and-Bound (B&B) and Ant Colony Optimization (ACO), to this problem. Parallel computing on the GPU is used to make these compute-intensive search techniques feasible. The proposed intelligent algorithms are also used to generate more efficient code for the GPU itself, thus allowing future GPUs to deliver higher performance for future AI programs. The project also develops parallel GPU-based versions of these algorithms to both minimize compilation time and to explore the limits of the performance gain that can be achieved using intelligent search.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ghassan",
   "pi_last_name": "Shobaki",
   "pi_mid_init": "O",
   "pi_sufx_name": "",
   "pi_full_name": "Ghassan O Shobaki",
   "pi_email_addr": "ghassan.shobaki@csus.edu",
   "nsf_id": "000723932",
   "pi_start_date": "2019-06-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Vahl Scott",
   "pi_last_name": "Gordon",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Vahl Scott Gordon",
   "pi_email_addr": "gordonvs@ecs.csus.edu",
   "nsf_id": "000463076",
   "pi_start_date": "2019-06-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Pinar",
   "pi_last_name": "Muyan-Ozcelik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pinar Muyan-Ozcelik",
   "pi_email_addr": "pmuyan@csus.edu",
   "nsf_id": "000792360",
   "pi_start_date": "2019-06-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University Enterprises, Incorporated",
  "inst_street_address": "6000 J ST STE 3700",
  "inst_street_address_2": "BOOKSTORE BLDG",
  "inst_city_name": "SACRAMENTO",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9162786402",
  "inst_zip_code": "958192605",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "CA07",
  "org_lgl_bus_name": "UNIVERSITY ENTERPRISES, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "N58JMBDDUGU7"
 },
 "perf_inst": {
  "perf_inst_name": "California State University, Sacramento",
  "perf_str_addr": "6000 J Street",
  "perf_city_name": "Sacramento",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "958196000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "CA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 293277.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"Default\">&nbsp;</p>\n<p class=\"Default\">In this project, we used a combination of intelligent-search techniques (Branch-and-Bound (B&amp;B) and Ant Colony Optimization (ACO)) and parallel computing to develop precise solutions for the compiler instruction-scheduling problem. More specifically, we accomplished the following.</p>\n<p class=\"Default\">&nbsp;1. We developed a B&amp;B instruction-scheduling algorithm that optimizes both register pressure (RP) and instruction-level parallelism (ILP) on the GPU. The results of our experimental evaluation using PlaidML on an AMD GPU show that the proposed algorithm speeds up most benchmarks by up to 31% relative to AMD&rsquo;s production scheduler, with a geometric-mean improvement of 5.5%. The results have been published at the <em>International Symposium on Code Generation and Optimization (CGO) </em>in 2020.</p>\n<p>DOI:&nbsp; <a href=\"https://doi.org/10.1145/3368826.3377918\">10.1145/3368826.3377918</a></p>\n<p class=\"Default\">&nbsp;</p>\n<p class=\"Default\">2. We developed an ACO instruction-scheduling algorithm that optimizes RP and ILP on the GPU. The results of our experimental evaluation using PlaidML show that the proposed algorithm gives a geometric-mean improvement of 7.14% in execution speed relative to AMD&rsquo;s production scheduler. The proposed ACO algorithm gives approximately the same execution-time results as the B&amp;B algorithm, with each algorithm outperforming the other on a substantial number of hard scheduling regions. The results have been published in the <em>ACM Transactions on Architecture and Code Optimization (TACO) </em>in 2022.</p>\n<p>DOI: 10.1145/3505558</p>\n<p class=\"Default\">&nbsp;</p>\n<p class=\"Default\">3. We developed a parallel ACO instruction-scheduling algorithm for the GPU that also runs on the GPU. To the best of our knowledge, our work is the first successful attempt to parallelize a compiler optimization algorithm on the GPU. The results of our experimental evaluation using rocPRIM show that parallel ACO-based scheduling on the GPU runs up to 27 times faster than sequential ACO-based scheduling on the CPU, and this leads to reducing the total compile time of the rocPRIM benchmarks by 21%. ACO-based scheduling improves the execution-speed of the compiled benchmarks by up to 74% relative to AMD's production scheduler. The results have been accepted for publication at the <em>International Symposium on Code Generation and Optimization (CGO) </em>in 2024.</p>\n<p class=\"Default\">&nbsp;</p>\n<p class=\"Default\">4. We developed a parallel B&amp;B algorithm for the Sequential Ordering Problem (SOP). The algorithm runs on a multi-core CPU. We evaluated our parallel B&amp;B algorithm experimentally using SOPLIB and TSPLIB on a 32-core CPU. The results show that our algorithm gives geometric-mean speedups of 72x and 20x on the medium-difficulty SOPLIB and TSPLIB instances, respectively. On the hard instances, it solves 12 instances that the sequential algorithm does not solve, with geometric-mean speedups of 16x on SOPLIB and 32x on TSPLIB. Super-linear speedups up to 366x are seen on 16 instances. The results have been published in the <em>Journal of Parallel and Distributed Computing (JPDC) </em>in 2023.</p>\n<p>DOI: <a title=\"Persistent link using digital object identifier\" href=\"https://doi.org/10.1016/j.jpdc.2022.10.007\" target=\"_blank\">10.1016/j.jpdc.2022.10.007</a></p>\n<p>This was preceded by a poster at the <em>Principles and Practice of Parallel Programming (PPoPP)</em> in 2022.</p>\n<p>DOI: 10.1145/3503221.3508415</p>\n<p>&nbsp;</p>\n<p>5. Based on the parallel B&amp;B algorithm for the SOP, we developed a parallel B&amp;B algorithm for the instruction-scheduling problem. The algorithm runs on a multi-core CPU and generates code for CPU and GPU targets. We evaluated our algorithm experimentally using the rocPRIM benchmarks for an AMD GPU target with the compilation carried on a 16-core CPU. The results show that our algorithm achieves an average speedup of 6.1 across the interesting scheduling regions, which amounts to a 1.2 speedup of the overall scheduling time, while still producing the same execution-time performance improvement of 5% relative to AMD&rsquo;s scheduler.</p>\n<p class=\"Default\">&nbsp;</p>\n<p class=\"Default\">6. We developed a hybrid algorithm that combines parallel B&amp;B and a strong heuristic for solving the SOP. A parallel B&amp;B algorithm is run in parallel with the Lin-Kernighan-Helsgaun (LKH) heuristic, which is known to be one of the strongest heuristics for solving the SOP. The results of our experimental evaluation using SOPLIB and TSPLIB show that the combined algorithm gives significantly better performance than any of the B&amp;B algorithm or the LKH heuristic individually. For example, the proposed algorithm delivers a geometric-mean speedup of 10.17 relative to LKH on the medium-difficulty SOPLIB instances. The results have been published at <em>the International Workshop on Parallel and Distributed Algorithms for Decision Sciences (PDADS) </em>in 2023.</p>\n<p class=\"Default\">DOI: <a href=\"https://doi.org/10.1145/3605731.3608929\">10.1145/3605731.3608929</a></p>\n<p class=\"Default\">&nbsp;</p>\n<p class=\"Default\">7. We developed graph transformations that speedup the intelligent-search algorithms (B&amp;B and ACO) by reducing the size of the solution space. The effect of the proposed transformations was evaluated experimentally on both CPU and GPU targets. The results show that the proposed transformations significantly reduce the compile time while giving approximately the same execution-time performance. The results were published at the <em>International Conference on Compiler Construction (CC)</em> in 2022.</p>\n<p>DOI: 10.1145/3497776.3517771</p>\n<p class=\"Default\">&nbsp;</p>\n<p class=\"Default\">This research project also had a great positive impact on the careers of the participating students. The compiler experience that the students gained by participating in this research project enabled six of them to land jobs as compiler engineers at leading companies in the industry. The research experience also enabled two participating students to earn admissions to the graduate programs at Carnegie Mellon and UC Davis.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/27/2024<br>\nModified by: Ghassan&nbsp;O&nbsp;Shobaki</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\nIn this project, we used a combination of intelligent-search techniques (Branch-and-Bound (B&B) and Ant Colony Optimization (ACO)) and parallel computing to develop precise solutions for the compiler instruction-scheduling problem. More specifically, we accomplished the following.\n\n\n1. We developed a B&B instruction-scheduling algorithm that optimizes both register pressure (RP) and instruction-level parallelism (ILP) on the GPU. The results of our experimental evaluation using PlaidML on an AMD GPU show that the proposed algorithm speeds up most benchmarks by up to 31% relative to AMDs production scheduler, with a geometric-mean improvement of 5.5%. The results have been published at the International Symposium on Code Generation and Optimization (CGO) in 2020.\n\n\nDOI: 10.1145/3368826.3377918\n\n\n\n\n\n2. We developed an ACO instruction-scheduling algorithm that optimizes RP and ILP on the GPU. The results of our experimental evaluation using PlaidML show that the proposed algorithm gives a geometric-mean improvement of 7.14% in execution speed relative to AMDs production scheduler. The proposed ACO algorithm gives approximately the same execution-time results as the B&B algorithm, with each algorithm outperforming the other on a substantial number of hard scheduling regions. The results have been published in the ACM Transactions on Architecture and Code Optimization (TACO) in 2022.\n\n\nDOI: 10.1145/3505558\n\n\n\n\n\n3. We developed a parallel ACO instruction-scheduling algorithm for the GPU that also runs on the GPU. To the best of our knowledge, our work is the first successful attempt to parallelize a compiler optimization algorithm on the GPU. The results of our experimental evaluation using rocPRIM show that parallel ACO-based scheduling on the GPU runs up to 27 times faster than sequential ACO-based scheduling on the CPU, and this leads to reducing the total compile time of the rocPRIM benchmarks by 21%. ACO-based scheduling improves the execution-speed of the compiled benchmarks by up to 74% relative to AMD's production scheduler. The results have been accepted for publication at the International Symposium on Code Generation and Optimization (CGO) in 2024.\n\n\n\n\n\n4. We developed a parallel B&B algorithm for the Sequential Ordering Problem (SOP). The algorithm runs on a multi-core CPU. We evaluated our parallel B&B algorithm experimentally using SOPLIB and TSPLIB on a 32-core CPU. The results show that our algorithm gives geometric-mean speedups of 72x and 20x on the medium-difficulty SOPLIB and TSPLIB instances, respectively. On the hard instances, it solves 12 instances that the sequential algorithm does not solve, with geometric-mean speedups of 16x on SOPLIB and 32x on TSPLIB. Super-linear speedups up to 366x are seen on 16 instances. The results have been published in the Journal of Parallel and Distributed Computing (JPDC) in 2023.\n\n\nDOI: 10.1016/j.jpdc.2022.10.007\n\n\nThis was preceded by a poster at the Principles and Practice of Parallel Programming (PPoPP) in 2022.\n\n\nDOI: 10.1145/3503221.3508415\n\n\n\n\n\n5. Based on the parallel B&B algorithm for the SOP, we developed a parallel B&B algorithm for the instruction-scheduling problem. The algorithm runs on a multi-core CPU and generates code for CPU and GPU targets. We evaluated our algorithm experimentally using the rocPRIM benchmarks for an AMD GPU target with the compilation carried on a 16-core CPU. The results show that our algorithm achieves an average speedup of 6.1 across the interesting scheduling regions, which amounts to a 1.2 speedup of the overall scheduling time, while still producing the same execution-time performance improvement of 5% relative to AMDs scheduler.\n\n\n\n\n\n6. We developed a hybrid algorithm that combines parallel B&B and a strong heuristic for solving the SOP. A parallel B&B algorithm is run in parallel with the Lin-Kernighan-Helsgaun (LKH) heuristic, which is known to be one of the strongest heuristics for solving the SOP. The results of our experimental evaluation using SOPLIB and TSPLIB show that the combined algorithm gives significantly better performance than any of the B&B algorithm or the LKH heuristic individually. For example, the proposed algorithm delivers a geometric-mean speedup of 10.17 relative to LKH on the medium-difficulty SOPLIB instances. The results have been published at the International Workshop on Parallel and Distributed Algorithms for Decision Sciences (PDADS) in 2023.\n\n\nDOI: 10.1145/3605731.3608929\n\n\n\n\n\n7. We developed graph transformations that speedup the intelligent-search algorithms (B&B and ACO) by reducing the size of the solution space. The effect of the proposed transformations was evaluated experimentally on both CPU and GPU targets. The results show that the proposed transformations significantly reduce the compile time while giving approximately the same execution-time performance. The results were published at the International Conference on Compiler Construction (CC) in 2022.\n\n\nDOI: 10.1145/3497776.3517771\n\n\n\n\n\nThis research project also had a great positive impact on the careers of the participating students. The compiler experience that the students gained by participating in this research project enabled six of them to land jobs as compiler engineers at leading companies in the industry. The research experience also enabled two participating students to earn admissions to the graduate programs at Carnegie Mellon and UC Davis.\n\n\n\t\t\t\t\tLast Modified: 02/27/2024\n\n\t\t\t\t\tSubmitted by: GhassanOShobaki\n"
 }
}