{
 "awd_id": "1931628",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Collaborative Research: F: Efficient Distributed Computation of Large-Scale Graph Problems in Epidemiology and Contagion Dynamics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-02-27",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 330833.0,
 "awd_amount": 346832.0,
 "awd_min_amd_letter_date": "2019-07-23",
 "awd_max_amd_letter_date": "2019-07-23",
 "awd_abstract_narration": "A number of phenomena of societal importance, such as the spread of diseases and\r\ncontagion processes, can be modeled by stochastic processes on networks. The analysis \r\nand control of such network phenomena involve, at their heart, fundamental graph-theoretic problems. \r\nThe graphs encountered are typically of large-scale (having tens of millions of nodes); \r\nfurther, typical experimental analyses involve large designs with a number of parameters, \r\nleading to hundreds of thousands of graph computations. Novel methods for solving these problems\r\nare needed, since fast response times are critical to effective decision making.\r\nThe overarching goal of this project is to develop efficient distributed algorithms \r\nand associated lower bounds for graph-theoretic problems that arise in computational \r\nepidemiology and contagion dynamics.  This will have a significant impact on these specific \r\napplications, through more efficient algorithmic tools for enabling complex analyses.  \r\nThe project will also make fundamental contributions to the design and analysis of \r\ndistributed algorithms for graph problems in large-scale networks, and will\r\nresult in an algorithmic toolkit with building blocks for performing large-scale \r\ndistributed graph computation.  The project will lead to significant curriculum development \r\nfor undergraduate as well as graduate students, as well as public health analysts. \r\nFinally, the project will help in involving minority and underrepresented students in research. \r\n\r\nThe technical focus of the project will be on distributed algorithms for fundamental topics \r\nin graph algorithms such as graph connectivity, distances, subgraph analysis, and different\r\nkinds of centrality measures.  These topics underlie some of the recurring problems in the \r\nmodeling, simulation and analysis and control of different kinds of contagion processes.  \r\nFor all these problems, the project will focus on developing provably efficient distributed \r\nalgorithms and showing lower bounds under a message-passing distributed computing model. \r\nThe PIs will also develop efficient implementations of these algorithms, and evaluate their \r\nperformance and solution quality in real-world graphs arising in epidemiology.  The graphs \r\nthat arise in these applications have several novel characteristics, which will present new \r\nchallenges as well as opportunities for distributed computing.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anil Kumar",
   "pi_last_name": "Vullikanti",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Anil Kumar S Vullikanti",
   "pi_email_addr": "asv9v@virginia.edu",
   "nsf_id": "000117423",
   "pi_start_date": "2019-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Virginia Main Campus",
  "inst_street_address": "1001 EMMET ST N",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTESVILLE",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "4349244270",
  "inst_zip_code": "229034833",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "VA05",
  "org_lgl_bus_name": "RECTOR & VISITORS OF THE UNIVERSITY OF VIRGINIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJG6HU8PA4S5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Virginia Main Campus",
  "perf_str_addr": "PO Box 400195",
  "perf_city_name": "Charlottesville",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "229044195",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "VA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7796",
   "pgm_ref_txt": "ALGORITHMIC FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7934",
   "pgm_ref_txt": "PARAL/DISTRIBUTED ALGORITHMS"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 330832.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The major goals of this project were to develop a rigorous algorithmic theory of distributed large-scale graph computation, focusing, in particular, on important graph problems that arise in computational epidemiology and contagion dynamics. We worked on topics related to fundamental problems in graph algorithms, graph mining and network science, including connectivity, subgraph analysis, anomaly detection, community detection and controlling the dynamics of diffusion processes on networks. Our focus has been to develop algorithms which would scale to massive networks, of the type found in real-world applications, with rigorous performance and approximation guarantees. We have applied these methods for a number of problems in public health.</p>\n<p>&nbsp;</p>\n<p>Some of the key topics studied in the project and the significant results are:</p>\n<p>&nbsp;</p>\n<p>1. Parallel algorithms for random graph generation: This involves generating networks with characteristics similar to real world networks, especially those relevant for epidemic spread, using different random graph models. This is a challenging problem since most random graph models are inherently sequential. We have developed a general approach which allows random generation of massive networks from multiple models.</p>\n<p>&nbsp;</p>\n<p>2. Efficient parallel algorithms for detecting and counting paths and trees: these are very common problems in graphmining, since subgraph statistics can help in characterizing networks and identifying anomalous nodes and clusters. These problems are computationally very challenging. We developed parallel algorithms by adapting the classical color coding technique, which is a fixed parameter tractable technique, whose running time is polynomial when the subgraph size is fixed. We have explored a variety of parallel computing models.</p>\n<p>&nbsp;</p>\n<p>3. Efficient parallel algorithms for anomaly detection using network scan statistics: Scan statistics are a popular approach used for detecting \"hotspots\" and \"anomalies\" in spatio-temporal and network data. This methodology is based on hypothesis testing, and has also been extended to networked data. However, it becomes computationally very challenging in networks, since the problem reduces to finding a connected subgraph that maximizes a score function. We adapted the color coding technique for optimizing network scan statistics, and used them in a diverse set of public health applications. We developed parallel algorithms for network scan statistics, are able to scale to networks with tens of millions of edges. We have also extended this method to incorporate uncertainty. Most existing work in anomaly detection (including scan statistics) typically assumes that the datasets are taken ?as is?, which is often not a realistic assumption. The observed counts in data have uncertainty and do not exactly match the real world due to reporting errors, geocoding errors, missing entries, etc. All these sources of uncertainty would affect the problem formulations and algorithms for anomaly detection, but they are especially relevant when using scan statistics because the anomaly score is formalized in terms of the log likelihood of occurrence of observed data. We use methods from the theory of stochastic optimization to formally characterize scan statistic maximization with uncertainty and develop novel algorithms and heuristics for optimizing them.</p>\n&nbsp;\n<p>5. Designing interventions to control epidemics on networks: a key topic in the project was analysis and control of epidemic processes on networks. These are very challenging computational problems. We have made significant advances in these problems. We developed the first algorithms for controlling epidemic processes with rigorous approximation guarantees, using stochastic optimization techniques. We have also shown that these can be implemented efficiently and scaled to national size networks using special techniques for solving linear programs with special structure. We have also developed intervention strategies based on the influence maximization problem, and show that they work very efficiently.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>6. Inference and Analysis Problems for Discrete Dynamical Systems: Discrete synchronous dynamical systems (SyDSs) are used in a host of settings to understand population-level contagion dynamics in terms of individual (human) agent behavior. Analyzing their dynamics, inferring their properties and estimating the sensitivity of parameters are some of the most basic problems for such systems. We investigated the problems of inferring the components of graph dynamical systems, such as the local functions and the underlying network using a limited set of observations.</p>\n<p>The methods developed in the project have been useful in a number of public health analyses involving networked datasets</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/20/2022<br>\n\t\t\t\t\tModified by: Anil Kumar&nbsp;S&nbsp;Vullikanti</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe major goals of this project were to develop a rigorous algorithmic theory of distributed large-scale graph computation, focusing, in particular, on important graph problems that arise in computational epidemiology and contagion dynamics. We worked on topics related to fundamental problems in graph algorithms, graph mining and network science, including connectivity, subgraph analysis, anomaly detection, community detection and controlling the dynamics of diffusion processes on networks. Our focus has been to develop algorithms which would scale to massive networks, of the type found in real-world applications, with rigorous performance and approximation guarantees. We have applied these methods for a number of problems in public health.\n\n \n\nSome of the key topics studied in the project and the significant results are:\n\n \n\n1. Parallel algorithms for random graph generation: This involves generating networks with characteristics similar to real world networks, especially those relevant for epidemic spread, using different random graph models. This is a challenging problem since most random graph models are inherently sequential. We have developed a general approach which allows random generation of massive networks from multiple models.\n\n \n\n2. Efficient parallel algorithms for detecting and counting paths and trees: these are very common problems in graphmining, since subgraph statistics can help in characterizing networks and identifying anomalous nodes and clusters. These problems are computationally very challenging. We developed parallel algorithms by adapting the classical color coding technique, which is a fixed parameter tractable technique, whose running time is polynomial when the subgraph size is fixed. We have explored a variety of parallel computing models.\n\n \n\n3. Efficient parallel algorithms for anomaly detection using network scan statistics: Scan statistics are a popular approach used for detecting \"hotspots\" and \"anomalies\" in spatio-temporal and network data. This methodology is based on hypothesis testing, and has also been extended to networked data. However, it becomes computationally very challenging in networks, since the problem reduces to finding a connected subgraph that maximizes a score function. We adapted the color coding technique for optimizing network scan statistics, and used them in a diverse set of public health applications. We developed parallel algorithms for network scan statistics, are able to scale to networks with tens of millions of edges. We have also extended this method to incorporate uncertainty. Most existing work in anomaly detection (including scan statistics) typically assumes that the datasets are taken ?as is?, which is often not a realistic assumption. The observed counts in data have uncertainty and do not exactly match the real world due to reporting errors, geocoding errors, missing entries, etc. All these sources of uncertainty would affect the problem formulations and algorithms for anomaly detection, but they are especially relevant when using scan statistics because the anomaly score is formalized in terms of the log likelihood of occurrence of observed data. We use methods from the theory of stochastic optimization to formally characterize scan statistic maximization with uncertainty and develop novel algorithms and heuristics for optimizing them.\n \n\n5. Designing interventions to control epidemics on networks: a key topic in the project was analysis and control of epidemic processes on networks. These are very challenging computational problems. We have made significant advances in these problems. We developed the first algorithms for controlling epidemic processes with rigorous approximation guarantees, using stochastic optimization techniques. We have also shown that these can be implemented efficiently and scaled to national size networks using special techniques for solving linear programs with special structure. We have also developed intervention strategies based on the influence maximization problem, and show that they work very efficiently.\n\n \n\n \n\n6. Inference and Analysis Problems for Discrete Dynamical Systems: Discrete synchronous dynamical systems (SyDSs) are used in a host of settings to understand population-level contagion dynamics in terms of individual (human) agent behavior. Analyzing their dynamics, inferring their properties and estimating the sensitivity of parameters are some of the most basic problems for such systems. We investigated the problems of inferring the components of graph dynamical systems, such as the local functions and the underlying network using a limited set of observations.\n\nThe methods developed in the project have been useful in a number of public health analyses involving networked datasets\n\n\t\t\t\t\tLast Modified: 12/20/2022\n\n\t\t\t\t\tSubmitted by: Anil Kumar S Vullikanti"
 }
}