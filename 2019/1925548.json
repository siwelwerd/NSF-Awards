{
 "awd_id": "1925548",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CCRI: Planning: Planning for the Development of a Platform to Support Multilingual and Multi-Domain Coreference Annotation for Natural Language Processing Research",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 99998.0,
 "awd_amount": 99998.0,
 "awd_min_amd_letter_date": "2019-08-01",
 "awd_max_amd_letter_date": "2021-10-28",
 "awd_abstract_narration": "In natural language processing, coreference resolution involves clustering together all words and phrases within a text that refer to the same entity. For example, in the sentence \"Monsieur Poirot assured Hastings that he ought to have faith in him,\" the strings \"Monsieur Poirot\" and \"him\" refer to the same person, while \"Hastings\" and \"he\" refer to a different character. Resolving these references is challenging because it requires the application of syntactic, semantic, and world knowledge, and it is important since coreference is essential to intelligently understand the meaning of text for question answering, translation, corpus insights, and many other applications. Unfortunately, current coreference models are held back by the lack of human-annotated training data from various domains and world languages, mainly because it is expensive and time-consuming to collect such data at scale.\r\n\r\nThis CCRI planning grant will take the first step toward breaking the coreference data bottleneck by creating two new resources for the community: (1) a software platform that facilitates cheap and accurate crowdsourced collection for tasks that require labeling text spans within documents, and (2) a multi-domain crowdsourced coreference dataset collected using this platform. The dataset resource will contain data from a variety of different domains (such as books and web forums), unlike prior datasets that focus primarily on newswire text, which will allow researchers who work on non-standard domains to integrate coreference systems into their modeling pipelines. This planning grant will also support discussions and conference workshops about the platform and data resources; the resulting community feedback will be incorporated into a CCRI full proposal that aims to use the platform to create a much larger and multilingual coreference dataset, as well as explore non-coreference data labeling tasks such as question answering.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Brendan",
   "pi_last_name": "O'Connor",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Brendan T O'Connor",
   "pi_email_addr": "brenocon@cs.umass.edu",
   "nsf_id": "000703500",
   "pi_start_date": "2019-08-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mohit",
   "pi_last_name": "Iyyer",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Mohit N Iyyer",
   "pi_email_addr": "miyyer@cs.umass.edu",
   "nsf_id": "000791748",
   "pi_start_date": "2019-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "140 Governors Drive",
  "perf_city_name": "Amherst",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010039264",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 99998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-4b5ca203-7fff-5cb6-1bfb-376b0f4aa1a3\"> </span></p>\n<p dir=\"ltr\"><span>In natural language processing, </span><span>coreference resolution</span><span> involves clustering together all words and phrases within a text that refer to the same entity. For example, consider the sentence:</span></p>\n<p dir=\"ltr\"><span><span style=\"white-space: pre;\"> </span>\"Monsieur Poirot assured Hastings that he ought to have faith in him.\"</span></p>\n<p dir=\"ltr\"><span>The strings \"Monsieur Poirot\" and \"him\" refer to the same person, while \"Hastings\" and \"he\" refer to a different character. Resolving these references is challenging because it requires the application of syntactic, semantic, and world knowledge. But computational models of coreference resolution are essential to get at deeper meaning of text, which has the potential to enable more powerful search engines, question-answering systems, translation, and dialogue or chatbot systems. For example, resolving pronouns and other phrases to their base entities can give users accurate answers to their questions (e.g., for the above example: \"who was supposed to have faith in Poirot?\").&nbsp;</span></p>\n<p dir=\"ltr\"><span>As is the case for most natural language processing technologies, the most effective approach for coreference modeling &mdash; supervised deep learning &mdash; requires a large number of training examples, where humans supply ground-truth coreference links between the words and phrases in a document. Unfortunately, current coreference models are held back by the lack of human-annotated training data from various domains and world languages, mainly because it is expensive and time-consuming to collect such data at scale.</span></p>\n<p dir=\"ltr\"><span>This CCRI Planning project sought to break the coreference data bottleneck by developing a more human-friendly paradigm, and open-source user interface software, to collect crowdsourced coreference annotations more rapidly and at lower cost than in an expert-oriented approach. We developed such a tool&mdash;</span><span>ezCoref</span><span>&mdash;as well as a detailed interactive tutorial geared for novice annotator users, and recruited crowdworkers from Amazon Mechanical Turk to use it.</span></p>\n<p dir=\"ltr\"><span>To study how non-expert annotators approach the problem, we used </span><span>ezCoref</span><span> to re-annotate 240 passages from seven existing English coreference datasets (spanning fiction, news, and multiple other domains) while only teaching annotators about linguistic phenomena that are treated similarly across these datasets. Surprisingly, we found that reasonable quality annotations were already achievable (&gt;90% agreement between the crowd and expert annotations) even without extensive training. When carefully analyzing the remaining disagreements, we identified the presence of linguistic cases that our annotators unanimously agree upon but lack unified treatments (such as generic pronouns and appositives) in existing datasets. We propose the research community should revisit these phenomena when curating future unified annotation guidelines.</span></p>\n<p dir=\"ltr\"><span>Our paper describing this research (its abstract was quoted in the previous paragraph) has been published in </span><span>Findings of the Association for Computational Linguistics: EACL 2023</span><span> (Gupta et al. 2023), and we've released the </span><span>ezCoref</span><span> tool as open-source. Given this approach's success for a variety of domains, we hope the approach can be used for future efforts for other corpora and languages, and the findings can inform ongoing efforts in unified guidelines and annotation planning. Extension to other languages and a richer set of referential phenomena will be important areas for future work.</span></p>\n<p dir=\"ltr\"><span>The paper and software can be accessed at:</span></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>https://arxiv.org/abs/2210.07188</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">https://aclanthology.org/2023.findings-eacl.24/</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>https://github.com/gnkitaa/ezCoref</span></p>\n</li>\n</ul>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/10/2023<br>\n\t\t\t\t\tModified by: Brendan&nbsp;T&nbsp;O'connor</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nIn natural language processing, coreference resolution involves clustering together all words and phrases within a text that refer to the same entity. For example, consider the sentence:\n \"Monsieur Poirot assured Hastings that he ought to have faith in him.\"\nThe strings \"Monsieur Poirot\" and \"him\" refer to the same person, while \"Hastings\" and \"he\" refer to a different character. Resolving these references is challenging because it requires the application of syntactic, semantic, and world knowledge. But computational models of coreference resolution are essential to get at deeper meaning of text, which has the potential to enable more powerful search engines, question-answering systems, translation, and dialogue or chatbot systems. For example, resolving pronouns and other phrases to their base entities can give users accurate answers to their questions (e.g., for the above example: \"who was supposed to have faith in Poirot?\"). \nAs is the case for most natural language processing technologies, the most effective approach for coreference modeling &mdash; supervised deep learning &mdash; requires a large number of training examples, where humans supply ground-truth coreference links between the words and phrases in a document. Unfortunately, current coreference models are held back by the lack of human-annotated training data from various domains and world languages, mainly because it is expensive and time-consuming to collect such data at scale.\nThis CCRI Planning project sought to break the coreference data bottleneck by developing a more human-friendly paradigm, and open-source user interface software, to collect crowdsourced coreference annotations more rapidly and at lower cost than in an expert-oriented approach. We developed such a tool&mdash;ezCoref&mdash;as well as a detailed interactive tutorial geared for novice annotator users, and recruited crowdworkers from Amazon Mechanical Turk to use it.\nTo study how non-expert annotators approach the problem, we used ezCoref to re-annotate 240 passages from seven existing English coreference datasets (spanning fiction, news, and multiple other domains) while only teaching annotators about linguistic phenomena that are treated similarly across these datasets. Surprisingly, we found that reasonable quality annotations were already achievable (&gt;90% agreement between the crowd and expert annotations) even without extensive training. When carefully analyzing the remaining disagreements, we identified the presence of linguistic cases that our annotators unanimously agree upon but lack unified treatments (such as generic pronouns and appositives) in existing datasets. We propose the research community should revisit these phenomena when curating future unified annotation guidelines.\nOur paper describing this research (its abstract was quoted in the previous paragraph) has been published in Findings of the Association for Computational Linguistics: EACL 2023 (Gupta et al. 2023), and we've released the ezCoref tool as open-source. Given this approach's success for a variety of domains, we hope the approach can be used for future efforts for other corpora and languages, and the findings can inform ongoing efforts in unified guidelines and annotation planning. Extension to other languages and a richer set of referential phenomena will be important areas for future work.\nThe paper and software can be accessed at:\n\n\nhttps://arxiv.org/abs/2210.07188\n\n\nhttps://aclanthology.org/2023.findings-eacl.24/\n\n\nhttps://github.com/gnkitaa/ezCoref\n\n\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 05/10/2023\n\n\t\t\t\t\tSubmitted by: Brendan T O'connor"
 }
}