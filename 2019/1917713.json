{
 "awd_id": "1917713",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Student Affect Detection and Intervention with Teachers in the Loop",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 249999.0,
 "awd_amount": 249999.0,
 "awd_min_amd_letter_date": "2019-07-12",
 "awd_max_amd_letter_date": "2019-07-12",
 "awd_abstract_narration": "In recent years, there has been increasing effort to integrate modern artificial intelligence technologies into adaptive learning systems to enhance student learning. One key emerging area is in the use of models that can recognize student emotion in context, referred to as affective states. These models typically take the form of machine learning classifiers that recognize affect from the student's interaction with an online learning system. In this project, the investigators will develop adaptive learning systems that actively enlist the help of teachers to develop better student affect detection methods. In return, the system will support the work of teachers by providing them reports on the affective state of each student in real-time. The system will then learn to mimic teachers' choices of intervention methods for disengaged students in order to deliver interventions automatically. Overall, this project is anticipated to lead to i) better understanding of how to leverage and align to teachers' perspectives in detecting and responding to affect, and ii) enhanced intervention by both teachers and automated software that re-engages students and improves learning outcomes.\r\n\r\nThis project will be organized into three phases. First, the investigators will employ active machine learning methods to ask teachers to observe specific students when they have a break in classroom activity; these methods can improve the quality of the affect detectors by providing data on the students whose affective states are most informative to improve the classifier, rather than the standard method of developing these detectors by observing students in round-robin fashion. Second, the investigators will incorporate richer data types (specifically, self-reported confidence ratings of affect labels) into the detectors to improve their quality. These self-reported confidence ratings reflect how uncertain humans are about specific affect judgements, which will be compared to the uncertainty of classifiers, to possibly reveal insights into student affect, such as what the properties are of situations where affect is ambiguous. Third, the investigators will use crowdsourcing to solicit ideas from teachers as to when specific affect interventions will be appropriate for specific students, and will develop automated intervention methods using reinforcement learning. These automated intervention methods are highly scalable since they can enable the system to take the actions the teacher would take to intervene to support different students experiencing negative affect at the same time. This intervention system will be tested in real classrooms as students learn within ASSISTments, a free web-based learning platform used by over 60,000 students a year. If successful, this project will lead to new scientific discoveries on the dynamics of affect and new technology for scalable student affect detection and intervention.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shiting",
   "pi_last_name": "Lan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shiting Lan",
   "pi_email_addr": "andrewlan@cs.umass.edu",
   "nsf_id": "000789169",
   "pi_start_date": "2019-07-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "140 Governors Drive, Computer Sc",
  "perf_city_name": "Amherst",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010039264",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 249999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-b77a37d4-7fff-8d17-6cb5-cdfbb27d146f\" style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This award enabled the research team to advance sensor-free student affect detection that estimates students&rsquo; affective states using their activity data in an online learning platform. Our main goal is to develop algorithmic, data analysis, and interface tools to help teachers in monitoring student affect. Due to the impact of COVID-19 and the switch to online learning, observers had limited access to real classrooms and opportunities to observe student affect in-person, causing a pivot to the use of self-report data and historical data. Our accomplishments were three-fold: On the affect detection algorithm side, we developed active learning algorithms to reduce the number of affect labels we need to collect to train affect detectors, relieving some burden off of teachers and/or classroom observers and/or self-report. We also developed differentiable learning algorithms for online (machine) learning settings that help us learn efficiently from sequential, time-series data, such as student affect.&nbsp; The resulting algorithms achieve as much as 50% sample efficiency improvement in a wide range of applications, even for non-educational applications such as item recommendation in collaborative filtering. On the data analysis side, we investigated the generalizability of affect detectors across different student demographic groups and whether we can use them to warm-start the initial stage of the active learning process. Our results suggest that doing so can result in a good quality detector of engaged concentration in some conditions, such as pre-training on data from urban schools, and not so effective in others, such as pre-training on data from suburban schools. We also found that the amount of data used for pre-training makes a difference. Furthermore, we found that it was possible to forecast student affect as much as two minutes in advance, creating the possibility of new interventions that disrupt negative affect before it occurs. On the interface side, we developed a tool called LIVE-CHART, a real-time reporting interface designed to help teachers monitor student performance, behavior, and affect in the classroom. LIVE-CHART allows teachers to monitor students asynchronously and students to self-report their affect. The tool was used by 9 teachers in their classrooms, collecting self-reports of affect from about 312 different students between 2021 and 2023. This award (partially) enabled the professional development of over 10 graduate students at UMass, UPenn, and WPI, resulting in tools that are integrated into ASSISTments workflow in predicting affect. There are new teacher reports that have benefited from our more clear understanding of affect.</span></p><br>\n<p>\n Last Modified: 09/30/2024<br>\nModified by: Shiting&nbsp;Lan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis award enabled the research team to advance sensor-free student affect detection that estimates students affective states using their activity data in an online learning platform. Our main goal is to develop algorithmic, data analysis, and interface tools to help teachers in monitoring student affect. Due to the impact of COVID-19 and the switch to online learning, observers had limited access to real classrooms and opportunities to observe student affect in-person, causing a pivot to the use of self-report data and historical data. Our accomplishments were three-fold: On the affect detection algorithm side, we developed active learning algorithms to reduce the number of affect labels we need to collect to train affect detectors, relieving some burden off of teachers and/or classroom observers and/or self-report. We also developed differentiable learning algorithms for online (machine) learning settings that help us learn efficiently from sequential, time-series data, such as student affect. The resulting algorithms achieve as much as 50% sample efficiency improvement in a wide range of applications, even for non-educational applications such as item recommendation in collaborative filtering. On the data analysis side, we investigated the generalizability of affect detectors across different student demographic groups and whether we can use them to warm-start the initial stage of the active learning process. Our results suggest that doing so can result in a good quality detector of engaged concentration in some conditions, such as pre-training on data from urban schools, and not so effective in others, such as pre-training on data from suburban schools. We also found that the amount of data used for pre-training makes a difference. Furthermore, we found that it was possible to forecast student affect as much as two minutes in advance, creating the possibility of new interventions that disrupt negative affect before it occurs. On the interface side, we developed a tool called LIVE-CHART, a real-time reporting interface designed to help teachers monitor student performance, behavior, and affect in the classroom. LIVE-CHART allows teachers to monitor students asynchronously and students to self-report their affect. The tool was used by 9 teachers in their classrooms, collecting self-reports of affect from about 312 different students between 2021 and 2023. This award (partially) enabled the professional development of over 10 graduate students at UMass, UPenn, and WPI, resulting in tools that are integrated into ASSISTments workflow in predicting affect. There are new teacher reports that have benefited from our more clear understanding of affect.\t\t\t\t\tLast Modified: 09/30/2024\n\n\t\t\t\t\tSubmitted by: ShitingLan\n"
 }
}