{
 "awd_id": "1910864",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Modules for neural computation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 452742.0,
 "awd_amount": 452742.0,
 "awd_min_amd_letter_date": "2019-09-04",
 "awd_max_amd_letter_date": "2022-06-22",
 "awd_abstract_narration": "Artificial intelligence need not replicate the human brain, but may constructively take inspiration from it. The brain is organized hierarchically, from large brain structures to smaller regions, cortical columns, all the way down to microcircuits made of a few interacting neurons. These modules may make our brains more efficient by dissecting problems into locally solvable subproblems. This in turn may make us learn faster by figuring out where in the brain a mistake was made and allow us to do better on new problems. Modules may also make the brain more efficient, allowing it to use fewer neurons and synapses. In those areas where brains seem to benefit from modularity, modern deep learning systems appear to be weaker. Building modules into deep neural networks promises to greatly improve generalization, interpretability, credit assignment in learning, computational cost and make them more resilient to adversarial stimuli. The result of this project will be improvements to the performance and understanding of modern artificial intelligence systems. The project will contribute in a broad way to the dissemination of computational results to neuroscience and of neuroscience results to the computational community through a combination of summer schools, teaching, and publishing. \r\n\r\nTo meet these goals, this project enables a broadly interdisciplinary approach both to produce systems with modularity and to dissect their modular aspects. The research aims to build networks that, while learning, dissect training tasks by incrementally developing structural modules. This is done by minimizing cost functions that evaluate the community structure of neuron connectivity. It will design learning algorithms that encourage modularity by performing credit assignment at the level of modules. This is done by gating learning at both the neuron and the module level. Finally, the project team will develop tools for interpreting modular networks. This is done by performing psychophysical experiments with human subjects and by computational analysis. All of these components interrelate, provide a unified picture of how modularity can improve current machine learning approaches, and build a new bridge between neuroscience and deep learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Konrad",
   "pi_last_name": "Kording",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Konrad Kording",
   "pi_email_addr": "koerding@gmail.com",
   "nsf_id": "000096260",
   "pi_start_date": "2019-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Rolnick",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Rolnick",
   "pi_email_addr": "david@climatechange.ai",
   "nsf_id": "000759954",
   "pi_start_date": "2019-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "240 S. 33rd Street",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046392",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 452742.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We analyze the modularity of deep neural networks with respect to (a) relationships in processing input data, and (b) effects upon resulting outputs. We find that these two approaches yield fundamentally different results in assessing modules [1]. We design methods for solving the symbol-grounding problem in deep learning methods for visual reasoning, addressing a significant prior bottleneck to fusing machine learning and symbolic AI approaches, while informing considerations of the parallel symbol-grounding problem in neuroscience [2]. We analyze the internal representation spaces of deep neural networks, which are typically measured via description vectors in parameter space, but also exist as points in function space [3]. Considering the layerwise representations of neural networks, we construct new mathematical structures to analyze and visualize the trajectory of a representation as it passes through a neural network [4].</p>\n<div class=\"sh-color-black sh-color\">[1] R.D. Lange, D. Rolnick, K.P. Kording, Clustering units in neural networks: upstream vs downstream information, Transactions on Machine Learning Research (TMLR), 2022.\n<div class=\"sh-color-black sh-color\">[2] S. Topan, D. Rolnick, X. Si, Techniques for symbol grounding with SATNet, Conference on Neural Information Processing Systems (NeurIPS) spotlight, 2021.</div>\n<div class=\"sh-color-black sh-color\">[3]&nbsp;G. Kerg, S. Mittal, D. Rolnick, Y. Bengio, B. Richards, G. Lajoie, On neural architecture inductive biases for relational tasks, preprint arXiv:2206.05056, 2022.</div>\n<div class=\"sh-color-black sh-color\">[4]&nbsp;R.D. Lange, J. Matelsky, X. Wang, D. Kwok, D. Rolnick, K.P. Kording, Deep networks as paths on the manifold of neural representations, Proceedings of the Workshop on Topology, Algebra, and Geometry in Machine Learning (TAG-ML) 2023.</div>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/09/2023<br>\n\t\t\t\t\tModified by: Konrad&nbsp;P&nbsp;Kording</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWe analyze the modularity of deep neural networks with respect to (a) relationships in processing input data, and (b) effects upon resulting outputs. We find that these two approaches yield fundamentally different results in assessing modules [1]. We design methods for solving the symbol-grounding problem in deep learning methods for visual reasoning, addressing a significant prior bottleneck to fusing machine learning and symbolic AI approaches, while informing considerations of the parallel symbol-grounding problem in neuroscience [2]. We analyze the internal representation spaces of deep neural networks, which are typically measured via description vectors in parameter space, but also exist as points in function space [3]. Considering the layerwise representations of neural networks, we construct new mathematical structures to analyze and visualize the trajectory of a representation as it passes through a neural network [4].\n[1] R.D. Lange, D. Rolnick, K.P. Kording, Clustering units in neural networks: upstream vs downstream information, Transactions on Machine Learning Research (TMLR), 2022.\n[2] S. Topan, D. Rolnick, X. Si, Techniques for symbol grounding with SATNet, Conference on Neural Information Processing Systems (NeurIPS) spotlight, 2021.\n[3] G. Kerg, S. Mittal, D. Rolnick, Y. Bengio, B. Richards, G. Lajoie, On neural architecture inductive biases for relational tasks, preprint arXiv:2206.05056, 2022.\n[4] R.D. Lange, J. Matelsky, X. Wang, D. Kwok, D. Rolnick, K.P. Kording, Deep networks as paths on the manifold of neural representations, Proceedings of the Workshop on Topology, Algebra, and Geometry in Machine Learning (TAG-ML) 2023.\n\n\n\t\t\t\t\tLast Modified: 10/09/2023\n\n\t\t\t\t\tSubmitted by: Konrad P Kording"
 }
}