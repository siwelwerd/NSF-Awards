{
 "awd_id": "1908727",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Small: A Query System for Rapid Audiovisual Analysis of Large-Scale Video Collections",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-08-07",
 "awd_max_amd_letter_date": "2020-07-17",
 "awd_abstract_narration": "Due to advances in computer vision and audio processing, it is now possible to automatically annotate large video collections with basic information about their audiovisual contents (e.g., people, places, objects, audio transcripts). However, it remains difficult to productively carry out higher level analytics tasks on video because of the challenges of defining higher level, complex events of interest. In response, this project seeks to enable more sophisticated and higher productivity video analysis through the design of a programming system for composing basic video annotations into higher level patterns and events of interest in a video. Queries authored in the proposed system can serve as a direct specification of video events of interest, or as a mechanism for automatically generating data labels that provide supervision for subsequent model training. The proposed systems will be applicable to many video domains; however, the project will feature a collaboration with journalists and news media personnel to conduct an audiovisual analysis that measures diversity and representation in nearly a decade of American cable TV news broadcasts (over 200,000 hours since 2010). Specifically, the project will create software tools for answering questions such as: What individuals appear most often on the news? In what contexts? (in interviews? on panels?) What topics and stories do certain individuals cover? In addition to disseminating the results of these analyses, the project will produce interactive web-based tools that will enable students and the public to perform their own diversity analyses of the contents of cable TV news.\r\n\r\nThe primary technical challenge of the project involves the design of a new video analysis system for defining spatio-temporal patterns and events of interest in video. Inspired by early multimedia database query systems, the system will support multi-modal video analyses by representing all video annotations (whether they result from pixels, audio, or transcripts) as continuous space-time volumes in a video. Users will define complex patterns via queries that compose (via spatio-temporal relations) and manipulate collections of simpler space-time annotations. The compositional nature of these queries will allow them to execute rapidly on large video collections, enabling analysts to iteratively conceptualize, prototype, and specify novel high-level patterns in videos. To reduce the cost of annotating large video collections, the project will also exploit the long running nature of TV and film video streams to train low-cost models that are specific to a show or film's video content. The project will investigate the use model distillation (and do so in a continuous, online setting) to train face and object detection models that maintain high accuracy on a video stream at an order of magnitude lower runtime cost than existing methods. All systems developed as part of the project will be distributed to the public as open source software, and the project will involve hosted hackathons to educate students and broader community about their use.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kayvon",
   "pi_last_name": "Fatahalian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kayvon Fatahalian",
   "pi_email_addr": "kayvonf@cs.stanford.edu",
   "nsf_id": "000624440",
   "pi_start_date": "2019-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "Gates Computer Science Bldg",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943059025",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 333052.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 166948.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-efaa9670-7fff-269c-f0d5-b3deab9ec1c0\"> </span></p>\n<p dir=\"ltr\"><span>In the modern world, a huge amount of information is conveyed through the medium of images and video, yet in general we lack productive computational tools for understanding the contents of the large amount of visual data on the internet (to the extent video has been called that \"dark matter\" of the internet). In response, our project strives to create new algorithms and new platforms for analyzing large image and video collections, and to demonstrate the potential benefits of new video applications that are based on analyzing big video data.</span></p>\n<p dir=\"ltr\"><span>One major thrust of our work is improving the quality and reducing the cost of algorithms for understanding visual data. Specifically, we focus on the difficulty of performing subtle analyses of \"real world\", in-the-wild datasets. Tasks like \"I want to create a detector for a specific type of bird\" in wildlife cams, or \"I want to know the specific frame an athlete kicks a ball in professional sports coverage\", or \"what's the screen time given to female-presenting individuals on a specific cable TV news show\".</span></p>\n<p dir=\"ltr\"><span>In this domain, we developed new algorithms for detecting fine-grained objects in image data or fine-grained events in video data. Our algorithms resulted in learned models that incur lower cost: both in terms of the computational cost of model evaluation but also by reducing the number of labeled examples that must be provided by human data labelers. Since the challenge in using AI to analyze video is not just training models on in-the-wild data, but also understanding the accuracy of these models, we are also developed techniques for reducing the data labeling costs needed to provide supervision for reliable model validation. As a result, we were able to demonstrate pipelines for human-in-the-loop model creation, where a subject matter expert that has knowledge of the contents of a video dataset can go from an idea of what they wish for the computer to identify to a working, validated model for that concept in far less computation and human effort than previously possible.</span></p>\n<p dir=\"ltr\"><span>A major aspect of our project was to show the benefits and capabilities of real-world, large-scale video analysis. Specifically, in collaboration with the Internet Archive, we've created a database of over 300,000 hours of US cable TV news video from the prior decade (since 2010). Using computational analysis of this news video, we were able to quantitatively understand how the contents of the news have evolved over the last decade: addressing questions like what individuals appear on the news the most? Are there differences in representation by gender? What topics get talked about the most?</span></p>\n<p dir=\"ltr\"><span>A public version of the Cable TV News Analyzer is online for public use at http://tvnews.stanford.edu. Using this tool the general public can quickly make queries against the dataset that are based on who appears on screen and what words are mentioned in the TV program transcripts. The site allows journalists and media watchdogs (such as work done using the tool by organizations like the Washington Post, Yahoo News, and Media Matters) to quickly perform quantitative analyses of who and what is on Cable TV News, and then use those analyses in real reporting. Since modern TV news media shapes the news stories that hundreds of millions receive each day, we believe a better understanding of the content of TV news, as well as who is telling the news, stands to have significant impact on society at large.&nbsp;</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/28/2023<br>\n\t\t\t\t\tModified by: Kayvon&nbsp;Fatahalian</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nIn the modern world, a huge amount of information is conveyed through the medium of images and video, yet in general we lack productive computational tools for understanding the contents of the large amount of visual data on the internet (to the extent video has been called that \"dark matter\" of the internet). In response, our project strives to create new algorithms and new platforms for analyzing large image and video collections, and to demonstrate the potential benefits of new video applications that are based on analyzing big video data.\nOne major thrust of our work is improving the quality and reducing the cost of algorithms for understanding visual data. Specifically, we focus on the difficulty of performing subtle analyses of \"real world\", in-the-wild datasets. Tasks like \"I want to create a detector for a specific type of bird\" in wildlife cams, or \"I want to know the specific frame an athlete kicks a ball in professional sports coverage\", or \"what's the screen time given to female-presenting individuals on a specific cable TV news show\".\nIn this domain, we developed new algorithms for detecting fine-grained objects in image data or fine-grained events in video data. Our algorithms resulted in learned models that incur lower cost: both in terms of the computational cost of model evaluation but also by reducing the number of labeled examples that must be provided by human data labelers. Since the challenge in using AI to analyze video is not just training models on in-the-wild data, but also understanding the accuracy of these models, we are also developed techniques for reducing the data labeling costs needed to provide supervision for reliable model validation. As a result, we were able to demonstrate pipelines for human-in-the-loop model creation, where a subject matter expert that has knowledge of the contents of a video dataset can go from an idea of what they wish for the computer to identify to a working, validated model for that concept in far less computation and human effort than previously possible.\nA major aspect of our project was to show the benefits and capabilities of real-world, large-scale video analysis. Specifically, in collaboration with the Internet Archive, we've created a database of over 300,000 hours of US cable TV news video from the prior decade (since 2010). Using computational analysis of this news video, we were able to quantitatively understand how the contents of the news have evolved over the last decade: addressing questions like what individuals appear on the news the most? Are there differences in representation by gender? What topics get talked about the most?\nA public version of the Cable TV News Analyzer is online for public use at http://tvnews.stanford.edu. Using this tool the general public can quickly make queries against the dataset that are based on who appears on screen and what words are mentioned in the TV program transcripts. The site allows journalists and media watchdogs (such as work done using the tool by organizations like the Washington Post, Yahoo News, and Media Matters) to quickly perform quantitative analyses of who and what is on Cable TV News, and then use those analyses in real reporting. Since modern TV news media shapes the news stories that hundreds of millions receive each day, we believe a better understanding of the content of TV news, as well as who is telling the news, stands to have significant impact on society at large. \n\n \n\n\t\t\t\t\tLast Modified: 03/28/2023\n\n\t\t\t\t\tSubmitted by: Kayvon Fatahalian"
 }
}