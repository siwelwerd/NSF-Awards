{
 "awd_id": "1908870",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Automatic Exploration and Analysis of Software Performance Responses",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-07-08",
 "awd_max_amd_letter_date": "2019-07-08",
 "awd_abstract_narration": "Performance issues in software systems often result in negative user experience, highly publicized commercial failures, substantial monetary penalties, and even abandonment of multi-million dollar projects.  Performance issues can cause a software system to run for an unexpectedly long time, or use an incredibly large amount of computer memory, potentially stalling the computer.  Performance issues are often input-dependent, occurring only when the software is run with certain specific inputs.  If malicious attackers find out the inputs on which programs have performance issues, they can force these inputs on the program and cause vital software systems to go down or become unavailable (i.e., a kind of denial-of-service attack).  This project's goal is to build tools which can automatically identify the inputs on which a given software system has serious performance issues.  These tools can then be used by programmers to identify performance issues in software before the software is vulnerable to attackers or deployed to the public.  Successful completion of this project will help programmers identify and fix software performance issues early, thus increasing the efficiency, reliability, and security of software.\r\n\r\nA large body of research has focused on diagnosing performance problems by analyzing dynamically collected performance profiles.  Almost all of these techniques assume the availability of test inputs for performance profiling.  This project proposes to develop techniques to discover potential performance issues in real-world software systems automatically.  Whole-system analysis, which is necessary for such input generation, does not scale for real-world software systems.  The project addresses this scalability challenge in phases: a top-down approach to identify components that may have performance bottlenecks, a sophisticated exploration and generalization technique to learn worst-case behavior patterns, and a bottom-up approach for creating a performance-degrading input for the entire program.  The technique will also create a performance regression test suite for a software system under test using a novel performance-coverage metric developed as part of the project.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Koushik",
   "pi_last_name": "Sen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Koushik Sen",
   "pi_email_addr": "ksen@eecs.berkeley.edu",
   "nsf_id": "000490260",
   "pi_start_date": "2019-07-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947045940",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Fuzz testing is one of the most effective techniques for finding performance, security, and correctness bugs in real-world software systems. It works by generating random input data for a program under test. A key reason behind its immense popularity is its low computation overhead compared to other sophisticated techniques, such as dynamic symbolic execution. While fuzz testing has been highly successful in practice, it has been primarily implemented in ad-hoc ways by incorporating a collection of hacks and best practices. It has primarily focused on finding security vulnerabilities and correctness bugs. As such, fuzz testing techniques usually generate many redundant test inputs and take several days to weeks to find bugs. For complex input formats, such as for random C program inputs for a C compiler, a huge amount of manual tuning is required to make fuzz testing generate valid test inputs.<br />In this project, we have developed ground-breaking automated test generation techniques that can find deep correctness and security bugs as well as pathological performance and resource usage bugs in real-world software. Such bugs were beyond the reach of existing automated testing techniques. A key insight behind our work is that if we use `waypoints` in our programs, we can dramatically improve the effectiveness and efficiency of automated testing. Such waypoints could either be injected manually or automatically in code. Moreover, we showed that the same techniques could be used to synthesize programs for data visualization. Our research contributions have made fuzz testing smarter and dramatically more effective for real-world software. Our research has won several ACM SIGSOFT Awards. We have released all the testing and program synthesis tools into the public domain so that other researchers and practitioners can build on our research. Large tech firms have adopted our testing tools and have been commercialized by security-oriented startups. Four Ph.D. students who worked on the project have taken prestigious positions at top schools (e.g., CMU) and startups. Our recent work on ItyFuzz has led to a VC-funded startup for finding bugs in Web3 and smart contracts.&nbsp;</p><br>\n<p>\n Last Modified: 03/05/2024<br>\nModified by: Koushik&nbsp;Sen</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nFuzz testing is one of the most effective techniques for finding performance, security, and correctness bugs in real-world software systems. It works by generating random input data for a program under test. A key reason behind its immense popularity is its low computation overhead compared to other sophisticated techniques, such as dynamic symbolic execution. While fuzz testing has been highly successful in practice, it has been primarily implemented in ad-hoc ways by incorporating a collection of hacks and best practices. It has primarily focused on finding security vulnerabilities and correctness bugs. As such, fuzz testing techniques usually generate many redundant test inputs and take several days to weeks to find bugs. For complex input formats, such as for random C program inputs for a C compiler, a huge amount of manual tuning is required to make fuzz testing generate valid test inputs.\nIn this project, we have developed ground-breaking automated test generation techniques that can find deep correctness and security bugs as well as pathological performance and resource usage bugs in real-world software. Such bugs were beyond the reach of existing automated testing techniques. A key insight behind our work is that if we use `waypoints` in our programs, we can dramatically improve the effectiveness and efficiency of automated testing. Such waypoints could either be injected manually or automatically in code. Moreover, we showed that the same techniques could be used to synthesize programs for data visualization. Our research contributions have made fuzz testing smarter and dramatically more effective for real-world software. Our research has won several ACM SIGSOFT Awards. We have released all the testing and program synthesis tools into the public domain so that other researchers and practitioners can build on our research. Large tech firms have adopted our testing tools and have been commercialized by security-oriented startups. Four Ph.D. students who worked on the project have taken prestigious positions at top schools (e.g., CMU) and startups. Our recent work on ItyFuzz has led to a VC-funded startup for finding bugs in Web3 and smart contracts.\t\t\t\t\tLast Modified: 03/05/2024\n\n\t\t\t\t\tSubmitted by: KoushikSen\n"
 }
}