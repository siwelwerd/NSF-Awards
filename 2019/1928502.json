{
 "awd_id": "1928502",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FW-HTF-P: Optimizing Long-term Human Performance in Future Work",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 149998.0,
 "awd_amount": 149998.0,
 "awd_min_amd_letter_date": "2019-08-14",
 "awd_max_amd_letter_date": "2019-08-14",
 "awd_abstract_narration": "Wearable systems, for example smart watches and smart glasses, are important emerging technologies for the future of work. When such systems are coupled with automation that supports and guides performance, they offer tremendous opportunities for American companies, but also might create challenges for their workers. Optical, see-through displays from wearable devices like smart glasses or head-mounted displays can project images while still allowing the user to see through them. The resulting blend of digital elements with the person's view of the real world is a form of augmented reality. This type of dynamic integration of new forms of information with our environment provides an opportunity to enable major innovations in the workplace. However, the ability to use these devices to constantly and seamlessly inform and guide people as they perform their jobs will impact what these individuals are learning. A key issue is how people can remain engaged in the tasks in ways that allow them to learn what is necessary for them to enhance performance and outcomes and also enrich their working lives. What people need to avoid is becoming passive, unquestioning recipients of external support. This research tackles the issue of how to optimize support and assistance to increase human capacities and improve immediate outcomes, while still allowing the durable, robust learning that ultimately produces skilled, experienced workers.\r\n\r\nThe core objective of this award is to advance the use of automation support for performance in future work by incorporating principles from the science of learning to produce superior long-term outcomes. This approach will provide a foundation for determining when and how external assistance would provide the best aid to humans. The work aims towards a new theoretical framework, as well as for  guidelines for practitioners and developers. An initial study of performance in an exemplar furniture assembly task will use augmented reality to examine the interaction between current ongoing performance and long-term learning. The investigators will also organize a broad, multidisciplinary workshop to foster future interest in the area and develop new collaborations. The ultimate goal of this planning project is to develop the necessary research personnel, research infrastructure, and foundational work to expand the opportunities for studying future technology, future workers, and future work at the level of a FW-HTF full research proposal.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Benjamin",
   "pi_last_name": "Clegg",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Benjamin A Clegg",
   "pi_email_addr": "benjamin.clegg@montana.edu",
   "nsf_id": "000433857",
   "pi_start_date": "2019-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Anne",
   "pi_last_name": "Cleary",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Anne M Cleary",
   "pi_email_addr": "Anne.Cleary@colostate.edu",
   "nsf_id": "000282993",
   "pi_start_date": "2019-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Rhodes",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew Rhodes",
   "pi_email_addr": "Matthew.Rhodes@colostate.edu",
   "nsf_id": "000661561",
   "pi_start_date": "2019-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Francisco",
   "pi_last_name": "Ortega",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Francisco R Ortega",
   "pi_email_addr": "fortega@colostate.edu",
   "nsf_id": "000715085",
   "pi_start_date": "2019-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Heggestad",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eric Heggestad",
   "pi_email_addr": "edhegges@uncc.edu",
   "nsf_id": "000799224",
   "pi_start_date": "2019-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Colorado State University",
  "inst_street_address": "601 S HOWES ST",
  "inst_street_address_2": "",
  "inst_city_name": "FORT COLLINS",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "9704916355",
  "inst_zip_code": "805212807",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "COLORADO STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "LT9CXX8L19G1"
 },
 "perf_inst": {
  "perf_inst_name": "Colorado State University",
  "perf_str_addr": "200 W. Lake Street",
  "perf_city_name": "Fort Collins",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "805214593",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "103Y00",
   "pgm_ele_name": "FW-HTF Futr Wrk Hum-Tech Frntr"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 149998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This planning grant on the Future of Work examined the use of a range of existing and emerging training technologies in the context of assembly tasks. Across a set of experiments this work highlights an important disconnect between what users think is improving their memory for a series of assembly steps versus the actual changes to learning occuring. Our initial experiment compared&nbsp;training the steps to assemble objects&nbsp;either using rich instructional materials from a set of videos, created using a virtual reality platform, to those viewing the same instructions in a set of static diagrams. The video&nbsp;led participants to believe they were learning more,&nbsp;but the video actually produced no difference in learning outcomes compared to the step by step diagrams. The disconnect suggests we might tend to believe that technologies producing new forms of instruction are inherently more effective learning tools, but the features these technologies supply can instead just produce an illustion of greater learning. Our second experiment examined whether the lack of learning benefits were an artifact of the video presentation, and compared the video-based learning conditions to individuals watching the same demonstration of the assembly task but now viewing the construction occuring in an immersive 3D environment. The findings revealed no learning advantage from the immersive presentation, but also no additional difference between the video presentation and the immersive viewing. These results highlight that despite the potential for greater fidelity and engagement, the richer training environment did not produce superior learning outcomes, but importantly for both theory and implications the presence of the types of features found within an immersive environment did not impact judgements of learning to a greater extent than the 2D video version of the instructions. Our third experiment took immersive training to another level, incorporating active participation in a virtual construction of the objects with different cues to guide the learning experience. Data collection finished as the project funding ended, and results will be available shortly that speak to whether the forms of guided instruction involved produce better learning outcomes and/or changes in judgments of learning. Our final experiment is currently being developed and will examine the use of augmented reality training support in the construction of actual objects, and we expect to be ready to collect these data in the upcoming year. Overall the work conducted has important implications for the Future of Work where learners might engage in less training than necessary when cues from emerging technologies offer an illustion of greater learning, and for&nbsp;instructional designers, who might be mislead in their choices for materials by these same types of cues available in richer extended reality environments.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/30/2021<br>\n\t\t\t\t\tModified by: Benjamin&nbsp;A&nbsp;Clegg</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis planning grant on the Future of Work examined the use of a range of existing and emerging training technologies in the context of assembly tasks. Across a set of experiments this work highlights an important disconnect between what users think is improving their memory for a series of assembly steps versus the actual changes to learning occuring. Our initial experiment compared training the steps to assemble objects either using rich instructional materials from a set of videos, created using a virtual reality platform, to those viewing the same instructions in a set of static diagrams. The video led participants to believe they were learning more, but the video actually produced no difference in learning outcomes compared to the step by step diagrams. The disconnect suggests we might tend to believe that technologies producing new forms of instruction are inherently more effective learning tools, but the features these technologies supply can instead just produce an illustion of greater learning. Our second experiment examined whether the lack of learning benefits were an artifact of the video presentation, and compared the video-based learning conditions to individuals watching the same demonstration of the assembly task but now viewing the construction occuring in an immersive 3D environment. The findings revealed no learning advantage from the immersive presentation, but also no additional difference between the video presentation and the immersive viewing. These results highlight that despite the potential for greater fidelity and engagement, the richer training environment did not produce superior learning outcomes, but importantly for both theory and implications the presence of the types of features found within an immersive environment did not impact judgements of learning to a greater extent than the 2D video version of the instructions. Our third experiment took immersive training to another level, incorporating active participation in a virtual construction of the objects with different cues to guide the learning experience. Data collection finished as the project funding ended, and results will be available shortly that speak to whether the forms of guided instruction involved produce better learning outcomes and/or changes in judgments of learning. Our final experiment is currently being developed and will examine the use of augmented reality training support in the construction of actual objects, and we expect to be ready to collect these data in the upcoming year. Overall the work conducted has important implications for the Future of Work where learners might engage in less training than necessary when cues from emerging technologies offer an illustion of greater learning, and for instructional designers, who might be mislead in their choices for materials by these same types of cues available in richer extended reality environments. \n\n\t\t\t\t\tLast Modified: 12/30/2021\n\n\t\t\t\t\tSubmitted by: Benjamin A Clegg"
 }
}