{
 "awd_id": "1927513",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AI-DCL: EAGER: Fairness-aware Informatics System for Enhancing Disaster Resilience",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Frederick Kronz",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2019-08-02",
 "awd_max_amd_letter_date": "2019-08-02",
 "awd_abstract_narration": "This award supports a research project to develop a smart, fairness-aware, emergency informatics system. The system would automatically collect disaster-related data for real-time event monitoring and prediction making to better coordinate search and rescue operations. The system could, for example, automatically collect real-time victim event data from social media such as Twitter, utilize predictive algorithms to capture the spatiotemporal dynamics associated with those events, forecast future events, and direct rescue teams in response. Such systems would be useful to state and local government agencies for resource allocation and planning. For the public to support their implementation, steps are needed to ensure that they operate fairly; it is well known that decisions made by algorithms generated by machine learning techniques often exhibit bias due to a number of factors including data bias and the design of algorithm models. A rescue system based only on Twitter data, for example, may exhibit socioeconomic bias since higher disaster-related Twitter-use communities tend to be communities of higher socioeconomic status. To address fairness concerns, a prototype will be tested and verified using Twitter data as well as data collected from other sources in response to Hurricane Harvey. The approach could be applied to various types of emergency situations including earthquakes and fires. The project is interdisciplinary; the research team includes an expert in computer science and artificial intelligence, and another in geography and spatial sciences. Two graduate research assistants will also be involved in the project, which will deepen their understanding of machine learning, data analytics, and environmental social science; as a result, the project will contribute to capacity building for interdisciplinary research. Results of this project will also be incorporated into course materials and classroom activities.\r\n\r\nThe central goal of this research project is to develop a fairness-aware AI system for emergency management. The project involves formulating and testing reliable principles and methods to adjust the AI algorithms for fairness, a very domain specific challenge. This is especially true in emergency management, where the system has to be able to predict rescue events in real time from large, noisy, and biased data, such as Twitter data. In light of this, the research team will develop a novel point process model for event prediction from streaming data, and it will investigate statistical learning problems when event data are noisy and incomplete. To adjust for the fairness of the prediction algorithm, the team will integrate heterogeneous social and geographical data with varying degrees of granularity and different levels to build a classic event prediction model and to examine correlations between the two approaches. Through comparing the approaches (with and without fairness adjustment) using an empirical example (Hurricane Harvey), the project will reveal the patterns of disparities, if any, and add new knowledge on community resilience and emergency management. Theory, models, and software all together form a framework that leads to scientific advances to further development in disaster resilience. This interdisciplinary research will serve to advance our understanding of machine learning, data science, and socioeconomic fairness in the management of environmental hazards. New methods will be developed to tackle incomplete and biased data and to integrate them with other components of emergency informatics systems. The approach will be applicable to many other AI system developments efforts.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mingxuan",
   "pi_last_name": "Sun",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mingxuan Sun",
   "pi_email_addr": "msun11@lsu.edu",
   "nsf_id": "000719755",
   "pi_start_date": "2019-08-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Nina",
   "pi_last_name": "Lam",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Nina S Lam",
   "pi_email_addr": "nlam@lsu.edu",
   "nsf_id": "000276929",
   "pi_start_date": "2019-08-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Louisiana State University",
  "inst_street_address": "202 HIMES HALL",
  "inst_street_address_2": "",
  "inst_city_name": "BATON ROUGE",
  "inst_state_code": "LA",
  "inst_state_name": "Louisiana",
  "inst_phone_num": "2255782760",
  "inst_zip_code": "708030001",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "LA06",
  "org_lgl_bus_name": "LOUISIANA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "ECQEYCHRNKJ4"
 },
 "perf_inst": {
  "perf_inst_name": "Louisiana State University and A&M College",
  "perf_str_addr": "",
  "perf_city_name": "Baton Rouge",
  "perf_st_code": "LA",
  "perf_st_name": "Louisiana",
  "perf_zip_code": "708032701",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "LA06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Event data such as rescue requests collected from social media can be leveraged for event monitoring and forecasting.&nbsp; Although current studies have sought to provide better technological infrastructure of systems to support event prediction, several key features such as data bias that may affect the fairness of decision making have seldom been examined. Our project focuses on AI models and tools that enable computer scientists and engineers to incorporate fairness requirements and to mitigate the unfairness, such as implementing equal probability of being rescued in disaster management.</p>\n<p>Our research greatly alleviates or adjusts the unfairness of the prediction algorithm through model regularization and data augmentation. Specifically, our research introduces fairness metrics into temporal point processes (TPPs) for event prediction and incorporates them to penalize the event likelihood function through model regularization. We also introduce data-synthesis methods based on event marker similarities such as geographical features to enhance temporal point processes for missing or biased data. Moreover, the temporal point processes learned by conventional maximum likelihood estimation (MLE) from biased data may be misspecified and may lead to inaccurate predictions. To overcome this issue, we model biased event sequences as modulating TPPs with additional unknown thinning processes and develop a novel debiased imitation learning framework to learn the modulated TPPs and suppress the negative influences of biased data, which is more robust than conventional MLE. Models and algorithms are tested and verified on several benchmark datasets including rescue events in response to 2017 Hurricane Harvey collected from Twitter.</p>\n<p>Through this project, we established the computer science and environmental science research group at LSU to foster interdisciplinary research on fair AI for disaster resilience analysis. The students have gained significant amount of knowledge in the general area of machine learning, &nbsp;deep learning, fair-AI and in the specific domain of statistical point processes, neural point processes and temporal data analysis. Findings of the project have been published in or submitted to prestigious journals and conference proceedings. They have also been incorporated in the instruction and curriculum of graduate and undergraduate courses.&nbsp;&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/06/2023<br>\nModified by: Mingxuan&nbsp;Sun</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nEvent data such as rescue requests collected from social media can be leveraged for event monitoring and forecasting. Although current studies have sought to provide better technological infrastructure of systems to support event prediction, several key features such as data bias that may affect the fairness of decision making have seldom been examined. Our project focuses on AI models and tools that enable computer scientists and engineers to incorporate fairness requirements and to mitigate the unfairness, such as implementing equal probability of being rescued in disaster management.\n\n\nOur research greatly alleviates or adjusts the unfairness of the prediction algorithm through model regularization and data augmentation. Specifically, our research introduces fairness metrics into temporal point processes (TPPs) for event prediction and incorporates them to penalize the event likelihood function through model regularization. We also introduce data-synthesis methods based on event marker similarities such as geographical features to enhance temporal point processes for missing or biased data. Moreover, the temporal point processes learned by conventional maximum likelihood estimation (MLE) from biased data may be misspecified and may lead to inaccurate predictions. To overcome this issue, we model biased event sequences as modulating TPPs with additional unknown thinning processes and develop a novel debiased imitation learning framework to learn the modulated TPPs and suppress the negative influences of biased data, which is more robust than conventional MLE. Models and algorithms are tested and verified on several benchmark datasets including rescue events in response to 2017 Hurricane Harvey collected from Twitter.\n\n\nThrough this project, we established the computer science and environmental science research group at LSU to foster interdisciplinary research on fair AI for disaster resilience analysis. The students have gained significant amount of knowledge in the general area of machine learning, deep learning, fair-AI and in the specific domain of statistical point processes, neural point processes and temporal data analysis. Findings of the project have been published in or submitted to prestigious journals and conference proceedings. They have also been incorporated in the instruction and curriculum of graduate and undergraduate courses.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 12/06/2023\n\n\t\t\t\t\tSubmitted by: MingxuanSun\n"
 }
}