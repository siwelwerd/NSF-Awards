{
 "awd_id": "1909370",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Sound Abstractions for Efficient and Reliable Automated Planning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 499923.0,
 "awd_amount": 515923.0,
 "awd_min_amd_letter_date": "2019-08-01",
 "awd_max_amd_letter_date": "2021-05-24",
 "awd_abstract_narration": "Autonomous systems have the potential to transform society by assisting people in activities ranging from household elder care to space exploration. Such agents need to be versatile enough to solve a range of tasks without prior task-specific programming.  However, it is difficult to compute the behavior that an autonomous agent should execute in order to achieve a new objective (e.g., to search for rocks with high moisture content). This project will develop a new framework and algorithms that utilize the principle of abstraction to efficiently compute task-specific behavior for autonomous agents in a domain-independent fashion.  Since abstraction blurs detail in general, this principle has been difficult to employ in practice -- plans computed using abstract models can miss details, and can be dangerous to use with real-world autonomous systems. This project will develop new methods that keep track of imprecision created by abstraction and effectively resolve it, to efficiently compute reliable plans.\r\n\r\nMore precisely, this project will develop a formal framework for analyzing and creating abstract models that are sound, i.e., they permit only correct inferences (and possibly a subset of correct inferences) with regard to the most accurate model available. In general, such models distinguish model imprecision caused by abstraction from non-determinism or stochasticity inherent in the domain.  It will develop new paradigms for efficient planning using sound abstract models while remaining provably correct with regard to the most accurate model available. These planning paradigms address settings with and without uncertainty; they will also allow AI systems to compute complex plans by automatically composing planners that are independently designed to be efficient for different types of abstract models.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Siddharth",
   "pi_last_name": "Srivastava",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Siddharth Srivastava",
   "pi_email_addr": "siddharths@asu.edu",
   "nsf_id": "000762398",
   "pi_start_date": "2019-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "ORSPA",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852816011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 499923.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The objective of this project was to develop theory and algorithms for abstractions that can make AI planning more efficient, reliable and easily deployable in the real world. While it is well known that good abstractions can improve the scope and scalability of autonomous planning, such abstractions are usually designed by hand; designing suitable abstractions for new tasks and deployments tends to be an error prone and expensive process. This hinders the deployment of autonomous agents that can reason and plan effectively and reliably in the real world.<br /><br />The project team developed new principles, algorithms and analytical approaches for learning and using abstractions while providing strong guarantees of correctness for the planning systems that were developed. The team developed approaches for using abstractions to learn generalized heuristics for planning and generalized Q-functions for Reinforcement Learning (RL). Generalized heuristics and Q-functions can be zero-shot or few-shot transferred to problems with significantly larger numbers of objects and exponentially larger state spaces. &nbsp;<br /><br />This project also showed that powerful and formally well-defined abstractions can be learned autonomously. Evaluation of methods developed in the project featured a range of settings involving physical robots as well as settings involving decision-support agents. <br /><br />Finally, research done as part of this project also showed that using abstractions for hierarchical planning in robotics can effectively bridge the gap between motion planning in the continuous state space and longer-horizon planning and reasoning in a logic-based state space.<br /><br /><br /><strong>Intellectual Merit</strong><br /><br />This project showed that it is possible to develop reliable algorithms for planning and learning that not only outperform SOTA approaches for end-to-end learning on long-horizon, sparse reward settings, but also support formal analysis about correctness with strong notions of reliability and transferrability to new problems not seen during training.&nbsp; Empirical and formal analyses of the approaches developed in this project showed that abstractions learned autonomously using the proposed methods can yield powerful sample efficiency and outperform existing approaches for planning and learning in challenging long-horizon, sparse-reward settings where closed form representations for action dynamics are not available.<br /><br />Methods developed as a part of the project led to several new technical directions and served as foundations for research in other related fields, including: <br /><br /></p>\n<ol>\n<li>Hierarchical explanations for autonomously computed plans</li>\n<li>Autonomous, independent assessment of AI systems. Abstraction mechanisms developed as a part of this project led to hierarchical approaches for interrogating black-box AI systems and assessing their limits and capabilities.</li>\n<li>Autonomous, on-the-job training for future of work with AI systems. The synthesis of methods developed in this project with applications in explainable planning (item #1 in this list) led a new paradigm for on-the-job training that allows workers to be continually informed about the limits and capabilities of their AI systems. </li>\n</ol>\n<p><br /><br /><br /><strong>Broader Impact</strong><br /><br />This project resulted in new computational and mathematical tools for developing AI systems that can autonomously plan to solve complex, long-horizon tasks, and explain their plans to their non-expert users. The methods developed in this project are already being used in research on diverse topics such as explaining AI behavior, AI assessment, and reliable hierarchical planning. <br /><br />These applications help address societal issues relating to the future of work in the presence of AI systems. Together, these methodologies can allow non-expert users to stay informed about the current limits and capabilities of their AI systems, and to understand how to use them productively without having to obtain advanced CS/AI degrees. They also support a new foundation for building AI systems that are not only efficient, but  also help their users to understand how to operate them safely.</p><br>\n<p>\n Last Modified: 11/29/2023<br>\nModified by: Siddharth&nbsp;Srivastava</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe objective of this project was to develop theory and algorithms for abstractions that can make AI planning more efficient, reliable and easily deployable in the real world. While it is well known that good abstractions can improve the scope and scalability of autonomous planning, such abstractions are usually designed by hand; designing suitable abstractions for new tasks and deployments tends to be an error prone and expensive process. This hinders the deployment of autonomous agents that can reason and plan effectively and reliably in the real world.\n\nThe project team developed new principles, algorithms and analytical approaches for learning and using abstractions while providing strong guarantees of correctness for the planning systems that were developed. The team developed approaches for using abstractions to learn generalized heuristics for planning and generalized Q-functions for Reinforcement Learning (RL). Generalized heuristics and Q-functions can be zero-shot or few-shot transferred to problems with significantly larger numbers of objects and exponentially larger state spaces. \n\nThis project also showed that powerful and formally well-defined abstractions can be learned autonomously. Evaluation of methods developed in the project featured a range of settings involving physical robots as well as settings involving decision-support agents. \n\nFinally, research done as part of this project also showed that using abstractions for hierarchical planning in robotics can effectively bridge the gap between motion planning in the continuous state space and longer-horizon planning and reasoning in a logic-based state space.\n\n\nIntellectual Merit\n\nThis project showed that it is possible to develop reliable algorithms for planning and learning that not only outperform SOTA approaches for end-to-end learning on long-horizon, sparse reward settings, but also support formal analysis about correctness with strong notions of reliability and transferrability to new problems not seen during training. Empirical and formal analyses of the approaches developed in this project showed that abstractions learned autonomously using the proposed methods can yield powerful sample efficiency and outperform existing approaches for planning and learning in challenging long-horizon, sparse-reward settings where closed form representations for action dynamics are not available.\n\nMethods developed as a part of the project led to several new technical directions and served as foundations for research in other related fields, including: \n\n\n\nHierarchical explanations for autonomously computed plans\nAutonomous, independent assessment of AI systems. Abstraction mechanisms developed as a part of this project led to hierarchical approaches for interrogating black-box AI systems and assessing their limits and capabilities.\nAutonomous, on-the-job training for future of work with AI systems. The synthesis of methods developed in this project with applications in explainable planning (item #1 in this list) led a new paradigm for on-the-job training that allows workers to be continually informed about the limits and capabilities of their AI systems. \n\n\n\n\n\n\nBroader Impact\n\nThis project resulted in new computational and mathematical tools for developing AI systems that can autonomously plan to solve complex, long-horizon tasks, and explain their plans to their non-expert users. The methods developed in this project are already being used in research on diverse topics such as explaining AI behavior, AI assessment, and reliable hierarchical planning. \n\nThese applications help address societal issues relating to the future of work in the presence of AI systems. Together, these methodologies can allow non-expert users to stay informed about the current limits and capabilities of their AI systems, and to understand how to use them productively without having to obtain advanced CS/AI degrees. They also support a new foundation for building AI systems that are not only efficient, but  also help their users to understand how to operate them safely.\t\t\t\t\tLast Modified: 11/29/2023\n\n\t\t\t\t\tSubmitted by: SiddharthSrivastava\n"
 }
}