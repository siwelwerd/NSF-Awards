{
 "awd_id": "1913149",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Statistical Learning Problems with Complex Stochastic Models",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2019-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2019-08-12",
 "awd_max_amd_letter_date": "2019-08-12",
 "awd_abstract_narration": "Big data is having a profound impact on scientific research and knowledge discovery. And while big data poses many statistical and computational challenges, it also presents unprecedented opportunities for statistics and data science. The investigator will focus on emerging scientific problems through the development of novel statistical and computational means, and address the challenges that arise in solving data intensive complex problems. The research in this project on finance statistics and computational algorithms is motivated by solving practical problems, and will yield cutting-edge statistical techniques and effective computational tools. The investigator actively participates in activities to integrate research with student training and applies the research outcomes to fields like finance and deep learning. \r\n\r\nThe investigator will conduct novel research on stochastic gradient descent algorithms and unified models for financial data. The research goals are to develop innovative statistical methodologies, computing techniques, and theories for: 1) unified stochastic models for combined inference based on both high-frequency and low-frequency financial data, and 2) statistical and computational analysis of stochastic gradient descent algorithms with applications to machine learning in particular deep learning. The investigator intends to establish theoretically-supported statistical methodologies and computational procedures, and significantly advance computational and statistical understanding to the proposed research problems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yazhen",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yazhen Wang",
   "pi_email_addr": "yzwang@stat.wisc.edu",
   "nsf_id": "000486531",
   "pi_start_date": "2019-08-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "21 North Park Street",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537151218",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Big data exerts a profound influence on scientific research and knowledge discovery, continually underscoring the significance of statistics and data science. While big data present considerable statistical and computational challenges, they also offer unprecedented opportunities for advancement in statistics and data science. The researcher aims to tackle emerging scientific issues using innovative statistical and computational approaches, addressing the complexities inherent in big data problem-solving. The proposed research focuses on finance statistics and computational algorithms, driven by real-world problem-solving needs. These endeavors may result in state-of-the-art statistical techniques and efficient computational tools. Additionally, the researcher actively integrates research into student training activities and applies research outcomes to domains such as finance and deep learning.</p>\n<p>Our work has yielded innovative statistical methodologies, computing techniques, and theories for unified stochastic models, accommodating both high-frequency and low-frequency financial data. We have also conducted statistical and computational analyses of stochastic gradient descent algorithms, particularly in the context of machine learning, including deep learning. These efforts are aimed at addressing challenges encountered in finance and machine learning, contributing to scientific advancement. Specific achievements include demonstrating gradient flow central limit theorems and conducting comprehensive joint computational and statistical analyses of gradient descent algorithms, such as stochastic gradient descent and accelerated gradient descent. These results are pivotal for understanding the dynamic behavior and convergence properties of gradient descent methods, especially in the context of non-convex optimization problems encountered in deep learning. Furthermore, our research has introduced unified realized GARCH-Ito models with jumps, enabling combined statistical inferences for both low-frequency and high-frequency financial data. This unified approach enhances the modeling of essential volatility features and facilitates statistical inference across diverse datasets, marking a significant advancement in the field.</p>\n<p>Overall, our research has deepened the understanding and modeling of financial data and advanced joint computational and statistical analysis of gradient descent algorithms, making a substantial impact on the scientific community at large. We have also actively engaged in educational initiatives and promoting diversity in statistics and other scientific disciplines. Dissemination efforts have included presentations at seminars, workshops, and conferences, as well as publications in professional journals and websites. These research findings have direct applications in domains such as finance and machine learning.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 04/15/2024<br>\nModified by: Yazhen&nbsp;Wang</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nBig data exerts a profound influence on scientific research and knowledge discovery, continually underscoring the significance of statistics and data science. While big data present considerable statistical and computational challenges, they also offer unprecedented opportunities for advancement in statistics and data science. The researcher aims to tackle emerging scientific issues using innovative statistical and computational approaches, addressing the complexities inherent in big data problem-solving. The proposed research focuses on finance statistics and computational algorithms, driven by real-world problem-solving needs. These endeavors may result in state-of-the-art statistical techniques and efficient computational tools. Additionally, the researcher actively integrates research into student training activities and applies research outcomes to domains such as finance and deep learning.\n\n\nOur work has yielded innovative statistical methodologies, computing techniques, and theories for unified stochastic models, accommodating both high-frequency and low-frequency financial data. We have also conducted statistical and computational analyses of stochastic gradient descent algorithms, particularly in the context of machine learning, including deep learning. These efforts are aimed at addressing challenges encountered in finance and machine learning, contributing to scientific advancement. Specific achievements include demonstrating gradient flow central limit theorems and conducting comprehensive joint computational and statistical analyses of gradient descent algorithms, such as stochastic gradient descent and accelerated gradient descent. These results are pivotal for understanding the dynamic behavior and convergence properties of gradient descent methods, especially in the context of non-convex optimization problems encountered in deep learning. Furthermore, our research has introduced unified realized GARCH-Ito models with jumps, enabling combined statistical inferences for both low-frequency and high-frequency financial data. This unified approach enhances the modeling of essential volatility features and facilitates statistical inference across diverse datasets, marking a significant advancement in the field.\n\n\nOverall, our research has deepened the understanding and modeling of financial data and advanced joint computational and statistical analysis of gradient descent algorithms, making a substantial impact on the scientific community at large. We have also actively engaged in educational initiatives and promoting diversity in statistics and other scientific disciplines. Dissemination efforts have included presentations at seminars, workshops, and conferences, as well as publications in professional journals and websites. These research findings have direct applications in domains such as finance and machine learning.\n\n\n\t\t\t\t\tLast Modified: 04/15/2024\n\n\t\t\t\t\tSubmitted by: YazhenWang\n"
 }
}