{
 "awd_id": "1908530",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Small: Collaborative Research: Explaining Unsupervised Learning:  Combinatorial Optimization Formulations, Methods and Applications",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927978",
 "po_email": "racharya@nsf.gov",
 "po_sign_block_name": "Raj Acharya",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 234999.0,
 "awd_amount": 234999.0,
 "awd_min_amd_letter_date": "2019-09-03",
 "awd_max_amd_letter_date": "2020-07-14",
 "awd_abstract_narration": "Clustering is a common machine learning and data mining technique which takes a collection of instances/records/things and divides them into groups. It is used in a large variety of domains including social networks (to find communities), biology (to create taxonomies) and neuroscience (to find regions of interest in the brain). There are many clustering algorithms already in existence, but these algorithms do not always explain the clustering. This award addresses the problem of describing the clustering algorithm results to a variety of stakeholders including data scientists, domain scientists and the general public. Explaining the results of these algorithms will allow them to be better understood by stakeholders and allow their use in challenging and sensitive domains where transparency is required. Explanations are given in an initiative form using easy to understand auxiliary information such as tags. This project will consist of three inter-twined tasks. The first will develop easy to understand mechanisms to explain a clustering, whilst the second will allow a human to interact with the explanation by asking queries about it. Finally the third task will attach measure of stability, trust and correctness to the explanations generated from task one.\r\n\r\nThe area of unsupervised learning is immensely popular due to the lack of need for labeled data and there exist many algorithms that can work on a variety of data types: images, graphs, documents, spatial and temporal data. Many domains have a preferred/well-accepted clustering algorithm. However, most algorithms provide just a grouping of the instances/objects into clusters with limited description. The work on describing and/or explaining a solution has gained popularity in the supervised learning context but is under-studied in the unsupervised context.  This award explores these novel explanation problems through discrete combinatorial optimization formulations. Such formulations help in developing explanations requiring interpretable (hence discrete) results, best possible explanations (not any plausible explanation) and in enforcing complex constraints to make explanations match human expectations. This research will leverage much work  in theoretical computer science and use tools from declarative paradigms such as ILP solvers and constraint programming languages. Such tools allow for easy modifications of formulations, a desirable trait as different domains may need different variations in explanation. The usefulness of the techniques will be  demonstrated through their applications to several domains including social networks and genomic data and evaluated by two domain experts in the area.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sekharipuram",
   "pi_last_name": "Ravi",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Sekharipuram S Ravi",
   "pi_email_addr": "ssr6nh@virginia.edu",
   "nsf_id": "000214050",
   "pi_start_date": "2019-09-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Virginia Main Campus",
  "inst_street_address": "1001 EMMET ST N",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTESVILLE",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "4349244270",
  "inst_zip_code": "229034833",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "VA05",
  "org_lgl_bus_name": "RECTOR & VISITORS OF THE UNIVERSITY OF VIRGINIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJG6HU8PA4S5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Virginia Main Campus",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "229034833",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "VA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 156666.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 78333.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\"><span class=\"s1\"><strong>Overview:</strong> With the tremendous growth in the number of applications</span></p>\r\n<p class=\"p1\"><span class=\"s1\">in which data mining and machine learning algorithms are used, it</span></p>\r\n<p class=\"p1\"><span class=\"s1\">has become crucial to add explanations to the decisions made by these</span></p>\r\n<p class=\"p1\"><span class=\"s1\">algorithms. This area of research is referred to as Explainable AI</span></p>\r\n<p class=\"p1\"><span class=\"s1\">(XAI). When this project started, much of the work on XAI considered</span></p>\r\n<p class=\"p1\"><span class=\"s1\">explaining outcomes of supervised learning methods where models learning</span></p>\r\n<p class=\"p1\"><span class=\"s1\">is achieved using training data (e.g., methods using neural networks).</span></p>\r\n<p class=\"p1\"><span class=\"s1\">This project explored techniques for developing explanations for</span></p>\r\n<p class=\"p1\"><span class=\"s1\">unsupervised learning tasks such as clustering and outlier detection,</span></p>\r\n<p class=\"p1\"><span class=\"s1\">which had not received enough attention in the literature. Explanation</span></p>\r\n<p class=\"p1\"><span class=\"s1\">methods for unsupervised learning are important since a large number</span></p>\r\n<p class=\"p1\"><span class=\"s1\">of algorithms for clustering and outlier detection are used in</span></p>\r\n<p class=\"p1\"><span class=\"s1\">practice.<span>&nbsp; </span>For example, in the context of clustering, it is important</span></p>\r\n<p class=\"p1\"><span class=\"s1\">to explain why an algorithm included two data points in the same</span></p>\r\n<p class=\"p1\"><span class=\"s1\">cluster or why it put them in different clusters for the following reason:</span></p>\r\n<p class=\"p1\"><span class=\"s1\">if clusters are constructed from a dataset involving people,</span></p>\r\n<p class=\"p1\"><span class=\"s1\">organizations may use different actions (e.g., approve or deny a</span></p>\r\n<p class=\"p1\"><span class=\"s1\">loan) on different clusters.<span>&nbsp; </span>In the context of outlier detection,</span></p>\r\n<p class=\"p1\"><span class=\"s1\">it is important to explain why a data point was identified as an</span></p>\r\n<p class=\"p1\"><span class=\"s1\">outlier; this is because the technique is used in applications where</span></p>\r\n<p class=\"p1\"><span class=\"s1\">the identified outliers may be further investigated or policed.</span></p>\r\n<p class=\"p2\"><span class=\"s1\">&nbsp;</span></p>\r\n<p class=\"p1\"><span class=\"s1\"><strong>Intellectual Merit:</strong> This research developed rigorous formulations</span></p>\r\n<p class=\"p1\"><span class=\"s1\">of problems associated with the generation of explanations for</span></p>\r\n<p class=\"p1\"><span class=\"s1\">unsupervised learning tasks. These problems belong to the category</span></p>\r\n<p class=\"p1\"><span class=\"s1\">of combinatorial optimization problems which can be studied using</span></p>\r\n<p class=\"p1\"><span class=\"s1\">techniques from algorithms and complexity theory. The work explored</span></p>\r\n<p class=\"p1\"><span class=\"s1\">several forms of explanation.</span></p>\r\n<p class=\"p1\"><span class=\"s1\">One form used auxiliary information (called tags) associated with</span></p>\r\n<p class=\"p1\"><span class=\"s1\">each data point to develop explanations. This form exploited the</span></p>\r\n<p class=\"p1\"><span class=\"s1\">connection with the well known minimum set cover problem in theoretical</span></p>\r\n<p class=\"p1\"><span class=\"s1\">computer science to identify a subset of tags as the explanation</span></p>\r\n<p class=\"p1\"><span class=\"s1\">for each cluster. The results of this work led to algorithmic and</span></p>\r\n<p class=\"p1\"><span class=\"s1\">mathematical programming based techniques for constructing optimal</span></p>\r\n<p class=\"p1\"><span class=\"s1\">or provably near-optimal explanations.<span>&nbsp; </span>This form of explanation</span></p>\r\n<p class=\"p1\"><span class=\"s1\">was was shown to be useful for clusters obtained from many different</span></p>\r\n<p class=\"p1\"><span class=\"s1\">datasets.</span></p>\r\n<p class=\"p2\"><span class=\"s1\">&nbsp;</span></p>\r\n<p class=\"p1\"><span class=\"s1\">A second form of explanation used small subsets of data points</span></p>\r\n<p class=\"p1\"><span class=\"s1\">themselves (called exemplars) as explanations of clusters. The</span></p>\r\n<p class=\"p1\"><span class=\"s1\">corresponding optimization problem combined the tasks of clustering</span></p>\r\n<p class=\"p1\"><span class=\"s1\">and generating exemplars. Since each of these problems is known to</span></p>\r\n<p class=\"p1\"><span class=\"s1\">be computationally intractable, approximation algorithms with</span></p>\r\n<p class=\"p1\"><span class=\"s1\">provable performance guarantees were developed. This exemplar-based</span></p>\r\n<p class=\"p1\"><span class=\"s1\">explanation was shown to be useful for datasets from domains which</span></p>\r\n<p class=\"p1\"><span class=\"s1\">are difficult to understand by humans (e.g., data obtained by</span></p>\r\n<p class=\"p1\"><span class=\"s1\">embedding images and text).</span></p>\r\n<p class=\"p2\"><span class=\"s1\">&nbsp;</span></p>\r\n<p class=\"p1\"><span class=\"s1\">A third form of explanation was developed to distinguish between</span></p>\r\n<p class=\"p1\"><span class=\"s1\">outliers and normal data points. This form of explanation, called</span></p>\r\n<p class=\"p1\"><span class=\"s1\">contrastive explanation, also relies on the use of tags (auxiliary</span></p>\r\n<p class=\"p1\"><span class=\"s1\">information). By focusing on the relationship between tags and data</span></p>\r\n<p class=\"p1\"><span class=\"s1\">points, a rigorous formulation of the contrastive explanation problem</span></p>\r\n<p class=\"p1\"><span class=\"s1\">was developed using the well known Knapsack problem from combinatorial</span></p>\r\n<p class=\"p1\"><span class=\"s1\">optimization as the basis.<span>&nbsp; </span>This enabled the development of efficient</span></p>\r\n<p class=\"p1\"><span class=\"s1\">algorithms for some versions of the problem and complexity results</span></p>\r\n<p class=\"p1\"><span class=\"s1\">for other versions. The resulting algorithms were applied to three</span></p>\r\n<p class=\"p1\"><span class=\"s1\">modalities of data, namely images, text and databases.</span></p>\r\n<p class=\"p1\"><span class=\"s1\">Other topics related to explanation were also explored during the</span></p>\r\n<p class=\"p1\"><span class=\"s1\">period of this grant. One such topic is the stability of explanations,</span></p>\r\n<p class=\"p1\"><span class=\"s1\">that is, whether the generated explanation changes significantly</span></p>\r\n<p class=\"p1\"><span class=\"s1\">when minor changes are made to the auxiliary information (i.e.,</span></p>\r\n<p class=\"p1\"><span class=\"s1\">tags) or the clusters. Another topic was the use of a different</span></p>\r\n<p class=\"p1\"><span class=\"s1\">combinatorial problem (namely, the hitting set problem) to generate</span></p>\r\n<p class=\"p1\"><span class=\"s1\">a more detailed explanation for each cluster.<span>&nbsp; </span>Results produced</span></p>\r\n<p class=\"p1\"><span class=\"s1\">from the work have been published in well known conferences and</span></p>\r\n<p class=\"p1\"><span class=\"s1\">journals. Several additional papers are under preparation.</span></p>\r\n<p class=\"p2\"><span class=\"s1\">&nbsp;</span></p>\r\n<p class=\"p1\"><span class=\"s1\"><strong>Broader Impact: </strong>The grant supported a number of students at the</span></p>\r\n<p class=\"p1\"><span class=\"s1\">graduate and undergraduate levels. Students who were supported by</span></p>\r\n<p class=\"p1\"><span class=\"s1\">the project received valuable training in several areas of computer</span></p>\r\n<p class=\"p1\"><span class=\"s1\">science, including data mining techniques, algorithm design and</span></p>\r\n<p class=\"p1\"><span class=\"s1\">implementation, combinatorial optimization, mathematical programming</span></p>\r\n<p class=\"p1\"><span class=\"s1\">and software design/testing.<span>&nbsp; </span>It also enabled the PI to participate</span></p>\r\n<p class=\"p1\"><span class=\"s1\">in the Computing for Global Challenges (C4GC) outreach program at</span></p>\r\n<p class=\"p1\"><span class=\"s1\">UVA for three years (2022 through 2024) and provide research</span></p>\r\n<p class=\"p1\"><span class=\"s1\">experience to undergraduate students.</span></p>\r\n<p class=\"p1\">&nbsp;</p>\r\n<p class=\"p1\"><span class=\"s1\"><br /></span></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/31/2025<br>\nModified by: Sekharipuram&nbsp;S&nbsp;Ravi</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738346091481_EXPL_image_02--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738346091481_EXPL_image_02--rgov-800width.png\" title=\"Change in descriptions due to block perturbation\"><img src=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738346091481_EXPL_image_02--rgov-66x44.png\" alt=\"Change in descriptions due to block perturbation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Image from a paper in ECML/PKDD 2021</div>\n<div class=\"imageCredit\">Authors</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Sekharipuram&nbsp;S&nbsp;Ravi\n<div class=\"imageTitle\">Change in descriptions due to block perturbation</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738346390915_EXPL_image_04--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738346390915_EXPL_image_04--rgov-800width.png\" title=\"Scaling study of a hitting set based approach for explanation\"><img src=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738346390915_EXPL_image_04--rgov-66x44.png\" alt=\"Scaling study of a hitting set based approach for explanation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Image from a poster by Robert Downey (undergraduate student), Summer 2023</div>\n<div class=\"imageCredit\">Author</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Sekharipuram&nbsp;S&nbsp;Ravi\n<div class=\"imageTitle\">Scaling study of a hitting set based approach for explanation</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738345714120_EXPL_image_01--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738345714120_EXPL_image_01--rgov-800width.png\" title=\"Performance of an approximation algorithm for explanation\"><img src=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738345714120_EXPL_image_01--rgov-66x44.png\" alt=\"Performance of an approximation algorithm for explanation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Image from a paper in AAAI 2020</div>\n<div class=\"imageCredit\">Authors</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Sekharipuram&nbsp;S&nbsp;Ravi\n<div class=\"imageTitle\">Performance of an approximation algorithm for explanation</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738351495537_EXPL_image_05--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738351495537_EXPL_image_05--rgov-800width.png\" title=\"Simultaneous generation of clusters and explanations\"><img src=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738351495537_EXPL_image_05--rgov-66x44.png\" alt=\"Simultaneous generation of clusters and explanations\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Image from a paper in SDM 2024</div>\n<div class=\"imageCredit\">Authors</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Sekharipuram&nbsp;S&nbsp;Ravi\n<div class=\"imageTitle\">Simultaneous generation of clusters and explanations</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738351811382_EXPL_image_06--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738351811382_EXPL_image_06--rgov-800width.png\" title=\"Clusters and Centroids for MNIST dataset\"><img src=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738351811382_EXPL_image_06--rgov-66x44.png\" alt=\"Clusters and Centroids for MNIST dataset\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Image from a paper in SDM 2024</div>\n<div class=\"imageCredit\">Authors</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Sekharipuram&nbsp;S&nbsp;Ravi\n<div class=\"imageTitle\">Clusters and Centroids for MNIST dataset</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738346248114_EXPL_image_03--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738346248114_EXPL_image_03--rgov-800width.png\" title=\"Percentage of clusters covered by tags for Threat dataset\"><img src=\"/por/images/Reports/POR/2025/1908530/1908530_10639762_1738346248114_EXPL_image_03--rgov-66x44.png\" alt=\"Percentage of clusters covered by tags for Threat dataset\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Image from a poser presented by George Li (undergraduate student),\r\nSummer 2022</div>\n<div class=\"imageCredit\">Author</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Sekharipuram&nbsp;S&nbsp;Ravi\n<div class=\"imageTitle\">Percentage of clusters covered by tags for Threat dataset</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nOverview: With the tremendous growth in the number of applications\r\n\n\nin which data mining and machine learning algorithms are used, it\r\n\n\nhas become crucial to add explanations to the decisions made by these\r\n\n\nalgorithms. This area of research is referred to as Explainable AI\r\n\n\n(XAI). When this project started, much of the work on XAI considered\r\n\n\nexplaining outcomes of supervised learning methods where models learning\r\n\n\nis achieved using training data (e.g., methods using neural networks).\r\n\n\nThis project explored techniques for developing explanations for\r\n\n\nunsupervised learning tasks such as clustering and outlier detection,\r\n\n\nwhich had not received enough attention in the literature. Explanation\r\n\n\nmethods for unsupervised learning are important since a large number\r\n\n\nof algorithms for clustering and outlier detection are used in\r\n\n\npractice. For example, in the context of clustering, it is important\r\n\n\nto explain why an algorithm included two data points in the same\r\n\n\ncluster or why it put them in different clusters for the following reason:\r\n\n\nif clusters are constructed from a dataset involving people,\r\n\n\norganizations may use different actions (e.g., approve or deny a\r\n\n\nloan) on different clusters. In the context of outlier detection,\r\n\n\nit is important to explain why a data point was identified as an\r\n\n\noutlier; this is because the technique is used in applications where\r\n\n\nthe identified outliers may be further investigated or policed.\r\n\n\n\r\n\n\nIntellectual Merit: This research developed rigorous formulations\r\n\n\nof problems associated with the generation of explanations for\r\n\n\nunsupervised learning tasks. These problems belong to the category\r\n\n\nof combinatorial optimization problems which can be studied using\r\n\n\ntechniques from algorithms and complexity theory. The work explored\r\n\n\nseveral forms of explanation.\r\n\n\nOne form used auxiliary information (called tags) associated with\r\n\n\neach data point to develop explanations. This form exploited the\r\n\n\nconnection with the well known minimum set cover problem in theoretical\r\n\n\ncomputer science to identify a subset of tags as the explanation\r\n\n\nfor each cluster. The results of this work led to algorithmic and\r\n\n\nmathematical programming based techniques for constructing optimal\r\n\n\nor provably near-optimal explanations. This form of explanation\r\n\n\nwas was shown to be useful for clusters obtained from many different\r\n\n\ndatasets.\r\n\n\n\r\n\n\nA second form of explanation used small subsets of data points\r\n\n\nthemselves (called exemplars) as explanations of clusters. The\r\n\n\ncorresponding optimization problem combined the tasks of clustering\r\n\n\nand generating exemplars. Since each of these problems is known to\r\n\n\nbe computationally intractable, approximation algorithms with\r\n\n\nprovable performance guarantees were developed. This exemplar-based\r\n\n\nexplanation was shown to be useful for datasets from domains which\r\n\n\nare difficult to understand by humans (e.g., data obtained by\r\n\n\nembedding images and text).\r\n\n\n\r\n\n\nA third form of explanation was developed to distinguish between\r\n\n\noutliers and normal data points. This form of explanation, called\r\n\n\ncontrastive explanation, also relies on the use of tags (auxiliary\r\n\n\ninformation). By focusing on the relationship between tags and data\r\n\n\npoints, a rigorous formulation of the contrastive explanation problem\r\n\n\nwas developed using the well known Knapsack problem from combinatorial\r\n\n\noptimization as the basis. This enabled the development of efficient\r\n\n\nalgorithms for some versions of the problem and complexity results\r\n\n\nfor other versions. The resulting algorithms were applied to three\r\n\n\nmodalities of data, namely images, text and databases.\r\n\n\nOther topics related to explanation were also explored during the\r\n\n\nperiod of this grant. One such topic is the stability of explanations,\r\n\n\nthat is, whether the generated explanation changes significantly\r\n\n\nwhen minor changes are made to the auxiliary information (i.e.,\r\n\n\ntags) or the clusters. Another topic was the use of a different\r\n\n\ncombinatorial problem (namely, the hitting set problem) to generate\r\n\n\na more detailed explanation for each cluster. Results produced\r\n\n\nfrom the work have been published in well known conferences and\r\n\n\njournals. Several additional papers are under preparation.\r\n\n\n\r\n\n\nBroader Impact: The grant supported a number of students at the\r\n\n\ngraduate and undergraduate levels. Students who were supported by\r\n\n\nthe project received valuable training in several areas of computer\r\n\n\nscience, including data mining techniques, algorithm design and\r\n\n\nimplementation, combinatorial optimization, mathematical programming\r\n\n\nand software design/testing. It also enabled the PI to participate\r\n\n\nin the Computing for Global Challenges (C4GC) outreach program at\r\n\n\nUVA for three years (2022 through 2024) and provide research\r\n\n\nexperience to undergraduate students.\r\n\n\n\r\n\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 01/31/2025\n\n\t\t\t\t\tSubmitted by: SekharipuramSRavi\n"
 }
}