{
 "awd_id": "1944389",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: EEG-based Cognitive-state Decoding for Interactive Virtual Reality",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 209996.0,
 "awd_amount": 209996.0,
 "awd_min_amd_letter_date": "2019-09-04",
 "awd_max_amd_letter_date": "2019-09-04",
 "awd_abstract_narration": "The increasing availability of affordable, high-performance virtual reality (VR) headsets creates great potential for applications including education, training, and therapy. In many applications, being able to sense a user's mental state could provide key benefits. For instance, VR environments could use brain signals such as the electroencephalogram (EEG) to infer aspects of the user's mental workload or emotional state; this, in turn, could be used to change the difficulty of a training task to make it better-suited to each user's unique experience.  Using such EEG feedback could be valuable not just for training, but in improving people's performance in real applications including aviation, healthcare, defense, and driving. This project's goal is to develop methods and algorithms for integrating EEG sensors into current VR headsets, which provide a logical and unobtrusive framework for mounting these sensors. However, there are important challenges to overcome. For instance, EEG sensors in labs are typically used with a conducting gel, but for VR headsets these sensors will need to work reliably in \"dry\" conditions without the gel. Further, in lab settings, motion isn't an issue, but algorithms for processing the EEG data will need to account for people's head and body motion when they are using headsets. \r\n\r\nTo address these challenges, the project team will build on recent advances in dry EEG electrode technologies and motion artifact suppression algorithms, focusing on supporting passive monitoring and cognitive state feedback. Such passive feedback is likely to be more usable in virtual environments than active EEG feedback, both because people will be using other methods to interact with the environment directly and because passive EEG sensing is more robust to slower response times and decoding errors than active control. Prior studies have demonstrated the potential of EEG for cognitive-state decoding in controlled laboratory scenarios, but practical EEG integration for closed-loop neurofeedback in interactive VR environments requires addressing three critical next questions: (1) can more-practical and convenient EEG dry sensors achieve comparable results to wet sensors?, (2) can passive EEG cognitive-state decoding be made robust to movement-related artifacts?, and (3) can these decoding schemes be generalized across a variety of cognitive tasks and to closed-loop paradigms?  To address these questions, classical cognitive tasks and more-complex simulator tasks will be implemented and tested as novel, interactive VR environments. Building upon preliminary results that successfully characterized movement artifacts and decoded cognitive workload in interactive VR using active-wet EEG sensors, this work will further explore the practical integration of EEG sensors with room-scale VR headsets to balance data quality, cognitive decoding performance, ease of setup and use, and user comfort.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dean",
   "pi_last_name": "Krusienski",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dean Krusienski",
   "pi_email_addr": "djkrusienski@vcu.edu",
   "nsf_id": "000500739",
   "pi_start_date": "2019-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Commonwealth University",
  "inst_street_address": "910 WEST FRANKLIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "RICHMOND",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "8048286772",
  "inst_zip_code": "232849005",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "VA04",
  "org_lgl_bus_name": "VIRGINIA COMMONWEALTH UNIVERSITY",
  "org_prnt_uei_num": "WXQLZ1PA6XP3",
  "org_uei_num": "MLQFL4JSSAA9"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Commonwealth University",
  "perf_str_addr": "425 Biotech 8",
  "perf_city_name": "Richmond",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "232190001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "VA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 209996.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main objective of this research is to investigate whether a user's cognitive state induced by interactive virtual reality (VR) environments can be inferred from simultaneous scalp electroencephalogram (EEG) recordings.&nbsp; The insights gained from this research are envisioned to facilitate virtual interactions that can be adapted based on the cognitive state of the user. These types of adaptive interactions play a key role in expanding the immersive VR experience, optimizing human performance, and providing resources to people with atypical needs.&nbsp;</p>\n<p>Intellectual Merit:</p>\n<p>Two distinct studies were designed and conducted in pursuit of the project objectives.&nbsp; The first study presented participants with a series of immersive VR videos while their EEG was recorded.&nbsp; The participants were asked to subjectively rate their reactions to each video experience according to standard psychological affective state metrics of valence, arousal, liking, and dominance. A novel EEG artifact suppression approach, specific to the prescribed VR interactions, was developed, implemented, and validated.&nbsp; Standard EEG spectral features were extracted, and several spatial and frequency features were found to consistently correlate with specific affective state ratings. Participant-specific machine learning models were developed to estimate the affective state ratings directly from the EEG measures. These models were able to reliably estimate the user's perceived affective state and are envisioned to serve as a framework for future closed-loop experiments where aspects of the VR environment are adapted according to the EEG proxy of affective state.</p>\n<p>The second study was designed to investigate the genesis and variability of EEG responses to visual stimuli presented in VR. Through a better understanding of how the EEG responds to controlled visual stimuli, undesirable EEG artifacts can be more effectively characterized and isolated for suppression, and more robust stimuli and detection algorithms can be designed for closed-loop applications. Participants attended to stereotyped visual stimuli presented through a VR headset while their EEG was recorded.&nbsp; &nbsp;A novel machine learning model was developed to estimate the EEG time series from the temporal properties of the stimuli. The model was able to synthesize reliable approximations of the EEG waveforms, conserving both the temporal and spectral characteristics. These results lay the groundwork for further study of variability and artifacts of EEG from VR stimuli, stimulus optimization for brain-computer interfaces, and the development of future biophysical models of the visual system.</p>\n<p>Broader Impacts:</p>\n<p>Modern VR headsets incorporate a cadre of physiological sensors, and the results of this work can inform the hardware and software development of future VR systems to create more immersive, effective, and inclusive VR experiences using neurofeedback. This technology can have wide-ranging applications including basic research on spatial cognition, navigation, social sciences, and multisensory integration; instructional training; decision and policy making; next-generation learning materials; cognitive therapies; and fitness and entertainment. This multidisciplinary project supported and involved undergraduate and graduate students in biomedical engineering, electrical and computer engineering, computer science, and psychology. The students involved have participated in developing and configuring various hardware and software components, designing and conducting human-subject experiments, performing data analysis, coauthoring papers, and giving technical presentations. This project produced two master's theses, multiple peer-reviewed publications, and numerous presentations. Additionally, two unique, annotated EEG datasets collected from 30 and 15 participants, respectively, were generated and are publicly available.</p><br>\n<p>\n Last Modified: 12/05/2023<br>\nModified by: Dean&nbsp;Krusienski</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe main objective of this research is to investigate whether a user's cognitive state induced by interactive virtual reality (VR) environments can be inferred from simultaneous scalp electroencephalogram (EEG) recordings. The insights gained from this research are envisioned to facilitate virtual interactions that can be adapted based on the cognitive state of the user. These types of adaptive interactions play a key role in expanding the immersive VR experience, optimizing human performance, and providing resources to people with atypical needs.\n\n\nIntellectual Merit:\n\n\nTwo distinct studies were designed and conducted in pursuit of the project objectives. The first study presented participants with a series of immersive VR videos while their EEG was recorded. The participants were asked to subjectively rate their reactions to each video experience according to standard psychological affective state metrics of valence, arousal, liking, and dominance. A novel EEG artifact suppression approach, specific to the prescribed VR interactions, was developed, implemented, and validated. Standard EEG spectral features were extracted, and several spatial and frequency features were found to consistently correlate with specific affective state ratings. Participant-specific machine learning models were developed to estimate the affective state ratings directly from the EEG measures. These models were able to reliably estimate the user's perceived affective state and are envisioned to serve as a framework for future closed-loop experiments where aspects of the VR environment are adapted according to the EEG proxy of affective state.\n\n\nThe second study was designed to investigate the genesis and variability of EEG responses to visual stimuli presented in VR. Through a better understanding of how the EEG responds to controlled visual stimuli, undesirable EEG artifacts can be more effectively characterized and isolated for suppression, and more robust stimuli and detection algorithms can be designed for closed-loop applications. Participants attended to stereotyped visual stimuli presented through a VR headset while their EEG was recorded. A novel machine learning model was developed to estimate the EEG time series from the temporal properties of the stimuli. The model was able to synthesize reliable approximations of the EEG waveforms, conserving both the temporal and spectral characteristics. These results lay the groundwork for further study of variability and artifacts of EEG from VR stimuli, stimulus optimization for brain-computer interfaces, and the development of future biophysical models of the visual system.\n\n\nBroader Impacts:\n\n\nModern VR headsets incorporate a cadre of physiological sensors, and the results of this work can inform the hardware and software development of future VR systems to create more immersive, effective, and inclusive VR experiences using neurofeedback. This technology can have wide-ranging applications including basic research on spatial cognition, navigation, social sciences, and multisensory integration; instructional training; decision and policy making; next-generation learning materials; cognitive therapies; and fitness and entertainment. This multidisciplinary project supported and involved undergraduate and graduate students in biomedical engineering, electrical and computer engineering, computer science, and psychology. The students involved have participated in developing and configuring various hardware and software components, designing and conducting human-subject experiments, performing data analysis, coauthoring papers, and giving technical presentations. This project produced two master's theses, multiple peer-reviewed publications, and numerous presentations. Additionally, two unique, annotated EEG datasets collected from 30 and 15 participants, respectively, were generated and are publicly available.\t\t\t\t\tLast Modified: 12/05/2023\n\n\t\t\t\t\tSubmitted by: DeanKrusienski\n"
 }
}