{
 "awd_id": "1941160",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Collaborative Research: World Modeling for Natural Language Understanding",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2021-12-31",
 "tot_intn_awd_amt": 23905.0,
 "awd_amount": 23905.0,
 "awd_min_amd_letter_date": "2019-09-04",
 "awd_max_amd_letter_date": "2019-09-04",
 "awd_abstract_narration": "A key goal of artificial intelligence (AI) is to build systems that can read and understand language as humans do. This capability underlies a broad range of technologies, including question answering, machine translation, and dialogue systems. While progress has been made, AI systems currently lack the robustness and flexibility of human language understanding---typical systems leverage shallow pattern-matching strategies to perform tasks, and as a result are only effective at the specific tasks they are built for, and fail easily even within those settings. This project addresses these issues by improving the ability of systems to construct rich representations of the \"world\" described in text: Who are the entities involved, and what are their attributes and relationships? What events are taking place, who is participating in those events, and why are they occurring? The design of the systems' notion of a world uses concepts like these that have been identified by cognitive scientists and psychologists as fundamental in human language understanding. The expected benefit of this work is the development of AI systems that can use language flexibly and robustly because, like humans, these systems will perform tasks based on the core information conveyed in language, rather than superficial pattern-matching. In addition to improving systems, this project will have the benefit of building bridges between the AI community and cognitive scientists, psychologists, and linguists---the project's modeling framework provides a pathway through which insights from cognitive science can be translated to model implementation, which can be utilized both for improvement of AI systems and for testing of cognitive hypotheses. \r\n\r\nThis exploratory EAGER project improves the capacity of systems to automatically construct the world underlying the text being analyzed, and designs targeted probing tasks to enable fine-grained assessment of the extent to which systems have captured this information. The modeling framework uses memory-augmented neural networks, leveraging the external memory components to represent worlds. Rather than explicit annotation, the project implements cognitively-inspired design of both world components themselves and inductive bias for encouraging particular components to capture what is intended. Learning is carried out via self-supervised objectives and auxiliary supervision on large datasets of narratives. System evaluation consists of both standard reading comprehension question answering tasks and the development of novel probing tasks. The use of controlled probing tasks draws critically from methodological approaches used in cognitive neuroscience and psycholinguistics, applying these scientific methods for interpretation of artificial systems. These probing tasks allow for targeted analysis of individual world components and provide guidance for model improvement. The methodology of the project iterates between model design and targeted testing via probing tasks, using the results of the latter to guide the former.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Allyson",
   "pi_last_name": "Ettinger",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Allyson Ettinger",
   "pi_email_addr": "aettinger@uchicago.edu",
   "nsf_id": "000791833",
   "pi_start_date": "2019-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606372612",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 23905.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>When humans read text, they develop a rich understanding of the \"world\" being described in that text: Who is involved? What are they doing? What relationship do the entities have, and when and why are different events happening? In this project, our goals were 1) to design artificial intelligence models that are better able to extract these kinds of rich information from language, and 2) to develop better assessments of AI models' capabilities in detecting this kind of information, in order to be able to evaluate models more accurately.</p>\n<p>During the course of this project, on the model development side we successfully designed a model that can effectively keep track of different entities mentioned in text. This model showed strong performance in tracking information about various entities and linking them to previous parts of the text, despite the fact that the model represented a simplification relative to previous models.&nbsp;</p>\n<p>On the model assessment side, we developed a broad range of tests designed to analyze different dimensions of information available in text, in order to test whether AI models can extract this information. These tests involved 1) examining models' knowledge about \"who did what to whom,\" 2) examining models' ability to combine words together to understand complex descriptions (like \"red cat\" or \"man flew\"), 3) testing whether models can retain and use descriptions about an entity even in the face of distraction, and 4) analyzing models' ability to grasp relationships between events based on linguistic cues. We designed all of these tests with careful controls to maximize the accuracy of the tests and avoid inflated results based on unwanted factors. When we applied these new tests to existing state-of-the-art AI models, we found that these AI models are fairly effective at representing information about individual words, but the models show fundamental limitations when it comes to representing and using information about more complex phrases and sentences. Instead, we find that these models rely more on shallow statistical cues, rather than rich information about the \"world\" described in the text. These findings are surprising given the seemingly impressive performance of these models in many contexts, and the findings highlight the importance of using controlled tests to obtain accurate assessment of AI models. Our results also help us to identify more precisely the areas of strength and weakness in current state-of-the-art AI models, which can help to guide additional future improvement of these models toward better representing these critical types of information from language.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/17/2022<br>\n\t\t\t\t\tModified by: Allyson&nbsp;Ettinger</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhen humans read text, they develop a rich understanding of the \"world\" being described in that text: Who is involved? What are they doing? What relationship do the entities have, and when and why are different events happening? In this project, our goals were 1) to design artificial intelligence models that are better able to extract these kinds of rich information from language, and 2) to develop better assessments of AI models' capabilities in detecting this kind of information, in order to be able to evaluate models more accurately.\n\nDuring the course of this project, on the model development side we successfully designed a model that can effectively keep track of different entities mentioned in text. This model showed strong performance in tracking information about various entities and linking them to previous parts of the text, despite the fact that the model represented a simplification relative to previous models. \n\nOn the model assessment side, we developed a broad range of tests designed to analyze different dimensions of information available in text, in order to test whether AI models can extract this information. These tests involved 1) examining models' knowledge about \"who did what to whom,\" 2) examining models' ability to combine words together to understand complex descriptions (like \"red cat\" or \"man flew\"), 3) testing whether models can retain and use descriptions about an entity even in the face of distraction, and 4) analyzing models' ability to grasp relationships between events based on linguistic cues. We designed all of these tests with careful controls to maximize the accuracy of the tests and avoid inflated results based on unwanted factors. When we applied these new tests to existing state-of-the-art AI models, we found that these AI models are fairly effective at representing information about individual words, but the models show fundamental limitations when it comes to representing and using information about more complex phrases and sentences. Instead, we find that these models rely more on shallow statistical cues, rather than rich information about the \"world\" described in the text. These findings are surprising given the seemingly impressive performance of these models in many contexts, and the findings highlight the importance of using controlled tests to obtain accurate assessment of AI models. Our results also help us to identify more precisely the areas of strength and weakness in current state-of-the-art AI models, which can help to guide additional future improvement of these models toward better representing these critical types of information from language.\n\n\t\t\t\t\tLast Modified: 04/17/2022\n\n\t\t\t\t\tSubmitted by: Allyson Ettinger"
 }
}