{
 "awd_id": "1839842",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Real-Time: Formal Reinforcement Learning Methods for the Design of Safety-critical Autonomous Systems",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yueyue Fan",
 "awd_eff_date": "2019-04-01",
 "awd_exp_date": "2022-03-31",
 "tot_intn_awd_amt": 286111.0,
 "awd_amount": 302111.0,
 "awd_min_amd_letter_date": "2019-04-01",
 "awd_max_amd_letter_date": "2020-05-18",
 "awd_abstract_narration": "This EArly-Concept Grant for Exploratory Research (EAGER) project takes a clean-slate first-principles approach to the design of safety-critical autonomous systems by integrating formal methods and reinforcement learning from data. Several recent high-profile traffic incidents involving semi-autonomous vehicles have raised questions about whether current artificial intelligence (AI)-centered methods can ever lead us to Level 4 or 5 autonomy, i.e., to the realization of fully-autonomous vehicles with performance equivalent to a human driver in all driving scenarios. On the other hand, approaches rooted in formal methods for verification and synthesis can provide safety guarantees but have difficulty in efficiently reasoning about uncertainty and the correctness of data-driven models. This project will combine these two, seemingly incompatible, paradigms for designing autonomous systems. It will use model-free reinforcement learning algorithms to learn from semi-autonomous vehicle driving data. It will adopt model-based methods for system design, verification, and synthesis to offer provably safe operation in highly uncertain scenarios. An AutoDrive testbed will be set up where human driving data from scaled vehicular models will be leveraged to infer safe control policies using imitation and inverse reinforcement learning algorithms. The research is relevant to the science of intelligent autonomous transportation systems with significant societal implications. The experimental testbed will be used to provide hands-on research experience to undergraduate students and for K-12 outreach efforts.\r\n\r\nIn particular, the project will develop a framework for optimal control synthesis for safety and performance specification expressed in signal temporal logic. It will then incorporate vehicular and pedestrian kinematics in non-deterministic/probabilistic  transition models specified via probabilistic computation tree logic. Finally, it will develop formal reinforcement learning methods for partially observed dynamic models subject to safety specifications and complex temporal goals by learning from traces of safe human drivers. One key technical contribution of the project will be development of new formal reinforcement learning methods that may be useful in a broad array of applications wherein we must synthesize optimal controllers that satisfy certain safety specifications by learning from data.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rahul",
   "pi_last_name": "Jain",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Rahul A Jain",
   "pi_email_addr": "rahul.jain@usc.edu",
   "nsf_id": "000515860",
   "pi_start_date": "2019-04-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Pierluigi",
   "pi_last_name": "Nuzzo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pierluigi Nuzzo",
   "pi_email_addr": "nuzzo@eecs.berkeley.edu",
   "nsf_id": "000780425",
   "pi_start_date": "2019-04-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3720 S Flower St",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900890001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "163100",
   "pgm_ele_name": "CIS-Civil Infrastructure Syst"
  },
  {
   "pgm_ele_code": "760700",
   "pgm_ele_name": "EPCN-Energy-Power-Ctrl-Netwrks"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "036E",
   "pgm_ref_txt": "CIVIL INFRASTRUCTURE"
  },
  {
   "pgm_ref_code": "1057",
   "pgm_ref_txt": "CIS BASE RESEARCH"
  },
  {
   "pgm_ref_code": "116E",
   "pgm_ref_txt": "RESEARCH EXP FOR UNDERGRADS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9231",
   "pgm_ref_txt": "SUPPL FOR UNDERGRAD RES ASSIST"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "CVIS",
   "pgm_ref_txt": "CIVIL INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 286111.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project set out with the goal of developing foundations of formal reinforcement learning, that marries the power of Reinforcement Learning (RL) to learn and generalize from datasets with the capability that Formal Methods of Control provide to obtain hard guarantees on safety and mission requirements. The two fields are quite different and seemingly incompatible. The project succeeded in bridging these fields. This has important implications in many contemporary applications, e.g., autonomous driving, autonomous robotic systems, power systems, etc. The project developed how to combine the framework of Markov Decision Processes (MDP) commonly used in Reinforcement Learning with the framework of Deterministic Finite Automata (DFA) as well as temporal logic frameworks that can be used to express hard requirements of safety and operational constraints. The project was also able to extend these frameworks to systems with partially observed states. This is important because scene occlusions is a major challenge for autonomous driving systems, as has been observed in many accidents involving vehicles operating with advanced driver-assistance systems (ADAS), sometimes also called Autopilots. The papers were published at top Machine Learning and design automation conferences such as ICML, AAAI, UAI, and ICCAD. The algorithms developed were tested in driving simulators and will eventually be tested on scaled hardware testbeds.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/12/2022<br>\n\t\t\t\t\tModified by: Rahul&nbsp;Jain</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project set out with the goal of developing foundations of formal reinforcement learning, that marries the power of Reinforcement Learning (RL) to learn and generalize from datasets with the capability that Formal Methods of Control provide to obtain hard guarantees on safety and mission requirements. The two fields are quite different and seemingly incompatible. The project succeeded in bridging these fields. This has important implications in many contemporary applications, e.g., autonomous driving, autonomous robotic systems, power systems, etc. The project developed how to combine the framework of Markov Decision Processes (MDP) commonly used in Reinforcement Learning with the framework of Deterministic Finite Automata (DFA) as well as temporal logic frameworks that can be used to express hard requirements of safety and operational constraints. The project was also able to extend these frameworks to systems with partially observed states. This is important because scene occlusions is a major challenge for autonomous driving systems, as has been observed in many accidents involving vehicles operating with advanced driver-assistance systems (ADAS), sometimes also called Autopilots. The papers were published at top Machine Learning and design automation conferences such as ICML, AAAI, UAI, and ICCAD. The algorithms developed were tested in driving simulators and will eventually be tested on scaled hardware testbeds.\n\n\t\t\t\t\tLast Modified: 09/12/2022\n\n\t\t\t\t\tSubmitted by: Rahul Jain"
 }
}