{
 "awd_id": "1908974",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS Core: Small: Realistic Traffic Generation through Application-Agnostic Learning",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922935",
 "po_email": "dmedhi@nsf.gov",
 "po_sign_block_name": "Deepankar Medhi",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 345841.0,
 "awd_amount": 353841.0,
 "awd_min_amd_letter_date": "2019-08-06",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "Industry evaluation of new computer network applications and infrastructure - as well as research evaluation of proposed platforms and protocols - rely on high quality representations of realistic network usage.  Historically these needs have largely been met through the use of workload generators that rely on generalized traffic models.  However, these models have increasingly proven inadequate in modern environments with fast-evolving applications, expanding mobility, and the rising prevalence of Internet-of-Things (IoT) devices in end-user networks.  As a result, novel methods, protocols, and hardware prove difficult to verify in real-world scenarios prior to production deployment.  This project distills complex applications into realistic models that can be used to evaluate future systems and deployments.\r\n\r\nThe tools developed through this project employ a combination of a novel expert system that separates application-specific behavior from infrastructure-specific behavior and a machine learning (ML) pipeline that captures complex application exchanges in order to provide realistic models of application traffic patterns for use in existing generators.  Label selection, classifier design, and choices of existing ML algorithms will drive documentation on both future research direction as well as the environments in which current tools and models are best employed.\r\n\r\nThe generation of abstract but high-fidelity models of application traffic patterns as a result of this project provides valuable data to industry users and researchers alike.  The separation of application behavior from potentially sensitive and proprietary input data  allows for significant expansion of the quality of traffic models available for planning and research tasks while also providing portability to environments exploring new protocols and infrastructure design. The availability of these models allows for significantly more effective validation and reproducibility of prospective studies. Furthermore, the production of these models will integrate with educational outreach efforts to high school, undergraduate, and graduate level courses on computer networking and cybersecurity where representative topologies and application traffic drive hand-on labs.\r\n\r\nDocumentation for project tools and code, as well as backing project data, will be located at http://docs.uh-netlab.org/appmodel/index.html, and it will be publicly available for at least 5 years after the end of substantive project work.  Source code (along with documentation source) will be made available at bitbucket (http://www.bitbucket.org/uh-netlab/) on an ongoing basis.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Deniz",
   "pi_last_name": "Gurkan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Deniz Gurkan",
   "pi_email_addr": "dgurkan@kent.edu",
   "nsf_id": "000486896",
   "pi_start_date": "2019-08-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Houston",
  "inst_street_address": "4300 MARTIN LUTHER KING BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "HOUSTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7137435773",
  "inst_zip_code": "772043067",
  "inst_country_name": "United States",
  "cong_dist_code": "18",
  "st_cong_dist_code": "TX18",
  "org_lgl_bus_name": "UNIVERSITY OF HOUSTON SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "QKWEF8XLMTT3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Houston",
  "perf_str_addr": "4800 Calhoun Boulevard",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "772042015",
  "perf_ctry_code": "US",
  "perf_cong_dist": "18",
  "perf_st_cong_dist": "TX18",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 345841.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>New computer network applications and infrastructure rely on high quality representations of realistic network usage. An early project outcome included a comprehensive study of more than a decade of academic research publications that utilize traffic generation methods. The study resulted in a survey paper outlining the overwhelming reliance on generalized traffic models. As these models have increasingly proven inadequate in modern environments with fast-evolving applications, expanding mobility, and the prevalence of Internet-of-Things devices, realistic models of traffic are a must in evaluation of future systems and deployments. To that end, the project outcomes are a suite of software tools, methods, and algorithms to extract realistic models out of captured network traffic. The model extraction has been achieved using machine learning algorithms through modularized software tools. These software tools embody a processing pipeline, components of which can be integrated into an expert system: traffic captures are first organized into specific end points (pcap processing tool), next a transport protocol handling step bundles the conversations into categories of applications (data set extraction tool), and then finally a clustering and feature extraction step finalizes the process to result in classes of traffic models. Each step of the process has a built-in validation mechanism to ensure a high fidelity traffic modeling outcome. <br />Furthermore, the first and second order analysis of models have been realized using the traffic metrics tool. Individual metrics that are relevant to network effects have been determined. The analysis reports have been created with these metrics to empower the users of the traffic models to make intuitive decisions on the aspects of traffic that are to be accurately represented in network evaluation studies. Finally, a prototype traffic generation capability is developed and included in the software suite to port the models onto any network topology with any number of end points that may be used to generate the traffic on. Additionally, the project achievements include a modeling method that provided an optimized model set for general traffic patterns of web applications that include a multi-tier interaction between a server, a backend service, and clients. The confidence levels on the accuracy of the traffic models have been provided in an extensive metric report that empowers the users of the system to optimize their usage scenario to applicable and relevant models of interest based on the expected performance parameters.<br />The documentation for project outcomes and code as well as project data are located at http://docs.uh-netlab.org/projects/trafficmodeling.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/06/2023<br>\n\t\t\t\t\tModified by: Deniz&nbsp;Gurkan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nNew computer network applications and infrastructure rely on high quality representations of realistic network usage. An early project outcome included a comprehensive study of more than a decade of academic research publications that utilize traffic generation methods. The study resulted in a survey paper outlining the overwhelming reliance on generalized traffic models. As these models have increasingly proven inadequate in modern environments with fast-evolving applications, expanding mobility, and the prevalence of Internet-of-Things devices, realistic models of traffic are a must in evaluation of future systems and deployments. To that end, the project outcomes are a suite of software tools, methods, and algorithms to extract realistic models out of captured network traffic. The model extraction has been achieved using machine learning algorithms through modularized software tools. These software tools embody a processing pipeline, components of which can be integrated into an expert system: traffic captures are first organized into specific end points (pcap processing tool), next a transport protocol handling step bundles the conversations into categories of applications (data set extraction tool), and then finally a clustering and feature extraction step finalizes the process to result in classes of traffic models. Each step of the process has a built-in validation mechanism to ensure a high fidelity traffic modeling outcome. \nFurthermore, the first and second order analysis of models have been realized using the traffic metrics tool. Individual metrics that are relevant to network effects have been determined. The analysis reports have been created with these metrics to empower the users of the traffic models to make intuitive decisions on the aspects of traffic that are to be accurately represented in network evaluation studies. Finally, a prototype traffic generation capability is developed and included in the software suite to port the models onto any network topology with any number of end points that may be used to generate the traffic on. Additionally, the project achievements include a modeling method that provided an optimized model set for general traffic patterns of web applications that include a multi-tier interaction between a server, a backend service, and clients. The confidence levels on the accuracy of the traffic models have been provided in an extensive metric report that empowers the users of the system to optimize their usage scenario to applicable and relevant models of interest based on the expected performance parameters.\nThe documentation for project outcomes and code as well as project data are located at http://docs.uh-netlab.org/projects/trafficmodeling.\n\n\t\t\t\t\tLast Modified: 01/06/2023\n\n\t\t\t\t\tSubmitted by: Deniz Gurkan"
 }
}