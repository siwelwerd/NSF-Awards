{
 "awd_id": "1905449",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "New Extensions of the Master Equation in Mean Field Control Theory and Applications",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Pedro Embid",
 "awd_eff_date": "2019-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 229999.0,
 "awd_amount": 229999.0,
 "awd_min_amd_letter_date": "2019-07-19",
 "awd_max_amd_letter_date": "2019-07-19",
 "awd_abstract_narration": "Mean Field Games and Mean Field Type Control Theory have brought major advances in decision making under uncertainty and control of dynamic systems. A significant step was taken when P.-L. Lions introduced a new partial differential equation known as the Master Equation, which conceptually synthesizes all potential approaches to the field. Unfortunately, this is an extraordinarily difficult equation. In this project, the investigators will develop new mathematical techniques to study the Master Equation. Therefore, the work is a contribution to the conceptual core of mean field theory, the master equation, focusing on two important applications: energy markets and stochastic control with partial information. The broader significance of this work is that it will produce new insights into economics, finance, machine learning, and other fields. Students at both graduate and undergraduate levels will be trained in a large variety of issues and concepts, with opportunities for research and applications. \r\n\r\nThe first problem of the project requires extended mean field control, where the extension lies in the fact that not only the probability distribution of the state, but also the probability distribution of the control enters in the model, and/or in the cost functional to be minimized. It is a new branch of the general theory, which the investigators will develop and apply to energy markets and related problems. The second problem regards nonlocal dependence, which the investigators will apply to the well-established domain of stochastic control with partial information, providing new insights from a mean field point of view. The mathematical techniques involved will include Hamilton-Jacobi equations on infinite dimensional spaces, backward stochastic partial differential equations, and forward-backward systems of nonlocal equations.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alain",
   "pi_last_name": "Bensoussan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alain Bensoussan",
   "pi_email_addr": "Alain.Bensoussan@utdallas.edu",
   "nsf_id": "000451694",
   "pi_start_date": "2019-07-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Philip",
   "pi_last_name": "Graber",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Philip J Graber",
   "pi_email_addr": "Jameson_Graber@baylor.edu",
   "nsf_id": "000722509",
   "pi_start_date": "2019-07-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Dallas",
  "inst_street_address": "800 WEST CAMPBELL RD.",
  "inst_street_address_2": "SP2.25",
  "inst_city_name": "RICHARDSON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9728832313",
  "inst_zip_code": "750803021",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "TX24",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT DALLAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "EJCVPNN1WFS5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas, Dallas",
  "perf_str_addr": "800 W. Campbell Rd",
  "perf_city_name": "Richardson",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "750803021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "TX24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126600",
   "pgm_ele_name": "APPLIED MATHEMATICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 229999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>&nbsp;</strong></p>\n<p>The issue of decision making under uncertainty is of drastic importance for everyone and any organization. Within this general framework, the guidance (control) of dynamic systems evolving in an uncertain environment is a very common situation, from rocket missions to organizations management. In fact, what is called &ldquo;Modern Control Theory&rdquo; was initiated in the context of the space race. It has been extremely successful and has become a basic theory in many diverse areas from Engineering to Economics, Operations Research, Management Science, and many others.</p>\n<p>A considerable number of new concepts, new methodologies, new algorithms have been introduced since the sixties, with impressive applications.</p>\n<p>At the beginning and for a long time, the models of evolution were deterministic. Controlling the deterministic evolution of a dynamic system was sufficiently complex and useful to neglect the issue of uncertainties.</p>\n<p>However, it was obviously insufficient, since all dynamic systems are subject to disturbances, which can have moderate to catastrophic impacts. It is imperative to take them into account in designing the control strategy.</p>\n<p>Stochastic Control became prevalent in the seventies, but not without a price. Modeling uncertainties is tricky. Since time is a key point, the issue of information is essential.&nbsp; To fix the right concepts and methods for stochastic processes took time and engineers and economists needed to learn a lot of new mathematics notions and methods.</p>\n<p>In the whole, despite the difficulties, the development of stochastic control has been extremely successful. For mathematicians, beautiful theories have been invented and turned out to be very useful in a broad range of domains. For non-mathematicians, after serious hurdles, the appropriation of the concepts of stochastic control has been achieved.</p>\n<p>One must realize that stochastic control is not an easy extension of deterministic control. Of course, it allows a fantastic enlargement of the models to be closer to reality, but at the price of new mathematical theories, which are not easy to learn. <br /> Certainly, the most famous is Dynamic Programming. It exists in deterministic control, but Stochastic Dynamic Programming represents a huge step forward, with many more complex mathematics. The success of stochastic control is also related to the development of numerous new concepts and methodologies. Thanks to this remarkable progress, applications could be addressed not only in the space and defense sector but in many others.</p>\n<p>However, there has been from the beginning of stochastic control a caveat. The functional to be optimized is random. The only thing which seemed to be possible is to optimize the average functional. Within this framework and limitation, a beautiful and very useful theory has flourished. The PI has been fortunate to participate from the beginning to this great adventure. The limitation was clear and there was no way to overcome it. The real breakthrough was made around 15 years ago with the introduction of mean field games, by J.M. Lasry and P.L. Lions who coined the name. Similar ideas were independently introduced by P. Caines, Minyi Huang, Roland Malhame. It is important to keep in mind that Mean Field Control and Mean Field Games are different, but very close mathematically.&nbsp; Mean Field Control is the theory which is really the extension of stochastic control, and the main topic of our research. It benefited from the introduction of Mean Field Games by the boost represented by this new theory. Since then, progress has been made in parallel.</p>\n<p>Mean Field Control waives the limitation of considering just averages. The model of evolution of the dynamic system can consider simultaneously random variables. and probability distributions of these random variables (McKean Vlasov diffusions).The same is true for the payoff to optimize. In this way, one is not limited to the average, and all moments can be apprehended. This is essential for risk considerations since the real random payoff can be very different from its average. Mean field games is a very different idea. It studies the limit (in the sense of law of large numbers) of a gigantic Nash game as the number of players becomes infinite. In fact, it transposes to social sciences a basic idea of physics, the averaging principle, which explains why the properties of a medium like a fluid&nbsp;&nbsp; or a gas can be considered at a macroscopic level. The limit of a Mean Field Game is not a control problem. Nevertheless, the mathematics for both mean field control and mean field games are quite similar.</p>\n<p>The mathematics which is needed goes much beyond what existed with stochastic control. During the fifteen past years fantastic progress has been achieved by numerous groups in the world.</p>\n<p>Thanks to the support of NSF, our group has established itself as a major contributor, by simplifying the concepts, developing the methods, solving mathematical hurdles, proposing algorithms, and exploring numerous applications.</p>\n<p>We are not at the end of the story.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/26/2023<br>\n\t\t\t\t\tModified by: Alain&nbsp;Bensoussan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \n\nThe issue of decision making under uncertainty is of drastic importance for everyone and any organization. Within this general framework, the guidance (control) of dynamic systems evolving in an uncertain environment is a very common situation, from rocket missions to organizations management. In fact, what is called \"Modern Control Theory\" was initiated in the context of the space race. It has been extremely successful and has become a basic theory in many diverse areas from Engineering to Economics, Operations Research, Management Science, and many others.\n\nA considerable number of new concepts, new methodologies, new algorithms have been introduced since the sixties, with impressive applications.\n\nAt the beginning and for a long time, the models of evolution were deterministic. Controlling the deterministic evolution of a dynamic system was sufficiently complex and useful to neglect the issue of uncertainties.\n\nHowever, it was obviously insufficient, since all dynamic systems are subject to disturbances, which can have moderate to catastrophic impacts. It is imperative to take them into account in designing the control strategy.\n\nStochastic Control became prevalent in the seventies, but not without a price. Modeling uncertainties is tricky. Since time is a key point, the issue of information is essential.  To fix the right concepts and methods for stochastic processes took time and engineers and economists needed to learn a lot of new mathematics notions and methods.\n\nIn the whole, despite the difficulties, the development of stochastic control has been extremely successful. For mathematicians, beautiful theories have been invented and turned out to be very useful in a broad range of domains. For non-mathematicians, after serious hurdles, the appropriation of the concepts of stochastic control has been achieved.\n\nOne must realize that stochastic control is not an easy extension of deterministic control. Of course, it allows a fantastic enlargement of the models to be closer to reality, but at the price of new mathematical theories, which are not easy to learn. \n Certainly, the most famous is Dynamic Programming. It exists in deterministic control, but Stochastic Dynamic Programming represents a huge step forward, with many more complex mathematics. The success of stochastic control is also related to the development of numerous new concepts and methodologies. Thanks to this remarkable progress, applications could be addressed not only in the space and defense sector but in many others.\n\nHowever, there has been from the beginning of stochastic control a caveat. The functional to be optimized is random. The only thing which seemed to be possible is to optimize the average functional. Within this framework and limitation, a beautiful and very useful theory has flourished. The PI has been fortunate to participate from the beginning to this great adventure. The limitation was clear and there was no way to overcome it. The real breakthrough was made around 15 years ago with the introduction of mean field games, by J.M. Lasry and P.L. Lions who coined the name. Similar ideas were independently introduced by P. Caines, Minyi Huang, Roland Malhame. It is important to keep in mind that Mean Field Control and Mean Field Games are different, but very close mathematically.  Mean Field Control is the theory which is really the extension of stochastic control, and the main topic of our research. It benefited from the introduction of Mean Field Games by the boost represented by this new theory. Since then, progress has been made in parallel.\n\nMean Field Control waives the limitation of considering just averages. The model of evolution of the dynamic system can consider simultaneously random variables. and probability distributions of these random variables (McKean Vlasov diffusions).The same is true for the payoff to optimize. In this way, one is not limited to the average, and all moments can be apprehended. This is essential for risk considerations since the real random payoff can be very different from its average. Mean field games is a very different idea. It studies the limit (in the sense of law of large numbers) of a gigantic Nash game as the number of players becomes infinite. In fact, it transposes to social sciences a basic idea of physics, the averaging principle, which explains why the properties of a medium like a fluid   or a gas can be considered at a macroscopic level. The limit of a Mean Field Game is not a control problem. Nevertheless, the mathematics for both mean field control and mean field games are quite similar.\n\nThe mathematics which is needed goes much beyond what existed with stochastic control. During the fifteen past years fantastic progress has been achieved by numerous groups in the world.\n\nThanks to the support of NSF, our group has established itself as a major contributor, by simplifying the concepts, developing the methods, solving mathematical hurdles, proposing algorithms, and exploring numerous applications.\n\nWe are not at the end of the story.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 10/26/2023\n\n\t\t\t\t\tSubmitted by: Alain Bensoussan"
 }
}