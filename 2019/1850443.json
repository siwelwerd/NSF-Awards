{
 "awd_id": "1850443",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: AF: Markov Chain Monte Carlo Algorithms for Spin Systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2019-01-30",
 "awd_max_amd_letter_date": "2019-01-30",
 "awd_abstract_narration": "Generating samples from probability distributions is a fundamental computational task in science, engineering, and technology. Efficient and unbiased sampling algorithms have a significant impact in a variety of fields, notably including statistics, biology, physics, and computer science. The Markov chain Monte Carlo (MCMC) method provides a powerful class of sampling algorithms used by an active community of researchers in diverse applications, typically relying on heuristics for their design and analysis.  This project focuses on the theoretical study of MCMC algorithms, aiming to increase their reliability and to reduce computational costs in practice. Two application areas will be most relevant: statistical physics and machine learning. Most of the work will be carried out in close collaboration with graduate students; the training provided will be conducive to their development as researchers. \r\n\r\nThe PI will consider the problem of sampling from Gibbs (or Boltzmann) distributions in the context of spin systems, a general framework for modeling interacting systems of simple elements. In this context, the PI intends to rigorously analyze the efficiency of popular MCMC algorithms. Two specific foci will be the Alternating Scan dynamics for bipartite systems and the Swendsen-Wang algorithm for the classical Ising/Potts model from statistical physics. The former is actively used to train Restricted Boltzmann Machines and build sophisticated deep learning architectures, while the latter is a standard method for sampling from the Ising/Potts distribution. The PI will also study the interplay between the efficiency of MCMC algorithms and the phase transitions of the underlying probabilistic model.  Additional computational implications of these phase transitions will be explored in the context of structure learning, a closely related supervised learning problem. As such, the connections between theoretical computer science, statistical physics, and machine learning will play a central role in this project.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Antonio",
   "pi_last_name": "Blanca",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Antonio Blanca",
   "pi_email_addr": "azb1015@psu.edu",
   "nsf_id": "000707156",
   "pi_start_date": "2019-01-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "110 Technology Center Building",
  "perf_city_name": "University Park",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168027000",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "PA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7796",
   "pgm_ref_txt": "ALGORITHMIC FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Sampling probability distributions is a fundamental task in science and engineering. The Markov chain Monte Carlo (MCMC) method provides a powerful class of sampling algorithms with extensive applications across many fields. These algorithms, however, &nbsp;typically rely on heuristics for their design and analysis. This project enhanced the theoretical methods for the rigorous study of MCMC sampling algorithms in some of their most fundamental applications in theoretical computer science, statistical physics, and machine learning. The theoretical study of MCMC algorithms is well known to improve their performance across most metrics.</p>\n<p><br />Several methods for analyzing Markov chains were developed or enhanced in this project, facilitating the theoretical analysis of popular MCMC sampling algorithms that have been deployed in applications for over 30 years, with some of the algorithms studied being among the most popular in applications in statistical physics and machine learning. The analytic techniques used create exciting connections between these research areas. Furthermore, the PI studied the computational complexity of related inference problems. Specifically, new connections between the computational hardness of inference and sampling were revealed as part of this project. The techniques used combine ideas from theoretical computer science, machine learning, and statistical physics, creating important bridges between these research areas. The work in this proposal was done in close collaboration with graduate students; the training provided was central to their development as researchers.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/20/2021<br>\n\t\t\t\t\tModified by: Antonio&nbsp;Blanca Pimentel</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSampling probability distributions is a fundamental task in science and engineering. The Markov chain Monte Carlo (MCMC) method provides a powerful class of sampling algorithms with extensive applications across many fields. These algorithms, however,  typically rely on heuristics for their design and analysis. This project enhanced the theoretical methods for the rigorous study of MCMC sampling algorithms in some of their most fundamental applications in theoretical computer science, statistical physics, and machine learning. The theoretical study of MCMC algorithms is well known to improve their performance across most metrics.\n\n\nSeveral methods for analyzing Markov chains were developed or enhanced in this project, facilitating the theoretical analysis of popular MCMC sampling algorithms that have been deployed in applications for over 30 years, with some of the algorithms studied being among the most popular in applications in statistical physics and machine learning. The analytic techniques used create exciting connections between these research areas. Furthermore, the PI studied the computational complexity of related inference problems. Specifically, new connections between the computational hardness of inference and sampling were revealed as part of this project. The techniques used combine ideas from theoretical computer science, machine learning, and statistical physics, creating important bridges between these research areas. The work in this proposal was done in close collaboration with graduate students; the training provided was central to their development as researchers. \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 08/20/2021\n\n\t\t\t\t\tSubmitted by: Antonio Blanca Pimentel"
 }
}