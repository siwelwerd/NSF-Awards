{
 "awd_id": "1925590",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CC* Compute: High Performance Campus Computing for Institutional Research at the American Museum of Natural History",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924220",
 "po_email": "kthompso@nsf.gov",
 "po_sign_block_name": "Kevin Thompson",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 399258.0,
 "awd_amount": 399258.0,
 "awd_min_amd_letter_date": "2019-06-21",
 "awd_max_amd_letter_date": "2019-06-21",
 "awd_abstract_narration": "Through the National Science Foundation CC* program, the American Museum of Natural History (AMNH) expands the High-Performance Computing (HPC) capabilities that directly support the Museum's research. AMNH conducts scientific research and educational activities across astrophysics, anthropology, biology, and geosciences. The increasingly data-intensive nature of this research requires greater access to computational resources and to ever more sophisticated tools, including local and remote HPC clusters.\r\n\r\nIn this project, AMNH is expanding its on-premise computing cluster capacity and consolidating all existing clusters into a unified open-source software framework. These clusters are connected to the Museum's Science DMZ, a high-performance network specifically designed for research data flows, which provides high-speed network access between the Internet2 and the AMNH on-premise clusters. Additionally, AMNH researchers can execute complex workloads at scale using cloud resources at Amazon via the same local HPC management framework. Federation with InCommon provides both AMNH researchers and outside collaborators with secure access to these resources via a common authentication and authorization framework. Finally, the AMNH clusters are integrated with the Open Science Grid allowing AMNH to offer idle computing cycles to the wider research community while providing AMNH researchers with the same access to remote computing resources. These improvements greatly expand the overall HPC capacity available to AMNH scientists, increasing the speed and effectiveness of their research and decreasing time to discovery. Additionally, the work of AMNH scientists informs the Museum's educational and curatorial programs, directly benefiting AMNH students and the public.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Juan",
   "pi_last_name": "Montes",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Juan Montes",
   "pi_email_addr": "jmontes@amnh.org",
   "nsf_id": "000769332",
   "pi_start_date": "2019-06-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Cheryl",
   "pi_last_name": "Hayashi",
   "pi_mid_init": "Y",
   "pi_sufx_name": "",
   "pi_full_name": "Cheryl Y Hayashi",
   "pi_email_addr": "chayashi@amnh.org",
   "nsf_id": "000474991",
   "pi_start_date": "2019-06-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Benedetto",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Michael J Benedetto",
   "pi_email_addr": "mbenedetto@amnh.org",
   "nsf_id": "000769392",
   "pi_start_date": "2019-06-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Samuel",
   "pi_last_name": "Tran",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Samuel Tran",
   "pi_email_addr": "stran@amnh.org",
   "nsf_id": "000769399",
   "pi_start_date": "2019-06-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "American Museum Natural History",
  "inst_street_address": "200 CENTRAL PARK W",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2127695975",
  "inst_zip_code": "100245102",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NY12",
  "org_lgl_bus_name": "THE AMERICAN MUSEUM OF NATURAL HISTORY",
  "org_prnt_uei_num": "MNJDKB4FXLM6",
  "org_uei_num": "MNJDKB4FXLM6"
 },
 "perf_inst": {
  "perf_inst_name": "American Museum of Natural History",
  "perf_str_addr": "Central Park West at 79th Street",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100245000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NY12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808000",
   "pgm_ele_name": "Campus Cyberinfrastructure"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 399258.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The American Museum of Natural History (AMNH) implemented a dedicated computing cluster named \"MENDEL\" to provide access to high-performance computing (HPC) resources for research programs spanning astrophysics, geosciences, biology, and genomics and provide a foundation for future HPC expansions at the Museum.</p>\n<p>MENDEL consists of twenty-six (26) compute nodes providing the following:</p>\n<ul>\n<li>1,344 traditional computing cores.</li>\n<li>10,752 GPU cores</li>\n<li> 10TB of compute memory.</li>\n<li> 256 terabytes (TB) of usable storage across all cluster nodes.</li>\n</ul>\n<p>Several supporting systems/services are deployed as part of MENDEL:</p>\n<ul>\n<li>A head node providing management and orchestration of computing jobs submitted to MENDEL using SLURM Workload Manager as the cluster job scheduler. The head node can also instantiate compute nodes in AWS, allowing researchers to directly leverage allocations of cloud resources from MENDEL.</li>\n<li>A Network File System (NFS) node that provides access to centrally shared data to all compute and support nodes.</li>\n<li>A Data Transfer Node (DTN) running Globus to facilitate high-speed data transfers between local Museum systems and/or various remote partners and data sources.</li>\n<li>An Open Science Pool (OSPool) Access Point allowing jobs to be directly submitted to the OSPool. The Open Science Pool (OSPool) is a virtual cluster operated by the Open Science Grid (OSG), with shared computing and data resources via distributed high-throughput computing (dHTC) technologies. Access to the OSPool greatly increases the resources available to Museum researchers for certain types of jobs.</li>\n<li>An Open OnDemand job submission web service.</li>\n<li>XDMod services which collect detailed operational metrics of the cluster. XDMod cluster statistics from MENDEL as well as other AMNH HPC clusters are sent daily to the XD Metrics Service (XMS) which aggregates usage data for NSF supported clusters nationally. </li>\n</ul>\n<p>MENDEL's cluster nodes are interconnected using InfiniBand for compute and storage access, and a separate dedicated 10Gbps Ethernet network is used for node management.</p>\n<p>Twenty percent (20%) of available resources on MENDEL are reserved for use by OSPool, which aggregates mostly opportunistic (\"backfill\") computing resources from contributing clusters, making them available to the US-based open science community.</p>\n<p><strong><span style=\"text-decoration: underline;\">SIGNIFICANT RESEARCH USAGE</span></strong></p>\n<p>More than 70 researchers at AMNH have been granted access to MENDEL to date. The work being undertaken using MENDEL includes:</p>\n<ul>\n<li>Whole genome sequence alignment, chromosome-level scaffolding, phylogenetic network inference, and genome assembly to various analyses of whole genomes.</li>\n<li>Hydrodynamical simulations of star formation with state-of-the-art physics (non-ideal MHD) using the 3D AMR code RAMSES with the aim of conducting a parametric study to compare the size of the protoplanetary disk with a recently developed analytical model.</li>\n<li>Studies of brown dwarfs using observed spectra to back-out fundamental parameters and parametrize cloud conditions.&nbsp; This \"spectral inversion method\" allows researchers to determine the Pressure - Temperature profile of a given source and determine molecular abundances which can be compared to stars and solar system planets alike.</li>\n<li>The creation of 3D models using high-resolution volumetric scans to reveal respiratory structures of insect tracheae allowing for a comprehensive comparative analysis of respiratory structures in many orders of insects. An expansion of this study into arthropods is underway with the goal to help elucidate evolutionary patterns of respiration in arthropods, possibly including the transition to land that occurred some 400 million years ago.</li>\n<li>The development of tools, workflows, and guides to help biologists and wildlife managers leverage the power of machine learning at scale to locate and identify animals in images, specifically camera trap datasets and streaming video.</li>\n<li>Investigation of the processes of speciation using whole genomes to understand gene divergence between populations and species and how variation in allelic introgression increases over time.</li>\n<li>The training of SMDET models to find moving objects in astronomical images which can be tailored to detect a variety of objects and phenomena, including dim and fast-moving objects that represent previously unknown low mass systems in the solar neighborhood to improve our understanding of stellar and planetary formation, chemistry, and weather.</li>\n<li>The creation of the most complete phylogenetic tree for Birds based on genomic data, including over 2,700 species using assembled data sets from studies that sequenced Ultraconserved Elements (UCE) or whole genomes to perform supermatrix and species tree analyses.</li>\n<li>Setting the genomic basis of a new model system in mammals (bats) to study the mechanisms of repeated evolution of traits using 20 new bat genomes to explore genomic regions of high and low divergence linked to purifying selection, gene inactivating regions, mutations leading to gain or change in function, molecular differences associated with diet and feeding behaviors, variation in genes related to lipid and fatty acid metabolism. Given the current health crisis that the world is facing due to COVID-19, genomic research on bats is crucial to understand, address, and prevent future pandemics.</li>\n</ul>\n<p>Additionally, students and post-docs at the Museum's Richard Gilder Graduate School are provided allocations on MENDEL, giving them the resources needed to pursue thier research and educational goals.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/17/2022<br>\n\t\t\t\t\tModified by: Juan&nbsp;Montes</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1925590/1925590_10613848_1654108865702_GLOBUSDECK--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1925590/1925590_10613848_1654108865702_GLOBUSDECK--rgov-800width.jpg\" title=\"AMNH MENDEL CLUSTER\"><img src=\"/por/images/Reports/POR/2022/1925590/1925590_10613848_1654108865702_GLOBUSDECK--rgov-66x44.jpg\" alt=\"AMNH MENDEL CLUSTER\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A structural overview of the ?MENDEL? Cluster at the American Museum of Natural History (AMNH).</div>\n<div class=\"imageCredit\">American Museum of Natural History</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Michael&nbsp;Benedetto</div>\n<div class=\"imageTitle\">AMNH MENDEL CLUSTER</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1925590/1925590_10613848_1654108994586_GLOBUSDECK2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1925590/1925590_10613848_1654108994586_GLOBUSDECK2--rgov-800width.jpg\" title=\"AMNH SCIENTIFIC COMPUTING OVERVIEW\"><img src=\"/por/images/Reports/POR/2022/1925590/1925590_10613848_1654108994586_GLOBUSDECK2--rgov-66x44.jpg\" alt=\"AMNH SCIENTIFIC COMPUTING OVERVIEW\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A high-level overview of the AMNH scientific computing infrastructure including the NSF funded MENDEL cluster and ScienceDMZ.</div>\n<div class=\"imageCredit\">American Museum of Natural History</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Michael&nbsp;Benedetto</div>\n<div class=\"imageTitle\">AMNH SCIENTIFIC COMPUTING OVERVIEW</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe American Museum of Natural History (AMNH) implemented a dedicated computing cluster named \"MENDEL\" to provide access to high-performance computing (HPC) resources for research programs spanning astrophysics, geosciences, biology, and genomics and provide a foundation for future HPC expansions at the Museum.\n\nMENDEL consists of twenty-six (26) compute nodes providing the following:\n\n1,344 traditional computing cores.\n10,752 GPU cores\n 10TB of compute memory.\n 256 terabytes (TB) of usable storage across all cluster nodes.\n\n\nSeveral supporting systems/services are deployed as part of MENDEL:\n\nA head node providing management and orchestration of computing jobs submitted to MENDEL using SLURM Workload Manager as the cluster job scheduler. The head node can also instantiate compute nodes in AWS, allowing researchers to directly leverage allocations of cloud resources from MENDEL.\nA Network File System (NFS) node that provides access to centrally shared data to all compute and support nodes.\nA Data Transfer Node (DTN) running Globus to facilitate high-speed data transfers between local Museum systems and/or various remote partners and data sources.\nAn Open Science Pool (OSPool) Access Point allowing jobs to be directly submitted to the OSPool. The Open Science Pool (OSPool) is a virtual cluster operated by the Open Science Grid (OSG), with shared computing and data resources via distributed high-throughput computing (dHTC) technologies. Access to the OSPool greatly increases the resources available to Museum researchers for certain types of jobs.\nAn Open OnDemand job submission web service.\nXDMod services which collect detailed operational metrics of the cluster. XDMod cluster statistics from MENDEL as well as other AMNH HPC clusters are sent daily to the XD Metrics Service (XMS) which aggregates usage data for NSF supported clusters nationally. \n\n\nMENDEL's cluster nodes are interconnected using InfiniBand for compute and storage access, and a separate dedicated 10Gbps Ethernet network is used for node management.\n\nTwenty percent (20%) of available resources on MENDEL are reserved for use by OSPool, which aggregates mostly opportunistic (\"backfill\") computing resources from contributing clusters, making them available to the US-based open science community.\n\nSIGNIFICANT RESEARCH USAGE\n\nMore than 70 researchers at AMNH have been granted access to MENDEL to date. The work being undertaken using MENDEL includes:\n\nWhole genome sequence alignment, chromosome-level scaffolding, phylogenetic network inference, and genome assembly to various analyses of whole genomes.\nHydrodynamical simulations of star formation with state-of-the-art physics (non-ideal MHD) using the 3D AMR code RAMSES with the aim of conducting a parametric study to compare the size of the protoplanetary disk with a recently developed analytical model.\nStudies of brown dwarfs using observed spectra to back-out fundamental parameters and parametrize cloud conditions.  This \"spectral inversion method\" allows researchers to determine the Pressure - Temperature profile of a given source and determine molecular abundances which can be compared to stars and solar system planets alike.\nThe creation of 3D models using high-resolution volumetric scans to reveal respiratory structures of insect tracheae allowing for a comprehensive comparative analysis of respiratory structures in many orders of insects. An expansion of this study into arthropods is underway with the goal to help elucidate evolutionary patterns of respiration in arthropods, possibly including the transition to land that occurred some 400 million years ago.\nThe development of tools, workflows, and guides to help biologists and wildlife managers leverage the power of machine learning at scale to locate and identify animals in images, specifically camera trap datasets and streaming video.\nInvestigation of the processes of speciation using whole genomes to understand gene divergence between populations and species and how variation in allelic introgression increases over time.\nThe training of SMDET models to find moving objects in astronomical images which can be tailored to detect a variety of objects and phenomena, including dim and fast-moving objects that represent previously unknown low mass systems in the solar neighborhood to improve our understanding of stellar and planetary formation, chemistry, and weather.\nThe creation of the most complete phylogenetic tree for Birds based on genomic data, including over 2,700 species using assembled data sets from studies that sequenced Ultraconserved Elements (UCE) or whole genomes to perform supermatrix and species tree analyses.\nSetting the genomic basis of a new model system in mammals (bats) to study the mechanisms of repeated evolution of traits using 20 new bat genomes to explore genomic regions of high and low divergence linked to purifying selection, gene inactivating regions, mutations leading to gain or change in function, molecular differences associated with diet and feeding behaviors, variation in genes related to lipid and fatty acid metabolism. Given the current health crisis that the world is facing due to COVID-19, genomic research on bats is crucial to understand, address, and prevent future pandemics.\n\n\nAdditionally, students and post-docs at the Museum's Richard Gilder Graduate School are provided allocations on MENDEL, giving them the resources needed to pursue thier research and educational goals.\n\n\t\t\t\t\tLast Modified: 06/17/2022\n\n\t\t\t\t\tSubmitted by: Juan Montes"
 }
}