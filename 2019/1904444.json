{
 "awd_id": "1904444",
 "agcy_id": "NSF",
 "tran_type": "CoopAgrmnt",
 "awd_istr_txt": "Cooperative Agreement",
 "awd_titl_txt": "Exploring Clouds for Acceleration of Science (E-CAS)",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924220",
 "po_email": "kthompso@nsf.gov",
 "po_sign_block_name": "Kevin Thompson",
 "awd_eff_date": "2018-11-15",
 "awd_exp_date": "2021-12-31",
 "tot_intn_awd_amt": 3030955.0,
 "awd_amount": 3030955.0,
 "awd_min_amd_letter_date": "2018-11-15",
 "awd_max_amd_letter_date": "2020-10-07",
 "awd_abstract_narration": "Internet2 leads the \"Exploring Clouds for Acceleration of Science (E-CAS)\" project in partnership with representative commercial cloud providers to accelerate scientific discoveries. The effort seek to demonstrate the effectiveness of commercial cloud platforms and services in supporting applications that are critical to growing academic and research computing and computational science communities, and seeks to illustrate the viability of these services as an option for leading-edge research across a broad scope of science. The project helps researchers understand the potential benefit of larger-scale commercial platforms for scientific application workflows such as those currently using NSF's High-Performance Computing (HPC). It also explores how scientific workflows can innovatively leverage advancements provided by commercial cloud providers.  The project aims to accelerate scientific discovery through integration and optimization of commercial cloud service advancements; identify gaps between cloud provider capabilities and their potential for enhancing academic research; and provide initial steps in documenting emerging tools and leading deployment practices to share with the community.\r\n\r\nCloud computing has revolutionized enterprise computing over the past decade and it has the potential to provide similar impact for campus-based scientific workloads. The E-CAS project explores this potential by providing two phases of funded campus-based projects addressing acceleration of science. Each phase is followed by a community-led workshop to assess lessons learned and to define leading practices. Projects are selected from two categories; time-to-science (to achieve the best time-to-solution for scientific application/workflows that may be time or situation sensitive) and innovation (to explore innovative use of heterogeneous hardware resources, serverless applications and/or machine learning to support and extend application workflows). The project is guided by an external advisory board including leading academic experts in computational science and other fields, commercial cloud representatives, NSF program officers, and others. It leverages prior and concurrent NSF investments while creating a new model of scalable cloud service partnerships to enhance science in a broad spectrum of disciplines.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Bottum",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "James Bottum",
   "pi_email_addr": "jb@internet2.edu",
   "nsf_id": "000717522",
   "pi_start_date": "2018-11-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Howard",
   "pi_last_name": "Pfeffer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Howard Pfeffer",
   "pi_email_addr": "hpfeffer@internet2.edu",
   "nsf_id": "000781740",
   "pi_start_date": "2018-11-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ana",
   "pi_last_name": "Hunsinger",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ana Hunsinger",
   "pi_email_addr": "ana@internet2.edu",
   "nsf_id": "000145007",
   "pi_start_date": "2018-11-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "INTERNET2",
  "inst_street_address": "1150 18TH ST NW STE 750",
  "inst_street_address_2": "",
  "inst_city_name": "WASHINGTON",
  "inst_state_code": "DC",
  "inst_state_name": "District of Columbia",
  "inst_phone_num": "7349134264",
  "inst_zip_code": "200363880",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DC00",
  "org_lgl_bus_name": "UNIVERSITY CORPORATION FOR ADVANCED INTERNET DEVELOPMENT",
  "org_prnt_uei_num": "",
  "org_uei_num": "DZEBKFRD1ZN6"
 },
 "perf_inst": {
  "perf_inst_name": "INTERNET2",
  "perf_str_addr": "1150 18th St NW",
  "perf_city_name": "Washington",
  "perf_st_code": "DC",
  "perf_st_name": "District of Columbia",
  "perf_zip_code": "200363825",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DC00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 3030955.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The first phase of the E-CAS project saw six teams develop and extend their scientific workflows using commercial cloud resources provided by Google Cloud Platform and Amazon Web Services over the course of a year.&nbsp;&nbsp;At the end of that first year, a peer review process was conducted to identify two teams who were able to scale and make the most effective use of the commercial cloud platforms through innovatively utilizing hardware accelerators and modern machine learning methods.&nbsp;&nbsp;The two teams selected to progress into Phase II were led by Philip Harris from the Massachusetts Institute of Technology and Salvador Dura-Bernal from the State University of New York. For the second phase of the E-CAS project these two teams were provided additional funding to accelerate science running their workflows at large scale.</p>\n<p>The project demonstrated that the variety of hardware platforms and software services available through commercial cloud providers could be leveraged to support a range of different scientific disciplines and has been shown to be a viable option for large scale computational science.&nbsp;</p>\n<p>The scale of resources available was demonstrated by the team from&nbsp;<strong>SUNY</strong>&nbsp;using more than 100,000 compute cores including simulations that used 1.8 million core hours over several days to create highly detailed models of the human motor cortex. The team from&nbsp;<strong>UW Madison</strong>&nbsp;showed how more than 50,000 Graphics Processing Unit (GPU) cores across multiple geographic regions and multiple cloud providers could be combined to provide an analysis platform for the IceCube neutrino observatory. The team from&nbsp;<strong>SDSC</strong>&nbsp;demonstrated how the dynamic scalability of the cloud platforms could be harnessed to provide additional compute power on demand by bursting phylogenetic workflows from the Comet supercomputer in San Diego to the latest generation of cloud-based graphics processors on the east coast, significantly reducing job queue times and speeding up processing. The teams from&nbsp;<strong>George Washington University&nbsp;</strong>and&nbsp;<strong>Purdue&nbsp;</strong>demonstrated how the easily accessible public nature of the cloud platforms could be leveraged to share their data sets and workflows with their communities to support reproducible computational workflow packages in bioinformatics and drug development, and to enable community contributions to a global database which is used to model the effects of urbanization on weather and climate. And finally, the team led by&nbsp;<strong>MIT</strong>&nbsp;demonstrated how high energy physics workflows could be individually optimized using a range of different hardware accelerators in the cloud to provide ?Machine Learning as a Service?, reducing compute loads and increasing performance of on-premises and national compute facilities.&nbsp;</p>\n<p>The project identified several key benefits of cloud platforms including:</p>\n<ul>\n<li>the flexibility to try many different combinations of hardware, software, and firmware to optimize Machine Learning and large-scale data processing.</li>\n<li>support for hybrid modalities using heterogeneous hardware, for example to provide Machine Learning as a Service. This is a form of non-traditional bursting that can be used to augment and improve on-prem compute models.</li>\n<li>Cloud operator specific hardware and machine learning platforms, such as tensor processing units. Specific hardware and software platforms are being developed by commercial cloud providers to create competitive advantage and differentiation.</li>\n<li>Cloud can be used to reserve significant resources for extended durations to support long duration jobs, or can be used to access large amounts of preemptible nodes at reduced costs for jobs that can be easily stopped and restarted.</li>\n</ul>\n<p>The following observations were also made:</p>\n<ul>\n<li>The flow of funds for research computing is important to institutions and the commercial transaction of ?real dollars? as opposed to credits and quotas increases focus on contracts, compliance and procurement issues which can in-turn cause project delays while the institution works towards operational maturity in cloud computing.</li>\n<li>Developing software to support workflows takes significant time and expertise.&nbsp;&nbsp;While this is not specific to commercial cloud platforms, there needs to be increased focus on the role of research support professionals and the associated skills required to establish well-managed platforms for experimentation and analysis.</li>\n</ul>\n<p>The E-CAS project clearly demonstrated the effectiveness of commercial cloud platforms in supporting a range of applications for the research computing communities and that commercial cloud has an important role in the computational science ecosystem.&nbsp;&nbsp;The enormous scale and continuous evolution of commercial cloud platforms mean that they can be a tremendous resource for innovation and large-scale data processing; however, to take full advantage of commercial cloud requires a focus on the development of research support staff and institutional familiarity with the administration of cloud procurement and platforms.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/30/2022<br>\n\t\t\t\t\tModified by: Howard&nbsp;Pfeffer</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe first phase of the E-CAS project saw six teams develop and extend their scientific workflows using commercial cloud resources provided by Google Cloud Platform and Amazon Web Services over the course of a year.  At the end of that first year, a peer review process was conducted to identify two teams who were able to scale and make the most effective use of the commercial cloud platforms through innovatively utilizing hardware accelerators and modern machine learning methods.  The two teams selected to progress into Phase II were led by Philip Harris from the Massachusetts Institute of Technology and Salvador Dura-Bernal from the State University of New York. For the second phase of the E-CAS project these two teams were provided additional funding to accelerate science running their workflows at large scale.\n\nThe project demonstrated that the variety of hardware platforms and software services available through commercial cloud providers could be leveraged to support a range of different scientific disciplines and has been shown to be a viable option for large scale computational science. \n\nThe scale of resources available was demonstrated by the team from SUNY using more than 100,000 compute cores including simulations that used 1.8 million core hours over several days to create highly detailed models of the human motor cortex. The team from UW Madison showed how more than 50,000 Graphics Processing Unit (GPU) cores across multiple geographic regions and multiple cloud providers could be combined to provide an analysis platform for the IceCube neutrino observatory. The team from SDSC demonstrated how the dynamic scalability of the cloud platforms could be harnessed to provide additional compute power on demand by bursting phylogenetic workflows from the Comet supercomputer in San Diego to the latest generation of cloud-based graphics processors on the east coast, significantly reducing job queue times and speeding up processing. The teams from George Washington University and Purdue demonstrated how the easily accessible public nature of the cloud platforms could be leveraged to share their data sets and workflows with their communities to support reproducible computational workflow packages in bioinformatics and drug development, and to enable community contributions to a global database which is used to model the effects of urbanization on weather and climate. And finally, the team led by MIT demonstrated how high energy physics workflows could be individually optimized using a range of different hardware accelerators in the cloud to provide ?Machine Learning as a Service?, reducing compute loads and increasing performance of on-premises and national compute facilities. \n\nThe project identified several key benefits of cloud platforms including:\n\nthe flexibility to try many different combinations of hardware, software, and firmware to optimize Machine Learning and large-scale data processing.\nsupport for hybrid modalities using heterogeneous hardware, for example to provide Machine Learning as a Service. This is a form of non-traditional bursting that can be used to augment and improve on-prem compute models.\nCloud operator specific hardware and machine learning platforms, such as tensor processing units. Specific hardware and software platforms are being developed by commercial cloud providers to create competitive advantage and differentiation.\nCloud can be used to reserve significant resources for extended durations to support long duration jobs, or can be used to access large amounts of preemptible nodes at reduced costs for jobs that can be easily stopped and restarted.\n\n\nThe following observations were also made:\n\nThe flow of funds for research computing is important to institutions and the commercial transaction of ?real dollars? as opposed to credits and quotas increases focus on contracts, compliance and procurement issues which can in-turn cause project delays while the institution works towards operational maturity in cloud computing.\nDeveloping software to support workflows takes significant time and expertise.  While this is not specific to commercial cloud platforms, there needs to be increased focus on the role of research support professionals and the associated skills required to establish well-managed platforms for experimentation and analysis.\n\n\nThe E-CAS project clearly demonstrated the effectiveness of commercial cloud platforms in supporting a range of applications for the research computing communities and that commercial cloud has an important role in the computational science ecosystem.  The enormous scale and continuous evolution of commercial cloud platforms mean that they can be a tremendous resource for innovation and large-scale data processing; however, to take full advantage of commercial cloud requires a focus on the development of research support staff and institutional familiarity with the administration of cloud procurement and platforms.\n\n\t\t\t\t\tLast Modified: 03/30/2022\n\n\t\t\t\t\tSubmitted by: Howard Pfeffer"
 }
}