{
 "awd_id": "1900941",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Medium: Collaborative Research: Empirically Validated Perceptual Tasks for Data Visualization",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Balakrishnan Prabhakaran",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2022-12-31",
 "tot_intn_awd_amt": 402405.0,
 "awd_amount": 402405.0,
 "awd_min_amd_letter_date": "2019-09-04",
 "awd_max_amd_letter_date": "2019-09-04",
 "awd_abstract_narration": "Understanding quantitative data is a foundation of science, education, and the public communication of information about public policy and health. Our brains process and understand numbers far more efficiently when we can rely on data visualizations, allowing us to process patterns in data by leveraging the 40% of our brain that processes visual patterns in the real world. Decades of research in data visualization has produced evidence-backed guidelines for how to design the best data visualization for a given data analysis or communication task. But this process is limited by our incomplete understanding of the process by which we recognize patterns in visualized data. When people see a weather map color-coded by temperature, are they processing the hot and cold colors at the same perceptual moment, or just one? When they inspect a scatterplot, are people processing individual points, or the shape of the whole collection? This project will combine past research in the study of human vision, research in data visualization, and new research at the intersection of those two fields to create a model of how the visual system pulls patterns and statistics from visualized data. This model will lead to a more complete understanding of how to best harness the power of human vision to analyze a given dataset and to communicate a critical pattern clearly to an audience; this model will then be used to improve existing visualization tools.\r\n\r\nData visualization research has sought to find the best visualization for a given data analysis task. For example, scatterplots allow relatively precise judgment of correlations, while line graphs are a powerful way to inspect trends over time. But systematically testing the performance of many tasks across many visualizations has not revealed systematic patterns of performance that would allow us to predict why some matches lead to better performance, what design changes might alter that performance, or how novel visualizations might perform. One problem is that current work is limited to focusing on what viewers want to accomplish, without being able to capture how viewers actually perform these tasks. The goal of the proposed research is to refine and empirically evaluate a lower-level model of \"perceptual tasks\" that underlie higher level tasks (e.g. \"What is the average value in the dataset?\") based on established results in perceptual psychology. First, the team will conduct a qualitative study that documents how people break a high-level task down into perceptual tasks, followed by an empirical evaluation of those qualitative findings. Next, the team will measure the precision and operation of the proposed perceptual tasks -- Filter Image, Judge Shape, Compute Distributions and Compute Ratio -- along with other tasks identified in the first study; together, these will provide a set of empirically-backed design guidelines to improve visualization effectiveness. Finally, the team will validate the model by comparing its predictions to findings from previous literature, then integrate new guidelines as constraints into the Draco visualization recommender system, which should improve its ability to predict the performance of different visualization designs. The resulting guidelines, model, and integration into Draco promise in turn to improve visualization education and practice.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Enrico",
   "pi_last_name": "Bertini",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Enrico Bertini",
   "pi_email_addr": "e.bertini@northeastern.edu",
   "nsf_id": "000636771",
   "pi_start_date": "2019-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 59081.0
  }
 ],
 "por": null
}