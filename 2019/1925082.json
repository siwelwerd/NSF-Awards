{
 "awd_id": "1925082",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: FND: Improving Robot Learning from Feedback  and Demonstration using Natural Language",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928074",
 "po_email": "jdonlon@nsf.gov",
 "po_sign_block_name": "James Donlon",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 749411.0,
 "awd_amount": 749411.0,
 "awd_min_amd_letter_date": "2019-08-29",
 "awd_max_amd_letter_date": "2019-08-29",
 "awd_abstract_narration": "Deploying general purpose robots on a wide scale ranging from the home to the workplace requires a more sustainable model to quickly and robustly train them to perform novel tasks in unknown environments without the intervention of robotics experts. Toward this goal, various approaches have been explored to allow an ordinary human user to train a robot using various forms of instruction and interaction, specifically by providing evaluative feedback while a robot is learning to perform a task, or by explicitly demonstrating how to perform the task. When a person is providing feedback or demonstrating a task for another human, they typically describe what they are doing in natural language, providing context, clarification, and/or explanations for their evaluations or actions. Therefore, this project focuses on developing new computational methods that will enable robots to more efficiently and robustly learn from feedback and demonstration by leveraging accompanying natural language narration as context.\r\n\r\nThe project develops two new approaches to using language to aid interactive task learning by integrating ideas from language grounding, explanation for deep learning, and learning from rationales.  The first approach uses language narration as a form of \"supervised attention\" that focuses learning on relevant features of the environment, thereby allowing effective learning from limited training data. First, the system learns to ground natural language in the robot's perceptions, utilizing prior work on automated video captioning and multi-modal linguistic grounding. Next, human linguistic narration is translated to a saliency map over the perceptual field using recent methods for visually explaining the processing of the resulting language-grounding networks. Finally, this saliency map is used to supervise the attention mechanism of a deep-reinforcement learning system that learns from feedback and/or demonstration, allowing it to learn faster and more effectively from limited interaction. The second approach uses natural language narrations to perform reward shaping. In this approach, natural language instructions are mapped to intermediate rewards, which can be seamlessly integrated into any standard reinforcement learning algorithm, again improving the speed and accuracy of learning. Both of these approaches are experimentally evaluated by using them to learn new tasks and quantitatively comparing the speed and effectiveness of learning with and without linguistic narration.  The hypothesis is that the use of linguistic narration will improve the speed and effectiveness of learning. Tasks will include simulated ones employing video games typically used to evaluate reinforcement learning and real-world robot tasks involving navigation and object manipulation.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Raymond",
   "pi_last_name": "Mooney",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Raymond J Mooney",
   "pi_email_addr": "mooney@cs.utexas.edu",
   "nsf_id": "000308265",
   "pi_start_date": "2019-08-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Stone",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Peter H Stone",
   "pi_email_addr": "pstone@cs.utexas.edu",
   "nsf_id": "000156504",
   "pi_start_date": "2019-08-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Scott",
   "pi_last_name": "Niekum",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Scott D Niekum",
   "pi_email_addr": "sniekum@cs.umass.edu",
   "nsf_id": "000663218",
   "pi_start_date": "2019-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121757",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 749411.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-8c447dba-7fff-4577-cf25-21df8dce3c82\" style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This project has developed new methods for using techniques from natural language processing to enable robots to learn new tasks more efficiently and effectively. Training robots to perform new tasks typically involves detailed, complex engineering that requires the skills of a robotics expert.&nbsp; Our research has designed and evaluated new approaches that allow novice users to train&nbsp; robots to perform new tasks by providing instructions in natural human language, such as English.&nbsp; These methods will help expand the accessibility of robotic technology and enable it to more effectively perform a broad range of tasks that can aid a wider subset of human society.</span></p>\r\n<p>&nbsp;</p>\r\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Our early work on the project developed novel methods for allowing natural language instructions to aid reinforcement learning of new tasks. Reinforcement learning is typically used to train robots to learn new tasks by rewarding appropriate behavior that helps achieve specific human goals. However, it typically involves a great deal of trial and error and can require an unrealistic number of training experiences to be effective.&nbsp; Therefore, we developed new techniques that use easily-provided human-language instructions that provide intermediate rewards for matching desired behavior, thereby speeding up the training process significantly. &nbsp; Extensive experiments on a detailed robot simulator demonstrated significantly faster learning of a variety of tasks, specifically, ones requiring manipulating and moving particular objects in a desired manner.</span></p>\r\n<p>&nbsp;</p>\r\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Another typical approach to robot training is for a human to provide a detailed demonstration of a new task by remotely operating it to produce the desired behavior.&nbsp; However, such demonstrations can be ambiguous or incomplete, and many alternative demonstrations can be required to effectively train the robot to perform the task independently. &nbsp; Therefore, we developed new methods that can utilize an easily-provided natural language description of the task in addition to the physical demonstration. This linguistic instruction provides additional information that helps more precisely define the task and allow effective learning from only a single demonstration.&nbsp; Extensive experiments on a detailed robot simulator showed that it could effectively learn to perform a range of \"pick and place\" tasks that required identifying a specific object and moving it to a desired location.&nbsp; By comparison, a system that learned from demonstrations alone required 50 more demonstrations on average to learn such tasks equally well.</span></p>\r\n<p>&nbsp;</p>\r\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">A final approach to robot training that we improved using natural-language techniques was \"sim to real transfer.\"&nbsp; To more efficiently acquire the extensive experience needed to learn a new task, a robotic system is typically trained extensively in a simulated environment and then attempts to transfer this learning to a robot operating in the real world using much more limited experience. However, there is typically a \"sim2real gap,\" i.e. a critical difference between the simulation and the real world, that limits the effectiveness of this approach.&nbsp; We developed novel methods that&nbsp; exploit human-language descriptions of real and simulated images that illustrate the important similarities and differences between simulated and real-world robot perceptions. The system uses this linguistic data to learn representations of&nbsp; robotic environments that bridge simulation and the real world. It then uses these representations to more effectively transfer skills between these environments. Extensive experiments transferring manipulation skills between a simulator and real robot arm demonstrated the ability of our approach to help bridge the \"sim2real gap.\"</span></p><br>\n<p>\n Last Modified: 12/22/2024<br>\nModified by: Raymond&nbsp;J&nbsp;Mooney</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project has developed new methods for using techniques from natural language processing to enable robots to learn new tasks more efficiently and effectively. Training robots to perform new tasks typically involves detailed, complex engineering that requires the skills of a robotics expert. Our research has designed and evaluated new approaches that allow novice users to train robots to perform new tasks by providing instructions in natural human language, such as English. These methods will help expand the accessibility of robotic technology and enable it to more effectively perform a broad range of tasks that can aid a wider subset of human society.\r\n\n\n\r\n\n\nOur early work on the project developed novel methods for allowing natural language instructions to aid reinforcement learning of new tasks. Reinforcement learning is typically used to train robots to learn new tasks by rewarding appropriate behavior that helps achieve specific human goals. However, it typically involves a great deal of trial and error and can require an unrealistic number of training experiences to be effective. Therefore, we developed new techniques that use easily-provided human-language instructions that provide intermediate rewards for matching desired behavior, thereby speeding up the training process significantly.  Extensive experiments on a detailed robot simulator demonstrated significantly faster learning of a variety of tasks, specifically, ones requiring manipulating and moving particular objects in a desired manner.\r\n\n\n\r\n\n\nAnother typical approach to robot training is for a human to provide a detailed demonstration of a new task by remotely operating it to produce the desired behavior. However, such demonstrations can be ambiguous or incomplete, and many alternative demonstrations can be required to effectively train the robot to perform the task independently.  Therefore, we developed new methods that can utilize an easily-provided natural language description of the task in addition to the physical demonstration. This linguistic instruction provides additional information that helps more precisely define the task and allow effective learning from only a single demonstration. Extensive experiments on a detailed robot simulator showed that it could effectively learn to perform a range of \"pick and place\" tasks that required identifying a specific object and moving it to a desired location. By comparison, a system that learned from demonstrations alone required 50 more demonstrations on average to learn such tasks equally well.\r\n\n\n\r\n\n\nA final approach to robot training that we improved using natural-language techniques was \"sim to real transfer.\" To more efficiently acquire the extensive experience needed to learn a new task, a robotic system is typically trained extensively in a simulated environment and then attempts to transfer this learning to a robot operating in the real world using much more limited experience. However, there is typically a \"sim2real gap,\" i.e. a critical difference between the simulation and the real world, that limits the effectiveness of this approach. We developed novel methods that exploit human-language descriptions of real and simulated images that illustrate the important similarities and differences between simulated and real-world robot perceptions. The system uses this linguistic data to learn representations of robotic environments that bridge simulation and the real world. It then uses these representations to more effectively transfer skills between these environments. Extensive experiments transferring manipulation skills between a simulator and real robot arm demonstrated the ability of our approach to help bridge the \"sim2real gap.\"\t\t\t\t\tLast Modified: 12/22/2024\n\n\t\t\t\t\tSubmitted by: RaymondJMooney\n"
 }
}