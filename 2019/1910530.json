{
 "awd_id": "1910530",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: A Differential Geometry Paradigm for Constructing a Semantic Mid-Level Representation for Multinocular Pose Estimation and Reconstruction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 470000.0,
 "awd_amount": 486000.0,
 "awd_min_amd_letter_date": "2019-08-01",
 "awd_max_amd_letter_date": "2020-05-07",
 "awd_abstract_narration": "3D vision is the process of constructing a scene from images obtained from multiple cameras or a single camera that is moving throughout the scene. However, current 3D vision suffers some problems due to three core issues: the emphasis on points rather than on curves and surfaces; sub-optimal integration of information from multiple images, and the need for richer semantic geometrical structuring of the scene. This project aims to rectify all three shortcomings by developing new technologies which work with curves and surfaces, integrate information from multiple cameras simultaneously, and use semantic primitives to describes objects in the scene. These developments will complement and present an invaluable addition to the plethora of existing techniques for 3D pose estimation and reconstruction, especially in textureless scenes such as man-made environments. Applications of this research include robotics, entertainment industry, archaeology, architecture, urban modeling, and metrology.\r\n\r\nThis project develops an end-to-end technology for pose estimation and scene reconstruction using differential geometry of curves and surfaces. First, it develops the technology necessary to use point-tangents as opposed to just points in the pose estimation process, transformative in reducing the number of necessary correspondences using information that is already available. It will also identify the minimal problems in this area. Second, the approach would allow for the integration of information from many cameras using intuitively defined geometric equations that can easily extend beyond three cameras, important in applications like visual odometry. Third, it develops a technology for surface reconstruction from a 3D curve graph acting like scaffold, while also taking into account both unorganized point reconstructions in textured areas and a novel set of differential photometric constraints in textureless areas. Fourth, it integrates the image-based grouping process with a simultaneous 3D reconstruction process resulting in a mid-level representation as a topologically connected set of curve fragments and surface fragments, which better matches the requirement of semantic and functional tasks.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Benjamin",
   "pi_last_name": "Kimia",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Benjamin B Kimia",
   "pi_email_addr": "Benjamin_Kimia@Brown.Edu",
   "nsf_id": "000110484",
   "pi_start_date": "2019-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "Office of Sponsored Projects",
  "perf_city_name": "Providence",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029129093",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 470000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Multiview 3D vision is the process of finding the location of multiple cameras from the images they produce of a 3D scene, and of reconstructing the 3D scene. This research area is experiencing an unprecedented escalating impact, largely due to structure from motion pipelines devised in the past decade providing new tools to reconstruct 3D models for use in videogames, film making, archaeology, architecture, urban modeling, augmented reality, cinematography, robotic manipulation, metrology, just to name a few.&nbsp;&nbsp;These tools, however, do not take advantage of the rich differential geometry structure inherent in curves and surfaces, especially when a scene lacks the required the features that the standard techniques rely on. This grant has made strides in developing the technology to make use of differential geometry structure, including trifocal pose estimation from oriented points (points endowed with orientation such as curve tangents), absolute pose estimation from two oriented points, trifocal use of image gradient in shape from shading, among others. A key technological barrier in the use of differential geometry in multiview geometry is the introduction of a significantly larger number of unknowns and consequently a larger system of polynomial equations whose solution defies classical techniques. The grant has developed parallel methods suitable for use on a GPU by employing homotopy continuation to solve large systems of polynomial equations in a practically useful timeframe. A key application of our methods is navigation, especially the more difficult pedestrian navigation where current visual odometry techniques and image localization techniques are not always successful. The grant developed the&nbsp;Brown Pedestrian Odometry Dataset (BPOD) to provide a ground-truth testbed for developing pedestrian visual odometry algorithms. Finally, a key bottleneck to relative pose estimation, a critical component required in 3D scene reconstruction, is the failure of classical methods when images lack a sufficient number of features. Observing that number of required features in practice is significantly higher than the theoretically expected breakdown point, research under this grant identified the culprit as the instability of techniques used. Specifically, the research identified a perhaps more significant role of RANSAC beyond weeding out the outliers, namely, that of stabilizing the estimation process, without denying its importance in filtering outliers. Furthermore, this research indicated that other multiview geometry techniques should consider a notion of stability in their operation.&nbsp;</p>\n<p>&nbsp;</p>\n<p>This grant has led to the training of four graduate students and three undergraduate students, has produced a PhD thesis, nine peer-reviewed publications, a pedestrian navigation dataset (BPOD), and software for solving complex polynomial systems.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/27/2023<br>\nModified by: Benjamin&nbsp;B&nbsp;Kimia</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nMultiview 3D vision is the process of finding the location of multiple cameras from the images they produce of a 3D scene, and of reconstructing the 3D scene. This research area is experiencing an unprecedented escalating impact, largely due to structure from motion pipelines devised in the past decade providing new tools to reconstruct 3D models for use in videogames, film making, archaeology, architecture, urban modeling, augmented reality, cinematography, robotic manipulation, metrology, just to name a few.These tools, however, do not take advantage of the rich differential geometry structure inherent in curves and surfaces, especially when a scene lacks the required the features that the standard techniques rely on. This grant has made strides in developing the technology to make use of differential geometry structure, including trifocal pose estimation from oriented points (points endowed with orientation such as curve tangents), absolute pose estimation from two oriented points, trifocal use of image gradient in shape from shading, among others. A key technological barrier in the use of differential geometry in multiview geometry is the introduction of a significantly larger number of unknowns and consequently a larger system of polynomial equations whose solution defies classical techniques. The grant has developed parallel methods suitable for use on a GPU by employing homotopy continuation to solve large systems of polynomial equations in a practically useful timeframe. A key application of our methods is navigation, especially the more difficult pedestrian navigation where current visual odometry techniques and image localization techniques are not always successful. The grant developed theBrown Pedestrian Odometry Dataset (BPOD) to provide a ground-truth testbed for developing pedestrian visual odometry algorithms. Finally, a key bottleneck to relative pose estimation, a critical component required in 3D scene reconstruction, is the failure of classical methods when images lack a sufficient number of features. Observing that number of required features in practice is significantly higher than the theoretically expected breakdown point, research under this grant identified the culprit as the instability of techniques used. Specifically, the research identified a perhaps more significant role of RANSAC beyond weeding out the outliers, namely, that of stabilizing the estimation process, without denying its importance in filtering outliers. Furthermore, this research indicated that other multiview geometry techniques should consider a notion of stability in their operation.\n\n\n\n\n\nThis grant has led to the training of four graduate students and three undergraduate students, has produced a PhD thesis, nine peer-reviewed publications, a pedestrian navigation dataset (BPOD), and software for solving complex polynomial systems.\n\n\n\t\t\t\t\tLast Modified: 12/27/2023\n\n\t\t\t\t\tSubmitted by: BenjaminBKimia\n"
 }
}