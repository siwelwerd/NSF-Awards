{
 "awd_id": "1843757",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Affordable Multi-Wavelength Lidar and Thermal Imager for Autonomous Vehicles",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Muralidharan Nair",
 "awd_eff_date": "2019-02-01",
 "awd_exp_date": "2020-01-31",
 "tot_intn_awd_amt": 222500.0,
 "awd_amount": 222500.0,
 "awd_min_amd_letter_date": "2019-02-06",
 "awd_max_amd_letter_date": "2019-02-06",
 "awd_abstract_narration": "The broader impact/commercial potential of this project is to provide a low cost Lidar+Thermal camera to the autonomous car market that will eventually enable level 4 and level 5 autonomy. The proposed innovation incorporates both a Lidar and a thermal detector to locate objects but also classify them, as this is the most crucial aspect of autonomous vehicles. The dual polarity Lidar+Thermal photodetector solves a few major issues in the current Lidar industry. First, current Lidars have to use advanced algorithms to classify the objects, whereas a Lidar+Thermal detector can easily distinguish between animate and inanimate objects, while continuing to establish their location. This is done due to the drastic heat signature of animate objects. Second, the dual polarity detector is able to detect and locate hazards on the road such as snow or puddles, which is vital if autonomous vehicles are used in northern regions. In addition, the frame rate of the Flash Lidar+Thermal is up to 200 Frames per second, which will drastically reduce smearing effects and allow for driving at speeds of 70+ MPH. Lastly, the high thermal resolution of the camera will ensure operation in bad weather conditions including fog and rain.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project will provide a proof-of-concept of the dual polarity Lidar+Thermal detector. An array of 32x32 pixels will demonstrate that in one polarity, a thermal hot-mid-wave image and in the other polarity the pixels will operate in a time-of-flight mode for Flash Lidar operation. The pixel?s spectral response will range from 500nm up to 3.5?m in the Lidar mode. Characterization of the detector array will use the eye-safe 1550nm laser. The goal is to show a 200m Lidar operation with a high resolution of a few centimeters and thermal imaging with a thermal sensitivity of 4mK. The transition to Phase II will include an array size of 1000x500 with 10?m pixel pitch. The detector will be evaluated outdoors to demonstrate the detection of animate objects, snow and puddles and will be tested under fog conditions.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shimon",
   "pi_last_name": "Maimon",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shimon Maimon",
   "pi_email_addr": "shimonmaimon@yahoo.com",
   "nsf_id": "000783178",
   "pi_start_date": "2019-02-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "NBN TECHNOLOGIES, LLC",
  "inst_street_address": "136 WILSHIRE RD",
  "inst_street_address_2": "",
  "inst_city_name": "Rochester",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5853555556",
  "inst_zip_code": "146181221",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "NBN TECHNOLOGIES, LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "TU6FJ4T78V84"
 },
 "perf_inst": {
  "perf_inst_name": "NBN TECHNOLOGIES, LLC",
  "perf_str_addr": null,
  "perf_city_name": "Rochester",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146180001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1185",
   "pgm_ref_txt": "SENSORY SYSTEMS"
  },
  {
   "pgm_ref_code": "5371",
   "pgm_ref_txt": "SMALL BUSINESS PHASE I"
  },
  {
   "pgm_ref_code": "8034",
   "pgm_ref_txt": "Hardware Components"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 222500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"yiv4923727586MsoNormal\">The NSF awarded NetzVision LLC with a Phase I SBIR award titled ?<span>Affordable Multi-Wavelength Lidar and Thermal Imager for Autonomous Vehicles</span>.? The broader impact of this technology is to provide sensors optimized for night and bad-weather conditions for the Autonomous Vehicles (AV) market. NetzVision has designed and developed state-of-the-art sensor technology for Infrared (IR) imagers and range-finding systems specifically for the AV market.</p>\n<p class=\"yiv4923727586MsoNormal\">Detecting material has been fabricated with specs well beyond difficult LIDAR and imaging requirements. Layout of silicon unit cells corresponding to the detector for various LIDAR detection methods such as Time-of-Flight (TOF),&nbsp;<span>and Amplitude Modulated Continuous Wave (AMCW</span>) have been designed, developed and implemented into small arrays.</p>\n<p class=\"yiv4923727586MsoNormal\">The initial testing for infrared imaging plus LIDAR will lead to a final dual operation detector to&nbsp;<span>reduce the number of sensors</span>&nbsp;required for autonomous vehicles, drastically increase the quality of object detection, provide clear vision at night, bad weather conditions, fog and haze, and locate hazards on the road such as snow, ice, and puddles. The In-Situ Fusion between the Lidar map and the Imaging eliminate the needs for AI Fusion, result in no AI mistakes, and achieved with no cost.</p>\n<p class=\"yiv4923727586MsoNormal\">The systems that use these sensors were researched in order to ensure that the proposed solution was viable. Various LIDAR&nbsp;plus Imaging approaches were studied to determine where the solution would offer the greatest performance benefit.</p>\n<p class=\"yiv4923727586MsoNormal\"><span>&nbsp;</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/27/2020<br>\n\t\t\t\t\tModified by: Shimon&nbsp;Maimon</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "The NSF awarded NetzVision LLC with a Phase I SBIR award titled ?Affordable Multi-Wavelength Lidar and Thermal Imager for Autonomous Vehicles.? The broader impact of this technology is to provide sensors optimized for night and bad-weather conditions for the Autonomous Vehicles (AV) market. NetzVision has designed and developed state-of-the-art sensor technology for Infrared (IR) imagers and range-finding systems specifically for the AV market.\nDetecting material has been fabricated with specs well beyond difficult LIDAR and imaging requirements. Layout of silicon unit cells corresponding to the detector for various LIDAR detection methods such as Time-of-Flight (TOF), and Amplitude Modulated Continuous Wave (AMCW) have been designed, developed and implemented into small arrays.\nThe initial testing for infrared imaging plus LIDAR will lead to a final dual operation detector to reduce the number of sensors required for autonomous vehicles, drastically increase the quality of object detection, provide clear vision at night, bad weather conditions, fog and haze, and locate hazards on the road such as snow, ice, and puddles. The In-Situ Fusion between the Lidar map and the Imaging eliminate the needs for AI Fusion, result in no AI mistakes, and achieved with no cost.\nThe systems that use these sensors were researched in order to ensure that the proposed solution was viable. Various LIDAR plus Imaging approaches were studied to determine where the solution would offer the greatest performance benefit.\n \n\n \n\n\t\t\t\t\tLast Modified: 04/27/2020\n\n\t\t\t\t\tSubmitted by: Shimon Maimon"
 }
}