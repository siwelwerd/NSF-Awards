{
 "awd_id": "1850153",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII:RI:A Multi-level Framework for Text Specificity",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2019-06-01",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 174496.0,
 "awd_amount": 190496.0,
 "awd_min_amd_letter_date": "2019-03-13",
 "awd_max_amd_letter_date": "2020-05-08",
 "awd_abstract_narration": "Language specificity, which captures the level of detail in text, varies throughout discourse as a reflection of speaker intent: general content makes high-level observations or claims, while specific content provides concrete details. Appropriately gauged specificity is a characteristic of well-organized text and plays a crucial role in comprehension. Intelligent systems that make predictions of sentence specificity have been useful for natural language processing tasks such as summarization and argumentation mining, as well as for linguistic analyses in fields such as forensic science, political science, and education. However, existing systems are domain-specific tools that operate only on the sentence level. This project addresses a series of challenges to enable domain-agnostic, multi-level analysis of specificity, bringing together concepts across computational methods, linguistic analysis and corpora development. It opens up venues of applying specificity as a pragmatic tool in a wide range of disciplines, including those where the use of computational methods is rapidly emerging. \r\n\r\nTo substantially advance our understanding and practical use of text specificity to capture information organization in discourse, this CISE Research Initiation Initiative (CRII) project aims to (1) develop effective specificity prediction systems that work across multiple domains, (2) develop annotation guidelines and datasets to capture specificity in a nuanced way, (3) develop techniques to predict specificity from multiple levels of linguistic analysis (words, phrases and sentences). Throughout these tasks, the project draws connections between specificity variations in text, their pragmatic functions, and their impact on discourse structure. This project also develops new methods that integrate text specificity in natural language generation tasks, for example, dialog generation systems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Junyi",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Junyi Li",
   "pi_email_addr": "jessy@austin.utexas.edu",
   "nsf_id": "000757062",
   "pi_start_date": "2019-03-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "The University of Texas at Austin",
  "perf_str_addr": "3925 W Braker Lane, Ste 3.340",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787595316",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "TX37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 174496.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>When we communicate through language, we package information into bits and pieces that vary in their specificity---or level of detail. Specificity plays a vital role in rhetorical and discourse structure: specific examples often follow general claims to help support them; we tend to be more specific if we want to be informative, but we also rarely fully specify every single part of a sentence, leaving room for different parts of a document to come together. Specificity is shown to be an important characteristic to analyze in many applications, but existing tools were ill-equipped: they worked only on one domain (news text from a single source), and only on the sentence level.</p>\n<p>This project led to new and versatile tools to model text specificity at multiple levels of analysis. We developed a domain agnostic model for sentence specificity prediction that produces accurate real-valued estimates without the need of training data in any target domain, thus useful in a wide range of applications. Our efforts resulted in new unsupervised domain adaptation techniques that were applied more broadly, beyond specificity prediction.</p>\n<p>At the sub-sentential level, we developed a new framework based on question generation and answering that modeled <em>what the reader thought needed elaborating</em> as they read. For example, a sentence like \"<em>This gritty city of 7.6 million rarely gets respect</em>\" triggers a question in a curious reader, \"<em>Why does it rarely get respect?</em>\". We developed resources and models to generate these questions and answer them.</p>\n<p>We applied predictions of specificity, as well as insights of its analysis, in two key applications. By estimating the specificity of dialog utterances, we augmented open-domain dialog generation models such that they generate more informative response generation. We also investigated automatic text simplification, modeling \"elaborative simplification\", i.e., inserting elaborations and explanations during the simplification process. These investigations led to a series of research to understand and improve natural language generation models.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/22/2022<br>\n\t\t\t\t\tModified by: Junyi&nbsp;Li</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhen we communicate through language, we package information into bits and pieces that vary in their specificity---or level of detail. Specificity plays a vital role in rhetorical and discourse structure: specific examples often follow general claims to help support them; we tend to be more specific if we want to be informative, but we also rarely fully specify every single part of a sentence, leaving room for different parts of a document to come together. Specificity is shown to be an important characteristic to analyze in many applications, but existing tools were ill-equipped: they worked only on one domain (news text from a single source), and only on the sentence level.\n\nThis project led to new and versatile tools to model text specificity at multiple levels of analysis. We developed a domain agnostic model for sentence specificity prediction that produces accurate real-valued estimates without the need of training data in any target domain, thus useful in a wide range of applications. Our efforts resulted in new unsupervised domain adaptation techniques that were applied more broadly, beyond specificity prediction.\n\nAt the sub-sentential level, we developed a new framework based on question generation and answering that modeled what the reader thought needed elaborating as they read. For example, a sentence like \"This gritty city of 7.6 million rarely gets respect\" triggers a question in a curious reader, \"Why does it rarely get respect?\". We developed resources and models to generate these questions and answer them.\n\nWe applied predictions of specificity, as well as insights of its analysis, in two key applications. By estimating the specificity of dialog utterances, we augmented open-domain dialog generation models such that they generate more informative response generation. We also investigated automatic text simplification, modeling \"elaborative simplification\", i.e., inserting elaborations and explanations during the simplification process. These investigations led to a series of research to understand and improve natural language generation models.\n\n\t\t\t\t\tLast Modified: 08/22/2022\n\n\t\t\t\t\tSubmitted by: Junyi Li"
 }
}