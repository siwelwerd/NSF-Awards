{
 "awd_id": "1850202",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: III: Optimal Data Organization for Hybrid Transactional/Analytical Processing Data Systems",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-06-01",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 174999.0,
 "awd_amount": 174999.0,
 "awd_min_amd_letter_date": "2019-05-20",
 "awd_max_amd_letter_date": "2019-05-20",
 "awd_abstract_narration": "Scientific, commercial, and governmental applications increasingly rely on data-driven insights and decision-making using both historical data and real-time updates. New workloads are generated by social feeds, sensor readings (a common use-case of Internet-of-Things applications) and electronic micro-payments (an emerging model of e-commerce). They all have in common: (i) a very high volume of transactions and (ii) a high volume of analysis queries that need to use both historic and real-time data to provide useful and actionable insights. The primary challenge is that these workloads have conflicting requirements, and typically use different data systems architectures. On the one hand, we want to be able to answer analysis queries like, \"what was the most discussed topic in each month of the past year?\", or \"what is the average power consumption per neighborhood of city X?\". On the other hand, we want to efficiently store incoming updates and be able to provide real-time insights like \"where do we have a power network overload now?\", or \"what is the probability that a disaster is taking place based on the social feeds of a city X?\". Traditionally, data systems were engineered to efficiently support either a transactional workload -- that is, storing quickly new items -- or an analytical workload. The latter typically includes changing the data layout and organization, and building auxiliary indexing structures to allow for efficient data access. The emergence of complex workloads has pushed towards the need to develop new systems that can support hybrid transactional/analytical processing (HTAP). This research will allow to execute such workloads efficiently and to anticipate workload changes in a robust way. Ultimately, the project will make data ingestion and data analysis a smoother process and will enable complex applications to have their data analyzed quickly.\r\n \r\nThe researchers will build data systems that can efficiently evaluate mixed workloads by navigating the read-optimized vs. update-optimized continuum of data systems architectures. The key to do so is to vary the physical data organization and find the optimal for each use-case. Typically, data objects are physically organized in various ways between two extremes: either they follow the ingestion order, that is, the way they are generated or inserted in the system, or they are organized based on their value (or a specific subset of their attributes). This \"structure\" (also called \"bounded disorder\" in the literature) is treated as a continuum between the two extremes. In-between, hybrid data organizations have different parts of the dataset organized with different schemes. Transactional updates add data with disorder, while answering analytical queries efficiently requires data with bounded disorder. A fundamental challenge today is to find the data organization that enables a data system to offer a tunable balance between efficient updates and fast analysis queries. This project addresses this challenge from three different angles. First, by formulating an optimization problem, which can be solved at run-time. Second, by formulating a robust optimization problem which will deliver good performance even when preliminary assumptions are not accurate. Third, by building access methods that can exploit any inherently limited disorder in the underlying data to reduce the data organization effort needed for efficient analysis tasks. This research effort introduces HTAP data systems that can optimally organize data and exploit inherently bounded disorder while being robust in workload changes.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Manos",
   "pi_last_name": "Athanassoulis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Manos Athanassoulis",
   "pi_email_addr": "mathan@bu.edu",
   "nsf_id": "000782147",
   "pi_start_date": "2019-05-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Trustees of Boston University",
  "inst_street_address": "1 SILBER WAY",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173534365",
  "inst_zip_code": "022151703",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "TRUSTEES OF BOSTON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "THL6A6JLE1S7"
 },
 "perf_inst": {
  "perf_inst_name": "Boston University",
  "perf_str_addr": "111 Cummington Mall",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "022151300",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 174999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>One of the key expectations when using a database management system (DBMS) is that it will offer efficient data storage with quick data access and updates.&nbsp;</p>\n<p>In order to be able to access data quickly, systems internally organize data so that they can search within these data collections quickly. On the other hand, every time data is updated, this internal organization is disturbed and needs to be repaired. To balance the effort required to add structure to the data to offer efficient data access when data is updated or modified and the speed of accessing data, this project, has the following four critical outcomes:</p>\n<p>1) We introduced a data partitioning approach capable of balancing the read and update performance when we have an accurate estimation of how many read queries and how many updates we have. Furthermore, we prove that this partitioning is ideal (optimal) if we have exact workload knowledge (that is, knowledge of the data operations type and proportion).</p>\n<p>2) As data management is increasingly becoming a cloud endeavor, the workload knowledge comes with uncertainty due to the volatile nature of the applications and the virtualization of resources on the cloud. To address this challenge, we developed a robust tuning technique that allows a system to be tuned without accurate workload knowledge, rather, with information about the expected workload and the uncertainty that comes with this expectation.</p>\n<p>3) Another facet of cloud-based data management is that data deletion comes with regulatory requirements of actual data purging from storage engines. This requirement stresses the ability to offer fast data ingestion and querying. To address this challenge, we built the first deletion-aware data system that is capable of provably respecting a threshold of completely purging deleted data (termed \"persistent data deletion\").</p>\n<p>4) Finally, in the quest to balance the effort needed to offer efficient read performance, we exploit any potential pre-existing data organization. Consider that any data organization technique like partitioning or building an index aims to add structure to an otherwise unstructured data collection. To use any pre-existing data organization, we designed the first database index that exploits data pre-sortedness to make data ingestion faster without having to pay the indexing cost (i.e., the cost to add structure to the data) that a traditional index would pay.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/25/2022<br>\n\t\t\t\t\tModified by: Manos&nbsp;Athanassoulis</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOne of the key expectations when using a database management system (DBMS) is that it will offer efficient data storage with quick data access and updates. \n\nIn order to be able to access data quickly, systems internally organize data so that they can search within these data collections quickly. On the other hand, every time data is updated, this internal organization is disturbed and needs to be repaired. To balance the effort required to add structure to the data to offer efficient data access when data is updated or modified and the speed of accessing data, this project, has the following four critical outcomes:\n\n1) We introduced a data partitioning approach capable of balancing the read and update performance when we have an accurate estimation of how many read queries and how many updates we have. Furthermore, we prove that this partitioning is ideal (optimal) if we have exact workload knowledge (that is, knowledge of the data operations type and proportion).\n\n2) As data management is increasingly becoming a cloud endeavor, the workload knowledge comes with uncertainty due to the volatile nature of the applications and the virtualization of resources on the cloud. To address this challenge, we developed a robust tuning technique that allows a system to be tuned without accurate workload knowledge, rather, with information about the expected workload and the uncertainty that comes with this expectation.\n\n3) Another facet of cloud-based data management is that data deletion comes with regulatory requirements of actual data purging from storage engines. This requirement stresses the ability to offer fast data ingestion and querying. To address this challenge, we built the first deletion-aware data system that is capable of provably respecting a threshold of completely purging deleted data (termed \"persistent data deletion\").\n\n4) Finally, in the quest to balance the effort needed to offer efficient read performance, we exploit any potential pre-existing data organization. Consider that any data organization technique like partitioning or building an index aims to add structure to an otherwise unstructured data collection. To use any pre-existing data organization, we designed the first database index that exploits data pre-sortedness to make data ingestion faster without having to pay the indexing cost (i.e., the cost to add structure to the data) that a traditional index would pay.\n\n\t\t\t\t\tLast Modified: 07/25/2022\n\n\t\t\t\t\tSubmitted by: Manos Athanassoulis"
 }
}