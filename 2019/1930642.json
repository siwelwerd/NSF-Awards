{
 "awd_id": "1930642",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Enhancing Critical Reflection on Data by Integrating Users' Expectations in Visualization Interaction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2018-09-16",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 485383.0,
 "awd_amount": 497383.0,
 "awd_min_amd_letter_date": "2019-06-07",
 "awd_max_amd_letter_date": "2022-06-03",
 "awd_abstract_narration": "Interactive graphs, charts, and other visual representations of data are increasingly common in public life.  People bring their own expectations and assumptions about the data and situations these visualizations represent, though most visualizations do not take these expectations into account. Comparing these expectations to actual data is a powerful tool for checking those assumptions, developing better understanding of situations, and making better decisions.  To support such expectation visualizations, the project team will use a combination of experiments, software development, and design activities to develop toolkits and best practices for developing visualizations that allow viewers to represent, interact with, and see feedback on their own predictions about the data.  The work will focus on helping people better understand scientific research and expert analysis around topics such as health decisions that might impact their own lives.  The work will also support a broader educational goal of data literacy education, through course modules that can be inserted into introductory informatics and data science courses and a new course on thinking with data, and outreach goals through developing a research and development platform where designers, researchers, and developers can work together to improve expectation visualization techniques.  \r\n\r\nTo do this, the project has three main research goals.  The first is to develop a suite of empirical findings on the effects of expectation visualization, through a series of experiments on how predicting data, receiving personalized feedback on those predictions, and reflecting on gaps between predictions and data affect people's later memory of the data and future expectations. The second thrust builds on the first, using these empirical results along with design studies and comprehensive reviews of existing tools and literature to build a design space with software examples characterizing key decisions in designing expectation visualizations. These decisions will include a range of techniques for graphically eliciting people's expectations, contextualization techniques that help people learn to use those techniques and constrain their choices appropriately, and feedback or reflection techniques that help call attention to places where expectations did and did not match the underlying data.  The third thrust is to put these principles into practice by developing applications to support the communication of uncertainty in experimental results, the reduction of spurious pattern discoveries in data analysis, and the integration of problem context and expert analysis with the visualization itself.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jessica",
   "pi_last_name": "Hullman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jessica Hullman",
   "pi_email_addr": "jhullman@northwestern.edu",
   "nsf_id": "000688613",
   "pi_start_date": "2019-06-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602013149",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 65905.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 120445.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 101823.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 105443.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 103767.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-33a6644d-7fff-b055-aae7-f3d741018ce7\">\n<h2 dir=\"ltr\"><span>While visualizations can enable us to see and understand data, to learn something new about the world from a data visualization requires integrating the new information with what we already know. Towards this goal, the investigator developed methods to help users of visualizations in the media and scientific publications to combine the knowledge they gave about a topic with the new information presented in a visualization. The view behind this goal is that Bayesian inference&ndash;a mathematical definition of how we can best update what we think about the probability of events given new information&ndash;is an ideal way to learn from new information.</span></h2>\n<br />\n<p dir=\"ltr\"><span>The investigator used this formulation to develop new interactive visualization designs and evaluation tools for data visualizations. One important step taken toward these goals was to develop and evaluate different interactive interfaces that allow people to express their beliefs about data prior to viewing a new visualized dataset. For example, before seeing visualized survey results on diseases affecting the elderly in the U.S., the tools developed in this project might ask the user to express their beliefs about the prevalence of different conditions in this population. The interface might elicit these beliefs graphically, by asking the user to sketch a distribution. Or they might be asked to provide an interval capturing the range in which they think a quantities &ndash; like the proportion of the elderly U.S. population living in assisted living centers who have dementia &ndash; falls. The investigator evaluated such approaches for collecting beliefs by examining the consistency of responses people provided and the degree to which their elicited beliefs accurately predicted the true value of the quantity.&nbsp;&nbsp;</span></p>\n<br />\n<p dir=\"ltr\"><span>Once a visualization user&rsquo;s beliefs have been elicited, their interaction with a visualization can be designed to reference these beliefs. A common bias when people are confronted with new information that can be used to update their beliefs is that they give too much weight to their prior beliefs. To help people grasp how much new information a visualization conveys, this project developed and evaluated several forms of analogies that can be generated. One type of analogy conveys how much (or less) information is contained in the visualized data relative to the user&rsquo;s prior beliefs on the topic. Another guides the user by expressing what their final (posterior) beliefs should be given what they believed before and the new information provided by the visualization. An empirical study finds that the analogies help people better account for the new information compared to just visualizing uncertainty affecting the data, but that how much they help depends on how likely people are to trust the source of the data a priori.&nbsp;</span></p>\n<br />\n<p dir=\"ltr\"><span>Another formulation relates to how people often use graphs to inform conclusions about the cause-effect relationship between multiple variables. Often it is thought that viewing and interacting graphs is useful in drawing conclusions about whether one factor causes another. This work conducted empirical study to determine to what extent different types of static and interactive graphs allow users to make accurate judgments about which of several &ldquo;possible worlds&rdquo; is most likely to hold given a set of prior beliefs and a visualized dataset. We find that many people struggle to make accurate judgments, and that factors like interactivity do not necessarily help.&nbsp;&nbsp;</span></p>\n<p dir=\"ltr\"><span>&nbsp;</span></p>\n<p dir=\"ltr\"><span>This work also explored applications of these ideas to particular domains, like when analysts wish to explore a dataset but the data is protected by a privacy preservation approach called different privacy. The project developed a new approach to helping an analyst incrementally query data, and conducted an empirical study evaluating their ability to arrive at accurate posterior beliefs using this approach.</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/16/2024<br>\nModified by: Jessica&nbsp;Hullman</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\nWhile visualizations can enable us to see and understand data, to learn something new about the world from a data visualization requires integrating the new information with what we already know. Towards this goal, the investigator developed methods to help users of visualizations in the media and scientific publications to combine the knowledge they gave about a topic with the new information presented in a visualization. The view behind this goal is that Bayesian inferencea mathematical definition of how we can best update what we think about the probability of events given new informationis an ideal way to learn from new information.\n\n\n\n\nThe investigator used this formulation to develop new interactive visualization designs and evaluation tools for data visualizations. One important step taken toward these goals was to develop and evaluate different interactive interfaces that allow people to express their beliefs about data prior to viewing a new visualized dataset. For example, before seeing visualized survey results on diseases affecting the elderly in the U.S., the tools developed in this project might ask the user to express their beliefs about the prevalence of different conditions in this population. The interface might elicit these beliefs graphically, by asking the user to sketch a distribution. Or they might be asked to provide an interval capturing the range in which they think a quantities  like the proportion of the elderly U.S. population living in assisted living centers who have dementia  falls. The investigator evaluated such approaches for collecting beliefs by examining the consistency of responses people provided and the degree to which their elicited beliefs accurately predicted the true value of the quantity.\n\n\n\n\nOnce a visualization users beliefs have been elicited, their interaction with a visualization can be designed to reference these beliefs. A common bias when people are confronted with new information that can be used to update their beliefs is that they give too much weight to their prior beliefs. To help people grasp how much new information a visualization conveys, this project developed and evaluated several forms of analogies that can be generated. One type of analogy conveys how much (or less) information is contained in the visualized data relative to the users prior beliefs on the topic. Another guides the user by expressing what their final (posterior) beliefs should be given what they believed before and the new information provided by the visualization. An empirical study finds that the analogies help people better account for the new information compared to just visualizing uncertainty affecting the data, but that how much they help depends on how likely people are to trust the source of the data a priori.\n\n\n\n\nAnother formulation relates to how people often use graphs to inform conclusions about the cause-effect relationship between multiple variables. Often it is thought that viewing and interacting graphs is useful in drawing conclusions about whether one factor causes another. This work conducted empirical study to determine to what extent different types of static and interactive graphs allow users to make accurate judgments about which of several possible worlds is most likely to hold given a set of prior beliefs and a visualized dataset. We find that many people struggle to make accurate judgments, and that factors like interactivity do not necessarily help.\n\n\n\n\n\nThis work also explored applications of these ideas to particular domains, like when analysts wish to explore a dataset but the data is protected by a privacy preservation approach called different privacy. The project developed a new approach to helping an analyst incrementally query data, and conducted an empirical study evaluating their ability to arrive at accurate posterior beliefs using this approach.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 10/16/2024\n\n\t\t\t\t\tSubmitted by: JessicaHullman\n"
 }
}