{
 "awd_id": "1907541",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Human-Machine Collaboration for Design Space Exploration",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032927933",
 "po_email": "kjabloko@nsf.gov",
 "po_sign_block_name": "Kathryn Jablokow",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 246650.0,
 "awd_amount": 246650.0,
 "awd_min_amd_letter_date": "2019-08-15",
 "awd_max_amd_letter_date": "2019-08-15",
 "awd_abstract_narration": "This project researches the collaboration between artificial intelligence (AI) agents and humans for Design Space Exploration (DSE). At the core of the research is a new perspective on designing complex systems, one in which machines complement humans instead of replacing them. The project addresses two research questions for human-machine collaborative design in the context of Design Space Exploration. First, how can engineers benefit from working with a team of separate expert AI agents, each taking a different role in the human-machine dialog? Second, how can an AI agent infer the engineer's underlying design intentions beyond explicit actions? These questions are addressed while taking into account user experience considerations and an engineer's cognitive style. The first question is approached by developing design assistants with various roles (e.g., Critic, Analyst, Historian) and different levels of initiative (proactive, reactive) and measuring their effect on design quality, diversity, learning, agent perception, and trust in the system through human-participant studies. The second question is approached by using probabilistic graphical models, including Dynamic Bayes Nets and Conditional Random Fields, taking into account explicit and implicit human behaviors, and then using Markov Decision Processes to estimate the best action. Research on user experience and the effects of cognitive style will identify the mechanisms through which these agents and benefit designers with different preferred modes of processing information.\r\n\r\nThe first intellectual merit of this project is the exploration and evaluation of AI tools that significantly go beyond the state of the art in Engineering Design Space Exploration (DSE). This project will advance knowledge towards human-multi-agent DSE, towards models of probabilistic intention inference in the DSE space, and towards embodied frameworks for human-machine collaborative design. The second intellectual merit is the provision of new data sets of collaborative DSE to shed light on how designers use their explicit actions and nonverbal communication with AI assistants. The third intellectual merit is investigating how people with different cognitive styles can benefit from AI assistants in design tasks. The research questions in this project apply to a large number of design problems, and can thus have impact on many industries which engage in design, including architecture, medicine, urban planning, industrial design, and business management. Enhancing the capabilities of humans through new modes of collaboration with artificial intelligence can significantly impact how design is performed across the above areas. Additionally, the research project here provides opportunities for education and outreach during its execution. Students will be directly involved in this research agenda, and the research will be integrated with AI, robotics, user experience, and design courses.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Selva Valero",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel Selva Valero",
   "pi_email_addr": "dselva@tamu.edu",
   "nsf_id": "000676003",
   "pi_start_date": "2019-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M Engineering Experiment Station",
  "perf_str_addr": "HR Bright Building",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433141",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "072Y00",
   "pgm_ele_name": "EDSE-Engineering Design and Sy"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "067E",
   "pgm_ref_txt": "DESIGN TOOLS"
  },
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 246650.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The overarching goal of this project was to study new modes of interaction in human-machine collaborative design space exploration. The main outcomes of this project are as follows:&nbsp;</p>\n<p><span id=\"docs-internal-guid-03ce72ed-7fff-8976-496a-35516bfae891\">1. We developed a theoretical framework to study human-machine collaborative design space exploration. In this framework, both the designer and the AI agent/cognitive assistant are modeled as agents that collaboratively work on a design task by interacting with a design tool and between them.&nbsp;</span>Both agents can sense the state of the environment and the other agent, and they make decisions about what designs to try next based on those perceptions, their goals, their state, and what they know about the problem. Both agents have a hierarchy of goals about the design task, state (e.g., cognitive workload for the designer) knowledge (of the task, domain, and design process), and attributes (e.g., level of expertise for the designer, capabilities of the agent).</p>\n<p dir=\"ltr\"><span>2. We developed 2 AI agents for human-machine collaborative design space exploration: We developed new roles (e.g., Engineer, Analyst, Historian, Expert, Critic) and modes of initiative (reactive vs proactive) for the Daphne-EO cognitive assistant, where the task at hand is to design a constellation of Earth observation satellites. In addition, we developed a second agent from scratch for design space exploration of mechanical meta-materials.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p>\n<p dir=\"ltr\"><span>3. We conducted 6 human-subject studies to help us understand several aspects of how the AI agent, designer, and task affect human-machine collaborative design space exploration outcomes---primarily design performance (quantity, quality, and diversity of designs) and designer learning. The six studies are as follows: </span></p>\n<p dir=\"ltr\"><span>1) Effect of agent role/level of initiative (peer vs assistant) on performance and learning:&nbsp;No significant difference was found in performance of learning between Peer vs Assistant conditions. However, a clear trend was found that more interaction with Daphne increases learning.&nbsp;</span></p>\n<p dir=\"ltr\"><span>2) Improving Designer Learning in Design Space Exploration by Adapting to the Designer's Learning Goals:&nbsp;Learning was significantly higher for the agent that adapts to the designer's learning goals vs the control. No significant differences were found between the agent that supports data mining without adapting and the control.&nbsp;</span></p>\n<p dir=\"ltr\"><span>3) Effect of goal-setting strategies on performance and learning:&nbsp;in a design space exploration task with two goals (performance vs learning), giving designers the goal of maximizing learning improves learning and giving them the goal of maximizing performance improves performance. There is a trade-off between these goals.</span></p>\n<p dir=\"ltr\"><span>4) Effect of explainability and level of automation of deep generative design agents on performance and learning:&nbsp;Higher automation degrades global design performance but improves local search performance, which makes sense because the agent is designed to perform local search. The&nbsp;effects of horizontal and vertical lines are easier to learn for the subjects than other semantic and abstract features.<span>&nbsp;</span></span></p>\n<p dir=\"ltr\"><span>5) Effect of Reflection and Incubation periods on performance and learning: A period of incubation results in better performance and learning than a period of self-reflection, but without significant differences compared to the control group.&nbsp;</span></p>\n<p dir=\"ltr\"><span> 6) Adapting to the designer?s level of expertise: Adapting to the level of expertise did not improve performance of learning in general. Performance and learning correlate with the number of designs evaluated and interactions with the agent.&nbsp;We observed some differences in the usage patterns of the agent by users of different levels of expertise.&nbsp; </span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/03/2023<br>\n\t\t\t\t\tModified by: Daniel&nbsp;Selva Valero</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe overarching goal of this project was to study new modes of interaction in human-machine collaborative design space exploration. The main outcomes of this project are as follows: \n\n1. We developed a theoretical framework to study human-machine collaborative design space exploration. In this framework, both the designer and the AI agent/cognitive assistant are modeled as agents that collaboratively work on a design task by interacting with a design tool and between them. Both agents can sense the state of the environment and the other agent, and they make decisions about what designs to try next based on those perceptions, their goals, their state, and what they know about the problem. Both agents have a hierarchy of goals about the design task, state (e.g., cognitive workload for the designer) knowledge (of the task, domain, and design process), and attributes (e.g., level of expertise for the designer, capabilities of the agent).\n2. We developed 2 AI agents for human-machine collaborative design space exploration: We developed new roles (e.g., Engineer, Analyst, Historian, Expert, Critic) and modes of initiative (reactive vs proactive) for the Daphne-EO cognitive assistant, where the task at hand is to design a constellation of Earth observation satellites. In addition, we developed a second agent from scratch for design space exploration of mechanical meta-materials.     \n3. We conducted 6 human-subject studies to help us understand several aspects of how the AI agent, designer, and task affect human-machine collaborative design space exploration outcomes---primarily design performance (quantity, quality, and diversity of designs) and designer learning. The six studies are as follows: \n1) Effect of agent role/level of initiative (peer vs assistant) on performance and learning: No significant difference was found in performance of learning between Peer vs Assistant conditions. However, a clear trend was found that more interaction with Daphne increases learning. \n2) Improving Designer Learning in Design Space Exploration by Adapting to the Designer's Learning Goals: Learning was significantly higher for the agent that adapts to the designer's learning goals vs the control. No significant differences were found between the agent that supports data mining without adapting and the control. \n3) Effect of goal-setting strategies on performance and learning: in a design space exploration task with two goals (performance vs learning), giving designers the goal of maximizing learning improves learning and giving them the goal of maximizing performance improves performance. There is a trade-off between these goals.\n4) Effect of explainability and level of automation of deep generative design agents on performance and learning: Higher automation degrades global design performance but improves local search performance, which makes sense because the agent is designed to perform local search. The effects of horizontal and vertical lines are easier to learn for the subjects than other semantic and abstract features. \n5) Effect of Reflection and Incubation periods on performance and learning: A period of incubation results in better performance and learning than a period of self-reflection, but without significant differences compared to the control group. \n 6) Adapting to the designer?s level of expertise: Adapting to the level of expertise did not improve performance of learning in general. Performance and learning correlate with the number of designs evaluated and interactions with the agent. We observed some differences in the usage patterns of the agent by users of different levels of expertise.  \n\n \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 02/03/2023\n\n\t\t\t\t\tSubmitted by: Daniel Selva Valero"
 }
}