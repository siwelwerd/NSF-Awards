{
 "awd_id": "1917763",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Immersive Virtual Reality with Haptic Feedback to Improve Safety Hazard Recognition, Assessment, and Decision-Making Among Construction Professionals",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927708",
 "po_email": "jladejio@nsf.gov",
 "po_sign_block_name": "Kemi Ladeji-Osias",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-08-22",
 "awd_max_amd_letter_date": "2019-08-22",
 "awd_abstract_narration": "The construction industry accounts for hundreds of fatalities and hundreds of thousands of non-fatal injuries annually. The current modes of safety training do not effectively prepare practitioners to build safely. Research shows that safety learning occurs to a great extent through experiential learning - especially when individuals experience or witness an injury firsthand. While these experiences may be impactful for learning, it is impossible to wait for all practitioners to sustain (or witness) a serious injury in order to learn safe construction practices. Therefore, this work aims to explore the use of increasingly affordable virtual reality and haptic feedback technologies to provide realistic, yet safe, learning environments that aim to replicate the types of situations where injuries have historically occurred onsite. The research team will develop construction site training modules where participants may navigate a virtual job site with the aim of identifying safety hazards. Unlike prior virtual-reality-based safety training, when hazards go unnoticed, users will see, hear, and feel haptic feedback to simulate the ramifications of the missed hazard. The research team will collect data before, during, and after experimental treatments to determine the extent to which this mode of simulation supports safety learning among users. The team envisions this work providing evidence to guide both researchers and practitioners interested in using enhanced safety training simulations by studying how immersive virtual experiences can impact learners on a psychological level to make them care about safety in order to catalyze learning related to safe construction practices.\r\n\r\nThe objectives of this research are to (1) create a novel and fully immersive Virtual Reality safety education environment that provides haptic feedback to users when hazards go unrecognized and unaddressed; (2) measure the extent to which instruction in this environment enhances learning outcomes in construction safety compared to traditional media; and (3) measure and explain the psychological mediators of cyberlearning in this multimedia-rich environment. The following research questions guide this study: How can haptic technology be incorporated with Virtual Reality technology to create an immersive visualization experience for construction safety education; and to what extent does Virtual Reality with haptic activate emotional arousal, generate situational awareness, and foster meaningful safety learning through multimedia? The experiment defined in this work will enable testing of explanatory hypotheses that examine the mediating roles of emotional arousal and situational interest in the cyberlearning process. Qualitative findings regarding multimedia learning will be explained using open-ended constructive interviews with the research subjects. This work will provide a novel approach for developing and using immersive cyberlearning experiences aimed at improving construction safety training. This will advance the body of knowledge related to designing cyberlearning environments, and will also provide empirical evidence of the ways in which this mode of education impacts safety learning. In terms of broad impact, this work directly aims to teach behaviors that will reduce injuries and save lives in construction. Furthermore, this work aims to target this form of learning using a scalable and cost-effective medium, which may broaden access to this critical form of cyberlearning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Steven",
   "pi_last_name": "Ayer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Steven Ayer",
   "pi_email_addr": "Steven.Ayer@colorado.edu",
   "nsf_id": "000688246",
   "pi_start_date": "2019-08-22",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Hallowell",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew R Hallowell",
   "pi_email_addr": "matthew.hallowell@colorado.edu",
   "nsf_id": "000526046",
   "pi_start_date": "2019-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "P.O. Box 876011",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852876011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "063Z",
   "pgm_ref_txt": "FW-HTF Futr Wrk Hum-Tech Frntr"
  },
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-6243aa8c-7fff-2533-9606-eaa7da52a299\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This research explored the use of Virtual Reality (VR) plus haptic (or touch-based) feedback to provide immersive educational experiences related to construction safety. The research team explored this topic through the development and testing of a novel immersive VR environment that allowed industry and student participants to navigate the environment to locate hazards in the virtual construction site. Unlike prior VR studies, when hazards remained unnoticed or unaddressed, participants were shown a realistic simulation of what ramifications from that hazard would likely occur through VR plus haptic. The aim of this work was to provide a realistic environment that would engage psychological mediators beyond what is typically observed through less immersive, and more traditional, media.</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Practitioners and student participants were involved throughout this work. In early phases of iterative VR development, practitioners were involved to validate or question the virtual construction site and hazards modeled. Later in the project, when a validated VR prototype was created, practitioners and students were asked to participate in the hazard identification activity. A mixed methods research approach was used to identify the ways in which participants were impacted when they observed the accidents that resulted from missed hazards. Specifically, the research team used interviews, pre-/post-activity assessments, eye tracking, and galvanic skin response data collection strategies to understand the extent to which the virtual experience triggered realistic reactions. In short, the team&rsquo;s work demonstrated that: environmental richness can directly impact the ability to simulate realistic conditions, which can lead to a more realistic reaction among participants; the realistic nature of this immersive experience can impact emotional states through both self-reported and biometric data; and finally, when paired with a traditional classroom training session, VR increases situational interest in construction safety trainings of construction workers.&nbsp;&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 12pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">In addition to the intellectual merits yielded through this work, the work also had several broad impacts that benefited those involved. This work involved participation from over 250 industry participants, 72 student participants, 3 graduate research associates, 28 undergraduate Computer Science student developers, and 6 Theatre students to provide realistic animations for virtual characters. The results of this work have been disseminated at several academic and industry conferences, and have also been published in leading peer-reviewed journals. Finally, the VR content produced through this work may be accessed here (https://github.com/ETBIMlab/ConstructionSafetySimulator/releases/). The people, publications, and downloadable products that were involved throughout this project will enable future educational research aimed at enabling learning that can support behavioral change and safer construction practices.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/15/2023<br>\n\t\t\t\t\tModified by: Steven&nbsp;Ayer</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "This research explored the use of Virtual Reality (VR) plus haptic (or touch-based) feedback to provide immersive educational experiences related to construction safety. The research team explored this topic through the development and testing of a novel immersive VR environment that allowed industry and student participants to navigate the environment to locate hazards in the virtual construction site. Unlike prior VR studies, when hazards remained unnoticed or unaddressed, participants were shown a realistic simulation of what ramifications from that hazard would likely occur through VR plus haptic. The aim of this work was to provide a realistic environment that would engage psychological mediators beyond what is typically observed through less immersive, and more traditional, media.\n\n \nPractitioners and student participants were involved throughout this work. In early phases of iterative VR development, practitioners were involved to validate or question the virtual construction site and hazards modeled. Later in the project, when a validated VR prototype was created, practitioners and students were asked to participate in the hazard identification activity. A mixed methods research approach was used to identify the ways in which participants were impacted when they observed the accidents that resulted from missed hazards. Specifically, the research team used interviews, pre-/post-activity assessments, eye tracking, and galvanic skin response data collection strategies to understand the extent to which the virtual experience triggered realistic reactions. In short, the team\u2019s work demonstrated that: environmental richness can directly impact the ability to simulate realistic conditions, which can lead to a more realistic reaction among participants; the realistic nature of this immersive experience can impact emotional states through both self-reported and biometric data; and finally, when paired with a traditional classroom training session, VR increases situational interest in construction safety trainings of construction workers.  \n\n \nIn addition to the intellectual merits yielded through this work, the work also had several broad impacts that benefited those involved. This work involved participation from over 250 industry participants, 72 student participants, 3 graduate research associates, 28 undergraduate Computer Science student developers, and 6 Theatre students to provide realistic animations for virtual characters. The results of this work have been disseminated at several academic and industry conferences, and have also been published in leading peer-reviewed journals. Finally, the VR content produced through this work may be accessed here (https://github.com/ETBIMlab/ConstructionSafetySimulator/releases/). The people, publications, and downloadable products that were involved throughout this project will enable future educational research aimed at enabling learning that can support behavioral change and safer construction practices.\n\n\t\t\t\t\tLast Modified: 09/15/2023\n\n\t\t\t\t\tSubmitted by: Steven Ayer"
 }
}