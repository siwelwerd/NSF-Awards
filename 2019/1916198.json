{
 "awd_id": "1916198",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Non-Convex Landscapes and High-Dimensional Latent Variable Models",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Pena Edsel",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 182654.0,
 "awd_amount": 182654.0,
 "awd_min_amd_letter_date": "2019-08-03",
 "awd_max_amd_letter_date": "2019-08-03",
 "awd_abstract_narration": "In many fields of science and engineering, probabilistic latent variable models are a powerful and widely-used tool for drawing inferences from complex data. They provide a flexible framework by modeling the complexity in observed data as arising from interactions between simpler random and unobserved quantities. Latent variable models used in modern applications are often high-dimensional, and this leads to both statistical and computational challenges for inference: Surprising phenomena emerge in which structure in one latent variable can create spurious and problematic artifacts in classical inference procedures for another. These classical procedures also commonly lead to non-convex optimization problems over a large number of parameters, which are difficult to computationally solve.\r\n\r\nThis research will study a flexible framework by modeling the complexity in observed data as arising from interactions between simpler random and unobserved quantities. The aim is in answering the following questions: How and why can one source of latent variation lead to artifacts in classical statistical estimates for another? What are the geometric properties of objective function landscapes in these models that render them difficult to optimize? And, can we design improved inferential procedures that correct for these artifacts and are easier to compute? The research will apply techniques from random matrix theory, free probability theory, and statistical physics to obtain a better understanding of these questions in high-dimensional settings.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zhou",
   "pi_last_name": "Fan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zhou Fan",
   "pi_email_addr": "zhou.fan@yale.edu",
   "nsf_id": "000792668",
   "pi_start_date": "2019-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Yale University",
  "inst_street_address": "150 MUNSON ST",
  "inst_street_address_2": "",
  "inst_city_name": "NEW HAVEN",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "2037854689",
  "inst_zip_code": "065113572",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "CT03",
  "org_lgl_bus_name": "YALE UNIV",
  "org_prnt_uei_num": "FL6GV84CKN57",
  "org_uei_num": "FL6GV84CKN57"
 },
 "perf_inst": {
  "perf_inst_name": "Yale University",
  "perf_str_addr": "10 Hillhouse Ave",
  "perf_city_name": "New Haven",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "065208290",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "CT03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 182654.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\"><span class=\"s1\">This research furthered our understanding of the statistical and computational challenges that arise in various high-dimensional and non-convex inference problems.</span>&nbsp;</p>\n<p class=\"p1\"><span class=\"s1\">One main thread of the research centered around computationally tractable methods for empirical Bayesian and variational Bayesian inference in high dimensions, via TAP formulations of variational objective functions and Approximate Message Passing </span><span class=\"s2\">alg</span><span class=\"s1\">orithms. Foundational investigations of mean-field phenomena in spin-glass models with non-i.i.d. couplings were undertaken, as a step towards developing </span><span class=\"s2\">alg</span><span class=\"s1\">orithms that yield more accurate mean-field approximations for posterior inference in Bayesian statistical settings.</span></p>\n<p class=\"p1\"><span class=\"s1\">A second thread of the research explored the non-convex geometry of likelihood optimization in mixture models with group invariance, as arising in applications of multi-reference alignment and single-particle cryo-electron microscopy. The research established connections between the statistical and computational difficulty of inference in these problems and the </span><span class=\"s2\">alg</span><span class=\"s1\">ebraic structure of the group invariants.</span></p>\n<p class=\"p1\"><span class=\"s1\">This research built upon and extended various techniques of random matrix theory, free probability theory, and statistical physics to study these problems. Additional applied outcomes of the research include characterizations of the spectra of neural networks, methods for optimizing neural network loss functions, </span><span class=\"s2\">alg</span><span class=\"s1\">orithms for estimating gradient-sparse signals over networks, methods for Bayesian and empirical Bayesian PCA, </span><span class=\"s2\">alg</span><span class=\"s1\">orithms for graph matching and network alignment, and characterizations of PCA estimates in linear mixed models.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/04/2022<br>\n\t\t\t\t\tModified by: Zhou&nbsp;Fan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "This research furthered our understanding of the statistical and computational challenges that arise in various high-dimensional and non-convex inference problems. \nOne main thread of the research centered around computationally tractable methods for empirical Bayesian and variational Bayesian inference in high dimensions, via TAP formulations of variational objective functions and Approximate Message Passing algorithms. Foundational investigations of mean-field phenomena in spin-glass models with non-i.i.d. couplings were undertaken, as a step towards developing algorithms that yield more accurate mean-field approximations for posterior inference in Bayesian statistical settings.\nA second thread of the research explored the non-convex geometry of likelihood optimization in mixture models with group invariance, as arising in applications of multi-reference alignment and single-particle cryo-electron microscopy. The research established connections between the statistical and computational difficulty of inference in these problems and the algebraic structure of the group invariants.\nThis research built upon and extended various techniques of random matrix theory, free probability theory, and statistical physics to study these problems. Additional applied outcomes of the research include characterizations of the spectra of neural networks, methods for optimizing neural network loss functions, algorithms for estimating gradient-sparse signals over networks, methods for Bayesian and empirical Bayesian PCA, algorithms for graph matching and network alignment, and characterizations of PCA estimates in linear mixed models.\n\n\t\t\t\t\tLast Modified: 12/04/2022\n\n\t\t\t\t\tSubmitted by: Zhou Fan"
 }
}