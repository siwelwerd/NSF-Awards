{
 "awd_id": "1907997",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III:Small: Optimal Query Processing meets Information Theory: from Proofs to Algorithms",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-08-09",
 "awd_max_amd_letter_date": "2020-06-29",
 "awd_abstract_narration": "The demand to analyze large datasets is increasing at a rate faster than our ability to compute meaningful insights from the data.  Despite the advances in query processing, query optimization, and novel hardware, efficient query evaluation remains a major challenge for the database community to date.  This project will explore new ways to design query processing algorithms by using techniques from information theory.  The field of information theory has been developed over the last seven decades and has found many applications ranging from communications to machine learning, but it has not been used yet in a significant way to support query processing.  This project transfers techniques from information theory to the task of processing massive amounts of data.\r\n\r\nThe project introduces a new paradigm for query evaluation, called \"from proofs to algorithms,\" which maps an information-theoretic proof of a query's upper bounds into optimal query evaluation algorithms. The project will pursue four thrusts.  In the first thrust it will use information theory to derive new bounds on the query answer based on database statistics.  The second thrust will develop a mapping from the information theoretic inequalities to relational operators, and from the complete proof of the query size to a complete query plan with provably optimal runtime.  The third thrust will extend these techniques to finer grained statistics, including sketches, distinct values, and heavy hitters.  Finally, the fourth thrust will extend the algorithm to queries with projections, aggregates, and group-by's.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dan",
   "pi_last_name": "Suciu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dan Suciu",
   "pi_email_addr": "suciu@cs.washington.edu",
   "nsf_id": "000218785",
   "pi_start_date": "2019-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981950001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 326947.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 173053.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Managing, transforming, and processing large amounts of data is a central task in many applications today.&nbsp; Specialized query processors can handle effectively large amounts of data, because they estimate the cost of the computation before they even begin the computation, then choose the most optimal algorithm given those estimates.&nbsp; However, the size- and cost-estimation methods found in query optimizers today are brittle.&nbsp; This project studied a new approach for estimating the output size of database queries, and choosing the most appropriate evaluation algorithm, by using Information Theory.&nbsp; Unlike existing cardinality estimators, those derived from information theory come with strong theoretical guarantees, and, in some cases, can lead to novel query evaluation algorithms.</p>\n<p><br />In a nutshell, Information Theory measures the number of bits needed to represent information, using a quantity called Entropy.&nbsp; There exists some well known inequalities connecting the entropies of joint random variables, called Shannon-inequalities, and some new, more sophisticated inequalities, called Non-Shannon inequalities.&nbsp; This project relied on such inequalities to derive new formulas giving upper bounds on the output to a complex query.&nbsp; Database systems often pre-compute various statistics on the base tables, such as their cardinalities, the number of distinct values in various columns, the maximum frequency in each column, etc.&nbsp; The entropy-based formula can use all available statistics to derive the best possible upper bound on the query's output.</p>\n<p><br />The project has lead to a number of results and two system.&nbsp; It proved that for most commonly used statistics, the output bound can be computed using only Shannon inequalities, which require only a linear solver; in contrast, it is an open problem whether Non-Shannon inequalities are computable.&nbsp; Next, the project explored how to use a compressed version of the degree sequences of the join attributes to further improve the bound on a query's output: this lead to both theoretical results, and to a system called SafeBound.&nbsp; The project also showed how Lp-norms on the degree sequence can be integrated into the information-theoretic bound.&nbsp; Finally, the project showed that the same Shannon-inequalities can be applied to database constraints.&nbsp; They can be used to prove implications between approximate Functional Dependencies and Multivalued Dependencies.&nbsp; The project used this insight to develop a system, called Maimon, for deriving an approximate acyclic schemas for a large and wide table.</p><br>\n<p>\n Last Modified: 11/12/2023<br>\nModified by: Dan&nbsp;Suciu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nManaging, transforming, and processing large amounts of data is a central task in many applications today. Specialized query processors can handle effectively large amounts of data, because they estimate the cost of the computation before they even begin the computation, then choose the most optimal algorithm given those estimates. However, the size- and cost-estimation methods found in query optimizers today are brittle. This project studied a new approach for estimating the output size of database queries, and choosing the most appropriate evaluation algorithm, by using Information Theory. Unlike existing cardinality estimators, those derived from information theory come with strong theoretical guarantees, and, in some cases, can lead to novel query evaluation algorithms.\n\n\n\nIn a nutshell, Information Theory measures the number of bits needed to represent information, using a quantity called Entropy. There exists some well known inequalities connecting the entropies of joint random variables, called Shannon-inequalities, and some new, more sophisticated inequalities, called Non-Shannon inequalities. This project relied on such inequalities to derive new formulas giving upper bounds on the output to a complex query. Database systems often pre-compute various statistics on the base tables, such as their cardinalities, the number of distinct values in various columns, the maximum frequency in each column, etc. The entropy-based formula can use all available statistics to derive the best possible upper bound on the query's output.\n\n\n\nThe project has lead to a number of results and two system. It proved that for most commonly used statistics, the output bound can be computed using only Shannon inequalities, which require only a linear solver; in contrast, it is an open problem whether Non-Shannon inequalities are computable. Next, the project explored how to use a compressed version of the degree sequences of the join attributes to further improve the bound on a query's output: this lead to both theoretical results, and to a system called SafeBound. The project also showed how Lp-norms on the degree sequence can be integrated into the information-theoretic bound. Finally, the project showed that the same Shannon-inequalities can be applied to database constraints. They can be used to prove implications between approximate Functional Dependencies and Multivalued Dependencies. The project used this insight to develop a system, called Maimon, for deriving an approximate acyclic schemas for a large and wide table.\t\t\t\t\tLast Modified: 11/12/2023\n\n\t\t\t\t\tSubmitted by: DanSuciu\n"
 }
}