{
 "awd_id": "1850220",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: RI: Principled Methods for Learning and Understanding of Neural Networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2019-05-01",
 "awd_exp_date": "2022-04-30",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2019-03-29",
 "awd_max_amd_letter_date": "2019-03-29",
 "awd_abstract_narration": "Deep neural networks have elicited breakthrough successes in machine learning by achieving impressive accuracies on diverse tasks such as facial recognition, object identification, anomaly detection and monitoring assistance on a large scale. However, deep neural networks are not theoretically guaranteed to always perform well, and they could, although rarely, fail in the presence of previously unseen data or small/imperceptible (adversarial) changes to the data. For instance, a home security system using a deep neural network facial recognition algorithm could mistake a stranger wearing pixelated sunglasses for the homeowner; a slight change of the environment, such as a rainy day, could cause a computer vision based autonomous driving vehicle to wrongly recognize a \"STOP\" sign as an outdoor commercial sign. The existence of such failure cases in widely used machine learning systems today could put our daily lives and even national security at risk. One way to make machine learning systems robust against these failure cases is to design algorithms that are guaranteed to provide an optimal solution, generalize to unseen scenarios and be robust to adversarial changes even if the attacker is given full knowledge of the algorithm. The methods developed via this research will provide theoretical bases that explain \"black-box\" deep neural networks and provide guarantees over their performance when applied to high-stakes problems. The project will be integrated with graduate and undergraduate education, fostering collaboration between researchers from Computer Science, Applied Math, Physics and Business. Software programs developed via this project will be released as an open-source toolkit, allowing widespread dissemination to researchers and practitioners in a range of fields.\r\n\r\nThis project will advocate theoretically guaranteed training and understanding of neural networks via techniques from learning theory, nonconvex optimization and consistent latent variable model learning using spectral methods. The investigator's goal is to design compressed neural networks that are theoretically guaranteed to generalize well, fit into Internet of Things devices with memory constraints, and are robust to adversarial examples. Concretely, the technical aims of the project are divided into three thrusts.  (1) Guaranteed training of deep nets. The investigator proposes to develop a theoretical justification of why deep residual networks are easier to optimize than non-residual ones when each layer provides a better-than-a-weak-baseline oracle in predicting labels. The investigator plans to use two approaches to guarantee existence and implement the better-than-a-weak-baseline oracle: (a) exploiting theoretically guaranteed training of shallow convolutional neural networks, a.k.a. convolutional dictionary learning, using spectral methods and (b) ensuring escaping from local optima using Homotopy transformations to \"sharpen\" local optima of network's objective landscape as recent advances in escaping from local optima showed that SGD will not get stuck at sharp local optima with small diameters. (2) Analyzing generalization ability of compressed deep neural networks. The investigator will introduce deep neural network compression using tensorized tensor decomposition, and develop tighter bounds for generalization error, which takes the input distribution and the compressibility of the network into account.  (3) Reliable deep neural networks robust to the worst attackers. To provide a universal defense mechanism against the worst possible adversarial examples using a minimax formulation, the investigator proposes to analyze the robustness of nonlinear single-layer neural nets using tensor decomposition method and ultimately design universal defense mechanisms for deep neural nets.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Furong",
   "pi_last_name": "Huang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Furong Huang",
   "pi_email_addr": "furongh@umd.edu",
   "nsf_id": "000762350",
   "pi_start_date": "2019-03-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425141",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Deep neural networks, deriving rich features using compositions of nonlinear layers, have elicited breakthrough successes in machine learning. Despite deep neural networks&rsquo; success in empirical studies, some foundational issues remain mysterious: (1) Why can we train deep networks given the high non-convex and extremely high-dimensional loss functions? (2) Why do deep networks generalize and how to derive non-vacuous generalization bounds? (3) How to design robust networks to defend against adversarial perturbations?</p>\n<p>In this proposal, we focus on theoretically guaranteed training and understanding of neural networks using my expertise on theoretical machine learning: learning theory, guaranteed learning of latent variable models using spectral methods, and nonconvex optimization.&nbsp;</p>\n<p>To achieve the goal of design compressed neural ntworks that are theoretically guaranteed to generalize well, can be fit into IoT devices with memory constraints and and are robust to adversarial examples, my lab as a group has collaborated within the lab and with external researchers. We have published 14 papers to understand architecture design in neural network and for interpretable neural networks, to improve robustness of deep neural networks and deep Reinforcement Learning, to&nbsp;design differentially private machine learning algorithms and to speedup&nbsp;transfer learning in Reinforcement Learning.&nbsp;</p>\n<p>We have implemented a tensorial neural network library on GPU<span>, a library that deals with a generalized neural network that allows for higher order tensor operations. We plan to open source the library. The library is likely to have a large impact on the Machine Learning research and deep learning community.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p><span>In conclusion, we have realized our ultimate goal to design compressed neural networks that are theoretically guaranteed to generalize well, can be fit into IoT devices with memory constraints and are robust to adversarial examples.<br /></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/30/2022<br>\n\t\t\t\t\tModified by: Furong&nbsp;Huang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDeep neural networks, deriving rich features using compositions of nonlinear layers, have elicited breakthrough successes in machine learning. Despite deep neural networks\u2019 success in empirical studies, some foundational issues remain mysterious: (1) Why can we train deep networks given the high non-convex and extremely high-dimensional loss functions? (2) Why do deep networks generalize and how to derive non-vacuous generalization bounds? (3) How to design robust networks to defend against adversarial perturbations?\n\nIn this proposal, we focus on theoretically guaranteed training and understanding of neural networks using my expertise on theoretical machine learning: learning theory, guaranteed learning of latent variable models using spectral methods, and nonconvex optimization. \n\nTo achieve the goal of design compressed neural ntworks that are theoretically guaranteed to generalize well, can be fit into IoT devices with memory constraints and and are robust to adversarial examples, my lab as a group has collaborated within the lab and with external researchers. We have published 14 papers to understand architecture design in neural network and for interpretable neural networks, to improve robustness of deep neural networks and deep Reinforcement Learning, to design differentially private machine learning algorithms and to speedup transfer learning in Reinforcement Learning. \n\nWe have implemented a tensorial neural network library on GPU, a library that deals with a generalized neural network that allows for higher order tensor operations. We plan to open source the library. The library is likely to have a large impact on the Machine Learning research and deep learning community. \n\n \n\nIn conclusion, we have realized our ultimate goal to design compressed neural networks that are theoretically guaranteed to generalize well, can be fit into IoT devices with memory constraints and are robust to adversarial examples.\n\n\n\t\t\t\t\tLast Modified: 08/30/2022\n\n\t\t\t\t\tSubmitted by: Furong Huang"
 }
}