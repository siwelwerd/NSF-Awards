{
 "awd_id": "1932068",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: Medium: Collaborative Research: Learning and Verifying Conformant Data-Driven Models for Cyber-Physical Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928950",
 "po_email": "rwachter@nsf.gov",
 "po_sign_block_name": "Ralph Wachter",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 599724.0,
 "awd_amount": 599724.0,
 "awd_min_amd_letter_date": "2019-09-09",
 "awd_max_amd_letter_date": "2022-05-26",
 "awd_abstract_narration": "This project investigates fundamental techniques for building mathematical models that can be safely used to make trustworthy predictions and control decisions. Mathematical models form the foundation for modern Cyber-Physical Systems (CPS). Examples include vehicle models that predict how a car will move when brakes are applied, or physiological models that predict how the blood glucose levels change in a patient with type-1 diabetes when insulin is administered. The success of machine learning tools has yielded data-driven models such as neural networks. However, depending on how data is collected and the models are learned, it is possible to obtain models that violate fundamental physical, chemical, or physiological facts that can potentially threaten life and property. The approach of the project is to expose these model flaws through advanced analysis. The project seeks to broaden participation in computing through mentoring activities that will encourage undergraduate women and members of underrepresented minority groups to consider a career in research.\r\n\r\nThe research combines falsification methods for exposing failure to conform with verification approaches for rigorously proving conformance. Furthermore, approaches for learning models of dynamical systems from data and imposing core cyber-physical domain knowledge are under investigation. The project is applying these data-driven models with conformance guarantees to the design of safe controllers for autonomous vehicles, models of human insulin glucose regulation and robotic swarms. The effort is advancing CPS education by creating a framework for distance education focused on CPS. The researchers are developing a series of low cost hardware testbeds and self-paced learning tasks that will expose students to the process of building highly reliable and safety critical CPS.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Georgios",
   "pi_last_name": "Fainekos",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Georgios Fainekos",
   "pi_email_addr": "fainekos@asu.edu",
   "nsf_id": "000542660",
   "pi_start_date": "2019-09-09",
   "pi_end_date": "2022-05-26"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Heni",
   "pi_last_name": "Ben Amor",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Heni Ben Amor",
   "pi_email_addr": "hbenamor@asu.edu",
   "nsf_id": "000702569",
   "pi_start_date": "2022-05-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Heni",
   "pi_last_name": "Ben Amor",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Heni Ben Amor",
   "pi_email_addr": "hbenamor@asu.edu",
   "nsf_id": "000702569",
   "pi_start_date": "2019-09-09",
   "pi_end_date": "2022-05-26"
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "PO Box 876011",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852816011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "791800",
   "pgm_ele_name": "CPS-Cyber-Physical Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 599724.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Machine learning and data-driven techniques have led to remarkable technological advances and new capabilities in many fields such as robotics, medicine, and entertainment. Their ability to process large swaths of data and derive useful models for complex phenomena renders them appealing to many scientists, engineers and practitioners. However, a lingering problem is the safety of such learned models. How is it possible to ensure that learned models conform to some basic safety properties? How can such properties be strictly enforced and verified? These questions become particularly important when ML-derived models are used to control cyber-physical systems, such as robots, prostheses, cars, or medical devices.</p>\n<p>In this project, we have developed new theoretical and practical frameworks for ensuring the safety and conformance of data-driven models. The introduced algorithms can be used to automatically train and adapt complex cyber-physical systems while also maintaining safety guarantees at all times. For example, when adjusting a robotic leg prosthesis to a human user, the algorithms ensure that the prosthesis does not exhibit any unsafe behaviors. Thus, models trained with machine learning can be verified to be locally safe. We argue that this type of approach is critical for human-centric and safety-critical applications of robot learning, e.g., the next-generation of assistive robotics. In addition, we have also derived predictive versions of our framework. Rather than waiting for unsafe behavior to occur, these algorithms can anticipate potentially dangerous states in the future and proactively steer away from them.&nbsp;</p>\n<p>The results of this project are published in a number of peer reviewed papers. Among others, these papers have been nominated for international awards such as the Best Poster Award at the NeurIPS Workshop on Robot Learning: TrustWorthy Robotics (NeurIPS 2022). The project also lead to a several open-source software packages for safe AI. The work has also been featured on national and international news channels such as the German TV channel Deutsche Welle.</p>\n<p>PI Ben Amor leveraged the project to develop new teaching materials which lead to him receiving 4x the Best Teacher Award at the Schools of Engineering at ASU. Likewise, substantial outreach activities have been performed to disseminate the research results to a wider audience. PI Ben Amor joined the IEEE Women in Engineering Committee as a member with the aim of promoting women engineers and scientists and inspiring girls around the world to follow their academic interests to a career in engineering. The project also lead to the graduation of 1 PhD student with 2 more PhD students anticipated to finish graduation in 2024.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/19/2024<br>\nModified by: Heni&nbsp;Ben Amor</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1932068/1932068_10640699_1708320380695_Screen_Shot_2024_02_18_at_9.25.01_PM--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1932068/1932068_10640699_1708320380695_Screen_Shot_2024_02_18_at_9.25.01_PM--rgov-800width.png\" title=\"Verified Control of Prostheses\"><img src=\"/por/images/Reports/POR/2024/1932068/1932068_10640699_1708320380695_Screen_Shot_2024_02_18_at_9.25.01_PM--rgov-66x44.png\" alt=\"Verified Control of Prostheses\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our algorithms ensure the safety of human-centric devices, such as prostheses.</div>\n<div class=\"imageCredit\">Heni Ben Amor</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Heni&nbsp;Ben Amor\n<div class=\"imageTitle\">Verified Control of Prostheses</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1932068/1932068_10640699_1708320253325_Screen_Shot_2024_02_18_at_9.19.52_PM--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1932068/1932068_10640699_1708320253325_Screen_Shot_2024_02_18_at_9.19.52_PM--rgov-800width.png\" title=\"A robot in a hospital environment.\"><img src=\"/por/images/Reports/POR/2024/1932068/1932068_10640699_1708320253325_Screen_Shot_2024_02_18_at_9.19.52_PM--rgov-66x44.png\" alt=\"A robot in a hospital environment.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">For a robot to navigate in a hospital it needs to ensure basic safety requirements so as to avoid patients and staff. Our methods guarantee such requirements at all times.</div>\n<div class=\"imageCredit\">Keyvan Majd</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Heni&nbsp;Ben Amor\n<div class=\"imageTitle\">A robot in a hospital environment.</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nMachine learning and data-driven techniques have led to remarkable technological advances and new capabilities in many fields such as robotics, medicine, and entertainment. Their ability to process large swaths of data and derive useful models for complex phenomena renders them appealing to many scientists, engineers and practitioners. However, a lingering problem is the safety of such learned models. How is it possible to ensure that learned models conform to some basic safety properties? How can such properties be strictly enforced and verified? These questions become particularly important when ML-derived models are used to control cyber-physical systems, such as robots, prostheses, cars, or medical devices.\n\n\nIn this project, we have developed new theoretical and practical frameworks for ensuring the safety and conformance of data-driven models. The introduced algorithms can be used to automatically train and adapt complex cyber-physical systems while also maintaining safety guarantees at all times. For example, when adjusting a robotic leg prosthesis to a human user, the algorithms ensure that the prosthesis does not exhibit any unsafe behaviors. Thus, models trained with machine learning can be verified to be locally safe. We argue that this type of approach is critical for human-centric and safety-critical applications of robot learning, e.g., the next-generation of assistive robotics. In addition, we have also derived predictive versions of our framework. Rather than waiting for unsafe behavior to occur, these algorithms can anticipate potentially dangerous states in the future and proactively steer away from them.\n\n\nThe results of this project are published in a number of peer reviewed papers. Among others, these papers have been nominated for international awards such as the Best Poster Award at the NeurIPS Workshop on Robot Learning: TrustWorthy Robotics (NeurIPS 2022). The project also lead to a several open-source software packages for safe AI. The work has also been featured on national and international news channels such as the German TV channel Deutsche Welle.\n\n\nPI Ben Amor leveraged the project to develop new teaching materials which lead to him receiving 4x the Best Teacher Award at the Schools of Engineering at ASU. Likewise, substantial outreach activities have been performed to disseminate the research results to a wider audience. PI Ben Amor joined the IEEE Women in Engineering Committee as a member with the aim of promoting women engineers and scientists and inspiring girls around the world to follow their academic interests to a career in engineering. The project also lead to the graduation of 1 PhD student with 2 more PhD students anticipated to finish graduation in 2024.\n\n\n\t\t\t\t\tLast Modified: 02/19/2024\n\n\t\t\t\t\tSubmitted by: HeniBen Amor\n"
 }
}