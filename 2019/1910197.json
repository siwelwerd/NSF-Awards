{
 "awd_id": "1910197",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Using Error-Bounded Lossy Compression to Improve High-Performance Computing Systems and Applications",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2022-12-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 326080.0,
 "awd_min_amd_letter_date": "2019-07-24",
 "awd_max_amd_letter_date": "2022-05-20",
 "awd_abstract_narration": "Performance of scientific simulations that are executed on large-scale computers is highly dependent on the volume of data transferred and the available bandwidth to transfer the data during the simulation. Higher performance decreases the time necessary for obtaining results from a scientific simulation and enables faster scientific advancement.  This project seeks to understand the trade-offs of performance and accuracy when using lossy compression to reduce the volume of data transferred during scientific simulations. Lossy data compression significantly reduces the volume of scientific data by trading a loss in accuracy of the decompressed data for larger reductions in the compressed data size. The goal of this project is to investigate how lossy compression impacts the fidelity of the results of scientific simulations, which is critical for understanding how lossy compression can be effectively applied in practice. This project fosters the use and importance of large-scale computing resources for undergraduate STEM students and  includes research experiences for undergraduates who are actively engaged in research tasks. \r\n\r\nThis project considers important trade-offs in using lossy compression for scientific simulations such as: energy efficiency, sensitivity of compression and decompression time and compression ratio to the selection of compression parameters, and impact on statistical measures. This project analyzes the effects of lossy compression on real-world scientific data from a diverse set of domains such as fluid dynamics, astrophysics, and genomics.  Understanding these trade-offs guides the integration of lossy data compression into computational kernels and applications. This project is jointly funded by CCF/SHF core program and  the Established Program to Stimulate Competitive Research (EPSCoR).\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jon",
   "pi_last_name": "Calhoun",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jon Calhoun",
   "pi_email_addr": "jonccal@clemson.edu",
   "nsf_id": "000766964",
   "pi_start_date": "2019-07-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Clemson University",
  "inst_street_address": "201 SIKES HALL",
  "inst_street_address_2": "",
  "inst_city_name": "CLEMSON",
  "inst_state_code": "SC",
  "inst_state_name": "South Carolina",
  "inst_phone_num": "8646562424",
  "inst_zip_code": "296340001",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "SC03",
  "org_lgl_bus_name": "CLEMSON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "H2BMNX7DSKU8"
 },
 "perf_inst": {
  "perf_inst_name": "Clemson University",
  "perf_str_addr": "230 Kappa Street",
  "perf_city_name": "Clemson",
  "perf_st_code": "SC",
  "perf_st_name": "South Carolina",
  "perf_zip_code": "296340001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "SC03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 300000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 10080.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Performance of scientific simulations that are executed on large-scale computers is highly dependent on the volume of data transferred and the available bandwidth to transfer the data during the simulation. Higher performance decreases the time necessary for obtaining results from a scientific simulation and enables faster scientific advancement. This project conducted research to understand the trade-offs of performance and accuracy when using lossy compression to reduce the volume of data transferred during scientific simulations. Lossy data compression significantly reduces the volume of scientific data by trading a loss in accuracy of the decompressed data for larger reductions in the compressed data size. The goal of this project was to investigate how lossy compression impacts the fidelity of the results of scientific simulations, which is critical for understanding how lossy compression can be effectively applied in practice. This project analyzed the effects of lossy compression on real-world scientific data from a diverse set of domains and considered important trade-offs in using lossy compression for scientific simulations such as: energy efficiency, sensitivity of compression and decompression time and compression ratio to the selection of compression parameters, and impact on statistical measures. To this end, it made the following novel contributions:</p>\n<ul>\n<li><span><strong>Energy Efficiency:</strong> Results show that lossy compressing large data files before they are transferred to the file-system allows for energy savings. In addition, the project investigated the energy costs associated with writing large volumes of data to different storage technologies.</span></li>\n<li><span><strong>Sensitivity:</strong> When investigating the sensitivity of lossy compression algorithms, this project discovered that lossy compressed data is very vulnerable to data corruption. Even a small amount of corruption in a lossy compressed data file can make the file unreadable, or make the decompression process distort the data so much that it makes the data useless for science. This project developed methods such as the Automated Resiliency for Compression (ARC) to protect lossy compressed data from multiple sources of data corruption. Furthermore, this project's work on integrating lossy compression into applications and workflows highlighted the need to have judicious control of the level of loss and its location. Experimental results show user specified correctness metrics can be maintained when using lossy data for applications and workflows. Finally, this project improved the runtime performance of lossy compressors.</span></li>\n<li><span><strong>Statistical Measures:</strong> To ensure user specified correctness metrics are met, we developed methods (e.g. FRaZ and OptZConfig) to automatically configure lossy compressors based on the user's metrics. Thus, removing the trial-and-error methods that practitioners commonly use. Moreover, we developed new methods of lossy compression that yield larger levels of reduction with fewer distortions in the data.</span></li>\n</ul>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>The advances made by this project developed software and methodologies to integrate lossy compression into scientific workflows while meeting domain specific measures for correctness. When domain scientists leverage lossy compression, they are able to save more experimental results faster, which can enhance their understanding of their field and increase their scientific throughput. Results from this project are published in multiple peer-reviewed conferences and journals. In addition, a subset of the results have been incorporated into revisions to current courses and in the development of new courses at the graduate and undergraduate level. This project fostered the use and importance of large-scale computing resources for undergraduate STEM students and includes research experiences for undergraduates (REU) who were actively engaged in the research tasks. Multiple graduate and undergraduate students conducted research on this project and were provided professional mentoring. Graduate students supported by this project used their research contributions to develop and defend the MS thesis or Ph.D. dissertation. Undergraduate and REU students went to graduate school or took industry jobs in areas related to large-scale and high-performance computing.</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p dir=\"ltr\">&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/01/2023<br>\n\t\t\t\t\tModified by: Jon&nbsp;Calhoun</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nPerformance of scientific simulations that are executed on large-scale computers is highly dependent on the volume of data transferred and the available bandwidth to transfer the data during the simulation. Higher performance decreases the time necessary for obtaining results from a scientific simulation and enables faster scientific advancement. This project conducted research to understand the trade-offs of performance and accuracy when using lossy compression to reduce the volume of data transferred during scientific simulations. Lossy data compression significantly reduces the volume of scientific data by trading a loss in accuracy of the decompressed data for larger reductions in the compressed data size. The goal of this project was to investigate how lossy compression impacts the fidelity of the results of scientific simulations, which is critical for understanding how lossy compression can be effectively applied in practice. This project analyzed the effects of lossy compression on real-world scientific data from a diverse set of domains and considered important trade-offs in using lossy compression for scientific simulations such as: energy efficiency, sensitivity of compression and decompression time and compression ratio to the selection of compression parameters, and impact on statistical measures. To this end, it made the following novel contributions:\n\nEnergy Efficiency: Results show that lossy compressing large data files before they are transferred to the file-system allows for energy savings. In addition, the project investigated the energy costs associated with writing large volumes of data to different storage technologies.\nSensitivity: When investigating the sensitivity of lossy compression algorithms, this project discovered that lossy compressed data is very vulnerable to data corruption. Even a small amount of corruption in a lossy compressed data file can make the file unreadable, or make the decompression process distort the data so much that it makes the data useless for science. This project developed methods such as the Automated Resiliency for Compression (ARC) to protect lossy compressed data from multiple sources of data corruption. Furthermore, this project's work on integrating lossy compression into applications and workflows highlighted the need to have judicious control of the level of loss and its location. Experimental results show user specified correctness metrics can be maintained when using lossy data for applications and workflows. Finally, this project improved the runtime performance of lossy compressors.\nStatistical Measures: To ensure user specified correctness metrics are met, we developed methods (e.g. FRaZ and OptZConfig) to automatically configure lossy compressors based on the user's metrics. Thus, removing the trial-and-error methods that practitioners commonly use. Moreover, we developed new methods of lossy compression that yield larger levels of reduction with fewer distortions in the data.\n\n\n \nThe advances made by this project developed software and methodologies to integrate lossy compression into scientific workflows while meeting domain specific measures for correctness. When domain scientists leverage lossy compression, they are able to save more experimental results faster, which can enhance their understanding of their field and increase their scientific throughput. Results from this project are published in multiple peer-reviewed conferences and journals. In addition, a subset of the results have been incorporated into revisions to current courses and in the development of new courses at the graduate and undergraduate level. This project fostered the use and importance of large-scale computing resources for undergraduate STEM students and includes research experiences for undergraduates (REU) who were actively engaged in the research tasks. Multiple graduate and undergraduate students conducted research on this project and were provided professional mentoring. Graduate students supported by this project used their research contributions to develop and defend the MS thesis or Ph.D. dissertation. Undergraduate and REU students went to graduate school or took industry jobs in areas related to large-scale and high-performance computing.\n\n\n\n \n \n\n\t\t\t\t\tLast Modified: 05/01/2023\n\n\t\t\t\t\tSubmitted by: Jon Calhoun"
 }
}