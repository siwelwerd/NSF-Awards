{
 "awd_id": "1930606",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Mutual Learning: A Systems Theoretic Investigation",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": "7032925394",
 "po_email": "rnash@nsf.gov",
 "po_sign_block_name": "Richard Nash",
 "awd_eff_date": "2019-09-15",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 268607.0,
 "awd_amount": 268607.0,
 "awd_min_amd_letter_date": "2019-08-23",
 "awd_max_amd_letter_date": "2019-08-23",
 "awd_abstract_narration": "Mutual learning can happen between two humans, a human and machine, or between two machines.  The first class is of interest to researchers in the field of social psychology.  The importance of human machine interactions is being felt in many situations and most recently in the interaction between the human driven and completely autonomous vehicles. The proposed research deals with machine-machine learning to investigate efficient cooperation between machines, but also reveal the limitations of this cooperation.  In particular, the research will attempt to answer questions such as whether two agents, although individually using schemes that will result in the desired behavior, may arrive at wrong conclusion using mutual learning.\r\n\r\nWhile the term mutual learning has been used by other investigators in the past, our objective is to investigate it in a quantitative sense within the framework of mathematical systems theory. The problems proposed for investigation include deterministic optimization in high dimensional spaces, stochastic reinforcement learning in static/stationary environments (learning automata) using both deterministic and stochastic schemes, learning in dynamic environments such as the ones described by Markov Decision Processes, and learning/adaptation by multiple agents in dynamic environments described by deterministic or stochastic difference and differential equations. The results on mutual learning obtained during the proposed project will be widely disseminated at national and international conferences as well as the bi-annual Yale Workshops on Adaptive and Learning Systems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Snehasis",
   "pi_last_name": "Mukhopadhyay",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Snehasis Mukhopadhyay",
   "pi_email_addr": "smukhopa@iupui.edu",
   "nsf_id": "000118072",
   "pi_start_date": "2019-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Indiana University",
  "inst_street_address": "107 S INDIANA AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BLOOMINGTON",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "3172783473",
  "inst_zip_code": "474057000",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IN09",
  "org_lgl_bus_name": "TRUSTEES OF INDIANA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "YH86RTW2YVJ4"
 },
 "perf_inst": {
  "perf_inst_name": "Indiana University-Purdue University at Indianapolis",
  "perf_str_addr": "723 W Michigan St SL 280",
  "perf_city_name": "Indianapolis",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "462025191",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "IN07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760700",
   "pgm_ele_name": "EPCN-Energy-Power-Ctrl-Netwrks"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "092E",
   "pgm_ref_txt": "Control systems & applications"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 268607.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The concept of mutual learning in which two (or more) agents &ldquo;learn&rdquo; from each other in a random environment is in a sense not new, since &ldquo;divide and conquer&rdquo; strategies have been used to solve many complex problems in the past. The essential difference between the PIs&rsquo; work and past work is the suggestion that the problems should be formulated within a mathematical framework and that the changes in each participant should be quantified in some fashion. The PIs work clearly point out that mutual learning is an approach (and not a single algorithm) which can take place in many forms and ways. Even in the relatively simple case of two stochastic learning automata operating in a stationary random environment, only general comments can be made at this stage of research; substantive and definitive answers require more work by the research community. The authors, however, believe that this work will give rise to interesting and meaningful discussions in the systems community concerning mutual learning.</p>\n<p>The following scientific papers have been published based on the research conducted under this project:</p>\n<p>Narendra, K.S. and Mukhopadhyay, S., 2019, July. Mutual learning: Part i-learning automata. In 2019 American Control Conference (ACC) (pp. 916-921). IEEE.<br />Narendra, K.S. and Mukhopadhyay, S., 2020, July. Mutual Learning: Part II--Reinforcement Learning. In 2020 American Control Conference (ACC) (pp. 1105-1110). IEEE.<br />Narendra, K.S., Mukhopadhyay, S. and Esfandiari, K., 2022, October. Mutual Learning in Optimization. In 2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC) (pp. 492-497). IEEE.<br />Reid, C. and Mukhopadhyay, S., 2020, December. Mutual Q-learning. In 2020 3rd International Conference on Control and Robots (ICCR) (pp. 128-133). IEEE.<br />Reid, C. and Mukhopadhyay, S., 2021, August. Mutual reinforcement learning with heterogenous agents. In 2021 IEEE International Conference on Smart Computing (SMARTCOMP) (pp. 395-397). IEEE.<br />Chowdhury, S., Narendra, K. S., and Mukhopadhyay, S. (2023). &ldquo;Mutual Learning for Pattern Recognition for Increasing Prediction Accuracy&rdquo;, IEEE Systems, Man, and Cybernetics Conference (IEEE SMC).<br />Chowdhury, S., Mukhopadhyay, S. and Narendra, K.S., (2023)&nbsp; Mutual Learning Algorithm for Kidney Cyst, Kidney Tumor, and Kidney Stone Diagnosis. Proceedings of the 18th Conference on Computer Science and Intelligence Systems pp. 401&ndash;410.<br />Narendra, K. S., Zheng, L., and Mukhopadhyay, S. (2024). Mutual Learning in Optimization- Part II, Submitted to American Control Conference (ACC), IEEE, 2024.</p><br>\n<p>\n Last Modified: 11/30/2023<br>\nModified by: Snehasis&nbsp;Mukhopadhyay</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe concept of mutual learning in which two (or more) agents learn from each other in a random environment is in a sense not new, since divide and conquer strategies have been used to solve many complex problems in the past. The essential difference between the PIs work and past work is the suggestion that the problems should be formulated within a mathematical framework and that the changes in each participant should be quantified in some fashion. The PIs work clearly point out that mutual learning is an approach (and not a single algorithm) which can take place in many forms and ways. Even in the relatively simple case of two stochastic learning automata operating in a stationary random environment, only general comments can be made at this stage of research; substantive and definitive answers require more work by the research community. The authors, however, believe that this work will give rise to interesting and meaningful discussions in the systems community concerning mutual learning.\n\n\nThe following scientific papers have been published based on the research conducted under this project:\n\n\nNarendra, K.S. and Mukhopadhyay, S., 2019, July. Mutual learning: Part i-learning automata. In 2019 American Control Conference (ACC) (pp. 916-921). IEEE.\nNarendra, K.S. and Mukhopadhyay, S., 2020, July. Mutual Learning: Part II--Reinforcement Learning. In 2020 American Control Conference (ACC) (pp. 1105-1110). IEEE.\nNarendra, K.S., Mukhopadhyay, S. and Esfandiari, K., 2022, October. Mutual Learning in Optimization. In 2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC) (pp. 492-497). IEEE.\nReid, C. and Mukhopadhyay, S., 2020, December. Mutual Q-learning. In 2020 3rd International Conference on Control and Robots (ICCR) (pp. 128-133). IEEE.\nReid, C. and Mukhopadhyay, S., 2021, August. Mutual reinforcement learning with heterogenous agents. In 2021 IEEE International Conference on Smart Computing (SMARTCOMP) (pp. 395-397). IEEE.\nChowdhury, S., Narendra, K. S., and Mukhopadhyay, S. (2023). Mutual Learning for Pattern Recognition for Increasing Prediction Accuracy, IEEE Systems, Man, and Cybernetics Conference (IEEE SMC).\nChowdhury, S., Mukhopadhyay, S. and Narendra, K.S., (2023) Mutual Learning Algorithm for Kidney Cyst, Kidney Tumor, and Kidney Stone Diagnosis. Proceedings of the 18th Conference on Computer Science and Intelligence Systems pp. 401410.\nNarendra, K. S., Zheng, L., and Mukhopadhyay, S. (2024). Mutual Learning in Optimization- Part II, Submitted to American Control Conference (ACC), IEEE, 2024.\t\t\t\t\tLast Modified: 11/30/2023\n\n\t\t\t\t\tSubmitted by: SnehasisMukhopadhyay\n"
 }
}