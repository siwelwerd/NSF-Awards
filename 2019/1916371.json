{
 "awd_id": "1916371",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Prior Calibration and Algorithmic Guarantees under Parameter Restrictions",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Pena Edsel",
 "awd_eff_date": "2019-08-15",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 107000.0,
 "awd_amount": 107000.0,
 "awd_min_amd_letter_date": "2019-08-15",
 "awd_max_amd_letter_date": "2019-08-15",
 "awd_abstract_narration": "Statistical learning of many real systems can be significantly enhanced by harnessing and translating domain knowledge into meaningful parameter restrictions. With the advent of high throughput datasets, such restrictions are often present on high-dimensional parameter spaces thereby complicating inference. This research aims to develop novel statistical methods and computational algorithms for such problems drawing motivation from a number of real applications. Working within a nonparametric Bayes framework, the first part of the research project lays emphasis on the importance of calibrating prior distributions in these constrained problems and theoretically quantifying the impact of the constraints on parameter learning. The second part aims to develop efficient Markov Chain Monte Carlo and variational algorithms and analyze their convergence behaviors for the said problems. The PIs will also propose undergraduate courses that will focus on the modeling and applied components of Bayesian methods. When teaching the courses, the PIs will use daily life as well as scientific examples across different disciplines to inspire students' learning. The Activity-Based Learning (ABL) courses aim to enrich students' academic experience and learning outcomes by connecting theory with practice and concepts with methods, using data & insights obtained through engagement with the larger world.\r\n\r\n\r\nThe research project is motivated by statistical and computing challenges posed by a number of real scientific applications where various complex restrictions are posed on key parameters, necessitating novel statistical methods and associated computational algorithms. Operating in a Bayesian paradigm which enables incorporation of various constraints in a principled framework and provides readily available uncertainty estimates often sought after in scientific applications, a major emphasis will be laid on calibration of prior distributions under these constrained spaces. Examples will be provided where seemingly innocuous prior choices routinely used in practice can lead to biased inferences in certain specific situations. A rigorous theoretical understanding of such phenomenon will be provided along with development of alternative default priors on these constrained spaces. The methodological and theoretical developments will be accompanied by efficient computational algorithms using novel approximation techniques in the context of Markov chain Monte Carlo and variational algorithms that meet the scalability demanded by the specific applications and beyond. The algorithm development will be paralleled by novel convergence analysis, bridging ideas between the optimization and sampling literature.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Debdeep",
   "pi_last_name": "Pati",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Debdeep Pati",
   "pi_email_addr": "dpati2@wisc.edu",
   "nsf_id": "000653196",
   "pi_start_date": "2019-08-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Anirban",
   "pi_last_name": "Bhattacharya",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anirban Bhattacharya",
   "pi_email_addr": "anirbanb@stat.tamu.edu",
   "nsf_id": "000655820",
   "pi_start_date": "2019-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M University",
  "inst_street_address": "400 HARVEY MITCHELL PKY S STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778454375",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A & M UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JF6XLNB4CDJ5"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M University Main Campus",
  "perf_str_addr": "3143 TAMU",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433143",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 107000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 2\">\n<div class=\"section\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>Statistical learning of many real systems can be significantly enhanced by harnessing and translating domain knowledge into meaningful constraints on model parameters. However, the inferential mechanism can become increasingly complicated when multiple constraints need to be accounted for, both in terms of model building as well as implementing efficient algorithms.&nbsp; We have&nbsp;</span>developed novel statistical methods and computational algorithms for such problems drawing motivation from a number of real applications. Working within a nonparanetric Bayes framework, one of our primary goals is to calibrate prior distributions in these constrained problems. We have been able to rigorously quantify why the standard prior choice leads to a biased estimate and was able to correct it using a shrinkage idea. The article is published in the Journal of the American Statistical Association.&nbsp; This provides a cautionary note to practitioners routinely implementing such ideas.&nbsp; We have also developed novel algorithms for conducting associated Bayesian inference, which is published in Statistics and Computing.&nbsp; &nbsp;The next important goal of the proposal was to provide statistical guarantees for non-standard variational algorithms which have gained prominence over the past two decades as a scalable computational environment for Bayesian inference. Despite the empirical success, it was unclear under what conditions such algorithms delivers the correct solution leaving it to expert tuning and experience for guaranteed results.&nbsp; In a sequence of articles published in AISTATS, Entropy and JMLR, the PIs are able to provide sufficient conditions for the algorithmic convergence and optimal statistical properties of the converges solutions. The PIs expect that these theoretical results will popularize the algorithms even more among machine learners and statisticians.&nbsp;&nbsp;</p>\n<p>&nbsp;</p>\n<p>4 PhD students advised / co-advised&nbsp; by PI Pati and co-PI Bhattacharya worked on the above projects as a part of their PhD dissertation.&nbsp; Two of them (including one female) obtained tenure-track Assistant professor positions and the remaining two are working pharmaceutical sectors upon completion of their PhD.&nbsp; The softwares obtained from the&nbsp; research are now available at the PIs github page: https://github.com/debdeeptamu.&nbsp; During Fall 2019, the PIs offered a special topic course on analyzing convergence of variational methods which attracted a significant percentage of the graduate students at the department of Statistics at Texas A&amp;M.&nbsp; &nbsp;Many of them gained expertise to provide theoretical guarantees for their own disseration problems. The PIs also co-organized a session on variational methods in the annual Data-Science conference at Texas A&amp;M on Oct 21-22, 2023 where world leaders working in this area are invited. The graduate students and postdocs at Texas A&amp;M University and beyond are hugely benefited from the interaction and they also got a chance to showcase their research through poster presentation.&nbsp;&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<div class=\"page\" title=\"Page 2\">\n<div class=\"section\"></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/28/2022<br>\n\t\t\t\t\tModified by: Debdeep&nbsp;Pati</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\n\n\nStatistical learning of many real systems can be significantly enhanced by harnessing and translating domain knowledge into meaningful constraints on model parameters. However, the inferential mechanism can become increasingly complicated when multiple constraints need to be accounted for, both in terms of model building as well as implementing efficient algorithms.  We have developed novel statistical methods and computational algorithms for such problems drawing motivation from a number of real applications. Working within a nonparanetric Bayes framework, one of our primary goals is to calibrate prior distributions in these constrained problems. We have been able to rigorously quantify why the standard prior choice leads to a biased estimate and was able to correct it using a shrinkage idea. The article is published in the Journal of the American Statistical Association.  This provides a cautionary note to practitioners routinely implementing such ideas.  We have also developed novel algorithms for conducting associated Bayesian inference, which is published in Statistics and Computing.   The next important goal of the proposal was to provide statistical guarantees for non-standard variational algorithms which have gained prominence over the past two decades as a scalable computational environment for Bayesian inference. Despite the empirical success, it was unclear under what conditions such algorithms delivers the correct solution leaving it to expert tuning and experience for guaranteed results.  In a sequence of articles published in AISTATS, Entropy and JMLR, the PIs are able to provide sufficient conditions for the algorithmic convergence and optimal statistical properties of the converges solutions. The PIs expect that these theoretical results will popularize the algorithms even more among machine learners and statisticians.  \n\n \n\n4 PhD students advised / co-advised  by PI Pati and co-PI Bhattacharya worked on the above projects as a part of their PhD dissertation.  Two of them (including one female) obtained tenure-track Assistant professor positions and the remaining two are working pharmaceutical sectors upon completion of their PhD.  The softwares obtained from the  research are now available at the PIs github page: https://github.com/debdeeptamu.  During Fall 2019, the PIs offered a special topic course on analyzing convergence of variational methods which attracted a significant percentage of the graduate students at the department of Statistics at Texas A&amp;M.   Many of them gained expertise to provide theoretical guarantees for their own disseration problems. The PIs also co-organized a session on variational methods in the annual Data-Science conference at Texas A&amp;M on Oct 21-22, 2023 where world leaders working in this area are invited. The graduate students and postdocs at Texas A&amp;M University and beyond are hugely benefited from the interaction and they also got a chance to showcase their research through poster presentation.  \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 11/28/2022\n\n\t\t\t\t\tSubmitted by: Debdeep Pati"
 }
}