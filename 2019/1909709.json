{
 "awd_id": "1909709",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Increasing the Spectral Resolution of Broadband Astronomical Imaging",
 "cfda_num": "47.049",
 "org_code": "03020000",
 "po_phone": "7032924905",
 "po_email": "nsharp@nsf.gov",
 "po_sign_block_name": "Nigel Sharp",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 313593.0,
 "awd_amount": 313593.0,
 "awd_min_amd_letter_date": "2019-07-30",
 "awd_max_amd_letter_date": "2019-07-30",
 "awd_abstract_narration": "The latest-generation telescopes and instruments are opening a new window on the variable and transient universe.  Forthcoming time-domain surveys will collect thousands of observational epochs for most of the night sky.  But these data provide opportunities beyond the study of time series, and this project will work towards realizing the promise of higher resolution shape measurement and improving the inference of galaxy properties.  Preliminary work has already shown the promise of future success.  Students in applied mathematics, computer science and astronomy will join forces to tackle the challenges of real data and subtle effects.  Multi-epoch image and video analysis is arguably the fastest growing topic in data science today.  The images and methods created in this study are ideal for inspiring and training students.  The derived visual representations are also an efficient vehicle for public outreach.\r\n\r\nThe science beyond the transient and variable cosmos comes firstly by oversampling in overlapping, repeated exposures, which can produce higher spatial resolution and shape measurements, thus improving weak lensing, cosmology and galaxy morphology studies.  Less obviously, introducing multiple effective sub-bands within a broad passband will significantly improve the inference of galaxy properties and the estimation of photometric redshifts.  This study will work towards the new methods needed to realize these opportunities, by (1) evaluating the limitations of these ideas in real situations, including photometric redshift estimation for the Large Synoptic Survey Telescope (LSST); (2) developing optimal, efficient methods for reconstruction; and (3) implementing production-quality code to make super-resolution hyper-color images from multi-epoch astronomical observations.  The approach of building on robust statistics has already been successful in a monochrome setting, but multi-color will need detailed modeling of differential chromatic refraction (DCR) in the atmosphere.  This will require a new method to leverage the color-dependent subtle shifts in source directions due to DCR.  Part of the created educational material will be publicly available Jupyter notebooks in Python.  Colorful renderings of scientific data will be developed as live Jupyter notebooks and made available on the SciServer for all to view and to modify, using just a browser.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "AST",
 "org_div_long_name": "Division Of Astronomical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tamas",
   "pi_last_name": "Budavari",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tamas Budavari",
   "pi_email_addr": "budavari@jhu.edu",
   "nsf_id": "000234436",
   "pi_start_date": "2019-07-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "3400 N. Charles St",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182608",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "121700",
   "pgm_ele_name": "EXTRAGALACTIC ASTRON & COSMOLO"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1206",
   "pgm_ref_txt": "THEORETICAL & COMPUTATIONAL ASTROPHYSICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 313593.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Ground-based observations of the night sky are inherently noisy because most celestial objects appear very faint. While longer exposure times can improve the signal-to-noise ratio, they also result in blurrier images due to atmospheric variations that wash out intricate details. This project explored mathematical and computational approaches to overcome these limitations, ultimately enabling clearer and deeper views of the sky than previously possible.</p>\r\n<p>The key idea is to combine multiple shorter exposures, each capturing the same region of the sky but providing different constraints on the objects' brightness, shapes, and colors. Previous methods, such as lucky imaging which considers only the sharpest exposures, or traditional image co-addition which further blurs exposures to have matching point-spread functions (PSF), ultimately lose information. The goal of this proposed effort was to develop analytic tools that make best use of all exposures from ongoing and forthcoming astronomy surveys, such as the Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST).</p>\r\n<p>To do this successfully, the intricacies of astronomy observations must be captured accurately. For instance, the same sky region observed at different times will be seen from different angles due to the Earth's rotation. This variation, caused by the atmospheric prism effect, results in objects of different colors appearing in slightly different directions. While this might initially seem problematic, it actually offers additional information, allowing us to infer the colors of objects even within a single photometric passband.</p>\r\n<p>The team developed a mathematical model of the night sky where each pixel represents an unknown variable. This latent image can achieve higher resolution than the original observations by inferring a matching super-resolution point-spread function.&nbsp;Building on the majorization-minimization algorithm, the new ImageMM solver can avoid the pitfalls of common greedy optimizers often used in deep learning and provide robust results in the presence of observational artifacts, such as satellite trails or cosmic rays. The resulting software application uses TensorFlow to derive high-dimensional solutions on Graphical Processing Units (GPUs) at speeds and scales that is relevant and practical for large surveys. The figure shows a comparison of images created by the current state of the art on the left and the ImageMM solution on the right. The latter is visibly sharper and less noisy.</p>\r\n<p>Beyond the original goals, the team also explored an AI-based approach. In a pilot study, a neural network called BlurNet was created to learn how to synthesize a latent image from input exposures such that it can reproduce all exposures when convolved with the corresponding PSFs. The main conceptual difference is that BlurNet learns to perform how to best combine the exposures, whereas ImageMM directly learns the image itself. The initial tests are not on par with the superior quality of ImageMM but seem very promising. The BlurNet approach has certain advantages, including the potential to provide variance estimates and to simultaneously learn the PSFs.</p>\r\n<p>The potential benefits to the scientific community are substantial. The techniques developed in this project can be applied to various areas of astronomy, such as the study of exoplanets, star formation, and galaxy evolution. Enhancing the resolution and clarity of images can lead to better photometry and shape measurements, which can also help weak lensing signals and hence contribute to cosmological studies, or improve detection and analysis of transient events, such as supernovae. Additionally, detecting fainter sources allows access to more distant objects, expanding the observable volume of the Universe.</p>\r\n<p>An overarching theme of the project was use of advanced statistical and machine learning methods in astronomy, and the project team was interdisciplinary, including astronomers, mathematicians, and computer scientists. The project supported a PhD student in applied mathematics and statistics who continued after graduation as a postdoc, and three undergraduate students in math and computer science. The team engaged in training young astronomers in modern statistics and machine learning methods, including lectures at summer schools at Penn State University and presenting results at the Statistical Challenges in Modern Astronomy conferences, annual meetings of the American Astronomical Society and Astronomical Data Analysis Software &amp; Systems.</p>\r\n<p>The broader implications of this project extend beyond astronomy. The mathematical and computational techniques developed here can be adapted to other fields that rely on high-resolution imaging. For example, medical imaging, such as MRI and CT scans, could benefit from improved imaging algorithms, leading to better diagnostic capabilities. Similarly, remote sensing applications, including environmental monitoring and surveillance, could achieve more accurate and detailed observations. The interdisciplinary nature of this research highlights the potential for cross-pollination of ideas and methods, fostering innovation across various scientific and engineering domains.</p><br>\n<p>\n Last Modified: 11/30/2024<br>\nModified by: Tamas&nbsp;Budavari</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1909709/1909709_10627611_1732985236041_Figure4--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1909709/1909709_10627611_1732985236041_Figure4--rgov-800width.png\" title=\"Spiral galaxy before and after\"><img src=\"/por/images/Reports/POR/2024/1909709/1909709_10627611_1732985236041_Figure4--rgov-66x44.png\" alt=\"Spiral galaxy before and after\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Solutions derived from 33 exposures by the Hyper Suprime-Cam on the Subaru Telescope. The project's ImageMM solution on the right is visibly sharper and less noisy than the current state of the art on the left.</div>\n<div class=\"imageCredit\">Tamas Budavari, Yashil Sukurdeep</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Tamas&nbsp;Budavari\n<div class=\"imageTitle\">Spiral galaxy before and after</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nGround-based observations of the night sky are inherently noisy because most celestial objects appear very faint. While longer exposure times can improve the signal-to-noise ratio, they also result in blurrier images due to atmospheric variations that wash out intricate details. This project explored mathematical and computational approaches to overcome these limitations, ultimately enabling clearer and deeper views of the sky than previously possible.\r\n\n\nThe key idea is to combine multiple shorter exposures, each capturing the same region of the sky but providing different constraints on the objects' brightness, shapes, and colors. Previous methods, such as lucky imaging which considers only the sharpest exposures, or traditional image co-addition which further blurs exposures to have matching point-spread functions (PSF), ultimately lose information. The goal of this proposed effort was to develop analytic tools that make best use of all exposures from ongoing and forthcoming astronomy surveys, such as the Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST).\r\n\n\nTo do this successfully, the intricacies of astronomy observations must be captured accurately. For instance, the same sky region observed at different times will be seen from different angles due to the Earth's rotation. This variation, caused by the atmospheric prism effect, results in objects of different colors appearing in slightly different directions. While this might initially seem problematic, it actually offers additional information, allowing us to infer the colors of objects even within a single photometric passband.\r\n\n\nThe team developed a mathematical model of the night sky where each pixel represents an unknown variable. This latent image can achieve higher resolution than the original observations by inferring a matching super-resolution point-spread function.Building on the majorization-minimization algorithm, the new ImageMM solver can avoid the pitfalls of common greedy optimizers often used in deep learning and provide robust results in the presence of observational artifacts, such as satellite trails or cosmic rays. The resulting software application uses TensorFlow to derive high-dimensional solutions on Graphical Processing Units (GPUs) at speeds and scales that is relevant and practical for large surveys. The figure shows a comparison of images created by the current state of the art on the left and the ImageMM solution on the right. The latter is visibly sharper and less noisy.\r\n\n\nBeyond the original goals, the team also explored an AI-based approach. In a pilot study, a neural network called BlurNet was created to learn how to synthesize a latent image from input exposures such that it can reproduce all exposures when convolved with the corresponding PSFs. The main conceptual difference is that BlurNet learns to perform how to best combine the exposures, whereas ImageMM directly learns the image itself. The initial tests are not on par with the superior quality of ImageMM but seem very promising. The BlurNet approach has certain advantages, including the potential to provide variance estimates and to simultaneously learn the PSFs.\r\n\n\nThe potential benefits to the scientific community are substantial. The techniques developed in this project can be applied to various areas of astronomy, such as the study of exoplanets, star formation, and galaxy evolution. Enhancing the resolution and clarity of images can lead to better photometry and shape measurements, which can also help weak lensing signals and hence contribute to cosmological studies, or improve detection and analysis of transient events, such as supernovae. Additionally, detecting fainter sources allows access to more distant objects, expanding the observable volume of the Universe.\r\n\n\nAn overarching theme of the project was use of advanced statistical and machine learning methods in astronomy, and the project team was interdisciplinary, including astronomers, mathematicians, and computer scientists. The project supported a PhD student in applied mathematics and statistics who continued after graduation as a postdoc, and three undergraduate students in math and computer science. The team engaged in training young astronomers in modern statistics and machine learning methods, including lectures at summer schools at Penn State University and presenting results at the Statistical Challenges in Modern Astronomy conferences, annual meetings of the American Astronomical Society and Astronomical Data Analysis Software & Systems.\r\n\n\nThe broader implications of this project extend beyond astronomy. The mathematical and computational techniques developed here can be adapted to other fields that rely on high-resolution imaging. For example, medical imaging, such as MRI and CT scans, could benefit from improved imaging algorithms, leading to better diagnostic capabilities. Similarly, remote sensing applications, including environmental monitoring and surveillance, could achieve more accurate and detailed observations. The interdisciplinary nature of this research highlights the potential for cross-pollination of ideas and methods, fostering innovation across various scientific and engineering domains.\t\t\t\t\tLast Modified: 11/30/2024\n\n\t\t\t\t\tSubmitted by: TamasBudavari\n"
 }
}