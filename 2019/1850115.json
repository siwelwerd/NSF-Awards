{
 "awd_id": "1850115",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: CHS: Modeling Analysis Behavior to Support Interactive Exploration of Massive Datasets",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Balakrishnan Prabhakaran",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2019-02-08",
 "awd_max_amd_letter_date": "2019-02-08",
 "awd_abstract_narration": "Scientists commonly use exploratory data analysis methods to gain insights from their data.  However, increases in the number and granularity of data sources raise problems of scale that complicate the already difficult problem of developing tools that help analysts manage the often-changing goals and analysis trajectories suggested by their exploratory work.  This project focuses on improving two key systems in exploratory data analysis tools: the visualization systems that provide graphical representations of the data, and the data management systems that efficiently manage large-scale data on the back end to support the analysis.  The key idea is to integrate these two systems by first inferring analysts' goals and future behaviors from their recent actions in the visualization system, then using those to proactively construct efficient processing queries in the data management system.  Doing this should improve system response times, which should in turn improve analysts' ability to use the system and the insights they gain; the techniques developed will contribute to the database, visualization, and human-computer interaction communities.  The tools themselves stand to benefit a number of scientific and industrial domains, and the team will also use the project work to support new interdisciplinary data science courses along with outreach and research opportunities for underrepresented students in computer science.\r\n\r\nTo improve performance, this project will produce dynamic optimization strategies for visual exploration systems, which infer the user's exploratory analysis goals over time, and deploy optimization algorithms tailored to the current analysis goal.  These optimizations will address both human performance, i.e., how effectively a scientist or analyst extracts insights and performs analysis tasks with a visual exploration system, and system performance, i.e., how efficiently and effectively the system responds to a user's interactions. The development of these optimizations will be done in two phases. First, a user study will be conducted to characterize how users interact with visual exploration systems under different exploratory data analysis scenarios and system designs. Second, using the collected study data, a predictive query execution engine will be designed to infer users' analysis goals from log data and detect shifts in behaviors over time. To boost data management system performance, existing techniques will be adapted to leverage the predictive query execution engine, including query scheduling of likely upcoming queries and multi-query optimization to leverage computational overlap between recent and predicted queries. To boost visualization system and human performance, the system will recommend predicted next queries to analysts, while the project team will conduct performance-driven interface design work to design new interactions based on data collected by the predictive query execution engine.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Leilani",
   "pi_last_name": "Battle",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Leilani Battle",
   "pi_email_addr": "leibatt@cs.washington.edu",
   "nsf_id": "000776356",
   "pi_start_date": "2019-02-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "3112 Lee Bldg 7809 Regents Drive",
  "perf_city_name": "CollegePark",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425141",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Whether they are governments, companies, or non-profits, all organizations today collect data, with the goal of using this data to make decisions. These organizations often hire analysts to help them process and make sense of this data. A common approach to analyzing data is to explore it through visualizations, where visualizations are intuitive image representations of data, such as a line chart showing daily price fluctuations in the stock market, or a geographic map showing where people moved during the COVID-19 pandemic. To enable a wide range of analysts to explore their data, computer scientists design new tools to make it easier and faster to create, analyze, and interact with visualizations. However, when the data is very large, these exploration tools can take a prohibitively long time to process the data and render the desired visualizations, hindering analysts' ability to do their jobs. Furthermore, computer scientists may inadvertently design tools that may bias the conclusions analysts draw from their data, which can lead to biased decisions that impact millions and even billions of people, such as who is protected from COVID-19 or how climate change is addressed.</p>\n<p>The focus of this project was two-fold. First, we aimed to study how the design of data exploration tools can lead to biased data analysis outcomes, especially when the data being explored is very large. Second, we aimed to develop new techniques to mitigate or ideally prevent biased exploration outcomes through the design of new data exploration tools.</p>\n<p>To address the first research aim, we conducted a series of human subjects experiments, where we asked analysts to explore data using a variety of interface designs, inspired by commercial tools such as Tableau Desktop, as well as academic tools such as ForeCache (developed at MIT), Voyager (developed at the University of Washington), and Falcon (developed at the University of Washington). We recorded each analyst's interactions with each tool, and in some cases made the interfaces faster or slower, to mimic realistic scenarios where an interface might slow down when processing a lot of data. Our findings show that current tools have some weaknesses in their designs that can result in biased analysis outcomes for analysts. For example, one of our studies finds that if certain interactions appear to slow the interface down, analysts will avoid interacting in that way with the tool. Furthermore, as this slowdown gets worse, analysts' try harder to avoid it. If analysts base their exploration on avoiding annoying interface lag rather than what they see in the data, then they may be missing key information.</p>\n<p>To address the second aim, we designed some new systems to prevent the issues we observed through our studies. One example is the Kyrix system developed in collaboration with MIT. Kyrix enables analysts to explore large datasets using fast panning and zooming interactions. Kyrix is optimized to reduce potential slowdown as users pan and zoom, mitigating the biased exploration outcomes observed in the aforementioned study. We also have ongoing projects to improve the design of existing exploration tools using similar optimization strategies.</p>\n<p>This project also helped to broaden participation in computing. 57% of the student researchers on the project were women and 93% were BIPOC students (Black, Indigenous, People Of Color).</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/16/2021<br>\n\t\t\t\t\tModified by: Leilani&nbsp;Battle</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1850115/1850115_10591379_1637114851423_search-study-optimized--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1850115/1850115_10591379_1637114851423_search-study-optimized--rgov-800width.jpg\" title=\"System Latency Study Example\"><img src=\"/por/images/Reports/POR/2021/1850115/1850115_10591379_1637114851423_search-study-optimized--rgov-66x44.jpg\" alt=\"System Latency Study Example\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">We conducted a study to measure how slow or laggy interfaces affect the way people explore visualizations. Study participants explored a collage of bird images. We inserted a delay in when bird images appeared on screen, and observed how participants' exploration of the collage changed in response.</div>\n<div class=\"imageCredit\">Leilani Battle</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Leilani&nbsp;Battle</div>\n<div class=\"imageTitle\">System Latency Study Example</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nWhether they are governments, companies, or non-profits, all organizations today collect data, with the goal of using this data to make decisions. These organizations often hire analysts to help them process and make sense of this data. A common approach to analyzing data is to explore it through visualizations, where visualizations are intuitive image representations of data, such as a line chart showing daily price fluctuations in the stock market, or a geographic map showing where people moved during the COVID-19 pandemic. To enable a wide range of analysts to explore their data, computer scientists design new tools to make it easier and faster to create, analyze, and interact with visualizations. However, when the data is very large, these exploration tools can take a prohibitively long time to process the data and render the desired visualizations, hindering analysts' ability to do their jobs. Furthermore, computer scientists may inadvertently design tools that may bias the conclusions analysts draw from their data, which can lead to biased decisions that impact millions and even billions of people, such as who is protected from COVID-19 or how climate change is addressed.\n\nThe focus of this project was two-fold. First, we aimed to study how the design of data exploration tools can lead to biased data analysis outcomes, especially when the data being explored is very large. Second, we aimed to develop new techniques to mitigate or ideally prevent biased exploration outcomes through the design of new data exploration tools.\n\nTo address the first research aim, we conducted a series of human subjects experiments, where we asked analysts to explore data using a variety of interface designs, inspired by commercial tools such as Tableau Desktop, as well as academic tools such as ForeCache (developed at MIT), Voyager (developed at the University of Washington), and Falcon (developed at the University of Washington). We recorded each analyst's interactions with each tool, and in some cases made the interfaces faster or slower, to mimic realistic scenarios where an interface might slow down when processing a lot of data. Our findings show that current tools have some weaknesses in their designs that can result in biased analysis outcomes for analysts. For example, one of our studies finds that if certain interactions appear to slow the interface down, analysts will avoid interacting in that way with the tool. Furthermore, as this slowdown gets worse, analysts' try harder to avoid it. If analysts base their exploration on avoiding annoying interface lag rather than what they see in the data, then they may be missing key information.\n\nTo address the second aim, we designed some new systems to prevent the issues we observed through our studies. One example is the Kyrix system developed in collaboration with MIT. Kyrix enables analysts to explore large datasets using fast panning and zooming interactions. Kyrix is optimized to reduce potential slowdown as users pan and zoom, mitigating the biased exploration outcomes observed in the aforementioned study. We also have ongoing projects to improve the design of existing exploration tools using similar optimization strategies.\n\nThis project also helped to broaden participation in computing. 57% of the student researchers on the project were women and 93% were BIPOC students (Black, Indigenous, People Of Color).\n\n \n\n\t\t\t\t\tLast Modified: 11/16/2021\n\n\t\t\t\t\tSubmitted by: Leilani Battle"
 }
}