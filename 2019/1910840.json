{
 "awd_id": "1910840",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Leveraging Coding Techniques for Distributed Computing",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 492271.0,
 "awd_amount": 492271.0,
 "awd_min_amd_letter_date": "2019-06-13",
 "awd_max_amd_letter_date": "2019-06-13",
 "awd_abstract_narration": "Clusters of computer processors that process huge amounts of data at specialized locations called data centers are ubiquitous in both industry and academia. The usage of distributed clusters is a necessity rather than a luxury since many modern datasets are too large to be stored in the memory or disk of a single computer.  However, using such clusters to obtain answers quickly and efficiently presents many new challenges. These include dealing with issues such as slow or failed processors (ie., worker nodes) and taking into account the time for these worker nodes to communicate among themselves for collaboratively executing a job. Such issues are critical, as it is well-recognized that for such large scale systems, worker node failures are the norm rather than the exception. The project will investigate classes of methods for the robust and efficient operation of large-scale distributed computing clusters. Furthermore, the project will train graduate and undergraduate students in data analytics and in using industry standard techniques for working with these clusters.\r\n\r\nThe overarching goal of this project is to leverage coding-theoretic ideas to make distributed computation robust to stragglers (slow or failed worker nodes) and reduce the communication overhead of distributed computing paradigms such as MapReduce and Spark. While there has been some recent work on the topic of straggler mitigation for distributed matrix computations, the majority of prior work proceeds by treating stragglers exclusively as node failures. This project will investigate rigorous techniques for leveraging slow (but not failed) stragglers. In particular, the sequential nature of computation within a worker node will be taken into account when designing codes for our systems. The second part of the project will deal with issues around the numerical stability of recovery within distributed matrix computation. Several well-known erasure codes that have been proposed for this problem perform rather poorly on this metric. The project will design classes of codes that are useful in straggler mitigation and analyze them through the lens of numerical stability. The last part of the project will address the reduction of shuffle phase traffic in MapReduce-like systems that are used for executing jobs over distributed clusters. Prior work in this area proposes techniques that are information-theoretically optimal (under an appropriate model). A major assumption of prior work is that jobs can be split into arbitrarily small parts. However, in practical systems, this assumption severely limits the actual gain in the overall job execution time. This project will study a large class of techniques that reduce shuffle phase traffic and the overall job execution time by leveraging the properties of suitably defined linear block codes.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aditya",
   "pi_last_name": "Ramamoorthy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aditya Ramamoorthy",
   "pi_email_addr": "adityar@iastate.edu",
   "nsf_id": "000305890",
   "pi_start_date": "2019-06-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Iowa State University",
  "inst_street_address": "1350 BEARDSHEAR HALL",
  "inst_street_address_2": "515 MORRILL ROAD",
  "inst_city_name": "AMES",
  "inst_state_code": "IA",
  "inst_state_name": "Iowa",
  "inst_phone_num": "5152945225",
  "inst_zip_code": "500112103",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IA04",
  "org_lgl_bus_name": "IOWA STATE UNIVERSITY OF SCIENCE AND TECHNOLOGY",
  "org_prnt_uei_num": "DQDBM7FGJPC5",
  "org_uei_num": "DQDBM7FGJPC5"
 },
 "perf_inst": {
  "perf_inst_name": "Iowa State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IA",
  "perf_st_name": "Iowa",
  "perf_zip_code": "500112207",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "IA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 492271.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The overarching goals of this project were to research techniques for mitigating the effect of stragglers (slow or failed nodes) in cloud computing clusters when performing distributed computations.</p>\r\n<p>Within this broad area our first goal focused on specific techniques for distributed matrix computations. Large scale matrix computations are routinely required in machine learning and scientific computing. Prior to our work, techniques in this area would treat stragglers as failed workers. Our work was among the first to design and analyze techniques that leverage partial work performed by slow (but not failed) workers. Furthermore, our work provided provably numerically stable algorithms. Many of the matrices in industrial and academic use cases tend to be sparse. We developed customized techniques for the case of sparse input matrices and showed the superior performance of our methods.</p>\r\n<p>The second major goal addressed by our work was to present efficient techniques for improving the efficiency of MapReduce-like distributed computing systems. MapReduce is a basic framework for general distributed computation. It consists of an initial compute (Map) phase where workers perform computations. Following this the distributed workers exchange messages over a network in the so-called Shuffle phase. Finally, the workers complete their computations in the Reduce phase. Our core contribution was to develop techniques that reduced the induced network load in the Shuffle phase. Our work demonstrated that for well-known benchmarks such as TeraSort, our algorithms required much lower job execution time.</p>\r\n<p>This project helped support (in part) the graduate education of five Ph. D. students, who have gone on to successful careers in industry and academia. One of the students won a university-level award for the most outstanding dissertation in the areas of mathematical and physical sciences. Open-source code for all our proposed algorithms was made available. This allowed for easy adoption and reproducibility within the broader research community.</p><br>\n<p>\n Last Modified: 02/06/2025<br>\nModified by: Aditya&nbsp;Ramamoorthy</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe overarching goals of this project were to research techniques for mitigating the effect of stragglers (slow or failed nodes) in cloud computing clusters when performing distributed computations.\r\n\n\nWithin this broad area our first goal focused on specific techniques for distributed matrix computations. Large scale matrix computations are routinely required in machine learning and scientific computing. Prior to our work, techniques in this area would treat stragglers as failed workers. Our work was among the first to design and analyze techniques that leverage partial work performed by slow (but not failed) workers. Furthermore, our work provided provably numerically stable algorithms. Many of the matrices in industrial and academic use cases tend to be sparse. We developed customized techniques for the case of sparse input matrices and showed the superior performance of our methods.\r\n\n\nThe second major goal addressed by our work was to present efficient techniques for improving the efficiency of MapReduce-like distributed computing systems. MapReduce is a basic framework for general distributed computation. It consists of an initial compute (Map) phase where workers perform computations. Following this the distributed workers exchange messages over a network in the so-called Shuffle phase. Finally, the workers complete their computations in the Reduce phase. Our core contribution was to develop techniques that reduced the induced network load in the Shuffle phase. Our work demonstrated that for well-known benchmarks such as TeraSort, our algorithms required much lower job execution time.\r\n\n\nThis project helped support (in part) the graduate education of five Ph. D. students, who have gone on to successful careers in industry and academia. One of the students won a university-level award for the most outstanding dissertation in the areas of mathematical and physical sciences. Open-source code for all our proposed algorithms was made available. This allowed for easy adoption and reproducibility within the broader research community.\t\t\t\t\tLast Modified: 02/06/2025\n\n\t\t\t\t\tSubmitted by: AdityaRamamoorthy\n"
 }
}