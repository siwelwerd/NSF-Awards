{
 "awd_id": "1856641",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Large: Collaborative Research: Analysis Engineering for Robust End-to-End Data Science",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 712500.0,
 "awd_amount": 728500.0,
 "awd_min_amd_letter_date": "2019-09-07",
 "awd_max_amd_letter_date": "2020-07-16",
 "awd_abstract_narration": "From poor statistical practices leading to retractions of scientific \"discoveries\" to low-level spreadsheet errors subverting high-stakes analyses, failures of data analysis can have catastrophic consequences. The rapid growth of data science practice in the last decade has led to large collaborative efforts to develop new data processing, machine learning, and analytics tools that put more advanced data analysis into the hands of a wider audience of practitioners, from students to scientists to designers. The most dominant tool for data science is code, where cutting-edge algorithms can be applied from an existing libraries. However, as this democratization of data science has lowered the barrier to using advanced methods, safely using these tools under sound statistical practice remains as difficult as ever. To facilitate more robust data science, this project investigates models and tools for analysis engineering by data scientists who write programs. The focus is on the complete end-to-end process of data analysis performed with code: the iterative, and often exploratory, steps that analysts go through to turn data into This project will contribute insights and characterizations of analytic work, novel methods for capturing and analyzing data science activities, and develop new programming tools and visualization methods for authoring and validating analyses. If successful, this project will augment people's ability to conduct and assess data analyses, promoting more robust results and reducing the gap between novice and expert analysts. The findings and tools from the project will be incorporated into educational efforts, including classroom teaching and tutorials and available as open source software integrated into popular analytical environments (e.g., Jupyter).\r\n\r\nData analysis is a central activity to scientific research, yet is too often conducted in an undisciplined fashion. This project treats the entire analytic process as our central phenomenon of study. The project will employ mixed methods to study and characterize common analysis practices and pitfalls, including direct observations of data analysts, large-scale analysis of computational notebooks, and instrumentation of analytic programming environments like JupyterLab. The project will contribute new methods for specifying and safeguarding analyses, including domain-specific languages and program synthesis methods to guide users to preferred next steps. It will also explore \"multiverse\" workflows to manage and assess a diversity of analysis decisions. Analogues of debugging and testing tools will be developed to flag problems and perform error analysis, while the capture and visualization of analytic provenance to aid reproducibility, verification, and collaborative review. The work will be evaluated through controlled studies, classroom use, and open-source deployment for wide-scale field use.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Brad",
   "pi_last_name": "Myers",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Brad A Myers",
   "pi_email_addr": "bam@cs.cmu.edu",
   "nsf_id": "000360868",
   "pi_start_date": "2019-09-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie Mellon University",
  "perf_str_addr": "5000 Forbes Ave",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "077Z",
   "pgm_ref_txt": "CSSI-1: Cyberinfr for Sustained Scientif"
  },
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 650000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 78500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-e7a72ab8-7fff-6e53-13c7-05bfdc8fc8f3\"> </span></p>\n<p dir=\"ltr\"><span>This was a large, collaborative project, between the University of Washington, MIT and CMU. Overall, the project worked on </span><span>facilitating more robust data science. We investigated models and tools for analysis engineering by data scientists who write programs. Our focus has not been limited to statistical modeling or machine learning, but rather the complete end-to-end process of data analysis performed with code: the iterative, and often exploratory, steps that analysts go through to turn data into results. We contribute insights and characterizations of analytic work, novel methods for capturing and analyzing data science activities, and new programming tools and visualization methods for authoring and validating analyses. Our major activities included studying the process of data analysis to identify best practices and develop new computational methods for characterizing analysis workflows; developing new methods and tools for more robust statistical analysis, with a focus on multiverse analysis; developing new methods and tools for assessing machine learning models and processes; and spporting in-situ assessment and organization of analytic usage histories within computational notebooks.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>The CMU portion of this project included the Verdant tool that supports the way that Data scientists want to work. Data scientists experiment with many different analyses and model decisions along the way towards a successful result. However, data workers have limited and ad-hoc tools for keeping track of their history of experimentation. We call this process &ldquo;exploratory programming&rdquo;, which we characterize as when the programmer writes code as a medium to prototype or experiment with different ideas, and the programmer is not just attempting to engineer working code to match a specification, but rather the goal is open-ended, and evolves through the process of programming.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>We performed formative studies detailing the mix of tools and ad-hoc methods data workers use to manage their experiments, and how data workers use computational notebooks for iteration. Our results pointed to two key barriers: the manual effort needed to collect experiment history today is unsustainable, and recovering semantic process information out of a pile of history logs is far too cumbersome for practitioners to fit into their workflows today.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>We then designed, built, and tested new interactive tools to meet these design goals, over a 5 year iterative human-centered design process. This culminated in a tool, called Verdant, that supports the kinds of exploratory programming common to data scientists and addresses those barriers. Verdant is a plugin for computational notebooks in which we took a human-centered design approach to building new interactions for data experiment history. It provides a set of novel visualization and interaction techniques for concisely summarizing history.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>We designed and implemented Verdant so it can be widely used, and released it as open source. It has been downloaded by around 2000 people in the wild. We also performed an elaborate 2-stage user study of Verdant, which showed that participants were able to answer 98% of history questions about their own work in only 1 minute, 26 seconds on average. The Verdant software was also released open source, and has been downloaded over 2000 times.</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/29/2024<br>\nModified by: Brad&nbsp;A&nbsp;Myers</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237396868_image_4_search_pane--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237396868_image_4_search_pane--rgov-800width.jpg\" title=\"Search view: The search icon is selected, which brings up a pane on the left, with the searched-for text at the top, here \ufffdgarage\ufffd at (A). Below that are the elements by category and the number of matches in each, like \ufffdcode artifacts\ufffd (5 matches), markdown (0), outputs by version, etc.\"><img src=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237396868_image_4_search_pane--rgov-66x44.jpg\" alt=\"Search view: The search icon is selected, which brings up a pane on the left, with the searched-for text at the top, here \ufffdgarage\ufffd at (A). Below that are the elements by category and the number of matches in each, like \ufffdcode artifacts\ufffd (5 matches), markdown (0), outputs by version, etc.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">In (A) and (B) the user can search the history using keywords and filters. To reduce excessive scrolling, we clustered the search into accordion bins by artifact type (C). In (D) we include links with clear names so that the user can open up the Artifact Detail View or Ghost Notebook.</div>\n<div class=\"imageCredit\">Mary Beth Kery</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Brad&nbsp;A&nbsp;Myers\n<div class=\"imageTitle\">Search view: The search icon is selected, which brings up a pane on the left, with the searched-for text at the top, here \ufffdgarage\ufffd at (A). Below that are the elements by category and the number of matches in each, like \ufffdcode artifacts\ufffd (5 matches), markdown (0), outputs by version, etc.</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237196003_image_3_Verdant_artifacts_panes_v2.--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237196003_image_3_Verdant_artifacts_panes_v2.--rgov-800width.jpg\" title=\"The Artifacts pane on the left contains rows for element, with the number of versions in which that element appeared. Clicking on an element expands it in-place to show the lines of code or output associated with that element for each version.\"><img src=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237196003_image_3_Verdant_artifacts_panes_v2.--rgov-66x44.jpg\" alt=\"The Artifacts pane on the left contains rows for element, with the number of versions in which that element appeared. Clicking on an element expands it in-place to show the lines of code or output associated with that element for each version.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The Verdant artifacts pane (B) previews history per cell for a more location-based overview. The details view (D) shows the full versions and output of any artifact in the notebook, which can be selected from the active notebook through the inspector interaction (C).</div>\n<div class=\"imageCredit\">Mary Beth Kery</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Brad&nbsp;A&nbsp;Myers\n<div class=\"imageTitle\">The Artifacts pane on the left contains rows for element, with the number of versions in which that element appeared. Clicking on an element expands it in-place to show the lines of code or output associated with that element for each version.</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237061563_image_1___Variolite--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237061563_image_1___Variolite--rgov-800width.jpg\" title=\"Screenshot of code editing window showing some Python code. Horizontal lines separate the different variant boxes, which contain different versions of the algorithm. The search and output panes are on the right side of the screen\"><img src=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237061563_image_1___Variolite--rgov-66x44.jpg\" alt=\"Screenshot of code editing window showing some Python code. Horizontal lines separate the different variant boxes, which contain different versions of the algorithm. The search and output panes are on the right side of the screen\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">First tool investigated the idea of \ufffdvariants\ufffd for the code. (a) the top level variant box wraps the entire file and also acts as the tool menu. (b and c) different variant boxes, one nested within the other. (d) a search bar. (e) the output pane and (f) an output and its commit with a custom tag</div>\n<div class=\"imageCredit\">Mary Beth Kery</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Brad&nbsp;A&nbsp;Myers\n<div class=\"imageTitle\">Screenshot of code editing window showing some Python code. Horizontal lines separate the different variant boxes, which contain different versions of the algorithm. The search and output panes are on the right side of the screen</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237809009_image_5_user_study_feature_usage_by_time--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237809009_image_5_user_study_feature_usage_by_time--rgov-800width.jpg\" title=\"User Study Participant Activities: There are 11 rows, one for each participant. Each row contains rectangles to indicate what the participant was doing during that time interval, such as Tables and Summary Stats, Visualization, Data Cleaning, Feature creation, Modeling, and Storytelling\"><img src=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730237809009_image_5_user_study_feature_usage_by_time--rgov-66x44.jpg\" alt=\"User Study Participant Activities: There are 11 rows, one for each participant. Each row contains rectangles to indicate what the participant was doing during that time interval, such as Tables and Summary Stats, Visualization, Data Cleaning, Feature creation, Modeling, and Storytelling\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Results of preliminary user study of Verdant showing activity over time during the user study. There were 11 participants all with at least 1 year of experience with data science and Jupyter notebooks. Blocks show the type of activity each participant engaged in over that period of time.</div>\n<div class=\"imageCredit\">Mary Beth Kery</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Brad&nbsp;A&nbsp;Myers\n<div class=\"imageTitle\">User Study Participant Activities: There are 11 rows, one for each participant. Each row contains rectangles to indicate what the participant was doing during that time interval, such as Tables and Summary Stats, Visualization, Data Cleaning, Feature creation, Modeling, and Storytelling</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730236974042_image_2_verdant_activity--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730236974042_image_2_verdant_activity--rgov-800width.jpg\" title=\"Verdant windows: The Activity pane is on the left. In it, rows start with a time, then the affected version followed by the minimap, which is a sequence of short vertical bars, each representing a cell. On the right are multiple panes, for the code and output for a version\"><img src=\"/por/images/Reports/POR/2024/1856641/1856641_10640559_1730236974042_image_2_verdant_activity--rgov-66x44.jpg\" alt=\"Verdant windows: The Activity pane is on the left. In it, rows start with a time, then the affected version followed by the minimap, which is a sequence of short vertical bars, each representing a cell. On the right are multiple panes, for the code and output for a version\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Verdant windows with the Activity pane shows rows for the versions with a minimap with a vertical bar for each a cell in the notebook, colored based on whether it was created (green), edited (blue), or deleted (red) in that version. Clicking on a version opens a ?Ghost Notebook? in a new code window</div>\n<div class=\"imageCredit\">Mary Beth Kery</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Brad&nbsp;A&nbsp;Myers\n<div class=\"imageTitle\">Verdant windows: The Activity pane is on the left. In it, rows start with a time, then the affected version followed by the minimap, which is a sequence of short vertical bars, each representing a cell. On the right are multiple panes, for the code and output for a version</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThis was a large, collaborative project, between the University of Washington, MIT and CMU. Overall, the project worked on facilitating more robust data science. We investigated models and tools for analysis engineering by data scientists who write programs. Our focus has not been limited to statistical modeling or machine learning, but rather the complete end-to-end process of data analysis performed with code: the iterative, and often exploratory, steps that analysts go through to turn data into results. We contribute insights and characterizations of analytic work, novel methods for capturing and analyzing data science activities, and new programming tools and visualization methods for authoring and validating analyses. Our major activities included studying the process of data analysis to identify best practices and develop new computational methods for characterizing analysis workflows; developing new methods and tools for more robust statistical analysis, with a focus on multiverse analysis; developing new methods and tools for assessing machine learning models and processes; and spporting in-situ assessment and organization of analytic usage histories within computational notebooks.\n\n\n\n\n\nThe CMU portion of this project included the Verdant tool that supports the way that Data scientists want to work. Data scientists experiment with many different analyses and model decisions along the way towards a successful result. However, data workers have limited and ad-hoc tools for keeping track of their history of experimentation. We call this process exploratory programming, which we characterize as when the programmer writes code as a medium to prototype or experiment with different ideas, and the programmer is not just attempting to engineer working code to match a specification, but rather the goal is open-ended, and evolves through the process of programming.\n\n\n\n\n\nWe performed formative studies detailing the mix of tools and ad-hoc methods data workers use to manage their experiments, and how data workers use computational notebooks for iteration. Our results pointed to two key barriers: the manual effort needed to collect experiment history today is unsustainable, and recovering semantic process information out of a pile of history logs is far too cumbersome for practitioners to fit into their workflows today.\n\n\n\n\n\nWe then designed, built, and tested new interactive tools to meet these design goals, over a 5 year iterative human-centered design process. This culminated in a tool, called Verdant, that supports the kinds of exploratory programming common to data scientists and addresses those barriers. Verdant is a plugin for computational notebooks in which we took a human-centered design approach to building new interactions for data experiment history. It provides a set of novel visualization and interaction techniques for concisely summarizing history.\n\n\n\n\n\nWe designed and implemented Verdant so it can be widely used, and released it as open source. It has been downloaded by around 2000 people in the wild. We also performed an elaborate 2-stage user study of Verdant, which showed that participants were able to answer 98% of history questions about their own work in only 1 minute, 26 seconds on average. The Verdant software was also released open source, and has been downloaded over 2000 times.\n\n\n\t\t\t\t\tLast Modified: 10/29/2024\n\n\t\t\t\t\tSubmitted by: BradAMyers\n"
 }
}