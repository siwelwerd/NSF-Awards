{
 "awd_id": "1909073",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: Software-Defined Imaging for Energy-Efficient Visual Computing",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 166000.0,
 "awd_amount": 166000.0,
 "awd_min_amd_letter_date": "2019-07-27",
 "awd_max_amd_letter_date": "2019-07-27",
 "awd_abstract_narration": "Image sensors are becoming ubiquitous in daily life as they are incorporated in future intelligent systems including autonomous navigation, health monitoring, and robotics. A central challenge in these camera-driven applications is the inflexibility of current sensor designs and their consequent energy cost. This project designs a new category of image sensors which exploit hardware -- software co-design to attain better sensing at lower cost. The project advances a vertically-integrated design from the mixed-signal sensor circuitry to the computational architecture and the operating system software support. The project's impacts are the creation of new, flexible image sensor systems that can be used for a variety of visual computing applications. The project further seeks to include broadening access to education and research through curriculum material which emphasize smart cameras of the future, outreach to middle and high school students in a summer program to discover imaging applications, and industry engagement through workshops on software-defined imaging. \r\n\r\nThe project focuses on designing software-defined image sensors, which offer new dimensions of configurability along with system support and programming abstractions to support application-specific needs. To achieve this, the project focuses on three main objectives: (1) Design and implementation of configurable sensor primitives, including programmable regions of interest with custom exposure, readout, and quantization, (2) architectures to control these sensor primitives, and to accelerate image signal processing and vision workloads, and (3) operating system services for scheduling the memory needs for our new sensor primitives, and OS interfaces that enable low-latency reactive sensor control for key applications. These innovations are evaluated in an integrative evaluation testbed that includes a fabricated software-defined image sensor prototype and a Field Programmable Gate Array (FPGA)-based system to measure energy and performance for a set of end-to-end visual applications.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Adrian",
   "pi_last_name": "Sampson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Adrian Sampson",
   "pi_email_addr": "asampson@cornell.edu",
   "nsf_id": "000719636",
   "pi_start_date": "2019-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "107 Hoy Road",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148537501",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 166000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The rapid growth in vision-based applications of computing, from smart-home appliances with embedded cameras to high-end augmented and virtual reality, all depend on combining optical sensing with efficient pixel processing. Traditionally, these two elements are designed separately: systems combine off-the-shelf cameras with generic image processing platforms. This project sought to harness new levels of efficiency in both camera sensing and visual computation by *combining* the design of both components. The key insight was that we can give vision algorithms and hardware control over the way they collect visual data. Specific applications can therefore eliminate unnecessary and redundant data collection while focusing on the subset of the data that they need.<br /><br />The project developed a series of new imaging hardware platforms and new algorithms to establish closed-loop control over camera sensors. It also produced new tools for designing the computational hardware that implements these vision and control algorithms. It demonstrated both that customizable sensors are feasible and competitive and that application-specific processing systems can be built to exploit them. Together, these tools will unlock the potential for software-defined imaging platforms that customize all aspects of a visual system for levels of efficiency that are not possible with today's fixed-function devices. The impacts of the project's work on productive hardware accelerator prototyping and design also extend beyond imaging and will make it easier to deliver other efficient, application-specific hardware accelerators.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/25/2023<br>\n\t\t\t\t\tModified by: Adrian&nbsp;Sampson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe rapid growth in vision-based applications of computing, from smart-home appliances with embedded cameras to high-end augmented and virtual reality, all depend on combining optical sensing with efficient pixel processing. Traditionally, these two elements are designed separately: systems combine off-the-shelf cameras with generic image processing platforms. This project sought to harness new levels of efficiency in both camera sensing and visual computation by *combining* the design of both components. The key insight was that we can give vision algorithms and hardware control over the way they collect visual data. Specific applications can therefore eliminate unnecessary and redundant data collection while focusing on the subset of the data that they need.\n\nThe project developed a series of new imaging hardware platforms and new algorithms to establish closed-loop control over camera sensors. It also produced new tools for designing the computational hardware that implements these vision and control algorithms. It demonstrated both that customizable sensors are feasible and competitive and that application-specific processing systems can be built to exploit them. Together, these tools will unlock the potential for software-defined imaging platforms that customize all aspects of a visual system for levels of efficiency that are not possible with today's fixed-function devices. The impacts of the project's work on productive hardware accelerator prototyping and design also extend beyond imaging and will make it easier to deliver other efficient, application-specific hardware accelerators.\n\n\t\t\t\t\tLast Modified: 10/25/2023\n\n\t\t\t\t\tSubmitted by: Adrian Sampson"
 }
}