{
 "awd_id": "1932858",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Photonic Tensor Accelerators for Artificial Neural Networks",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": "7032922967",
 "po_email": "sekim@nsf.gov",
 "po_sign_block_name": "Margaret Kim",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 474997.0,
 "awd_amount": 474997.0,
 "awd_min_amd_letter_date": "2019-07-09",
 "awd_max_amd_letter_date": "2021-08-20",
 "awd_abstract_narration": "Artificial intelligence (AI) and artificial neural networks (ANNs) have dominated conversations about the future of science, technology, economy, society and culture, and even humanity itself. Excitement about AI comes about because it recognizes patterns and even discovers solutions that are superior to those based on human intelligence. The rapid progress of AI is greatly attributed to increased computing capabilities. In recent years, the computation power of integrated circuits (ICs) have been unable to sustain the growth rate according to Moore's law. Hardware accelerators, with processing units and optimized memory architecture designed specifically for parallel computing, played a key role in the implementation of machine learning (ML) models. However, electronic hardware accelerators have already been pushed to their limits in term of scalability, unable to keep up with the exponential growth of data volume. Against this backdrop, there have been renewed efforts in exploring the role of optics in computing, motivated by the large bandwidth and low loss of optical transmission. This project proposes the photonic tensor accelerator (PTA), a highly-parallel photonic architecture capable of matrix-vector multiplication and matrix-matrix multiplication, that offers a computing power several orders of magnitude higher than existing electronic accelerators. Thanks to its high degree of parallelization, PTA is specifically suited for batch matrix multiplication for the implementation of ANN models. The technology developed in this proposal could demonstrate the cooperative roles of advanced hardware and software and attract more students into hardware-related areas. The research proposed is interdisciplinary in nature and can serve as a platform for training both graduate and undergraduate students at UCF, a Hispanic Serving Institution (HSI) designated by the U.S. Department of Education.\r\n\r\nThe overarching goal of this project is to construct photonic accelerators that 1) offer orders-of-magnitude higher scalability over electronics, 2) are fast, programmable, ideally compatible with training as well as inference, and 3) lower the power-consumption density to enable ANNs that are competitive over their pure electronic counterparts. The core of ANNs is tensor multiplication, which only require special operations (multiplication and accumulation, rather than general-purpose computing) in large scale that are especially suited for photonic accelerators. In addition, ANNs are robust to low dynamic range variabilities in nonlinear activation. PTA exploits all degrees of freedom of light to accelerate tensor multiplication. Specifically, PTA utilizes coherent beating between a signal and local oscillator to perform multiplication, frequency/wavelength, spatial modes and polarization for accumulation, and 2-D and 3-D parallelism of free space to scale the processing power. The proposed approach could scale the number of multiply-accumulate (MAC) operations by several orders of magnitude over the state-of-the-art IC hardware accelerators, including graphical processing units (GPUs) and ASICs such as tensor processing units (TPUs). The project will repurpose the technique of recirculating loops to scale up the number of layers for deep neural networks (DNNs). The proposed research is also synergistic with artificial intelligence (AI) in that some of the new devices will be designed using machine-learning techniques and the availability of the PTA-based ANNs allows new paradigms of ANN training.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Guifang",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Guifang Li",
   "pi_email_addr": "li@creol.ucf.edu",
   "nsf_id": "000238619",
   "pi_start_date": "2019-07-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Shuo",
   "pi_last_name": "Pang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shuo Pang",
   "pi_email_addr": "pang@creol.ucf.edu",
   "nsf_id": "000693985",
   "pi_start_date": "2019-07-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "The University of Central Florida Board of Trustees",
  "inst_street_address": "4000 CENTRAL FLORIDA BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "ORLANDO",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "4078230387",
  "inst_zip_code": "328168005",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "FL10",
  "org_lgl_bus_name": "THE UNIVERSITY OF CENTRAL FLORIDA BOARD OF TRUSTEES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RD7MXJV7DKT9"
 },
 "perf_inst": {
  "perf_inst_name": "The University of Central Florida",
  "perf_str_addr": "4304 Scorpius Street",
  "perf_city_name": "Orlando",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "328162700",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "FL10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "151700",
   "pgm_ele_name": "EPMD-ElectrnPhoton&MagnDevices"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "094E",
   "pgm_ref_txt": "Optoelectronic devices"
  },
  {
   "pgm_ref_code": "095E",
   "pgm_ref_txt": "Photonic integration"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 474997.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Artificial intelligence (AI) and artificial neural networks (ANNs) have dominated conversations about the future of science, technology, economy, society and culture, and even humanity itself. We investigated the photonic tensor accelerator (PTA) for matrix computations using photonics instead of electronics. An example of a computing function that can be performed by the PTA is batch matrix multiplication for AI applications, for example, multiplying a batch of images (3D data cube) by a weight matrix all at once.</p>\r\n<p>Matrix multiplications can be reduced to multiply-accumulate operations (MACs). The intellectual merits of the PTA originate from introducing techniques that exploit all degrees freedom of light. More specifically, we utilize 1) coherent beating to perform multiplication, 2) frequency/wavelength, spatial modes and polarization for accumulation, and 3) 2-D and 3-D parallelism of free space to scale the processing power. Because accumulation in the PTA is multi-dimensional, the scalability of the PTAs is multiplicative since these dimensions are orthogonal. The speed and energy efficiency of PTAs are limited only by data encoding and accumulations; multiplications (coherent beating) in PTAs are instantaneous and passive. During the course of this research project, we demonstrated matrix-matrix multiplication PTAs using discrete or free-space components as well as using micro-optics-based multi-plane light processing. &nbsp;We also demonstrated the application of the PTAs in solving eigenvalue problems, partial differential equations, as well as performing image reconstructions. Iterative algorithms were developed to improve the accuracy of the solutions beyond the native fixed-point precision of the analog PTAs.</p>\r\n<p>&nbsp;Advanced AI computing technologies that offer significant increase in computing power and energy efficiency can help to bring transformational changes to many areas of science and technology. However, there is still a very large gap from the feasibility demonstration of the PTA in this project to practical use cases. The research conducted during this project was interdisciplinary in nature and served as a platform for training both graduate and undergraduate students at UCF, a Hispanic Serving Institution (HSI) designated by the U.S. Department of Education.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/13/2025<br>\nModified by: Guifang&nbsp;Li</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nArtificial intelligence (AI) and artificial neural networks (ANNs) have dominated conversations about the future of science, technology, economy, society and culture, and even humanity itself. We investigated the photonic tensor accelerator (PTA) for matrix computations using photonics instead of electronics. An example of a computing function that can be performed by the PTA is batch matrix multiplication for AI applications, for example, multiplying a batch of images (3D data cube) by a weight matrix all at once.\r\n\n\nMatrix multiplications can be reduced to multiply-accumulate operations (MACs). The intellectual merits of the PTA originate from introducing techniques that exploit all degrees freedom of light. More specifically, we utilize 1) coherent beating to perform multiplication, 2) frequency/wavelength, spatial modes and polarization for accumulation, and 3) 2-D and 3-D parallelism of free space to scale the processing power. Because accumulation in the PTA is multi-dimensional, the scalability of the PTAs is multiplicative since these dimensions are orthogonal. The speed and energy efficiency of PTAs are limited only by data encoding and accumulations; multiplications (coherent beating) in PTAs are instantaneous and passive. During the course of this research project, we demonstrated matrix-matrix multiplication PTAs using discrete or free-space components as well as using micro-optics-based multi-plane light processing. We also demonstrated the application of the PTAs in solving eigenvalue problems, partial differential equations, as well as performing image reconstructions. Iterative algorithms were developed to improve the accuracy of the solutions beyond the native fixed-point precision of the analog PTAs.\r\n\n\nAdvanced AI computing technologies that offer significant increase in computing power and energy efficiency can help to bring transformational changes to many areas of science and technology. However, there is still a very large gap from the feasibility demonstration of the PTA in this project to practical use cases. The research conducted during this project was interdisciplinary in nature and served as a platform for training both graduate and undergraduate students at UCF, a Hispanic Serving Institution (HSI) designated by the U.S. Department of Education.\r\n\n\n\t\t\t\t\tLast Modified: 01/13/2025\n\n\t\t\t\t\tSubmitted by: GuifangLi\n"
 }
}