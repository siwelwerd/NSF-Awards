{
 "awd_id": "1908406",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: Efficient Memory Persistency for GPUs",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Danella Zhao",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-12-31",
 "tot_intn_awd_amt": 246928.0,
 "awd_amount": 246928.0,
 "awd_min_amd_letter_date": "2019-07-27",
 "awd_max_amd_letter_date": "2019-07-27",
 "awd_abstract_narration": "Scientific progress often depends on computer technology providing ever faster computers  capable of processing ever increasing amounts of data. The growth in memory capacity and density of current computer systems, however, is in peril as Dynamic Random Access Memory (DRAM), the current dominant main memory technology, faces serious roadblocks in scaling. Non-volatile memory or persistent memory is an emerging alternative technology that offers high integration density, speed similar to current main memory, byte addressability similar to current main memory, and lower standby power than current main memory. Hence, persistent memory is expected to increasingly augment or replace DRAM as main memory, and such a change is also expected to happen in Graphics Processing Unit (GPU) based computing systems which are the dominant accelerators for high performance computing. However, in order to fully realize its potential, research on persistency models on GPUs is needed. This project investigates integrated software and hardware techniques to enable GPUs to make efficient use of non-volatile memory. Successful outcomes of this project will lead to faster access to data by reducing overheads involved with file access. The software produced (persistent GPU benchmarks, compiler, and tuner) and prototyping platform will be made available to other researchers. Education and outreach activities in this project seek to train the next generation of programmers in this discipline.\r\n\r\nThe research in this project answers the question: on a GPU system, what architecture supports are needed to achieve efficient persistency programming on GPUs with persistent memory (PM) as their device memory? The research contributions include:  (1) an open-source GPU PM benchmark suite that is representative of various application domains; (2) an exploration of persistency models in GPUs and Instruction Set Architecture support; (3) optimizations on the persistency models by removing the need for logging; (4) a compiler pass and performance tuner to automatically determine the best-performing memory persistency and recovery model, and transform the code accordingly.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Huiyang",
   "pi_last_name": "Zhou",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Huiyang Zhou",
   "pi_email_addr": "hzhou@ncsu.edu",
   "nsf_id": "000250126",
   "pi_start_date": "2019-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "Dept. of ECE",
  "perf_city_name": "Raleigh",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276957914",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 246928.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project investigates how GPU (Graphics Processing Unit) computing benefits from persistent memory. Given its high integration density, high speed, byte addressability, and low standby power, persistent memory offers a promising way to address the memory capacity wall for GPUs that are increasingly used to process high volumes of data, e.g., training large machine learning (ML) models. Persistent data storage in memory provides a unique opportunity to achieve recoverable data structures (RDS), which allows programs, e.g., ML training, to recover from crashes just by using data in main memory directly instead of a special checkpoint. This project adapts, re-architects, and optimizes CPU persistency models for GPUs. Novel hardware and software schemes are devised to achieve GPU memory persistency efficiently, paving the way for the practical adoption of persistent memory for GPUs. Furthermore, this project researches the architectural support for GPU secure memory, which provides a trusted execution environment (TEE) compatible with CPU TEEs in cloud systems. With GPUs being mostly bandwidth sensitive, a set of novel optimizations have been developed to reduce the bandwidth contention between the regular data and the security metadata in different GPU computing configurations. The resulting low-performance overhead shows the feasibility of supporting GPU TEEs in cloud systems. &nbsp;</p>\n<p>This project advances state-of-the-art GPU memory systems, both in GPU memory persistency models and secure GPU memory systems. It offers the participating graduate students interdisciplinary research experiences in both hardware and software development. Research findings from this project have been published in premium conferences in the computer architecture and supercomputing fields and incorporated into a graduate-level course on advanced computer architecture. Open-source artifacts have been produced from this project to facilitate the reproducing of the results.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/30/2024<br>\nModified by: Huiyang&nbsp;Zhou</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project investigates how GPU (Graphics Processing Unit) computing benefits from persistent memory. Given its high integration density, high speed, byte addressability, and low standby power, persistent memory offers a promising way to address the memory capacity wall for GPUs that are increasingly used to process high volumes of data, e.g., training large machine learning (ML) models. Persistent data storage in memory provides a unique opportunity to achieve recoverable data structures (RDS), which allows programs, e.g., ML training, to recover from crashes just by using data in main memory directly instead of a special checkpoint. This project adapts, re-architects, and optimizes CPU persistency models for GPUs. Novel hardware and software schemes are devised to achieve GPU memory persistency efficiently, paving the way for the practical adoption of persistent memory for GPUs. Furthermore, this project researches the architectural support for GPU secure memory, which provides a trusted execution environment (TEE) compatible with CPU TEEs in cloud systems. With GPUs being mostly bandwidth sensitive, a set of novel optimizations have been developed to reduce the bandwidth contention between the regular data and the security metadata in different GPU computing configurations. The resulting low-performance overhead shows the feasibility of supporting GPU TEEs in cloud systems. \n\n\nThis project advances state-of-the-art GPU memory systems, both in GPU memory persistency models and secure GPU memory systems. It offers the participating graduate students interdisciplinary research experiences in both hardware and software development. Research findings from this project have been published in premium conferences in the computer architecture and supercomputing fields and incorporated into a graduate-level course on advanced computer architecture. Open-source artifacts have been produced from this project to facilitate the reproducing of the results.\n\n\n\t\t\t\t\tLast Modified: 01/30/2024\n\n\t\t\t\t\tSubmitted by: HuiyangZhou\n"
 }
}