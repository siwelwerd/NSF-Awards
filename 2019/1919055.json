{
 "awd_id": "1919055",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Doctoral Dissertation Research in DRMS: Developing and Validating a Method of Coherence-Based Judgment Aggregation",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032924710",
 "po_email": "clagonza@nsf.gov",
 "po_sign_block_name": "Claudia Gonzalez-Vallejo",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 19870.0,
 "awd_amount": 19870.0,
 "awd_min_amd_letter_date": "2019-06-18",
 "awd_max_amd_letter_date": "2019-06-18",
 "awd_abstract_narration": "High quality forecasting is essential to any area where people make decisions based on uncertain information, such as in geopolitics, the environment, and medical and financial domains. Subjective judgements of probabilities that quantify uncertainty are often used to produce such predictions. Previous research has differentiated two qualities of forecasts: accuracy, and coherence, or the extent of logical and probabilistic consistency in judgments. Recent work has suggested that coherent judgments tend to also be more accurate. Yet there exists no measure of coherence that might be used to identify a \"select crowd\" of judges who are more accurate than the average. The purpose of this research is to develop a psychological measure of coherence and determine how it predicts accuracy.  Specifically, the research will compare the relative accuracy of judgments that are weighed by this new measure with judgments weighed by existing methods of judgment aggregation. Results of this work can help improve judgment quality in highly consequential fields. \r\n\r\nTo answer this question, the researchers will create items that measure various aspects of probabilistic coherence.  For example, items would test whether the probabilities assigned to all possible outcomes add to 1, as expected. Researchers will assess the psychometric properties - reliability, convergent and divergent validity - of the newly devised measure.  To test the hypothesis that individuals with higher coherence scores are also more accurate, the researchers will weigh judgments from an incentivized forecasting tournament with this newly devised coherence measure. They will compare the accuracy of judgments weighed by this new method with other existing methods, such as linear and logarithmic averaging. The coherence measure may also produce a new, out-of-sample way of identifying the experts without additional knowledge of forecast performance, which will further our understanding of the role that individual-level coherence plays in maximizing judgment quality.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Budescu",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "David V Budescu",
   "pi_email_addr": "budescu@fordham.edu",
   "nsf_id": "000532919",
   "pi_start_date": "2019-06-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Emily",
   "pi_last_name": "Ho",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Emily Ho",
   "pi_email_addr": "eho2@fordham.edu",
   "nsf_id": "000795738",
   "pi_start_date": "2019-06-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Fordham University",
  "inst_street_address": "441 E FORDHAM RD",
  "inst_street_address_2": "",
  "inst_city_name": "BRONX",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "7188174086",
  "inst_zip_code": "104589993",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "NY15",
  "org_lgl_bus_name": "FORDHAM UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "ECESTN2SSVH1"
 },
 "perf_inst": {
  "perf_inst_name": "Fordham University",
  "perf_str_addr": "441 E Fordham Road, Dealy Hall",
  "perf_city_name": "Bronx",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "104585149",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "NY15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132100",
   "pgm_ele_name": "Decision, Risk & Mgmt Sci"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 19870.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Making quantitative forecasts are essential in a variety of fields, from intelligence analysis to geopolitics to meteorology, and more. These include questions such as, &ldquo;What are the chances it will rain tomorrow&rdquo;? People have thus been interested in the qualities that make a good forecaster, or one that is more accurate than others. There are two ways of assessing the quality of a forecast: by its conforming to probability rules, or by its accuracy, or how close the forecast is to ground truth. Evidence from an international forecasting tournament suggests the ability to correctly reason with probabilities, or the property of coherence, is related to making more accurate forecasts. Evidence from statistically and algorithmically coherentizing raw forecasts suggests that increases accuracy. Despite the potential centrality of coherence in producing more accurate forecasts, there is no measure that assesses this individual difference in individuals. There were two goals in this project which spanned three pilot studies and four studies. The first was to develop a psychometrically valid coherence scale, which will measure the ability for individuals to reason using probability axioms and to overcome logical and probability fallacies. The second goal was to use these scores from individuals to determine which judgments to give more weight so to ensure the most accurate aggregated estimate.</p>\n<p>&nbsp;</p>\n<p>We wrote items designed to measure the psychological construct of coherence and tested them. To maximize the number of items in the scale, we used a new method of generating items that allows for similar items produced to have the same psychometric properties as their original item. After developing and validating the scale, we used the coherence scale scores to weigh individuals on forecasts they gave in three independent samples. In one we asked participants from Amazon Mechanical Turk who had previously completed forecasts to complete the coherence scale, and in the second, we asked participants in an online forecasting tournament, Good Judgment Open. In the third sample, we conducted a longitudinal study on Amazon Mechanical Turk where we asked participants five times over the course of four months what they believed would be the outcome of questions such as the 2020 US election outcomes. All participants provided their own forecast about each question, rated their confidence in their forecast, and also provided their own estimate of the crowd&rsquo;s forecast.</p>\n<p>Compared with a variety of methods in the literature, the coherence measure generally performed well across the three studies. In both studies, coherence-based weighting increased judgment accuracy compared with the baseline method of unit weighting all estimates. Additionally, using only a select group of highly coherent forecasters for judgment aggregation procured more accurate judgments, compared with including all participants. Participants were incentivized for accuracy. The correlation between coherence and accuracy exceeded the correlations with all other predictive measures at each time point, as well as across all time points.</p>\n<p>These findings impact the broad area of judgment and decision-making, an interdisciplinary field spanning psychology, economics, management, and more. The method of generating the coherence scale such that multiple items could be produced allowed us to develop and test a new method for assessing psychometric equivalence across items and test forms. Developing the individual difference of coherence allowed us to test the extent to which individual differences affected forecasting accuracy, rather than looking only at statistical rules.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/28/2021<br>\n\t\t\t\t\tModified by: Emily&nbsp;Ho</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMaking quantitative forecasts are essential in a variety of fields, from intelligence analysis to geopolitics to meteorology, and more. These include questions such as, \"What are the chances it will rain tomorrow\"? People have thus been interested in the qualities that make a good forecaster, or one that is more accurate than others. There are two ways of assessing the quality of a forecast: by its conforming to probability rules, or by its accuracy, or how close the forecast is to ground truth. Evidence from an international forecasting tournament suggests the ability to correctly reason with probabilities, or the property of coherence, is related to making more accurate forecasts. Evidence from statistically and algorithmically coherentizing raw forecasts suggests that increases accuracy. Despite the potential centrality of coherence in producing more accurate forecasts, there is no measure that assesses this individual difference in individuals. There were two goals in this project which spanned three pilot studies and four studies. The first was to develop a psychometrically valid coherence scale, which will measure the ability for individuals to reason using probability axioms and to overcome logical and probability fallacies. The second goal was to use these scores from individuals to determine which judgments to give more weight so to ensure the most accurate aggregated estimate.\n\n \n\nWe wrote items designed to measure the psychological construct of coherence and tested them. To maximize the number of items in the scale, we used a new method of generating items that allows for similar items produced to have the same psychometric properties as their original item. After developing and validating the scale, we used the coherence scale scores to weigh individuals on forecasts they gave in three independent samples. In one we asked participants from Amazon Mechanical Turk who had previously completed forecasts to complete the coherence scale, and in the second, we asked participants in an online forecasting tournament, Good Judgment Open. In the third sample, we conducted a longitudinal study on Amazon Mechanical Turk where we asked participants five times over the course of four months what they believed would be the outcome of questions such as the 2020 US election outcomes. All participants provided their own forecast about each question, rated their confidence in their forecast, and also provided their own estimate of the crowd\u2019s forecast.\n\nCompared with a variety of methods in the literature, the coherence measure generally performed well across the three studies. In both studies, coherence-based weighting increased judgment accuracy compared with the baseline method of unit weighting all estimates. Additionally, using only a select group of highly coherent forecasters for judgment aggregation procured more accurate judgments, compared with including all participants. Participants were incentivized for accuracy. The correlation between coherence and accuracy exceeded the correlations with all other predictive measures at each time point, as well as across all time points.\n\nThese findings impact the broad area of judgment and decision-making, an interdisciplinary field spanning psychology, economics, management, and more. The method of generating the coherence scale such that multiple items could be produced allowed us to develop and test a new method for assessing psychometric equivalence across items and test forms. Developing the individual difference of coherence allowed us to test the extent to which individual differences affected forecasting accuracy, rather than looking only at statistical rules.\n\n \n\n\t\t\t\t\tLast Modified: 09/28/2021\n\n\t\t\t\t\tSubmitted by: Emily Ho"
 }
}