{
 "awd_id": "1940981",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Learning a High-Fidelity Semantic Parser",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 149108.0,
 "awd_amount": 181108.0,
 "awd_min_amd_letter_date": "2019-08-16",
 "awd_max_amd_letter_date": "2022-09-21",
 "awd_abstract_narration": "Communication with computers in ordinary language is a long-sought goal of AI researchers, educational, commercial, and government enterprises, and everyone who uses computers. The most impressive systems to date depend on coding of thousands of specialized \"skills\" by thousands of expert programmers. Ordinary comments such as \"I'm afraid I won't make it to the meeting\" and \"She managed to get the insulin shot in time\" are not understood well enough to draw obvious conclusions such as \"I won't be at the meeting\" and \"She got the insulin shot in time\". This exploratory EAGER project takes a step towards machine understanding of ordinary language, by providing a comprehensive way of representing the content of language in machines, and developing a machine learning technique that allows computers to translate language into that representation, and hence make the kinds of inferences mentioned. This in turn provides immediate tools for improving systems that require some degree of general understanding and inference, such as dialogue systems, sentiment analysis systems, and systems that extract desired knowledge from text. The high-fidelity representations of meaning produced by the semantic parser also provides a substrate for deriving deeper meanings, using what we know about the way discourse segments form coherent passages, and making use of general knowledge about word meanings and the world. The project team consists of a diverse group guided by the project principal investigators, several graduate-level and a dozen undergraduate-level researchers.\r\n\r\nThis project focuses on deriving \"unscoped logical forms\" (ULFs) reflecting the semantic type structure of standard English sentences with unprecedented fidelity, covering not only predication but also quantification, tense, modality, reification, predicate and sentence modification, comparison structures, and other semantic phenomena.  As such, it moves well beyond the expressive range of current mainstream approaches, such as Abstract Meaning Representation (AMR).  Thanks to its type coherence, ULF supports forward discourse inferences from text in a more comprehensive way than Natural Logic, and without requiring knowledge of a target hypothesis to be confirmed or disconfirmed.  Demonstrating inferences from clause-taking verbs, counterfactuals, questions, and requests provides an important proof of concept.  The semantic ULF parser is produced by supervised learning of a cache transition parser, much like one previously applied successfully to AMR parsing, but enhanced by prioritizing type-consistent operator-operand combinations.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lenhart",
   "pi_last_name": "Schubert",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Lenhart K Schubert",
   "pi_email_addr": "schubert@cs.rochester.edu",
   "nsf_id": "000235732",
   "pi_start_date": "2019-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Gildea",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel Gildea",
   "pi_email_addr": "gildea@cs.rochester.edu",
   "nsf_id": "000449779",
   "pi_start_date": "2019-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "500 Joseph C. Wilson BLVD",
  "perf_city_name": "Rochester",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146270140",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 149108.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\"><span class=\"s1\">This project was aimed at developing techniques for automatically generating semantic representations from English sentences, where these representations capture the full richness of language, while at the same time enabling comprehensible, justifiable inference. This is part of a larger enterprise that seeks to create intelligent computational agents that not only are fluent in language, but also can reason and plan combinatorially based on their knowledge -- something that eludes current \"large language models\" (LLMs). However, LLMs have turned out to be useful tools in this project and related ones.</span></p>\n<p class=\"p1\"><span class=\"s1\">The representations generated from English are termed \"unscoped logical forms\" (ULFs), and the mechanisms developed to generate them use neural-net techniques and LLMs to learn from manually created examples (training corpora).</span></p>\n<p class=\"p1\"><span class=\"s1\">While ULFs retain some of the context dependencies and ambiguities of the original English (e.g., what previously mentioned entities a pronoun like \"they\" might refer to), they are semantically and structurally sufficiently definite to enable classes of inferences that include so-called \"natural deduction\" inferences as a special case. For example, the ULF derived from \"Bob tried but failed to sleep on the plane\" enables the obvious inferences that Bob wanted to sleep on the plane, but in fact did not sleep on the plane.</span></p>\n<p class=\"p1\"><span class=\"s1\">ULFs can be further decontextualized to obtain formal propositions that can be used for reasoning and planning independently of context. This is not enabled by currently popular semantic representations such as Abstract Meaning Representation (AMR), whose semantic types are not well-defined and which suppress important aspects of meaning, such as temporal relations and the distinction between factual and hypotheical propositions.</span>&nbsp;</p>\n<p class=\"p1\"><span class=\"s1\">The project also intersected and supported related ventures aimed at (1) creating lifelike on-screen personas that enable various classes of users, such as autistic teens, older adults, or oncological clinicians, to practice casual or purposeful conversations, where the system can observe its users and provide helpful feedback about their conversational behavior; and (2) in a quite different vein, creating another speech- and vision-enabled system for discussing configurations of children's blocks on a table and how they have been moved about.</span></p>\n<p class=\"p1\"><span class=\"s1\">Both types of systems use a uniform new framework for representing the expected behavior of dialogue participants as schemas -- structured sets of conditions, steps, and anticipated effects, expressed in the same propositional formalism that the ULF parser is aimed at, and which can be decontextualized for precise reasoning, for example about spatial relations in the blocks world. Schemas of the same type also provide general behavioral and factual knowledge to the dialogue practice agents, to enhance their understanding of user inputs and to inform their responses. The agents that have been created have been successfully tested with appropriate user groups. Moreover, the very general dialogue infrastructure developed for such agents is expected to be broadly usable for practical applications such as training of medical students.</span></p>\n<p class=\"p1\"><span class=\"s1\">Another closely related thrust in this project was the automatic acquisition of commonsense knowledge in the form of schemas. This was initially pursued by using LLMs to create simple stories that involve a target concept, such as getting a fruit from a tree by climbing it, or catching fish with a fishing rod and lure. By interpreting the stories into ULF and decontextualizing them, formal schemas were derived that could subsequently be used for prediction in stories. In later efforts, both on-line lexicons and LLMs were used directly for knowledge mining, in particular for creating schemas for thousands of physical objects, formally representing their part structure, composition, and typical usage (especially in the case of artifacts). The lexical approach directly used lexical glosses for particular word senses, parsed them into ULF, and decontextualized the ULFs so as to fit their contents into the expected \"slots\" of object schemas. The LLM-based approach is similar but starts with prompts that directly elicit general facts about an object concept or action concept from the LLM. This work is still being documented and expanded.</span></p>\n<p class=\"p1\"><span class=\"s1\">The availability of a general method for deriving loss-free meaning representations from ordinary language, where these representations lend themselves to reasoning, should prove useful to the research community working on natural language processing and reasoning. As well, the dialogue management infrastructure developed in this project, allowing for speech interaction with online personas, can potentially serve as a basis for many useful systems. The general knowledge that has been mined, and is being further mined, from lexicons and LLMs will in future enable reasoning and planning in unrestricted domains, in an explainable and justifiable way, in contrast with \"black box\" methods that represent knowledge as billions of numerical parameters.</span></p>\n<p class=\"p1\"><span class=\"s1\"><br /></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/30/2023<br>\n\t\t\t\t\tModified by: Lenhart&nbsp;K&nbsp;Schubert</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "This project was aimed at developing techniques for automatically generating semantic representations from English sentences, where these representations capture the full richness of language, while at the same time enabling comprehensible, justifiable inference. This is part of a larger enterprise that seeks to create intelligent computational agents that not only are fluent in language, but also can reason and plan combinatorially based on their knowledge -- something that eludes current \"large language models\" (LLMs). However, LLMs have turned out to be useful tools in this project and related ones.\nThe representations generated from English are termed \"unscoped logical forms\" (ULFs), and the mechanisms developed to generate them use neural-net techniques and LLMs to learn from manually created examples (training corpora).\nWhile ULFs retain some of the context dependencies and ambiguities of the original English (e.g., what previously mentioned entities a pronoun like \"they\" might refer to), they are semantically and structurally sufficiently definite to enable classes of inferences that include so-called \"natural deduction\" inferences as a special case. For example, the ULF derived from \"Bob tried but failed to sleep on the plane\" enables the obvious inferences that Bob wanted to sleep on the plane, but in fact did not sleep on the plane.\nULFs can be further decontextualized to obtain formal propositions that can be used for reasoning and planning independently of context. This is not enabled by currently popular semantic representations such as Abstract Meaning Representation (AMR), whose semantic types are not well-defined and which suppress important aspects of meaning, such as temporal relations and the distinction between factual and hypotheical propositions. \nThe project also intersected and supported related ventures aimed at (1) creating lifelike on-screen personas that enable various classes of users, such as autistic teens, older adults, or oncological clinicians, to practice casual or purposeful conversations, where the system can observe its users and provide helpful feedback about their conversational behavior; and (2) in a quite different vein, creating another speech- and vision-enabled system for discussing configurations of children's blocks on a table and how they have been moved about.\nBoth types of systems use a uniform new framework for representing the expected behavior of dialogue participants as schemas -- structured sets of conditions, steps, and anticipated effects, expressed in the same propositional formalism that the ULF parser is aimed at, and which can be decontextualized for precise reasoning, for example about spatial relations in the blocks world. Schemas of the same type also provide general behavioral and factual knowledge to the dialogue practice agents, to enhance their understanding of user inputs and to inform their responses. The agents that have been created have been successfully tested with appropriate user groups. Moreover, the very general dialogue infrastructure developed for such agents is expected to be broadly usable for practical applications such as training of medical students.\nAnother closely related thrust in this project was the automatic acquisition of commonsense knowledge in the form of schemas. This was initially pursued by using LLMs to create simple stories that involve a target concept, such as getting a fruit from a tree by climbing it, or catching fish with a fishing rod and lure. By interpreting the stories into ULF and decontextualizing them, formal schemas were derived that could subsequently be used for prediction in stories. In later efforts, both on-line lexicons and LLMs were used directly for knowledge mining, in particular for creating schemas for thousands of physical objects, formally representing their part structure, composition, and typical usage (especially in the case of artifacts). The lexical approach directly used lexical glosses for particular word senses, parsed them into ULF, and decontextualized the ULFs so as to fit their contents into the expected \"slots\" of object schemas. The LLM-based approach is similar but starts with prompts that directly elicit general facts about an object concept or action concept from the LLM. This work is still being documented and expanded.\nThe availability of a general method for deriving loss-free meaning representations from ordinary language, where these representations lend themselves to reasoning, should prove useful to the research community working on natural language processing and reasoning. As well, the dialogue management infrastructure developed in this project, allowing for speech interaction with online personas, can potentially serve as a basis for many useful systems. The general knowledge that has been mined, and is being further mined, from lexicons and LLMs will in future enable reasoning and planning in unrestricted domains, in an explainable and justifiable way, in contrast with \"black box\" methods that represent knowledge as billions of numerical parameters.\n\n\n\n \n\n\t\t\t\t\tLast Modified: 08/30/2023\n\n\t\t\t\t\tSubmitted by: Lenhart K Schubert"
 }
}