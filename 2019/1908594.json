{
 "awd_id": "1908594",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Collaborative Research: Stream-Based Active Mining at Scale: Non-Linear Non-Submodular Maximization",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927978",
 "po_email": "racharya@nsf.gov",
 "po_sign_block_name": "Raj Acharya",
 "awd_eff_date": "2019-10-15",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2019-09-13",
 "awd_max_amd_letter_date": "2019-09-13",
 "awd_abstract_narration": "The past decades have witnessed enormous transformations of intelligent data analysis in the realm of datasets at an unprecedented scale. Analysis of big data is computationally demanding, resource hungry, and much more complex.  With recent emerging applications, most of the studied objective functions have been shown to be non-submodular or non-linear. Additionally, with the presence of dynamics in billion-scale datasets, such as items are arriving in an online fashion, scalable and stream-based adaptive algorithms which can quickly update solutions instead of recalculating from scratch must be investigated. All of the aforementioned issues call for a scalable and stream-based active mining techniques to cope with enormous applications of non-submodular maximization in the era of big data. With the society's growing dependence on the cyberspace and computer technologies, the premium placed on the intelligent big data analysis for many emerging applications. Therefore, the success of this project has a high impact in almost any field that needs lightweight and near-optimal big data analysis. The findings of this project will also enrich the research on network science, graph theory, optimization, and big data analysis. In addition to creating new courses, undergrad and high school students will be involved in hands-on activities over the experimental platform. Outreach events targeted at under-represented groups and K-1\r\n\r\nThis project develops a theoretical framework together with highly scalable approximation algorithms and tight theoretical performance bound guarantees for the class of non-submodular and non-linear optimization. In particular, the project lays the foundation for the novel data mining techniques, suitable to the new era of big data with emerging applications, as well as advance the research front of stochastic and stream-based algorithm designs, with several key innovations: 1) Rigorous mathematical techniques to analyze and design highly scalable approximation algorithms to the class of non-monotonic, non-submodular maximization, which underlies many emerging applications. 2) Attempt a new research direction by bridging the non-linear optimization and the combinatorial optimization, thereby bringing the new angles for the study of non-submodular optimization as well as getting deeper understanding of the problem structures. 3) Novel stream-based active mining at scale for multiple applications, focused on the two general models which unify many optimization problems in the domain of online social networks and privacy. It also provides a novel theoretical framework for adaptive non-submodular maximization, which has not been studied in the literature. 4) Extensive evaluation through a combination of various tools and methods, including the real-world datasets and applications that will bridge the gap between theory and practice.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "My",
   "pi_last_name": "Thai",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "My T Thai",
   "pi_email_addr": "mythai@cise.ufl.edu",
   "nsf_id": "000391957",
   "pi_start_date": "2019-09-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "University of Florida",
  "perf_city_name": "Gainesville, FL",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326112002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-b372d9a7-7fff-bb58-2bcd-d5c55b968831\"> </span></p>\n<p dir=\"ltr\"><span>Analysis of big data is computationally demanding, resource hungry, and much more complex. With recent emerging applications, most of the studied objective functions have been shown to be non-submodular or non-linear. Additionally, with the presence of dynamics in billion-scale datasets, such as items arriving in an online fashion, scalable and stream-based adaptive algorithms which can quickly update solutions instead of recalculating from scratch must be investigated. All of the aforementioned issues call for a scalable and stream-based active mining techniques to cope with enormous applications of non-submodular maximization in the era of big data.</span></p>\n<p dir=\"ltr\"><span>This project develops a suite of theories and highly scalable approximation algorithms, with tight theoretical performance bound guarantees for the class of non-submodular, non-linear optimization. In particular, the project lays the foundation for the novel data mining techniques, suitable to the new era of big data with emerging applications, as well as advance the research front of stochastic and stream-based algorithm designs. Specifically, for the class of non-submodular maximization, the mathematical analysis and approximation algorithms were designed, considering both monotonic and non-monotonic. For the class of non-linear maximization, several important observations have been identified, focusing on extension from continuous to discrete and extension from linear to nonlinear.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Considering the lightweight and scalable stream-based algorithms for dynamic and online settings, we developed several important techniques, advancing the research front for stochastic optimization.&nbsp; In particular, highly scalable active mining&nbsp; techniques which can be executed in billion-scale datasets in a very short time were developed, including stream-based setting algorithms with theoretical performance guarantees. The developed techniques consider both the streaming-realizations model and the streaming-candidates model, covering most of the real-life scenarios. We further developed novel parallel algorithms to significantly improve the query complexity of a non-linear optimization problem, specifically the submodular maximization under a cardinality constraint (SMC) problem. The SMC problem has numerous applications in artificial intelligence, including data summarization, recommendation systems, and weight cutting. With the rapid growth of input data, existing solutions to SMC suffer from high query complexity. Our developed algorithms not only improve the query complexity but also maintain a similar adaptive performance ratio.</span></p>\n<p dir=\"ltr\"><span>In addition to developing the set of theories and approximation algorithms, the new theoretical results and algorithms have been integrated into many emerging applications, namely general influence maximization and network vulnerability assessment. In addition, we also evaluated our theoretical results against other application domains, such as differential privacy preservation in deep learning under model attacks.</span></p>\n<p dir=\"ltr\"><span>The research outcomes and results have been disseminated to communities of interest through research publications, conference/workshop presentations, and invited talks at academic institutions as well as industrial research labs. Several book chapters on large-scale data-mining and algorithm design have been published. Four Ph.D. students have graduated with the support of this project.</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/21/2024<br>\nModified by: My&nbsp;T&nbsp;Thai</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nAnalysis of big data is computationally demanding, resource hungry, and much more complex. With recent emerging applications, most of the studied objective functions have been shown to be non-submodular or non-linear. Additionally, with the presence of dynamics in billion-scale datasets, such as items arriving in an online fashion, scalable and stream-based adaptive algorithms which can quickly update solutions instead of recalculating from scratch must be investigated. All of the aforementioned issues call for a scalable and stream-based active mining techniques to cope with enormous applications of non-submodular maximization in the era of big data.\n\n\nThis project develops a suite of theories and highly scalable approximation algorithms, with tight theoretical performance bound guarantees for the class of non-submodular, non-linear optimization. In particular, the project lays the foundation for the novel data mining techniques, suitable to the new era of big data with emerging applications, as well as advance the research front of stochastic and stream-based algorithm designs. Specifically, for the class of non-submodular maximization, the mathematical analysis and approximation algorithms were designed, considering both monotonic and non-monotonic. For the class of non-linear maximization, several important observations have been identified, focusing on extension from continuous to discrete and extension from linear to nonlinear.\n\n\nConsidering the lightweight and scalable stream-based algorithms for dynamic and online settings, we developed several important techniques, advancing the research front for stochastic optimization. In particular, highly scalable active mining techniques which can be executed in billion-scale datasets in a very short time were developed, including stream-based setting algorithms with theoretical performance guarantees. The developed techniques consider both the streaming-realizations model and the streaming-candidates model, covering most of the real-life scenarios. We further developed novel parallel algorithms to significantly improve the query complexity of a non-linear optimization problem, specifically the submodular maximization under a cardinality constraint (SMC) problem. The SMC problem has numerous applications in artificial intelligence, including data summarization, recommendation systems, and weight cutting. With the rapid growth of input data, existing solutions to SMC suffer from high query complexity. Our developed algorithms not only improve the query complexity but also maintain a similar adaptive performance ratio.\n\n\nIn addition to developing the set of theories and approximation algorithms, the new theoretical results and algorithms have been integrated into many emerging applications, namely general influence maximization and network vulnerability assessment. In addition, we also evaluated our theoretical results against other application domains, such as differential privacy preservation in deep learning under model attacks.\n\n\nThe research outcomes and results have been disseminated to communities of interest through research publications, conference/workshop presentations, and invited talks at academic institutions as well as industrial research labs. Several book chapters on large-scale data-mining and algorithm design have been published. Four Ph.D. students have graduated with the support of this project.\n\n\n\t\t\t\t\tLast Modified: 10/21/2024\n\n\t\t\t\t\tSubmitted by: MyTThai\n"
 }
}