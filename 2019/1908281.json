{
 "awd_id": "1908281",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Collaborative Research: Rigorous Approaches for Scalable Privacy-preserving Deep Learning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922182",
 "po_email": "pbrass@nsf.gov",
 "po_sign_block_name": "Peter Brass",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 208738.0,
 "awd_amount": 208738.0,
 "awd_min_amd_letter_date": "2019-07-12",
 "awd_max_amd_letter_date": "2019-07-12",
 "awd_abstract_narration": "One of the most salient features of this time is the dissemination of massive amounts of personal and sensitive data. Despite their enormous societal benefits, the powerful tools of modern machine learning, especially deep learning, can pose real threats to personal privacy. For example, over the last few years, it has become evident that deep neural networks have a remarkable power in learning even the finest details from large complex data sets. With such powerful tools, the need for robust and rigorous guarantees for privacy protection has become more crucial. The last decade has witnessed the rise of a sound mathematical theory, known as differential privacy, that enables designing data-analysis algorithms with rigorous privacy guarantees for their input data sets. Despite the noticeable success of this theory, existing tools from differential privacy are severely limited in offering acceptable utility guarantees when dealing with complex models like those arising in deep learning. This project will address those limitations by offering new principled approaches for designing differentially-private deep-learning algorithms that can scale to industrial workloads. The project will also involve collaboration with industry, which will facilitate the evaluation of the developed algorithms on real-world datasets and the development of open-source software tools. The products of this project have the potential to transform the way massive sets of sensitive data are used in modern machine-learning systems, which will impact the way these systems are designed and implemented in practice. The activities of this project will also aim at promoting diversity in computing by recruiting women and members of underrepresented groups.\r\n\r\nThe investigators will develop a rigorous, multi-faceted design paradigm for scalable, practical, differentially private algorithms for modern machine learning. This paradigm is based on two general strategies: (i) exploiting realistic and useful properties of the data and the machine-learning models to circumvent existing limitations in the literature on differential privacy, and (ii) leveraging a limited amount of public data (that has no privacy constraints) to boost the utility of the algorithms. Based on these strategies, the project will pursue following directions: (1) developing a new, generic framework for utilizing public data in privacy-preserving machine learning, (2) designing improved iterative training algorithms that can bypass the standard use of the so-called \"composition theorem\" of differential privacy, and (3) designing new differentially private stochastic-gradient methods tuned specifically to non-convex and over-parameterized machine-learning problems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Raef",
   "pi_last_name": "Bassily",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Raef Bassily",
   "pi_email_addr": "Bassily.1@osu.edu",
   "nsf_id": "000763723",
   "pi_start_date": "2019-07-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio State University",
  "inst_street_address": "1960 KENNY RD",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBUS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "6146888735",
  "inst_zip_code": "432101016",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OH03",
  "org_lgl_bus_name": "OHIO STATE UNIVERSITY, THE",
  "org_prnt_uei_num": "MN4MDDMN8529",
  "org_uei_num": "DLWBSLWAJWR1"
 },
 "perf_inst": {
  "perf_inst_name": "Ohio State University",
  "perf_str_addr": "1960 Kenny Road",
  "perf_city_name": "Columbus",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "432101016",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OH03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 208738.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;</p>\n<p>In this project, we made several fundamental contributions to privacy-preserving machine learning and developed new algorithmic tools to address major challenges in this important area of research. The fundamental nature of our results has motivated many follow-ups and led to a significant progress in this area along several directions. This project has led to 12 publications in top-tier machine learning and theory conferences such as NeurIPS, ICML, COLT, ALT, and AISTATS, in addition to two Ph.D. dissertations at OSU. &nbsp;</p>\n<p>&nbsp;</p>\n<p>We established the optimal accuracy and sample complexity guarantees for several central problems in differentially private (DP) machine learning and optimization. Notably, we established the optimal statistical error (population risk) of DP stochastic convex optimization (SCO), which is one of the most fundamental problems in machine learning and optimization, and developed several, new, efficient DP algorithms attaining the optimal error. Prior to our work, this problem has remained open for many years. We also extended our results and characterization of the optimal error to the non-Euclidean settings of SCO, which capture a wide range of problems in modern machine learning. In another direction, we initiated a formal study of DP learning and DP query release when the DP algorithm is assisted with public data and characterized the optimal error, as well as the optimal private and public sample complexities, in these problems. In another work, we gave a formal, quantitative characterization of uniform stability of stochastic gradient methods in non-smooth convex optimization and showed that several variants of these methods attain the optimal generalization guarantees for learning under general convex (possibly non-smooth) loss functions. We demonstrated the central role of algorithmic stability in private learning and gave new DP algorithms where stability is exploited to attain the optimal error (population risk). In another direction, we developed new DP learning algorithms with dimension-independent error guarantees based on the notion of confidence margin. Our results cover a wide spectrum of problems, including DP learning of neural networks. Recently, we also initiated a systematic study of privacy-preserving domain adaptation and developed new DP algorithms for adaptation from a public source domain (with no privacy constraints) to a private target domain (from which the available data is private and limited in quantity and labels).</p>\n<p>&nbsp;</p>\n<p>Some of the algorithmic techniques in this project were developed in collaboration with several researchers from industry (e.g., Google), which could potentially facilitate technology transfer in the future. Several Ph.D. students received extensive training and gained substantial expertise in the fundamentals of privacy-preserving machine learning and optimization while working on problems related to this project. One of them completed her dissertation successfully in Fall 2022 and graduated, and another is currently finalizing his dissertation and is expected to graduate in Spring 2024. Part of this research was also used to develop a graduate-level course on privacy-preserving data analysis at OSU.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/27/2024<br>\nModified by: Raef&nbsp;Bassily</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\nIn this project, we made several fundamental contributions to privacy-preserving machine learning and developed new algorithmic tools to address major challenges in this important area of research. The fundamental nature of our results has motivated many follow-ups and led to a significant progress in this area along several directions. This project has led to 12 publications in top-tier machine learning and theory conferences such as NeurIPS, ICML, COLT, ALT, and AISTATS, in addition to two Ph.D. dissertations at OSU. \n\n\n\n\n\nWe established the optimal accuracy and sample complexity guarantees for several central problems in differentially private (DP) machine learning and optimization. Notably, we established the optimal statistical error (population risk) of DP stochastic convex optimization (SCO), which is one of the most fundamental problems in machine learning and optimization, and developed several, new, efficient DP algorithms attaining the optimal error. Prior to our work, this problem has remained open for many years. We also extended our results and characterization of the optimal error to the non-Euclidean settings of SCO, which capture a wide range of problems in modern machine learning. In another direction, we initiated a formal study of DP learning and DP query release when the DP algorithm is assisted with public data and characterized the optimal error, as well as the optimal private and public sample complexities, in these problems. In another work, we gave a formal, quantitative characterization of uniform stability of stochastic gradient methods in non-smooth convex optimization and showed that several variants of these methods attain the optimal generalization guarantees for learning under general convex (possibly non-smooth) loss functions. We demonstrated the central role of algorithmic stability in private learning and gave new DP algorithms where stability is exploited to attain the optimal error (population risk). In another direction, we developed new DP learning algorithms with dimension-independent error guarantees based on the notion of confidence margin. Our results cover a wide spectrum of problems, including DP learning of neural networks. Recently, we also initiated a systematic study of privacy-preserving domain adaptation and developed new DP algorithms for adaptation from a public source domain (with no privacy constraints) to a private target domain (from which the available data is private and limited in quantity and labels).\n\n\n\n\n\nSome of the algorithmic techniques in this project were developed in collaboration with several researchers from industry (e.g., Google), which could potentially facilitate technology transfer in the future. Several Ph.D. students received extensive training and gained substantial expertise in the fundamentals of privacy-preserving machine learning and optimization while working on problems related to this project. One of them completed her dissertation successfully in Fall 2022 and graduated, and another is currently finalizing his dissertation and is expected to graduate in Spring 2024. Part of this research was also used to develop a graduate-level course on privacy-preserving data analysis at OSU.\n\n\n\t\t\t\t\tLast Modified: 01/27/2024\n\n\t\t\t\t\tSubmitted by: RaefBassily\n"
 }
}