{
 "awd_id": "1940287",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Machine Learning methods for multi-disciplinary multi-scales problems",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Eva Zanzerkia",
 "awd_eff_date": "2020-01-01",
 "awd_exp_date": "2023-12-31",
 "tot_intn_awd_amt": 331136.0,
 "awd_amount": 331136.0,
 "awd_min_amd_letter_date": "2019-09-18",
 "awd_max_amd_letter_date": "2020-08-12",
 "awd_abstract_narration": "This project addresses two of the most pressing challenges in modern scientific research: (a) modeling natural phenomena across a broad range of space and time scales, and (b) the application of data science to discover physically meaningful relationships from large datasets. It will leverage knowledge from related and disparate disciplines, connecting them through data science. Four specific problems will be studied: cloud formation and evolution, movement of particles through random media, frustrated magnetic systems, and the reconstruction of urban topography. These benchmark problems have been selected as they capture different disciplinary aspects of multi-scale challenges. State-of-the-art methods in machine learning (including Artificial Neural Networks) will be used to develop new mathematical representation for small-scale processes. If successful, this project will substantially increase the capability of scientific computing to address a wide variety of important problems from the natural and social sciences, and will be disseminated widely through a pair of workshops, multiple campus visits across the 5-institution consortium, high impact peer-reviewed publications and presentations and the training of a cadre of more than a dozen post-docs and students.\r\n\r\nThis project will develop, implement and evaluate a new constrained optimization framework to discover and test physical phenomena at different resolutions and scales, including new machine learning algorithms aimed at discovering the stochastic differential equations underlying noisy data. This will be used to train physical parameterizations that account for the effects of small-scale processes in coarse resolution models. Core to this will be the design of a new framework to constrain artificial neural networks to deliver solutions that are interpretable and meaningful in the domain sciences and that can be directly associated with differential operators.\r\n\r\nThis project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dallas",
   "pi_last_name": "Trinkle",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Dallas R Trinkle",
   "pi_email_addr": "dtrinkle@illinois.edu",
   "nsf_id": "000280420",
   "pi_start_date": "2019-09-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "506 S. Wright Street",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "099Y00",
   "pgm_ele_name": "HDR-Harnessing the Data Revolu"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 162666.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 168470.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"Normal1\">This project had four technical aims designed towards advancing data science and computational techniques for complex, big data problems.&nbsp;These aims relate to&nbsp;designing a systematic methodology to build parameterization problems through machine learning, implementation of this methodology to address benchmark problems in multiple disciplines, development of new machine learning algorithms focused on model reduction, regularization and&nbsp;uncertainty quantification and construction of new, interpretable neural nets to gain physical insights from the parameterizations.&nbsp;As part of the research output from this project, we have obtained fast and efficient feature selection procedures under very general frameworks, where both the number of features, as well as the observations in each feature can be large. Moreover, our algorithm can be simultaneously used for uncertainty quantification and scientific hypothesis testing. Also, we devised methodology and principles for hypothesis tests to verify if two sets of complex data, for example two time series, have the same underlying characteristics. We have developed techniques for uncertainty quantification in digital twins and in cases where constrained optimization is used to calibrate machine learning algorithms to known scientific information. The algorithms and theoretical results we obtained through this project can be applied to several different disciplines, including problems in physics, material sciences, urban engineering, healthcare and biomedical research, and so on. Multiple students were involved in different parts of this project, leading to highly skilled workforce development. Results from this project are disseminated in various outlets like peer-reviewed journal papers, books, and conference proceedings, and through seminars and conferences.&nbsp;</p><br>\n<p>\n Last Modified: 08/09/2024<br>\nModified by: Dallas&nbsp;R&nbsp;Trinkle</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project had four technical aims designed towards advancing data science and computational techniques for complex, big data problems.These aims relate todesigning a systematic methodology to build parameterization problems through machine learning, implementation of this methodology to address benchmark problems in multiple disciplines, development of new machine learning algorithms focused on model reduction, regularization anduncertainty quantification and construction of new, interpretable neural nets to gain physical insights from the parameterizations.As part of the research output from this project, we have obtained fast and efficient feature selection procedures under very general frameworks, where both the number of features, as well as the observations in each feature can be large. Moreover, our algorithm can be simultaneously used for uncertainty quantification and scientific hypothesis testing. Also, we devised methodology and principles for hypothesis tests to verify if two sets of complex data, for example two time series, have the same underlying characteristics. We have developed techniques for uncertainty quantification in digital twins and in cases where constrained optimization is used to calibrate machine learning algorithms to known scientific information. The algorithms and theoretical results we obtained through this project can be applied to several different disciplines, including problems in physics, material sciences, urban engineering, healthcare and biomedical research, and so on. Multiple students were involved in different parts of this project, leading to highly skilled workforce development. Results from this project are disseminated in various outlets like peer-reviewed journal papers, books, and conference proceedings, and through seminars and conferences.\t\t\t\t\tLast Modified: 08/09/2024\n\n\t\t\t\t\tSubmitted by: DallasRTrinkle\n"
 }
}