{
 "awd_id": "1944993",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Collaborative Research: Analytics on Edge-labeled Hypergraphs: Limits to De-anonymization",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032920000",
 "po_email": "ahero@nsf.gov",
 "po_sign_block_name": "Alfred Hero",
 "awd_eff_date": "2019-05-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 227515.0,
 "awd_amount": 227515.0,
 "awd_min_amd_letter_date": "2019-08-22",
 "awd_max_amd_letter_date": "2021-04-09",
 "awd_abstract_narration": "Data analytics is a rapidly growing field, aided by the availability of huge amounts of data and significant computing power. The immense potential of data analytics to provide benefits to the society in application areas such as health, economics, and finance, is reliant on the fundamental and urgent challenge of protecting privacy of users. In this project, new theoretical paradigms and approaches to address privacy vulnerability of users in network environments in presence of big data are studied. The vulnerability results from the indigenous structural dependencies in the network as well as the presence of exogenous auxiliary information outside of the network that permits deanonymization of the users. This project has transformative potential to impact a broad class of applications where user privacy is critical. The project?s inherently inter-disciplinary nature and real-world technological potential complements the investigators? on-going efforts to engage more students (especially women and minorities) to study topics at the intersection of application and quantitative reasoning in the STEM disciplines. \r\n\r\nThe research is divided into three thrusts: (1) Development of information-theoretic converses for deanonymization problem in random edge-labeled hyper-graphs for adversaries with access to correlated information sources. Such converses enable deriving necessary conditions under which the adversary cannot deanonymize the system, no matter how much computational power or storage is available. (2) Research practical achievable schemes: Besides tight (but not necessarily efficient) achievable schemes required for calibrating the converses, the design of practical deanonymization algorithms to quantify how much attackers can learn when the released datasets do not meet the necessary conditions of the converse, are explored. (3) Real-world evaluations: The performance of the algorithms and their practical applicability are evaluated on real world datasets.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Negar",
   "pi_last_name": "Kiyavash",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Negar Kiyavash",
   "pi_email_addr": "negar.kiyavash@gatech.edu",
   "nsf_id": "000307877",
   "pi_start_date": "2019-08-22",
   "pi_end_date": "2020-05-22"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Siva Theja",
   "pi_last_name": "Maguluri",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Siva Theja Maguluri",
   "pi_email_addr": "siva.theja@gatech.edu",
   "nsf_id": "000730305",
   "pi_start_date": "2020-05-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Tech Research Corporation",
  "perf_str_addr": "505 10th St.",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320420",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 227515.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Aided by the availability of huge amounts of data and significant computing power, machine learning has led to immense breakthroughs. The immense potential of data analytics to provide benefits to the society in application areas such as health, economics, and finance, is reliant on the fundamental and urgent challenge of protecting privacy of users. In this project, new theoretical paradigms and approaches to address privacy vulnerability of users in network environments in presence of big data and reinforcement learning are studied.<br /><br />This project investigates the fundamental limits to anonymization. One setting of interest is the case of correlated databases. More specifically, consider the following setting: There are a large set of entities (e,g, users) with some measurable characteristics with known statistics. We refer to these measures as features. Consider two different sources, each providing a database with lists of features for these entities. Furthermore, let one these sources lack proper labeling for features that would allow for the identification of feature pairs from the two sources that correspond to the same entity. We studied the conditions that allow for the exact-alignment and near-exact alignment of correlated databases.<br /><br />The second part of this project is on privacy in reinforcement learning. We develop state-of-the art sample complexity of a large class of actor-critic style reinoforcement learning algorithms, in both tabular and linear function approximation settings under off-policy sampling. We did this by overcoming the infamous deadly triad phenomenon, and also by developing novel analysis to study two time-scale algorithms. We then consider a federated reinforcement learning paradigm where each agent only shares their estimates of parameters and not the data to protect its provacy. We characterize the sample complexity of a large class of reinforcement learning algorithms in this paradigm, and show that there is a linear speed up in the number of agents. <br /><br />The results have been disseminated through journal and conference publications, as well as invited talks. This award supported two graduate students, and one of them recently received a job offer for a faculty position based on his work in this project.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/09/2023<br>\n\t\t\t\t\tModified by: Siva Theja&nbsp;Maguluri</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAided by the availability of huge amounts of data and significant computing power, machine learning has led to immense breakthroughs. The immense potential of data analytics to provide benefits to the society in application areas such as health, economics, and finance, is reliant on the fundamental and urgent challenge of protecting privacy of users. In this project, new theoretical paradigms and approaches to address privacy vulnerability of users in network environments in presence of big data and reinforcement learning are studied.\n\nThis project investigates the fundamental limits to anonymization. One setting of interest is the case of correlated databases. More specifically, consider the following setting: There are a large set of entities (e,g, users) with some measurable characteristics with known statistics. We refer to these measures as features. Consider two different sources, each providing a database with lists of features for these entities. Furthermore, let one these sources lack proper labeling for features that would allow for the identification of feature pairs from the two sources that correspond to the same entity. We studied the conditions that allow for the exact-alignment and near-exact alignment of correlated databases.\n\nThe second part of this project is on privacy in reinforcement learning. We develop state-of-the art sample complexity of a large class of actor-critic style reinoforcement learning algorithms, in both tabular and linear function approximation settings under off-policy sampling. We did this by overcoming the infamous deadly triad phenomenon, and also by developing novel analysis to study two time-scale algorithms. We then consider a federated reinforcement learning paradigm where each agent only shares their estimates of parameters and not the data to protect its provacy. We characterize the sample complexity of a large class of reinforcement learning algorithms in this paradigm, and show that there is a linear speed up in the number of agents. \n\nThe results have been disseminated through journal and conference publications, as well as invited talks. This award supported two graduate students, and one of them recently received a job offer for a faculty position based on his work in this project.\n\n\t\t\t\t\tLast Modified: 04/09/2023\n\n\t\t\t\t\tSubmitted by: Siva Theja Maguluri"
 }
}