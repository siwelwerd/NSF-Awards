{
 "awd_id": "1908605",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Small: DataWorld: Externalizing Hidden Data Flows for Situated Analytics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2019-08-15",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-08-02",
 "awd_max_amd_letter_date": "2023-05-31",
 "awd_abstract_narration": "Understanding data from everyday life could help professionals, policymakers, and citizens make our society better, fairer, and more efficient. For example, imagine hunting for a house by walking through the neighborhood in which you want to live and discovering facts about the area from social media, census data, and nearby schools. Alternatively, imagine an architect showing her clients a new office building in its actual location in the city with the wandering sun, ebb and flow of crowds, and waves of car traffic as a backdrop. However, most of collected information cannot be accessed and integrated based on geographical space. This project will investigate how to bridge data and the world from where it was collected by adding visualizations that will make the underlying data visible in the real world by using Augmented Reality (AR). This will help people use the massive troves of data on the internet by literally putting it at their fingertips as part of the world around them. The project will be deployed on a university campus to help students, faculty, and visitors tune in to its \"heartbeat\" of events, alerts, and historical background. Finally, the project will also engage students in refining and contributing to the database, help attract underrepresented students to computing careers, and build a community of researchers interested in the combination of data and geographical place.\r\n\r\nTo achieve these goals, this project will build a framework called DataWorld for creating situated data streams and externalizing them using AR technology. In effect, this will blend the real world with the hidden world of data. This framework will both combine existing data from a wide variety of sources, such as social media, public databases, and popular websites, as well as enable grassroot contributions from DataWorld users. This framework will then be applied to three separate themes. (1) Public safety, where information about crime, emergencies, and current events can help users. (2) History awareness, where the situated data streams will be used to reveal the footsteps of those who came before us, such as placing old newspaper stories in their geographical context, highlighting the struggles -- large and small -- of the civil rights movement, and showing urban development in situ over time. (3) Civic awareness, where the situated data streams can disseminate information about current events, promote sustainability and environmentally-conscious behavior, and facilitate crowdsourced data collection at a grassroots level, fostering a form of \"virtual\" geocaching where data can be hidden in the world. These applications will not only provide new techniques and frameworks that contribute to our knowledge of situated data, data visualization, and Augmented Reality, but will be deployed in practice using the University of Maryland campus as a testbed. The project will generate one or several DataWorld apps, both for handheld devices as well as head-mounted displays, that will enable both contributing grassroot data to the DataWorld platform as well as viewing the data in situ. At the end of the project, an anonymized version of the DataWorld database will be published. Finally, educational material, source code, and documentation will also be released as open source during the project.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Niklas",
   "pi_last_name": "Elmqvist",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Niklas E Elmqvist",
   "pi_email_addr": "elm@umd.edu",
   "nsf_id": "000517418",
   "pi_start_date": "2019-08-02",
   "pi_end_date": "2023-05-31"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Huaishu",
   "pi_last_name": "Peng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Huaishu Peng",
   "pi_email_addr": "huaishu@umd.edu",
   "nsf_id": "000807869",
   "pi_start_date": "2023-05-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland",
  "perf_str_addr": "4130 Campus Drive",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207420001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 319124.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 180876.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Humans are inherently spatial beings, with much of our reasoning deeply connected to our physical embodiment. Everyday decisions related to social interactions, navigation, purchases, personal appearance, and leisure activities are influenced by our physical surroundings&mdash;spanning scales from streets and neighborhoods to cities and countries. Even more abstract or long-term decisions are often shaped by our immediate environments. For example, many people find clarity while walking or exercising, and major life choices, like purchasing a home, are tied to specific physical locations and their attributes. Furthermore, the concept of the workplace is evolving, shifting from traditional offices to more distributed, dynamic environments.</p>\r\n<p>The <em>DataWorld</em> project seeks to harness this inherent spatial reasoning by leveraging consumer-grade wearable augmented and mixed reality (AR/MR) technologies. The project explores how AR/MR can facilitate sensemaking by externalizing and visualizing data streams as situated information flows anchored in their geophysical locations. These spatially contextualized data streams enable users to easily discover, view, and analyze information to address spatial queries effectively.</p>\r\n<p>Research within <em>DataWorld</em> is organized around four interconnected components, focusing on the development of the <em>DataWorld Framework</em> and its applications across domains such as public safety, historical awareness, and civic engagement. Below are examples of projects that illustrate these components:</p>\r\n<p><strong>Wizualization Project</strong>: This initiative introduced a visual analytics system for extended reality, enabling analysts to create and interact with visualizations using gestures, speech commands, and touch inputs. The system operates across devices, including the Hololens 2 HMD and smartphones, demonstrating its adaptability and accessibility.</p>\r\n<p><strong>VisTorch Project</strong>: Expanding the <em>DataWorld Framework</em>, this project utilized a custom-designed handheld MR visualization device called <em>VisTorch</em>. The device allows users to project and view charts within physical spaces by pointing it at surfaces to reveal location-specific visualizations. Applications explored include AR-based museum guiding and environmental education, with expert reviews validating its potential for in-situ visualization.</p>\r\n<p><strong>Datamancer Project</strong>: This project investigated cross-platform, in-situ data analytics using a custom wearable device designed for bimanual gesture interactions. The <em>Datamancer</em> system integrates a finger-mounted pinhole camera and a chest-mounted gesture sensor, enabling users to perform tasks such as panning, zooming, and selection using both hands. The research also examined its applications in collaborative decision-making settings involving multiple large-scale displays, personal computers, and tablets.</p>\r\n<p>Through these projects, <em>DataWorld</em> demonstrates the potential of AR/MR technologies in enabling spatially informed sensemaking and interaction across diverse domains.</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/21/2024<br>\nModified by: Huaishu&nbsp;Peng</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1908605/1908605_10629392_1734799296695_vistorch--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1908605/1908605_10629392_1734799296695_vistorch--rgov-800width.png\" title=\"Vistorch\"><img src=\"/por/images/Reports/POR/2024/1908605/1908605_10629392_1734799296695_vistorch--rgov-66x44.png\" alt=\"Vistorch\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Vistorch hardware</div>\n<div class=\"imageCredit\">Niklas Elmqvist</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Huaishu&nbsp;Peng\n<div class=\"imageTitle\">Vistorch</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1908605/1908605_10629392_1734799324795_datamancer--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1908605/1908605_10629392_1734799324795_datamancer--rgov-800width.png\" title=\"Datamancer overview\"><img src=\"/por/images/Reports/POR/2024/1908605/1908605_10629392_1734799324795_datamancer--rgov-66x44.png\" alt=\"Datamancer overview\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Datamancer overview</div>\n<div class=\"imageCredit\">Niklas Elmqvist</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Huaishu&nbsp;Peng\n<div class=\"imageTitle\">Datamancer overview</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1908605/1908605_10629392_1734799272988_wizulization--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1908605/1908605_10629392_1734799272988_wizulization--rgov-800width.png\" title=\"Wizulization framework\"><img src=\"/por/images/Reports/POR/2024/1908605/1908605_10629392_1734799272988_wizulization--rgov-66x44.png\" alt=\"Wizulization framework\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The core responsibilities\r\nof Wizualization.</div>\n<div class=\"imageCredit\">Niklas Elmqvist</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Huaishu&nbsp;Peng\n<div class=\"imageTitle\">Wizulization framework</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nHumans are inherently spatial beings, with much of our reasoning deeply connected to our physical embodiment. Everyday decisions related to social interactions, navigation, purchases, personal appearance, and leisure activities are influenced by our physical surroundingsspanning scales from streets and neighborhoods to cities and countries. Even more abstract or long-term decisions are often shaped by our immediate environments. For example, many people find clarity while walking or exercising, and major life choices, like purchasing a home, are tied to specific physical locations and their attributes. Furthermore, the concept of the workplace is evolving, shifting from traditional offices to more distributed, dynamic environments.\r\n\n\nThe DataWorld project seeks to harness this inherent spatial reasoning by leveraging consumer-grade wearable augmented and mixed reality (AR/MR) technologies. The project explores how AR/MR can facilitate sensemaking by externalizing and visualizing data streams as situated information flows anchored in their geophysical locations. These spatially contextualized data streams enable users to easily discover, view, and analyze information to address spatial queries effectively.\r\n\n\nResearch within DataWorld is organized around four interconnected components, focusing on the development of the DataWorld Framework and its applications across domains such as public safety, historical awareness, and civic engagement. Below are examples of projects that illustrate these components:\r\n\n\nWizualization Project: This initiative introduced a visual analytics system for extended reality, enabling analysts to create and interact with visualizations using gestures, speech commands, and touch inputs. The system operates across devices, including the Hololens 2 HMD and smartphones, demonstrating its adaptability and accessibility.\r\n\n\nVisTorch Project: Expanding the DataWorld Framework, this project utilized a custom-designed handheld MR visualization device called VisTorch. The device allows users to project and view charts within physical spaces by pointing it at surfaces to reveal location-specific visualizations. Applications explored include AR-based museum guiding and environmental education, with expert reviews validating its potential for in-situ visualization.\r\n\n\nDatamancer Project: This project investigated cross-platform, in-situ data analytics using a custom wearable device designed for bimanual gesture interactions. The Datamancer system integrates a finger-mounted pinhole camera and a chest-mounted gesture sensor, enabling users to perform tasks such as panning, zooming, and selection using both hands. The research also examined its applications in collaborative decision-making settings involving multiple large-scale displays, personal computers, and tablets.\r\n\n\nThrough these projects, DataWorld demonstrates the potential of AR/MR technologies in enabling spatially informed sensemaking and interaction across diverse domains.\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 12/21/2024\n\n\t\t\t\t\tSubmitted by: HuaishuPeng\n"
 }
}