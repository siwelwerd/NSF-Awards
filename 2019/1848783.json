{
 "awd_id": "1848783",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Multiple Object Awareness",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2019-08-07",
 "awd_max_amd_letter_date": "2019-09-07",
 "awd_abstract_narration": "The world is a dynamic place. Objects move, information changes, and human observers need to keep updating their representations of that world in order to continue to function effectively. It is obvious that humans lack the capacity to monitor everything continuously but what is the limit? In classic experiments where people have to track subsets of items as they move around a screen, they seem to be able track 3-4 if all items in the display are identical, and just 2-3 if the items are distinct and they also have to track the identities of the items. However, these numbers seem artificially low, and our personal experience is that our visual awareness is much larger. The key reason seems to be that traditional experimental designs do not account for partial knowledge of items' identity and location. We developed the Multiple Object Awareness (MOA) task to measure this partial knowledge. When we include partial knowledge, it turns out that you know something about 8-12 items, not just 2-4. Why do we care? Many real-world tasks involve being able to rapidly find and interact with multiple items in a changing world. Think of a commander, trying to keep track of his squad and his enemies while monitoring the rest of the action around him or first responders, handling an evolving accident scene. Understanding MOA capacity can impact the design of workplaces (e.g. aircraft cockpits). Moreover, training may improve MOA capacity. If this proves to be the case, then MOA could provide a path to improvement on tasks from monitoring multiple streams of information in an operating room to keeping any eye on your 3rd grade class.\r\n \r\nThe basic MOA tasks, used in this project, are modifications of the Multiple Object Tracking (MOT) and Multiple Identity Tracking (MIT) tasks. Observers monitor a set of moving objects (cartoon animals in our pilot work). The observers are asked to keep track of all of the objects as best they can. Every so often, we cover all items with disks and ask about the location of a specific animal. The crucial innovation is that we ask observers to keep clicking on disks until they find the target animal. As an observer, if you are guessing, you need to click on half the items on average. If you have some idea about the target location, you will need fewer clicks. Based on the number of clicks required, it is possible to derive a MOA capacity estimate of 8-12 items, far greater than MOT or MIT.  Our specific plans are: (1) To screen a large population in order to test the hypothesis that MOA will show a wider natural range of variation than MOT or working memory, (2) to test the hypothesis that MOA is trainable in ways that MOT and working memory are not, and (3) to study MOA in more complex, realistic settings.\r\n\r\nThe Behavioral Systems Cluster in the Division of Integrative Organismal Systems participated in co-funding of the award.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeremy",
   "pi_last_name": "Wolfe",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jeremy M Wolfe",
   "pi_email_addr": "jwolfe@bwh.harvard.edu",
   "nsf_id": "000202279",
   "pi_start_date": "2019-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brigham & Women's Hospital Inc",
  "inst_street_address": "75 FRANCIS ST",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "8572821670",
  "inst_zip_code": "021156110",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "BRIGHAM & WOMENS HOSPITAL INC",
  "org_prnt_uei_num": "KH2QJR76KMZ6",
  "org_uei_num": "QN6MS4VN7BD1"
 },
 "perf_inst": {
  "perf_inst_name": "Brigham & Women's Hospital Inc",
  "perf_str_addr": "75 Francis Street",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021156110",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  },
  {
   "pgm_ele_code": "765900",
   "pgm_ele_name": "Animal Behavior"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The key focus of this work has been the idea that ?partial knowledge is still knowledge?. We investigated this most extensively in the context of multiple object tracking (MOT). In traditional MOT studies, observers (Os) monitor objects as they move around the screen. After some period of tracking, Os are queried about the locations of tracked objects. In a variant of this paradigm, unique objects (e.g. different animals) move around. Then they stop and are hidden behind occluders. Os are asked to indicate the location of specific items (Where is the lion?). This is ?multiple identity tracking? (MIT).&nbsp; Typically, in MOT or MIT experiments, if Os do not indicate exactly the correct location of the queried item, the answer is labeled as ?incorrect?. Under those roles, it is usually found that Os can keep track of 2-4 items. However, this ignores the possibility that the observer, while not exactly correct, knows that the target is roughly ?over there?. This partial knowledge is still knowledge. Our ?multiple object awareness? method measures this partial knowledge by requiring that Os, in an MIT experiment, continue to click on possible locations until they find the target. From the number of clicks required to locate the target, we can calculate a MOA capacity. When Os are trying to keep track of 16 cartoon animals, moving around on the screen, this capacity turns out to be 8-11 items, obviously bigger than the 2-4 item MOT and MIT estimates.</p>\n<p>We investigated three further hypotheses.</p>\n<p>&nbsp;</p>\n<p>1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MOA capacity would be dissociable from MIT/MOT capacity. That is, these would represent two, distinct abilities.</p>\n<p>&nbsp;</p>\n<p>2)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MOA capacity would vary widely in the population with some people showing dramatically high capacity, akin to the capacity of memory savants.</p>\n<p>&nbsp;</p>\n<p>3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Even if high MOA capacity was not seen in the na?ve observer population, it would improve dramatically with practice.</p>\n<p>Each of these is a reasonable thought, based what we know about memory. However, reasonable or not, none of these hypotheses appears to be true.</p>\n<p>&nbsp;</p>\n<p>1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In our work to date, MOA capacity appears to be strongly correlated with MIT capacity. That is, to a first approximation, MOA = k(MIT)</p>\n<p>&nbsp;</p>\n<p>2)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We have not found na?ve Os who appear to have ?super-MOA? capacity.</p>\n<p>&nbsp;</p>\n<p>3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In our training study, half of the Os actually got worse with training (We suspect that</p>\n<p>they basically gave up over the course of a two week training period). The other half improved, but not dramatically.</p>\n<p>&nbsp;</p>\n<p>All of these findings are negative findings, with all the usual drawbacks of negative findings. We can?t prove the negative. We can only say that we have found no evidence for the positive. In all of these cases, COVID restricted our data collection so we are now collecting more data (even if the grant period is over).</p>\n<p>&nbsp;</p>\n<p>Toward the end of the grant period, we developed a new task that we call ?Spatial Massive Memory? (SMM). Humans have the ability to recognize large numbers of pictures of objects or scenes after a few seconds exposure to each one. Clearly, they know WHAT they saw, but do they know WHERE they saw it? This question is clearly related to the MOA question but our methods and our answers turn out to be quite different. Here, our observers viewed groups of objects placed in a 7x7 grid of cells. After seeing 300 objects, they were tested with 600 objects, 300 old and 300 new. If an item was reported to be old, observers were asked to click on its remembered location. An estimate of object-location capacity can be obtained by counting the number of clicks falling in a region surround the object?s original location.</p>\n<p>&nbsp;</p>\n<p>If we labeled as ?correct? answers +/- one cell around objects? true locations and if we subtracted the estimated number of clicks that could have fallen in the same region by chance, our SMM method revealed that observers had knowledge about dozens of items (Exps 1 &amp; 2: mean: 77 items, SD:65), with many observers correctly localizing more than 100 items out of 300. These estimates are obviously far larger than the MOA capacities, described above.</p>\n<p>Interestingly, when we used faces as stimuli, performance was relatively terrible. We think faces are too similar to each other to support SMM.</p>\n<p>&nbsp;</p>\n<p>We also have found evidence for ?temporal massive memory? for when an item was presented. When items were presented one at a time, we could ask Os during the test period to indicate on a timeline when the item was shown the first time. Many Os localized 60-80% of old items to within +/-10% of their correct time, against a 40% average chance/guessing level.</p>\n<p>Why is SMM performance so much better than MOA performance, even if MOA performance is better than MOT/MIT performance? We are pursuing such questions in ongoing work.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/03/2022<br>\n\t\t\t\t\tModified by: Jeremy&nbsp;M&nbsp;Wolfe</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe key focus of this work has been the idea that ?partial knowledge is still knowledge?. We investigated this most extensively in the context of multiple object tracking (MOT). In traditional MOT studies, observers (Os) monitor objects as they move around the screen. After some period of tracking, Os are queried about the locations of tracked objects. In a variant of this paradigm, unique objects (e.g. different animals) move around. Then they stop and are hidden behind occluders. Os are asked to indicate the location of specific items (Where is the lion?). This is ?multiple identity tracking? (MIT).  Typically, in MOT or MIT experiments, if Os do not indicate exactly the correct location of the queried item, the answer is labeled as ?incorrect?. Under those roles, it is usually found that Os can keep track of 2-4 items. However, this ignores the possibility that the observer, while not exactly correct, knows that the target is roughly ?over there?. This partial knowledge is still knowledge. Our ?multiple object awareness? method measures this partial knowledge by requiring that Os, in an MIT experiment, continue to click on possible locations until they find the target. From the number of clicks required to locate the target, we can calculate a MOA capacity. When Os are trying to keep track of 16 cartoon animals, moving around on the screen, this capacity turns out to be 8-11 items, obviously bigger than the 2-4 item MOT and MIT estimates.\n\nWe investigated three further hypotheses.\n\n \n\n1)         MOA capacity would be dissociable from MIT/MOT capacity. That is, these would represent two, distinct abilities.\n\n \n\n2)         MOA capacity would vary widely in the population with some people showing dramatically high capacity, akin to the capacity of memory savants.\n\n \n\n3)         Even if high MOA capacity was not seen in the na?ve observer population, it would improve dramatically with practice.\n\nEach of these is a reasonable thought, based what we know about memory. However, reasonable or not, none of these hypotheses appears to be true.\n\n \n\n1)         In our work to date, MOA capacity appears to be strongly correlated with MIT capacity. That is, to a first approximation, MOA = k(MIT)\n\n \n\n2)         We have not found na?ve Os who appear to have ?super-MOA? capacity.\n\n \n\n3)         In our training study, half of the Os actually got worse with training (We suspect that\n\nthey basically gave up over the course of a two week training period). The other half improved, but not dramatically.\n\n \n\nAll of these findings are negative findings, with all the usual drawbacks of negative findings. We can?t prove the negative. We can only say that we have found no evidence for the positive. In all of these cases, COVID restricted our data collection so we are now collecting more data (even if the grant period is over).\n\n \n\nToward the end of the grant period, we developed a new task that we call ?Spatial Massive Memory? (SMM). Humans have the ability to recognize large numbers of pictures of objects or scenes after a few seconds exposure to each one. Clearly, they know WHAT they saw, but do they know WHERE they saw it? This question is clearly related to the MOA question but our methods and our answers turn out to be quite different. Here, our observers viewed groups of objects placed in a 7x7 grid of cells. After seeing 300 objects, they were tested with 600 objects, 300 old and 300 new. If an item was reported to be old, observers were asked to click on its remembered location. An estimate of object-location capacity can be obtained by counting the number of clicks falling in a region surround the object?s original location.\n\n \n\nIf we labeled as ?correct? answers +/- one cell around objects? true locations and if we subtracted the estimated number of clicks that could have fallen in the same region by chance, our SMM method revealed that observers had knowledge about dozens of items (Exps 1 &amp; 2: mean: 77 items, SD:65), with many observers correctly localizing more than 100 items out of 300. These estimates are obviously far larger than the MOA capacities, described above.\n\nInterestingly, when we used faces as stimuli, performance was relatively terrible. We think faces are too similar to each other to support SMM.\n\n \n\nWe also have found evidence for ?temporal massive memory? for when an item was presented. When items were presented one at a time, we could ask Os during the test period to indicate on a timeline when the item was shown the first time. Many Os localized 60-80% of old items to within +/-10% of their correct time, against a 40% average chance/guessing level.\n\nWhy is SMM performance so much better than MOA performance, even if MOA performance is better than MOT/MIT performance? We are pursuing such questions in ongoing work.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 11/03/2022\n\n\t\t\t\t\tSubmitted by: Jeremy M Wolfe"
 }
}