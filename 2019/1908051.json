{
 "awd_id": "1908051",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS Core: Small: Collaborative Research: Towards Intelligent Multi-User Augmented Reality with Edge Computing",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2019-08-12",
 "awd_max_amd_letter_date": "2019-08-12",
 "awd_abstract_narration": "Augmented reality (AR), which overlays digital content with the real world around a user, has only recently become available to everyday users. AR applications are finding initial adoption in multiple areas including education, medicine, and gaming. Yet, the technology is currently in its infancy, limited in its ability to adapt to user preferences and environmental conditions, and offering restricted multi-user capabilities. Delivering adaptive multi-user AR experiences poses challenges to existing mobile systems and adaptation algorithms. From a mobile systems perspective, AR devices have strict energy and computing constraints and may experience network failures. Algorithmically, existing adaptation algorithms are often based on distributed machine learning, which is not designed to run on constrained AR devices and may not cope well with environment dynamics. This work will leverage edge computing as a solution for the mobile systems challenges, designing system architectures optimized to provide the similar but not identical user experiences required for multi-user AR. The work will also quantify the performance of existing distributed learning approaches under the constraints of multi-user AR, and will develop algorithms that optimize the resulting performance tradeoffs. The work will finally result in a dataset of AR-related inputs, outputs, and system and network resource utilization characteristics, which will be released publicly for the use of a wider community of researchers to validate their work on AR systems and algorithms. \r\n\r\nThis project will enable AR capabilities not possible with existing stand-alone or cloud-supported AR, and will extend the scope of applications of machine learning in AR. The work will allow for the development of new AR applications for education, medicine, retail, and gaming that better engage users through delivering more personalized and dynamic user experiences. The developed solutions will be tested in education-specific settings at Duke Lemur Center, where AR will be used to educate visitors to the center about endangered animals and conservation efforts. The research will be integrated into course curricula at Duke and Carnegie Mellon and will be used as the basis for several undergraduate and graduate independent research projects.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maria",
   "pi_last_name": "Gorlatova",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maria Gorlatova",
   "pi_email_addr": "maria.gorlatova@duke.edu",
   "nsf_id": "000761546",
   "pi_start_date": "2019-08-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277054010",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Augmented reality (AR), a mobile computing technology that integrates 3D digital content with the real-world around a user, has been gaining increasing attention as a promising technology of the future. While AR applications are finding adoption in multiple areas including education, medicine, and gaming, AR still faces multiple limitations that hinder its usability in unconstrained real-world environments.</p>\n<p><br />This project focused on designing, developing, and evaluating solutions that leverage the capabilities of edge computing to enable intelligent and multi-user AR. As part of this research, we identified multiple opportunities for employing edge-based intelligence to enhance semantic and spatial awareness in AR, and have designed, developed, and evaluated edge-supported platforms for a range of AR functions. The solutions we have developed demonstrate the joint potential of edge computing and machine learning in bringing about significant improvements to the quality of AR-captured depth data and the accuracy of the inference of user&rsquo;s cognitive context obtained through AR headset-based eye tracking. We designed, developed, and evaluated a methodology to enhance the performance of AR-based object recognition in scenarios where multiple users are observing the same object. Additionally, we created a first-of-its-kind system that guides AR users in collecting high-quality data to train robust object detection algorithms for a given environment.</p>\n<p>The project has provided opportunities for training&nbsp; more than 35 PhD, MS, undergraduate, and high school students. The research outcomes have been presented at numerous academic and industrial venues. Several unique datasets collected as part of this project have been open-sourced via GitHub.</p><br>\n<p>\n Last Modified: 02/14/2024<br>\nModified by: Maria&nbsp;Gorlatova</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nAugmented reality (AR), a mobile computing technology that integrates 3D digital content with the real-world around a user, has been gaining increasing attention as a promising technology of the future. While AR applications are finding adoption in multiple areas including education, medicine, and gaming, AR still faces multiple limitations that hinder its usability in unconstrained real-world environments.\n\n\n\nThis project focused on designing, developing, and evaluating solutions that leverage the capabilities of edge computing to enable intelligent and multi-user AR. As part of this research, we identified multiple opportunities for employing edge-based intelligence to enhance semantic and spatial awareness in AR, and have designed, developed, and evaluated edge-supported platforms for a range of AR functions. The solutions we have developed demonstrate the joint potential of edge computing and machine learning in bringing about significant improvements to the quality of AR-captured depth data and the accuracy of the inference of users cognitive context obtained through AR headset-based eye tracking. We designed, developed, and evaluated a methodology to enhance the performance of AR-based object recognition in scenarios where multiple users are observing the same object. Additionally, we created a first-of-its-kind system that guides AR users in collecting high-quality data to train robust object detection algorithms for a given environment.\n\n\nThe project has provided opportunities for training more than 35 PhD, MS, undergraduate, and high school students. The research outcomes have been presented at numerous academic and industrial venues. Several unique datasets collected as part of this project have been open-sourced via GitHub.\t\t\t\t\tLast Modified: 02/14/2024\n\n\t\t\t\t\tSubmitted by: MariaGorlatova\n"
 }
}