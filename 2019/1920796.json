{
 "awd_id": "1920796",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Advancing Computational Grounded Theory for Audiovisual Data from STEM Classrooms",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032922296",
 "po_email": "jdbostic@nsf.gov",
 "po_sign_block_name": "Jonathan Bostic",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 1313855.0,
 "awd_amount": 1313855.0,
 "awd_min_amd_letter_date": "2019-08-08",
 "awd_max_amd_letter_date": "2020-01-13",
 "awd_abstract_narration": "This proposal was submitted in response to EHR Core Research (ECR) program announcement NSF 19-508. The ECR program of fundamental research in STEM education provides funding in critical research areas that are essential, broad and enduring. EHR seeks proposals that will help synthesize, build and/or expand research foundations in the following focal areas: STEM learning, STEM learning environments, STEM workforce development, and broadening participation in STEM. The ECR program is distinguished by its emphasis on the accumulation of robust evidence to inform efforts to (a) understand, (b) build theory to explain, and (c) suggest interventions (and innovations) to address persistent challenges in STEM interest, education, learning, and participation.\r\n\r\nThis EHR Core Research project is conducting methodological research on the computational analysis of video data focused on the social and spatial dimensions of STEM learning in classrooms. Video data are complex. They involve visual, acoustic, spatial, and temporal features that can be reduced in several ways. To date, analysis of video data of STEM classrooms has not been able to leverage computational power to take advantage of their richness. However, recent advancements in data science, coupled with existing speech analytics methods, make it possible to computationally identify important features from video in ways that preserve complexity and nuance. These advancements will improve research replicability. The methods developed through this project will facilitate use of sophisticated computational analysis with video data by more researchers. Application of these new methods will help increase the scale and generalizability of video research and lead to the building of new theory. \r\n\r\nThis research project builds on state-of-the-art computer vision and speech analytics methods tested on video data collected in STEM classrooms. It does so within a computational grounded theory methodological framework, which leverages the interpretive power of grounded analytical approaches with the processing power of computational methods. Specifically, two types of computational analysis procedures will be produced: (a) extracting meaningful features from video and audio data of STEM classrooms, and (b) conducting exploratory pattern identification using these extracted features. To develop these procedures, existing large-scale video datasets of STEM classrooms will be used to test and refine increasingly sophisticated analyses, which will also be used to demonstrate the application of these methods to investigate the social and spatial dimensions of STEM classrooms. The project focuses on integrating these methods to improve their power and leverages existing large-scale datasets of STEM classrooms, such that the methods developed can be tested on realistic data. The datasets are extensive enough to support the investigation of a wide range of research questions, including high-inference questions about students' participation in disciplinary practices. Finally, by pairing computational and grounded analytical methods, the project is developing methods that have the potential to enhance and test construct validity of the patterns found in the data.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christina",
   "pi_last_name": "Krist",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christina Krist",
   "pi_email_addr": "stinakrist@stanford.edu",
   "nsf_id": "000756977",
   "pi_start_date": "2019-08-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Cynthia",
   "pi_last_name": "D'Angelo",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Cynthia M D'Angelo",
   "pi_email_addr": "cdangelo@illinois.edu",
   "nsf_id": "000655422",
   "pi_start_date": "2019-08-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Elizabeth",
   "pi_last_name": "Dyer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Elizabeth Dyer",
   "pi_email_addr": "edyer@illinois.edu",
   "nsf_id": "000769847",
   "pi_start_date": "2019-08-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Joshua",
   "pi_last_name": "Rosenberg",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Joshua M Rosenberg",
   "pi_email_addr": "jmrosenberg@utk.edu",
   "nsf_id": "000791354",
   "pi_start_date": "2019-08-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Nigel",
   "pi_last_name": "Bosch",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nigel Bosch",
   "pi_email_addr": "pnb@illinois.edu",
   "nsf_id": "000796696",
   "pi_start_date": "2019-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "506 S. Wright Street",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "798000",
   "pgm_ele_name": "ECR-EDU Core Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8817",
   "pgm_ref_txt": "STEM Learning & Learning Environments"
  }
 ],
 "app_fund": [
  {
   "app_code": "0419",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001920DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 1313855.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project developed computationally-infused methodologies for qualitative analysis of video data of STEM classrooms. Specifically, we developed (1) computational techniques to extract meaningful features from video and audio data; and (2) methodological frameworks and approaches that integrated computational tools in ways that supported the goals of qualitative analysis. Our case examples showcasing our use of these tools and approaches have also contributed to our understanding of learning in the context of mathematical problem solving.</span></p>\r\n<p><strong><span>Intellectual Merit.</span></strong><span>&nbsp;Our project&rsquo;s commitment to centering the goals and values of qualitative research contrasts with predominant uses of computational tools to automate analyses, such as training a computer to code large amounts of qualitative data. While automating analysis might make qualitative research more efficient, we argue that such efficiency is in direct opposition to the broader epistemologies driving qualitative research. Accordingly, instead of using computational tools to code more data more quickly, we have instead used computational tools to construct increasingly rich descriptions of (large amounts of) complex data in ways that allow us to understand the particularities, nuances, and complex processes evident within these data. The goals of such uses of computational tools are to develop new insights; to trouble existing understandings; and to generate new theoretical connections. To this end, we have shown how &ldquo;errors&rdquo; in computational detection, differences in human vs. computer noticing, and &ldquo;outlier&rdquo; moments of particular sets of audio and visual features have been especially important components of our methodological approaches. We position these approaches as explicitly&nbsp;<em><strong>feminist and anti-capitalist</strong></em>&nbsp;in that they expand beyond automation and seek to resist making data analysis more efficient at the expense of particularity, nuance, richness, and complexity.&nbsp;</span></p>\r\n<p><em><strong><span>Technical developments</span></strong></em><strong><span>.</span></strong><span>&nbsp;Building from existing open-source tools for extraction of audio features (OpenSmile) and visual aspects of human skeletal movement (OpenPose), we built custom tools for processing audiovisual data recorded in high school mathematics classrooms. These tools include an algorithm to track unique individuals across frames of video data within OpenPose (Hur &amp; Bosch, 2022); bespoke methods for feature engineering (Hur, Machaka, Krist, &amp; Bosch, 2023); and protocols for merging and syncing extracted audio feature data from OpenSmile (Palaguachi, D&rsquo;Angelo, Dyer, &amp; Machaka, 2024; Cox, Dyer, &amp; Krist, forthcoming).&nbsp;</span></p>\r\n<p><em><strong><span>Methodological developments</span></strong></em><strong><span>.&nbsp;</span></strong><span>We developed a suite of methodological frameworks that provide epistemological and ideological guidance for integrating computational tools to augment qualitative analyses. These frameworks are not uniform; instead, they highlight the breadth of possibilities for careful and creative uses of computational methods in qualitative research. First, and most broadly, the DEFT framework (Distributing Epistemic Functions and Tasks; Kubsch, Krist, &amp; Rosenberg, 2023) challenges researchers to consider the alignment between the goals of their research and the role of the computational tools they choose to use as part of an integrated human-computational system. Second, the CADAs framework (Computationally Assisted Descriptive Approaches; D&rsquo;Angelo, Krist, &amp; Dyer, forthcoming) provides a rationale and guidance for using audio and visual data as additional layers of&nbsp;rich description&nbsp;within analysis, making a dataset more complex and nuanced. Third, two papers present empirical examples of variations on Laura Nelson&rsquo;s (2020) computational grounded theory (CGT)&nbsp;method, &ldquo;remixing&rdquo; the pattern exploration and data interpretation phases of CGT&nbsp;(Hur,&nbsp;Palaguachi, Machaka, Dyer, D&rsquo;Angelo, &amp; Bosch, forthcoming; Krist, Dyer, &amp; Hall, forthcoming). Finally, in a forthcoming manuscript and 2025 AERA Presidential Session (Krist, Dyer, Rosenberg, &amp; Cox), we articulate the ideological tensions we encountered throughout the project. Namely, we note that most computational tools and their associated metrics for rigor, reliability, accuracy, etc., have been developed with goals of automation and efficiency in mind. When we intentionally sought to subvert those goals, we were faced with new tensions and sets of decisions around when, why, and how to deploy various computational tools. We discuss those dilemmas and provide guidance for others as they grapple with similar tensions and decisions.</span></p>\r\n<p><strong><span>Broader Impacts.</span></strong><span>&nbsp;Our work has been disseminated broadly through a range of venues, including 8 empirical journal articles; 12 terminal conference proceedings; 14 conference presentations; 2 invited keynote presentations; 4 workshops; and an open-access textbook on integrating machine learning in science education research co-edited by PI Krist and including 5 chapters contributed by project team members. Our project website includes all workshop materials and a link to our github repository.</span></p>\r\n<p><span>Our frameworks hold broad applicability beyond the integration of computational tools focused on audio and visual features of data. For example, ChatGPT and generative AI rapidly emerged and gained popularity midway through the life of the project. We have continually responded to the AI &ldquo;boom&rdquo; with critical optimism, presenting our approaches and frameworks to challenge the field to proceed with caution (or to avoid altogether) when attempting automation in research. Our responses demonstrate our frameworks&rsquo; relevance and applicability to developing methodologies that infuse a broad range of computational tools into qualitative research.</span></p><br>\n<p>\n Last Modified: 01/02/2025<br>\nModified by: Christina&nbsp;Krist</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project developed computationally-infused methodologies for qualitative analysis of video data of STEM classrooms. Specifically, we developed (1) computational techniques to extract meaningful features from video and audio data; and (2) methodological frameworks and approaches that integrated computational tools in ways that supported the goals of qualitative analysis. Our case examples showcasing our use of these tools and approaches have also contributed to our understanding of learning in the context of mathematical problem solving.\r\n\n\nIntellectual Merit.Our projects commitment to centering the goals and values of qualitative research contrasts with predominant uses of computational tools to automate analyses, such as training a computer to code large amounts of qualitative data. While automating analysis might make qualitative research more efficient, we argue that such efficiency is in direct opposition to the broader epistemologies driving qualitative research. Accordingly, instead of using computational tools to code more data more quickly, we have instead used computational tools to construct increasingly rich descriptions of (large amounts of) complex data in ways that allow us to understand the particularities, nuances, and complex processes evident within these data. The goals of such uses of computational tools are to develop new insights; to trouble existing understandings; and to generate new theoretical connections. To this end, we have shown how errors in computational detection, differences in human vs. computer noticing, and outlier moments of particular sets of audio and visual features have been especially important components of our methodological approaches. We position these approaches as explicitlyfeminist and anti-capitalistin that they expand beyond automation and seek to resist making data analysis more efficient at the expense of particularity, nuance, richness, and complexity.\r\n\n\nTechnical developments.Building from existing open-source tools for extraction of audio features (OpenSmile) and visual aspects of human skeletal movement (OpenPose), we built custom tools for processing audiovisual data recorded in high school mathematics classrooms. These tools include an algorithm to track unique individuals across frames of video data within OpenPose (Hur & Bosch, 2022); bespoke methods for feature engineering (Hur, Machaka, Krist, & Bosch, 2023); and protocols for merging and syncing extracted audio feature data from OpenSmile (Palaguachi, DAngelo, Dyer, & Machaka, 2024; Cox, Dyer, & Krist, forthcoming).\r\n\n\nMethodological developments.We developed a suite of methodological frameworks that provide epistemological and ideological guidance for integrating computational tools to augment qualitative analyses. These frameworks are not uniform; instead, they highlight the breadth of possibilities for careful and creative uses of computational methods in qualitative research. First, and most broadly, the DEFT framework (Distributing Epistemic Functions and Tasks; Kubsch, Krist, & Rosenberg, 2023) challenges researchers to consider the alignment between the goals of their research and the role of the computational tools they choose to use as part of an integrated human-computational system. Second, the CADAs framework (Computationally Assisted Descriptive Approaches; DAngelo, Krist, & Dyer, forthcoming) provides a rationale and guidance for using audio and visual data as additional layers ofrich descriptionwithin analysis, making a dataset more complex and nuanced. Third, two papers present empirical examples of variations on Laura Nelsons (2020) computational grounded theory (CGT)method, remixing the pattern exploration and data interpretation phases of CGT(Hur,Palaguachi, Machaka, Dyer, DAngelo, & Bosch, forthcoming; Krist, Dyer, & Hall, forthcoming). Finally, in a forthcoming manuscript and 2025 AERA Presidential Session (Krist, Dyer, Rosenberg, & Cox), we articulate the ideological tensions we encountered throughout the project. Namely, we note that most computational tools and their associated metrics for rigor, reliability, accuracy, etc., have been developed with goals of automation and efficiency in mind. When we intentionally sought to subvert those goals, we were faced with new tensions and sets of decisions around when, why, and how to deploy various computational tools. We discuss those dilemmas and provide guidance for others as they grapple with similar tensions and decisions.\r\n\n\nBroader Impacts.Our work has been disseminated broadly through a range of venues, including 8 empirical journal articles; 12 terminal conference proceedings; 14 conference presentations; 2 invited keynote presentations; 4 workshops; and an open-access textbook on integrating machine learning in science education research co-edited by PI Krist and including 5 chapters contributed by project team members. Our project website includes all workshop materials and a link to our github repository.\r\n\n\nOur frameworks hold broad applicability beyond the integration of computational tools focused on audio and visual features of data. For example, ChatGPT and generative AI rapidly emerged and gained popularity midway through the life of the project. We have continually responded to the AI boom with critical optimism, presenting our approaches and frameworks to challenge the field to proceed with caution (or to avoid altogether) when attempting automation in research. Our responses demonstrate our frameworks relevance and applicability to developing methodologies that infuse a broad range of computational tools into qualitative research.\t\t\t\t\tLast Modified: 01/02/2025\n\n\t\t\t\t\tSubmitted by: ChristinaKrist\n"
 }
}