{
 "awd_id": "1910993",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Enabling Sound-based Human Activity Monitoring for Home Service Robots",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 488692.0,
 "awd_amount": 488692.0,
 "awd_min_amd_letter_date": "2019-09-06",
 "awd_max_amd_letter_date": "2019-09-06",
 "awd_abstract_narration": "The increasing demand for in-home elderly care involves challenges that call for innovative solutions. As more older adults prefer to live in their own homes as they age, living alone may pose serious risks to those who have age-related problems such as reduced mobility, dementia, or other chronic diseases.  This at-risk population needs regular visits from in-home healthcare services, which in turn creates pressure on the geriatric home healthcare industry. Home service robots offer a solution to this societal problem by facilitating smart aging-in-place. This project aims to solve a fundamental research problem critical to the application of service robots in complex home environments: human activity monitoring. By creating a bridge between environmental understanding and human behavior understanding, this project offers a new theory to realize sound-based monitoring of resident behaviors in realistic home environments. Such a human-aware capability frees home service robots to do their daily routine work, while being able to care for the resident more proactively and effectively. Sound-based human behavior understanding will greatly improve the capability and usability of home service robots, therefore accelerating their adoption in human daily life. This project also incorporates education and outreach activities to stimulate prospective and current college students to pursue degrees and careers in science and engineering, attract underrepresented minority students to these research activities, and to disseminate new, useful datasets to the research community and home healthcare industry to promote continued advances in this area.\r\n \r\nThis project investigates a new theoretical framework for human activity monitoring in home environments, which takes advantage of deep learning while considering the locational context, thereby greatly improving the accuracy of human behavior understanding. The target framework is intended for broader application to similar deep learning-based machine perception problems.  The project aims to establish a novel visual-acoustic semantic map (VASM) to connect environmental understanding and behavior understanding. Constructed through robotic semantic mapping and voice-based human-robot interaction, the VASM concept extends traditional visual semantic maps by incorporating rich acoustic information in the environment.  When cloud-connected and scaled up to a large number of robots, this approach is expected to provide an effective and distributed solution to constructing a large dataset with annotated home event sounds.  That dataset will then be used to train deep neural networks for sound event recognition. The project also develops a multi-sensor fusion approach to combining sound data with distributed motion sensor data to solve the problem of human activity recognition without using visual sensors.  Such an approach overcomes the shortcomings associated with vision sensors and offers a fundamentally different solution to human activity monitoring.  Finally, the planned theoretical framework will be verified and evaluated through experiments in a robot-integrated smart home.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Weihua",
   "pi_last_name": "Sheng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Weihua Sheng",
   "pi_email_addr": "weihua.sheng@okstate.edu",
   "nsf_id": "000321508",
   "pi_start_date": "2019-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Oklahoma State University",
  "inst_street_address": "401 WHITEHURST HALL",
  "inst_street_address_2": "",
  "inst_city_name": "STILLWATER",
  "inst_state_code": "OK",
  "inst_state_name": "Oklahoma",
  "inst_phone_num": "4057449995",
  "inst_zip_code": "740781031",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OK03",
  "org_lgl_bus_name": "OKLAHOMA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNYDFK5FTSX9"
 },
 "perf_inst": {
  "perf_inst_name": "Oklahoma State University",
  "perf_str_addr": "101 WHITEHURST HALL",
  "perf_city_name": "Stillwater",
  "perf_st_code": "OK",
  "perf_st_name": "Oklahoma",
  "perf_zip_code": "740781011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OK03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 488692.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this research is to develop robust robot intelligence for human activity monitoring in realistic home environments using non-visual data, mainly sounds and locational context.&nbsp;</p>\n<p>&nbsp;The research findings of this project are:</p>\n<p>1) &nbsp;This project developed two prototypes of home service robots: one mobile robot and one tabletop robot.&nbsp;&nbsp;The mobile robot is capable of 3D environment mapping and semantic understanding in both autonomous and human-robot collaborative modes.&nbsp;</p>\n<p>2) &nbsp;The work reveals that it is feasible for a robot to accurately recognize most of the daily activities in a home environment by fusing sound data and locational context.&nbsp;&nbsp;The activity recognition is achieved in a framework of sound-based human activity monitoring (SoHAM) which consists of a context-aware sound event recognition (CoSER) module, a dynamic time window-based human action recognition (DTW-HaR) module, and a conditional random field (CRF)-based activity monitoring module.&nbsp;</p>\n<p>3) &nbsp;This work shows that the range of human activity monitoring can be extended by paring the robot with a wearable device on the human body, which is implemented through multi-modal sensor fusion using a Dynamic Bayesian Network (DBN).&nbsp;</p>\n<p>4) &nbsp;This work created an open dataset called HomeSoundNet, which consists of various sound events&nbsp;&nbsp;of daily activities that occur in home environments. The current dateset has&nbsp;36 types of sound events&nbsp;with a total of 42,685 audio segments. This dataset is made available to the research community for work related to human activity recognition in home environments.&nbsp;</p>\n<p>The broader impacts of this project are:&nbsp;</p>\n<p>1) &nbsp;This project provides precious opportunities to train graduate students in conducting research in multiple disciplines including artificial intelligence, signal processing,&nbsp;&nbsp;and robotics.&nbsp;&nbsp;Three Ph.D students, one master student and one undergraduate student were supported. The main research skills that students have gained from this project are: a) robot design and implementation with a focus on embedded system design and mechanical body design; b) software programming skills and network programming skills that involve Cloud computing; c) signal processing skills that involve audio processing and data fusion; d) AI and machine learning skills that involve Hidden Markov Models, Dynamic Bayesian Networks and deep neural networks; e) experiment design, data collection and analysis; f) conducting user study and interview with human subjects.</p>\n<p>2) &nbsp;This project resulted in 1 book chapter, 14 journal papers, 6 conference papers over the period of this project.&nbsp;</p>\n<p>3) &nbsp;The developed robots provide an excellent platform of collaboration for the PI and his collaborators to explore new robotic elderly care technologies and secure new fundings for potential commercialization. Led by the PI, a special issue on Homecare Robots in IEEE Robotics and Automation Magazine was organized.&nbsp;</p>\n<p>4) &nbsp;This project significantly strengthens the educational capabilities of the PIs in teaching both undergraduate and graduate courses in multiple disciplines. This project helps create an instructional infrastructure that provides students hands-on experiences in multiple topic areas including artificial intelligence, embedded computing, and internet of things.&nbsp;</p>\n<p>5) &nbsp;The project allowed the PI and his collaborators to reach out to older adults and healthcare professionals in local communities, which helped educate the potential users of robot and smart home technologies. The STEM robotics summer camp provided precious learning experience for 8-12 graders in computer programming and basics of mobile robotics, helping ignite their interest in computer science and electrical and engineering.&nbsp;&nbsp;It is also found that age-appropriate themes and competitions can make the summer camps more attractive to K-12 students. Our work on the Robotics Summer Camp has been published in an article in IEEE Potential.&nbsp;&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/28/2024<br>\nModified by: Weihua&nbsp;Sheng</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1910993/1910993_10640470_1706459625487_framework--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/1910993/1910993_10640470_1706459625487_framework--rgov-800width.jpg\" title=\"Framework\"><img src=\"/por/images/Reports/POR/2024/1910993/1910993_10640470_1706459625487_framework--rgov-66x44.jpg\" alt=\"Framework\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The overall framework of sound-based human activity monitoring.</div>\n<div class=\"imageCredit\">Weihua Sheng</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Weihua&nbsp;Sheng\n<div class=\"imageTitle\">Framework</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1910993/1910993_10640470_1706459389221_robots--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/1910993/1910993_10640470_1706459389221_robots--rgov-800width.jpg\" title=\"Robots\"><img src=\"/por/images/Reports/POR/2024/1910993/1910993_10640470_1706459389221_robots--rgov-66x44.jpg\" alt=\"Robots\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The two robots for this project: a tabletop companion robot (left) and a mobile robot (right).</div>\n<div class=\"imageCredit\">Weihua Sheng</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Weihua&nbsp;Sheng\n<div class=\"imageTitle\">Robots</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe goal of this research is to develop robust robot intelligence for human activity monitoring in realistic home environments using non-visual data, mainly sounds and locational context.\n\n\nThe research findings of this project are:\n\n\n1) This project developed two prototypes of home service robots: one mobile robot and one tabletop robot.The mobile robot is capable of 3D environment mapping and semantic understanding in both autonomous and human-robot collaborative modes.\n\n\n2) The work reveals that it is feasible for a robot to accurately recognize most of the daily activities in a home environment by fusing sound data and locational context.The activity recognition is achieved in a framework of sound-based human activity monitoring (SoHAM) which consists of a context-aware sound event recognition (CoSER) module, a dynamic time window-based human action recognition (DTW-HaR) module, and a conditional random field (CRF)-based activity monitoring module.\n\n\n3) This work shows that the range of human activity monitoring can be extended by paring the robot with a wearable device on the human body, which is implemented through multi-modal sensor fusion using a Dynamic Bayesian Network (DBN).\n\n\n4) This work created an open dataset called HomeSoundNet, which consists of various sound eventsof daily activities that occur in home environments. The current dateset has36 types of sound eventswith a total of 42,685 audio segments. This dataset is made available to the research community for work related to human activity recognition in home environments.\n\n\nThe broader impacts of this project are:\n\n\n1) This project provides precious opportunities to train graduate students in conducting research in multiple disciplines including artificial intelligence, signal processing,and robotics.Three Ph.D students, one master student and one undergraduate student were supported. The main research skills that students have gained from this project are: a) robot design and implementation with a focus on embedded system design and mechanical body design; b) software programming skills and network programming skills that involve Cloud computing; c) signal processing skills that involve audio processing and data fusion; d) AI and machine learning skills that involve Hidden Markov Models, Dynamic Bayesian Networks and deep neural networks; e) experiment design, data collection and analysis; f) conducting user study and interview with human subjects.\n\n\n2) This project resulted in 1 book chapter, 14 journal papers, 6 conference papers over the period of this project.\n\n\n3) The developed robots provide an excellent platform of collaboration for the PI and his collaborators to explore new robotic elderly care technologies and secure new fundings for potential commercialization. Led by the PI, a special issue on Homecare Robots in IEEE Robotics and Automation Magazine was organized.\n\n\n4) This project significantly strengthens the educational capabilities of the PIs in teaching both undergraduate and graduate courses in multiple disciplines. This project helps create an instructional infrastructure that provides students hands-on experiences in multiple topic areas including artificial intelligence, embedded computing, and internet of things.\n\n\n5) The project allowed the PI and his collaborators to reach out to older adults and healthcare professionals in local communities, which helped educate the potential users of robot and smart home technologies. The STEM robotics summer camp provided precious learning experience for 8-12 graders in computer programming and basics of mobile robotics, helping ignite their interest in computer science and electrical and engineering.It is also found that age-appropriate themes and competitions can make the summer camps more attractive to K-12 students. Our work on the Robotics Summer Camp has been published in an article in IEEE Potential.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 01/28/2024\n\n\t\t\t\t\tSubmitted by: WeihuaSheng\n"
 }
}