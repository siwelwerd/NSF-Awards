{
 "awd_id": "1909067",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS Core: Small: Multi-Scale GPU Resource Management for AI Applications",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jason Hallstrom",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 462704.0,
 "awd_amount": 462704.0,
 "awd_min_amd_letter_date": "2019-05-29",
 "awd_max_amd_letter_date": "2019-05-29",
 "awd_abstract_narration": "As an increasing amount of data, such as text, audio, and video, are collected from many sources, the need to better understand the collected data is increasing as well.  The analysis of large datasets has evolved into complex artificial intelligence (AI) techniques in recent years. This is because the need has expanded from just a human analyzing the data to enabling a machine to make sense of it on its own. The overarching goal of this project is to enable such AI applications - specifically, deep learning - to become more efficient.\r\n\r\nGraphics Processing Units (GPUs) are often used in AI applications like those mentioned above.  This project addresses the fundamental limitations in resource management in modern GPUs. To this end, this project plans to take a holistic approach with three broad focus areas: (1) fine-grained sharing of individual GPUs; (2) coarse-grained sharing of a GPU cluster; and (3) dynamic readjustments to mitigate the impact of communication on distributed deep learning. The core techniques include temporal scheduling and spatial resource allocation with partial or no knowledge of job durations or workload characteristics. Algorithms designed as part of this project will have applications beyond simply running AI applications on GPU clusters. \r\n\r\nIncreasing GPU efficiency will help reduce the cost of using AI, leading to pervasive use of deep learning techniques. This will enable new applications of AI in emerging domains such as augmented/virtual reality and real-time interactive video analytics, while making them more cost-effective. The project includes plans to work with industry to translate the research into practice and to include its outcomes in graduate/undergraduate curricula. Lastly, it will build upon already-established outreach activities at the University of Michigan to help better convey the impact of AI on society to diverse student population groups and the general public. \r\n\r\nAll code and data generated and collected for this project, including software systems, simulators, and emulators, will be made available to the public as open-source resources at https://github.com/symbioticlab. They will be will be retained for at least the duration of the project.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mosharaf",
   "pi_last_name": "Chowdhury",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mosharaf Chowdhury",
   "pi_email_addr": "mosharaf@umich.edu",
   "nsf_id": "000702601",
   "pi_start_date": "2019-05-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "2260 Hayward",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092121",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 462704.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-d3cfe8c4-7fff-bc58-d1a5-82899d644592\"> </span></p>\n<p dir=\"ltr\"><span>With the meteoric rise of deep learning (DL) over the past decade, GPU clusters have emerged as a popular choice for training and doing inference on AI models. The overarching goal of this project was to achieve cost-effectiveness in GPU clusters via efficiently sharing resources between multiple users. To this end, over the course of the past four years, we have built a collection of software tools that increase resource efficiency of deep learning models throughout their entire lifecycle. Our work laid the groundwork for efficient resource management for the recently emerging large AI models.</span></p>\n<p dir=\"ltr\"><span>To enable fine-grained sharing of individual GPUs, we developed </span>Salus<span> and </span><span>Fluid</span><span>. <strong>Salus</strong> is a general-purpose solution that provides flexible scheduling policies among co-existing DL jobs. It enables </span><em>fast job switching</em><span>&nbsp;by distinguishing between different types of memory usage in DL applications, while it enables&nbsp;<em>GPU memory sharing&nbsp;</em>by partitioning memory into virtual lanes. Combining the two primitives, we have built several scheduling and packing solutions for training, inference, and hyperparameter tuning jobs. </span><span>Salus can improve the average completion time of DL training jobs by 3.19X, GPU utilization for hyper-parameter tuning by 2.38X, and GPU utilization of DL inference applications by 7X w.r.t. NVIDIA MPS with small overhead.&nbsp;</span></p>\n<p dir=\"ltr\"><span><strong>Fluid</strong>, in contrast, takes a co-design approach where it leverages the characteristics of hyperparameter tuning algorithms to better utilize GPUs. A hyperparameter tuning job contains a large group of training </span><span>trials</span><span>, each with its own configuration. Unfortunately, current hyperparameter tuning solutions cannot efficiently leverage distributed computation. We observed that the root cause of the suboptimal use of resources in current hyperparameter tuning solutions is their indifference to how trials are executed. Fluid decouples the execution strategy from hyperparameter tuning algorithms into a separate execution engine and performs algorithm- and resource-aware hyperparameter tuning by coordinating between the GPU cluster and hyperparameter tuning algorithms. Extensive evaluation showed that </span><span>Fluid can speed up state-of-the-art hyperparameter solutions like synchronous BOHB, BOHB, and ASHA by up to 100% while having similar final accuracy.</span></p>\n<p>At the GPU cluster granularity, our research focused on better scheduling of cluster resources. Most modern DL frameworks support heterogeneous computation devices (e.g., GPUs, CPUs, FPGAs, and TPUs). It is possible to use them in an interchangeable manner by maintaining multiple configurations in cluster managers such as Kubernetes. We focused on how to pick the best combination of resources for a collection of jobs submitted by different users. This leads to both theoretical and practical challenges. From a theoretical perspective, we needed to extend existing multi-resource sharing algorithms to support interchangeable resources. From a practical perspective, we determined how to profile jobs to run them efficiently. We addressed these challenges in a system called <strong>AlloX</strong> that provides a novel algorithm and implementation. Evaluations on CPU-GPU hybrid clusters and large-scale simulations showed that AlloX can reduce the average job completion time significantly (by up to 95% when the system load is high) while providing fairness and preventing starvation.&nbsp;</p>\n<p dir=\"ltr\"><span>Finally, we looked into how to keep GPU clusters highly utilized even when failures happen in large model training jobs. As model and dataset sizes increase, </span><span>the likelihood of experiencing training failures increases too. Failure rates are even higher for training jobs that use spot instances in the cloud. Existing frameworks have little systematic support for fault tolerance, where all GPUs idle until failure recovery happens. In </span><strong>Oobleck</strong><span>, we presented a fault-tolerant hybrid-parallel training framework that provides high training throughput, guaranteed fault tolerance, and fast recovery without introducing additional overhead. We evaluated Oobleck on large models like GPT-3 with billions of parameters and found that Oobleck outperforms the state-of-the-art solutions by up to 29.6X.</span></p>\n<p dir=\"ltr\"><span>Apart from these major achievements, we also explored a variety of research challenges that attempted to increase the efficiency of GPU resources that ranged from minimizing the amount of computation needed by freezing layers within a model and transferring knowledge across models with similar architectures as well as focusing on specific types of workloads such as neural architecture search and specific types of models such recommendation models.&nbsp;</span></p>\n<p dir=\"ltr\"><span>All software developed as part of this project is based on established open-source systems, and we continue to open-source our works at </span><a href=\"https://github.com/symbioticlab\"><span>https://github.com/symbioticlab</span></a><span>. Research papers summarizing our works have been published or are under submission in top venues in networking and systems including NSDI, OSDI, SOSP, and MLSys. We created a new course called </span><strong>Systems for AI</strong><span> in Michigan CSE. Some of the works have been incorporated into course contents in graduate- and undergraduate-level systems and networking courses. Last but not the least, two PhD students at the University of Michigan have graduated, joining industry and academia, and many undergraduate and graduate students have learned from working on different smaller components of the various research projects.</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/11/2023<br>\nModified by: Mosharaf&nbsp;Chowdhury</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nWith the meteoric rise of deep learning (DL) over the past decade, GPU clusters have emerged as a popular choice for training and doing inference on AI models. The overarching goal of this project was to achieve cost-effectiveness in GPU clusters via efficiently sharing resources between multiple users. To this end, over the course of the past four years, we have built a collection of software tools that increase resource efficiency of deep learning models throughout their entire lifecycle. Our work laid the groundwork for efficient resource management for the recently emerging large AI models.\n\n\nTo enable fine-grained sharing of individual GPUs, we developed Salus and Fluid. Salus is a general-purpose solution that provides flexible scheduling policies among co-existing DL jobs. It enables fast job switchingby distinguishing between different types of memory usage in DL applications, while it enablesGPU memory sharingby partitioning memory into virtual lanes. Combining the two primitives, we have built several scheduling and packing solutions for training, inference, and hyperparameter tuning jobs. Salus can improve the average completion time of DL training jobs by 3.19X, GPU utilization for hyper-parameter tuning by 2.38X, and GPU utilization of DL inference applications by 7X w.r.t. NVIDIA MPS with small overhead.\n\n\nFluid, in contrast, takes a co-design approach where it leverages the characteristics of hyperparameter tuning algorithms to better utilize GPUs. A hyperparameter tuning job contains a large group of training trials, each with its own configuration. Unfortunately, current hyperparameter tuning solutions cannot efficiently leverage distributed computation. We observed that the root cause of the suboptimal use of resources in current hyperparameter tuning solutions is their indifference to how trials are executed. Fluid decouples the execution strategy from hyperparameter tuning algorithms into a separate execution engine and performs algorithm- and resource-aware hyperparameter tuning by coordinating between the GPU cluster and hyperparameter tuning algorithms. Extensive evaluation showed that Fluid can speed up state-of-the-art hyperparameter solutions like synchronous BOHB, BOHB, and ASHA by up to 100% while having similar final accuracy.\n\n\nAt the GPU cluster granularity, our research focused on better scheduling of cluster resources. Most modern DL frameworks support heterogeneous computation devices (e.g., GPUs, CPUs, FPGAs, and TPUs). It is possible to use them in an interchangeable manner by maintaining multiple configurations in cluster managers such as Kubernetes. We focused on how to pick the best combination of resources for a collection of jobs submitted by different users. This leads to both theoretical and practical challenges. From a theoretical perspective, we needed to extend existing multi-resource sharing algorithms to support interchangeable resources. From a practical perspective, we determined how to profile jobs to run them efficiently. We addressed these challenges in a system called AlloX that provides a novel algorithm and implementation. Evaluations on CPU-GPU hybrid clusters and large-scale simulations showed that AlloX can reduce the average job completion time significantly (by up to 95% when the system load is high) while providing fairness and preventing starvation.\n\n\nFinally, we looked into how to keep GPU clusters highly utilized even when failures happen in large model training jobs. As model and dataset sizes increase, the likelihood of experiencing training failures increases too. Failure rates are even higher for training jobs that use spot instances in the cloud. Existing frameworks have little systematic support for fault tolerance, where all GPUs idle until failure recovery happens. In Oobleck, we presented a fault-tolerant hybrid-parallel training framework that provides high training throughput, guaranteed fault tolerance, and fast recovery without introducing additional overhead. We evaluated Oobleck on large models like GPT-3 with billions of parameters and found that Oobleck outperforms the state-of-the-art solutions by up to 29.6X.\n\n\nApart from these major achievements, we also explored a variety of research challenges that attempted to increase the efficiency of GPU resources that ranged from minimizing the amount of computation needed by freezing layers within a model and transferring knowledge across models with similar architectures as well as focusing on specific types of workloads such as neural architecture search and specific types of models such recommendation models.\n\n\nAll software developed as part of this project is based on established open-source systems, and we continue to open-source our works at https://github.com/symbioticlab. Research papers summarizing our works have been published or are under submission in top venues in networking and systems including NSDI, OSDI, SOSP, and MLSys. We created a new course called Systems for AI in Michigan CSE. Some of the works have been incorporated into course contents in graduate- and undergraduate-level systems and networking courses. Last but not the least, two PhD students at the University of Michigan have graduated, joining industry and academia, and many undergraduate and graduate students have learned from working on different smaller components of the various research projects.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 12/11/2023\n\n\t\t\t\t\tSubmitted by: MosharafChowdhury\n"
 }
}