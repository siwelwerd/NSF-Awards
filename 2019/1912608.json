{
 "awd_id": "1912608",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FoMR: Speculative Super-optimization: Boosting Performance via Speculation-Driven Dynamic Binary Optimization",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Danella Zhao",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 216000.0,
 "awd_min_amd_letter_date": "2019-08-14",
 "awd_max_amd_letter_date": "2020-06-16",
 "awd_abstract_narration": "Modern processors are characterized by increasing 'core' counts on a single multi-core processor, where a 'core' is a computing unit, allowing each core to operate in parallel to, and independently of, other cores on the processor. Yet, a substantial chunk of software applications is inherently sequential.  Although modern compilers feature sophisticated optimizations, significant waste of computational resources across these multiple-cores still occurs due to computational patterns that are unpredictable at compile-time.  This project explores techniques to deploy aggressive speculative dynamic optimizations within the micro-processor, enabling continuous optimization of inherently sequential code.  This work addresses a pressing need for systems that can aggressively and yet seamlessly super-optimize machine code, adapting to the dynamic execution environment, and thereby speed up execution of applications on computers.  This research will also foster existing efforts and initiatives of the investigators to build a pipeline of students from diverse backgrounds.\r\n\r\nThis project explores dynamic binary optimization techniques at the processor level to speculatively generate and execute a super-optimized instruction stream, by leveraging established speculative processor features such as branch prediction, value prediction, and loop stream detection.  This project introduces two distinct flavors of speculative super-optimization: (a) a hardware implementation that leverages dynamically predicted program state to perform simple, yet powerful peephole optimizations on short instruction sequences, and (b) a firmware implementation that leverages a microcode-based dynamic re-compiler running as a helper thread to perform more sophisticated optimizations.  Owing to the plethora of speculative processor features and compiler/runtime/hardware optimizations to choose from, this project explores a rich sample space of speculative super-optimization strategies, along with extensive profitability analysis to dynamically identify appropriate targets for super-optimization.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ashish",
   "pi_last_name": "Venkat",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ashish Venkat",
   "pi_email_addr": "av6ds@virginia.edu",
   "nsf_id": "000784372",
   "pi_start_date": "2019-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kevin",
   "pi_last_name": "Skadron",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kevin Skadron",
   "pi_email_addr": "skadron@cs.virginia.edu",
   "nsf_id": "000393383",
   "pi_start_date": "2019-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Virginia Main Campus",
  "inst_street_address": "1001 EMMET ST N",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTESVILLE",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "4349244270",
  "inst_zip_code": "229034833",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "VA05",
  "org_lgl_bus_name": "RECTOR & VISITORS OF THE UNIVERSITY OF VIRGINIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJG6HU8PA4S5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Virginia Main Campus",
  "perf_str_addr": "PO Box 400740",
  "perf_city_name": "Charlottesville",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "229044195",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "VA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "021Z",
   "pgm_ref_txt": "Industry Partnerships"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "8585",
   "pgm_ref_txt": "NSF/Intel Partnership Projects"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 200000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Modern workloads feature data-dependent computation and control flow patterns that often vary considerably with changing datasets and configuration parameters. This has greatly reduced the effectiveness of conventional compiler optimizations that rely on hoisting program invariants identifiable at compile-time to eliminate redundant computation and further apply machine-specific optimizations to the residual code.&nbsp; Run-time optimizations have largely been profile-guided and conservative in nature, limiting their ability to adapt to changing execution profiles as datasets evolve, notwithstanding high profiling overheads.</p>\n<p>The project makes the key&nbsp;observation that modern datasets offer remarkable predictability, because data access and control flow patterns in many workload-dataset pairs manifest as invariants across long execution intervals, unmasking an untapped pocket of opportunity for speculatively optimizing such code paths at run-time, by exposing and eliminating dead code, entirely within the processor, based on dynamically predicted data and control invariants, enabling the continuous optimization of inherently sequential code, without the need for profiling, compiler metadata, or other source-level information.</p>\n<p>Speculative Superoptimization&nbsp;is a minimally-invasive, prediction-driven microarchitectural technique that advances state-of-the-art dynamic binary optimization schemes in several important ways. First, it leverages the rich contextual knowledge available from a wide array of in-processor speculation techniques such as branch prediction, address prediction, and value prediction to track deterministic computational patterns in hot code regions and further transform an instruction sequence in execution into a compact stream of speculatively optimized instructions.&nbsp; Second, it opens the door to the deployment of aggressive and speculative optimization techniques that have been traditionally deemed unsafe, thanks to the processor's ability to rollback execution to a safe point in the event of a misprediction by flushing speculatively optimized instructions and redirecting execution to the corresponding stream of unoptimized instructions that are co-hosted in the processor's micro-op cache.&nbsp; Third, by exploiting predictability as the basis for optimization, it offers seamless adaptability to changing datasets and workload patterns, unlike existing runtime optimizations employed by software giants such as Google, Microsoft, and Meta that either require extensive profiling or tend to make conservative assumptions when they lack adequate context about the dynamic execution behavior.</p>\n<p><span>The results from this work have been disseminated through top-tier conference and journal publications, such as MICRO, ISCA, and USENIX Security, and through tech talks at industry and academic institutions alike.&nbsp; In addition, the software artifacts for this work have been made available through Github, for greater community use.&nbsp; Notably, the simulator release includes a faithful implementation of a modern x86 front-end (including the micro-op cache and micro-op fusion) along with new speculative features such as value prediction and loop stream detection, providing researchers a strong foundation to build on.</span></p>\n<p><span>The PIs also regularly teach graduate and undergraduate Computer Architecture courses with a significant emphasis on quantitative methods and performance analysis.&nbsp; The PIs also offer specialization courses on hardware security and acceleration.</span></p>\n<p><span><span>The PIs are also extremely committed towards diversity efforts in Computer Science and other STEM disciplines.&nbsp; They provided research mentorship to three graduate students from India, China, Iran, and the US, in addition to multiple undergraduate students, one of whom is a female student who was recognized nationally by CRA's outstanding undergraduate researcher award honorable mention.</span><br /></span></p>\n<p>&nbsp;</p>\n<div><span style=\"color: #1b1b1b; font-family: Verdana; font-size: 11.312px;\"><br /></span></div><br>\n<p>\n Last Modified: 04/29/2024<br>\nModified by: Ashish&nbsp;Venkat</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nModern workloads feature data-dependent computation and control flow patterns that often vary considerably with changing datasets and configuration parameters. This has greatly reduced the effectiveness of conventional compiler optimizations that rely on hoisting program invariants identifiable at compile-time to eliminate redundant computation and further apply machine-specific optimizations to the residual code. Run-time optimizations have largely been profile-guided and conservative in nature, limiting their ability to adapt to changing execution profiles as datasets evolve, notwithstanding high profiling overheads.\n\n\nThe project makes the keyobservation that modern datasets offer remarkable predictability, because data access and control flow patterns in many workload-dataset pairs manifest as invariants across long execution intervals, unmasking an untapped pocket of opportunity for speculatively optimizing such code paths at run-time, by exposing and eliminating dead code, entirely within the processor, based on dynamically predicted data and control invariants, enabling the continuous optimization of inherently sequential code, without the need for profiling, compiler metadata, or other source-level information.\n\n\nSpeculative Superoptimizationis a minimally-invasive, prediction-driven microarchitectural technique that advances state-of-the-art dynamic binary optimization schemes in several important ways. First, it leverages the rich contextual knowledge available from a wide array of in-processor speculation techniques such as branch prediction, address prediction, and value prediction to track deterministic computational patterns in hot code regions and further transform an instruction sequence in execution into a compact stream of speculatively optimized instructions. Second, it opens the door to the deployment of aggressive and speculative optimization techniques that have been traditionally deemed unsafe, thanks to the processor's ability to rollback execution to a safe point in the event of a misprediction by flushing speculatively optimized instructions and redirecting execution to the corresponding stream of unoptimized instructions that are co-hosted in the processor's micro-op cache. Third, by exploiting predictability as the basis for optimization, it offers seamless adaptability to changing datasets and workload patterns, unlike existing runtime optimizations employed by software giants such as Google, Microsoft, and Meta that either require extensive profiling or tend to make conservative assumptions when they lack adequate context about the dynamic execution behavior.\n\n\nThe results from this work have been disseminated through top-tier conference and journal publications, such as MICRO, ISCA, and USENIX Security, and through tech talks at industry and academic institutions alike. In addition, the software artifacts for this work have been made available through Github, for greater community use. Notably, the simulator release includes a faithful implementation of a modern x86 front-end (including the micro-op cache and micro-op fusion) along with new speculative features such as value prediction and loop stream detection, providing researchers a strong foundation to build on.\n\n\nThe PIs also regularly teach graduate and undergraduate Computer Architecture courses with a significant emphasis on quantitative methods and performance analysis. The PIs also offer specialization courses on hardware security and acceleration.\n\n\nThe PIs are also extremely committed towards diversity efforts in Computer Science and other STEM disciplines. They provided research mentorship to three graduate students from India, China, Iran, and the US, in addition to multiple undergraduate students, one of whom is a female student who was recognized nationally by CRA's outstanding undergraduate researcher award honorable mention.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 04/29/2024\n\n\t\t\t\t\tSubmitted by: AshishVenkat\n"
 }
}