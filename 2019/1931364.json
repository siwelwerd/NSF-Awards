{
 "awd_id": "1931364",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Medium: Collaborative: User-Centered Deployment of Differential Privacy",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "James Joshi",
 "awd_eff_date": "2020-01-01",
 "awd_exp_date": "2021-12-31",
 "tot_intn_awd_amt": 76745.0,
 "awd_amount": 76745.0,
 "awd_min_amd_letter_date": "2019-08-16",
 "awd_max_amd_letter_date": "2019-08-16",
 "awd_abstract_narration": "Differential privacy (DP) has been accepted as the de facto standard for data privacy in the research community and beyond. Both companies and government agencies are trying to deploy DP technologies.  Broader deployments of DP technology, however, face challenges.  This project aims to understand the needs of different stakeholders in data  privacy, and to develop algorithms and software to enable broader deployment of private data sharing.  The project's novelty is combining the expertise of social science researchers with that of computer scientists who have both theoretical and system research experiences related to DP to develop a hybrid approach to private data sharing to achieve better privacy-utility tradeoff.  The project's impacts are in advancing the state-of-the-art with regard to DP deployment in particular and privacy protection in general.  More specifically the project identifies the workflow of DP data sharing, improve understanding of DP communication, and develop new algorithms, privacy concepts, and privacy mechanisms to support deployment of DP. \r\n \r\nThe project has four tasks that will advance the understanding of user-centered DP and lay a foundation for its deployment. (1) Examine individual human users' perception, comprehension and acceptance of the concept and guarantee of DP and the effect of privacy parameter, and to investigate effective ways to communicate those concepts.  (2) Implement methods from the domains of human factors and human-computer interaction to identify tasks, goals, and workflow in private data sharing.   (3) Develop key algorithms and software for a hybrid approach of private data sharing.  In the hybrid approach, one first publishes a private synopsis of dataset using carefully selected low-degree marginals.  From these marginals, one can either synthesize new datasets, or answer queries directly using inference under the maximum entropy principle.  The hybrid approach enhances this with interactive query answering, enabling extraction of information not covered by low-degree marginals.  (4) Develop techniques to further improve the privacy-utility tradeoff in private data sharing, including a theory of differential privacy under publishable information.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Somesh",
   "pi_last_name": "Jha",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Somesh Jha",
   "pi_email_addr": "jha@cs.wisc.edu",
   "nsf_id": "000205526",
   "pi_start_date": "2019-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537061613",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 76745.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>With the increasing deployment of privacy techniques, such as</p>\n<p>differential privacy (DP) and</p>\n<p>local differential privacy (LDP) techniques, an interesting and important open question is: dousers understand these techniques, trust them, and consequently,increase their data disclosure when these techniques are deployed?This project explores this important question -- after all if the users don't understand these techniques, they will be hesitant to deploy them.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Recall that DP is a central mechanism where the users send data to a trusted</p>\n<p>curator, who answers queries but adds random noise to the answers. In LDP users add noise to the their data before sending it to a central server. The question is do user's understand that LDP has better privacy guarantees than DP. In one of the works related to this project, we report four online human-subject experiments investigating theeffects of using different approaches to communicate differential privacy techniques to laypersons in a health app data collection setting. When shown descriptions that explain the implications instead of the definition/processes of DP or LDP technique, participants demonstrated better comprehension and showed more willingness to share information with LDP than with DP, indicating their understanding of LDP's stronger privacy guarantee compared with DP. Recall that&nbsp;</p>\n<p>The project hasjust emabrked on this important research topic, but more needs to be investigated in this direction.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/01/2022<br>\n\t\t\t\t\tModified by: Somesh&nbsp;Jha</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWith the increasing deployment of privacy techniques, such as\n\ndifferential privacy (DP) and\n\nlocal differential privacy (LDP) techniques, an interesting and important open question is: dousers understand these techniques, trust them, and consequently,increase their data disclosure when these techniques are deployed?This project explores this important question -- after all if the users don't understand these techniques, they will be hesitant to deploy them. \n\n \n\nRecall that DP is a central mechanism where the users send data to a trusted\n\ncurator, who answers queries but adds random noise to the answers. In LDP users add noise to the their data before sending it to a central server. The question is do user's understand that LDP has better privacy guarantees than DP. In one of the works related to this project, we report four online human-subject experiments investigating theeffects of using different approaches to communicate differential privacy techniques to laypersons in a health app data collection setting. When shown descriptions that explain the implications instead of the definition/processes of DP or LDP technique, participants demonstrated better comprehension and showed more willingness to share information with LDP than with DP, indicating their understanding of LDP's stronger privacy guarantee compared with DP. Recall that \n\nThe project hasjust emabrked on this important research topic, but more needs to be investigated in this direction. \n\n\t\t\t\t\tLast Modified: 06/01/2022\n\n\t\t\t\t\tSubmitted by: Somesh Jha"
 }
}