{
 "awd_id": "1849559",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: OAC: A Framework for Parallel Data-Intensive Computing on Emerging Architectures and Astroinformatics Applications",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Alan Sussman",
 "awd_eff_date": "2019-03-15",
 "awd_exp_date": "2022-02-28",
 "tot_intn_awd_amt": 174975.0,
 "awd_amount": 174975.0,
 "awd_min_amd_letter_date": "2019-02-14",
 "awd_max_amd_letter_date": "2019-02-14",
 "awd_abstract_narration": "The amount of data that needs to be analyzed by the scientific community is increasing due to growing volumes of data collected by current and future instruments and sensors. Consequently, scientific data analysis requires a significant amount of time. To decrease the amount of time needed to analyze data, methods need to utilize more computational resources, such as more processors in a computer. While the central processing unit (CPU) in a modern computer has traditionally been used to carry out data analysis, the past decade has seen an increase in using graphics processing units (GPUs) for data analysis. The modern graphics processing unit contains thousands of processors that can be used to execute a program faster than on the CPU. However, many algorithms for data analysis do not use the GPU to its full potential within the context of the broader computer system. This project advances a framework for understanding the performance of GPUs as applied to data analysis applications. The major goal of the project is to bridge the gap between algorithms that only use the GPU, and fully integrated algorithms that exploit the strengths of both the CPU and GPU. The ensemble of algorithms that are explored in the project support the needs of the astronomy community and researchers in other scientific areas that require efficient data analysis methods. The project aims to realize a new era in CPU/GPU computing that impacts both computer science and other scientific fields.  An outcome of the project is the development of materials for educators teaching at the intersection of data analysis and parallel computing. This project includes mentoring K-12, undergraduate, and graduate students.  Consequently, the project serves the national interest, as stated by NSF's mission, by promoting the progress of science, and to advance the national health and prosperity. \r\n\r\nNew cyberinfrastructure, such as data analysis algorithms for emerging heterogeneous architectures, are needed to address cutting-edge scientific problems. Data analysis building blocks and algorithms have many data-dependent performance bottlenecks. New architectures have the potential to alleviate some of these key bottlenecks. However, the majority of GPU research minimally involves the CPU/host, and performs most of the computation on the GPU. This is a missed opportunity to more closely integrate both data and task parallelism between the CPU and GPU to simultaneously exploit concurrency across both architectures. This project examines a selection of key algorithms in the database, machine learning, data mining, and parallel computing communities. Using these algorithms, this project explores the continuum between GPU-only and mixed hybrid parallelism (data and task parallelism between the CPU and GPU) to identify key bottlenecks that can be reduced by exploiting underutilized resources. The selected algorithms are fundamental to scientific data processing workflows, and can advance time-domain astronomy cyberinfrastructure.  The project integrates data-intensive computing insights into courses at the undergraduate and graduate levels, and pedagogical modules are developed to be used by instructors for teaching concepts of mixed (data and task) parallelism across the CPU and GPU. This project includes mentoring students at the undergraduate, graduate, and K-12 levels, including outreach at science festivals to encourage participation and interest in science, technology, engineering, and mathematics.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Gowanlock",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Gowanlock",
   "pi_email_addr": "michael.gowanlock@nau.edu",
   "nsf_id": "000753566",
   "pi_start_date": "2019-02-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northern Arizona University",
  "inst_street_address": "601 S KNOLES DR RM 220",
  "inst_street_address_2": "",
  "inst_city_name": "FLAGSTAFF",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "9285230886",
  "inst_zip_code": "86011",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "AZ02",
  "org_lgl_bus_name": "NORTHERN ARIZONA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "MXHAS3AKPRN1"
 },
 "perf_inst": {
  "perf_inst_name": "Northern Arizona University",
  "perf_str_addr": "1295 S. Knoles Drive, PO Box 569",
  "perf_city_name": "Flagstaff",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "860110001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "AZ02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "026Y00",
   "pgm_ele_name": "CRII CISE Research Initiation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 174975.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Current and near-future scientific instruments are generating large amounts of data. Therefore, scientific discovery in many fields is limited by the ability of researchers to examine and understand these large quantities of data. One such field is that of time-domain astronomy, which will require significant computational capability and new infrastructure to realize the potential of new state-of-the-art instruments.</p>\n<p><br />At the same time, there are emerging parallel computing architectures, such as graphics processing units (GPUs) that can typically process data much faster than standard multi-core central processing units (CPUs). Both of these architectures are parallel processors where computation is carried out on multiple cores concurrently. Despite the great promise of GPUs, there are certain situations where a data analysis algorithm may benefit from parallel execution on the CPU rather than the GPU.</p>\n<p><br />This project examined the spectrum of parallel processing techniques for several data analysis algorithms that are used in many applications. The project examined splitting up the work and assigning it to the CPU and GPU architectures under several scenarios, where both the CPU and GPU execute the work concurrently. In summary, ten papers were published, and the source code of the new algorithms has been made publicly available. We found that our hybrid CPU+GPU algorithms are generally robust to many different algorithm input parameters, and data-dependent properties, including data dimensionality and distribution. We find that this hybrid approach is generally preferable to using CPU-only or GPU-only algorithms. In addition to these research artifacts, we engaged in STEM outreach at the K-12 level, and developed new pedagogic modules for teaching parallel and distributed computing at the graduate level. Also, several undergraduate and graduate students worked on the project. Consequently, this project has helped train the STEM workforce, which is an investment that will serve to bolster the U.S. economy.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/04/2022<br>\n\t\t\t\t\tModified by: Michael&nbsp;Gowanlock</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nCurrent and near-future scientific instruments are generating large amounts of data. Therefore, scientific discovery in many fields is limited by the ability of researchers to examine and understand these large quantities of data. One such field is that of time-domain astronomy, which will require significant computational capability and new infrastructure to realize the potential of new state-of-the-art instruments.\n\n\nAt the same time, there are emerging parallel computing architectures, such as graphics processing units (GPUs) that can typically process data much faster than standard multi-core central processing units (CPUs). Both of these architectures are parallel processors where computation is carried out on multiple cores concurrently. Despite the great promise of GPUs, there are certain situations where a data analysis algorithm may benefit from parallel execution on the CPU rather than the GPU.\n\n\nThis project examined the spectrum of parallel processing techniques for several data analysis algorithms that are used in many applications. The project examined splitting up the work and assigning it to the CPU and GPU architectures under several scenarios, where both the CPU and GPU execute the work concurrently. In summary, ten papers were published, and the source code of the new algorithms has been made publicly available. We found that our hybrid CPU+GPU algorithms are generally robust to many different algorithm input parameters, and data-dependent properties, including data dimensionality and distribution. We find that this hybrid approach is generally preferable to using CPU-only or GPU-only algorithms. In addition to these research artifacts, we engaged in STEM outreach at the K-12 level, and developed new pedagogic modules for teaching parallel and distributed computing at the graduate level. Also, several undergraduate and graduate students worked on the project. Consequently, this project has helped train the STEM workforce, which is an investment that will serve to bolster the U.S. economy. \n\n\t\t\t\t\tLast Modified: 05/04/2022\n\n\t\t\t\t\tSubmitted by: Michael Gowanlock"
 }
}