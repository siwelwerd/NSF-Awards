{
 "awd_id": "1927227",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: AI-DCL: Measuring and Mitigating Animosity toward Artificial Intelligence Systems and Science",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2019-08-15",
 "awd_exp_date": "2023-10-31",
 "tot_intn_awd_amt": 299712.0,
 "awd_amount": 299712.0,
 "awd_min_amd_letter_date": "2019-08-15",
 "awd_max_amd_letter_date": "2023-06-30",
 "awd_abstract_narration": "Artificial Intelligence (AI) applications are demonstrating undeniable success and widespread adoption, but the problem of algorithmic bias has arisen.  Algorithmic bias occurs when AI systems produce unjust decisions.  This problem is made worse by the fact that AI systems are opaque and unfamiliar to most people.  Scientists and the public want to unlock the power of fast, intelligent computer systems, but they are understandably hesitant when they see these systems unfairly discriminate or simply make unexplained decisions.  This research will answer fundamental questions to assist in understanding the public's trust and mistrust of AI: How does the public feel about AI systems?  What do they think of the shapers of these systems?  And do these attitudes change as they gain experience with AI systems?\r\n\r\nThe aim of this research is to directly measure public opinion regarding artificial intelligence systems and scientists and test the hypothesis that exposure to interpretable AI will lead to more positive attitudes.  The integration of AI systems into decision-making processes previously the sole domain of human judgement is still a relatively novel phenomenon.  Public opinion is likely in a dynamic phase and measuring how public attitudes toward AI evolve over the next few years is crucially important.  Thus, this project will compile monthly composite measures of trust in AI systems and scientists through surveying a representative sample of the US population.  Additionally, it is the case that much effort is currently being expended to make AI systems more interpretable.  This effort is predicated on the untested assumption that negative attitudes toward AI are due to the complex and opaque nature of its underlying algorithms.  The investigators will test the effect of firsthand experience with AI systems while experimentally controlling the level of transparency.  The goal is an explicit test of the theory that increased exposure to interpretable AI will decrease distrust and other negative attitudes toward AI.  With this research, the investigators will measure and test a method to mitigate mistrust of AI and advance the conversation currently taking place across social science and engineering disciplines regarding how humanity shall relate to a powerful new tool.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jason",
   "pi_last_name": "Jones",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Jason J Jones",
   "pi_email_addr": "jason.j.jones@stonybrook.edu",
   "nsf_id": "000519557",
   "pi_start_date": "2019-08-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Steven",
   "pi_last_name": "Skiena",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Steven Skiena",
   "pi_email_addr": "skiena@cs.stonybrook.edu",
   "nsf_id": "000199813",
   "pi_start_date": "2019-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "WEST 5510 FRK MEL LIB",
  "perf_city_name": "Stony Brook",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117940001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 299712.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We measured American public opinion toward Artificial Intelligence over the course of several years.</p>\n<p>For two years we ran weekly surveys of 100 Americans. We found the American public supported the development of Artificial Intelligence. Survey respondents could choose one of seven points between Strongly Oppose and Strongly Support.&nbsp; Over 82 weeks, we never observed the average dip below the midpoint.</p>\n<p>Every few weeks we asked Americans \"How much trust do you have in ______ to do the right thing?\"&nbsp; The blank was randomly filled with Congress, the President, the average American, your best friend or artificial intelligence algorithms.&nbsp; As Figure 1 demonstrates, Americans trusted AI algorithms more than Congress or the President but less than the average American or their best friend.&nbsp; We maintained a website presenting these results and more titled <em>Jones-Skiena Public Opinion of Artificial Intelligence Dashboard</em>.&nbsp; You can find it here at https://jasonjones.ninja/jones-skiena-public-opinion-of-ai/</p>\n<p>With two students, we published a peer-reviewed, open-access research article titled <em>American Public Opinion on Artificial Intelligence in Healthcare</em>.&nbsp; As Figure 2 illustrates, we found that the American public strongly prefers human medical professionals make medical decisions, while at the same time believing they are more likely to make culturally biased decisions than AI.</p>\n<p>With another student, Dr. Jones published a peer-reviewed, open-access research article titled <em>The Effect of Artificial Intelligence on Social Trust in American Institutions</em>.&nbsp; Using survey experiments again, we discovered that Americans report less trust in companies, hospitals and police when they are said to \"use artificial intelligence.\"&nbsp; See Figure 3.</p>\n<p>Artificial General Intelligence (AGI) refers to a computer system that could learn to complete any intellectual task that a human being could.&nbsp; Dr. Jones and Dr. Skiena wondered if Americans are ready for AGI computer equals.&nbsp; We asked Americans how much they agreed with the following three statements - once in 2021 and once in 2023:</p>\n<ol>\n<li>I personally believe it will be possible to build an AGI.</li>\n<li>If scientists determine AGI can be built, it should be built.</li>\n<li>An AGI should have the same rights as a human being.</li>\n</ol>\n<p>In Figure 4, you can see how Americans responded and how their opinions changed.&nbsp; From 2021 to 2023, Americans increasingly agreed AGI was <em>possible </em>to build.&nbsp; But they agreed more weakly that AGI <em>should </em>be built.&nbsp; Finally, Americans mostly disagreed that an AGI should have the same <em>rights </em>as a human being - disagreeing more strongly in 2023 than in 2021.</p>\n<p>Overall, we have found that American public opinion is at a tipping point.&nbsp; Most Americans have only weak feelings - neither very positive nor very negative - toward Artificial Intelligence.&nbsp; However, with the large amount of public attention the field currently draws, we expect that to change in the near future.</p><br>\n<p>\n Last Modified: 02/01/2024<br>\nModified by: Jason&nbsp;J&nbsp;Jones</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706735953835_trust1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706735953835_trust1--rgov-800width.png\" title=\"Figure 3\"><img src=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706735953835_trust1--rgov-66x44.png\" alt=\"Figure 3\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Americans report decreased trust in companies, hospitals and police when they are said to \"use artificial intelligence.\"</div>\n<div class=\"imageCredit\">Dr. Jason J. Jones</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Jason&nbsp;J&nbsp;Jones\n<div class=\"imageTitle\">Figure 3</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706734743170_figure2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706734743170_figure2--rgov-800width.png\" title=\"Figure 2\"><img src=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706734743170_figure2--rgov-66x44.png\" alt=\"Figure 2\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The American public strongly prefers human medical professionals make medical decisions, while at the same time believing they are more likely to make culturally biased decisions than AI.</div>\n<div class=\"imageCredit\">Dr. Jason J. Jones</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Jason&nbsp;J&nbsp;Jones\n<div class=\"imageTitle\">Figure 2</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706734003544_trust_cumulative--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706734003544_trust_cumulative--rgov-800width.png\" title=\"Figure 1\"><img src=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706734003544_trust_cumulative--rgov-66x44.png\" alt=\"Figure 1\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Trust in artificial intelligence algorithms in comparison to other items</div>\n<div class=\"imageCredit\">Dr. Jason J. Jones</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Jason&nbsp;J&nbsp;Jones\n<div class=\"imageTitle\">Figure 1</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706736294389_2021_versus_2023--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706736294389_2021_versus_2023--rgov-800width.png\" title=\"Figure 4\"><img src=\"/por/images/Reports/POR/2024/1927227/1927227_10634275_1706736294389_2021_versus_2023--rgov-66x44.png\" alt=\"Figure 4\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">From 2021 to 2023, Americans increasingly agreed AGI was possible to build.  But they agreed more weakly that AGI should be built.  Finally, American adults mostly disagreed that an AGI should have the same rights as a human being - disagreeing more strongly in 2023 than in 2021.</div>\n<div class=\"imageCredit\">Dr. Jason J. Jones</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Jason&nbsp;J&nbsp;Jones\n<div class=\"imageTitle\">Figure 4</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nWe measured American public opinion toward Artificial Intelligence over the course of several years.\n\n\nFor two years we ran weekly surveys of 100 Americans. We found the American public supported the development of Artificial Intelligence. Survey respondents could choose one of seven points between Strongly Oppose and Strongly Support. Over 82 weeks, we never observed the average dip below the midpoint.\n\n\nEvery few weeks we asked Americans \"How much trust do you have in ______ to do the right thing?\" The blank was randomly filled with Congress, the President, the average American, your best friend or artificial intelligence algorithms. As Figure 1 demonstrates, Americans trusted AI algorithms more than Congress or the President but less than the average American or their best friend. We maintained a website presenting these results and more titled Jones-Skiena Public Opinion of Artificial Intelligence Dashboard. You can find it here at https://jasonjones.ninja/jones-skiena-public-opinion-of-ai/\n\n\nWith two students, we published a peer-reviewed, open-access research article titled American Public Opinion on Artificial Intelligence in Healthcare. As Figure 2 illustrates, we found that the American public strongly prefers human medical professionals make medical decisions, while at the same time believing they are more likely to make culturally biased decisions than AI.\n\n\nWith another student, Dr. Jones published a peer-reviewed, open-access research article titled The Effect of Artificial Intelligence on Social Trust in American Institutions. Using survey experiments again, we discovered that Americans report less trust in companies, hospitals and police when they are said to \"use artificial intelligence.\" See Figure 3.\n\n\nArtificial General Intelligence (AGI) refers to a computer system that could learn to complete any intellectual task that a human being could. Dr. Jones and Dr. Skiena wondered if Americans are ready for AGI computer equals. We asked Americans how much they agreed with the following three statements - once in 2021 and once in 2023:\n\nI personally believe it will be possible to build an AGI.\nIf scientists determine AGI can be built, it should be built.\nAn AGI should have the same rights as a human being.\n\n\n\nIn Figure 4, you can see how Americans responded and how their opinions changed. From 2021 to 2023, Americans increasingly agreed AGI was possible to build. But they agreed more weakly that AGI should be built. Finally, Americans mostly disagreed that an AGI should have the same rights as a human being - disagreeing more strongly in 2023 than in 2021.\n\n\nOverall, we have found that American public opinion is at a tipping point. Most Americans have only weak feelings - neither very positive nor very negative - toward Artificial Intelligence. However, with the large amount of public attention the field currently draws, we expect that to change in the near future.\t\t\t\t\tLast Modified: 02/01/2024\n\n\t\t\t\t\tSubmitted by: JasonJJones\n"
 }
}