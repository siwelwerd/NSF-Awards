{
 "awd_id": "1940322",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Biology-guided neural networks for discovering phenotypic traits",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032927163",
 "po_email": "rsbeaman@nsf.gov",
 "po_sign_block_name": "Reed Beaman",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 298454.0,
 "awd_amount": 298454.0,
 "awd_min_amd_letter_date": "2019-09-17",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "Unlike genetic data, the traits of organisms such as their visible features, are not available in databases for analysis.  The lack of machine-readable trait data has slowed progress on four grand challenge problems in biology: predicting the genes that generate traits, understanding the patterns of evolution, predicting the effects of ecological change, and species identification. This project will use advances in machine learning and machine-readable biological knowledge to create a new method to automatically identify traits from images of organisms.  Images of organisms are widely available, and this new method could be used to rapidly harvest traits that could be used to solve the grand challenges in biology.  Large image collections and corresponding digital data from fishes will be used in this study because of the extensive resources available for these organisms. The new machine learning model can be generalized to other disciplines that have similar machine-readable knowledge, and it will help in explaining the results of artificial intelligence, thus advancing the field of computer science.  The new method stands to benefit society in application to areas such as agriculture or medicine, where trait discovery from images is critical in disease diagnosis.  The project will support the education of students and postdocs in biology, computer science, and information science.  It will disseminate its findings through workshops, presentations, publications, and open access to data and code that it produces. \r\n\r\nThis project will leverage advances in state-of-the-art machine learning to develop a novel class of artificial neural networks that can exploit the machine readable and predictive knowledge about biology that is available in the form of phylogenies and anatomy ontologies.  These biology-guided neural networks are expected to automatically detect and predict traits from specimen images, with little training data. Image-based trait data derived from this work will enable progress in gene-phenotype mapping to novel traits and understanding patterns of evolution. The resulting machine learning model can be generalized to other disciplines that have formally structured knowledge, and will contribute to advances in computer science by going beyond black-box learning and making important advances toward Explainable Artificial Intelligence.  It may be extended to applied areas, such as agriculture or the biomedical domain. The research will be piloted using teleost fishes because of many high-quality data resources (digital images, evolutionary trees, anatomy ontology). Methods for automated metadata quality assessment and provenance tracking will be developed in the course of this project to ensure the results and processes are verifiable, replicable and reusable.  These will broadly impact the many domains that will adopt machine learning as a way to make discoveries from images. This convergent research will accelerate scientific discovery across the biological sciences and computer science by harnessing the data revolution in conjunction with biological knowledge.\r\n\r\nThis project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Henry",
   "pi_last_name": "Bart",
   "pi_mid_init": "L",
   "pi_sufx_name": "Jr",
   "pi_full_name": "Henry L Bart",
   "pi_email_addr": "hbartjr@tulane.edu",
   "nsf_id": "000358626",
   "pi_start_date": "2019-09-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Tulane University",
  "inst_street_address": "6823 SAINT CHARLES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "NEW ORLEANS",
  "inst_state_code": "LA",
  "inst_state_name": "Louisiana",
  "inst_phone_num": "5048654000",
  "inst_zip_code": "701185665",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "LA01",
  "org_lgl_bus_name": "THE ADMINISTRATORS OF TULANE EDUCATIONAL FUND",
  "org_prnt_uei_num": "XNY5ULPU8EN6",
  "org_uei_num": "XNY5ULPU8EN6"
 },
 "perf_inst": {
  "perf_inst_name": "Tulane University",
  "perf_str_addr": "6823 St. Charles Ave.",
  "perf_city_name": "New Orleans",
  "perf_st_code": "LA",
  "perf_st_name": "Louisiana",
  "perf_zip_code": "701185698",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "LA01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "099Y00",
   "pgm_ele_name": "HDR-Harnessing the Data Revolu"
  },
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1165",
   "pgm_ref_txt": "ADVANCES IN BIO INFORMATICS"
  },
  {
   "pgm_ref_code": "7231",
   "pgm_ref_txt": "CYBERINFRASTRUCTURE"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 216830.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 81624.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project proposed to develop a novel class of artificial neural networks (ANNs) for classifying fish species from images, identifying the morphological features (traits) of the specimens and extracting data on the traits from the images.To accomplish this, the project leveraged structured biological knowledge (trait anatomy ontology, phylogeny) about the fish species, hence the use of \"Biology Guided Neural Networks\" (BGNN) in the title. The BGNN project advanced methods of manually and automatically assessing the quality of images, through a human of machine preformed task of processing the images. The BGNN project produced a large, openly accessible repository of fish specimens images, hosted by Tulane University, that can be used in research for many years to come. The project also created approaches to semantically integrate discovered traits with existing knowledgebases, while automatically tracking object history (provenance).<span>&nbsp;By applying the BGNN model to vast volumes of unlabeled images of fish specimens, the investigators of this project were able to create&nbsp;</span>novel biological knowledge, including ontological relationships among known traits of the fish specimens, previously undiscovered traits,and complete and accurate trait distributions across multple fish species.</p>\n<p>The BGNN project was a unique collaboration involving biologists, computer and information scientists. The project?s methods and findings helped to lay the foundation for a new Harnessing the Data Revolution Institute, called Imageomics, which is encompasses an even broader range or scientific disiplines and collaborators united in the common goal of training computer algorithms to mine pheotypic traits from images of biological specimens. The research of the Imageomice institute is built on a foundation of research on traits mined from images of fish specimens established by the BGNN project.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/13/2023<br>\n\t\t\t\t\tModified by: Henry&nbsp;L&nbsp;Bart</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676335656235_TulaneFishDataInfrastructure20221024-1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676335656235_TulaneFishDataInfrastructure20221024-1--rgov-800width.jpg\" title=\"Fish Data Workflow\"><img src=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676335656235_TulaneFishDataInfrastructure20221024-1--rgov-66x44.jpg\" alt=\"Fish Data Workflow\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Workflow showing how fish specimens are gathered from image repositories, processed, quality checked and saved to a web accessible database.</div>\n<div class=\"imageCredit\">Yasin Bakis</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Henry&nbsp;L&nbsp;Bart</div>\n<div class=\"imageTitle\">Fish Data Workflow</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676335938725_TulaneFishDataInfrastructure20221024-3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676335938725_TulaneFishDataInfrastructure20221024-3--rgov-800width.jpg\" title=\"Image processing hierarchy\"><img src=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676335938725_TulaneFishDataInfrastructure20221024-3--rgov-66x44.jpg\" alt=\"Image processing hierarchy\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Steps involved in preparing a fish image for trait extraction experiments, including removing fish from its background, scaling the specimen, and segmenting body features .</div>\n<div class=\"imageCredit\">Yasin Bakis</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Henry&nbsp;L&nbsp;Bart</div>\n<div class=\"imageTitle\">Image processing hierarchy</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676336108104_TulaneFishDataInfrastructure20221024-4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676336108104_TulaneFishDataInfrastructure20221024-4--rgov-800width.jpg\" title=\"Data Access via API\"><img src=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676336108104_TulaneFishDataInfrastructure20221024-4--rgov-66x44.jpg\" alt=\"Data Access via API\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Process of accessing specimen images via an API and packaging the images as a .zip file for distribution via the web</div>\n<div class=\"imageCredit\">Yasin Bakis</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Henry&nbsp;L&nbsp;Bart</div>\n<div class=\"imageTitle\">Data Access via API</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676336976272_TulaneFishDataInfrastructure20221024-5--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676336976272_TulaneFishDataInfrastructure20221024-5--rgov-800width.jpg\" title=\"Image Dataset Profile\"><img src=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676336976272_TulaneFishDataInfrastructure20221024-5--rgov-66x44.jpg\" alt=\"Image Dataset Profile\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Image Data Profile, with data and descriptive files describing the  source of the images and how to cite them.</div>\n<div class=\"imageCredit\">Yasin Bakis</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Henry&nbsp;L&nbsp;Bart</div>\n<div class=\"imageTitle\">Image Dataset Profile</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676337364969_TulaneFishDataInfrastructure20221024-2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676337364969_TulaneFishDataInfrastructure20221024-2--rgov-800width.jpg\" title=\"Data &amp; Metadata structure\"><img src=\"/por/images/Reports/POR/2023/1940322/1940322_10642761_1676337364969_TulaneFishDataInfrastructure20221024-2--rgov-66x44.jpg\" alt=\"Data &amp; Metadata structure\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Chart showing how image metadata and collection event data combine with species data to for a  complete description of each image.</div>\n<div class=\"imageCredit\">Yasin Bakis</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Henry&nbsp;L&nbsp;Bart</div>\n<div class=\"imageTitle\">Data & Metadata structure</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project proposed to develop a novel class of artificial neural networks (ANNs) for classifying fish species from images, identifying the morphological features (traits) of the specimens and extracting data on the traits from the images.To accomplish this, the project leveraged structured biological knowledge (trait anatomy ontology, phylogeny) about the fish species, hence the use of \"Biology Guided Neural Networks\" (BGNN) in the title. The BGNN project advanced methods of manually and automatically assessing the quality of images, through a human of machine preformed task of processing the images. The BGNN project produced a large, openly accessible repository of fish specimens images, hosted by Tulane University, that can be used in research for many years to come. The project also created approaches to semantically integrate discovered traits with existing knowledgebases, while automatically tracking object history (provenance). By applying the BGNN model to vast volumes of unlabeled images of fish specimens, the investigators of this project were able to create novel biological knowledge, including ontological relationships among known traits of the fish specimens, previously undiscovered traits,and complete and accurate trait distributions across multple fish species.\n\nThe BGNN project was a unique collaboration involving biologists, computer and information scientists. The project?s methods and findings helped to lay the foundation for a new Harnessing the Data Revolution Institute, called Imageomics, which is encompasses an even broader range or scientific disiplines and collaborators united in the common goal of training computer algorithms to mine pheotypic traits from images of biological specimens. The research of the Imageomice institute is built on a foundation of research on traits mined from images of fish specimens established by the BGNN project. \n\n\t\t\t\t\tLast Modified: 02/13/2023\n\n\t\t\t\t\tSubmitted by: Henry L Bart"
 }
}