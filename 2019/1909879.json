{
 "awd_id": "1909879",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Small: A Study of Agent's Expectations for Nondeterministic and Dynamic Domains",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 350388.0,
 "awd_amount": 350388.0,
 "awd_min_amd_letter_date": "2019-07-15",
 "awd_max_amd_letter_date": "2023-06-20",
 "awd_abstract_narration": "Society is increasing relying on both (1) fully autonomous systems physically-embodied such as self-driving cars and automated cashiers as well as virtually-embodied such as automated stock traders and characters in virtual environments; and (2) semi-autonomous systems in physically-embodied platforms such as the break system in vehicles and virtual environments such as trip advisors. This project addresses the following question: when these agents are executing a course of action, how to compute the expectations of the agent's actions? This is a fundamental question as expectations can be used to detect when the agent's behavior is anomalous; that is, when their course of action deviates from the expectations. They can also be used to explain the agent's behavior by indicating what to expect from the agent's own execution. This project also includes a concrete educational activity targeting high school students that is tightly integrated with the particularities of the research program. The project will develop a plan for an educational unit providing an experience centered around a hands-on exercise experiencing AI by evaluating if an automated agent is performing its assigned tasks.  Through that educational unit, students will gain an appreciation of the challenges in assessing if automated AI systems are behaving as intended.\r\n\r\nThis project studies the problem of computing the expectations of course of action generated by an agent. Specifically, this project will investigate this problem (1) when the course of action is a policy that accounts for non-determinism in the outcome of the actions in the domain;  (2)  when the course of action is a  plan  and the domain includes numeric fluents bounded by margins of error; (3) when the course of action is a policy and the domain includes numeric fluents bounded by margins of error.  The project is agnostic with regard to the particular planning paradigm used to generate the course of action and with regard to the paradigm used for correction of the course of action when a discrepancy is detected. The study is based on two representations of the courses of action:  (1) sequential plans with numeric fluents valued within margins of errors and (2) policies for  non-deterministic domains. Both of these representations account for uncertainty in the execution of the actions.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Hector",
   "pi_last_name": "Munoz-Avila",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hector Munoz-Avila",
   "pi_email_addr": "hem4@lehigh.edu",
   "nsf_id": "000236759",
   "pi_start_date": "2019-07-15",
   "pi_end_date": "2020-07-23"
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Sihong",
   "pi_last_name": "Xie",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sihong Xie",
   "pi_email_addr": "six316@lehigh.edu",
   "nsf_id": "000728918",
   "pi_start_date": "2020-07-23",
   "pi_end_date": "2023-06-20"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lifang",
   "pi_last_name": "He",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lifang He",
   "pi_email_addr": "lifanghescut@gmail.com",
   "nsf_id": "000819777",
   "pi_start_date": "2023-06-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Lehigh University",
  "inst_street_address": "526 BRODHEAD AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BETHLEHEM",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "6107583021",
  "inst_zip_code": "180153008",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "PA07",
  "org_lgl_bus_name": "LEHIGH UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "E13MDBKHLDB5"
 },
 "perf_inst": {
  "perf_inst_name": "Lehigh University",
  "perf_str_addr": "113 Research Drive",
  "perf_city_name": "Bethlehem",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "180154731",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "PA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 350388.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Overview</strong></p>\r\n<p>This project aimed to enhance AI safety and autonomous decision-making by developing expectation models that help AI agents detect and respond to deviations from planned actions. The research focused on nondeterministic and dynamic environments, where agents must anticipate multiple possible outcomes and adjust their behavior accordingly. The project has contributed to AI safety, reinforcement learning, multi-agent systems, and biomedical AI applications, leading to significant scientific and societal impacts.</p>\r\n<h4><strong style=\"font-size: 1em;\">Key Outcomes and Findings</strong></h4>\r\n<p><strong>1. Advancements in AI Safety and Autonomous Systems</strong></p>\r\n<p><strong></strong>- Developed a taxonomy of expectations that helps AI agents monitor their execution and detect deviations.</p>\r\n<p>- Designed novel algorithms for computing expectations in environments with uncertainty and numeric constraints.</p>\r\n<p>- Improved multi-agent reinforcement learning through Bayesian distributional value estimation, leading to more robust decision-making.</p>\r\n<p><strong>2. Real-World Applications and Impact<br /></strong></p>\r\n<p>- Robotics and Autonomous Vehicles: Improved AI adaptability in self-driving systems by ensuring they can detect and correct unexpected behaviors.</p>\r\n<p>- Cybersecurity and Anomaly Detection: Developed methods for identifying unexpected patterns in AI-driven security applications.</p>\r\n<p>- Medical AI: Applied AI safety methodologies to&nbsp;medical image analysis,&nbsp;disease prediction, including Alzheimer&rsquo;s disease diagnosis.</p>\r\n<p><strong>3. Scientific Contributions and Dissemination</strong></p>\r\n<p>- Published 31 peer-reviewed papers in leading journals and conferences, including Nature Medicine, IEEE Transactions on Medical Imaging, NeurIPS, IJCAI, AAAI, KDD, ACM Multimedia, etc.</p>\r\n<p>- Trained and mentored multiple PhD students, contributing to workforce development in AI safety and explainability.</p>\r\n<p>- Shared research findings through public datasets, open-source AI models, and international conference presentations.</p>\r\n<p><strong>4. Broader Impacts on Society</strong></p>\r\n<p>- Increased public trust in AI by improving explainability and robustness in critical applications such as healthcare, finance, and national security.</p>\r\n<p>- Supported policy discussions on AI ethics and fairness, informing guidelines for responsible AI deployment.</p>\r\n<p>- Strengthened interdisciplinary collaborations across AI, biomedical research, and computational neuroscience, expanding the impact of AI safety methodologies.</p>\r\n<h3><strong style=\"color: #000000;\">Conclusion</strong></h3>\r\n<p>This project has significantly advanced AI safety, autonomous decision-making, and multi-agent learning, with applications in healthcare, robotics, cybersecurity, and public policy. By developing explainable and reliable AI models, the research contributes to safer and more trustworthy AI systems that align with human values and societal needs.</p><br>\n<p>\n Last Modified: 02/11/2025<br>\nModified by: Lifang&nbsp;He</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nOverview\r\n\n\nThis project aimed to enhance AI safety and autonomous decision-making by developing expectation models that help AI agents detect and respond to deviations from planned actions. The research focused on nondeterministic and dynamic environments, where agents must anticipate multiple possible outcomes and adjust their behavior accordingly. The project has contributed to AI safety, reinforcement learning, multi-agent systems, and biomedical AI applications, leading to significant scientific and societal impacts.\r\nKey Outcomes and Findings\r\n\n\n1. Advancements in AI Safety and Autonomous Systems\r\n\n\n- Developed a taxonomy of expectations that helps AI agents monitor their execution and detect deviations.\r\n\n\n- Designed novel algorithms for computing expectations in environments with uncertainty and numeric constraints.\r\n\n\n- Improved multi-agent reinforcement learning through Bayesian distributional value estimation, leading to more robust decision-making.\r\n\n\n2. Real-World Applications and Impact\n\r\n\n\n- Robotics and Autonomous Vehicles: Improved AI adaptability in self-driving systems by ensuring they can detect and correct unexpected behaviors.\r\n\n\n- Cybersecurity and Anomaly Detection: Developed methods for identifying unexpected patterns in AI-driven security applications.\r\n\n\n- Medical AI: Applied AI safety methodologies tomedical image analysis,disease prediction, including Alzheimers disease diagnosis.\r\n\n\n3. Scientific Contributions and Dissemination\r\n\n\n- Published 31 peer-reviewed papers in leading journals and conferences, including Nature Medicine, IEEE Transactions on Medical Imaging, NeurIPS, IJCAI, AAAI, KDD, ACM Multimedia, etc.\r\n\n\n- Trained and mentored multiple PhD students, contributing to workforce development in AI safety and explainability.\r\n\n\n- Shared research findings through public datasets, open-source AI models, and international conference presentations.\r\n\n\n4. Broader Impacts on Society\r\n\n\n- Increased public trust in AI by improving explainability and robustness in critical applications such as healthcare, finance, and national security.\r\n\n\n- Supported policy discussions on AI ethics and fairness, informing guidelines for responsible AI deployment.\r\n\n\n- Strengthened interdisciplinary collaborations across AI, biomedical research, and computational neuroscience, expanding the impact of AI safety methodologies.\r\nConclusion\r\n\n\nThis project has significantly advanced AI safety, autonomous decision-making, and multi-agent learning, with applications in healthcare, robotics, cybersecurity, and public policy. By developing explainable and reliable AI models, the research contributes to safer and more trustworthy AI systems that align with human values and societal needs.\t\t\t\t\tLast Modified: 02/11/2025\n\n\t\t\t\t\tSubmitted by: LifangHe\n"
 }
}