{
 "awd_id": "1909577",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Secure, Private, and Resource-Constrained Approaches to Federated Machine Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2019-07-17",
 "awd_max_amd_letter_date": "2019-07-17",
 "awd_abstract_narration": "In a world increasingly shaped by data-driven machine learning (ML), one of the emerging challenges is that data are often collected and stored in a distributed manner -- across multiple datacenters or devices. On the other hand, due to security and privacy concerns, there are often low levels of trust between the data owners. To this end, federated ML enables ML with distributed data, while avoiding the transfer of private data from distributed devices to a central datacenter. Towards the goal of democratizing ML, this project will design and implement new techniques to make federated ML secure and private. Of particular interest are new system designs that enable federated ML on devices with limited computational power or communication bandwidth e.g., smartphones, smart health monitors, and smartwatches, among others. The ideas, software, and results of this project will directly impact industry and real-world applications. This project will include curriculum development for federated ML and plans to involve participation by graduate students from underrepresented groups. \r\n\r\nThis project creates a transformative new direction for federated machine learning (ML) research, by enabling ML on devices that are untrusted or weak, and across organizations and for users who would like to maintain the privacy of their data. This project will include new work on theoretical foundations, systems design, implementation, and integration with popular ML software. Concretely, this project tackles three challenges in federated ML. The first challenge is fault-tolerant ML algorithms, i.e., new techniques to perform ML when workers act in arbitrarily malicious manners (called Byzantine failures) -- in particular, this project will show that by leveraging natural noise-tolerance in ML, it is possible to tolerate significantly more Byzantine workers than indicated by the traditional distributed computing literature. The second challenge is to develop privacy-preserving ML algorithms which introduce noise from workers to preserve the privacy of data owned by participants while leading to correct and fast ML at the global level. The third challenge is to investigate resource-constrained ML scheduling by including new techniques to allow large neural network models to run across multiple devices which have memory constraints. In addition to developing the algorithmic and theoretical frameworks for these directions, this project will also build and release open software.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Oluwasanmi",
   "pi_last_name": "Koyejo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Oluwasanmi Koyejo",
   "pi_email_addr": "sanmi@cs.stanford.edu",
   "nsf_id": "000732197",
   "pi_start_date": "2019-07-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Indranil",
   "pi_last_name": "Gupta",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Indranil Gupta",
   "pi_email_addr": "indy@illinois.edu",
   "nsf_id": "000148881",
   "pi_start_date": "2019-07-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "506 S. Wright Street",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This award created new directions for federated machine learning (ML) research, allowing ML to run on devices that are untrusted or weak, across organizations, and for users who would like to maintain their data privacy. This research tackled three challenges in federated machine learning: worst-case distributed training robustness, privacy preservation, and resource-constrained scheduling. Our work built on recent publications where we developed the technical foundations of robust distributed learning and advancements to model parallelism.Specific objectives focused on advancing robust distributed ML systems. To this end, our goals included developing robust methods for both distributed and federated ML, building on our recent advances. For instance, based on work showing that median aggregation and Krum, two popular robust aggregation schemes, are vulnerable to inner-product manipulation attacks, we proposed filtering approaches with improved resilience to attacks and extended this work to more complex federated learning settings. Beyond this, our outcomes included advances in adaptive optimization schemes that speed up learning in distributed environments.<br />Our outreach and broader impact plan focused on disseminating this work to industry and academia and mentoring underrepresented and K-12 students. For example, Zeno has been adapted as part of open-source software for robust federated learning. Our outreach also included developing on-campus courses with new material on distributed and robust learning related to this proposal.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/21/2022<br>\n\t\t\t\t\tModified by: Oluwasanmi&nbsp;Koyejo</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis award created new directions for federated machine learning (ML) research, allowing ML to run on devices that are untrusted or weak, across organizations, and for users who would like to maintain their data privacy. This research tackled three challenges in federated machine learning: worst-case distributed training robustness, privacy preservation, and resource-constrained scheduling. Our work built on recent publications where we developed the technical foundations of robust distributed learning and advancements to model parallelism.Specific objectives focused on advancing robust distributed ML systems. To this end, our goals included developing robust methods for both distributed and federated ML, building on our recent advances. For instance, based on work showing that median aggregation and Krum, two popular robust aggregation schemes, are vulnerable to inner-product manipulation attacks, we proposed filtering approaches with improved resilience to attacks and extended this work to more complex federated learning settings. Beyond this, our outcomes included advances in adaptive optimization schemes that speed up learning in distributed environments.\nOur outreach and broader impact plan focused on disseminating this work to industry and academia and mentoring underrepresented and K-12 students. For example, Zeno has been adapted as part of open-source software for robust federated learning. Our outreach also included developing on-campus courses with new material on distributed and robust learning related to this proposal. \n\n\t\t\t\t\tLast Modified: 12/21/2022\n\n\t\t\t\t\tSubmitted by: Oluwasanmi Koyejo"
 }
}