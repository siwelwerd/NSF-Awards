{
 "awd_id": "1854831",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Geometric Harmonic Analysis in Learning and Inference: Theory and Applications",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 110000.0,
 "awd_amount": 110000.0,
 "awd_min_amd_letter_date": "2019-07-18",
 "awd_max_amd_letter_date": "2021-08-10",
 "awd_abstract_narration": "Pairwise comparison of objects is an important way human beings learn to reason from massive data sets. In many modern science and engineering fields, large-scale high dimensional data sets are generated with abundant structural information within each object, allowing people to conduct detailed pairwise comparisons between individual objects. To preserve the fine structural information of the data, it is important to take into account both the scalar similarity measure and the transformations that describes the relation between the data points. When the transformations admit an algebraic structure such as a group, the additional algebraic rigidity constraints shed new lights upon efficient learning and inference strategies largely unexplored in existing literature. The PIs aim to utilize the two sources of low-dimensional structures in data: (i) the manifold underlying the data, and  (ii) the algebraic consistency among the group transformations, to devise highly accurate and computationally efficient statistical methods for extracting patterns in massive complex data sets emerging from social, biomedical, and comparative biological sciences. This project will involve educating and training the next wave of students, and equipping them with the necessary tools to work in data science. Dissemination of research results and building connections among different fields through organizing workshops are also important aspects of the proposed work.\r\n\r\nThe goal of the project is to develop novel geometric harmonic analysis methods to extract information and perform inference on large-scale datasets equipped with group transformations. This will involve foundational theoretical work and algorithm development in the following three interrelated objectives: (i) angular synchronization across frequency channels, (ii) extended vector diffusion maps on multiple associated vector bundles of a common principal bundle, and (iii) community detection in conformation spaces of molecules and shape spaces of biological anatomical surfaces through multiple irreducible representations of group-valued pairwise interactions. On the practical side, the PIs propose to apply these newly developed techniques to high impact domain applications in biomedical and comparative biological sciences, including (1) cryo-EM and cryo-electron tomography (ET) image denoising, (2) shape space analysis in evolutionary and comparative biology, and (3) learning conformation spaces and dynamical structures of biomolecular machines. The techniques developed during the project period will be broadly applicable across disciplines, where the observations are noisy, incomplete, and possibly modified by a latent transformation through the action of an unknown group element.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lek-Heng",
   "pi_last_name": "Lim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lek-Heng Lim",
   "pi_email_addr": "lekheng@galton.uchicago.edu",
   "nsf_id": "000150703",
   "pi_start_date": "2020-06-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Tingran",
   "pi_last_name": "Gao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tingran Gao",
   "pi_email_addr": "trg17@uchicago.edu",
   "nsf_id": "000703914",
   "pi_start_date": "2019-07-18",
   "pi_end_date": "2020-06-12"
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "5747 S. Ellis Avenue",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606375418",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 35881.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 36667.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 37452.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 1\">\n<div class=\"section\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>The primary goal of the project is to develop novel geometric methods for estimation and inference on large-scale datasets.&nbsp;</span></p>\n<div class=\"page\" title=\"Page 2\">\n<div class=\"section\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>We developed the capability to take any common distances between probability distributions such as Wasserstein metric, KL-divergence, total variation distance, etc, and extend them to define a distance between two probability distributions on spaces of different dimensions.&nbsp;</span>Moreover, many of these distances that we defined have closed-form or near- closed-form expressions or may be computed using manifold or polynomial optimization algorithms.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"page\" title=\"Page 5\">\n<div class=\"section\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>We create a new geometric framework for optimization over a Grassmannian that gives the fastest and stablest known such algorithm to date.&nbsp;</span>These algorithms are also extremely efficient, avoiding the computations of SVD and EVD (which require iterative algorithms as subroutines), and can be accomplished with one QR decomposition and one special matrix exponentiation that takes time O(k(n&nbsp;&minus;&nbsp;k)).</p>\n<div class=\"page\" title=\"Page 5\">\n<div class=\"section\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>Our new stochastic Steffensen method could potentially become a viable alternative for the widely used stochastic gradient descent SGD method in the training of deep neural networks. For univariate functions, t</span>he&nbsp;method&nbsp;avoids second derivatives and is still quadratically convergent like Newton method. In fact, by incorporating an optimal step size, which turns out to be the same as that of Barzilai and Borwein, we even pushed the convergence order beyond quadratic to 1+&nbsp;&radic;2&nbsp;&asymp;&nbsp;2.414. While such high convergence orders are a pointless overkill for a deterministic algorithm, they become enormously rewarding when the algorithm is randomized for problems of massive sizes, as randomization invariably compromises convergence speed.</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div><br>\n<p>\n Last Modified: 08/27/2024<br>\nModified by: Lek-Heng&nbsp;Lim</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1854831/1854831_10622758_1724767037771_hinge_passes--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1854831/1854831_10622758_1724767037771_hinge_passes--rgov-800width.png\" title=\"Stochastic Steffensen Method\"><img src=\"/por/images/Reports/POR/2024/1854831/1854831_10622758_1724767037771_hinge_passes--rgov-66x44.png\" alt=\"Stochastic Steffensen Method\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Stochastic Steffensen Method</div>\n<div class=\"imageCredit\">Zhao, Lai, Lim</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Lek-Heng&nbsp;Lim\n<div class=\"imageTitle\">Stochastic Steffensen Method</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\n\nThe primary goal of the project is to develop novel geometric methods for estimation and inference on large-scale datasets.\n\n\n\n\n\n\nWe developed the capability to take any common distances between probability distributions such as Wasserstein metric, KL-divergence, total variation distance, etc, and extend them to define a distance between two probability distributions on spaces of different dimensions.Moreover, many of these distances that we defined have closed-form or near- closed-form expressions or may be computed using manifold or polynomial optimization algorithms.\n\n\n\n\n\n\n\n\n\n\nWe create a new geometric framework for optimization over a Grassmannian that gives the fastest and stablest known such algorithm to date.These algorithms are also extremely efficient, avoiding the computations of SVD and EVD (which require iterative algorithms as subroutines), and can be accomplished with one QR decomposition and one special matrix exponentiation that takes time O(k(nk)).\n\n\n\n\n\n\nOur new stochastic Steffensen method could potentially become a viable alternative for the widely used stochastic gradient descent SGD method in the training of deep neural networks. For univariate functions, themethodavoids second derivatives and is still quadratically convergent like Newton method. In fact, by incorporating an optimal step size, which turns out to be the same as that of Barzilai and Borwein, we even pushed the convergence order beyond quadratic to 1+22.414. While such high convergence orders are a pointless overkill for a deterministic algorithm, they become enormously rewarding when the algorithm is randomized for problems of massive sizes, as randomization invariably compromises convergence speed.\n\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 08/27/2024\n\n\t\t\t\t\tSubmitted by: Lek-HengLim\n"
 }
}