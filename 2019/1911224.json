{
 "awd_id": "1911224",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Highly Realistic Virtual Human Hands using Anatomically Based Modeling",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922533",
 "po_email": "hshen@nsf.gov",
 "po_sign_block_name": "Han-Wei Shen",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 498865.0,
 "awd_amount": 498865.0,
 "awd_min_amd_letter_date": "2019-08-01",
 "awd_max_amd_letter_date": "2019-08-01",
 "awd_abstract_narration": "The skeleton of the human hand consists of 27 bones, including 8 short carpel bones. Current state-of-the-art in human hand modeling only supports an approximate version of human hand because of the difficulty in acquiring a \"stable\" (without hand movements) data of the internal hand anatomy, as well in segmentation algorithms for identifying bones in the captured anatomical images. Computed Tomography (CT) scans irradiate the hand with harmful radiation and do not have the contrast to show any anatomy other than bones. Magnetic Resonance Imaging (MRI) scanners can provide internal anatomy, but the acquisition is difficult because the hand must be kept still inside the MRI scanner and because a quality scanning session is long (about 10 minutes). The goal of this project is to greatly improve the modeling, simulation and animation of human hands. Such models are useful in many fields. In computer graphics, virtual reality, telecommunication and film, they enable better, more believable virtual hands, enhancing the immersive experience. Accurate hand models can be used to design tools, equipment and everyday objects that must be manipulated by hands. In healthcare, they improve the design of medical devices that come in contact with hands. In the apparel industry, they enable one to design better gloves.  These computer models can also improve the design of robotic hands for medical prosthetics, enabling the artificial hands with artificial bones and muscles to move and deform like their real biological counterparts.\r\n\r\nThe project will develop a stable method to acquire hand internal anatomy (bones, muscles, fat) in multiple hand poses using MRI scanners, by manufacturing ergonomic rigid molds that hold the hand in a fixed and known pose during the scan. Real bones do not simply rotate around some center of rotation at the end of another bone, but instead undergo complex rigid body motion relative to their parent bones. Using the acquired bone rigid body motion, the research team will develop new methods to model this complex rigid motion, using novel data-driven and model-based techniques. Finite Element Methods (FEM) based simulations are then applied to combine acquired pose-varying muscle and fat/skin shapes. These advances enable realistic modeling of detailed surface appearance of hands that matches ground truth surface scans and that generalizes to arbitrary hand poses. The research team will then build a computer model for how the bones and muscles of the human hand move when the hand is articulated. Given the three-dimensional surface scans of the hand in a few poses, the research team also will use computer simulation to \"fill-in\" occlusions in scanned poses (occurring in a closed hand, fist pose and similar). This procedure will create a computer model of both the internal hand anatomy and the external hand appearance.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jernej",
   "pi_last_name": "Barbic",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jernej Barbic",
   "pi_email_addr": "jnb@usc.edu",
   "nsf_id": "000565189",
   "pi_start_date": "2019-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "941 Bloom Walk, SAL 104",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900890781",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 498865.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The goal of this project is to significantly improve the modeling of human hand anatomy, kinematics, and dynamics, including bones, muscles, tendons, fat, and skin. While computational models of hand kinematics exist, few have attempted to model internal structures comprehensively or produce anatomically precise models that align with real-world data, especially across the entire range of motion of the hand. In this project, we acquired detailed hand anatomy in multiple (12) poses of the same subject, using MRI scans. These scans were segmented into bones, muscles, tendons, and fat for each scanned pose. We then simulated hand biomechanics using Finite Element Method (FEM) soft-tissue simulation. This enabled us to extrapolate the MRI scans and the musculoskeletal anatomy to any hand pose. We also trained neural networks to compute accurate hand shapes in any pose at very fast computational speeds. Our work has applications in virtual reality, robotics, medicine, physical therapy, computer graphics, and other interactive domains.</span></p>\r\n<p><strong>Key Innovations</strong><br />Our model is uniquely detailed, comprising bones, muscles, tendons, fat, ligaments, and skin measured from a real person's hand. It distinguishes itself from other methods by:</p>\r\n<ol>\r\n<li><strong>Unprecedented Anatomical Detail:</strong>&nbsp;We modeled all musculoskeletal tissues of the hand undergoing motion, a first in any field to our knowledge.</li>\r\n<li><strong>Multi-Pose Data Acquisition:</strong>&nbsp;Unlike traditional approaches based on a single pose, we acquired data across multiple hand poses. This enabled a precise understanding of how each bone translates and rotates relative to its parent bone, and how the volumetric shape of the hand muscles changes as the hand articulates across its range of motion.</li>\r\n</ol>\r\n<p>This allowed us to build an anatomically accurate model of musculoskeletal actuation during hand motion. Existing models are typically static or less detailed, whereas our work captures the hand anatomy in motion. By leveraging this detailed data and our FEM simulator, we also demonstrated how hands can be simulated in real time using deep neural networks, broadening applications to interactive computing, virtual reality, gaming, and real-time medicine.</p>\r\n<p><strong>Impact on Robotics</strong><br />Our work advances understanding of internal hand anatomy and motion, which is crucial for developing next-generation robotic hands. Most robotic hands today use rigid structures actuated by servo motors at the joints. In contrast, human hand dexterity originates from the intricate interplay between soft tissues (muscles, tendons) and bones. Our insights pave the way for robotic hands that mimic biological functionality, potentially transforming prosthetics by enabling designs that replicate real hand versatility.</p>\r\n<p><strong>Applications in Medical Education</strong><br />We enable three-dimensional, real-time visualizations of how bones, muscles, ligaments, and tendons move inside the human hand during articulation. Similar to continuous X-ray imaging but without radiation risks, our technology offers a powerful new tool for medical education. Medical students can observe internal anatomy in motion, enhancing their understanding beyond static images in textbooks.</p>\r\n<p><strong>Relevance to the Metaverse</strong><br />Human hands play a pivotal role in next-generation metaverse technologies, which aim to revolutionize human communication in virtual reality. <span>The metaverse is world's next generation human-to-human communication system, making it possible for any two humans on the planet to communicate highly realistically in virtual reality (think \"Holodec\" from Star Trek).&nbsp;</span>Highly realistic digital hands are essential for creating lifelike virtual interactions. Our method promises to deliver such realism. <span>Note that key computer science technology companies have made announcements that they will heavily invest in metaverse technologies, with at least two companies (Meta and Apple) maintaining a large research and commercial effort on digital humans.</span></p>\r\n<p><strong>Dataset Contribution</strong><br />As part of the project, we released a free hand MRI dataset consisting of 4 subjects, each in 12 poses (48 MRI scans in total). This unique resource is valuable across multiple disciplines, including computer graphics, robotics, visualization, and medicine.</p>\r\n<p><a href=\"http://viterbi-web.usc.edu/~jbarbic/hand-mri-dataset/index.html\">http://viterbi-web.usc.edu/~jbarbic/hand-mri-dataset/index.html</a></p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/28/2024<br>\nModified by: Jernej&nbsp;Barbic</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe goal of this project is to significantly improve the modeling of human hand anatomy, kinematics, and dynamics, including bones, muscles, tendons, fat, and skin. While computational models of hand kinematics exist, few have attempted to model internal structures comprehensively or produce anatomically precise models that align with real-world data, especially across the entire range of motion of the hand. In this project, we acquired detailed hand anatomy in multiple (12) poses of the same subject, using MRI scans. These scans were segmented into bones, muscles, tendons, and fat for each scanned pose. We then simulated hand biomechanics using Finite Element Method (FEM) soft-tissue simulation. This enabled us to extrapolate the MRI scans and the musculoskeletal anatomy to any hand pose. We also trained neural networks to compute accurate hand shapes in any pose at very fast computational speeds. Our work has applications in virtual reality, robotics, medicine, physical therapy, computer graphics, and other interactive domains.\r\n\n\nKey Innovations\nOur model is uniquely detailed, comprising bones, muscles, tendons, fat, ligaments, and skin measured from a real person's hand. It distinguishes itself from other methods by:\r\n\r\nUnprecedented Anatomical Detail:We modeled all musculoskeletal tissues of the hand undergoing motion, a first in any field to our knowledge.\r\nMulti-Pose Data Acquisition:Unlike traditional approaches based on a single pose, we acquired data across multiple hand poses. This enabled a precise understanding of how each bone translates and rotates relative to its parent bone, and how the volumetric shape of the hand muscles changes as the hand articulates across its range of motion.\r\n\r\n\n\nThis allowed us to build an anatomically accurate model of musculoskeletal actuation during hand motion. Existing models are typically static or less detailed, whereas our work captures the hand anatomy in motion. By leveraging this detailed data and our FEM simulator, we also demonstrated how hands can be simulated in real time using deep neural networks, broadening applications to interactive computing, virtual reality, gaming, and real-time medicine.\r\n\n\nImpact on Robotics\nOur work advances understanding of internal hand anatomy and motion, which is crucial for developing next-generation robotic hands. Most robotic hands today use rigid structures actuated by servo motors at the joints. In contrast, human hand dexterity originates from the intricate interplay between soft tissues (muscles, tendons) and bones. Our insights pave the way for robotic hands that mimic biological functionality, potentially transforming prosthetics by enabling designs that replicate real hand versatility.\r\n\n\nApplications in Medical Education\nWe enable three-dimensional, real-time visualizations of how bones, muscles, ligaments, and tendons move inside the human hand during articulation. Similar to continuous X-ray imaging but without radiation risks, our technology offers a powerful new tool for medical education. Medical students can observe internal anatomy in motion, enhancing their understanding beyond static images in textbooks.\r\n\n\nRelevance to the Metaverse\nHuman hands play a pivotal role in next-generation metaverse technologies, which aim to revolutionize human communication in virtual reality. The metaverse is world's next generation human-to-human communication system, making it possible for any two humans on the planet to communicate highly realistically in virtual reality (think \"Holodec\" from Star Trek).Highly realistic digital hands are essential for creating lifelike virtual interactions. Our method promises to deliver such realism. Note that key computer science technology companies have made announcements that they will heavily invest in metaverse technologies, with at least two companies (Meta and Apple) maintaining a large research and commercial effort on digital humans.\r\n\n\nDataset Contribution\nAs part of the project, we released a free hand MRI dataset consisting of 4 subjects, each in 12 poses (48 MRI scans in total). This unique resource is valuable across multiple disciplines, including computer graphics, robotics, visualization, and medicine.\r\n\n\nhttp://viterbi-web.usc.edu/~jbarbic/hand-mri-dataset/index.html\r\n\n\n\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 11/28/2024\n\n\t\t\t\t\tSubmitted by: JernejBarbic\n"
 }
}