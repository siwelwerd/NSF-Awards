{
 "awd_id": "1901492",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Medium: Collaborative Research: Collaborative Online Learning and Control for Motor Prosthesis",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 633000.0,
 "awd_amount": 649000.0,
 "awd_min_amd_letter_date": "2019-08-26",
 "awd_max_amd_letter_date": "2020-07-31",
 "awd_abstract_narration": "It is estimated that approximately 5.4 million people in the United States live with some form of paralysis, defined as a central nervous system disorder resulting in difficulty or inability to move the upper and/or lower extremities. Many paralyzed individuals consider restoration of lost basic motor functions such as grasping and walking as important abilities that could improve their quality of life. The goal of this project is to develop and evaluate advanced machine learning algorithms that enable quadriplegic individuals to control a robotic hand with heterologous muscles (that is, muscles not typically involved in moving the limbs; for example, muscles of the neck). To enable this research, prospective algorithms will be initially evaluated in normally-enabled individuals. The most promising algorithms will subsequently be evaluated in quadriplegic individuals. This research is a first step toward providing benefit to the paralyzed community by creating pathways toward the development and commercialization of functional motor prosthetic systems. Paralyzed individuals can be trained to use the system by planning the movements in their minds, much like moving their natural limbs. Success of this research could lead to a significant advance in improving function and quality of life for individuals affected by stroke or spinal cord injury. High-School students as well as undergraduate and graduate students will be trained on this multi-disciplinary project.\r\n\r\nThis research involves learning human intent from biological signals, extracting higher-level goals using sensors embodied in the patient, and developing controllers for motor manipulation based on estimated motor movement intent and higher-level goals. Specific sub-goals proposed to achieve the overall goal of the project include: a collaborative brain-machine learning system that trains the human brain to remap limb movement control to heterologous muscles while simultaneously training the machine to interpret the movement intent from surface electromyograms of the heterologous muscles; algorithms to extract higher-level movement goals using biologic and auxiliary sensor signals; shared brain-machine controllers of robotic hands using the extracted goal and decoded movement intent; and experimental assessment of the capabilities of the methods on individuals with paralysis of the upper limbs. In addition to the innovations in the development of motor prostheses for people with paralysis of the limbs, the proposed research will provide new insights into online learning in nonlinear and time-varying environments, collaborative brain-machine learning, and shared brain-machine control algorithms for motor prostheses.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "V John",
   "pi_last_name": "Mathews",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "V John Mathews",
   "pi_email_addr": "mathews@oregonstate.edu",
   "nsf_id": "000707814",
   "pi_start_date": "2019-08-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Alan",
   "pi_last_name": "Fern",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alan Fern",
   "pi_email_addr": "afern@eecs.oregonstate.edu",
   "nsf_id": "000088242",
   "pi_start_date": "2019-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Oregon State University",
  "inst_street_address": "1500 SW JEFFERSON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CORVALLIS",
  "inst_state_code": "OR",
  "inst_state_name": "Oregon",
  "inst_phone_num": "5417374933",
  "inst_zip_code": "973318655",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "OR04",
  "org_lgl_bus_name": "OREGON STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "MZ4DYXE1SL98"
 },
 "perf_inst": {
  "perf_inst_name": "Oregon State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "OR",
  "perf_st_name": "Oregon",
  "perf_zip_code": "973318507",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "OR04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 206472.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 442528.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Approximately 5.4 million people in the USA live with some form of paralysis, defined as a central nervous system disorder resulting in difficulty or inability to move the upper and/or lower extremities. Many paralyzed individuals consider restoration of lost basic motor functions such as grasping and walking as important abilities that could improve their quality of life. The goal of this research was to develop and evaluate advanced machine learning algorithms that enable quadriplegic and amputee individuals to intuitively control a robotic hand (i. e., inferring motor tasks desired by the user and performing them) using biologic signals that may not used in motor control in healthy individuals with intact arms. This project contributed to the development of signal processing and machine learning algorithms that are fundamental to intuitive control of robotic arms, several prosthesis and robotic hand control algorithms, and evaluation of the methods in healthy volunteers with intact arms, upper arm amputees and quadriplegics. Important contributions of this work included:</p>\n<ul>\n<li>Continuous movement intent decoders, which interpret volitional movement intent from bioelectric (electromyograms (EMGs), peripheral nerve signals, electroencephalogram, etc.) and other sensor signals (e. g., camera outputs), are critical components of intuitive controllers. A general framework for shared control of prosthetic and robotic hands was developed in this work. It employs multiple movement intent decoders using bioelectric and external sensor signals and develops control strategies that combine the controllers based on individual decoders to achieve performance that may be better than controllers employing a single decoder. It was experimentally demonstrated that shared controllers can reduce the physical and cognitive demands of maintaining a secure grip.</li>\n<li> A critical issue in developing movement intent decoders based on EMGs measured from heterologous muscles (muscles that are not normally used in controlling movement) is to determine which muscles (and actions) to use and to train the prosthetic or robotic hand user to reliably and consistently evoke EMGs in the selected muscles to create specific movements. An efficient search algorithm and an experimental protocol were developed in this project to down select the actions from a large number of possible choices to the minimum number needed.</li>\n<li> Movement intent decoders, whose parameters are typically held constant after training, deteriorate in performance over time because the human body and bioelectric interfaces are non-stationary. This research formulated and developed a real-time framework for adaptive neural network-based decoders, whose parameters adapt over time. Experimental analysis demonstrated that the adaptive approach reduces performance degradation over time in a statistically significant manner over non-adaptive decoders.</li>\n<li> Noise in biological signals can lead to undesirable jitter in the output of movement intent decoders. A latching filter, which is a nonlinear system that operates on the output of the decoder and provides smoothing of small amplitude jitter while allowing quick changes to its output in response to large input changes was developed in this work. Experimental evaluations showed that the latching filter provided a statistically significant improvement in the user's ability to hold a prosthetic hand steady when compared to unsmoothed decoder outputs.</li>\n<li> A multimodal and modular assistive-robotic-arm control system using combinations of gyroscope measurements, eye-tracking, and heterologous EMG was created and validated in this research. Experimental evaluation in a virtual reality environment employing healthy and quadriplegic volunteer subjects indicated that the system provided adequate control to all participants to complete functional tasks such as opening door handles, turning stove dials, eating, and drinking, all of which enable independence and improved quality of life.</li>\n<li> Accurate separation of neural source signals from EMGs can substantially improve our ability to interpret movement intent. A blind, neural source separation algorithm for EMGs was developed in this research. Experimental work employing a high-density EMG data set demonstrated that this method performed statistically significantly better than two competing algorithms in accurately estimating the force evoked by the digits of the hand, providing better ability to control evoked forces in a robotic hand.</li>\n<li>Developing efficient training algorithms for neural networks is important for machine learning based movement decoders and robotic hand controllers. A generalized framework called AutoSGM for accelerated learning was developed in this research. This lowpass regularized learning framework contains as special cases several popular accelerated stochastic gradient methods including Adam. An optimal iteration-dependent learning rate was derived, and empirical analyses indicated that AutoSGM employing the iteration-dependent learning rate can outperform Adam in many situations.</li>\n</ul>\n<p>Successful adoption of the methods developed in this project could lead to significant advances in improving function and quality of life for individuals affected by limb amputation, stroke or spinal cord injury.</p>\n<p>Over the grant's duration, 2 high school students, 10 undergraduate students, 3 MS students, 3 PhD students&nbsp; and one post-doctoral student were trained on problems related to this grant. In addition, 2 undergraduates 1 MS student and 4 PhD students were trained at the University of Utah on a collaborative grant.</p><br>\n<p>\n Last Modified: 01/02/2024<br>\nModified by: V John&nbsp;Mathews</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nApproximately 5.4 million people in the USA live with some form of paralysis, defined as a central nervous system disorder resulting in difficulty or inability to move the upper and/or lower extremities. Many paralyzed individuals consider restoration of lost basic motor functions such as grasping and walking as important abilities that could improve their quality of life. The goal of this research was to develop and evaluate advanced machine learning algorithms that enable quadriplegic and amputee individuals to intuitively control a robotic hand (i. e., inferring motor tasks desired by the user and performing them) using biologic signals that may not used in motor control in healthy individuals with intact arms. This project contributed to the development of signal processing and machine learning algorithms that are fundamental to intuitive control of robotic arms, several prosthesis and robotic hand control algorithms, and evaluation of the methods in healthy volunteers with intact arms, upper arm amputees and quadriplegics. Important contributions of this work included:\n\nContinuous movement intent decoders, which interpret volitional movement intent from bioelectric (electromyograms (EMGs), peripheral nerve signals, electroencephalogram, etc.) and other sensor signals (e. g., camera outputs), are critical components of intuitive controllers. A general framework for shared control of prosthetic and robotic hands was developed in this work. It employs multiple movement intent decoders using bioelectric and external sensor signals and develops control strategies that combine the controllers based on individual decoders to achieve performance that may be better than controllers employing a single decoder. It was experimentally demonstrated that shared controllers can reduce the physical and cognitive demands of maintaining a secure grip.\n A critical issue in developing movement intent decoders based on EMGs measured from heterologous muscles (muscles that are not normally used in controlling movement) is to determine which muscles (and actions) to use and to train the prosthetic or robotic hand user to reliably and consistently evoke EMGs in the selected muscles to create specific movements. An efficient search algorithm and an experimental protocol were developed in this project to down select the actions from a large number of possible choices to the minimum number needed.\n Movement intent decoders, whose parameters are typically held constant after training, deteriorate in performance over time because the human body and bioelectric interfaces are non-stationary. This research formulated and developed a real-time framework for adaptive neural network-based decoders, whose parameters adapt over time. Experimental analysis demonstrated that the adaptive approach reduces performance degradation over time in a statistically significant manner over non-adaptive decoders.\n Noise in biological signals can lead to undesirable jitter in the output of movement intent decoders. A latching filter, which is a nonlinear system that operates on the output of the decoder and provides smoothing of small amplitude jitter while allowing quick changes to its output in response to large input changes was developed in this work. Experimental evaluations showed that the latching filter provided a statistically significant improvement in the user's ability to hold a prosthetic hand steady when compared to unsmoothed decoder outputs.\n A multimodal and modular assistive-robotic-arm control system using combinations of gyroscope measurements, eye-tracking, and heterologous EMG was created and validated in this research. Experimental evaluation in a virtual reality environment employing healthy and quadriplegic volunteer subjects indicated that the system provided adequate control to all participants to complete functional tasks such as opening door handles, turning stove dials, eating, and drinking, all of which enable independence and improved quality of life.\n Accurate separation of neural source signals from EMGs can substantially improve our ability to interpret movement intent. A blind, neural source separation algorithm for EMGs was developed in this research. Experimental work employing a high-density EMG data set demonstrated that this method performed statistically significantly better than two competing algorithms in accurately estimating the force evoked by the digits of the hand, providing better ability to control evoked forces in a robotic hand.\nDeveloping efficient training algorithms for neural networks is important for machine learning based movement decoders and robotic hand controllers. A generalized framework called AutoSGM for accelerated learning was developed in this research. This lowpass regularized learning framework contains as special cases several popular accelerated stochastic gradient methods including Adam. An optimal iteration-dependent learning rate was derived, and empirical analyses indicated that AutoSGM employing the iteration-dependent learning rate can outperform Adam in many situations.\n\n\n\nSuccessful adoption of the methods developed in this project could lead to significant advances in improving function and quality of life for individuals affected by limb amputation, stroke or spinal cord injury.\n\n\nOver the grant's duration, 2 high school students, 10 undergraduate students, 3 MS students, 3 PhD students and one post-doctoral student were trained on problems related to this grant. In addition, 2 undergraduates 1 MS student and 4 PhD students were trained at the University of Utah on a collaborative grant.\t\t\t\t\tLast Modified: 01/02/2024\n\n\t\t\t\t\tSubmitted by: V JohnMathews\n"
 }
}