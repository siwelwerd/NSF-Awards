{
 "awd_id": "1923980",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CyberTraining: Pilot: Semi-Automatic Assessment of Parallel Programs in Training of Students and Faculty",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032928235",
 "po_email": "bmihaila@nsf.gov",
 "po_sign_block_name": "Bogdan Mihaila",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 82000.0,
 "awd_amount": 82000.0,
 "awd_min_amd_letter_date": "2019-07-10",
 "awd_max_amd_letter_date": "2023-08-28",
 "awd_abstract_narration": "Modern computers allow a computer program to be decomposed into multiple activities or threads that can execute concurrently.  Emerging big-data scientific, health, social, and engineering applications require such concurrency to give results in a timely manner. The key to matching the computation needs of these applications to the available computing resources is training of a workforce to develop, maintain, and configure concurrent programs. Ongoing work on developing toolkits for teaching concurrency is challenging because instruction is particularly labor-intensive, and thus, these toolkits, on their own, cannot help instructors meet the demands for such instruction. Specifically, concurrent programs are notoriously difficult to write, and substantial instructor effort is required to evaluate the performance and correctness of these programs, and identify potential problems. This project will extend an existing instructional toolkit with a new software framework to automate assessment of concurrent programs, and using instructional workshops and university courses to validate the extended toolkit. Successful execution of the project will improve the workforce development and promote the progress of science.\r\n\r\nThe main research question we are exploring is: What should be the nature of a rule-based software framework for assessing concurrent programs written in multiple programming languages that improves the productivity and learning, respectively, of trainers and trainees? The key novel steps we are taking to explore this question are (a) development of a semi-automatic assessment model in which manual evaluation, integrated with automatic rules, reduces false positives and negatives of the automated checks; (b) identification of  new protocols and associated architectures that leverage the capabilities of several existing powerful tools that have not been used before to address our question, (c) creation of new techniques based on the insight that solutions to a concurrent programming assignment often have a prescribed code-structure and algorithm, (d) support for layered techniques that allow rule-writers to tradeoff assessment quality for low rule-writing effort, (e) development of a meta-assessment framework to train the trainers to write rules, (f) use of the meta-assessment and assessment framework in instructional workshops and university course offerings, respectively, and (g) evaluation of the usability, programmability, effectiveness and learning gain of the frameworks through diverse mechanisms including pre-post surveys, course exit interviews, and focus groups.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Rogers",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Michael D Rogers",
   "pi_email_addr": "mrogers@tntech.edu",
   "nsf_id": "000342292",
   "pi_start_date": "2023-02-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Sheikh",
   "pi_last_name": "Ghafoor",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sheikh Ghafoor",
   "pi_email_addr": "sghafoor@tntech.edu",
   "nsf_id": "000555279",
   "pi_start_date": "2019-07-10",
   "pi_end_date": "2023-02-06"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ada",
   "pi_last_name": "Haynes",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ada Haynes",
   "pi_email_addr": "ahaynes@tntech.edu",
   "nsf_id": "000348659",
   "pi_start_date": "2019-07-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Tennessee Technological University",
  "inst_street_address": "1 WILLIAM L JONES DR",
  "inst_street_address_2": "",
  "inst_city_name": "COOKEVILLE",
  "inst_state_code": "TN",
  "inst_state_name": "Tennessee",
  "inst_phone_num": "9313723374",
  "inst_zip_code": "385050001",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "TN06",
  "org_lgl_bus_name": "TENNESSEE TECHNOLOGICAL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "KZNHNMDUTJA5"
 },
 "perf_inst": {
  "perf_inst_name": "Tennessee Technological University",
  "perf_str_addr": "",
  "perf_city_name": "Cookeville",
  "perf_st_code": "TN",
  "perf_st_name": "Tennessee",
  "perf_zip_code": "385050001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "TN06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "044Y00",
   "pgm_ele_name": "CyberTraining - Training-based"
  },
  {
   "pgm_ele_code": "199800",
   "pgm_ele_name": "IUSE"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8209",
   "pgm_ref_txt": "Improv Undergrad STEM Ed(IUSE)"
  },
  {
   "pgm_ref_code": "8244",
   "pgm_ref_txt": "EHR CL Opportunities (NSF 14-302)"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0419",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001920DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 82000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Emerging big-data scientific, health, social, and engineering applications require concurrency to give results in a timely manner. The key to matching the computational needs of these applications to the available computing resources is training of a workforce to develop, maintain, and configure concurrent programs. Ongoing work on developing toolkits for teaching concurrency is challenging because instruction is particularly labor-intensive, and thus, these toolkits, on their own, cannot help instructors meet the demands for such instruction. Specifically, concurrent programs are notoriously difficult to write, and substantial instructor effort is required to evaluate the performance and correctness of these programs, and identify potential problems. The broader impacts of this project are (a) it extends an existing instructional toolkit with a new software framework to automate assessment of concurrent programs, (b) it uses instructional workshops and university courses to validate the extended toolkit,&nbsp; (c) it trained 77 faculty through faculty development workshops at Tennessee Tech University and at IEEE EduHiPC training workhops for integrating parallel and distributed computing into their introductory programming classes, and (d) refined hands-on modules for introductory computing classes.</p>\r\n<p>This project&rsquo;s intellectual merit was the development of a rule-based software framework for assessing concurrent programs that improves the teaching and learning. The key outcomes of the project are: (a) we developed a semi-automatic assessment model in which manual evaluation, integrated with automatic rules, reduces false positives and negatives of the automated checks, (b) identified new protocols and associated architectures that leverage the capabilities of several existing powerful tools, (c) created new techniques based on the insight that solutions to a concurrent programming assignment often have a prescribed code-structure and algorithm, and (d) supported the development of a meta-assessment framework.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/05/2025<br>\nModified by: Michael&nbsp;D&nbsp;Rogers</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nEmerging big-data scientific, health, social, and engineering applications require concurrency to give results in a timely manner. The key to matching the computational needs of these applications to the available computing resources is training of a workforce to develop, maintain, and configure concurrent programs. Ongoing work on developing toolkits for teaching concurrency is challenging because instruction is particularly labor-intensive, and thus, these toolkits, on their own, cannot help instructors meet the demands for such instruction. Specifically, concurrent programs are notoriously difficult to write, and substantial instructor effort is required to evaluate the performance and correctness of these programs, and identify potential problems. The broader impacts of this project are (a) it extends an existing instructional toolkit with a new software framework to automate assessment of concurrent programs, (b) it uses instructional workshops and university courses to validate the extended toolkit, (c) it trained 77 faculty through faculty development workshops at Tennessee Tech University and at IEEE EduHiPC training workhops for integrating parallel and distributed computing into their introductory programming classes, and (d) refined hands-on modules for introductory computing classes.\r\n\n\nThis projects intellectual merit was the development of a rule-based software framework for assessing concurrent programs that improves the teaching and learning. The key outcomes of the project are: (a) we developed a semi-automatic assessment model in which manual evaluation, integrated with automatic rules, reduces false positives and negatives of the automated checks, (b) identified new protocols and associated architectures that leverage the capabilities of several existing powerful tools, (c) created new techniques based on the insight that solutions to a concurrent programming assignment often have a prescribed code-structure and algorithm, and (d) supported the development of a meta-assessment framework.\r\n\n\n\t\t\t\t\tLast Modified: 02/05/2025\n\n\t\t\t\t\tSubmitted by: MichaelDRogers\n"
 }
}