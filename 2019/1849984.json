{
 "awd_id": "1849984",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: IIS: RUI: Understanding Learning Analytics Algorithms in Teacher and Student Decision-making",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Bainbridge",
 "awd_eff_date": "2019-05-01",
 "awd_exp_date": "2023-04-30",
 "tot_intn_awd_amt": 150474.0,
 "awd_amount": 150474.0,
 "awd_min_amd_letter_date": "2019-04-19",
 "awd_max_amd_letter_date": "2019-04-19",
 "awd_abstract_narration": "This project explores the relationship between instructor and student understanding of the artificial intelligence (AI) algorithms that underlay their educational technology, and the impact of that algorithmic understanding on decision-making for learning. The research will involve studies with people to investigate how algorithmic understanding impacts system trust and decision-making for learning, as well as the development of \"explainables\" or brief, engaging interactive tutoring systems to provide algorithmic understanding to classroom stakeholders. These two thrusts will yield a framework for designers of algorithmically enhanced learning environments to determine what level of algorithmic understanding is necessary to achieve the goals of informed decision-making by users of their systems.  The explainables developed by this project will be publicly accessible and usable by external projects, increasing algorithmic understanding for the initially intended stakeholders, but also for the general public.  The main contributions of this work include a methodologically rigorous investigation of the knowledge components of algorithmic understanding for learning contexts that can be applied to model interpretability discussions in the wider machine learning community.\r\n\r\nThe research involves systematically identifying the concepts that qualify as \"understanding\" an AI algorithm, building brief interactive tutoring systems to target those concepts, and observing resultant changes in system trust and decision-making for learning contexts.  It combines approaches from the learning sciences, human-computer interaction, ethics, and machine learning. Student researchers will perform cognitive task analyses to identify hierarchical models of expert comprehension of AI models, apply a user-centered design process to develop explainables to teach the varying levels of expert comprehension, and perform evaluation studies comparing various explainables' impact on algorithmic understanding, trust, and decision making. The results will add to ongoing discussions about ethical algorithmic transparency in the larger machine learning community, but also provide an actionable framework for developing a more AI-informed student and teacher body as well as lightweight explainables for appending to external algorithmically enhanced learning environments.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Iris",
   "pi_last_name": "Howley",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Iris Howley",
   "pi_email_addr": "iris@cs.williams.edu",
   "nsf_id": "000785151",
   "pi_start_date": "2019-04-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Williams College",
  "inst_street_address": "880 MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "WILLIAMSTOWN",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135974352",
  "inst_zip_code": "012672600",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MA01",
  "org_lgl_bus_name": "PRESIDENT & TRUSTEES OF WILLIAMS COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "JVZEJJ6N5EM8"
 },
 "perf_inst": {
  "perf_inst_name": "Williams College",
  "perf_str_addr": "",
  "perf_city_name": "Williamstown",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "012672565",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "MA01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 150474.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>With the growing use of Artificial Intelligence (AI) and complex algorithmic systems, it is necessary that users of these systems understand the potential biases, flaws, limitations, and strengths of the algorithms they use. The overall goal of this project is to empower users of complex algorithmic systems to appropriately interrogate their systems' algorithms. This project achieved that through identifying necessary algorithmic understanding, teaching that understanding, and then evaluating what effect that understanding has on user behavior. The domain context selected for this project was learning analytics in which Bayesian Knowledge Tracing (BKT), an algorithm to predict student skill mastery is used by instructors and students through a variety of educational technologies.</p>\n<p>Findings from our randomized controlled experiment comparing interactive and static versions of the same tutorial show that depending on the user's educational background, different interactive modes will be more effective. A further controlled experiment investigated the impact of varying the amount of shared knowledge about the algorithm's limitations on participant attitudes about AI and the algorithm. Our results from this final study show that less information is not always worse. Participants who received some information about BKT's limitations had no change in general attitudes about AI (unlike participants who received all information or no information who showed an increase in positive general attitudes toward AI). They also trusted the accuracy of the BKT algorithm significantly less than the all-information and no-information groups.</p>\n<p>Other key outcomes of this project include a collection of knowledge components that experts use when using a complex AI algorithm. These publicly available knowledge components are shared so that others may design their own interactive tutorials of BKT and other algorithms.&nbsp; The project also produced over ten prototypes of interactive tutorials exploring the design space of ways to explain a complex algorithm.</p>\n<p>&nbsp;</p>\n<p>This project provided funding for eight undergraduate students, largely from under-represented groups in computing, to experience computer science research, including sending two students to a competitive academic research conference to present their work. Four of the students funded by this project have begun PhD programs in computer science, information science, and economics.</p>\n<p>&nbsp;</p>\n<p>This project also furthered the development of an undergraduate course on \"Human Artificial Intelligence Interaction\" now offered regularly at Williams College.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/01/2023<br>\n\t\t\t\t\tModified by: Iris&nbsp;Howley</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1849984/1849984_10601532_1690906525355_xAIdesign-framework--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1849984/1849984_10601532_1690906525355_xAIdesign-framework--rgov-800width.jpg\" title=\"Designing Evaluable Post-hoc Explainable Artificial Intelligence\"><img src=\"/por/images/Reports/POR/2023/1849984/1849984_10601532_1690906525355_xAIdesign-framework--rgov-66x44.jpg\" alt=\"Designing Evaluable Post-hoc Explainable Artificial Intelligence\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A framework diagram for building evaluable XAI, including identifying learning objectives, then assessments of that understanding, and then building activities to support that understanding.</div>\n<div class=\"imageCredit\">Iris Howley</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Iris&nbsp;Howley</div>\n<div class=\"imageTitle\">Designing Evaluable Post-hoc Explainable Artificial Intelligence</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nWith the growing use of Artificial Intelligence (AI) and complex algorithmic systems, it is necessary that users of these systems understand the potential biases, flaws, limitations, and strengths of the algorithms they use. The overall goal of this project is to empower users of complex algorithmic systems to appropriately interrogate their systems' algorithms. This project achieved that through identifying necessary algorithmic understanding, teaching that understanding, and then evaluating what effect that understanding has on user behavior. The domain context selected for this project was learning analytics in which Bayesian Knowledge Tracing (BKT), an algorithm to predict student skill mastery is used by instructors and students through a variety of educational technologies.\n\nFindings from our randomized controlled experiment comparing interactive and static versions of the same tutorial show that depending on the user's educational background, different interactive modes will be more effective. A further controlled experiment investigated the impact of varying the amount of shared knowledge about the algorithm's limitations on participant attitudes about AI and the algorithm. Our results from this final study show that less information is not always worse. Participants who received some information about BKT's limitations had no change in general attitudes about AI (unlike participants who received all information or no information who showed an increase in positive general attitudes toward AI). They also trusted the accuracy of the BKT algorithm significantly less than the all-information and no-information groups.\n\nOther key outcomes of this project include a collection of knowledge components that experts use when using a complex AI algorithm. These publicly available knowledge components are shared so that others may design their own interactive tutorials of BKT and other algorithms.  The project also produced over ten prototypes of interactive tutorials exploring the design space of ways to explain a complex algorithm.\n\n \n\nThis project provided funding for eight undergraduate students, largely from under-represented groups in computing, to experience computer science research, including sending two students to a competitive academic research conference to present their work. Four of the students funded by this project have begun PhD programs in computer science, information science, and economics.\n\n \n\nThis project also furthered the development of an undergraduate course on \"Human Artificial Intelligence Interaction\" now offered regularly at Williams College.\n\n\t\t\t\t\tLast Modified: 08/01/2023\n\n\t\t\t\t\tSubmitted by: Iris Howley"
 }
}