{
 "awd_id": "1910830",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Small: Regret-Bounded Query Evaluation via Reinforcement Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Wei Ding",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 499999.0,
 "awd_amount": 499999.0,
 "awd_min_amd_letter_date": "2019-07-27",
 "awd_max_amd_letter_date": "2020-07-10",
 "awd_abstract_narration": "Database systems try to shield their users from the intricacies of data processing. Users specify queries at a high level of abstraction, describing desired results rather than the way in which they are generated. Hence, given a query, database systems need to find efficient data processing plans automatically. Those plans are generated based on simplifying assumptions about queries and data. All too often, those assumptions turn out to be overly simplistic and generated plans do not finish within reasonable amounts of processing time. In such cases, efficient processing plans must be generated manually, based on expert knowledge. This creates high overheads for organizations which employ database experts. Laymen users who have no access to such expertise may be unable to execute certain queries altogether. The proposed project will overcome those challenges by a novel approach to plan generation. This approach makes no simplifying assumptions and therefore guarantees near-optimal plans.\r\n\r\nThe proposed work will explore the potential for \"intra-query learning,\" a new approach combining query execution and plan generation. Intra-query learning divides the execution of a single query into many micro-episodes in which different plans are tried. Each episode serves two purposes. First, it generates query result fragments that will be collected to form complete query results. Second, it yields information on the quality of plan alternatives. This information will be leveraged to select better plans for the remaining episodes. The project will use methods from the area of reinforcement learning to select plans in each episode. Those methods offer formal guarantees on making near-optimal decisions under uncertainty. This project will translate such guarantees into guarantees on near-optimal expected processing cost. The research outcomes will be integrated into SkinnerDB, a novel database system designed from the ground up for robust performance without manual interventions. SkinnerDB will entirely abandon tools such as coarse-grained data statistics, or simplifying cost and cardinality models, that are traditionally used to select query plans. Instead, it will rely exclusively on reinforcement learning in combination with an execution engine that is tailored to the needs of intra-query learning. This will enable it to learn near-optimal plans from scratch even for queries that execute on freshly loaded data or contain newly introduced user-defined functions. Starting from a first approach showing promising performance, the project will explore various extensions such as parallel and distributed processing, query plan compilation, and disk-based data processing.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Immanuel",
   "pi_last_name": "Trummer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Immanuel Trummer",
   "pi_email_addr": "it224@cornell.edu",
   "nsf_id": "000738187",
   "pi_start_date": "2019-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "107 Hoy Road",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148537501",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 363257.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 136742.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Database management systems, i.e. systems that manage and process large data sets, are nowadays ubiquitous. Their performance depends significantly on various tuning decisions. These include, for instance, the order of data analysis operations as well as the choice of auxiliary data structures, created to enable fast access to data subsets. Traditionally, such tuning decisions are made automatically, based on hand-crafted models that predict performance for specific tuning choices. Unfortunately, such models are often unreliable, leading to highly sub-optimal tuning choices that require manual intervention.</p>\n<p>This project explores novel approaches to automated database tuning. Instead of relying on hand-crafted performance models, tuning options are evaluated by measuring performance of live trial runs on small data samples. This approach yields more reliable performance estimates, compared to prior models. On the other side, evaluating tuning options via trial runs is expensive. Hence the need for a framework that carefully selects the most interesting tuning options to evaluate next, balancing the desire for refining seemingly promising tuning options with the need to try novel alternatives. Reinforcement learning resolves this dilemma in a principled manner and guarantees near-optimal choices in the face of uncertainty.&nbsp;</p>\n<p>The project has resulted in multiple research prototypes that apply the approach described above to database tuning problems. SkinnerDB uses reinforcement learning to find optimal execution orders for analysis operators. It divides data processing into small time slices in which different orders are tried. To make this approach efficient, it uses a customized processing engine and data structures that are tailored for fast order switching. UDO, the Universal Database Optimizer, addresses various database tuning problems via a specialized reinforcement learning algorithm. This algorithm enables UDO to delay evaluation of tuning options, selected via reinforcement learning. Thereby, it allows the system to amortize database reconfiguration overheads over large batches of tuning options to evaluate.&nbsp;</p>\n<p>A comparison to prior work reveals that reinforcement learning is often preferable over prior methods. This applies specifically to common scenarios in which simplifying assumptions, typically used to construct traditional performance prediction models, do not hold. In such cases, tuning options selected via reinforcement learning may reduce data processing overheads by orders of magnitude. The research outcomes of this project have been disseminated to the scientific community in publications at primary venues in the database area, some of them were selected for awards. The source code of all systems developed over the course of this project is publicly available.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/17/2022<br>\n\t\t\t\t\tModified by: Immanuel&nbsp;Trummer</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDatabase management systems, i.e. systems that manage and process large data sets, are nowadays ubiquitous. Their performance depends significantly on various tuning decisions. These include, for instance, the order of data analysis operations as well as the choice of auxiliary data structures, created to enable fast access to data subsets. Traditionally, such tuning decisions are made automatically, based on hand-crafted models that predict performance for specific tuning choices. Unfortunately, such models are often unreliable, leading to highly sub-optimal tuning choices that require manual intervention.\n\nThis project explores novel approaches to automated database tuning. Instead of relying on hand-crafted performance models, tuning options are evaluated by measuring performance of live trial runs on small data samples. This approach yields more reliable performance estimates, compared to prior models. On the other side, evaluating tuning options via trial runs is expensive. Hence the need for a framework that carefully selects the most interesting tuning options to evaluate next, balancing the desire for refining seemingly promising tuning options with the need to try novel alternatives. Reinforcement learning resolves this dilemma in a principled manner and guarantees near-optimal choices in the face of uncertainty. \n\nThe project has resulted in multiple research prototypes that apply the approach described above to database tuning problems. SkinnerDB uses reinforcement learning to find optimal execution orders for analysis operators. It divides data processing into small time slices in which different orders are tried. To make this approach efficient, it uses a customized processing engine and data structures that are tailored for fast order switching. UDO, the Universal Database Optimizer, addresses various database tuning problems via a specialized reinforcement learning algorithm. This algorithm enables UDO to delay evaluation of tuning options, selected via reinforcement learning. Thereby, it allows the system to amortize database reconfiguration overheads over large batches of tuning options to evaluate. \n\nA comparison to prior work reveals that reinforcement learning is often preferable over prior methods. This applies specifically to common scenarios in which simplifying assumptions, typically used to construct traditional performance prediction models, do not hold. In such cases, tuning options selected via reinforcement learning may reduce data processing overheads by orders of magnitude. The research outcomes of this project have been disseminated to the scientific community in publications at primary venues in the database area, some of them were selected for awards. The source code of all systems developed over the course of this project is publicly available.\n\n\t\t\t\t\tLast Modified: 11/17/2022\n\n\t\t\t\t\tSubmitted by: Immanuel Trummer"
 }
}