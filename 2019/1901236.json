{
 "awd_id": "1901236",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Medium: Collaborative Research: Collaborative Online Learning and Control for Motor Prosthesis",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 508255.0,
 "awd_amount": 508255.0,
 "awd_min_amd_letter_date": "2019-08-26",
 "awd_max_amd_letter_date": "2020-08-04",
 "awd_abstract_narration": "It is estimated that approximately 5.4 million people in the United States live with some form of paralysis, defined as a central nervous system disorder resulting in difficulty or inability to move the upper and/or lower extremities. Many paralyzed individuals consider restoration of lost basic motor functions such as grasping and walking as important abilities that could improve their quality of life. The goal of this project is to develop and evaluate advanced machine learning algorithms that enable quadriplegic individuals to control a robotic hand with heterologous muscles (that is, muscles not typically involved in moving the limbs; for example, muscles of the neck). To enable this research, prospective algorithms will be initially evaluated in normally-enabled individuals. The most promising algorithms will subsequently be evaluated in quadriplegic individuals. This research is a first step toward providing benefit to the paralyzed community by creating pathways toward the development and commercialization of functional motor prosthetic systems. Paralyzed individuals can be trained to use the system by planning the movements in their minds, much like moving their natural limbs. Success of this research could lead to a significant advance in improving function and quality of life for individuals affected by stroke or spinal cord injury. High-School students as well as undergraduate and graduate students will be trained on this multi-disciplinary project.\r\n\r\nThis research involves learning human intent from biological signals, extracting higher-level goals using sensors embodied in the patient, and developing controllers for motor manipulation based on estimated motor movement intent and higher-level goals. Specific sub-goals proposed to achieve the overall goal of the project include: a collaborative brain-machine learning system that trains the human brain to remap limb movement control to heterologous muscles while simultaneously training the machine to interpret the movement intent from surface electromyograms of the heterologous muscles; algorithms to extract higher-level movement goals using biologic and auxiliary sensor signals; shared brain-machine controllers of robotic hands using the extracted goal and decoded movement intent; and experimental assessment of the capabilities of the methods on individuals with paralysis of the upper limbs. In addition to the innovations in the development of motor prostheses for people with paralysis of the limbs, the proposed research will provide new insights into online learning in nonlinear and time-varying environments, collaborative brain-machine learning, and shared brain-machine control algorithms for motor prostheses.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Warren",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "David J Warren",
   "pi_email_addr": "David.Warren@utah.edu",
   "nsf_id": "000588288",
   "pi_start_date": "2019-08-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gregory",
   "pi_last_name": "Clark",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Gregory A Clark",
   "pi_email_addr": "greg.clark@m.cc.utah.edu",
   "nsf_id": "000089927",
   "pi_start_date": "2019-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841128930",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 166481.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 341774.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Approximately 5.4 million people in the United States live with paralysis, defined as a central nervous system disorder resulting in difficulty or inability to move the upper and/or lower extremities. Many paralyzed individuals consider restoration of lost basic motor functions, such as grasping and walking, as important abilities that could improve their quality of life. This research&rsquo;s goal was to develop and evaluate advanced machine learning algorithms that enable tetraplegic and amputee individuals to intuitively control a robotic hand (i.e., inferring a user&rsquo;s desired movements and performing them) using biological signals that may not be involved in such motor control by individuals with intact arms. This project contributed to the development of signal processing and machine learning algorithms that are fundamental to the intuitive control of robotic arms and hands, and evaluated these in intact arms volunteers, upper arm amputee volunteers, and quadriplegic volunteers. Important contributions resulting from this work included the following:</p>\n<ul>\n<li>Continuous movement intent decoders, which interpret volitional movement intent from bioelectric (electromyograms (EMGs), peripheral nerve signals, electroencephalogram, etc.) and other sensor signals (e.g., camera outputs), are critical components of intuitive controllers. A general framework for shared control of prosthetic and robotic hands was developed in this work. It employs multiple movement intent decoders using bioelectric and external sensor signals and develops control strategies that combine individual decoders to achieve performance that may be better than any individual decoders on its own. It was experimentally demonstrated that shared controllers can reduce the physical and cognitive demands of maintaining a secure grip.</li>\n<li>A critical issue in developing movement intent decoders based on EMGs measured from heterologous muscles (muscles not normally used in desired movement) is to determine which muscles (and actions) to use and to train the prosthetic or robotic hand user to evoke EMGs reliably and consistently in the selected muscles to create specific movements. An efficient search algorithm and an experimental protocol were developed to downselect the actions from a large number of possible choices to the minimum number needed. </li>\n<li>Movement intent decoders, whose parameters are typically held constant after training, deteriorate in performance over time because the human body and bioelectric interfaces are non-stationary. This research formulated and developed a real-time framework for adaptive neural network-based decoders, whose parameters adapt over time. Experimental analysis demonstrated that the adaptive approach reduces performance degradation over time in a statistically significant manner over non-adaptive decoders.</li>\n<li>Noise in biological signals can lead to undesirable jitter in the output of movement intent decoders. A latching filter was developed, which is a nonlinear system that operates on the output of the decoder and provides smoothing of small amplitude jitter while allowing quick changes to its output in response to large input changes. Experimental evaluations showed that the latching filter provided a statistically significant improvement in the user&rsquo;s ability to hold a prosthetic hand steady when compared to unsmoothed decoder outputs.</li>\n<li>A multimodal and modular assistive-robotic-arm control system using combinations of gyroscope measurements, eye-tracking, and heterologous EMG was created and validated in this research. Experimental evaluation in a virtual reality environment employing healthy and quadriplegic volunteer subjects indicated that the system provided adequate control to all participants to complete functional tasks such as opening door handles, turning stove dials, eating, and drinking, which could enable independence and improved quality of life for these individuals.</li>\n<li>Accurate separation of neural source signals from EMGs can substantially improve our ability to interpret movement intent. A blind, neural source separation algorithm was developed. Experimental work employing a high-density EMG data set demonstrated that this method performed statistically significantly better than two competing algorithms in accurately estimating the force evoked by the digits of the hand, providing a better ability to control the force evoked by a robotic hand&rsquo;s digits.</li>\n<li>Developing efficient training algorithms for neural networks is important for machine learning-based movement decoders and robotic hand controllers. A generalized framework called AutoSGM for accelerated learning was developed in this research. This lowpass regularized learning framework contains, as special cases, several popular accelerated stochastic gradient methods including Adam. An optimal iteration-dependent learning rate was derived, and empirical analyses indicated that AutoSGM employing the iteration-dependent learning rate can outperform Adam in many situations.</li>\n</ul>\n<p>Successful adoption of the methods developed in this project could lead to a significant advance in improving function and quality of life for individuals affected by stroke or spinal cord injury.</p>\n<p>This project furthered the training and development of multiple high school, undergraduate, and graduate students. Over the grant&rsquo;s duration, 5 PhD students, 1 masters&rsquo; student, and 1 undergraduate student were trained in problems related to this grant. In addition, 2 high school students, 10 undergraduate students, 3 master&rsquo;s students, 3 PhD students, and one post-doctoral student were trained at Oregon State University on a collaborative grant.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/03/2024<br>\nModified by: David&nbsp;J&nbsp;Warren</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nApproximately 5.4 million people in the United States live with paralysis, defined as a central nervous system disorder resulting in difficulty or inability to move the upper and/or lower extremities. Many paralyzed individuals consider restoration of lost basic motor functions, such as grasping and walking, as important abilities that could improve their quality of life. This researchs goal was to develop and evaluate advanced machine learning algorithms that enable tetraplegic and amputee individuals to intuitively control a robotic hand (i.e., inferring a users desired movements and performing them) using biological signals that may not be involved in such motor control by individuals with intact arms. This project contributed to the development of signal processing and machine learning algorithms that are fundamental to the intuitive control of robotic arms and hands, and evaluated these in intact arms volunteers, upper arm amputee volunteers, and quadriplegic volunteers. Important contributions resulting from this work included the following:\n\nContinuous movement intent decoders, which interpret volitional movement intent from bioelectric (electromyograms (EMGs), peripheral nerve signals, electroencephalogram, etc.) and other sensor signals (e.g., camera outputs), are critical components of intuitive controllers. A general framework for shared control of prosthetic and robotic hands was developed in this work. It employs multiple movement intent decoders using bioelectric and external sensor signals and develops control strategies that combine individual decoders to achieve performance that may be better than any individual decoders on its own. It was experimentally demonstrated that shared controllers can reduce the physical and cognitive demands of maintaining a secure grip.\nA critical issue in developing movement intent decoders based on EMGs measured from heterologous muscles (muscles not normally used in desired movement) is to determine which muscles (and actions) to use and to train the prosthetic or robotic hand user to evoke EMGs reliably and consistently in the selected muscles to create specific movements. An efficient search algorithm and an experimental protocol were developed to downselect the actions from a large number of possible choices to the minimum number needed. \nMovement intent decoders, whose parameters are typically held constant after training, deteriorate in performance over time because the human body and bioelectric interfaces are non-stationary. This research formulated and developed a real-time framework for adaptive neural network-based decoders, whose parameters adapt over time. Experimental analysis demonstrated that the adaptive approach reduces performance degradation over time in a statistically significant manner over non-adaptive decoders.\nNoise in biological signals can lead to undesirable jitter in the output of movement intent decoders. A latching filter was developed, which is a nonlinear system that operates on the output of the decoder and provides smoothing of small amplitude jitter while allowing quick changes to its output in response to large input changes. Experimental evaluations showed that the latching filter provided a statistically significant improvement in the users ability to hold a prosthetic hand steady when compared to unsmoothed decoder outputs.\nA multimodal and modular assistive-robotic-arm control system using combinations of gyroscope measurements, eye-tracking, and heterologous EMG was created and validated in this research. Experimental evaluation in a virtual reality environment employing healthy and quadriplegic volunteer subjects indicated that the system provided adequate control to all participants to complete functional tasks such as opening door handles, turning stove dials, eating, and drinking, which could enable independence and improved quality of life for these individuals.\nAccurate separation of neural source signals from EMGs can substantially improve our ability to interpret movement intent. A blind, neural source separation algorithm was developed. Experimental work employing a high-density EMG data set demonstrated that this method performed statistically significantly better than two competing algorithms in accurately estimating the force evoked by the digits of the hand, providing a better ability to control the force evoked by a robotic hands digits.\nDeveloping efficient training algorithms for neural networks is important for machine learning-based movement decoders and robotic hand controllers. A generalized framework called AutoSGM for accelerated learning was developed in this research. This lowpass regularized learning framework contains, as special cases, several popular accelerated stochastic gradient methods including Adam. An optimal iteration-dependent learning rate was derived, and empirical analyses indicated that AutoSGM employing the iteration-dependent learning rate can outperform Adam in many situations.\n\n\n\nSuccessful adoption of the methods developed in this project could lead to a significant advance in improving function and quality of life for individuals affected by stroke or spinal cord injury.\n\n\nThis project furthered the training and development of multiple high school, undergraduate, and graduate students. Over the grants duration, 5 PhD students, 1 masters student, and 1 undergraduate student were trained in problems related to this grant. In addition, 2 high school students, 10 undergraduate students, 3 masters students, 3 PhD students, and one post-doctoral student were trained at Oregon State University on a collaborative grant.\n\n\n\t\t\t\t\tLast Modified: 01/03/2024\n\n\t\t\t\t\tSubmitted by: DavidJWarren\n"
 }
}