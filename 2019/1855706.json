{
 "awd_id": "1855706",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Turning Visual Noise into Hardware Efficiency: Viewer-Aware Energy-Quality Adaptive Mobile Video Storage",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Danella Zhao",
 "awd_eff_date": "2018-11-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 316000.0,
 "awd_min_amd_letter_date": "2018-10-22",
 "awd_max_amd_letter_date": "2020-02-13",
 "awd_abstract_narration": "Mobile devices, such as smart phones, are being increasingly utilized for watching videos, since they can be conveniently used for this purpose anywhere anytime, such as commuting on a subway or train, sitting in a waiting room, or lounging at home. Due to the large data size and intensive computation, video processing requires frequent memory access that consumes a large amount of power, limiting battery life and frustrating mobile users. On one hand, memory designers are focusing on hardware-level power-optimization techniques without considering how hardware performance influences viewers' actual experience. On the other hand, the human visual system is limited in its ability to detect subtle degradations in image quality; for example, under conditions of high ambient illumination, such as outdoors in direct sunlight, the veiling luminance (i.e., glare) on the screen of a mobile device can effectively mask imperfections in the image, so that under these circumstances a video can be rendered in lower than full quality without the viewer being able to detect any difference. This isolation between hardware design and viewer experience significantly increases hardware implementation overhead due to overly pessimistic design margins. This project integrates viewer-awareness and hardware adaptation to achieve power optimization without degrading video quality, as perceived by users. The results of this project will impact both basic research on hardware design and human vision, and provide critical viewer awareness data from human subjects, which can be used to engineer better video rendering for increased battery life on mobile devices. The project will directly involve undergraduate and graduate students, including females and Native Americans, in interdisciplinary research. \r\n\r\nDeveloping a viewer-aware mobile video-memory solution has proven to be a very challenging problem due to (i) complex existing viewer-experience models; (ii) memory modules without runtime adaptation; and (iii) the difficulty of viewer-experience analysis for hardware designers. This project addresses the problem by (i) focusing on the most influential viewing-context factor impacting viewer experience - ambient luminance; (ii) proposing novel methodologies for adaptive hardware design; and (iii) integrating a unique combination of expertise from the investigators, ranging from psychology to Integrated Circuit design and embedded systems. Specifically, this project will (i) experimentally and mathematically connect viewer experience, ambient illuminance, and memory performance; (ii) develop energy-quality adaptive hardware that can adjust memory usage based on ambient luminance so as to reduce power usage without impacting viewer experience; and (iii) design a mobile video system to fully evaluate the effectiveness of the developed methodologies.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Na",
   "pi_last_name": "Gong",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Na Gong",
   "pi_email_addr": "nagong@southalabama.edu",
   "nsf_id": "000653450",
   "pi_start_date": "2018-10-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of South Alabama",
  "inst_street_address": "307 N UNIVERSITY BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "MOBILE",
  "inst_state_code": "AL",
  "inst_state_name": "Alabama",
  "inst_phone_num": "2514606333",
  "inst_zip_code": "366083053",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "AL02",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTH ALABAMA",
  "org_prnt_uei_num": "",
  "org_uei_num": "QB12VPNQQFE8"
 },
 "perf_inst": {
  "perf_inst_name": "University of South Alabama",
  "perf_str_addr": "150 Jaguar Drive",
  "perf_city_name": "Mobile",
  "perf_st_code": "AL",
  "perf_st_name": "Alabama",
  "perf_zip_code": "366880002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "AL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 300000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this SHF project was to develop viewer-aware mobile video-memory design techniques by integrating mobile viewer-awareness with hardware adaptation to achieve power optimization. It addressed a number of critical challenges to viewer-aware video hardware design from three aspects: (1) experimentally and mathematically connect viewer experience, ambient illuminance, and memory performance; (2) develop energy-quality adaptive hardware that can adjust memory usage based on ambient luminance so as to reduce power usage without impacting viewer experience; and (3) design a mobile video system for verification.</p>\n<p>We conducted psychophysical experiments on viewer experience in different viewing contexts, which illustrated that if a video system is operating in poor light conditions, viewers can tolerate larger amounts of quality degradation, such that more least-significant-bits (LSBs) of video data can be truncated to save energy without impacting perceived video quality. We also assessed the degree to which human observers were able to discriminate between reference videos and bit-truncated versions that were rendered and displayed at various levels of objective quality as a function of the ambient-illumination level. Based on the experimental results, we developed expectation-based mathematical models to connect video quality and memory performance. The results of the numerical studies on embedded memory design showed that the developed models provide a useful and fast tool to enable optimal hardware designs<strong>. </strong></p>\n<p>We studied viewer-aware hardware-implementation schemes for dynamic energy-quality knobs with minimal effect on viewer experience, such as voltage scaling, bitcell structures, LSB truncations, error correction code (ECC) schemes, device sizing, hardening most significant bits (MSBs), and hardening parity bits. As an example, we developed a novel viewer-aware bit truncation technique that enables better visual experience while maintaining similar power efficiency. We also designed a flexible power-efficient video memory that can dynamically adjust the strength of ECC, thereby enabling power-quality trade-off based on application requirements. We developed a new adaptive ECC technique, which can effectively select three power-quality tradeoff levels for video applications: hamming code-74, hamming code-1511, and no ECC. Using 1,000 randomly selected videos, our results showed that the developed memory enables runtime quality adaptation with significantly reduced overhead and better video quality, as compared to existing techniques.</p>\n<p>Additionally, the impact of video content on viewer experience was studied from the psychological perspective. Our research demonstrated the correlation characteristics between &ldquo;banding distortion&rdquo; to viewers caused by hardware noise and the areas in frames that exhibit low variance among pixel luminance values, which has the potential to enable content-adaptation opportunities for hardware design. Based on macroblock characteristics analysis and subjective video testing, two models, decision tree and logistic regression, were developed to enable effective connection of the video content to the hardware design process. We further developed a novel viewer-aware bit truncation technique that enables better visual experience while maintaining similar power efficiency. Based on the developed models and viewer-aware bit truncation technique, a content-adaptive video memory design with dynamic energy-quality tradeoff was implemented, which enables up to 33.31% power savings.</p>\n<p>We also developed a Region-of-Interest (ROI)-aware video storage technique that takes advantage of deep learning to identify the most important areas to optimize the video output quality while saving power consumption. Based on this, we designed a content-adaptable ROI-aware video system to support general videos, and conducted system testing, including power efficiency, number of truncated bits, output quality, and area overhead, which shows that this proposed memory enables run&#8208;time quality adaptation with significantly reduced pixel bits and further power savings, as compared to existing techniques.&nbsp;</p>\n<p>The outcomes of this project have been widely disseminated to the research community and general public. This project directly trained over ten graduate students and undergraduate students (funded through supplements), including four underrepresented (female and minority) students. Among them, one MS and three PhD students have successfully defended their theses/dissertations. The team published five journal papers at prestigious venues such as <em>IEEE Transactions on Very Large Scale Integration (VLSI) Systems</em>, <em>IEEE Transactions on Sustainable Computing</em>, and <em>IEEE Access</em>. The findings of this project have been integrated into the PIs&rsquo; existing undergraduate and graduate courses; and the project further promoted K-12 STEM and computing education community outreach through the team&rsquo;s organized outreach events and on-going NSF-funded RET award.&nbsp;&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/26/2023<br>\n\t\t\t\t\tModified by: Na&nbsp;Gong</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this SHF project was to develop viewer-aware mobile video-memory design techniques by integrating mobile viewer-awareness with hardware adaptation to achieve power optimization. It addressed a number of critical challenges to viewer-aware video hardware design from three aspects: (1) experimentally and mathematically connect viewer experience, ambient illuminance, and memory performance; (2) develop energy-quality adaptive hardware that can adjust memory usage based on ambient luminance so as to reduce power usage without impacting viewer experience; and (3) design a mobile video system for verification.\n\nWe conducted psychophysical experiments on viewer experience in different viewing contexts, which illustrated that if a video system is operating in poor light conditions, viewers can tolerate larger amounts of quality degradation, such that more least-significant-bits (LSBs) of video data can be truncated to save energy without impacting perceived video quality. We also assessed the degree to which human observers were able to discriminate between reference videos and bit-truncated versions that were rendered and displayed at various levels of objective quality as a function of the ambient-illumination level. Based on the experimental results, we developed expectation-based mathematical models to connect video quality and memory performance. The results of the numerical studies on embedded memory design showed that the developed models provide a useful and fast tool to enable optimal hardware designs. \n\nWe studied viewer-aware hardware-implementation schemes for dynamic energy-quality knobs with minimal effect on viewer experience, such as voltage scaling, bitcell structures, LSB truncations, error correction code (ECC) schemes, device sizing, hardening most significant bits (MSBs), and hardening parity bits. As an example, we developed a novel viewer-aware bit truncation technique that enables better visual experience while maintaining similar power efficiency. We also designed a flexible power-efficient video memory that can dynamically adjust the strength of ECC, thereby enabling power-quality trade-off based on application requirements. We developed a new adaptive ECC technique, which can effectively select three power-quality tradeoff levels for video applications: hamming code-74, hamming code-1511, and no ECC. Using 1,000 randomly selected videos, our results showed that the developed memory enables runtime quality adaptation with significantly reduced overhead and better video quality, as compared to existing techniques.\n\nAdditionally, the impact of video content on viewer experience was studied from the psychological perspective. Our research demonstrated the correlation characteristics between \"banding distortion\" to viewers caused by hardware noise and the areas in frames that exhibit low variance among pixel luminance values, which has the potential to enable content-adaptation opportunities for hardware design. Based on macroblock characteristics analysis and subjective video testing, two models, decision tree and logistic regression, were developed to enable effective connection of the video content to the hardware design process. We further developed a novel viewer-aware bit truncation technique that enables better visual experience while maintaining similar power efficiency. Based on the developed models and viewer-aware bit truncation technique, a content-adaptive video memory design with dynamic energy-quality tradeoff was implemented, which enables up to 33.31% power savings.\n\nWe also developed a Region-of-Interest (ROI)-aware video storage technique that takes advantage of deep learning to identify the most important areas to optimize the video output quality while saving power consumption. Based on this, we designed a content-adaptable ROI-aware video system to support general videos, and conducted system testing, including power efficiency, number of truncated bits, output quality, and area overhead, which shows that this proposed memory enables run&#8208;time quality adaptation with significantly reduced pixel bits and further power savings, as compared to existing techniques. \n\nThe outcomes of this project have been widely disseminated to the research community and general public. This project directly trained over ten graduate students and undergraduate students (funded through supplements), including four underrepresented (female and minority) students. Among them, one MS and three PhD students have successfully defended their theses/dissertations. The team published five journal papers at prestigious venues such as IEEE Transactions on Very Large Scale Integration (VLSI) Systems, IEEE Transactions on Sustainable Computing, and IEEE Access. The findings of this project have been integrated into the PIs\u2019 existing undergraduate and graduate courses; and the project further promoted K-12 STEM and computing education community outreach through the team\u2019s organized outreach events and on-going NSF-funded RET award.  \n\n\t\t\t\t\tLast Modified: 01/26/2023\n\n\t\t\t\t\tSubmitted by: Na Gong"
 }
}