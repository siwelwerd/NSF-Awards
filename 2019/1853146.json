{
 "awd_id": "1853146",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase II:  Gripper-integrated proximity, contact and force sensing for collaborative robots",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Muralidharan Nair",
 "awd_eff_date": "2019-04-15",
 "awd_exp_date": "2020-09-30",
 "tot_intn_awd_amt": 743051.0,
 "awd_amount": 809043.0,
 "awd_min_amd_letter_date": "2019-04-17",
 "awd_max_amd_letter_date": "2020-07-27",
 "awd_abstract_narration": "The broader impact/commercial potential of this project is a new generation of smart robotic hands that will manifest a new plateau for industrial manipulation and robotics research. Previously hard manipulation challenges will be available out-of-the-box, enabling industry to create new, complex applications. Integration of sensing, actuation, control, and programming environment into a single low-cost device will decrease complexity, setup time and cost of collaborative robotic solutions, and, together with a new generation of low-cost robotic arms, enable industrial tasks of high commercial value, including bin-picking, kitting and assembly. A simple, graphical programming interface paired with a browser-based scripting interface will make robot programming accessible to a workforce with widely varying educational backgrounds, thereby increasing productivity and efficiency in the workplace and ensuring long-term economic viability of US-based manufacturing. This project also contributes to workforce development by training a new breed of engineers that are equally versed with mechanical, electronics and control, while providing opportunities for a diverse population of students at the University of Colorado. \r\n\r\nThis Small Business Innovation Research Phase II project fundamentally advances the understanding of the interplay between proximity, contact and force sensing; self-supervised learning techniques to improve hand-coded robot controllers; and manufacturing challenges of systems that tightly integrate sensing, actuation, and computation. Building up on a proof-of-concept gripper design resulting from Phase I research that has successfully demonstrated a variety of challenging industrially-relevant bin picking, kitting and assembly tasks, this research will investigate new algorithms for dual-arm assembly problems including improved path planning and collision avoidance, optimization algorithms for automatic parameter tuning to improve grasp and assembly success, and training of deep convolutional neural networks to replace hand-coded segmentation algorithms for object identification and ?actor critics?. Rigorous testing for robustness, reliability and accuracy throughout the project will drive algorithm development. Safety analysis will feed back into hardware and controller design.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nicolaus",
   "pi_last_name": "Correll",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Nicolaus J Correll",
   "pi_email_addr": "ncorrell@colorado.edu",
   "nsf_id": "000546404",
   "pi_start_date": "2019-04-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Robotic Materials Inc",
  "inst_street_address": "3080 VALMONT RD # 100",
  "inst_street_address_2": "",
  "inst_city_name": "BOULDER",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "3037171436",
  "inst_zip_code": "803012152",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "ROBOTIC MATERIALS INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "DAVKSDE6BGW4"
 },
 "perf_inst": {
  "perf_inst_name": "University of Colorado and Robotic Materials Inc.",
  "perf_str_addr": "1860 38th street",
  "perf_city_name": "Boulder",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "803012620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537300",
   "pgm_ele_name": "SBIR Phase II"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5373",
   "pgm_ref_txt": "SMALL BUSINESS PHASE II"
  },
  {
   "pgm_ref_code": "8033",
   "pgm_ref_txt": "Hardware Software Integration"
  },
  {
   "pgm_ref_code": "8034",
   "pgm_ref_txt": "Hardware Components"
  },
  {
   "pgm_ref_code": "8240",
   "pgm_ref_txt": "SBIR/STTR CAP"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 743051.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 65992.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has led to a novel robotic manipulator that integrates eye-in-hand 3D perception and compliant, multi-finger actuation to address a series of manipulation challenges ranging from picking previously unseen items out of shelves and bins to assembly of standard industrial parts.</p>\n<p>The intellectual merit of this project are a patent-pending mechatronic design that enables a wide range of aperture and forces, allowing the hand to grasp objects as small as a screw and as large as a toner cartridge while exerting forces as low to gently manipulate a Strawberry and as strong as necessary to perform tight peg-in-hole insertions during industrial assembly. Furthermore, this project has led to novel algorithms for object segmentation in 3D point-clouds, merging 3D depth and 2D image information for object identification, grasp pose generation, as well as novel planning algorithms that combine reactive controllers with semantic reasoning for robust task execution and error recovery.&nbsp;&nbsp;</p>\n<p>The broader impact of this project are novel tools that will allow retailers, manufacturers, and e-commerce to further automate their processes and augment the abilitites of human co-workers leading to increased efficiency and throughput in production environments. In these scenarios, robots provide value not only by performing repetitive tasks that would otherwise need to be done by humans, but by increasing cadence and coordination in a production process, which often outweighs the actual labor contribution, while at the same time allowing humans to focus on tasks with the highest value creation. This project has also provided training opportunities for multiple undergraduates, freshly graduated college students, and PhDs to gain experience at the intersection of robotic hardware and software.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/22/2020<br>\n\t\t\t\t\tModified by: Nicolaus&nbsp;J&nbsp;Correll</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603400121382_allrobots--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603400121382_allrobots--rgov-800width.jpg\" title=\"Robotic Materials' autonomous material handling solution\"><img src=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603400121382_allrobots--rgov-66x44.jpg\" alt=\"Robotic Materials' autonomous material handling solution\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">RMMove and RMHandle, a material handling solution powered by Robotic Materials' Smart Hand</div>\n<div class=\"imageCredit\">Nikolaus Correll</div>\n<div class=\"imageSubmitted\">Nicolaus&nbsp;J&nbsp;Correll</div>\n<div class=\"imageTitle\">Robotic Materials' autonomous material handling solution</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603396582157_IMG_7886--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603396582157_IMG_7886--rgov-800width.jpg\" title=\"Assembly Task\"><img src=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603396582157_IMG_7886--rgov-66x44.jpg\" alt=\"Assembly Task\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Robotic Materials' Smart Hand assembling the Siemens Learning Challenge.</div>\n<div class=\"imageCredit\">Nikolaus Correll</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Nicolaus&nbsp;J&nbsp;Correll</div>\n<div class=\"imageTitle\">Assembly Task</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603396837412_binpicking--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603396837412_binpicking--rgov-800width.jpg\" title=\"Bin picking\"><img src=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603396837412_binpicking--rgov-66x44.jpg\" alt=\"Bin picking\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Robotic Materials' Smart Hand during a bin picking activity</div>\n<div class=\"imageCredit\">Nikolaus Correll</div>\n<div class=\"imageSubmitted\">Nicolaus&nbsp;J&nbsp;Correll</div>\n<div class=\"imageTitle\">Bin picking</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603396168276_smarthand--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603396168276_smarthand--rgov-800width.jpg\" title=\"Robotic Materials' Smart Hand\"><img src=\"/por/images/Reports/POR/2020/1853146/1853146_10601212_1603396168276_smarthand--rgov-66x44.jpg\" alt=\"Robotic Materials' Smart Hand\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Robotic Materials' Smart Hand integrates 3D perception, force control and computation, enabling robot arms to perform bin picking, kitting and complex assembly actions</div>\n<div class=\"imageCredit\">Nikolaus Correll</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Nicolaus&nbsp;J&nbsp;Correll</div>\n<div class=\"imageTitle\">Robotic Materials' Smart Hand</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project has led to a novel robotic manipulator that integrates eye-in-hand 3D perception and compliant, multi-finger actuation to address a series of manipulation challenges ranging from picking previously unseen items out of shelves and bins to assembly of standard industrial parts.\n\nThe intellectual merit of this project are a patent-pending mechatronic design that enables a wide range of aperture and forces, allowing the hand to grasp objects as small as a screw and as large as a toner cartridge while exerting forces as low to gently manipulate a Strawberry and as strong as necessary to perform tight peg-in-hole insertions during industrial assembly. Furthermore, this project has led to novel algorithms for object segmentation in 3D point-clouds, merging 3D depth and 2D image information for object identification, grasp pose generation, as well as novel planning algorithms that combine reactive controllers with semantic reasoning for robust task execution and error recovery.  \n\nThe broader impact of this project are novel tools that will allow retailers, manufacturers, and e-commerce to further automate their processes and augment the abilitites of human co-workers leading to increased efficiency and throughput in production environments. In these scenarios, robots provide value not only by performing repetitive tasks that would otherwise need to be done by humans, but by increasing cadence and coordination in a production process, which often outweighs the actual labor contribution, while at the same time allowing humans to focus on tasks with the highest value creation. This project has also provided training opportunities for multiple undergraduates, freshly graduated college students, and PhDs to gain experience at the intersection of robotic hardware and software. \n\n\t\t\t\t\tLast Modified: 10/22/2020\n\n\t\t\t\t\tSubmitted by: Nicolaus J Correll"
 }
}