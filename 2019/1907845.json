{
 "awd_id": "1907845",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Approximating Characteristic Polynomial of Matroids",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2019-07-01",
 "awd_max_amd_letter_date": "2019-07-01",
 "awd_abstract_narration": "Randomized algorithms represent an elegant and sometimes only known approach for solving some intractably hard real-life problems. The notion of probability distribution over a set of objects is essential to many randomized algorithms. For example, Google?s PageRank approach to ranking search results in effect defines a probability distribution over the set of webpages. A large class of randomized algorithms rely on generating samples from some desired probability distribution over possible inputs. Markov Chains have been one the most interesting, prominent and useful structures because of their ability to generate and draw samples from desired probability distributions. This project is about developing and improving Markov-Chain-based algorithms for several fundamental problems using a new mathematical technique called ?Geometry of Polynomials?. The results from this project will have applications in a number of areas of science and technology such as machine learning, statistical physics, and quantum mechanics. The PI intends to implement algorithms that he will study in this project and make them available to researchers. This proposal includes integration of research and teaching by means of new graduate courses to introduce new techniques in this field to students in mathematics and engineering departments. Although grounded in theoretical computer science, the project will also attract many graduate students in probability theory, combinatorics, statistics, and statistical physics who are interested in the analysis of Markov chains. Furthermore, the PI plans to train strong undergraduate and graduate students with diverse gender and ethnicity.\r\n \r\nOver the last few decades researchers have developed several techniques to bound the mixing time of Markov chains. In most cases, these techniques are \"local?, and they fail to bound the mixing time when the underlying combinatorial structure is complex. So, there is a need for new families of ``global'' techniques that can overcome barriers that have failed over the years to yield to classical methods.  The main purpose of this project is to investigate the hidden power of a new \"global\" machinery based on high-dimensional expanders and the field of geometry of polynomials. High-dimensional expanders originated in mathematics and are a natural generalization of expander graphs. They have proved to be useful in complexity theory, and coding theory. Recently, high dimensional expanders were exploited by the PI and collaborators as a new tool in the analysis of Markov chains for sampling bases of matroids. In this project the researcher and his team plan to further investigate this new tool and see if it can be used at other frontiers of the field of approximate counting.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shayan",
   "pi_last_name": "Oveis Gharan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shayan Oveis Gharan",
   "pi_email_addr": "shayan@cs.washington.edu",
   "nsf_id": "000699800",
   "pi_start_date": "2019-07-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "185 Stevens Way",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981952350",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Random walks and Markov chains are one of the most practical algorithmic primitives with applications all over the science from hard to social. They are the primarily used in many of the modern technological industries such as search engines or social network. At the same time, they serve as the first method of choice in simulating and testing almost any scientific theory in nearly all areas of science.&nbsp;&nbsp;In the Markov Chain Monte Carlo method, one first designs a Markov chain whose stationary distribution is the target probability distribution. Then, researchers &ldquo;hope&rdquo; that after running the chain &ldquo;long enough&rdquo; a true sample from the target distribution is generated. The real question is: how long does one need to run the chain to get an honest sample, technically, what is the mixing time of the chain? To answer this question, we need mathematical techniques that can provably bound the &ldquo;distance&rdquo; of the probability distribution after running the chain for some number steps from the stationary distribution.</p>\n<p>In this project we introduced a new technique&nbsp;called&nbsp;the spectral independence and we used it to prove that the Glauber dynamics Markov chain mixes in polynomial time to sample from the hard-core model, a well-known model studied in statistical physics, answering a 25-year-old open problem in the field. In addition, we managed to make progress on other frontiers of the field such as sampling random (edge) coloring of a graph or unifying different proof techniques for analyzing Markov chains. Since our first paper on the spectral independence technique, this method has revolutionized the field of approximate counting and sampling. Over the last couple of years around 70 publications have studied this method in a wide range of applications and used it to prove that certain Markov chains mix in polynomial time and sometime in (near) linear time for problems that seemed unapproachable just 3 years ago. The spectral independence method is now a major tool in the field; it is being taught in graduate courses on algorithms and it is probably one of the main tools one would try to analyze a Markov chain (probably after trying the famous coupling technique).</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/24/2022<br>\n\t\t\t\t\tModified by: Shayan&nbsp;O&nbsp;Gharan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nRandom walks and Markov chains are one of the most practical algorithmic primitives with applications all over the science from hard to social. They are the primarily used in many of the modern technological industries such as search engines or social network. At the same time, they serve as the first method of choice in simulating and testing almost any scientific theory in nearly all areas of science.  In the Markov Chain Monte Carlo method, one first designs a Markov chain whose stationary distribution is the target probability distribution. Then, researchers \"hope\" that after running the chain \"long enough\" a true sample from the target distribution is generated. The real question is: how long does one need to run the chain to get an honest sample, technically, what is the mixing time of the chain? To answer this question, we need mathematical techniques that can provably bound the \"distance\" of the probability distribution after running the chain for some number steps from the stationary distribution.\n\nIn this project we introduced a new technique called the spectral independence and we used it to prove that the Glauber dynamics Markov chain mixes in polynomial time to sample from the hard-core model, a well-known model studied in statistical physics, answering a 25-year-old open problem in the field. In addition, we managed to make progress on other frontiers of the field such as sampling random (edge) coloring of a graph or unifying different proof techniques for analyzing Markov chains. Since our first paper on the spectral independence technique, this method has revolutionized the field of approximate counting and sampling. Over the last couple of years around 70 publications have studied this method in a wide range of applications and used it to prove that certain Markov chains mix in polynomial time and sometime in (near) linear time for problems that seemed unapproachable just 3 years ago. The spectral independence method is now a major tool in the field; it is being taught in graduate courses on algorithms and it is probably one of the main tools one would try to analyze a Markov chain (probably after trying the famous coupling technique).\n\n \n\n \n\n\t\t\t\t\tLast Modified: 11/24/2022\n\n\t\t\t\t\tSubmitted by: Shayan O Gharan"
 }
}