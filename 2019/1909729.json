{
 "awd_id": "1909729",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Collaborative Research: Dynamic Light Transport Acquisition and Applications to Computational Illumination",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2019-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2019-08-06",
 "awd_max_amd_letter_date": "2019-08-06",
 "awd_abstract_narration": "Cameras that view a dynamic scene typically capture interactions of moving objects with light. Computer vision algorithms can use these measurements to infer properties of these objects, such as depth, motion and appearance. However, there is a subtler, richer visual back-story that occurs as an object moves in a scene, and usually these effects are ignored in traditional algorithms, sometimes causing errors. This project studies all the interactions of light with dynamic scenes, which we term as dynamic light transport, and the goal is to understand and recover effects such as multiple reflections and scattering as objects move in a scene. The innovations of the project include new computational cameras and projectors to capture light transport for dynamic scenes, and to explore new physics-based and data-driven algorithms to exploit this information for improved computer vision and graphics applications. The project further seeks to include broadening access to computing education and research through curriculum material and capstone experiences which emphasize the intersection of light transport and digital media as well as outreach to middle and high school students in summer programs to discover imaging and optics applications.\r\n\r\nThis research focuses on designing new light transport acquisition frameworks to capture dynamic scenes, characterization of dynamic light transport properties including sparsity and low-rank, and algorithms to exploit this information for computer vision applications. In particular, the project focuses on three main objectives.  The first is design of an MEMs-based optical scanner coupled with high frame rate cameras to capture the full set of light transport paths at extremely fast timescales.  The second contribution is new algorithms for adaptive light transport sampling using both physics-based and data-driven priors for light transport interpolation via generalized light transport flow.  Finally, the project will provide applications of dynamic light transport for 3D scanning of deformable, moving, and specular objects. These innovations are evaluated in an integrated testbed via the optical scanner and the collection of a dataset of dynamic light transport for real-world scenes.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanjeev",
   "pi_last_name": "Koppal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sanjeev Koppal",
   "pi_email_addr": "sjkoppal@ece.ufl.edu",
   "nsf_id": "000668802",
   "pi_start_date": "2019-08-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "",
  "perf_city_name": "Gainesville",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326116200",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Light-transport represents the complex interactions of light in a scene. Fast, compressed, and accurate light-transport capture for dynamic scenes is an open challenge in vision and graphics. During this project's timeline, we were able to create hardware and software that modeled the light transport of dynamic scenes. We were able to relight a video of water droplets and fog after the video had been captured. We were able to create color videos of objects around a corner, which the camera could not directly see. We were also able to recover the geometry of transparent objects around an obstacle. We investigated methods of using sparse capture, such as event cameras, and deep learning to speed up the sampling. We were able to demonstrate algorithms and hardware for complex illumination scenarios with dense angular sampling.</p>\n<p>We had many calibration contributions for the hardware, that enabled dynamic light transport acquisition at near video rates with such a system. We developed new methods for overcoming the effects of MEMS mirror resonance. We utilize<br />new algorithms for denoising impulse scanning at high frame rates and compare the trade-offs in visual quality between frame rate and illumination power. Finally, we showed the utility of our calibrated setup by demonstrating graphics applications such as video relighting, direct/global separation, and dual videography<br />for dynamic scenes such as fog, water, and glass</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/07/2023<br>\n\t\t\t\t\tModified by: Sanjeev&nbsp;Koppal</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nLight-transport represents the complex interactions of light in a scene. Fast, compressed, and accurate light-transport capture for dynamic scenes is an open challenge in vision and graphics. During this project's timeline, we were able to create hardware and software that modeled the light transport of dynamic scenes. We were able to relight a video of water droplets and fog after the video had been captured. We were able to create color videos of objects around a corner, which the camera could not directly see. We were also able to recover the geometry of transparent objects around an obstacle. We investigated methods of using sparse capture, such as event cameras, and deep learning to speed up the sampling. We were able to demonstrate algorithms and hardware for complex illumination scenarios with dense angular sampling.\n\nWe had many calibration contributions for the hardware, that enabled dynamic light transport acquisition at near video rates with such a system. We developed new methods for overcoming the effects of MEMS mirror resonance. We utilize\nnew algorithms for denoising impulse scanning at high frame rates and compare the trade-offs in visual quality between frame rate and illumination power. Finally, we showed the utility of our calibrated setup by demonstrating graphics applications such as video relighting, direct/global separation, and dual videography\nfor dynamic scenes such as fog, water, and glass\n\n\t\t\t\t\tLast Modified: 08/07/2023\n\n\t\t\t\t\tSubmitted by: Sanjeev Koppal"
 }
}