{
 "awd_id": "1850069",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: RI: Learning Predictive Representations from Unlabeled Video",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2019-06-15",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2019-06-13",
 "awd_max_amd_letter_date": "2019-06-13",
 "awd_abstract_narration": "The project studies computer systems that predict how objects and people will move, even when they are out-of-sight due to occlusion, for example keys inside pockets. Predictive models have the potential to enable many new applications impacting health, security, and robotics, which can improve the efficiency, safety, and welfare of the overall population. To achieve this, the research investigates computer vision algorithms that learn the visual patterns for prediction automatically from large amounts of video data. This computer software will be able to track objects obscured by occlusion, accurately represent shadows in video, and forecast object movements into the future. The project will provide research opportunities for both graduate and undergraduate students, and increase the diversity in machine intelligence research. Outcomes from this project will translate into course material to teach students in computer science and machine learning. \r\n\r\nThis research focuses on robustly generalizing predictive models to the natural diversity and complexity of real-world video. While large annotated datasets fuel rapid advancements in visual scene recognition, machine understanding of events and dynamics remains challenging because the amount of knowledge required for video understanding is vast and potentially ambiguous. Instead, the investigators aim to capitalize on large amounts of raw, unlabeled video in order to create machine algorithms that efficiently learn to predict the future behaviors of events, objects, and people. Building off highly competitive frameworks from the research team and others, this project will leverage natural redundancy in unlabeled video, such as color coherency and repetitive motion, to train deep convolutional neural networks without human supervision. The research team proposes extensions to spatiotemporal memory models to handle such situations, and methods to learn representations of color constancy that will improve tracking performance. The investigators also propose analysis tools to measure and visualize the representation that emerges, enabling new methods to quantify performance in predictive models.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Carl",
   "pi_last_name": "Vondrick",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Carl M Vondrick",
   "pi_email_addr": "cv2428@columbia.edu",
   "nsf_id": "000755733",
   "pi_start_date": "2019-06-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100276902",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project developed computer software that allow machines to robustly recognize and classify images and speech. While there has been many advances in artificial intelligence over the last several years, the methodology is often brittle and fails in unexpected ways. This project showed how to make these methods more robust and accurate, and consequently more trustworthy in critical applications. The research team showed that unsupervised learning methods have intrinsic advantages for robustness, which they demonstrated both theoretically and empirically. The project resulted in several publications in the top scientific venues for computer vision and machine learning.</p>\n<p>The project also generated new educational material for teaching the next generation of students about the fundamental concepts in computer vision and machine learning. These educational materials were used in several classes at Columbia University. Moreover, the research project trained both graduate and undergraduate students in artificial intelligence and computer vision.&nbsp;</p>\n<p>All the software code, datasets, and machine learning models have been made publicly available as free open-source software, which can be downloaded from Columbia University. These research resources come with short tutorials that allow researchers to quickly build off these results and make neural networks more robust in a variety of tangible applications.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/04/2022<br>\n\t\t\t\t\tModified by: Carl&nbsp;M&nbsp;Vondrick</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project developed computer software that allow machines to robustly recognize and classify images and speech. While there has been many advances in artificial intelligence over the last several years, the methodology is often brittle and fails in unexpected ways. This project showed how to make these methods more robust and accurate, and consequently more trustworthy in critical applications. The research team showed that unsupervised learning methods have intrinsic advantages for robustness, which they demonstrated both theoretically and empirically. The project resulted in several publications in the top scientific venues for computer vision and machine learning.\n\nThe project also generated new educational material for teaching the next generation of students about the fundamental concepts in computer vision and machine learning. These educational materials were used in several classes at Columbia University. Moreover, the research project trained both graduate and undergraduate students in artificial intelligence and computer vision. \n\nAll the software code, datasets, and machine learning models have been made publicly available as free open-source software, which can be downloaded from Columbia University. These research resources come with short tutorials that allow researchers to quickly build off these results and make neural networks more robust in a variety of tangible applications.\n\n\t\t\t\t\tLast Modified: 06/04/2022\n\n\t\t\t\t\tSubmitted by: Carl M Vondrick"
 }
}