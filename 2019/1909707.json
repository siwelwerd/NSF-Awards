{
 "awd_id": "1909707",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Toward Human-Level Face Verification Performance Using Distinctive Features",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 419979.0,
 "awd_amount": 435979.0,
 "awd_min_amd_letter_date": "2019-07-22",
 "awd_max_amd_letter_date": "2020-03-23",
 "awd_abstract_narration": "This project aims to transform the way in which researchers approach face recognition technology by modeling distinctive features. Humans are capable of recognizing images of familiar faces even as they become extremely distorted. This project seeks to address current issues with face recognition technology by modeling the process after human perception. This project advances the fields of automated face recognition and human face perception by combining research in both areas to produce computational models of human face memory. This research will benefit society by producing techniques capable of recognizing faces in low-quality imagery as seen in surveillance and human-computer interaction settings. This project supports education and diversity through the recruitment of a diverse research team, the incorporation of research results into artificial intelligence courses and the wide dissemination of research results, data and code. This project is jointly funded by the Robust Intelligence (RI), the Established Program to Stimulate Competitive Research (EPSCoR), and the Secure and Trustworthy Cyberspace (SaTC) programs. \r\n\r\nThis research investigates whether automated face verification performance can be improved by recognizing and emphasizing distinctive facial features. The project focuses on three main objectives: 1) modeling distinctive facial features, 2) face verification using distinctive features and 3) modeling exaggerated distinctive features. In modeling distinctive facial features, a new set of data will be collected with many images per identity and each identity labeled with distinctive features. Baseline and robust approaches to distinctive feature recognition will be developed and made publicly available along with the data. For face verification using distinctive features, multi-task learning approaches will be explored and evaluated on several large-scale surveillance and human-computer interaction datasets. The approach for modeling exaggerated distinctive features of faces involves learning generative models from weakly labeled data to produce realistic facial images from veridical faces. Automatically generated images will then be used to break up end-to-end deep learning frameworks for face verification in low-quality imagery.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Emily",
   "pi_last_name": "Hand",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Emily M Hand",
   "pi_email_addr": "emhand@unr.edu",
   "nsf_id": "000784557",
   "pi_start_date": "2019-07-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Board of Regents, NSHE, obo University of Nevada, Reno",
  "inst_street_address": "1664 N VIRGINIA ST # 285",
  "inst_street_address_2": "",
  "inst_city_name": "RENO",
  "inst_state_code": "NV",
  "inst_state_name": "Nevada",
  "inst_phone_num": "7757844040",
  "inst_zip_code": "895570001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NV02",
  "org_lgl_bus_name": "BOARD OF REGENTS OF THE NEVADA SYSTEM OF HIGHER ED",
  "org_prnt_uei_num": "WLDGTNCFFJZ3",
  "org_uei_num": "WLDGTNCFFJZ3"
 },
 "perf_inst": {
  "perf_inst_name": "Board of Regents, NSHE, obo University of Nevada, Reno",
  "perf_str_addr": "1664 North Virginia Street",
  "perf_city_name": "Reno",
  "perf_st_code": "NV",
  "perf_st_name": "Nevada",
  "perf_zip_code": "895570001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NV02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 419979.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aimed to improve face verification performance by focusing on distinctive facial features through caricatures. A good caricature is said to look more like a person than the actual person does. This is because caricatures exaggerate the prominent features of an individual.&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<p>Intellectual Merit:</p>\r\n<p>This project collected new data in order to explore the role of prominent facial features in face verification. Prominent feature labels were added to a popular dataset -- CelebA. Additionally, a new dataset of realistic and caricatured faces was collected -- CarVer. The goal of this dataset is to explore the challenges associated with matching a face to its caricatures. Along with the face images, we collected prominent facial features for each person in the dataset. Finally, we collected a dataset of doppelgangers -- DoppelVer -- to explore the use of prominent features to distinguish two people who look very similar.&nbsp;</p>\r\n<p>Beyond data collection, this project explored approaches to face verification with caricatures -- identifying if a real and caricatured image belonged to the same person. The goal of this work was to improve general face verification techniques by exploring the model's capacity to handle real and caricatured images. Humans are capable of identifying individuals from their caricatures easily. This is an extreme challenge for modern machine learning models. As a part of this project, we introduced the concept of prominent facial features. This was a new concept for the field of computer vision. Prior work focused on recognizing facial attributes, such as hair color, mouth shape and nose shape. These attributes are rather generic and have never been particularly helpful for face recognition or verification. Prominent features, however, are specifically designed for face recognition, as they are the facial features that make an individual unique. Prominent features include short nose, cleft chin, wide-set eyes, etc. They are much more specific than facial attributes. We expect these features to be useful for future work in face recognition and verification.</p>\r\n<p>We introduced methods to test existing face verification, including a new dataset of doppelgangers. Doppelgangers are pairs of individuals who are visually very similar. This dataset was used to test existing state-of-the-art face verification methods. We found that many state-of-the-art methods, which achieve extremely high accuracies on many other datasets, struggled with our dataset, highlighting a critical flaw in exising face recognition software. Often times, we describe people based on other people we know. This project explored this idea with computational models and the idea of likeness-based face verification.</p>\r\n<p>&nbsp;</p>\r\n<p>Broader Impacts:</p>\r\n<p>This project has wide ranging broader impacts outside of the immediate impact on the discipline of computer science.</p>\r\n<p>This project supported one postdoctoral researcher, five graduate students, and twelve undergraduate students over the past five years. One PhD and three MS degrees were awarded under this project.</p>\r\n<p>The datasets collected can be utilized by researchers in human perception to better understand how humans recognize faces. This will in turn improve automated methods for face recognition. The work to better understand and improve face verification will benefit society broadly as automated methods for face verification become more ubiquitous. Face verification is used by our phones, and in airports for security. Ensuring these systems are accurate, even in challenging situations, is essential to encouraging trust and cooperation from the public.</p><br>\n<p>\n Last Modified: 11/26/2024<br>\nModified by: Emily&nbsp;M&nbsp;Hand</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project aimed to improve face verification performance by focusing on distinctive facial features through caricatures. A good caricature is said to look more like a person than the actual person does. This is because caricatures exaggerate the prominent features of an individual.\r\n\n\n\r\n\n\nIntellectual Merit:\r\n\n\nThis project collected new data in order to explore the role of prominent facial features in face verification. Prominent feature labels were added to a popular dataset -- CelebA. Additionally, a new dataset of realistic and caricatured faces was collected -- CarVer. The goal of this dataset is to explore the challenges associated with matching a face to its caricatures. Along with the face images, we collected prominent facial features for each person in the dataset. Finally, we collected a dataset of doppelgangers -- DoppelVer -- to explore the use of prominent features to distinguish two people who look very similar.\r\n\n\nBeyond data collection, this project explored approaches to face verification with caricatures -- identifying if a real and caricatured image belonged to the same person. The goal of this work was to improve general face verification techniques by exploring the model's capacity to handle real and caricatured images. Humans are capable of identifying individuals from their caricatures easily. This is an extreme challenge for modern machine learning models. As a part of this project, we introduced the concept of prominent facial features. This was a new concept for the field of computer vision. Prior work focused on recognizing facial attributes, such as hair color, mouth shape and nose shape. These attributes are rather generic and have never been particularly helpful for face recognition or verification. Prominent features, however, are specifically designed for face recognition, as they are the facial features that make an individual unique. Prominent features include short nose, cleft chin, wide-set eyes, etc. They are much more specific than facial attributes. We expect these features to be useful for future work in face recognition and verification.\r\n\n\nWe introduced methods to test existing face verification, including a new dataset of doppelgangers. Doppelgangers are pairs of individuals who are visually very similar. This dataset was used to test existing state-of-the-art face verification methods. We found that many state-of-the-art methods, which achieve extremely high accuracies on many other datasets, struggled with our dataset, highlighting a critical flaw in exising face recognition software. Often times, we describe people based on other people we know. This project explored this idea with computational models and the idea of likeness-based face verification.\r\n\n\n\r\n\n\nBroader Impacts:\r\n\n\nThis project has wide ranging broader impacts outside of the immediate impact on the discipline of computer science.\r\n\n\nThis project supported one postdoctoral researcher, five graduate students, and twelve undergraduate students over the past five years. One PhD and three MS degrees were awarded under this project.\r\n\n\nThe datasets collected can be utilized by researchers in human perception to better understand how humans recognize faces. This will in turn improve automated methods for face recognition. The work to better understand and improve face verification will benefit society broadly as automated methods for face verification become more ubiquitous. Face verification is used by our phones, and in airports for security. Ensuring these systems are accurate, even in challenging situations, is essential to encouraging trust and cooperation from the public.\t\t\t\t\tLast Modified: 11/26/2024\n\n\t\t\t\t\tSubmitted by: EmilyMHand\n"
 }
}