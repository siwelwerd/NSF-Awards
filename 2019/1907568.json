{
 "awd_id": "1907568",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Risk-Averse Control of Markov Systems with Model Uncertainty",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Pedro Embid",
 "awd_eff_date": "2019-07-15",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 220000.0,
 "awd_amount": 220000.0,
 "awd_min_amd_letter_date": "2019-07-10",
 "awd_max_amd_letter_date": "2019-07-10",
 "awd_abstract_narration": "This project focuses on mathematical theory and computational methods of decision-making in systems that evolve randomly in time and whose essential characteristics are not precisely known to the observer. The research will address in a coherent way how to model risk in such systems and how to control them within the risk-averse paradigm. This will be accomplished by developing dynamic risk-assessment procedures, called risk filters, and by employing adaptive robust control techniques. The outcome of the project will directly advance and promote the progress of science and engineering, with potential applications in applied areas such as medical sciences, engineering, economics, finance, inventory management and insurance. Special attention will be given to popularizing the proposed research and its impact in these applied fields. In particular, this will be achieved through advising of graduate and undergraduate students, including students from underrepresented groups, presentations at popular, international and local forums, and dissemination of the results via scientific journal and book publications.\r\n\r\nThe classical theory and practice of Markov decision processes have proven to provide a powerful and successful toolkit for generating optimal or sub-optimal decision strategies in situations where the decision maker has access to adequately known (accurate) model of the underlying Markovian dynamical system, and acts so to optimize the expected cumulative cost or reward arising from the decision maker's actions. However, on the one hand, in many decision-making processes the decision maker needs to account for the trade-off between the cumulative award and cumulative risk of the decision. Risk-averse decision criteria underlying this research project and the theory of risk filters are ideally suited for such purposes. On the other hand, it is a typical situation in decision making processes that the model of the underlying Markovian dynamical system is not known exactly. Frequently, such model is a semi-adequate formalization of the underlying Markovian system, in the sense that the structural dynamical features of the system are modeled adequately, but precise knowledge of relevant model parameters is missing. In such cases, we say that the decision maker faces model uncertainty. Part of the proposed research will be devoted to develop methodologies that address this issue through adaptive robust stochastic control framework. Thus, the proposed research addresses in a coherent and novel way two important aspects of decision making in Markov systems: risk-averse decision criteria and model uncertainty. The theory of risk filters will be combined with the adaptive robust control methodology that will lead to novel dynamic programming equations, for which new numerical methods will be established.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tomasz",
   "pi_last_name": "Bielecki",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Tomasz R Bielecki",
   "pi_email_addr": "tbielecki@iit.edu",
   "nsf_id": "000260621",
   "pi_start_date": "2019-07-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Igor",
   "pi_last_name": "Cialenco",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Igor Cialenco",
   "pi_email_addr": "cialenco@iit.edu",
   "nsf_id": "000081508",
   "pi_start_date": "2019-07-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Illinois Institute of Technology",
  "inst_street_address": "10 W 35TH ST",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125673035",
  "inst_zip_code": "606163717",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "ILLINOIS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "E2NDENMDUEG8"
 },
 "perf_inst": {
  "perf_inst_name": "Illinois Institute of Technology",
  "perf_str_addr": "3300 South Federal Street",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606163732",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126600",
   "pgm_ele_name": "APPLIED MATHEMATICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 220000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The undertaken research focused on mathematical theory and computational methods of decision-making in systems that evolve randomly in time and whose essential characteristics are not precisely known to the controller/observer.</span></p>\n<p><span>In particular, the PIs studied a class of&nbsp;<strong><span>risk-sensitive Markovian control problems in discrete time subject to model uncertainty</span></strong>, subject to discounted cost criterion and with finite time horizon. The obtained results hinge on the following main building concepts: incorporating model uncertainty through the adaptive robust paradigm introduced in by the PI&rsquo;s in 2019, and developing efficient numerical solutions for the obtained Bellman equations by adopting the machine learning techniques. In contrast to previous works, we allow intermediate rewards and we use the discounted risk sensitive criterion. Accordingly, we derive a new set of adaptive robust Bellman equations.</span></p>\n<p><span>In addition, the PIs studied a class of&nbsp;<strong><span>time-inconsistent terminal Markovian control problems in discrete time subject to model uncertainty</span></strong>. We combine the concept of the sub-game perfect strategies with the adaptive robust stochastic to tackle the theoretical aspects of the considered stochastic control problem. Consequently, as an important application of the theoretical results, by applying a machine learning algorithm we solve numerically the mean-variance portfolio selection problem under the model uncertainty.</span></p>\n<p><span>Significant effort was put towards developing a comprehensive methodology in dealing with stochastic models with characteristics only partially reveled to the modeler who controls the systems within the risk-averse paradigm. In particular we allow the situation in which the actual cost is not known or observed by the modeler - a practically important feature that leads non-standard and non-trivial risk-averse Markov decision problems. We deal with this by introducing <strong><span>novel&nbsp;dynamic risk-assessment procedures,&nbsp;called risk filters</span></strong>, framed in the context of the adaptive robust control techniques. The paper took a long time to complete due to its conceptual and technical advancement, and is currently submitted.</span></p>\n<p><span>The obtained results, and developed algorithms directly advance and promote the progress of science and engineering, with potential applications in applied areas such as medical sciences, engineering, economics, finance, inventory management and insurance.&nbsp;</span></p>\n<p><span>One of the PIs and his collaborators investigate the optimal investment problem by using coherent acceptability indices (CAIs) as a tool to measure the portfolio performance. Using robust representations of CAIs in terms of a family of dynamic coherent risk measures (DCRMs), they establish an intriguing dichotomy: if the corresponding family of DCRMs is recursive (i.e. strongly time consistent) and assuming some recursive structure of the market model, then the acceptability maximization problem reduces to just a one period problem and the maximal acceptability is constant across all states and times. On the other hand, if the family of DCRMs is not recursive, which is often the case, then the acceptability maximization problem typically is a time-inconsistent stochastic control problem, similar to the classical mean-variance criteria. To overcome this form of time-inconsistency, they adapt to their setup the set-valued Bellman&rsquo;s principle applied to two particular dynamic CAIs - the dynamic risk-adjusted return on capital and the dynamic gain-to-loss ratio. The obtained theoretical results are illustrated via numerical examples that include, in particular, the computation of the intermediate mean-risk efficient frontiers.</span></p>\n<p><span>The PIs, together with the PhD student Hao Liu, studied the dynamic risk measures and dynamic performance measures generated by distortion functions. We show that conditional version of Choquet integrals indeed are dynamic coherent risk measures (DCRMs), and also introduce the class of&nbsp; dynamic&nbsp; weighted value at risk measures. We prove that these two classes of risk measures&nbsp; coincides. In the spirit of robust representations theorem for DCAIs, we establish some relevant properties of families of DCRMs generated by distortion functions, and then define and study the corresponding DCAIs. Second, we study the time consistency of DCRMs and&nbsp; DCAIs generated by distortion functions. &nbsp;&nbsp;&nbsp; In particular, we prove that such DCRMs &nbsp;are&nbsp; sub-martingale time consistent, but they are not super-martingale time consistent. We also show that DCRMs generated by distortion functions are not weakly acceptance time consistent. We also present several widely used classes of distortion functions and derive some new representations of these distortions.</span></p>\n<p><span>The PIs have co-supervised the work of four doctoral students in the past five years. The PIs are actively involved in extracurricular activities such as giving public lectures on stochastic control accessible to a large audience, mentoring students and early career researchers from various back-grounds, and participating in numerous scholar activities of the mathematical finance and control communities. The PIs have co-organized a number of sessions and minisymposia at SIAM Conferences on Financial Mathematics and Engineering and a workshop at the Institute for the Mathematical and Statistical Innovation.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/29/2023<br>\n\t\t\t\t\tModified by: Tomasz&nbsp;R&nbsp;Bielecki</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe undertaken research focused on mathematical theory and computational methods of decision-making in systems that evolve randomly in time and whose essential characteristics are not precisely known to the controller/observer.\n\nIn particular, the PIs studied a class of risk-sensitive Markovian control problems in discrete time subject to model uncertainty, subject to discounted cost criterion and with finite time horizon. The obtained results hinge on the following main building concepts: incorporating model uncertainty through the adaptive robust paradigm introduced in by the PI\u2019s in 2019, and developing efficient numerical solutions for the obtained Bellman equations by adopting the machine learning techniques. In contrast to previous works, we allow intermediate rewards and we use the discounted risk sensitive criterion. Accordingly, we derive a new set of adaptive robust Bellman equations.\n\nIn addition, the PIs studied a class of time-inconsistent terminal Markovian control problems in discrete time subject to model uncertainty. We combine the concept of the sub-game perfect strategies with the adaptive robust stochastic to tackle the theoretical aspects of the considered stochastic control problem. Consequently, as an important application of the theoretical results, by applying a machine learning algorithm we solve numerically the mean-variance portfolio selection problem under the model uncertainty.\n\nSignificant effort was put towards developing a comprehensive methodology in dealing with stochastic models with characteristics only partially reveled to the modeler who controls the systems within the risk-averse paradigm. In particular we allow the situation in which the actual cost is not known or observed by the modeler - a practically important feature that leads non-standard and non-trivial risk-averse Markov decision problems. We deal with this by introducing novel dynamic risk-assessment procedures, called risk filters, framed in the context of the adaptive robust control techniques. The paper took a long time to complete due to its conceptual and technical advancement, and is currently submitted.\n\nThe obtained results, and developed algorithms directly advance and promote the progress of science and engineering, with potential applications in applied areas such as medical sciences, engineering, economics, finance, inventory management and insurance. \n\nOne of the PIs and his collaborators investigate the optimal investment problem by using coherent acceptability indices (CAIs) as a tool to measure the portfolio performance. Using robust representations of CAIs in terms of a family of dynamic coherent risk measures (DCRMs), they establish an intriguing dichotomy: if the corresponding family of DCRMs is recursive (i.e. strongly time consistent) and assuming some recursive structure of the market model, then the acceptability maximization problem reduces to just a one period problem and the maximal acceptability is constant across all states and times. On the other hand, if the family of DCRMs is not recursive, which is often the case, then the acceptability maximization problem typically is a time-inconsistent stochastic control problem, similar to the classical mean-variance criteria. To overcome this form of time-inconsistency, they adapt to their setup the set-valued Bellman\u2019s principle applied to two particular dynamic CAIs - the dynamic risk-adjusted return on capital and the dynamic gain-to-loss ratio. The obtained theoretical results are illustrated via numerical examples that include, in particular, the computation of the intermediate mean-risk efficient frontiers.\n\nThe PIs, together with the PhD student Hao Liu, studied the dynamic risk measures and dynamic performance measures generated by distortion functions. We show that conditional version of Choquet integrals indeed are dynamic coherent risk measures (DCRMs), and also introduce the class of  dynamic  weighted value at risk measures. We prove that these two classes of risk measures  coincides. In the spirit of robust representations theorem for DCAIs, we establish some relevant properties of families of DCRMs generated by distortion functions, and then define and study the corresponding DCAIs. Second, we study the time consistency of DCRMs and  DCAIs generated by distortion functions.     In particular, we prove that such DCRMs  are  sub-martingale time consistent, but they are not super-martingale time consistent. We also show that DCRMs generated by distortion functions are not weakly acceptance time consistent. We also present several widely used classes of distortion functions and derive some new representations of these distortions.\n\nThe PIs have co-supervised the work of four doctoral students in the past five years. The PIs are actively involved in extracurricular activities such as giving public lectures on stochastic control accessible to a large audience, mentoring students and early career researchers from various back-grounds, and participating in numerous scholar activities of the mathematical finance and control communities. The PIs have co-organized a number of sessions and minisymposia at SIAM Conferences on Financial Mathematics and Engineering and a workshop at the Institute for the Mathematical and Statistical Innovation.\n\n \n\n\t\t\t\t\tLast Modified: 09/29/2023\n\n\t\t\t\t\tSubmitted by: Tomasz R Bielecki"
 }
}