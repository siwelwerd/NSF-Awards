{
 "awd_id": "1945105",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Best Viewpoints for External Robots or Sensors Assisting Other Robots",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Juan Wachs",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2019-09-09",
 "awd_max_amd_letter_date": "2019-09-09",
 "awd_abstract_narration": "Bomb squads, SWAT teams, nuclear workers, and first responders typically use two robots to complete a single task: The primary robot performs the task but the operators use a second robot to get a better view of what the primary robot is doing. It is hard for the two sets of operators to coordinate the robots. But the biggest problem is not manual coordination, it is that operators often do not place the secondary robot where it provides the best viewpoint for increasing performance.  While studies starting in 2001 have consistently shown that operators do not pick optimal viewpoints, there has been no formal theory of what is good for different types of tasks. This project will create the formal theory using perceptual psychology and apply it to an Endeavor Packbot 510 mobile robot that has been modified to carry a tethered Fotokite unmanned aerial vehicle (UAV).  Using the formal theory, the Packbot will be able to perform a remote task while the UAV autonomously moves and maintains the optimal viewpoint given the clutter in the environment. This will reduce the manpower, inefficiency, and time it takes for robots to accomplish tasks in all domains, from public safety to manufacturing. The theory can also be applied to placing external sensors or cameras where they will be most helpful in controlling telecommuting robots, construction robots, or space robotics.\r\n\r\nThis project will provide a fundamental, principled understanding of the perception needed to reduce the cognitive demands on robot operators, thereby increasing productivity while reducing costly errors. The model will allow ground robots, aerial robots, or external cameras to autonomously position themselves to give the best viewpoint for the current task. The project's approach is to use cognitive science concept of affordances, where the potential for an action can be directly perceived without knowing intent or models, and thus is universal to all robots and tasks.  The project will learn from expert robot operators the value of viewpoints for four different affordances (passability, reachability, manipulability, traversability) as they use a computer simulator developed under previous NSF funding to perform tasks. The project will then use machine learning to cluster the performance into a set of equivalent manifolds representing the relative value of viewpoints in that region for an affordance. These rankings will be used by a risk-based planner, also developed under previous NSF funding, to move the external robot to the best view for the operator, given the risk of the path to the view. The resulting theory will be implemented on a Packbot ground robot (primary) and carrying a tethered Fotokite (secondary) aerial assistant for two tasks: a door opening and traversal test capturing the most common bottleneck for any indoor navigation application and a sensor insertion task duplicating an especially difficult mission at Fukushima. The project will enable robots to be more useful during disasters and public safety incidents, accelerate the safe decommissioning of the Fukushima Daiichi facility, and aid with NASA and NIH missions for assistive robots.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robin",
   "pi_last_name": "Murphy",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Robin R Murphy",
   "pi_email_addr": "robin.r.murphy@tamu.edu",
   "nsf_id": "000511836",
   "pi_start_date": "2019-09-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M Engineering Experiment Station",
  "perf_str_addr": "3112 TAMU",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433112",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>In disasters, nuclear plant decommissioning, or construction, two robots are better than one: the acknowledged best practice is to use one robot to perform the task while another robot serves as a mobile camera. This external viewpoint gives the operator a better view of the task. But Department of Energy studies have shown that robot operators are not guaranteed to place the secondary robot in the best location and may never notice that there was a better viewpoint. The problem has been that no one knows what the best location is for a particular task. This project turned to psychomotor models in cognitive psychology which state that the perceptual component of robot tasks can be broken down into unique perceptual capabilities called affordances. For example, if a robot has to pass through a narrow door or a robot arm has to move around the interior of an airplane wing, the view has to show passability. Four affordances were identified (reachability, passability, manipulability, traversability) and a high fidelity computer simulation was created to test how well experts could control a robot using those four affordances from different viewpoints. Thirty-one expert robot bomb squad and nuclear power plant operators from the United States and Japan experimented with two different robots. The systems learned from their performance, producing a hemispherical ?map? of the value of the viewpoint from each location around the primary robot. The maps for the four affordances clearly showed that there were different good and bad regions for each particular task. For example, in the passability case, the most helpful viewpoints were elevated view either in front or behind the robot, while the worst were on the sides (because the sides were essentially blocked by whatever the robot was trying to get past). Taken together, the operators saw an increase in performance of 18-25% and a 87% decrease in errors. This means that current robot operators can immediately use the results as guidelines for difficult or dangerous situations, thus improving performance and safety of teleoperated robots. The results have advanced the theory of robotics and artificial intelligence plus confirmed psychomotor models and transferred those models from cognitive science to robotics. =. The short term benefit has been the production of a set of easy to use guidelines for robot operators, especially those in bomb squads and nuclear decommissioning, that will improve efficiency and safety. The longer term benefits are that it has set the foundation for autonomously directing the robots, that is, the secondary robot now knows where to autonomously move to maintain the best viewpoint. This will further improve performance and safety, thereby increasing US economic competitiveness and increase workplace safety. In addition, the project has trained six computer science and engineering graduate students in artificial intelligence and field robotics. It has contributed to increased diversity as one of the graduate students is a woman.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/30/2023<br>\n\t\t\t\t\tModified by: Robin&nbsp;R&nbsp;Murphy</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1945105/1945105_10640941_1675131325775_NRIVAsimplifiedposter--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1945105/1945105_10640941_1675131325775_NRIVAsimplifiedposter--rgov-800width.jpg\" title=\"Guide: Where to Put External Robots/Sensors to Assist Other Robots\"><img src=\"/por/images/Reports/POR/2023/1945105/1945105_10640941_1675131325775_NRIVAsimplifiedposter--rgov-66x44.jpg\" alt=\"Guide: Where to Put External Robots/Sensors to Assist Other Robots\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Illustrated Guide of Where to Put External Robots/Sensors to Assist Other Robots</div>\n<div class=\"imageCredit\">Texas A&M Engineering Extension Service</div>\n<div class=\"imageSubmitted\">Robin&nbsp;R&nbsp;Murphy</div>\n<div class=\"imageTitle\">Guide: Where to Put External Robots/Sensors to Assist Other Robots</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nIn disasters, nuclear plant decommissioning, or construction, two robots are better than one: the acknowledged best practice is to use one robot to perform the task while another robot serves as a mobile camera. This external viewpoint gives the operator a better view of the task. But Department of Energy studies have shown that robot operators are not guaranteed to place the secondary robot in the best location and may never notice that there was a better viewpoint. The problem has been that no one knows what the best location is for a particular task. This project turned to psychomotor models in cognitive psychology which state that the perceptual component of robot tasks can be broken down into unique perceptual capabilities called affordances. For example, if a robot has to pass through a narrow door or a robot arm has to move around the interior of an airplane wing, the view has to show passability. Four affordances were identified (reachability, passability, manipulability, traversability) and a high fidelity computer simulation was created to test how well experts could control a robot using those four affordances from different viewpoints. Thirty-one expert robot bomb squad and nuclear power plant operators from the United States and Japan experimented with two different robots. The systems learned from their performance, producing a hemispherical ?map? of the value of the viewpoint from each location around the primary robot. The maps for the four affordances clearly showed that there were different good and bad regions for each particular task. For example, in the passability case, the most helpful viewpoints were elevated view either in front or behind the robot, while the worst were on the sides (because the sides were essentially blocked by whatever the robot was trying to get past). Taken together, the operators saw an increase in performance of 18-25% and a 87% decrease in errors. This means that current robot operators can immediately use the results as guidelines for difficult or dangerous situations, thus improving performance and safety of teleoperated robots. The results have advanced the theory of robotics and artificial intelligence plus confirmed psychomotor models and transferred those models from cognitive science to robotics. =. The short term benefit has been the production of a set of easy to use guidelines for robot operators, especially those in bomb squads and nuclear decommissioning, that will improve efficiency and safety. The longer term benefits are that it has set the foundation for autonomously directing the robots, that is, the secondary robot now knows where to autonomously move to maintain the best viewpoint. This will further improve performance and safety, thereby increasing US economic competitiveness and increase workplace safety. In addition, the project has trained six computer science and engineering graduate students in artificial intelligence and field robotics. It has contributed to increased diversity as one of the graduate students is a woman.\n\n \n\n\t\t\t\t\tLast Modified: 01/30/2023\n\n\t\t\t\t\tSubmitted by: Robin R Murphy"
 }
}