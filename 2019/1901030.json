{
 "awd_id": "1901030",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Medium: Visually Interactive Neural Probabilistic Models of Language",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2019-11-01",
 "awd_exp_date": "2024-10-31",
 "tot_intn_awd_amt": 1200000.0,
 "awd_amount": 1200000.0,
 "awd_min_amd_letter_date": "2019-07-29",
 "awd_max_amd_letter_date": "2022-08-15",
 "awd_abstract_narration": "The application of machine learning to automate everyday tasks is becoming increasingly common. While automation has the potential of yielding higher efficiency and improved outcomes, it can lead to unpredictable mistakes that can be hard to analyze and correct. Users of machine learning algorithms need better explanations for predictions and choices that are made. Moreover, to prevent harm, a user should be able to intervene in and control the decision process of the algorithm. This award is primarily concerned with applications in neural language models, i.e., machine learning systems that communicate using natural language. Because these systems interact with users using text or speech, it is essential to avoid misinformation from automated approaches and to retain human agency. Developing explainable and controllable artificial intelligence methods will empower users to collaborate with automation tools and gain efficiency and performance benefits while at the same time preventing harm and misinformation. \r\n\r\nThis project targets the development of methods and visually interactive tools that allow researchers to develop, examine, and correct probabilistic neural models of language. Co-designing machine learning models and visual interfaces will be a necessary step towards interpretable models for common use-cases such as language summarization, translation, and data-to-text applications. To achieve these interactive and collaborative systems requires developing novel probabilistic neural network models with latent variables that can act as \"hooks\" within the model. These hooks correspond to interpretable decisions that a model has to take and that enable end-users to overwrite and interact with model decisions. In a second step, the project will develop query and visualization methods that utilize these hooks to allow users to explore, debug, and improve neural models on real examples through interactive user feedback. The project progress will be evaluated using quantitative methods from machine learning, qualitative and quantitative user studies, and long-term longitudinal observations of user engagement. The project will result in an extensible software framework for visually interactive analysis of neural sequence models that will assist other researchers and developers in their application domains.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hanspeter",
   "pi_last_name": "Pfister",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hanspeter Pfister",
   "pi_email_addr": "pfister@seas.harvard.edu",
   "nsf_id": "000185558",
   "pi_start_date": "2019-07-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Alexander",
   "pi_last_name": "Rush",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alexander Rush",
   "pi_email_addr": "arush@cornell.edu",
   "nsf_id": "000703197",
   "pi_start_date": "2019-07-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University",
  "perf_str_addr": "33 Oxford Street",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021382933",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 218628.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 646858.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 334514.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-9fe66f82-7fff-ee89-5330-6229c3bed1e1\"> </span></p>\r\n<p dir=\"ltr\"><span>Large language models (LLMs) are among the most promising and challenging technologies in use today. In this project,&nbsp;</span><span>&ldquo;Visually Interactive Neural Probabilistic Models of Language,&rdquo;</span><span>&nbsp;the investigators have conducted research at the intersection of visualization and machine learning to better understand how these systems function and to develop visualization methods that enhance exploration and control of their output. Over the course of the project, the investigators have created foundational techniques that combine visualization, interpretability, machine learning, and interactive tooling. This work has illuminated the internal structure of language models, showcasing their core properties, making them more accessible for application, and uncovering their central limitations.</span></p>\r\n<p dir=\"ltr\"><span>The efforts have resulted in dozens of papers published at top conferences, including InfoVis, NeurIPS, ICLR, ICML, EMNLP, and ACL. The project has focused on three key areas:</span></p>\r\n<ol>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\"><span>Developing </span><span>visual mechanisms</span><span> to interact with language models.</span></p>\r\n</li>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\"><span>Building </span><span>tools to debug and improve language model functionality.</span></p>\r\n</li>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\"><span>Designing </span><span>analysis methods to understand their internal workings.</span></p>\r\n</li>\r\n</ol>\r\n<h3 dir=\"ltr\"><span>Visualization Approaches for Language Models</span></h3>\r\n<p dir=\"ltr\"><span>The investigator's research has significantly influenced the development of large-scale interactive systems for understanding language models. A notable contribution is&nbsp;</span><span>&ldquo;</span><span>GLTR&rdquo; (2020)</span><span>,</span><span>&nbsp;a visual analysis tool designed to demonstrate whether text was generated from a human or a language model. This tool saw widespread use and was integrated into the Hugging Face platform. More recently, research on analyzing LLMs trained on Othello for \"Emergent World Representations\" (2023) has uncovered fascinating structures within their internal states, contributing to the community's understanding of world models in LLMs.</span></p>\r\n<h3 dir=\"ltr\"><span>Debugging Tools and Methods</span></h3>\r\n<p dir=\"ltr\"><span>Using and debugging LLMs was once the domain of experts but has now become a commonplace activity. Notable contributions include&nbsp;</span><span>&ldquo;</span><span>PromptIDE&rdquo; (2022)</span><span>,</span><span>&nbsp;a visually interactive tool that helps users design few-shot prompts for in-context learning tasks. This tool demonstrated that interaction with LLMs can significantly improve prompt accuracy and inspired numerous follow-up approaches. The investigators also explored &ldquo;Inference Time Interventions&rdquo; (2023)</span><span>,</span><span>&nbsp;which showed how targeted modifications to LLMs&rsquo; internal representations during inference could adjust generation properties more effectively than additional training.</span></p>\r\n<h3 dir=\"ltr\"><span>Collaborative Interaction for Understanding LLMs</span></h3>\r\n<p dir=\"ltr\"><span>A key goal of the project has been to develop frameworks that help humans build intuition about LLM decision-making through interaction. In &ldquo;Visual Interaction with Deep Learning Models Through Collaborative Semantic Inference&rdquo; (2020)</span><span>,</span><span>&nbsp;the investigators formalized mechanisms for interacting with LLM systems and built a prototype for semantic interaction in language model applications. Building on these lessons, the investigators developed systems like&nbsp;</span><span>&ldquo;</span><span>Rationales for Sequential Prediction&rdquo; (2021)</span><span>,</span><span>&nbsp;which allowed models to provide feedback&mdash;such as identifying the words that influenced a decision&mdash;to improve interpretability.</span></p>\r\n<h3 dir=\"ltr\"><span>Broader Impact</span></h3>\r\n<p dir=\"ltr\"><span>Beyond the core research, the investigators have contributed extensively to teaching, organization, and the dissemination of knowledge. Key achievements include:</span></p>\r\n<ul>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\"><span>Developing the </span><span>Miniconf virtual conference system,</span><span> which powered major ML and NLP conferences during COVID and integrated visualization methods.</span></p>\r\n</li>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\"><span>Designing and teaching the </span><span>Breakthrough Tech AI program</span><span> at Cornell Tech, which introduces AI to a primarily female cohort of students in the NYC area.</span></p>\r\n</li>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\">Actively participating in the&nbsp;BigScience initiative,&nbsp;an open-source collaboration that produced the multilingual BLOOM language model.</p>\r\n</li>\r\n</ul>\r\n<p dir=\"ltr\">&nbsp;</p><br>\n<p>\n Last Modified: 12/16/2024<br>\nModified by: Alexander&nbsp;Rush</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \r\n\n\nLarge language models (LLMs) are among the most promising and challenging technologies in use today. In this project,Visually Interactive Neural Probabilistic Models of Language,the investigators have conducted research at the intersection of visualization and machine learning to better understand how these systems function and to develop visualization methods that enhance exploration and control of their output. Over the course of the project, the investigators have created foundational techniques that combine visualization, interpretability, machine learning, and interactive tooling. This work has illuminated the internal structure of language models, showcasing their core properties, making them more accessible for application, and uncovering their central limitations.\r\n\n\nThe efforts have resulted in dozens of papers published at top conferences, including InfoVis, NeurIPS, ICLR, ICML, EMNLP, and ACL. The project has focused on three key areas:\r\n\r\n\r\n\n\nDeveloping visual mechanisms to interact with language models.\r\n\r\n\r\n\n\nBuilding tools to debug and improve language model functionality.\r\n\r\n\r\n\n\nDesigning analysis methods to understand their internal workings.\r\n\r\n\r\nVisualization Approaches for Language Models\r\n\n\nThe investigator's research has significantly influenced the development of large-scale interactive systems for understanding language models. A notable contribution isGLTR (2020),a visual analysis tool designed to demonstrate whether text was generated from a human or a language model. This tool saw widespread use and was integrated into the Hugging Face platform. More recently, research on analyzing LLMs trained on Othello for \"Emergent World Representations\" (2023) has uncovered fascinating structures within their internal states, contributing to the community's understanding of world models in LLMs.\r\nDebugging Tools and Methods\r\n\n\nUsing and debugging LLMs was once the domain of experts but has now become a commonplace activity. Notable contributions includePromptIDE (2022),a visually interactive tool that helps users design few-shot prompts for in-context learning tasks. This tool demonstrated that interaction with LLMs can significantly improve prompt accuracy and inspired numerous follow-up approaches. The investigators also explored Inference Time Interventions (2023),which showed how targeted modifications to LLMs internal representations during inference could adjust generation properties more effectively than additional training.\r\nCollaborative Interaction for Understanding LLMs\r\n\n\nA key goal of the project has been to develop frameworks that help humans build intuition about LLM decision-making through interaction. In Visual Interaction with Deep Learning Models Through Collaborative Semantic Inference (2020),the investigators formalized mechanisms for interacting with LLM systems and built a prototype for semantic interaction in language model applications. Building on these lessons, the investigators developed systems likeRationales for Sequential Prediction (2021),which allowed models to provide feedbacksuch as identifying the words that influenced a decisionto improve interpretability.\r\nBroader Impact\r\n\n\nBeyond the core research, the investigators have contributed extensively to teaching, organization, and the dissemination of knowledge. Key achievements include:\r\n\r\n\r\n\n\nDeveloping the Miniconf virtual conference system, which powered major ML and NLP conferences during COVID and integrated visualization methods.\r\n\r\n\r\n\n\nDesigning and teaching the Breakthrough Tech AI program at Cornell Tech, which introduces AI to a primarily female cohort of students in the NYC area.\r\n\r\n\r\n\n\nActively participating in theBigScience initiative,an open-source collaboration that produced the multilingual BLOOM language model.\r\n\r\n\r\n\n\n\t\t\t\t\tLast Modified: 12/16/2024\n\n\t\t\t\t\tSubmitted by: AlexanderRush\n"
 }
}