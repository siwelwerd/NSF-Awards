{
 "awd_id": "1937301",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RTML: Large: Continuous Adaptation for Decision Streams",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 1500000.0,
 "awd_amount": 1500000.0,
 "awd_min_amd_letter_date": "2019-09-08",
 "awd_max_amd_letter_date": "2019-09-08",
 "awd_abstract_narration": "Systems that can efficiently make real-time decisions based on large-scale data streams will impact broad areas of daily life, including autonomous vehicles, personal assistants, medicine, and fraud detection tools. Such systems have become critical as machine learning is increasingly tasked with making richer decisions over constantly-changing large data streams for both consumer and industry applications. This project seeks to develop hardware-software systems capable of making such real-time decisions over large data streams while flexibly and continuously adapting to changes in their environment. This project will also support redesign of courses on hardware accelerators and parallel computing at Stanford University, with large-scale data streaming systems as a central driver. These courses are designed to provide students with a sufficiently strong background to engage in systems and machine learning research, thus enabling a diverse and much desired US workforce in an area of technology of current importance.\r\n\r\nThis project will create tools and techniques for large-scale data streaming systems by producing innovations spanning software, hardware, and machine learning. Modern machine learning requires a vast amount of labeled data, and streaming scenarios only increase this requirement. To handle the need for more data, techniques for automatically labeling data (and in particular, temporal data) under real-time constraints will be developed. Because the environment for data streaming systems is constantly changing, the proposed project seeks to continuously adapt and specialize models to the current environment, leading to vastly improved efficiency. Real-time data streaming systems will require hardware that achieves both exceptional efficiency, as well as provides sufficient flexibility to support both real-time model training and inference; this project will develop such hardware. These innovations will be demonstrated and evaluated on two applications: next-generation video stream processing in autonomous vehicle, medical and industrial domains and smart routers for networking systems. The project will also collaborate with a synergistic DARPA program for related hardware development.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Oyekunle",
   "pi_last_name": "Olukotun",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Oyekunle A Olukotun",
   "pi_email_addr": "kunle@stanford.edu",
   "nsf_id": "000320046",
   "pi_start_date": "2019-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Re",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher Re",
   "pi_email_addr": "chrismre@cs.stanford.edu",
   "nsf_id": "000555316",
   "pi_start_date": "2019-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kayvon",
   "pi_last_name": "Fatahalian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kayvon Fatahalian",
   "pi_email_addr": "kayvonf@cs.stanford.edu",
   "nsf_id": "000624440",
   "pi_start_date": "2019-09-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "353 Serra Mall, Gates Building",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943055008",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "082Z",
   "pgm_ref_txt": "RTML-Real Time Machine Learning"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 1500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-f9072845-7fff-6604-302c-d3d8aa9936c4\"> </span></p>\n<p dir=\"ltr\"><strong>Intellectual Merit. </strong><span>Over the course of this grant, we have made fundamental progress in learning from weaker forms of supervision and developing new optimization techniques.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>On learning from weaker forms of supervision, we have developed techniques both for aggregating multiple sources of weak data, and for learning from self-supervised signals. In FlyingSquid and its follow-ups, we developed new systems to aggregate multiple noisy sources of weak labels into training data for supervised machine learning models. In Liger and AMA, we showed how to further incorporate signals from foundation models, a new class of powerful pretrained machine learning models that have broad capabilities but require adaptation to specific circumstances. Our group also developed techniques for learning from weak, self-supervised signals. In Bootleg and TABi, we showed that incorporating type information into self-supervised learning pipelines improves the performance of named entity disambiguation. We also showed how to use embeddings from pretrained models to improve the robustness of downstream tasks.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>We have also developed new techniques for optimizing machine learning pipelines, especially for long sequence data. We developed FlashAttention, a new algorithm for speeding up Transformers &mdash; a large class of modern machine learning models &mdash; and reducing their memory footprint. In S4 and SaShiMi, we pioneered the development of a new class of models -&ndash; structured state space models &mdash; and showed that they are best-in-class architectures for long sequence modeling and speech generation. In H3, we developed new techniques to optimize these models, and showed they are also strong architectures for language modeling.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><strong>Broader Impacts. </strong><span>Our work has seen rapid adoption and impact in industry. FlashAttention has been adopted in every major Transformer training pipeline, and has seen adoption in PyTorch, OpenAI, Microsoft, NVIDIA, and more. Bootleg has been deployed for named entity disambiguation pipelines at Apple. Our work in learning from weaker forms of supervision has also been adopted for downstream medical and scientific applications.</span></p>\n<p dir=\"ltr\"><span><span>&nbsp;</span></span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/02/2023<br>\n\t\t\t\t\tModified by: Oyekunle&nbsp;A&nbsp;Olukotun</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nIntellectual Merit. Over the course of this grant, we have made fundamental progress in learning from weaker forms of supervision and developing new optimization techniques.\n\n \nOn learning from weaker forms of supervision, we have developed techniques both for aggregating multiple sources of weak data, and for learning from self-supervised signals. In FlyingSquid and its follow-ups, we developed new systems to aggregate multiple noisy sources of weak labels into training data for supervised machine learning models. In Liger and AMA, we showed how to further incorporate signals from foundation models, a new class of powerful pretrained machine learning models that have broad capabilities but require adaptation to specific circumstances. Our group also developed techniques for learning from weak, self-supervised signals. In Bootleg and TABi, we showed that incorporating type information into self-supervised learning pipelines improves the performance of named entity disambiguation. We also showed how to use embeddings from pretrained models to improve the robustness of downstream tasks.\n\n \nWe have also developed new techniques for optimizing machine learning pipelines, especially for long sequence data. We developed FlashAttention, a new algorithm for speeding up Transformers &mdash; a large class of modern machine learning models &mdash; and reducing their memory footprint. In S4 and SaShiMi, we pioneered the development of a new class of models -&ndash; structured state space models &mdash; and showed that they are best-in-class architectures for long sequence modeling and speech generation. In H3, we developed new techniques to optimize these models, and showed they are also strong architectures for language modeling.\n\n \nBroader Impacts. Our work has seen rapid adoption and impact in industry. FlashAttention has been adopted in every major Transformer training pipeline, and has seen adoption in PyTorch, OpenAI, Microsoft, NVIDIA, and more. Bootleg has been deployed for named entity disambiguation pipelines at Apple. Our work in learning from weaker forms of supervision has also been adopted for downstream medical and scientific applications.\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 03/02/2023\n\n\t\t\t\t\tSubmitted by: Oyekunle A Olukotun"
 }
}