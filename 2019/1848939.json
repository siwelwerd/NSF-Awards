{
 "awd_id": "1848939",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Visual feature perception during dynamic spatial attention and distraction",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 450265.0,
 "awd_amount": 450265.0,
 "awd_min_amd_letter_date": "2019-06-17",
 "awd_max_amd_letter_date": "2019-09-11",
 "awd_abstract_narration": "How does our visual system make sense of the world around us? Our brains construct incredibly rich perceptual experiences from the rawest of visual inputs: patterns of light on the eye's retina. A major challenge is that the environment presents more information than our visual system can fully process at a time, so we rely on the mechanisms of attention to prioritize the most relevant information. Attention and perception are vital cognitive processes that affect every aspect of our daily functioning. Understanding how these processes typically work - and when we are susceptible to perceptual errors and distortions - has critical repercussions for both the healthy visual system and various disorders, along with broad-reaching applications ranging from maximizing human behavior to development of artificial intelligence and technology. The project's education component will increase STEM opportunities for underrepresented racial and ethnic groups, enhance undergraduate education, and offer community outreach. \r\n\r\nThis proposal outlines a three-year integrated research and education plan addressing how visual feature perception is altered during dynamic spatial attention and distraction. The proposal investigates a fundamental challenge for our visual systems: How do we successfully integrate information about 'what' an object is with 'where' it is? While the binding process is challenging enough on its own, it becomes particularly crucial during dynamic vision and cognition, where there are often multiple objects or locations of interest in the environment and spatial attention is constantly shifting. Using a paradigm recently developed by PI Golomb, we test the hypothesis that unstable spatial attention can cause errors in feature and object perception. In Aim 1, we focus on how visual feature perception might be altered during conditions of distraction, in collaboration with co-PI Leber, an expert in attentional control and distraction. In Aim 2, we expand in an even more fundamental direction, asking how different types of dynamic spatial attention might impact object integration for multi-feature objects. The experiments include a combination of perceptual feature reports, probabilistic mixture modeling, EEG alpha decoding, eye-tracking, and reward-based manipulations. This innovative and novel approach strives to advance our understanding of how we achieve stable and integrated visual perception, especially under conditions of dynamic attention and distraction.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Julie",
   "pi_last_name": "Golomb",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Julie D Golomb",
   "pi_email_addr": "golomb.9@osu.edu",
   "nsf_id": "000675077",
   "pi_start_date": "2019-06-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andrew",
   "pi_last_name": "Leber",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Andrew B Leber",
   "pi_email_addr": "leber.30@osu.edu",
   "nsf_id": "000521759",
   "pi_start_date": "2019-06-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio State University",
  "inst_street_address": "1960 KENNY RD",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBUS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "6146888735",
  "inst_zip_code": "432101016",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OH03",
  "org_lgl_bus_name": "OHIO STATE UNIVERSITY, THE",
  "org_prnt_uei_num": "MN4MDDMN8529",
  "org_uei_num": "DLWBSLWAJWR1"
 },
 "perf_inst": {
  "perf_inst_name": "The Ohio State University",
  "perf_str_addr": "1835 Neil Ave",
  "perf_city_name": "Columbus",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "432101351",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OH03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 450265.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project was to understand how visual feature perception is altered during dynamic spatial attention and distraction. Attention and perception are fundamental cognitive processes that affect every aspect of our daily functioning. Understanding how these processes typically work &ndash; and when we are susceptible to perceptual errors and distortions &ndash; has critical repercussions for both the healthy visual system and various disorders, along with broad-reaching applications ranging from maximizing human behavior to development of artificial intelligence and technology. A fundamental challenge for our visual systems is: How do we successfully integrate information about 'what' an object is with 'where' it is? While the binding process is challenging enough on its own, it becomes particularly crucial during dynamic vision and cognition, where there are often multiple objects or locations of interest in the environment and spatial attention is constantly shifting.</p>\r\n<p class=\"Default\">Our work demonstrated several key findings. First, we found that visual feature perception is altered during distraction. Using a continuous report task and novel confidence range report paradigm, we discovered two types of feature-binding errors when a distractor was presented along with the target: First, when attention is strongly captured by the distractor, participants commit swapping errors (misreporting the color at the distractor location instead of the target color), which remarkably seem to occur without awareness. Second, when participants successfully resist capture, they tend to exhibit repulsion (perceptual distortion away from the color at the distractor location). In a subsequent study, we manipulated the timing of the stimulus presentation relative to the distractor cue to test if the pattern of feature errors changes over the timecourse of attentional capture and disengagement. To gain further insight into these processes, we also developed an EEG analysis approach that produces dynamic estimates of neural representations of attended features (time point-by-time point inverted encoding model reconstructions) and attended location (time point-by-time point decoding) that can be simultaneously tracked across shifts of covert attention.</p>\r\n<p class=\"Default\">In Aim 2 we examined a more complex version of this challenge: our real-world visual environments typically contain multiple objects each composed of multiple visual features (e.g., color, shape, texture) that must be integrated together into a cohesive object-level representation. We found that rapid shifts of spatial attention maintain bound objects &ndash; at either the correct or a wrong location &ndash; whereas splitting attention across multiple locations degrades object integrity, causing misbinding of features (e.g. reporting the color of one item and orientation of another). Across several studies we then investigated different types of dynamic spatial attention and distraction, including intentional shifts of attention towards goal-relevant locations, unintentional capture of attention by salient distractors, automatic orienting towards locations where a target is likely to appear, remapping of attention across eye movements, lapses of attention, etc.</p>\r\n<p class=\"Default\">Additional findings focused on the broader consequences of distraction, including disruptions of higher-level filters gating working memory and cognitive control, as well as work examining how and when we can protect against some of these consequences of distraction.</p>\r\n<p>Our research results were widely and openly disseminated, with increased focus on Open Science principles, such as preregistering experiments and making data openly available.</p>\r\n<p>In addition to the research goals, a primary goal was an education component aiming to provide mentoring and training for the next generation of scientists, to increase STEM opportunities for underrepresented racial and ethnic groups, to enhance undergraduate education, and to offer community outreach to engage the general public. Several graduate students, postdoctoral fellows, post-baccalaureate students, and undergraduates collaborated on projects related to the grant, which supported these students to travel to conferences and workshops and enabled additional collaboration, educational, outreach, and professional development opportunities. Of particular note, the grant supported eight undergraduates to present first-author<em> </em>posters or talks at major conferences in the field. Moreover, both postdocs supported in part by the grant were hired into tenure-track faculty positions following their training in the lab, former PhD students involved in the grant went on to postdoctoral or industry research positions, and all five postbaccalaureate students continued on to PhD programs. Of the students listed above, 10 are international students or first-generation immigrants, 3 are Black, 2 are Latinx, 3 are first-generation college students, and 50% are female or nonbinary. The lab engaged in various community outreach activities, including organizing an annual booth at the Columbus Center of Science &amp; Industry (COSI) Science Festival, a free event with hundreds of thousands of attendees.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/10/2024<br>\nModified by: Julie&nbsp;D&nbsp;Golomb</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe goal of this project was to understand how visual feature perception is altered during dynamic spatial attention and distraction. Attention and perception are fundamental cognitive processes that affect every aspect of our daily functioning. Understanding how these processes typically work  and when we are susceptible to perceptual errors and distortions  has critical repercussions for both the healthy visual system and various disorders, along with broad-reaching applications ranging from maximizing human behavior to development of artificial intelligence and technology. A fundamental challenge for our visual systems is: How do we successfully integrate information about 'what' an object is with 'where' it is? While the binding process is challenging enough on its own, it becomes particularly crucial during dynamic vision and cognition, where there are often multiple objects or locations of interest in the environment and spatial attention is constantly shifting.\r\n\n\nOur work demonstrated several key findings. First, we found that visual feature perception is altered during distraction. Using a continuous report task and novel confidence range report paradigm, we discovered two types of feature-binding errors when a distractor was presented along with the target: First, when attention is strongly captured by the distractor, participants commit swapping errors (misreporting the color at the distractor location instead of the target color), which remarkably seem to occur without awareness. Second, when participants successfully resist capture, they tend to exhibit repulsion (perceptual distortion away from the color at the distractor location). In a subsequent study, we manipulated the timing of the stimulus presentation relative to the distractor cue to test if the pattern of feature errors changes over the timecourse of attentional capture and disengagement. To gain further insight into these processes, we also developed an EEG analysis approach that produces dynamic estimates of neural representations of attended features (time point-by-time point inverted encoding model reconstructions) and attended location (time point-by-time point decoding) that can be simultaneously tracked across shifts of covert attention.\r\n\n\nIn Aim 2 we examined a more complex version of this challenge: our real-world visual environments typically contain multiple objects each composed of multiple visual features (e.g., color, shape, texture) that must be integrated together into a cohesive object-level representation. We found that rapid shifts of spatial attention maintain bound objects  at either the correct or a wrong location  whereas splitting attention across multiple locations degrades object integrity, causing misbinding of features (e.g. reporting the color of one item and orientation of another). Across several studies we then investigated different types of dynamic spatial attention and distraction, including intentional shifts of attention towards goal-relevant locations, unintentional capture of attention by salient distractors, automatic orienting towards locations where a target is likely to appear, remapping of attention across eye movements, lapses of attention, etc.\r\n\n\nAdditional findings focused on the broader consequences of distraction, including disruptions of higher-level filters gating working memory and cognitive control, as well as work examining how and when we can protect against some of these consequences of distraction.\r\n\n\nOur research results were widely and openly disseminated, with increased focus on Open Science principles, such as preregistering experiments and making data openly available.\r\n\n\nIn addition to the research goals, a primary goal was an education component aiming to provide mentoring and training for the next generation of scientists, to increase STEM opportunities for underrepresented racial and ethnic groups, to enhance undergraduate education, and to offer community outreach to engage the general public. Several graduate students, postdoctoral fellows, post-baccalaureate students, and undergraduates collaborated on projects related to the grant, which supported these students to travel to conferences and workshops and enabled additional collaboration, educational, outreach, and professional development opportunities. Of particular note, the grant supported eight undergraduates to present first-author posters or talks at major conferences in the field. Moreover, both postdocs supported in part by the grant were hired into tenure-track faculty positions following their training in the lab, former PhD students involved in the grant went on to postdoctoral or industry research positions, and all five postbaccalaureate students continued on to PhD programs. Of the students listed above, 10 are international students or first-generation immigrants, 3 are Black, 2 are Latinx, 3 are first-generation college students, and 50% are female or nonbinary. The lab engaged in various community outreach activities, including organizing an annual booth at the Columbus Center of Science & Industry (COSI) Science Festival, a free event with hundreds of thousands of attendees.\r\n\n\n\t\t\t\t\tLast Modified: 12/10/2024\n\n\t\t\t\t\tSubmitted by: JulieDGolomb\n"
 }
}