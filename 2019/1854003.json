{
 "awd_id": "1854003",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research:  New Bayesian Nonparametric Paradigms of Personalized Medicine for Lung Cancer",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Pedro Embid",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 356553.0,
 "awd_amount": 356553.0,
 "awd_min_amd_letter_date": "2018-10-18",
 "awd_max_amd_letter_date": "2018-10-18",
 "awd_abstract_narration": "Rapid technological advances have allowed for molecular profiling across multiple domains from a single tumor sample, supporting clinical decision making in many diseases, especially cancer.  Key challenges are to effectively assimilate information across these domains to identify genomic signatures and biological entities that may be targeted by drugs, develop accurate risk prediction profiles for future patients, and identify novel patient subgroups for tailored therapy and monitoring.  The primary objective of this project is the development of an innovative, flexible and scalable statistical framework for analyzing  multi-domain, complex-structured, and high throughput  modern array and next generation sequencing-based 'omics datasets.  The work is motivated by several investigations related to lung cancer; however, the proposed methods and computational tools are broadly applicable in a variety of contexts involving high-dimensional data.  From a broader scientific perspective, the application of these novel methodologies to the motivating clinical and genomic datasets will allow for principled \"structure hunting\".  This will provide more accurate prediction of clinical outcomes, greater statistical power to detect important biologically actionable biomarkers for improved risk estimation and treatment selection for cancer diagnosis and prognosis, and better utilization of biological domain knowledge to find relationships between different platforms.  It will lead to subsequent implementation of rational biomarker-based and individualized clinical trials that increase the success rate of personalized therapies based on molecular markers.\r\n\r\nTo achieve these goals, the following specific aims are proposed: (1) Develop versatile and flexible statistical techniques for identifying differential genomic signatures for lung cancer in mixed, heterogeneously scaled single-domain datasets arising from array and next-generation sequencing based studies.  A general class of nonparametric Bayesian models based on sound theoretical justifications will be developed and implemented using efficient, scalable algorithms.  These models provide biologically interpretable summaries and enable applicability to a wide variety of high-throughput datasets.  (2) Formulate integrative probabilistic frameworks for massive multiple-domain data, which coherently incorporate dependence within and between domains to accurately detect tumor subtypes and predict clinical outcomes, thus providing a catalogue of genomic aberrations associated with cancer taxonomy.  (3) Foster massively parallel algorithms and high-performance computational and inferential tools that drastically reduce the computation times and increase scalability of high-throughput datasets.  These scalable inferential procedures are able to assimilate information from several platforms and select flexible models with the appropriate dependence structures, while detecting optimally sparse, non-linear mechanisms for predicting and identifying tumor subtypes.  Because these formulations are fully probabilistic, they offer substantial improvements over purely algorithmic approaches by accounting for different sources of variation and providing measures of inference uncertainty.  Since existing simulation-based algorithms do not scale for massive datasets, theoretical properties of these models will be exploited to devise data-squashing algorithms for efficient inference.  Furthermore, as traditional CPUs are limited by energy consumption, heat generation and memory access, software that harnesses the power of low-cost massively parallel computing tools such as graphics processing units (GPUs) will be developed and made freely available.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Subharup",
   "pi_last_name": "Guha",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Subharup Guha",
   "pi_email_addr": "s.guha@ufl.edu",
   "nsf_id": "000079982",
   "pi_start_date": "2018-10-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1 University of Florida",
  "perf_city_name": "Gainesville",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326112002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "804700",
   "pgm_ele_name": "NIGMS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "4075",
   "pgm_ref_txt": "NSF/NIGMS Initiative-Mathematical Bio"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 153799.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 202754.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has developed versatile and flexible nonparametric statistical techniques for identifying differential genomic signatures in cancer, invented integrative probabilistic frameworks for massive multiple-domain data, fostered massively parallel algorithms and high-performance computational and inferential tools, and trained the next generation of quantitative scientists to meet the challenges of interdisciplinary research involving high-dimensional data.</p>\n<p class=\"Default\">Many standard approaches to modeling high-dimensional datasets in cancer, especially high-throughput genomics relies on several simplifying assumptions to model the complex structural aspects of the data, which might be unrealistic. We have shown that coherent, flexible and scalable nonparametric technique that adequately borrow strength and account for the complex correlation structures can out-perform existing methods in both clustering and prediction ? two widely applied tools for high-dimensional data analyses.</p>\n<p class=\"Default\">The research work conducted under this proposal has laid groundwork for new nonparametric frameworks for analyzing complex-structured high-dimensional datasets especially in oncology. While specifically motivated by applications in biomedicine and cancer, the formulations of our methods are general enough to be applied to any subject-area domain. In addition, the development of the freely available software to implement these methods has increased the visibility and scope of the applications. We have trained the next generation of quantitative scientists, particularly women, to meet the challenges of interdisciplinary research involving high-dimensional data. Given the broad applicability of the research areas, this will help these individuals to be more competitive in future career opportunities. To benefit the larger scientific community, the research results have been published in peer-reviewed journals for rapid dissemination and application in statistics and medicine, and in other areas where massive datasets are becoming increasingly common.</p>\n<p class=\"Default\"><strong><em>Computation and Software Developments</em></strong></p>\n<p class=\"Default\"><strong><em>&nbsp;</em></strong>Our software contributions include an open-source R packages available in public repositories at https://github.com/suchard-group/NPCluster and https://github.com/sguha-lab. Specifically:</p>\n<ul>\n<li>We have developed high-performance statistical tools and providing software implementations is a major achievement of this project. Along with Marc Suchard, we have implemented the Markov chain Monte Carlo (MCMC) procedure of Guha and Baladandayuthapani (2016). The software is available for general use as an R package called NPCluster. This dramatically speeds up the calculations by multiple orders of magnitude, allowing fully Bayesian inferences of user-specified datasets on ordinary desktop and laptop computers. All code is available in a public repository at https://github.com/suchard-group/NPCluster. </li>\n</ul>\n<ul>\n<li>R code for generating simulated data and fitting the Bayesian Connectomics (BaCon) model class of Guha, Jung and Dunson (2020) is publicly available at https://github.com/sguha-lab/BaCon/ We are currently working on a package that implements the algorithm in C++.</li>\n</ul>\n<ul>\n<li>Code for fitting microbiome datasets using the Bayesian SVD-type decomposition technique of Guha and Datta (2021) is available at https://github.com/sguha-lab/Microbiome-SVD</li>\n</ul>\n<ul>\n<li>Code for implementing the Bayesian technique of Guha and Ghosh (2020) for inferring unknown conic sections on the basis of noisy data is available at https://github.com/sguha-lab/BayesConics</li>\n</ul>\n<ul>\n<li>We have also created, using the R package shiny, an interactive web application (available at https://sites.google.com/site/yangniresearchsite/behavior) to interactively display the varying effects of prognostic proteins of different critical pathways in response to the user?s choice of the desired expressions of their respective encoding genes. This allows our results easily accessible to the broader scientific and research community. </li>\n</ul>\n<p><strong><em>Papers submitted/under review</em></strong></p>\n<p>Three manuscripts are currently under review in high-impact and domain-specific leading journals:</p>\n<ul>\n<li><strong><em>&nbsp;</em></strong>Anyaso-Samuel, S., Sachdeva, A., Guha, S., and Datta, S. (2021) Metagenomic Geolocation Prediction Using an Adaptive Ensemble Classifier.</li>\n</ul>\n<ul>\n<li>Gu, C., Baladandayuthapani, V., and Guha, S.&nbsp; Bayesian Nonparametric Differential Analysis for Dependent Multigroup Data with Application to DNA Methylation Analyses in Cancer. Invited revision by Journal of the American Statistical Association.</li>\n</ul>\n<ul>\n<li>Guha, S., Jung, R. and Dunson, D. Predicting Phenotypes from Brain Connection Structure. Invited revision by Journal of the Royal Statistical Society: Series C.</li>\n</ul><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/04/2021<br>\n\t\t\t\t\tModified by: Subharup&nbsp;Guha</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project has developed versatile and flexible nonparametric statistical techniques for identifying differential genomic signatures in cancer, invented integrative probabilistic frameworks for massive multiple-domain data, fostered massively parallel algorithms and high-performance computational and inferential tools, and trained the next generation of quantitative scientists to meet the challenges of interdisciplinary research involving high-dimensional data.\nMany standard approaches to modeling high-dimensional datasets in cancer, especially high-throughput genomics relies on several simplifying assumptions to model the complex structural aspects of the data, which might be unrealistic. We have shown that coherent, flexible and scalable nonparametric technique that adequately borrow strength and account for the complex correlation structures can out-perform existing methods in both clustering and prediction ? two widely applied tools for high-dimensional data analyses.\nThe research work conducted under this proposal has laid groundwork for new nonparametric frameworks for analyzing complex-structured high-dimensional datasets especially in oncology. While specifically motivated by applications in biomedicine and cancer, the formulations of our methods are general enough to be applied to any subject-area domain. In addition, the development of the freely available software to implement these methods has increased the visibility and scope of the applications. We have trained the next generation of quantitative scientists, particularly women, to meet the challenges of interdisciplinary research involving high-dimensional data. Given the broad applicability of the research areas, this will help these individuals to be more competitive in future career opportunities. To benefit the larger scientific community, the research results have been published in peer-reviewed journals for rapid dissemination and application in statistics and medicine, and in other areas where massive datasets are becoming increasingly common.\nComputation and Software Developments\n Our software contributions include an open-source R packages available in public repositories at https://github.com/suchard-group/NPCluster and https://github.com/sguha-lab. Specifically:\n\nWe have developed high-performance statistical tools and providing software implementations is a major achievement of this project. Along with Marc Suchard, we have implemented the Markov chain Monte Carlo (MCMC) procedure of Guha and Baladandayuthapani (2016). The software is available for general use as an R package called NPCluster. This dramatically speeds up the calculations by multiple orders of magnitude, allowing fully Bayesian inferences of user-specified datasets on ordinary desktop and laptop computers. All code is available in a public repository at https://github.com/suchard-group/NPCluster. \n\n\nR code for generating simulated data and fitting the Bayesian Connectomics (BaCon) model class of Guha, Jung and Dunson (2020) is publicly available at https://github.com/sguha-lab/BaCon/ We are currently working on a package that implements the algorithm in C++.\n\n\nCode for fitting microbiome datasets using the Bayesian SVD-type decomposition technique of Guha and Datta (2021) is available at https://github.com/sguha-lab/Microbiome-SVD\n\n\nCode for implementing the Bayesian technique of Guha and Ghosh (2020) for inferring unknown conic sections on the basis of noisy data is available at https://github.com/sguha-lab/BayesConics\n\n\nWe have also created, using the R package shiny, an interactive web application (available at https://sites.google.com/site/yangniresearchsite/behavior) to interactively display the varying effects of prognostic proteins of different critical pathways in response to the user?s choice of the desired expressions of their respective encoding genes. This allows our results easily accessible to the broader scientific and research community. \n\n\nPapers submitted/under review\n\nThree manuscripts are currently under review in high-impact and domain-specific leading journals:\n\n Anyaso-Samuel, S., Sachdeva, A., Guha, S., and Datta, S. (2021) Metagenomic Geolocation Prediction Using an Adaptive Ensemble Classifier.\n\n\nGu, C., Baladandayuthapani, V., and Guha, S.  Bayesian Nonparametric Differential Analysis for Dependent Multigroup Data with Application to DNA Methylation Analyses in Cancer. Invited revision by Journal of the American Statistical Association.\n\n\nGuha, S., Jung, R. and Dunson, D. Predicting Phenotypes from Brain Connection Structure. Invited revision by Journal of the Royal Statistical Society: Series C.\n\n\n\t\t\t\t\tLast Modified: 01/04/2021\n\n\t\t\t\t\tSubmitted by: Subharup Guha"
 }
}