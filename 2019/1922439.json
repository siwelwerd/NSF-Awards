{
 "awd_id": "1922439",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NCS-FO:  The Neural Basis of Human Spatial Navigation in Large-Scale Virtual Spaces with Vestibular Input",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2018-07-30",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 504390.0,
 "awd_amount": 504390.0,
 "awd_min_amd_letter_date": "2019-02-06",
 "awd_max_amd_letter_date": "2019-02-06",
 "awd_abstract_narration": "How do people learn large-scale spaces, like new towns and cities that they visit, as they navigate? Addressing this question poses surprising obstacles, such as the difficulty in optimizing large-scale spaces for experimental testing and controlling for pre-existing knowledge. Desktop virtual reality offers one possible way to address this question, although such testing offers an incomplete rendition of the full-body, immersive experience that is real-world navigation. Researchers will develop a 2-D treadmill coupled with a head-mounted display to allow free ambulation of large-scale virtual spaces. Successful development of this device has important societal applications. For example, pre-training with enriched body-based cues has the potential to increase knowledge transfer to real world environments, which could be helpful for training individuals such as first-responders and navigation in wilderness environments. Also, the device and proposed experiments will provide a completely novel understanding of the neural basis of human spatial navigation with body-based cues, fundamental to accurately modeling spatial cognition and understanding why we often get lost when we visit new cities.\r\n\r\nAlmost all theories of the neural basis of spatial navigation, largely developed in freely navigating rodents, assume the critical importance of importance of body-based cues to this code. Yet the vast majority of studies in humans involve navigation in desktop virtual reality. The novel device that will be developed will permit 2-D locomotion-based VR navigation, allowing a full range of body/head rotations and ambulation. The experiments will determine 1) the contributions of body-based input to human spatial navigation and how navigation in VR with body-based can enhance subsequent knowledge of real world environments 2) how the brain codes spatial distance by employing simultaneous EEG recordings 3) how the brain codes the relative directions of landmarks in the environment by modeling the underlying multidimensional brain networks using high-resolution functional magnetic imaging (fMRI). The outcomes from these experiments will be important to testing models of spatial navigation and advancing our understanding of the extent to which we employ visual vs. body-based cues to represent spatial environments, currently an issue of significant debate in the field.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Arne",
   "pi_last_name": "Ekstrom",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Arne Ekstrom",
   "pi_email_addr": "adekstrom@email.arizona.edu",
   "nsf_id": "000628782",
   "pi_start_date": "2019-02-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Arizona",
  "inst_street_address": "845 N PARK AVE RM 538",
  "inst_street_address_2": "",
  "inst_city_name": "TUCSON",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "5206266000",
  "inst_zip_code": "85721",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "AZ07",
  "org_lgl_bus_name": "UNIVERSITY OF ARIZONA",
  "org_prnt_uei_num": "",
  "org_uei_num": "ED44Y3W6P7B9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Arizona",
  "perf_str_addr": "888 N Euclid Ave",
  "perf_city_name": "Tucson",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "857194824",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "AZ07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "798000",
   "pgm_ele_name": "ECR-EDU Core Research"
  },
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "8551",
   "pgm_ref_txt": "IntgStrat Undst Neurl&Cogn Sys"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0416",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001617DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 504389.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Navigation critically involves what we see and how we move our body to understand where we are going.&nbsp; Yet, much of the research in human spatial navigation has employed desktop virtual reality, which does not permit free movement of the body.&nbsp; In this proposal, we developed&nbsp; novel technology, including an omnidirectional treadmill and wireless, untethered navigation using a head-mounted display, to test novel hypotheses about how we navigate.&nbsp; The proposal also involved building novel software and brain recording technology to record wireless while people navigate.&nbsp; The funding resulted in a total of 18 different papers total on this and related topics, some of which have had a high impact on current research on the field.&nbsp; One particular finding that we think has been influential is our demonstration that movement-related cues matter under some conditions (for example, when first learning an environment) but not others (when an environment is well learned).&nbsp; This suggest that immersive technology may be helpful for novel learning situations but less so when an environment can be well learned or has already been experienced.&nbsp; We also report brain signals related to navigating with our body, including novel neural signatures that track distance.&nbsp; We have also worked with both industry and academic partners to share our novel hardware and software, and found significant interest and efforts amongst others to adopt the technology developed from this funding.&nbsp;&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/02/2021<br>\n\t\t\t\t\tModified by: Arne&nbsp;Ekstrom</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nNavigation critically involves what we see and how we move our body to understand where we are going.  Yet, much of the research in human spatial navigation has employed desktop virtual reality, which does not permit free movement of the body.  In this proposal, we developed  novel technology, including an omnidirectional treadmill and wireless, untethered navigation using a head-mounted display, to test novel hypotheses about how we navigate.  The proposal also involved building novel software and brain recording technology to record wireless while people navigate.  The funding resulted in a total of 18 different papers total on this and related topics, some of which have had a high impact on current research on the field.  One particular finding that we think has been influential is our demonstration that movement-related cues matter under some conditions (for example, when first learning an environment) but not others (when an environment is well learned).  This suggest that immersive technology may be helpful for novel learning situations but less so when an environment can be well learned or has already been experienced.  We also report brain signals related to navigating with our body, including novel neural signatures that track distance.  We have also worked with both industry and academic partners to share our novel hardware and software, and found significant interest and efforts amongst others to adopt the technology developed from this funding.  \n\n \n\n\t\t\t\t\tLast Modified: 12/02/2021\n\n\t\t\t\t\tSubmitted by: Arne Ekstrom"
 }
}