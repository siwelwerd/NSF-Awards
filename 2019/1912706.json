{
 "awd_id": "1912706",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Fast and Robust Algorithms for Signal Recovery from Underdetermined Measurements:  Generalized Sparse Fourier Transforms, Inverse Problems, and Density Estimation",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922113",
 "po_email": "ygorb@nsf.gov",
 "po_sign_block_name": "Yuliya Gorb",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2019-05-30",
 "awd_max_amd_letter_date": "2019-05-30",
 "awd_abstract_narration": "This project aims to develop computational methods capable of quickly generating best-possible simple solutions for several difficult computational problems of wide interest.  As an example, the developed computational methods will include an algorithm for rapidly finding the best possible simple approximation of a given function of many variables from just a few function evaluations.  If, e.g., the function one cares about is the probability of having an extreme rain event in Florida in two weeks as a function of current ocean temperatures, wind speeds, atmospheric pressures, etc. then such a method could help to provide a generic framework for quickly building up simple models to help predict such extreme rain events based on a reduced number of costly weather observations and climate simulations.  A second example of the numerical methods to be developed as part of this project include provably accurate methods for producing correct pictures of, e.g., microscopic material features from realistic ptychographic imaging data.  Such methods can help guarantee that the images one can obtain using well-planned ptychographic scans of microscopic object features (that are too small to see with the naked eye) actually look like the true object one scanned as opposed to, e.g., a distorted, fake, or even disguised version of the true object which just so happens to produce similar scan results.  \r\n\r\n\r\nMore generally, this project will develop fast computational methods, supported by rigorous theoretical guarantees, for several problems that involve learning extremely large and high dimensional signals from severely underdetermined measurements. The developed numerical methods will include: (i) improved and generalized sublinear-time Sparse Fourier Transform (SFT) algorithms capable of rapidly approximating any function of many variables that exhibits sparsity in any given bounded orthonormal product basis, (ii) FFT-time and provably accurate lifted phase retrieval algorithms for approximately recovering compactly supported functions (up to a global phase factor) from their spectrogram measurements as well as new and even faster SFT-based compressive phase retrieval methods which run in only sublinear-time, and (iii) the development of new, fast, low-memory, and highly-parallel distributed density estimation algorithms for large multimodal datasets and tensors. A common difficulty in developing all three sets of algorithms for the problems above stems from the shear size of the memory and/or processing power required by their standard solution approaches, which limits both their applicability as well as one's ability to obtain fully determined sets of signal measurements for their use in many settings. In all three cases, new and computationally tractable algorithms will be developed that take advantage of hidden simplifying structure in each application above (e.g., generalized Fourier sparsity in the first case, intrinsically low rank data in the second case, and intrinsic low-dimensional geometric structure in the third) thereby providing numerical approaches capable of solving several types of large problems whose numerical solution currently lies beyond our collective capabilities.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Iwen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mark Iwen",
   "pi_email_addr": "markiwen@math.msu.edu",
   "nsf_id": "000605848",
   "pi_start_date": "2019-05-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Michigan State University",
  "inst_street_address": "426 AUDITORIUM RD RM 2",
  "inst_street_address_2": "",
  "inst_city_name": "EAST LANSING",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "5173555040",
  "inst_zip_code": "488242600",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MI07",
  "org_lgl_bus_name": "MICHIGAN STATE UNIVERSITY",
  "org_prnt_uei_num": "VJKZC4D1JN36",
  "org_uei_num": "R28EKN92ZTZ9"
 },
 "perf_inst": {
  "perf_inst_name": "Michigan State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "488242600",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MI07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Compressive sensing has generated tremendous amounts of interest since first being proposed almost two decades ago. &nbsp;This mathematical framework has its origins in (i) the observation that traditional signal processing applications, such as MRI imaging problems, often deal with the acquisition of signals which are known a priori to be sparse in some basis, as well as (ii) the subsequent realization that this knowledge could in fact be used to help streamline the signal acquisition process in the first place (by taking the bare minimum of signal measurements necessary in order to discover and then reconstruct the important basis coefficients only). &nbsp;The resulting mathematical theory has since led to dramatic reductions in measurement needs over traditional approaches in many situations where one would previously have reconstructed a fuller set of a given signal's basis coefficients only to later discard most of them as insignificant.</p>\n<p>Though extremely successful at reducing the number of measurements needed in order to reconstruct a given signal, most standard compressive sensing recovery algorithms still individually represent every basis function during the signal's numerical reconstruction. &nbsp;This leads one to ask a computationally oriented variant of the original question which led to the development of compressive sensing in the first place: &nbsp;why should one consider all possible basis coefficients individually during the numerical reconstruction of a given signal when one knows in advance that only a few of them will end up being significant? &nbsp;In fact, it turns out that one often does not have to explicitly consider each basis function individually during the reconstruction process, and so can reduce both the measurement needs *and* computational complexity of signal reconstruction to depend on the bare minimum of signal measurements necessary in order to reconstruct the important basis coefficients in many settings. &nbsp;This award developed several sublinear-time numerical methods which do exactly this for functions that are sparse in various orthonormal bases.</p>\n<p><em>More specifically, this award developed fast computational methods, supported by rigorous theoretical guarantees, for several problems that involve learning extremely large and high dimensional signals from&nbsp;</em><em>severely underdetermined measurements. The developed numerical methods include: (i) improved and generalized sublinear-time Sparse Fourier Transform (SFT) algorithms capable of rapidly&nbsp;</em><em>approximating any function of many variables that exhibits sparsity in any given bounded orthonormal product basis, (ii) nearly FFT-time and provably accurate lifted phase retrieval algorithms for&nbsp;</em><em>approximately recovering compactly supported L</em><em>2</em><em>- functions (up to a global phase factor) from their spectrogram measurements</em><em>, and (iii) the development of new, fast, embedding algorithms for reducing the size of huge datasets and tensors afterwhich faster processing can take place. &nbsp;</em></p>\n<p>To highlight the implications of just one of these developed fast computational methods in more detail, let us focus briefly on the develeped SFT methods mentioned above. &nbsp;In his monograph ``Chebyshev and Fourier Spectral Methods\", John Boyd claimed that, regarding Fourier spectral methods for solving differential equations, &ldquo;[t]he virtues of the Fast Fourier Transform will continue to improve as the relentless march to larger and larger [bandwidths] continues&rdquo; [pg. 194]. Instead of using a traditional FFT however, one may now use a sparse Fourier transform (SFT) algorithm to solve Partial Differential Equations (PDEs). &nbsp;The resulting sparse spectral methods rapidly and automatically determine a set of Fourier basis functions whose span is guaranteed to contain an accurate approximation of the solution of a given PDE. This much smaller, near-optimal Fourier basis can then used to efficiently solve the given PDE in a runtime which only depends on the PDE&rsquo;s data/solution compressibility and ellipticity properties, while breaking the curse of dimensionality and relieving linear dependence on any multiscale structure in the original problem. &nbsp;Given the extreme importance of PDE models in, e.g., physical modeling, the fast methods resulting from this award therefore open up the possibility of potentially tackeling larger and higher-dimensional modeling tasks that previously possible.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/24/2023<br>\n\t\t\t\t\tModified by: Mark&nbsp;Iwen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nCompressive sensing has generated tremendous amounts of interest since first being proposed almost two decades ago.  This mathematical framework has its origins in (i) the observation that traditional signal processing applications, such as MRI imaging problems, often deal with the acquisition of signals which are known a priori to be sparse in some basis, as well as (ii) the subsequent realization that this knowledge could in fact be used to help streamline the signal acquisition process in the first place (by taking the bare minimum of signal measurements necessary in order to discover and then reconstruct the important basis coefficients only).  The resulting mathematical theory has since led to dramatic reductions in measurement needs over traditional approaches in many situations where one would previously have reconstructed a fuller set of a given signal's basis coefficients only to later discard most of them as insignificant.\n\nThough extremely successful at reducing the number of measurements needed in order to reconstruct a given signal, most standard compressive sensing recovery algorithms still individually represent every basis function during the signal's numerical reconstruction.  This leads one to ask a computationally oriented variant of the original question which led to the development of compressive sensing in the first place:  why should one consider all possible basis coefficients individually during the numerical reconstruction of a given signal when one knows in advance that only a few of them will end up being significant?  In fact, it turns out that one often does not have to explicitly consider each basis function individually during the reconstruction process, and so can reduce both the measurement needs *and* computational complexity of signal reconstruction to depend on the bare minimum of signal measurements necessary in order to reconstruct the important basis coefficients in many settings.  This award developed several sublinear-time numerical methods which do exactly this for functions that are sparse in various orthonormal bases.\n\nMore specifically, this award developed fast computational methods, supported by rigorous theoretical guarantees, for several problems that involve learning extremely large and high dimensional signals from severely underdetermined measurements. The developed numerical methods include: (i) improved and generalized sublinear-time Sparse Fourier Transform (SFT) algorithms capable of rapidly approximating any function of many variables that exhibits sparsity in any given bounded orthonormal product basis, (ii) nearly FFT-time and provably accurate lifted phase retrieval algorithms for approximately recovering compactly supported L2- functions (up to a global phase factor) from their spectrogram measurements, and (iii) the development of new, fast, embedding algorithms for reducing the size of huge datasets and tensors afterwhich faster processing can take place.  \n\nTo highlight the implications of just one of these developed fast computational methods in more detail, let us focus briefly on the develeped SFT methods mentioned above.  In his monograph ``Chebyshev and Fourier Spectral Methods\", John Boyd claimed that, regarding Fourier spectral methods for solving differential equations, \"[t]he virtues of the Fast Fourier Transform will continue to improve as the relentless march to larger and larger [bandwidths] continues\" [pg. 194]. Instead of using a traditional FFT however, one may now use a sparse Fourier transform (SFT) algorithm to solve Partial Differential Equations (PDEs).  The resulting sparse spectral methods rapidly and automatically determine a set of Fourier basis functions whose span is guaranteed to contain an accurate approximation of the solution of a given PDE. This much smaller, near-optimal Fourier basis can then used to efficiently solve the given PDE in a runtime which only depends on the PDE\u2019s data/solution compressibility and ellipticity properties, while breaking the curse of dimensionality and relieving linear dependence on any multiscale structure in the original problem.  Given the extreme importance of PDE models in, e.g., physical modeling, the fast methods resulting from this award therefore open up the possibility of potentially tackeling larger and higher-dimensional modeling tasks that previously possible.\n\n \n\n\t\t\t\t\tLast Modified: 07/24/2023\n\n\t\t\t\t\tSubmitted by: Mark Iwen"
 }
}