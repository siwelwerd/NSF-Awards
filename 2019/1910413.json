{
 "awd_id": "1910413",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Architectural Support for Securing Deep Neural Networks",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 499972.0,
 "awd_amount": 499972.0,
 "awd_min_amd_letter_date": "2019-07-23",
 "awd_max_amd_letter_date": "2023-09-21",
 "awd_abstract_narration": "Machine learning algorithms based on deep neural networks have achieved remarkable results in a variety of domains such as spam detection, traffic analysis, intrusion detection, medical predictions, and financial predictions. Neural network (NN) driven technologies such as image/voice recognition and personal assistance apps have greatly improved the quality of life and have become utilities people rely on everyday. NN-based machine learning algorithms are often hosted on cloud servers as a service provided to users, which concerns their security, that is, how to protect user private data from hackers as well as trusted-yet-curious servers; how to protect model piracy and enforce intellectual property (IP) protection. Adopting traditional encryption based defenses tends to introduce severe performance degradation to the system. This project addresses these issues and thus help increase the use of accelerator architectures for machine learning in the computing cloud and mobile clients. It assures the IP of users are securely protected. The work integrates research with high education with curricular innovation at both the undergraduate and graduate levels and with outreach to under-represented groups and K-12 education.  \r\n\r\nThis project develops a secure, privacy-preserving and confidential and tamper-proofing environment for users to acquire services from the cloud. It focuses on three tasks. 1) IP protection via user dependent modeling: lightweight training and inference methodologies are developed to produce models that can only execute on legitimate IP owners. Such dependency can be derived from either target hardware or a secret shared among IP owners. 2) Data privacy protection: acceleration techniques are developed for a privacy-preserving cryptographic homomorphic encryption (HE) which runs NN on encrypted data but could slow down an inference by several orders of magnitude. HE is analyzed, the most suitable accelerator is selected and optimized mapping of HE onto the accelerator is developed to maximize its performance. 3) Protection for confidentiality and integrity of NN, and defend side-channel attacks: protect dynamic execution of NNs by adding memory encryption, authentication, bus protection and isolation to defend sophisticated attacks targeted at the accelerator hardware. The proposed designs in this project exploit uniqueness of NN and achieve minimum impact on performance.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Youtao",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Youtao Zhang",
   "pi_email_addr": "zhangyt@cs.pitt.edu",
   "nsf_id": "000104863",
   "pi_start_date": "2019-07-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jun",
   "pi_last_name": "Yang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jun Yang",
   "pi_email_addr": "juy9@pitt.edu",
   "nsf_id": "000106419",
   "pi_start_date": "2019-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pittsburgh",
  "inst_street_address": "4200 FIFTH AVENUE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4126247400",
  "inst_zip_code": "152600001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "UNIVERSITY OF PITTSBURGH - OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "MKAGLD59JRL1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pittsburgh",
  "perf_str_addr": "University Club",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152132303",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 499972.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Modern Neural Network (NN) based machine learning models have achieved significant successes in many application domains, e.g., computer vision, speech recognition, disease diagnosis systems, and many others. NNs training and inference often demand a pool of high-end GPUs and/or customized accelerators for higher performance and throughput, which are enabled using cloud servers in data centers. Unfortunately, there is an increasing concern of security concerns of the cloud server based NN deployment. Cloud servers may be trusted-yet-curious, meaning they will providecomputing services for the customers, but will also peek into the data for their own purposes. There is noguarantee of data privacy for the customers. In a different scenario, a trained NN model contains valuableintellectual property of the customer who provided large amount of proprietary data and paid for thetraining services from a cloud.</p>\r\n<p>To enable the IP protection of ML models, we developed a secure CNN accelerator that exploits stochastic computing to achieve IP protection for both training and inference phases. Our design, termed SCA, is the first work that uses hardware fingerprints for model protection. SCA uses eDRAM refresh errors as hardware fingerprint to generate bit streams for stochastic computing conversion. We develop a remapping technique to insert 0&rsquo;s or 1&rsquo;s to different part of the bit stream to prevent the stochastic format weights get closer to their binary values. Further, we developed a hybrid addition method to avoid memory footprint bloat caused by long stochastic bit streams.</p>\r\n<p>To enhance the IP protection of DNN models, we developed a secure ReRAM-based DNN accelerator that stores DNN weights on crossbars in an encrypted format while still maintaining ReRAM's in-memory computing capability. The proposed encryption scheme also supports sharing bits among multiple weights, significantly reducing the storage overhead. In addition, SRA uses a novel high-bandwidth SC conversion scheme to protect each layer's intermediate results, which also contain sensitive information of the model.</p>\r\n<p>To address the security vulnerability of an attention-based AI model, vision transformer (VIT), we systematically study the attention-based patch attack. We experimentally observe that adversarial patches only activate in a few layers and become lazy during attention updating.&nbsp; We then study how a small adversarial patch perturbates the whole model. Based on the understanding of the adversarial patch attacks, we propose AbnoRmality-Masking RObust (ARMRO), a simple but efficient defense, that can effectively detect patch-based adversarial attacks. We divide this process into three stages: the inactivate stage; the activate stage, where the score of the adversarial token becomes the most salient; the polluted stage, where vast noise keys and queries gather closely and dominate the attention.&nbsp; We focus on detecting the position of adversarial patches in the activate stage and masks them from the input.&nbsp;</p>\r\n<p>To address the performance overhead of tag/version-ID based UAF (use-after-free) detectors, we introduced RTT, which leverages the concept of the binning allocator to divide the heap into a user-defined number of equally sized bins. Such a design helps to achieve (1) a limited number of possible starting (base) addresses; 2) encoding the starting address into the pointer value itself. Thus RTT can reduce the version ID to 16 bit, store it in the unused bits of a 64-bit pointer, and thus allow data propogation naturally with mitigated performance overhead.</p><br>\n<p>\n Last Modified: 02/12/2025<br>\nModified by: Youtao&nbsp;Zhang</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nModern Neural Network (NN) based machine learning models have achieved significant successes in many application domains, e.g., computer vision, speech recognition, disease diagnosis systems, and many others. NNs training and inference often demand a pool of high-end GPUs and/or customized accelerators for higher performance and throughput, which are enabled using cloud servers in data centers. Unfortunately, there is an increasing concern of security concerns of the cloud server based NN deployment. Cloud servers may be trusted-yet-curious, meaning they will providecomputing services for the customers, but will also peek into the data for their own purposes. There is noguarantee of data privacy for the customers. In a different scenario, a trained NN model contains valuableintellectual property of the customer who provided large amount of proprietary data and paid for thetraining services from a cloud.\r\n\n\nTo enable the IP protection of ML models, we developed a secure CNN accelerator that exploits stochastic computing to achieve IP protection for both training and inference phases. Our design, termed SCA, is the first work that uses hardware fingerprints for model protection. SCA uses eDRAM refresh errors as hardware fingerprint to generate bit streams for stochastic computing conversion. We develop a remapping technique to insert 0s or 1s to different part of the bit stream to prevent the stochastic format weights get closer to their binary values. Further, we developed a hybrid addition method to avoid memory footprint bloat caused by long stochastic bit streams.\r\n\n\nTo enhance the IP protection of DNN models, we developed a secure ReRAM-based DNN accelerator that stores DNN weights on crossbars in an encrypted format while still maintaining ReRAM's in-memory computing capability. The proposed encryption scheme also supports sharing bits among multiple weights, significantly reducing the storage overhead. In addition, SRA uses a novel high-bandwidth SC conversion scheme to protect each layer's intermediate results, which also contain sensitive information of the model.\r\n\n\nTo address the security vulnerability of an attention-based AI model, vision transformer (VIT), we systematically study the attention-based patch attack. We experimentally observe that adversarial patches only activate in a few layers and become lazy during attention updating. We then study how a small adversarial patch perturbates the whole model. Based on the understanding of the adversarial patch attacks, we propose AbnoRmality-Masking RObust (ARMRO), a simple but efficient defense, that can effectively detect patch-based adversarial attacks. We divide this process into three stages: the inactivate stage; the activate stage, where the score of the adversarial token becomes the most salient; the polluted stage, where vast noise keys and queries gather closely and dominate the attention. We focus on detecting the position of adversarial patches in the activate stage and masks them from the input.\r\n\n\nTo address the performance overhead of tag/version-ID based UAF (use-after-free) detectors, we introduced RTT, which leverages the concept of the binning allocator to divide the heap into a user-defined number of equally sized bins. Such a design helps to achieve (1) a limited number of possible starting (base) addresses; 2) encoding the starting address into the pointer value itself. Thus RTT can reduce the version ID to 16 bit, store it in the unused bits of a 64-bit pointer, and thus allow data propogation naturally with mitigated performance overhead.\t\t\t\t\tLast Modified: 02/12/2025\n\n\t\t\t\t\tSubmitted by: YoutaoZhang\n"
 }
}