{
 "awd_id": "1845852",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Information-Theoretic Foundations of Fairness in Machine Learning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032920000",
 "po_email": "ahero@nsf.gov",
 "po_sign_block_name": "Alfred Hero",
 "awd_eff_date": "2019-02-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 547900.0,
 "awd_amount": 547900.0,
 "awd_min_amd_letter_date": "2018-12-07",
 "awd_max_amd_letter_date": "2021-08-19",
 "awd_abstract_narration": "Machine learning algorithms can identify complex patterns in very large datasets. These algorithms are increasingly used in applications of significant social consequence, such as loan approval, hiring, and bail and sentencing decisions. However, real-world data may reflect discrimination patterns that exist in society at large. Consequently, decisions based on algorithms that learn from data are at risk of inheriting and, ultimately, reinforcing discriminatory and unfair social biases. This project aims to precisely characterize the operational limits of discrimination discovery and control in machine learning by combining legal and social science definitions of fairness with powerful mathematical tools from information theory, statistics, and optimization. This cross-disciplinary effort aims to provide fundamental theory and design guidelines for data scientists and engineers who will create the next generation of fair data-driven algorithms and applications. The technical results of this project will also inform the debate surrounding the social impact of machine learning. Moreover, this research will be used as a vessel for engaging students and researchers from diverse backgrounds in the applicability of information theory, machine learning, optimization, and, more broadly, math and engineering to social challenges.\r\n\r\nAutomated methods for discovering and controlling discrimination in machine learning inherently face a trade-off between fairness and accuracy, and are limited by the dimensionality of the underlying data. This project creates a comprehensive information-theoretic framework that captures the limits of discrimination control by determining (i) how to systematically identify data features that may lead to discrimination; (ii) how to ensure fairness by producing new, information-theoretically grounded data representations; (iii) the fundamental information-theoretic trade-offs between fairness, distortion, and accuracy; and (iv) the impact of finite samples in discrimination detection and mitigation. The key advantage of the information-theoretic methodology adopted in this project is that it captures fundamental, algorithm-independent properties of discrimination, while being fertile ground for the development of novel mathematical tools and models relevant to both data scientists and information theorists. The theoretical component of this research weaves new connections between information theory and robust statistics by analyzing the impact of local perturbations of probability distributions on discrimination metrics, and creates new information-theoretic models useful in discrimination control, privacy, and representation learning. The applied component of this research develops robust, data-driven methods for measuring and mitigating discrimination that are immediately relevant for fair algorithmic decision-making in applications of consequence.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Flavio",
   "pi_last_name": "Calmon",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Flavio Calmon",
   "pi_email_addr": "flavio@seas.harvard.edu",
   "nsf_id": "000733796",
   "pi_start_date": "2018-12-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University",
  "perf_str_addr": "33 Oxford Street",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021382933",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0123",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 106915.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 100698.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 340287.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-5df68081-7fff-ec15-7d82-bdda4fa716f7\"> </span></p>\r\n<p dir=\"ltr\"><span>This CAREER project developed the information-theoretic foundations of algorithmic fairness. Machine learning and artificial intelligence algorithms are increasingly used in applications with individual-level consequences. Even though these algorithms can be very precise on average, they can display disparate performance across different users and population groups. The disparate impact of machine learning algorithms has been documented in applications ranging from facial recognition to healthcare.&nbsp;</span></p>\r\n<p dir=\"ltr\"><span>This project used tools from information theory to delineate fundamental limits and develop practical algorithms for discovering and controlling biases and performance disparities in machine learning. Information theory, in turn, has historically provided mathematical foundations for digital communications and data storage systems. This research extended the field of information theory to tackle emerging challenges in fair machine learning and artificial intelligence.&nbsp;&nbsp;</span></p>\r\n<p dir=\"ltr\"><span>The project led to several discoveries and state-of-the-art algorithms that can inform the design of more accurate and reliable machine learning systems. It established fundamental sample complexity bounds for bias detection in prediction and classification tasks across demographic groups. It also characterized the theoretically optimal Pareto frontier between several fairness and accuracy metrics. The research developed state-of-the-art algorithms that approach this Pareto frontier in multi-class classification and prediction tasks. The project also demonstrated that models with equivalent accuracy can produce conflicting predictions on individual samples -- a phenomenon named 'predictive multiplicity.' The award resulted in several new methods for discovering, measuring, and mitigating predictive multiplicity. Another notable outcome was the creation of metrics and methods for ensuring proportional and accurate representation in image retrieval and generation tasks.</span></p>\r\n<p dir=\"ltr\"><span>The award provided significant educational and training opportunities in information theory, machine learning, and artificial intelligence for a generation of students. Research findings were integrated into undergraduate and graduate information theory and signal processing courses at Harvard University. The work supported by this project involved multiple PhD students, postdoctoral fellows, and undergraduate researchers who have joined the American workforce in positions at academia and industry research labs.</span></p>\r\n<div><span><br /></span></div>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/26/2025<br>\nModified by: Flavio&nbsp;Calmon</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \r\n\n\nThis CAREER project developed the information-theoretic foundations of algorithmic fairness. Machine learning and artificial intelligence algorithms are increasingly used in applications with individual-level consequences. Even though these algorithms can be very precise on average, they can display disparate performance across different users and population groups. The disparate impact of machine learning algorithms has been documented in applications ranging from facial recognition to healthcare.\r\n\n\nThis project used tools from information theory to delineate fundamental limits and develop practical algorithms for discovering and controlling biases and performance disparities in machine learning. Information theory, in turn, has historically provided mathematical foundations for digital communications and data storage systems. This research extended the field of information theory to tackle emerging challenges in fair machine learning and artificial intelligence.\r\n\n\nThe project led to several discoveries and state-of-the-art algorithms that can inform the design of more accurate and reliable machine learning systems. It established fundamental sample complexity bounds for bias detection in prediction and classification tasks across demographic groups. It also characterized the theoretically optimal Pareto frontier between several fairness and accuracy metrics. The research developed state-of-the-art algorithms that approach this Pareto frontier in multi-class classification and prediction tasks. The project also demonstrated that models with equivalent accuracy can produce conflicting predictions on individual samples -- a phenomenon named 'predictive multiplicity.' The award resulted in several new methods for discovering, measuring, and mitigating predictive multiplicity. Another notable outcome was the creation of metrics and methods for ensuring proportional and accurate representation in image retrieval and generation tasks.\r\n\n\nThe award provided significant educational and training opportunities in information theory, machine learning, and artificial intelligence for a generation of students. Research findings were integrated into undergraduate and graduate information theory and signal processing courses at Harvard University. The work supported by this project involved multiple PhD students, postdoctoral fellows, and undergraduate researchers who have joined the American workforce in positions at academia and industry research labs.\r\n\n\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 01/26/2025\n\n\t\t\t\t\tSubmitted by: FlavioCalmon\n"
 }
}