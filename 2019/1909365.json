{
 "awd_id": "1909365",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: AF: Small: Optimizing probabilities for learning: sampling meets optimization",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2019-07-23",
 "awd_max_amd_letter_date": "2022-05-25",
 "awd_abstract_narration": "Methods for large-scale machine learning and artificial intelligence (AI) have had major impacts on the world over the past decade, including in both industrial and scientific contexts.  These spectacular successes are driven by a combination of the availability of massive datasets, and appropriate models and algorithms for extracting useful information and insights from these datasets.  This research project aims to advance the methodology and understanding of algorithms for large-scale machine learning and AI by exploiting the interplay between sampling and optimization. In particular, two grand challenges are addressed: first, the tools and insights of optimization theory can develop more effective design and analysis techniques for sampling methods; second, these techniques can be used to design and analyze optimization methods for problems such as those that arise in deep learning.  Successful research outcomes of this project are likely to increase the understanding of methods used for sampling and for optimization, and to facilitate their principled design. Successful outcomes have a significant potential for practical impact in the large and growing set of applications where large-scale sampling and optimization methods are used, including computer vision, speech recognition, and self-driving cars.  The research will support the development of graduate students, will be disseminated through large graduate courses at Berkeley and their web-based course materials, and has the potential to benefit the broader community through the application of the methods studied in deployed AI systems.\r\n\r\nThe project has three main technical directions. First, it aims to identify the inherent difficulty of sampling problems by proving lower bounds.  Second, it aims to produce analysis tools and design methodologies for sampling algorithms based on a certain family of stochastic differential equations known as a Langevin diffusion. This will enable the development of sampling algorithms with performance guarantees.  Third, it will use the viewpoint of sampling techniques to analyze and design stochastic gradient methods for nonconvex optimization problems, such as the optimization of parameters in deep neural networks. An additional outcome of the project will be the organization of a workshop on the topic of the interface between sampling and optimization.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Bartlett",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Peter Bartlett",
   "pi_email_addr": "bartlett@stat.berkeley.edu",
   "nsf_id": "000489454",
   "pi_start_date": "2022-05-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Martin",
   "pi_last_name": "Wainwright",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Martin Wainwright",
   "pi_email_addr": "wainwrigwork@gmail.com",
   "nsf_id": "000060031",
   "pi_start_date": "2019-07-23",
   "pi_end_date": "2022-05-25"
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Bartlett",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Peter Bartlett",
   "pi_email_addr": "bartlett@stat.berkeley.edu",
   "nsf_id": "000489454",
   "pi_start_date": "2019-07-23",
   "pi_end_date": "2022-05-25"
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947045940",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 144834.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 305166.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Efficient algorithms for optimization (finding the best solution from a set of feasible solutions) and for sampling (generating data that has a desired distribution) are crucial components of large machine learning and AI systems. This project explored the connections between sampling and optimization, identifying how the two areas can contribute to each other.<br />The results and findings of the project have led to the development of new algorithms for sampling from high dimensional distributions, along with theoretical guarantees on their performance, practical guidance on their use, and fundamental understanding about their limitations.<br />Sampling from high-dimensional distributions is a core problem that has applications across a wide variety of disciplines in the physical sciences, biological sciences and social sciences.&nbsp; We anticipate that our algorithms and theory will provide useful guidance to practitioners in these fields.<br />The grant has been used to support the training of graduate students and postdoctoral fellows, who have gone on to tenure track faculty positions and will contribute to the technical expertise of the US in the STEM fields broadly.&nbsp; It facilitated collaborative research programs and workshops that involved multiple graduate students, postdocs and junior researchers.&nbsp; These included many tutorial lectures, archived on the web, which provide a snapshot of the state of the sampling and optimization area.&nbsp;</p><br>\n<p>\n Last Modified: 05/07/2024<br>\nModified by: Peter&nbsp;Bartlett</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nEfficient algorithms for optimization (finding the best solution from a set of feasible solutions) and for sampling (generating data that has a desired distribution) are crucial components of large machine learning and AI systems. This project explored the connections between sampling and optimization, identifying how the two areas can contribute to each other.\nThe results and findings of the project have led to the development of new algorithms for sampling from high dimensional distributions, along with theoretical guarantees on their performance, practical guidance on their use, and fundamental understanding about their limitations.\nSampling from high-dimensional distributions is a core problem that has applications across a wide variety of disciplines in the physical sciences, biological sciences and social sciences. We anticipate that our algorithms and theory will provide useful guidance to practitioners in these fields.\nThe grant has been used to support the training of graduate students and postdoctoral fellows, who have gone on to tenure track faculty positions and will contribute to the technical expertise of the US in the STEM fields broadly. It facilitated collaborative research programs and workshops that involved multiple graduate students, postdocs and junior researchers. These included many tutorial lectures, archived on the web, which provide a snapshot of the state of the sampling and optimization area.\t\t\t\t\tLast Modified: 05/07/2024\n\n\t\t\t\t\tSubmitted by: PeterBartlett\n"
 }
}