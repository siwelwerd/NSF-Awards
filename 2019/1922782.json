{
 "awd_id": "1922782",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SCC: Video Based Machine Learning for Smart Traffic Analysis and Management",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032920000",
 "po_email": "vsharma@nsf.gov",
 "po_sign_block_name": "Vishal Sharma",
 "awd_eff_date": "2019-05-01",
 "awd_exp_date": "2024-04-30",
 "tot_intn_awd_amt": 1999770.0,
 "awd_amount": 1999770.0,
 "awd_min_amd_letter_date": "2019-04-30",
 "awd_max_amd_letter_date": "2023-11-10",
 "awd_abstract_narration": "The goal of this project is to further the ability of cities and communities to deploy technology that saves lives through safer transportation systems. The approach is to create open source analytics solutions to enable novel transportation applications that utilize data from low-cost video sensors. Video data are processed using edge computing (inexpensive computing hardware that performs analysis without storing significant amounts of data) in order to reduce the amount of data stored. Social dimensions of the research project emerge from the deep research partnership between the City and the University, with the goal to provide replicable and near-term social impacts. The project aligns with the Vision Zero concept to reduce traffic fatalities, with programs that are based on education, enforcement and design. By understanding the risk profile of an intersection through automated detection of near miss events, communities will be able to proactively design and alter streets and intersections to be safer. \r\n\r\nThe goal of designing a smart city, when addressing the technical challenges at the intersection, street and system levels, has several research components. (i) Development of new algorithms for multi-target tracking: The problems of occlusion, temporal assignment of features to objects and target motion will be jointly formulated. (ii) Integrated optimization and simulation for signal control: We formulate the problem of estimating signal control parameters (offsets, phasing etc.) in a network as one of global optimization. (iii) Real-time reinforcement learning is a natural choice when online machine learning meets real world feedback from the City. Our ability to obtain and analyze continuous-time data at the network level will provide insights on how conflict points and patterns can change through the network. This is expected to impact decisions in traffic management, smart city planning and safety.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanjay",
   "pi_last_name": "Ranka",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sanjay Ranka",
   "pi_email_addr": "ranka@cise.ufl.edu",
   "nsf_id": "000381796",
   "pi_start_date": "2019-04-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Anand",
   "pi_last_name": "Rangarajan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anand Rangarajan",
   "pi_email_addr": "anand@cise.ufl.edu",
   "nsf_id": "000438535",
   "pi_start_date": "2019-04-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sivaramakrishna",
   "pi_last_name": "Srinivasan",
   "pi_mid_init": "",
   "pi_sufx_name": "PhD",
   "pi_full_name": "Sivaramakrishna Srinivasan",
   "pi_email_addr": "siva@ce.ufl.edu",
   "nsf_id": "000506446",
   "pi_start_date": "2019-04-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Lily-Ageliki",
   "pi_last_name": "Elefteriadou",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lily-Ageliki Elefteriadou",
   "pi_email_addr": "elefter@ce.ufl.edu",
   "nsf_id": "000671335",
   "pi_start_date": "2019-04-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Hoffman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel Hoffman",
   "pi_email_addr": "hoffmandc@cityofgainesville.org",
   "nsf_id": "000771179",
   "pi_start_date": "2019-04-30",
   "pi_end_date": "2021-09-02"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Emmanuel",
   "pi_last_name": "Posadas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Emmanuel Posadas",
   "pi_email_addr": "posadasep@cityofgainesville.org",
   "nsf_id": "000771177",
   "pi_start_date": "2023-11-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Malisa",
   "pi_last_name": "Mccreedy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Malisa Mccreedy",
   "pi_email_addr": "mccreedyma@cityofgainesville.org",
   "nsf_id": "000801479",
   "pi_start_date": "2021-09-02",
   "pi_end_date": "2023-11-10"
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326116120",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "033Y00",
   "pgm_ele_name": "S&CC: Smart & Connected Commun"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 1999770.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"x_xmsonormal\">We have created a sophisticated system that combines data from cameras, LiDAR, and traffic sensors to monitor and analyze traffic&nbsp;<span class=\"markyjx7kw4dj\">in</span>&nbsp;real-time.<span>&#8203;</span>&nbsp;Our technology focuses on identifying&nbsp;<span class=\"markyjx7kw4dj\">in</span>dividual vehicles and pedestrians, capturing their positions and speeds. The use of LiDAR is particularly useful during nighttime when cameras may not work as effectively. All the gathered data is mapped onto a Google Maps-based coordinate system, which allows us to track movement patterns and identify potential collision points between vehicles and pedestrians, aiding&nbsp;<span class=\"markyjx7kw4dj\">in</span>&nbsp;recognizing both near-misses and serious&nbsp;<span class=\"markyjx7kw4dj\">in</span>cidents.</p>\n<p class=\"x_xmsonormal\">&nbsp;</p>\n<p class=\"x_xmsonormal\">The video tracking component relies on a machine learning model known as YOLO to detect various road users such as vehicles, pedestrians, cyclists, and motorcyclists. Alongside this, we utilize state-of-the-art algorithms to process LiDAR data, creating three-dimensional models of detected objects, which helps&nbsp;<span class=\"markyjx7kw4dj\">in</span>&nbsp;understanding their size and movement direction. Our system also employs Kalman filters to predict future movements based on current data, and these predictions are crucial&nbsp;<span class=\"markyjx7kw4dj\">in</span>&nbsp;determining possible future collisions. This&nbsp;<span class=\"markyjx7kw4dj\">in</span>formation is displayed as video clips and heatmaps, pointing out conflict zones around&nbsp;<span class=\"markyjx7kw4dj\">in</span>tersections, particularly using ground sensor data that offers detailed&nbsp;<span class=\"markyjx7kw4dj\">in</span>sights&nbsp;<span class=\"markyjx7kw4dj\">in</span>to traffic flows.</p>\n<p class=\"x_xmsonormal\">&nbsp;</p>\n<p class=\"x_xmsonormal\">Our system features high-frequency data from ground sensors at numerous&nbsp;<span class=\"markyjx7kw4dj\">in</span>tersections, which helps&nbsp;<span class=\"markyjx7kw4dj\">in</span>&nbsp;predicting traffic movements and suggesting improvements to signal timings to enhance safety. We analyze this data alongside video and LiDAR&nbsp;<span class=\"markyjx7kw4dj\">in</span>puts to compute severe events&nbsp; that are extensions of traditional measures based on Time to Collision (TTC) and Post Encroachment Time (PET). These severe events estimate the risk levels of potential collisions. By adhering to thresholds for these metrics, any detected severe events signify&nbsp;<span class=\"markyjx7kw4dj\">in</span>tersections where&nbsp;<span class=\"markyjx7kw4dj\">in</span>terventions might be beneficial. This comprehensive examination of traffic&nbsp;<span class=\"markyjx7kw4dj\">in</span>teractions allows for better understanding and prevention of accidents, helping traffic management authorities plan effective countermeasures.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 08/30/2024<br>\nModified by: Sanjay&nbsp;Ranka</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nWe have created a sophisticated system that combines data from cameras, LiDAR, and traffic sensors to monitor and analyze trafficinreal-time.&#8203;Our technology focuses on identifyingindividual vehicles and pedestrians, capturing their positions and speeds. The use of LiDAR is particularly useful during nighttime when cameras may not work as effectively. All the gathered data is mapped onto a Google Maps-based coordinate system, which allows us to track movement patterns and identify potential collision points between vehicles and pedestrians, aidinginrecognizing both near-misses and seriousincidents.\n\n\n\n\n\nThe video tracking component relies on a machine learning model known as YOLO to detect various road users such as vehicles, pedestrians, cyclists, and motorcyclists. Alongside this, we utilize state-of-the-art algorithms to process LiDAR data, creating three-dimensional models of detected objects, which helpsinunderstanding their size and movement direction. Our system also employs Kalman filters to predict future movements based on current data, and these predictions are crucialindetermining possible future collisions. Thisinformation is displayed as video clips and heatmaps, pointing out conflict zones aroundintersections, particularly using ground sensor data that offers detailedinsightsinto traffic flows.\n\n\n\n\n\nOur system features high-frequency data from ground sensors at numerousintersections, which helpsinpredicting traffic movements and suggesting improvements to signal timings to enhance safety. We analyze this data alongside video and LiDARinputs to compute severe events that are extensions of traditional measures based on Time to Collision (TTC) and Post Encroachment Time (PET). These severe events estimate the risk levels of potential collisions. By adhering to thresholds for these metrics, any detected severe events signifyintersections whereinterventions might be beneficial. This comprehensive examination of trafficinteractions allows for better understanding and prevention of accidents, helping traffic management authorities plan effective countermeasures.\n\n\n\t\t\t\t\tLast Modified: 08/30/2024\n\n\t\t\t\t\tSubmitted by: SanjayRanka\n"
 }
}