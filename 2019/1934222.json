{
 "awd_id": "1934222",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "WORKSHOP: Toward User-Oriented Agents: Research Directions and Challenges",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 42197.0,
 "awd_amount": 42197.0,
 "awd_min_amd_letter_date": "2019-08-06",
 "awd_max_amd_letter_date": "2019-08-06",
 "awd_abstract_narration": "Many intelligent agents such as Alexa and SIRI have appeared as products for general consumption in the past decade. The public has welcomed them with open arms. Public use has brought interesting and novel challenges for the research community that works on intelligent agents and dialog. On the one hand, the acceptance of these agents lets research to push its boundaries, challenged by many new applications, interactions with real users, and accounting of how well the agent performs. On the other hand, in order to maintain this golden opportunity, the users' expectations must be met. At present much of the research on intelligent agents has centered on the agent itself: giving it human-like qualities and concentrating on advanced statistical methods to decide what the agent should say. While this has produced much interesting work, it has not taken the user into account: how the user feels about the agent's performance, whether the agent was useful to the user, how reliable the agent has been. The goal of the USER workshop is to identify the challenges for future research in dialog and intelligent agents that will push researchers to turn the focus of their research from the agent to the user. To achieve this goal, the USER workshop will gather experts from fields related to intelligent agents and dialog for a discussion of how their research can be better directed toward the user, going from \"how may I help you?\" to \"have I helped you?\". \r\n \r\n\r\nPresent research into intelligent agents concentrates on the characterization of the agent and its actions and rarely characterizes the user: the user's assessment of system performance, real user data, the behavior of the user, and the evolution of the user's needs during the course of a dialog. Orienting an agent to serve the user touches on expertise in many domains within Artificial Intelligence such as: advanced dialog systems, commercially available agents, dialog assessment, datasets, entrainment and adaptation, ethics. The goal of the USER workshop is to provide a guideline for future research in dialog and intelligent agents as focus turns to the user. It will explore the present state of the art and envisage the research path of the future on intelligent agents and dialog. Specifically, it will define large scale collaborative projects and community-wide challenges. It will also identify priorities in research and the best directions in which to invest research funding. The workshop will produce a report that integrates input from all participants and conclusions from the workshop, which can be used by funding agencies to shape the future direction of research in this area. It will concentrate on the issue of user-directed research and give examples of successful past work and several concrete future research directions. It will reflect the opinions of a community of researchers.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maxine",
   "pi_last_name": "Eskenazi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maxine Eskenazi",
   "pi_email_addr": "max@cs.cmu.edu",
   "nsf_id": "000224874",
   "pi_start_date": "2019-08-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Tiancheng",
   "pi_last_name": "Zhao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tiancheng Zhao",
   "pi_email_addr": "tianchez@cs.cmu.edu",
   "nsf_id": "000801553",
   "pi_start_date": "2019-08-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie Mellon University",
  "perf_str_addr": "5000 Forbes Ave",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 42197.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>When people interact with an intelligent agent like Alexa or Siri, they has some expectations, such as that it will correctly answer the question they asked, that it will speak in a polite manner and that it will be a good companion. This has not always been the case. This is partly due to much of the past research concentrating on some abstract aspect of the system, not on the people who use it. For example, research has tried to make the system appear to be a real person, which is confusing to the user. There have also been attempts to make the system seem angry or happy, but out of contect, again causing confusion to the user. The goal of the two workshops funded here has been to get researchers to concentrate on making their intelligent agents to serve the needs of the user above all else. The outcomes of these workshops have been a summary report that has been widely cited and talks and meetings that have influenced the manner in which these systems are assessed.&nbsp; We see that these outcomes have had a wide-ranging influence on the intelligent agent research. This influence on research should in turn make intelligent agents much more useful to the average person.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/20/2021<br>\n\t\t\t\t\tModified by: Maxine&nbsp;Eskenazi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhen people interact with an intelligent agent like Alexa or Siri, they has some expectations, such as that it will correctly answer the question they asked, that it will speak in a polite manner and that it will be a good companion. This has not always been the case. This is partly due to much of the past research concentrating on some abstract aspect of the system, not on the people who use it. For example, research has tried to make the system appear to be a real person, which is confusing to the user. There have also been attempts to make the system seem angry or happy, but out of contect, again causing confusion to the user. The goal of the two workshops funded here has been to get researchers to concentrate on making their intelligent agents to serve the needs of the user above all else. The outcomes of these workshops have been a summary report that has been widely cited and talks and meetings that have influenced the manner in which these systems are assessed.  We see that these outcomes have had a wide-ranging influence on the intelligent agent research. This influence on research should in turn make intelligent agents much more useful to the average person.\n\n \n\n\t\t\t\t\tLast Modified: 12/20/2021\n\n\t\t\t\t\tSubmitted by: Maxine Eskenazi"
 }
}