{
 "awd_id": "1919167",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SPX: Collaborative Research: Scalable Neural Network Paradigms to Address Variability in Emerging Device based Platforms for Large Scale Neuromorphic Computing",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 344142.0,
 "awd_amount": 360142.0,
 "awd_min_amd_letter_date": "2019-08-27",
 "awd_max_amd_letter_date": "2020-08-10",
 "awd_abstract_narration": "Future computer data centers are being flooded with workloads requiring high-levels of computation using power-hungry deep neural network (DNN) models. DNN accelerators based on processing in memory built with new storage devices can offer great energy efficiency and performance for data centers. One challenge faced by these accelerators is their poor stability. This is due to the physical limitations of the new storage devices. This project aims to address this issue by developing efficient approaches to neural networks. One impact of proposed research is to develop more powerful, scalable, and sustainable deep learning computing systems. This will result in new consumer, business, scientific and national security applications. It will affect the fields of big data and cloud computing. This project will lead to new results in Computer Engineering and in fields that are hungry for deep learning capabilities. It will expose students to cutting-edge knowledge and hands-on research opportunities and elevate their competence. It will increase their confidence in facing today's highly competitive global job market. The education impact includes course integration of research results and outreach activities. Special attention is given in this to including women and underrepresented minority groups.\r\n\r\nThe goal of the proposed research is to address a key issue in existing processing-in-memory-based neural network accelerators built with emerging nonvolatile devices, which is the bad stability due to weight uncertainties induced by the device characteristics. To escalate the stability of these promising emerging accelerators in a scalable and sustainable manner for future data centers, the project will include four tasks: 1) the explicitly modeling of weight uncertainties, which may exhibit spatial correlations extracted from device non-idealities, as parameterized canonical distributions. 2) a statistical neural network paradigm, which can be easily integrated into existing convolutional neural network architectures by replacing their deterministic operations with the statistical counterparts operating on parameterized canonical distributions. 3) variability-aware neural network classifier inspired by error correction output codes and modern neural network architecture. 4) variability-aware input pre-processing without touching neural networks. These paradigms will be generic to different software and hardware platforms, and will be implemented and evaluated with a wide set of real-world applications including image classification, biomedical image segmentation, and drone target tracking.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yiyu",
   "pi_last_name": "Shi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yiyu Shi",
   "pi_email_addr": "yshi4@nd.edu",
   "nsf_id": "000575253",
   "pi_start_date": "2019-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Notre Dame",
  "inst_street_address": "940 GRACE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "NOTRE DAME",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "5746317432",
  "inst_zip_code": "465565708",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "IN02",
  "org_lgl_bus_name": "UNIVERSITY OF NOTRE DAME DU LAC",
  "org_prnt_uei_num": "FPU6XGFXMBE9",
  "org_uei_num": "FPU6XGFXMBE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Notre Dame",
  "perf_str_addr": "325D Cushing Hall, University of",
  "perf_city_name": "Notre Dame",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "465560001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "IN02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 344142.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>As modern computer data centers process an increasing number of complex deep learning tasks, they face growing challenges in energy efficiency and computational performance. This project focused on improving the stability of deep neural network (DNN) accelerators built on processing-in-memory (PIM) technology using advanced nonvolatile storage devices. While these accelerators offer exceptional energy efficiency and speed, they suffer from stability issues due to the inherent physical limitations of emerging storage technologies. Our research aimed to develop scalable approaches to enhance the reliability of these accelerators, ensuring their feasibility for widespread adoption in future data centers.</p>\r\n<p><strong>Key Findings and Achievements </strong></p>\r\n<p>Modeling Weight Uncertainties: To address instability, we developed an innovative approach to explicitly model weight uncertainties in neural networks. By characterizing these uncertainties as parameterized canonical distributions, we provided a systematic and efficient way to model and analyze the worst-case scenarios induced by the weight variability in hardware-driven neural networks.&nbsp;</p>\r\n<p>Statistical Neural Networks for Stability: We introduced a statistical neural network paradigm that replaces traditional deterministic operations with statistical equivalents. This approach significantly improves the robustness of DNN accelerators, allowing them to function reliably despite the inherent variability in nonvolatile storage devices.</p>\r\n<p>Negative Feedback Training: Inspired by negative feedback in control theory, we designed a new training scheme that adapts dynamically to variations in neural network parameters. This ensures consistent performance across diverse data sets and enhances the resilience of AI-driven applications in real-world settings.&nbsp;</p>\r\n<p><strong>Broader Impacts and Societal Benefits </strong></p>\r\n<p>The outcomes of this project have broad implications for the future of AI-driven computing, particularly in cloud computing, big data analytics, and national security applications.</p>\r\n<p>Energy-Efficient AI for Data Centers: Our research enables more sustainable and scalable deep learning computing systems, helping data centers reduce power consumption while maintaining high computational performance. The techniques developed in this project were successfully evaluated in diverse real-world applications, including image classification, biomedical image segmentation, and drone target tracking. These advances have the potential to improve AI-driven healthcare diagnostics, autonomous surveillance, and other critical fields.</p>\r\n<p>Education and Workforce Development: The project provided hands-on research opportunities for students through course integration, exposing them to cutting-edge AI technologies. Two tutorials were also given by the PI in premier conferences around the research supported by this project.&nbsp;</p>\r\n<p>By addressing the stability issues of PIM-based neural network accelerators, this research has laid the foundation for scalable, energy-efficient AI computing in future data centers. Our novel approaches to weight uncertainty modeling, statistical neural networks, and variability-aware classification have significantly improved the reliability of AI accelerators, making them more viable for large-scale deployment. The project&rsquo;s contributions to education and workforce development ensure that future researchers and engineers are well-equipped to continue advancing the field of AI-driven computing.</p><br>\n<p>\n Last Modified: 02/05/2025<br>\nModified by: Yiyu&nbsp;Shi</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nAs modern computer data centers process an increasing number of complex deep learning tasks, they face growing challenges in energy efficiency and computational performance. This project focused on improving the stability of deep neural network (DNN) accelerators built on processing-in-memory (PIM) technology using advanced nonvolatile storage devices. While these accelerators offer exceptional energy efficiency and speed, they suffer from stability issues due to the inherent physical limitations of emerging storage technologies. Our research aimed to develop scalable approaches to enhance the reliability of these accelerators, ensuring their feasibility for widespread adoption in future data centers.\r\n\n\nKey Findings and Achievements \r\n\n\nModeling Weight Uncertainties: To address instability, we developed an innovative approach to explicitly model weight uncertainties in neural networks. By characterizing these uncertainties as parameterized canonical distributions, we provided a systematic and efficient way to model and analyze the worst-case scenarios induced by the weight variability in hardware-driven neural networks.\r\n\n\nStatistical Neural Networks for Stability: We introduced a statistical neural network paradigm that replaces traditional deterministic operations with statistical equivalents. This approach significantly improves the robustness of DNN accelerators, allowing them to function reliably despite the inherent variability in nonvolatile storage devices.\r\n\n\nNegative Feedback Training: Inspired by negative feedback in control theory, we designed a new training scheme that adapts dynamically to variations in neural network parameters. This ensures consistent performance across diverse data sets and enhances the resilience of AI-driven applications in real-world settings.\r\n\n\nBroader Impacts and Societal Benefits \r\n\n\nThe outcomes of this project have broad implications for the future of AI-driven computing, particularly in cloud computing, big data analytics, and national security applications.\r\n\n\nEnergy-Efficient AI for Data Centers: Our research enables more sustainable and scalable deep learning computing systems, helping data centers reduce power consumption while maintaining high computational performance. The techniques developed in this project were successfully evaluated in diverse real-world applications, including image classification, biomedical image segmentation, and drone target tracking. These advances have the potential to improve AI-driven healthcare diagnostics, autonomous surveillance, and other critical fields.\r\n\n\nEducation and Workforce Development: The project provided hands-on research opportunities for students through course integration, exposing them to cutting-edge AI technologies. Two tutorials were also given by the PI in premier conferences around the research supported by this project.\r\n\n\nBy addressing the stability issues of PIM-based neural network accelerators, this research has laid the foundation for scalable, energy-efficient AI computing in future data centers. Our novel approaches to weight uncertainty modeling, statistical neural networks, and variability-aware classification have significantly improved the reliability of AI accelerators, making them more viable for large-scale deployment. The projects contributions to education and workforce development ensure that future researchers and engineers are well-equipped to continue advancing the field of AI-driven computing.\t\t\t\t\tLast Modified: 02/05/2025\n\n\t\t\t\t\tSubmitted by: YiyuShi\n"
 }
}