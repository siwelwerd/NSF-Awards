{
 "awd_id": "1904992",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Methods for Analysis and Optimization of Stochastic Systems with Model Uncertainty and Related Monte Carlo Schemes",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Pedro Embid",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 482945.0,
 "awd_amount": 482945.0,
 "awd_min_amd_letter_date": "2019-08-09",
 "awd_max_amd_letter_date": "2021-09-13",
 "awd_abstract_narration": "Mathematical models are used in every area of science, engineering, and policy to design systems or to understand physical or social phenomena.  In every instance, the issue of model error is important.  In general, it is not possible for practical reasons (such as limited amounts of data, or the need to maintain computational feasibility) to work with a perfectly accurate model.  Hence it is important to identify those aspects of the model that are uncertain, quantify their impact on predictions, and perhaps even account for this uncertainty while using the model, for example as an engineering tool.  The models of interest in this project are probabilistic.  In this setting we acknowledge that the system is random, and the model error is due to an imperfect understanding of the parameters that describe the probability distribution.  To assess how mathematical predictions based on the model change as the model itself changes, one needs metrics to compare the outcome based on different distributions (e.g., the distribution that is used for \"design,\" and an ideal but not available \"true\" distribution).  The topic of this research is the development of the theory and application of such metrics.  In contrast to prior work, here we focus on situations where the quantities of interest are tied to rare events, such as a catastrophic system failure.  Graduate students participate in the research of the project.\r\n\r\nThe main theme of this project is the use of divergences and metrics on probability measures to study model uncertainty, and optimization and control in the presence of model uncertainty.  The probability measures are typically on high-dimensional or complicated spaces, and typically on a path space to model stochastic dynamics.  An important aspect of the work is to establish useful qualitative properties, such as scaling limits and chain rule-type formulas.  In contrast to prior work, the focus here is on situations where (a) one wishes to consider differing models that are not absolutely continuous, and (b) performance measures and quantities of interest are largely determined by rare events and tail properties.  The main mathematical tools used are convex duality or variational formulas that relate the divergences to exponential integrals.  To implement the theory, one needs to evaluate such exponential integrals, which for example may take the form of a moment-generating function with respect to the stationary distribution of some Markov process.  The project also considers the design and analysis of Monte Carlo methods for this class of problems.  Graduate students participate in the research of the project.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Paul",
   "pi_last_name": "Dupuis",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Paul G Dupuis",
   "pi_email_addr": "dupuis@cfm.brown.edu",
   "nsf_id": "000110853",
   "pi_start_date": "2019-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "Office of Sponsored Projects",
  "perf_city_name": "Providence",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029129093",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126300",
   "pgm_ele_name": "PROBABILITY"
  },
  {
   "pgm_ele_code": "126600",
   "pgm_ele_name": "APPLIED MATHEMATICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 154310.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 162529.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 166106.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>There were two main focus areas for this project. One was the development and application of so-called divergences, which can be used to quantitatively and qualitatively compare probability distributions.&nbsp; The most famous such divergence is Kullback-Leibler divergence, also known as relative entropy. &nbsp;Starting from the Donsker-Varadhan representation for relative entropy, we developed a new divergence that retains many of the attractive properties of relative entropy, such as strong convexity, but which allows measures that are not absolutely continuous to be compared.&nbsp; This is important, since it is often important to be able to compare distributions that do not satisfy this relationship, for example when building a continuously distributed model of the basis of data. &nbsp;The initial work in this direction appeared in the paper <strong>Formulation and properties of a divergence used to compare probability measures without absolute continuity. </strong>&nbsp;However, for other applications such as to heavy tailed distributions a generalization was needed, and so later with colleagues from UMass we completed the paper <strong>(f,&Gamma;)-divergences: Interpolating between f-divergences and integral probability metrics</strong>. &nbsp;Divergences have been found to be quite convenient for purposes of model construction and uncertainty quantification, where they are used to compare e.g. a design model versus the \"true\" model.&nbsp; These generalized divergences were subsequently applied to problems of machine learning.</p>\n<p>A related issue is how to account for model form uncertainty when the performance or behavior of a systems is impacted by rare events.&nbsp; We completed several projects in this direction.&nbsp; One paper on the topic was <strong>Robust bounds and optimization at the large deviations scale for queueing models via Renyi divergence</strong>. &nbsp;As suggested by the title, the emphasis here was on applications of the theory to problems originating in queueing, where model form uncertainty is an important issue.&nbsp; A second paper which focuses on sensitivity analysis and with a broader set of application examples is <strong>Sensitivity analysis for rare events based on Renyi divergence</strong>, and related work appears in <strong>Variational representations and neural network estimation for Renyi divergences</strong>, which develops new variational formulas for Renyi divergences, which can then be used as the basis for numerical approximation.<em> </em></p>\n<p>The second main topic of the project was the development of mathematical methods for the analysis and design of Monte Carlo methods to deal with the so-called rare event sampling problem.&nbsp; To do this the first step was develop methods, analogous to the Freidlin-Wentsell theory for the stationary distribution of small noise perturbations of dynamical systems, that would allow one to characterize the variance of Markov Chain Monte Carlo schemes when metastability issues are relevant.&nbsp; This was done in the paper <strong>Large deviation properties of the empirical measure of a stochastic differential equation with small noise</strong>. The results of this paper were subsequently applied address the question of how to optimally design parallel tempering schemes, and the limiting scheme introduced by the PI and J. Doll called Infinite Swapping. This application appeared in the paper <strong>Analysis and optimization of certain parallel Monte Carlo methods in the low temperature limit</strong>. &nbsp;</p><br>\n<p>\n Last Modified: 04/09/2024<br>\nModified by: Paul&nbsp;G&nbsp;Dupuis</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThere were two main focus areas for this project. One was the development and application of so-called divergences, which can be used to quantitatively and qualitatively compare probability distributions. The most famous such divergence is Kullback-Leibler divergence, also known as relative entropy. Starting from the Donsker-Varadhan representation for relative entropy, we developed a new divergence that retains many of the attractive properties of relative entropy, such as strong convexity, but which allows measures that are not absolutely continuous to be compared. This is important, since it is often important to be able to compare distributions that do not satisfy this relationship, for example when building a continuously distributed model of the basis of data. The initial work in this direction appeared in the paper Formulation and properties of a divergence used to compare probability measures without absolute continuity. However, for other applications such as to heavy tailed distributions a generalization was needed, and so later with colleagues from UMass we completed the paper (f,)-divergences: Interpolating between f-divergences and integral probability metrics. Divergences have been found to be quite convenient for purposes of model construction and uncertainty quantification, where they are used to compare e.g. a design model versus the \"true\" model. These generalized divergences were subsequently applied to problems of machine learning.\n\n\nA related issue is how to account for model form uncertainty when the performance or behavior of a systems is impacted by rare events. We completed several projects in this direction. One paper on the topic was Robust bounds and optimization at the large deviations scale for queueing models via Renyi divergence. As suggested by the title, the emphasis here was on applications of the theory to problems originating in queueing, where model form uncertainty is an important issue. A second paper which focuses on sensitivity analysis and with a broader set of application examples is Sensitivity analysis for rare events based on Renyi divergence, and related work appears in Variational representations and neural network estimation for Renyi divergences, which develops new variational formulas for Renyi divergences, which can then be used as the basis for numerical approximation. \n\n\nThe second main topic of the project was the development of mathematical methods for the analysis and design of Monte Carlo methods to deal with the so-called rare event sampling problem. To do this the first step was develop methods, analogous to the Freidlin-Wentsell theory for the stationary distribution of small noise perturbations of dynamical systems, that would allow one to characterize the variance of Markov Chain Monte Carlo schemes when metastability issues are relevant. This was done in the paper Large deviation properties of the empirical measure of a stochastic differential equation with small noise. The results of this paper were subsequently applied address the question of how to optimally design parallel tempering schemes, and the limiting scheme introduced by the PI and J. Doll called Infinite Swapping. This application appeared in the paper Analysis and optimization of certain parallel Monte Carlo methods in the low temperature limit. \t\t\t\t\tLast Modified: 04/09/2024\n\n\t\t\t\t\tSubmitted by: PaulGDupuis\n"
 }
}