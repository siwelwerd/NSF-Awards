{
 "awd_id": "1941613",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Collaborative Assembly of Large and Comprehensive Causal Networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 198971.0,
 "awd_amount": 198971.0,
 "awd_min_amd_letter_date": "2019-08-16",
 "awd_max_amd_letter_date": "2019-08-16",
 "awd_abstract_narration": "People are highly motivated to find explanations and solutions to address the pressing problems facing our country and our world, but they often lack the proper analytical tools to move beyond limited-scope analyses, guesswork, and instincts. This project aims to tackle this problem by developing a set of tools that make use of the massive amount of data that is freely available on the web. Anyone with a modern web browser will be able to run these tools and take part in a collaborative effort to construct comprehensive causal models for complex socio-economic and other systems. Uncovering the causal relations that exist among the variables in multivariate datasets is one of the ultimate goals in data analytics. A causal assertion separates cause and effect, for example, it states that \"smoking causes cancer\", but not the reverse. This is what makes causal models more definite than correlation. Causal models are attractive since they are inherently interpretable. They are able to directly explain the complex interactions that exist in the underlying data. The online tools developed in this project will take causal modeling to the next level. They will support collaboration in constructing comprehensive causal models of unprecedented scale for complex socio-economic and other systems. \r\n\r\nThis exploratory project aims to develop a set of tools that use freely available, web-scale data for the collaborative construction of comprehensive causal models of unprecedented scale for complex socio-economic and other systems. The project will break new grounds on how the creative energies of experts and non-experts can be harnessed to (1) identify datasets on the web that can add novel aspects (variables) to an evolving causal model, and (2) integrate these novel aspects (variables) as new nodes and causal edges into the model. Since building a complex, large-scale causal model can become difficult as the model grows in size, the project will produce several new automated tools that will hide this complexity from the human users, aid them in dealing with incomplete or adverse data, and provide inspiration for possible refinements. At the same time, novel techniques will also be developed that ensure validity and correctness of the evolving causal model in the presence of concurrent users. In order to hide complexity, the project will produce new techniques that can break a large causal model into a set of human-manageable subgraphs which will nevertheless retain sufficient information about the particular thematic aspect to be refined. A subgraph will be visualized in the form of a causal flowchart that can effectively show the propagation of causal relationships, and support users who may lack sufficient domain knowledge, intuition, or other helpful information to identify promising variables that could make the model more expressive. The project will develop new techniques based on the paradigm of word embeddings to assist users in this discovery process. Word embeddings map words mentioned in similar contexts in large text corpora into close neighborhoods in high-dimensional space. A 2D map-like visualization will be developed that maps words (denoting candidate variables) in the causal subgraph's thematic context near the labels of semantically related variables already in the model. Human model editors can then inspect this visual map of words (candidate variables), hypothesize possible new causal relations from these new variables, search for associated data on the web or in the evolving causal model, and test and embed the new causal relations into the subgraph using the system's causal inference engine. Behind the scenes, an automated causal network manager will then derive causal edges to other variables and so fully evolve the model. Since automated causal inference in the presence of observed data can occasionally generate wrongly directed or undirected edges, the interface will also provide new paradigms that allow human model appraisers to verify the generated edges and suggest changes. A set of carefully designed user experiments will be conducted to verify and optimize all system components. The research is expected to yield new theoretical knowledge and algorithms on human centered computational causal reasoning and the utilization of the vast body of data available online. It will also deliver new insights on how humans interact with the tools for deriving and exploring causal models. The platform and tools generated in this research will be applicable to multiple fields of knowledge and enable construction of causal models capable of explaining how the various aspects and fields relate in a larger context. The developed tools will be made available as part of the online platform.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Klaus",
   "pi_last_name": "Mueller",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Klaus Mueller",
   "pi_email_addr": "mueller@cs.stonybrook.edu",
   "nsf_id": "000735898",
   "pi_start_date": "2019-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "Computer Science Department",
  "perf_city_name": "Stony Brook",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117940001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 198971.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Causality is deeply rooted in human psychology. Humans have a natural curiosity to learn how things work in a causal sense, that is, what is the cause of an observed effect or what is the effect a certain cause produces. When several cause and effect relations are joined together they form what is called a <em>causal network</em>. For example, a car with a bigger engine will \"cause\" a greater amount of horsepower, and this in turn will \"cause\" a better acceleration, meaning the car will reach a speed of 50 mph faster. But at the same time, cars with higher horsepower will be heavier, i.e., they \"cause\" a greater amount of weight and this in turn \"causes\" them to use more gas, leading to a lower amount of miles per gallon. These relations can be graphically visualized as a node-link diagram of variables, such as horsepower and weight, connected by their causal links. &nbsp;&nbsp;&nbsp;</p>\n<p>There are many complex phenomena that can be explained with a causal network, such as climate change, the economy, taxation, immigration, etc. These are phenomena where people have different perspectives but due to the complexity of the underlying causal networks there are often gaps and misconceptions that can lead to misunderstandings. This NSF-funded work set out to see whether it is possible to empower humans without specific scientific background to collaboratively construct causal networks of complex phenomena, and through this process better understand where the existing knowledge gaps and misconceptions are and how they relate in a causal sense. These insights could then be used to improve communication strategies about these complex topics.</p>\n<p>Essentially what our mechanism can extract are the causal beliefs of the human engaging in the step-by-step causal network construction. The methodology we devised can evaluate people's causal beliefs, potential misconceptions, and obliviousness to established facts. Here, a misconception is a causal belief that is popular but is not supported by credible scientific research. On the other hand, an oblivious relation is an infrequently held causal belief which however is well supported by credible scientific research, meaning it is a scientific fact that most people are not aware of.</p>\n<p>For our research we used climate change as an example and here we focused primarily on the symptom of excessive forest fires. To collect the causal beliefs, we designed an interactive visual interface where people could create causal relations between different factors such as wildfires, heatwaves, fossil fuel burning, solar radiation, CO2, etc. We applied game design principles such as self-determination, progress, sense of ownership, and accomplishment for engaging participants. A crowdsourcing experiment with 94 workers recruited from Amazon?s Mechanical Turk gig platform revealed that workers could easily create small causal networks by ways of our system. By analyzing these small networks we were able to make assertions about the crowd's perceptions and the potential misconceptions that existed in them related to climate change.</p>\n<p>To give a few examples, the most voted spurious (causally invalid) relations were \"increasing solar radiation &rarr; more intense heat waves\" and \"increasing solar radiation &rarr; increasing temperature\" which are not untrue per se but they miss the core substance of the problem. These relations, in fact, are often used by climate change deniers who minimize the problem by stating that \"it is the sun\" that's causing all that heat. Other frequently marked relations were \"increasing solar radiation &rarr; increasing CO2\" and \"increasing temperature &rarr; increasing CO2\" which are both fallacies. Some relations with relatively high vote counts also lacked crucial causal mediators, such as \"more human activities &rarr; increasing CO2\". Here, a more accurate assertion is the chain of two relations \"more human activities &rarr; more fossil fuel burning &rarr; increasing CO2\".</p>\n<p>At the end of each session workers were asked how confident they were in the validity of the network they constructed. We found that spurious or incomplete networks often led to lower confidence scores. In the above example, networks that contained the single relation had lower confidence scores than networks with the complete 2-relation chain. We believe that the confidence in the former model was lower since it did not explain precisely what \"human activities\" caused the \"increasing CO2\".</p>\n<p>Misconceptions were often based on causal confounders, causal colliders, and omitted mediators. Some examples we found were (1) Rising Human Activities as a confounder for the (misconceived) causal link Rising Fossil Fuel Burning &rarr; Declining Forests, (2) Rising CO2 as a collider for the (misconceived) causal link Rising Fossil Fuel Burning &rarr; Declining Forests, and (3) Rising CO2 is a mediator for the (misconceived shortcut) causal link Declining Forests&rarr; Rising Trapped Heat. These are just a few examples of the findings we gathered, and given these successes we are confident that this tool we developed could be an effective platform for social science researchers and public policy makers.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/09/2022<br>\n\t\t\t\t\tModified by: Klaus&nbsp;Mueller</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090234438_figure2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090234438_figure2--rgov-800width.jpg\" title=\"Discrepancy network comparing crowd beliefs with scientific beliefs\"><img src=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090234438_figure2--rgov-66x44.jpg\" alt=\"Discrepancy network comparing crowd beliefs with scientific beliefs\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">See text below the picture</div>\n<div class=\"imageCredit\">Klaus Mueller</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Klaus&nbsp;Mueller</div>\n<div class=\"imageTitle\">Discrepancy network comparing crowd beliefs with scientific beliefs</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090063214_figure1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090063214_figure1--rgov-800width.jpg\" title=\"Crowd vs ground truth causal network\"><img src=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090063214_figure1--rgov-66x44.jpg\" alt=\"Crowd vs ground truth causal network\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">See text below the picture</div>\n<div class=\"imageCredit\">Klaus Mueller</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Klaus&nbsp;Mueller</div>\n<div class=\"imageTitle\">Crowd vs ground truth causal network</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090431745_figure3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090431745_figure3--rgov-800width.jpg\" title=\"Some misconception and obliviousness cases in the discrepancy network\"><img src=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090431745_figure3--rgov-66x44.jpg\" alt=\"Some misconception and obliviousness cases in the discrepancy network\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Some misconception and obliviousness cases in the discrepancy network</div>\n<div class=\"imageCredit\">Klaus Mueller</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Klaus&nbsp;Mueller</div>\n<div class=\"imageTitle\">Some misconception and obliviousness cases in the discrepancy network</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090519877_figure4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090519877_figure4--rgov-800width.jpg\" title=\"Causal triads\"><img src=\"/por/images/Reports/POR/2022/1941613/1941613_10635029_1660090519877_figure4--rgov-66x44.jpg\" alt=\"Causal triads\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Cases containing a confounder, a collider and a mediator (from left to right)</div>\n<div class=\"imageCredit\">Klaus Mueller</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Klaus&nbsp;Mueller</div>\n<div class=\"imageTitle\">Causal triads</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nCausality is deeply rooted in human psychology. Humans have a natural curiosity to learn how things work in a causal sense, that is, what is the cause of an observed effect or what is the effect a certain cause produces. When several cause and effect relations are joined together they form what is called a causal network. For example, a car with a bigger engine will \"cause\" a greater amount of horsepower, and this in turn will \"cause\" a better acceleration, meaning the car will reach a speed of 50 mph faster. But at the same time, cars with higher horsepower will be heavier, i.e., they \"cause\" a greater amount of weight and this in turn \"causes\" them to use more gas, leading to a lower amount of miles per gallon. These relations can be graphically visualized as a node-link diagram of variables, such as horsepower and weight, connected by their causal links.    \n\nThere are many complex phenomena that can be explained with a causal network, such as climate change, the economy, taxation, immigration, etc. These are phenomena where people have different perspectives but due to the complexity of the underlying causal networks there are often gaps and misconceptions that can lead to misunderstandings. This NSF-funded work set out to see whether it is possible to empower humans without specific scientific background to collaboratively construct causal networks of complex phenomena, and through this process better understand where the existing knowledge gaps and misconceptions are and how they relate in a causal sense. These insights could then be used to improve communication strategies about these complex topics.\n\nEssentially what our mechanism can extract are the causal beliefs of the human engaging in the step-by-step causal network construction. The methodology we devised can evaluate people's causal beliefs, potential misconceptions, and obliviousness to established facts. Here, a misconception is a causal belief that is popular but is not supported by credible scientific research. On the other hand, an oblivious relation is an infrequently held causal belief which however is well supported by credible scientific research, meaning it is a scientific fact that most people are not aware of.\n\nFor our research we used climate change as an example and here we focused primarily on the symptom of excessive forest fires. To collect the causal beliefs, we designed an interactive visual interface where people could create causal relations between different factors such as wildfires, heatwaves, fossil fuel burning, solar radiation, CO2, etc. We applied game design principles such as self-determination, progress, sense of ownership, and accomplishment for engaging participants. A crowdsourcing experiment with 94 workers recruited from Amazon?s Mechanical Turk gig platform revealed that workers could easily create small causal networks by ways of our system. By analyzing these small networks we were able to make assertions about the crowd's perceptions and the potential misconceptions that existed in them related to climate change.\n\nTo give a few examples, the most voted spurious (causally invalid) relations were \"increasing solar radiation &rarr; more intense heat waves\" and \"increasing solar radiation &rarr; increasing temperature\" which are not untrue per se but they miss the core substance of the problem. These relations, in fact, are often used by climate change deniers who minimize the problem by stating that \"it is the sun\" that's causing all that heat. Other frequently marked relations were \"increasing solar radiation &rarr; increasing CO2\" and \"increasing temperature &rarr; increasing CO2\" which are both fallacies. Some relations with relatively high vote counts also lacked crucial causal mediators, such as \"more human activities &rarr; increasing CO2\". Here, a more accurate assertion is the chain of two relations \"more human activities &rarr; more fossil fuel burning &rarr; increasing CO2\".\n\nAt the end of each session workers were asked how confident they were in the validity of the network they constructed. We found that spurious or incomplete networks often led to lower confidence scores. In the above example, networks that contained the single relation had lower confidence scores than networks with the complete 2-relation chain. We believe that the confidence in the former model was lower since it did not explain precisely what \"human activities\" caused the \"increasing CO2\".\n\nMisconceptions were often based on causal confounders, causal colliders, and omitted mediators. Some examples we found were (1) Rising Human Activities as a confounder for the (misconceived) causal link Rising Fossil Fuel Burning &rarr; Declining Forests, (2) Rising CO2 as a collider for the (misconceived) causal link Rising Fossil Fuel Burning &rarr; Declining Forests, and (3) Rising CO2 is a mediator for the (misconceived shortcut) causal link Declining Forests&rarr; Rising Trapped Heat. These are just a few examples of the findings we gathered, and given these successes we are confident that this tool we developed could be an effective platform for social science researchers and public policy makers.\n\n\t\t\t\t\tLast Modified: 08/09/2022\n\n\t\t\t\t\tSubmitted by: Klaus Mueller"
 }
}