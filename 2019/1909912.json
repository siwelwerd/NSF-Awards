{
 "awd_id": "1909912",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Collaborative Research: Scalable Deep Bayesian Tensor Decomposition",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 199134.0,
 "awd_amount": 199134.0,
 "awd_min_amd_letter_date": "2019-09-07",
 "awd_max_amd_letter_date": "2020-01-30",
 "awd_abstract_narration": "Many applications in the real world, such as online \r\nshopping, recommendation, social media and information \r\nsecurity, involve interactions among different \r\nentities. For example, online shopping behaviors can \r\nbe simply described by the interactions between \r\ncustomers, commodities and shopping web sites. These \r\ninteractions are naturally represented by tensors, \r\nwhich are arrays of multiple dimensions. Each \r\ndimension represents a type of entities (e.g., \r\ncustomers or commodities), and each element describes \r\na particular interaction (e.g, purchased/not \r\npurchased). The project aims to develop flexible and \r\nefficient tensor decomposition approaches that can \r\ndiscover a variety of complicated relationships \r\nbetween the entities in tensors, handle a tremendous \r\namount of data from practical applications, and adapt \r\nto rapid data growth. The developed approaches can be \r\nused to promote many important prediction and \r\nknowledge discovery tasks, such as improving the \r\nrecommendation accuracy, predicting advertisement \r\nclick rates, understanding how misinformation propagation \r\nthrough social media, and detecting malicious cell- \r\nphone apps. \r\n\r\nDespite the success of the existing tensor \r\ndecomposition approaches, they use multilinear \r\ndecomposition forms or shallow kernels, and are \r\nincapable of capturing highly complicated \r\nrelationships in data. However, complex and nonlinear \r\nrelationships, effects and patterns are ubiquitous, \r\ndue to the diversity and complexity of the practical \r\napplications. Furthermore, there is a lack of \r\nefficient, scalable nonlinear decomposition algorithms \r\nto handle static tensors nowadays at unprecedented \r\nscales, and dynamic tensors that grow fast and \r\ncontinuously. The project aims to develop scalable \r\ndeep Bayesian tensor decomposition approaches that \r\nmaximize the flexibility to capture all kinds of \r\ncomplex relationships, efficiently process static data \r\nat unprecedented scales and rapid data streams, and \r\nprovide uncertainty quantification for both embedding \r\nestimations and predictions. The research will be \r\naccomplished through: (1) the design of new Bayesian \r\ntensor decomposition models that incorporate deep \r\narchitectures to improve the capability of estimating \r\nintricate functions, (2) the development of \r\ndecentralized, asynchronous learning algorithms to \r\nprocess extremely large-scale static tensors, (3) the \r\ndevelopment of online incremental learning algorithms \r\nto handle rapid data streams and to produce responsive \r\nupdates upon receiving new data, without retraining \r\nfrom scratch, and (4) comprehensive evaluations on \r\nboth synthetic and real-world big data. The proposed \r\nresearch will contribute a markedly improved tensor \r\ndecomposition toolset that are powerful to estimate \r\narbitrarily complex relationships, scalable to static \r\ntensors at unprecedented scales (e.g., billions of \r\nnodes and trillions of entries) and to fast data \r\nstreams with efficient incremental updates. Moreover, \r\nas Bayesian approaches, the toolset are resilient to \r\nnoise, provide posterior distributions for \r\nuncertainty quantification, and integrate all possible \r\noutcomes into robust predictions. Once the toolsets are \r\navailable, the understanding of the high-order \r\nrelationships in tensors, and the mining of associated \r\npatterns, such as communities and anomalies, will be \r\nenormously enhanced; the predictive performance for \r\nthe quantify of interests, such as social links, \r\nclick-through-rates, and recommendation, will be \r\ndramatically promoted.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Ji",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ji Liu",
   "pi_email_addr": "jliu@cs.rochester.edu",
   "nsf_id": "000678098",
   "pi_start_date": "2019-09-07",
   "pi_end_date": "2020-01-30"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chenliang",
   "pi_last_name": "Xu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chenliang Xu",
   "pi_email_addr": "chenliang.xu@rochester.edu",
   "nsf_id": "000728261",
   "pi_start_date": "2020-01-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146270140",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 199134.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>While many AI applications make human life more convenient, they also bring concerns and worries to human societies. Addressing these concerns needs to pivot the research from blind persuasion for performance to a more comprehensive study on multiple facets of responsible AI.</p>\n<p>The first aspect we considered was model bias for discriminative and generative image models. Regarding the discriminative image models, we studied biases in image classifiers. While existing works mainly focus on mitigating one predefined bias, we asked a more novel, practical, and fundamental research question: how to detect and mitigate unknown biases---bias types that are out of human assumption and the number of biases is unconfirmed? We answered the new research questions with a trilogy of works on unknown bias discovery and multi-bias mitigation, contributing new datasets, benchmarks, and algorithms to advance future research on unknown biases. We further studied biases in generative image models. Concretely, we studied how to mitigate biases of text-to-image generation, contributing a novel method based on disentangled representations to enhance the compositionality of text-to-image models, leading to fairer generation results.</p>\n<p>The second aspect was model robustness. We systematically studied the robustness of machines' multisensory perception against attacks and noises. We used the audio-visual event recognition task against multimodal adversarial attacks as a proxy to investigate the robustness of audio-visual learning. We also studied counterfactual robustness in learning joint audio-text embeddings from raw audio-text pairs describing audio in natural language and certified defense against text adversarial attacks.&nbsp;</p>\n<p>The third aspect was model interpretability. We devised a simple yet highly generalizable method for explaining interacting parts within a neural network's reasoning process. The technique was effective in reasoning both 2-way and higher-order (3-way) interactions.&nbsp;</p>\n<p>For broader impacts, results obtained from this project are of keen interest to machine learning practitioners in ensuring the responsible application of their models. It is particularly needed today, with powerful Large Language Models (LLMs) and multimodel LLMs. Knowing their biases, identifying their robustness, and unfolding their reasoning processes is crucial.&nbsp;</p>\n<p>This project has provided opportunities for research, teaching, and mentoring in computer science by allowing the PI to work closely with graduate students involved in the project and teach them research methodologies, scientific writing, and presentation skills. We have graduated one Ph.D. student in this project. The results of this project have been featured as course modules in the PI's Deep Learning course. We have released many of our curated datasets and developed algorithms freely and publicly for use by the research community.&nbsp;</p><br>\n<p>\n Last Modified: 01/22/2024<br>\nModified by: Chenliang&nbsp;Xu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nWhile many AI applications make human life more convenient, they also bring concerns and worries to human societies. Addressing these concerns needs to pivot the research from blind persuasion for performance to a more comprehensive study on multiple facets of responsible AI.\n\n\nThe first aspect we considered was model bias for discriminative and generative image models. Regarding the discriminative image models, we studied biases in image classifiers. While existing works mainly focus on mitigating one predefined bias, we asked a more novel, practical, and fundamental research question: how to detect and mitigate unknown biases---bias types that are out of human assumption and the number of biases is unconfirmed? We answered the new research questions with a trilogy of works on unknown bias discovery and multi-bias mitigation, contributing new datasets, benchmarks, and algorithms to advance future research on unknown biases. We further studied biases in generative image models. Concretely, we studied how to mitigate biases of text-to-image generation, contributing a novel method based on disentangled representations to enhance the compositionality of text-to-image models, leading to fairer generation results.\n\n\nThe second aspect was model robustness. We systematically studied the robustness of machines' multisensory perception against attacks and noises. We used the audio-visual event recognition task against multimodal adversarial attacks as a proxy to investigate the robustness of audio-visual learning. We also studied counterfactual robustness in learning joint audio-text embeddings from raw audio-text pairs describing audio in natural language and certified defense against text adversarial attacks.\n\n\nThe third aspect was model interpretability. We devised a simple yet highly generalizable method for explaining interacting parts within a neural network's reasoning process. The technique was effective in reasoning both 2-way and higher-order (3-way) interactions.\n\n\nFor broader impacts, results obtained from this project are of keen interest to machine learning practitioners in ensuring the responsible application of their models. It is particularly needed today, with powerful Large Language Models (LLMs) and multimodel LLMs. Knowing their biases, identifying their robustness, and unfolding their reasoning processes is crucial.\n\n\nThis project has provided opportunities for research, teaching, and mentoring in computer science by allowing the PI to work closely with graduate students involved in the project and teach them research methodologies, scientific writing, and presentation skills. We have graduated one Ph.D. student in this project. The results of this project have been featured as course modules in the PI's Deep Learning course. We have released many of our curated datasets and developed algorithms freely and publicly for use by the research community.\t\t\t\t\tLast Modified: 01/22/2024\n\n\t\t\t\t\tSubmitted by: ChenliangXu\n"
 }
}