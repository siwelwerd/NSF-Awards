{
 "awd_id": "1914917",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Complex Problems in Functional Data Analysis",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2019-06-19",
 "awd_max_amd_letter_date": "2021-08-16",
 "awd_abstract_narration": "Functional data analysis (FDA) deals with infinite-dimensional data in the form of random functions. Such data have become increasingly common due to new technology to record and store massive data. The field has gained much traction and research has accelerated, but there remain many unsolved problems and new opportunities for research. This research focuses on four projects that address: 1) an open problem regarding the choice of the domain of interest in a regression setting with a functional covariate and scalar response, 2) implementing the RKHS (reproducing kernel Hilbert space) approach for conventional functional linear models when the functional covariates are observed sparsely, 3) dynamic modeling for multivariate functional data, and 4) challenges for the analysis of functional snippet data, for which each subject is observed in a different interval much shorter than the domain of the functional data. The developed methods will be applied to various data with functional components to evaluate the effect of pollutants on lung cancer mortality and to explore the interaction of these pollutants.  The proposed research thus has direct impacts on public health research. In addition, the proposed approaches for functional snippets have broad applications in accelerated longitudinal studies, which are common in social and health sciences. The computer code of developed algorithms will be integrated into an existing R-package, fdapace, on CRAN. The research findings will be incorporated into graduate curricula, undergraduate and graduate research projects, and short courses at workshops, and be presented at professional meetings. \r\n \r\nProject 1 is important for interpreting the influence of a functional covariate, yet to date, there is no algorithm that can reliably identify the relevant domain and the theory is incomplete. We propose to resolve these open problems through a new framework that involves a dynamic RKHS approach to overcome the challenges. This has the potential to break new ground in the well-established field of RKHS.  A weakness of the RKHS approach is that it has difficulty to handle sparsely observed functional covariates. In Project 2, we propose a solution by imputing incomplete functional covariates and show that the regression coefficient function can be recovered through the imputed functional covariates. A new line of theory will be developed to deal with the approximation errors in the Karhunen-Lo\\'eve expansion for functional data.  These new results will facilitate future research that involves imputation for functional data. Project 3 aims at modeling the derivatives of multivariate functional data using the component processes as covariates. We propose a concurrent approach that avoids an ill-posed inverse problem and has the advantage to accommodate time-lags of the predictor component processes. Project 4 deals with another open problem in FDA. We propose two nonparametric approaches for functional snippets and will develop supporting theory. These new approaches provide a new frontier of research in FDA, as once the covariance can be estimated accurately, existing FDA approaches, such as principal component analysis, classification or clustering, can be readily adapted for functional snippets.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jane-Ling",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jane-Ling Wang",
   "pi_email_addr": "janelwang@ucdavis.edu",
   "nsf_id": "000452165",
   "pi_start_date": "2019-06-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California, Davis",
  "perf_str_addr": "Department of Statistics, UC Dav",
  "perf_city_name": "Davis",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956165270",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 65064.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 65700.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 69236.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project tackles several challenges in Functional Data Analysis (FDA), a field dealing with random functions that have become increasingly prevalent due to advancements in handling massive datasets. &nbsp;The field has emerged as a mainstream research area, but the application of deep neural networks to functional data remains limited. The inherent infinite dimensionality of functional data means standard learning algorithms can be applied only after appropriate dimension reduction, typically achieved via basis expansions. Currently, these bases are chosen a priori without the information for the task at hand and thus may not be effective for the designated task. In a 2021 paper at the International Conference in Machine Learning, we propose to adaptively learn these bases in an end-to-end fashion. We introduce neural networks that employ a new Basis Layer whose hidden units are each basis functions themselves implemented as a micro neural network. Our architecture learns to apply parsimonious dimension reduction to functional inputs that focuses only on information relevant to the target rather than irrelevant variation in the input function. Across numerous classification and regression tasks involving functional data, our method empirically outperforms other types of neural networks, and we establish its statistically consistent with low generalization error.</p>\n<p>Additionally, this project addresses a significant challenge posed by the discrete observation of functional data at irregular time points, resulting in extensive missing data and diverse measurement schedules for subjects. Three specific problems associated with such data are examined: 1) Estimation of mean and covariance for functional snippet data, 2) Dynamic modeling for multivariate functional data, and 3) Prediction in functional linear models with sparsely observed covariates.</p>\n<p>Functional snippets frequently emerge in accelerated longitudinal studies (ALS), a prevalent approach in social science and health research for efficiently conducting experiments within a short timeframe, while extrapolating results to a more extended period of interest. Although ALS is cost-effective, existing methodologies have predominantly relied on parametric approaches. In contrast, our work on functional snippets, in two published papers in 2021 (Biometrika) and 2022 (Journal of the American Statistical Association), introduces two nonparametric approaches that offer increased flexibility over parametric methods. This mitigates the risk of model misspecifications and significantly impacting social sciences, health research, and any field employing accelerated longitudinal studies.</p>\n<p>In a newly accepted paper by the Journal of Econometrics, we studied the dynamic modeling for multivariate functional data, aiming to predict derivatives based on sparsely and irregularly measured multivariate functional data. This represents the first work in this domain, and we substantiate our findings with theoretical support. Additionally, we confront another open problem in predicting a scalar response through a functional linear model, where functional covariates are observed only sporadically and irregularly, possibly with measurement errors. &nbsp;Although this seems infeasible, we show in a submitted paper that a special imputation method can ensure consistent predictions and provide a quantifiable convergence rate.</p>\n<p>Functional data, commonly observed across scientific fields, often elude the grasp of general researchers and practitioners in other scientific fields. The methodologies and theory developed in this project address a critical void in the existing literature of statistical and machine learning. Furthermore, our research group at UC Davis is the developer and maintainer of the open-source R-package fdapace. This package contains a plethora of tools designed to facilitate the handling and analysis of functional data, even for those lacking an extensive theoretical background in FDA. This initiative significantly broadens the accessibility and the impact of our work.</p>\n<p>A total of 20 papers have been published or accepted for publications during the award period.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/13/2023<br>\nModified by: Jane-Ling&nbsp;Wang</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project tackles several challenges in Functional Data Analysis (FDA), a field dealing with random functions that have become increasingly prevalent due to advancements in handling massive datasets. The field has emerged as a mainstream research area, but the application of deep neural networks to functional data remains limited. The inherent infinite dimensionality of functional data means standard learning algorithms can be applied only after appropriate dimension reduction, typically achieved via basis expansions. Currently, these bases are chosen a priori without the information for the task at hand and thus may not be effective for the designated task. In a 2021 paper at the International Conference in Machine Learning, we propose to adaptively learn these bases in an end-to-end fashion. We introduce neural networks that employ a new Basis Layer whose hidden units are each basis functions themselves implemented as a micro neural network. Our architecture learns to apply parsimonious dimension reduction to functional inputs that focuses only on information relevant to the target rather than irrelevant variation in the input function. Across numerous classification and regression tasks involving functional data, our method empirically outperforms other types of neural networks, and we establish its statistically consistent with low generalization error.\n\n\nAdditionally, this project addresses a significant challenge posed by the discrete observation of functional data at irregular time points, resulting in extensive missing data and diverse measurement schedules for subjects. Three specific problems associated with such data are examined: 1) Estimation of mean and covariance for functional snippet data, 2) Dynamic modeling for multivariate functional data, and 3) Prediction in functional linear models with sparsely observed covariates.\n\n\nFunctional snippets frequently emerge in accelerated longitudinal studies (ALS), a prevalent approach in social science and health research for efficiently conducting experiments within a short timeframe, while extrapolating results to a more extended period of interest. Although ALS is cost-effective, existing methodologies have predominantly relied on parametric approaches. In contrast, our work on functional snippets, in two published papers in 2021 (Biometrika) and 2022 (Journal of the American Statistical Association), introduces two nonparametric approaches that offer increased flexibility over parametric methods. This mitigates the risk of model misspecifications and significantly impacting social sciences, health research, and any field employing accelerated longitudinal studies.\n\n\nIn a newly accepted paper by the Journal of Econometrics, we studied the dynamic modeling for multivariate functional data, aiming to predict derivatives based on sparsely and irregularly measured multivariate functional data. This represents the first work in this domain, and we substantiate our findings with theoretical support. Additionally, we confront another open problem in predicting a scalar response through a functional linear model, where functional covariates are observed only sporadically and irregularly, possibly with measurement errors. Although this seems infeasible, we show in a submitted paper that a special imputation method can ensure consistent predictions and provide a quantifiable convergence rate.\n\n\nFunctional data, commonly observed across scientific fields, often elude the grasp of general researchers and practitioners in other scientific fields. The methodologies and theory developed in this project address a critical void in the existing literature of statistical and machine learning. Furthermore, our research group at UC Davis is the developer and maintainer of the open-source R-package fdapace. This package contains a plethora of tools designed to facilitate the handling and analysis of functional data, even for those lacking an extensive theoretical background in FDA. This initiative significantly broadens the accessibility and the impact of our work.\n\n\nA total of 20 papers have been published or accepted for publications during the award period.\n\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 11/13/2023\n\n\t\t\t\t\tSubmitted by: Jane-LingWang\n"
 }
}