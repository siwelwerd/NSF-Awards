{
 "awd_id": "1946088",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: Small: Reconfigurable In-Sensor Architectures for High Speed and Low Power In-situ Image Analysis",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2019-06-14",
 "awd_exp_date": "2022-10-31",
 "tot_intn_awd_amt": 273815.0,
 "awd_amount": 384763.0,
 "awd_min_amd_letter_date": "2019-08-16",
 "awd_max_amd_letter_date": "2021-05-19",
 "awd_abstract_narration": "Cameras are pervasively used for surveillance and monitoring applications and can capture a substantial amount of image data. The processing of this data, however, is either performed a posteriori or at powerful backend servers. While a posteriori and non-real-time video analysis may be sufficient for certain groups of applications, it does not suffice for applications such as autonomous navigation in complex environments, or hyper spectral image analysis using cameras on drones, that require near real-time video and image analysis, sometimes under SWAP (Size Weight and Power) constraints. \r\n\r\nThis work hypothesizes that future data challenges in real-time imaging can be overcome by pushing computation into the image sensor. Such systems will exploit the massive parallel nature of sensor arrays to reduce the amount of data analyzed at the processing unit. To this end, vertically integrated technology, such as focal plane sensor processors (FPSP), have been developed to overcome the limitations of conventional image processing systems. While some of these devices are programmable and offer the benefits of close-to-sensor processing such as performance and bandwidth reduction, they exhibit many drawbacks. For instance, each column of pixels is handled by a single processor, which reduces the parallelism and all pixels are treated equally and processed at the same rate, despite differences in input relevance for the application at hand. Consequently, systems spend more time spinning on non-relevant data, which increases sensing and computation time and power consumption. Research on FPSPs has mostly focused on technology aspects with some proof of concepts. Architectural design approaches, that involve high-level synthesis with the goal of mapping applications to low-level architectures, have not gained a lot of attention.\r\n\r\nTo overcome the limitations of existing architectures, the goal of this research is the design of a highly parallel, hierarchical, reconfigurable and vertically-integrated 3D sensing-computing architecture (XPU), along with high-level synthesis methods for real-time, low-power video analysis. The architecture is composed of hierarchical intertwined planes, each of which consists of computational units called XPUs. The lowest-level plane processes pixels in parallel to determine low level shapes in an image while higher-level planes use outputs from low-level planes to infer global features in the image. The proposed architecture presents three novel contributions: a hierarchical, configurable architecture for parallel feature extraction in video streams, a machine learning based relevance-feedback method that adapts computational performance and resource usage to input data relevance, and a framework for converting sequential image processing algorithms to multiple layers of parallel computational processing units in the sensor. \r\n\r\nThe results of this projects can be used in other fields, where large amounts of processing need to be performed on data collected by generic sensors deployed in the field. Furthermore, mechanisms for translating sequential constructs into functionally equivalent accelerators using hardware constructs will lead to highly parallel and efficient sensing units that can perform domain specific tasks more efficiently.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christophe",
   "pi_last_name": "Bobda",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christophe Bobda",
   "pi_email_addr": "cbobda@ufl.edu",
   "nsf_id": "000583623",
   "pi_start_date": "2019-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "336A Larsen Hall",
  "perf_city_name": "Gainesville",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326116200",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 91864.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 165950.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 94948.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Over the period of performance, various design of the smart-sensor in-situ image processing was explored, and some implemented, using various technologies. We settled down on a final architecture on 2 planes, instead of 3 as initially designed with the region processing units (RPU) encapsulating the pixel processing units (PPU) functions in their implementation on the second plane. This architecture demonstrates hierarchical processing in the readout circuit of a pixel-parallel image sensor implemented by Sony and Olympus. The execution procedure is split into two logical layers: Attention-Based Preprocessing Layer (APL) and Inference Computation Layer (ICL). The sensor performs readout after completing the hierarchical operations in these two layers. The APL works on an M&times;N image which is logically split into M smaller image patches or regions. Each region is identical and has a 2D array of N pixels. Next, the ICL computational layer has an array of region inference engines (RIE). Only the relevant regions are mapped into the RIEs. A fully connected neural network (FcNN) sequentially receives the output from each RIE. These hardware modules are combined with an embedded processor and create a system on chip (SoC) environment.</p>\n<p>In addition to the high-level inference processing for image classification, the research investigates security primitives in the sensor for time-critical secure communication with external devices. We apply an attention-based encryption system to enhance data confidentiality and integrity.</p>\n<p>The high-level inference model which is the third layer of the proposed design on FPGA and ASIC platform and developed a simulator as a proof of concept. We leverage the event detection model with the inference architecture and developed the new concept of learning which introduces edge intelligence</p>\n<p>The project has supported 3 PhD students and 1 master student with thesis and 3 other non-master students, one of whom was a female African American PhD student.</p>\n<p>Beside the core research activities, we conducted a various activity such as the design of a new class in robotics, the organization of summer camps with high-school students in robotics in 2021 and 2022 to increase the impact of the project.</p>\n<p>Initiate a collaboration with a neuroscientist for a better understanding of brain processes and elaboration of computational models for direct integration in the sensor.</p>\n<p>The project also generated 8 journals and eleven conference publications in leading venues in the field of system-on-chip, computer architecture, image processing and FPGA. Among the produced work, one received a paper award at the FCCM-21 r, the second one received the best poster award at the EVW at CVPR in 2018, and the third one received the second place in poster competition at the Warren B Nelms Annual IoT Conference, 2019, Gainesville, Florida</p>\n<p>The results of this research have impacted other fields like 1) missile detection and very small images in cluttered environment and 2) neuroscience where the technology is used in calcium imaging for fast scan Start a collaboration with a company for better understanding the neuromorphic computation on the chip.</p>\n<p>A patent was filled, and a startup was created to gather resources to finalize the development and commercialization of the technology.</p>\n<p>The results of this project have been disseminated through the project webpage and publication at conferences and journals.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/10/2023<br>\n\t\t\t\t\tModified by: Christophe&nbsp;Bobda</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOver the period of performance, various design of the smart-sensor in-situ image processing was explored, and some implemented, using various technologies. We settled down on a final architecture on 2 planes, instead of 3 as initially designed with the region processing units (RPU) encapsulating the pixel processing units (PPU) functions in their implementation on the second plane. This architecture demonstrates hierarchical processing in the readout circuit of a pixel-parallel image sensor implemented by Sony and Olympus. The execution procedure is split into two logical layers: Attention-Based Preprocessing Layer (APL) and Inference Computation Layer (ICL). The sensor performs readout after completing the hierarchical operations in these two layers. The APL works on an M&times;N image which is logically split into M smaller image patches or regions. Each region is identical and has a 2D array of N pixels. Next, the ICL computational layer has an array of region inference engines (RIE). Only the relevant regions are mapped into the RIEs. A fully connected neural network (FcNN) sequentially receives the output from each RIE. These hardware modules are combined with an embedded processor and create a system on chip (SoC) environment.\n\nIn addition to the high-level inference processing for image classification, the research investigates security primitives in the sensor for time-critical secure communication with external devices. We apply an attention-based encryption system to enhance data confidentiality and integrity.\n\nThe high-level inference model which is the third layer of the proposed design on FPGA and ASIC platform and developed a simulator as a proof of concept. We leverage the event detection model with the inference architecture and developed the new concept of learning which introduces edge intelligence\n\nThe project has supported 3 PhD students and 1 master student with thesis and 3 other non-master students, one of whom was a female African American PhD student.\n\nBeside the core research activities, we conducted a various activity such as the design of a new class in robotics, the organization of summer camps with high-school students in robotics in 2021 and 2022 to increase the impact of the project.\n\nInitiate a collaboration with a neuroscientist for a better understanding of brain processes and elaboration of computational models for direct integration in the sensor.\n\nThe project also generated 8 journals and eleven conference publications in leading venues in the field of system-on-chip, computer architecture, image processing and FPGA. Among the produced work, one received a paper award at the FCCM-21 r, the second one received the best poster award at the EVW at CVPR in 2018, and the third one received the second place in poster competition at the Warren B Nelms Annual IoT Conference, 2019, Gainesville, Florida\n\nThe results of this research have impacted other fields like 1) missile detection and very small images in cluttered environment and 2) neuroscience where the technology is used in calcium imaging for fast scan Start a collaboration with a company for better understanding the neuromorphic computation on the chip.\n\nA patent was filled, and a startup was created to gather resources to finalize the development and commercialization of the technology.\n\nThe results of this project have been disseminated through the project webpage and publication at conferences and journals.\n\n \n\n\t\t\t\t\tLast Modified: 03/10/2023\n\n\t\t\t\t\tSubmitted by: Christophe Bobda"
 }
}