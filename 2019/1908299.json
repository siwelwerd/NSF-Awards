{
 "awd_id": "1908299",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Modeling Multi-Level Connectivity of Brain Dynamics",
 "cfda_num": "47.041, 47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-12-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 823000.0,
 "awd_min_amd_letter_date": "2019-09-08",
 "awd_max_amd_letter_date": "2024-07-21",
 "awd_abstract_narration": "The temporal dynamics of blood flows through the network of cerebral arteries and veins provides a window into the health of the human brain. Since the brain is vulnerable to disrupted blood supply, brain dynamics serves as a crucial indicator for many kinds of neurological diseases such as stroke, brain cancer, and Alzheimer's disease. Existing efforts at characterizing brain dynamics have predominantly centered on 'isolated' models in which data from single-voxel, single-modality, and single-subject are characterized. However, the brain is a vast network, naturally connected on structural and functional levels, and multimodal imaging provides complementary information on this natural connectivity. Thus, the current isolated models are deemed not capable of offering the platform necessary to enable many of the potential advancements in understanding, diagnosing, and treating neurological and cognitive diseases, leaving a critical gap between the current computational modeling capabilities and the needs in brain dynamics analysis. This project aims to bridge this gap by exploiting multi-scale structural (voxel, vasculature, tissue) connectivity and multi-modal (anatomical, angiography, perfusion) connectivity to develop an integrated connective computational paradigm for characterizing and understanding brain dynamics.\r\n\r\nThe approach consists of three thrusts: (1) multi-scale structural connectivity modeling to quantify brain dynamics beyond a single voxel; (2) multimodal dynamic dictionary learning for mining hidden complementary information; and (3) multicenter evaluation to assess the efficacy of the proposed models at three nationally renowned healthcare systems. Successful project completion would potentially transform the rapidly evolving field of brain dynamics modeling, facilitate basic neuroscience discovery and enable comprehensive identification of neurovascular diseases. Aiming to broaden its impact this project will also implement educational initiatives to expose students, middle school teachers, and medical professionals to 'CS for All,' to foster interests in STEM and cross-disciplinary careers, and to promote research on the convergence of computer science and computational thinking for brain health and neuromedicine.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ruogu",
   "pi_last_name": "Fang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ruogu Fang",
   "pi_email_addr": "ruogu.fang@bme.ufl.edu",
   "nsf_id": "000678411",
   "pi_start_date": "2019-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mingzhou",
   "pi_last_name": "Ding",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mingzhou Ding",
   "pi_email_addr": "mding@bme.ufl.edu",
   "nsf_id": "000235088",
   "pi_start_date": "2019-09-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1 University of Florida",
  "perf_city_name": "Gainesville",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326112002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  },
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1504",
   "pgm_ref_txt": "GRANT OPP FOR ACAD LIA W/INDUS"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "170E",
   "pgm_ref_txt": "Interagency Agreements"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "019Z",
   "pgm_ref_txt": "Grad Prep APG:Enhan. Experience"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 500000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 126000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 126000.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 55000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Over the course of this NSF-funded project, we have made substantial advancements in modeling multi-level brain connectivity using cutting-edge artificial intelligence (AI) and machine learning (ML) techniques. Our primary aim has been to develop a novel computational framework that captures brain dynamics through the integration of structural and modality-level neuroimaging data. Through this work, we have achieved notable intellectual merit in developing scalable, interpretable, and clinically relevant computational models for the study of the human brain.</p>\r\n<p>We successfully developed a multi-scale structural connectivity framework that accounts for spatial similarity and temporal correlation across voxel, vasculature, and tissue levels. This has led to improvements in head tissue segmentation using deep neural networks, resulting in enhanced accuracy in the delineation of neuroanatomical structures, especially in aging populations. Our team introduced advanced segmentation models such as DOMINO and DOMINO++ and demonstrated their clinical applicability in neurodegenerative disease assessment.</p>\r\n<p>On the multimodal front, we developed MAGIC, an AI-driven tool that generates contrast-free CT perfusion maps using non-contrast CT images. The tool has been trained on over 13,000 patient scans and evaluated through both quantitative metrics and physician-led subjective analysis. It represents a leap forward in reducing patient risk while maintaining diagnostic accuracy in stroke imaging. These efforts have resulted in multiple publications and ongoing collaborations with external research institutions.</p>\r\n<p>We also made pioneering strides in neuroscience-inspired AI. Notably, we developed and validated models mimicking artificial neuron selectivity and affective conditioning, bridging biological and computational neuroscience. The Visual Cortex-Amygdala model has shown promising results in replicating Pavlovian emotional conditioning, enabling deeper exploration of emotion encoding in AI systems.</p>\r\n<p>Broadening the scope, we developed a large-scale foundation model trained on over 80,000 MRI scans. Leveraging state-of-the-art transformer architectures, the model has outperformed baselines in multiple neuroimaging benchmarks such as BraTS and ADNI, offering a scalable solution for automated analysis of medical images across diverse applications.</p>\r\n<p>Beyond algorithmic advancements, our project had significant broader impacts. We created and curated a multimodal stroke imaging database of over 13,000 de-identified subjects and developed open-source tools to support reproducible research. Our team mentored over 20 students, including undergraduates, master&rsquo;s, and Ph.D. trainees, many of whom received national recognition, such as the NSF-GRFP, NIH F31, NIH T32, and IEEE NextGen Scholar Awards. Several students were supported through NSF INTERN supplements, promoting industry engagement and translational research experience.</p>\r\n<p>Research outcomes were disseminated through more than 60 publications and presentations at top venues such as MICCAI, RSNA, SfN, BMES, and Brain Stimulation. These efforts have not only pushed the frontier of brain modeling research but also ensured meaningful impact across clinical, educational, and technological domains. As a result, the project has set a strong foundation for next-generation neuroimaging and AI applications in medicine.</p><br>\n<p>\n Last Modified: 03/28/2025<br>\nModified by: Ruogu&nbsp;Fang</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743192975628_Figure3--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743192975628_Figure3--rgov-800width.png\" title=\"Visual Cortex\ufffdAmygdala model\"><img src=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743192975628_Figure3--rgov-66x44.png\" alt=\"Visual Cortex\ufffdAmygdala model\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Visual Cortex\ufffdAmygdala model simulating affective conditioning through image-cue associations. The model learns to associate visual quadrant cues with emotional valence and successfully recalls learned emotional patterns. Results show statistically significant decoding of pleasant vs. unpleasant emo</div>\n<div class=\"imageCredit\">Ruogu Fang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ruogu&nbsp;Fang\n<div class=\"imageTitle\">Visual Cortex\ufffdAmygdala model</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743192901947_Figure2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743192901947_Figure2--rgov-800width.png\" title=\"MAGIC\"><img src=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743192901947_Figure2--rgov-66x44.png\" alt=\"MAGIC\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">MAGIC pipeline overview for synthesizing contrast-free CT perfusion maps from non-contrast CT images.</div>\n<div class=\"imageCredit\">Ruogu Fang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ruogu&nbsp;Fang\n<div class=\"imageTitle\">MAGIC</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743193030066_Figure4--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743193030066_Figure4--rgov-800width.png\" title=\"BrainSegFounder\"><img src=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743193030066_Figure4--rgov-66x44.png\" alt=\"BrainSegFounder\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Study design of BrainSegFounder, a large-scale foundation model for neuroimage segmentation. The model is pretrained on over 80,000 healthy brain MRIs from the UK Biobank (UKB) using self-supervised learning (Stage 1), adapted to smaller clinical datasets (Stage 2), and fine-tuned on labeled medical</div>\n<div class=\"imageCredit\">Ruogu Fang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ruogu&nbsp;Fang\n<div class=\"imageTitle\">BrainSegFounder</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743192845636_Figure1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743192845636_Figure1--rgov-800width.png\" title=\"DOMINO++\"><img src=\"/por/images/Reports/POR/2025/1908299/1908299_10640624_1743192845636_Figure1--rgov-66x44.png\" alt=\"DOMINO++\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Segmentation results of our novel pipelines. Reference segmentation: the MR-derived manually corrected reference, Base Model: A standard transformer-based approach, DOMINO: our first novelty and contribution area.</div>\n<div class=\"imageCredit\">Skylar E. Stolte, Kyle Volle, Aprinda Indahlastari, Alejandro Albizu, Adam J. Woods, Kevin Brink, Matthew Hale, Ruogu Fang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ruogu&nbsp;Fang\n<div class=\"imageTitle\">DOMINO++</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nOver the course of this NSF-funded project, we have made substantial advancements in modeling multi-level brain connectivity using cutting-edge artificial intelligence (AI) and machine learning (ML) techniques. Our primary aim has been to develop a novel computational framework that captures brain dynamics through the integration of structural and modality-level neuroimaging data. Through this work, we have achieved notable intellectual merit in developing scalable, interpretable, and clinically relevant computational models for the study of the human brain.\r\n\n\nWe successfully developed a multi-scale structural connectivity framework that accounts for spatial similarity and temporal correlation across voxel, vasculature, and tissue levels. This has led to improvements in head tissue segmentation using deep neural networks, resulting in enhanced accuracy in the delineation of neuroanatomical structures, especially in aging populations. Our team introduced advanced segmentation models such as DOMINO and DOMINO++ and demonstrated their clinical applicability in neurodegenerative disease assessment.\r\n\n\nOn the multimodal front, we developed MAGIC, an AI-driven tool that generates contrast-free CT perfusion maps using non-contrast CT images. The tool has been trained on over 13,000 patient scans and evaluated through both quantitative metrics and physician-led subjective analysis. It represents a leap forward in reducing patient risk while maintaining diagnostic accuracy in stroke imaging. These efforts have resulted in multiple publications and ongoing collaborations with external research institutions.\r\n\n\nWe also made pioneering strides in neuroscience-inspired AI. Notably, we developed and validated models mimicking artificial neuron selectivity and affective conditioning, bridging biological and computational neuroscience. The Visual Cortex-Amygdala model has shown promising results in replicating Pavlovian emotional conditioning, enabling deeper exploration of emotion encoding in AI systems.\r\n\n\nBroadening the scope, we developed a large-scale foundation model trained on over 80,000 MRI scans. Leveraging state-of-the-art transformer architectures, the model has outperformed baselines in multiple neuroimaging benchmarks such as BraTS and ADNI, offering a scalable solution for automated analysis of medical images across diverse applications.\r\n\n\nBeyond algorithmic advancements, our project had significant broader impacts. We created and curated a multimodal stroke imaging database of over 13,000 de-identified subjects and developed open-source tools to support reproducible research. Our team mentored over 20 students, including undergraduates, masters, and Ph.D. trainees, many of whom received national recognition, such as the NSF-GRFP, NIH F31, NIH T32, and IEEE NextGen Scholar Awards. Several students were supported through NSF INTERN supplements, promoting industry engagement and translational research experience.\r\n\n\nResearch outcomes were disseminated through more than 60 publications and presentations at top venues such as MICCAI, RSNA, SfN, BMES, and Brain Stimulation. These efforts have not only pushed the frontier of brain modeling research but also ensured meaningful impact across clinical, educational, and technological domains. As a result, the project has set a strong foundation for next-generation neuroimaging and AI applications in medicine.\t\t\t\t\tLast Modified: 03/28/2025\n\n\t\t\t\t\tSubmitted by: RuoguFang\n"
 }
}