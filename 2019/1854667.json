{
 "awd_id": "1854667",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Aggregated Monte Carlo: A General Framework for Distributed Bayesian Inference in Massive Spatiotemporal Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2019-06-15",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 188016.0,
 "awd_amount": 188016.0,
 "awd_min_amd_letter_date": "2019-06-10",
 "awd_max_amd_letter_date": "2019-06-10",
 "awd_abstract_narration": "With tremendous advancements in spatial referencing technologies such as Global Positioning Systems that can identify geographical coordinates with a simple hand-held device, researchers in various disciplines have gathered an unprecedented variety of geo-coded temporal data. Consequently, modeling spatiotemporal data with flexible statistical models has become an enormously active area of research over the last decade in many disciplines including the environmental sciences, health sciences and oceanography, among others. In all these applications, researchers require efficient data modeling tools that can adapt to the complexity and size of modern spatiotemporal data, empowering them to quickly fit a variety of scientific models that explain the intricate nature of associations. This research project develops a new class of distributed Bayesian statistical algorithms, the Aggregated Monte Carlo (AMC), that enables efficient modeling of massive spatiotemporal data on an unprecedented scale. While the motivation of the PIs comes primarily from complex modeling and uncertainty quantification of massive spatiotemporal data, the proposed algorithm is general enough to set important footprints in the related literature of machine learning and computer experiments. The overarching goal also includes the development of software toolkits to better serve practitioners in related disciplines. \r\n\r\nThere has been an explosion in the size, complexity, and availability of spatiotemporally indexed data. This event has outpaced the development in Bayesian statistical methodology in that the fitting of state-of-the-art methods based on stochastic processes for analyzing spatiotemporal point referenced and point process data is prohibitively slow unless restrictive assumptions are imposed. The main problem is that the Monte Carlo (MC) computations in Markov chain Monte Carlo (MCMC) methods for fitting these models scale poorly with the size of the data. Solving this problem, the PIs develop a general framework, called Aggregated Monte Carlo (AMC), for scaling MC computations in the stochastic process-based modeling of massive space-time data using a divide-and-conquer technique. AMC has three stages that involve dividing the data into smaller subsets, obtaining posterior samples of the unknown parameters and latent variables across all the subsets using MCMC, and combining the MCMC samples from all the subsets. AMC is tuned to boost the scalability of any state-of-the-art model based on a stochastic process using a divide-and-conquer technique. Computationally, the main innovations include the development of general division and combination schemes for data with diverse spatiotemporal structures. Theoretically, the project provides bounds on the number of subsets such that the posterior distribution estimated using AMC provides a near optimal approximation of the full data posterior distribution in terms of decay of the posterior risks and contraction rates. Conceptually, AMC provides a natural extension of the existing results for combination using the barycenter of subset posterior distributions in parametric models to non-parametric models with complex spatiotemporal structures. The most appealing features of AMC are that it exploits parallel computer architecture for efficient and flexible modeling of massive spatiotemporal data and it provides posterior inference and uncertainty estimates with theoretical guarantees.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanvesh",
   "pi_last_name": "Srivastava",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sanvesh Srivastava",
   "pi_email_addr": "sanvesh-srivastava@uiowa.edu",
   "nsf_id": "000733434",
   "pi_start_date": "2019-06-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Iowa",
  "inst_street_address": "105 JESSUP HALL",
  "inst_street_address_2": "",
  "inst_city_name": "IOWA CITY",
  "inst_state_code": "IA",
  "inst_state_name": "Iowa",
  "inst_phone_num": "3193352123",
  "inst_zip_code": "522421316",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IA01",
  "org_lgl_bus_name": "THE UNIVERSITY OF IOWA",
  "org_prnt_uei_num": "",
  "org_uei_num": "Z1H9VJS8NG16"
 },
 "perf_inst": {
  "perf_inst_name": "The University of Iowa",
  "perf_str_addr": "241 Schaeffer Hall",
  "perf_city_name": "Iowa City",
  "perf_st_code": "IA",
  "perf_st_name": "Iowa",
  "perf_zip_code": "522421409",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IA01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 188016.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span style=\"text-decoration: underline;\"><strong>Overview:</strong></span>&nbsp;Technological progress has paved the way for collecting large and complex datasets across all disciplines, intensifying the focus on hierarchical Bayesian models due to their flexibility and interoperability; however, inference and predictions in these models using traditional Monte Carlo algorithms are inefficient due to the need for multiple passes through the entire dataset in each iteration. To overcome this challenge, the PI's group has developed extensions of these Monte Carlo algorithms leveraging distributed and asynchronous computations. These enhanced algorithms facilitate efficient posterior inference and predictions in parametric and nonparametric models under mild assumptions. Their key strength lies in their broad applicability, as they are not tied to any data-specific constraints or features.</p>\n<p><span style=\"text-decoration: underline;\"><strong>Intellectual Merit:</strong></span> <span><span>This project has significantly advanced distributed Bayesian inference across three key areas. First, the PI's group has developed divide-and-conquer algorithms for independent and dependent data models, such as varying coefficients and hidden Markov models. Second, they have introduced the asynchronous and distributed data augmentation framework for scaling existing data augmentation algorithms using distributed computing. Demonstrating its broad applicability, the PI's group has used it for efficient Bayesian inference in high-dimensional variable selection, logistic regression, and linear mixed-effects models. These algorithms eliminate a key drawback of traditional divide-and-conquer methods by guaranteeing that the distance between the target and estimated posterior distributions becomes negligible, provided that the data augmentation algorithm runs sufficiently long. Finally, for the seamless use and widespread adoption of these algorithms, the PI's group has established theoretical guarantees for the asymptotic optimality of these algorithms under mild assumptions. The PI's group is applying these methodologies in collaborative projects to analyze complex biomedical datasets. The research outcomes of this project have been published in top-ranking machine learning and statistics journals.</span></span></p>\n<p><span style=\"text-decoration: underline;\"><strong>Broader Impacts:&nbsp;</strong></span><span>The project yields dual benefits in data science education and biomedical research. On the educational front, the PI has mentored a diverse range of students, from doctoral to undergraduate levels. Post-graduation, these students have found employment across academia and industry, broadening the real-world impact of data science. Additionally, the PI has developed a new data science course at the University of Iowa, incorporating some project-related materials. This course has been integrated into the standard curricula for bachelor's and master's programs in data science at the university. Furthermore, the PI has made the project's code publicly accessible on Github, facilitating its use by professional data scientists. On the biomedical research front, the project has led to collaborations with nursing&nbsp;researchers and behavioral scientists at the university, enabling the application of statistical methodologies developed in this project to analyze electronic health records and genetic, epigenetic, and neuroimaging data collected in behavioral experiments.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/28/2023<br>\n\t\t\t\t\tModified by: Sanvesh&nbsp;Srivastava</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOverview: Technological progress has paved the way for collecting large and complex datasets across all disciplines, intensifying the focus on hierarchical Bayesian models due to their flexibility and interoperability; however, inference and predictions in these models using traditional Monte Carlo algorithms are inefficient due to the need for multiple passes through the entire dataset in each iteration. To overcome this challenge, the PI's group has developed extensions of these Monte Carlo algorithms leveraging distributed and asynchronous computations. These enhanced algorithms facilitate efficient posterior inference and predictions in parametric and nonparametric models under mild assumptions. Their key strength lies in their broad applicability, as they are not tied to any data-specific constraints or features.\n\nIntellectual Merit: This project has significantly advanced distributed Bayesian inference across three key areas. First, the PI's group has developed divide-and-conquer algorithms for independent and dependent data models, such as varying coefficients and hidden Markov models. Second, they have introduced the asynchronous and distributed data augmentation framework for scaling existing data augmentation algorithms using distributed computing. Demonstrating its broad applicability, the PI's group has used it for efficient Bayesian inference in high-dimensional variable selection, logistic regression, and linear mixed-effects models. These algorithms eliminate a key drawback of traditional divide-and-conquer methods by guaranteeing that the distance between the target and estimated posterior distributions becomes negligible, provided that the data augmentation algorithm runs sufficiently long. Finally, for the seamless use and widespread adoption of these algorithms, the PI's group has established theoretical guarantees for the asymptotic optimality of these algorithms under mild assumptions. The PI's group is applying these methodologies in collaborative projects to analyze complex biomedical datasets. The research outcomes of this project have been published in top-ranking machine learning and statistics journals.\n\nBroader Impacts: The project yields dual benefits in data science education and biomedical research. On the educational front, the PI has mentored a diverse range of students, from doctoral to undergraduate levels. Post-graduation, these students have found employment across academia and industry, broadening the real-world impact of data science. Additionally, the PI has developed a new data science course at the University of Iowa, incorporating some project-related materials. This course has been integrated into the standard curricula for bachelor's and master's programs in data science at the university. Furthermore, the PI has made the project's code publicly accessible on Github, facilitating its use by professional data scientists. On the biomedical research front, the project has led to collaborations with nursing researchers and behavioral scientists at the university, enabling the application of statistical methodologies developed in this project to analyze electronic health records and genetic, epigenetic, and neuroimaging data collected in behavioral experiments.\n\n\t\t\t\t\tLast Modified: 09/28/2023\n\n\t\t\t\t\tSubmitted by: Sanvesh Srivastava"
 }
}