{
 "awd_id": "1931441",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Medium: Collaborative: User-Centered Deployment of Differential Privacy",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2020-01-01",
 "awd_exp_date": "2023-12-31",
 "tot_intn_awd_amt": 80145.0,
 "awd_amount": 96145.0,
 "awd_min_amd_letter_date": "2019-08-16",
 "awd_max_amd_letter_date": "2023-04-30",
 "awd_abstract_narration": "Differential privacy (DP) has been accepted as the de facto standard for data privacy in the research community and beyond. Both companies and government agencies are trying to deploy DP technologies.  Broader deployments of DP technology, however, face challenges.  This project aims to understand the needs of different stakeholders in data  privacy, and to develop algorithms and software to enable broader deployment of private data sharing.  The project's novelty is combining the expertise of social science researchers with that of computer scientists who have both theoretical and system research experiences related to DP to develop a hybrid approach to private data sharing to achieve better privacy-utility tradeoff.  The project's impacts are in advancing the state-of-the-art with regard to DP deployment in particular and privacy protection in general.  More specifically the project identifies the workflow of DP data sharing, improve understanding of DP communication, and develop new algorithms, privacy concepts, and privacy mechanisms to support deployment of DP. \r\n \r\nThe project has four tasks that will advance the understanding of user-centered DP and lay a foundation for its deployment. (1) Examine individual human users' perception, comprehension and acceptance of the concept and guarantee of DP and the effect of privacy parameter, and to investigate effective ways to communicate those concepts.  (2) Implement methods from the domains of human factors and human-computer interaction to identify tasks, goals, and workflow in private data sharing.   (3) Develop key algorithms and software for a hybrid approach of private data sharing.  In the hybrid approach, one first publishes a private synopsis of dataset using carefully selected low-degree marginals.  From these marginals, one can either synthesize new datasets, or answer queries directly using inference under the maximum entropy principle.  The hybrid approach enhances this with interactive query answering, enabling extraction of information not covered by low-degree marginals.  (4) Develop techniques to further improve the privacy-utility tradeoff in private data sharing, including a theory of differential privacy under publishable information.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aiping",
   "pi_last_name": "Xiong",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aiping Xiong",
   "pi_email_addr": "axx29@psu.edu",
   "nsf_id": "000784636",
   "pi_start_date": "2019-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "110 Technology Center Building",
  "perf_city_name": "University Park",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168021503",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "PA15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 80145.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">Differential Privacy (DP) has been accepted as the de facto standard for data privacy in the research community and beyond.&nbsp; Companies and government agencies are starting to deploy DP technologies.&nbsp; To facilitate the broader deployments of DP technology, in this project, we aim to 1) advance the understanding of user-centered differential privacy (DP) and 2) understand the needs of different stakeholders in data privacy.&nbsp; To achieve the goals, we have investigated three topics and obtained significant results as follows.&nbsp;</p>\n<p class=\"p1\">1. Textual communication of DP<span>&nbsp; </span>to end users</p>\n<p class=\"p1\">Using a health app data collection setting, we proposed different textual descriptions of central DP and local DP and evaluated online participants' comprehension of the concepts and their data disclosure rates as a function of the description.&nbsp; The overall results revealed that lay people have difficulty understanding the DP definitions, especially the perturbation processes of adding noise.&nbsp; However, communication of implications was effective, especially in helping the participants understand which technique provides better privacy protection.<span>&nbsp;</span></p>\n<p class=\"p1\">Following our findings, a few studies have further investigated communicating DP using text descriptions (e.g., Cummings et al., 2021; Franzen et al., 2022).&nbsp; In particular, Kuhtreiber et al. (2022) replicated our findings using a different sample in Germany.&nbsp; Our proposed descriptions have been used as control conditions in recent studies (e.g., Franze et al., 2020).&nbsp; In general, our proposed descriptions still show state-of-the-art performance. <span>&nbsp; &nbsp;</span></p>\n<p class=\"p1\">2. Visual communication of DP to end users</p>\n<p class=\"p1\">In addition to textual descriptions, we have explored different visual communication of DP.<span>&nbsp;</span></p>\n<p class=\"p1\">a) dotplots</p>\n<p class=\"p1\">Informed by the health risk communication literature, we started our evaluation using a facts box with dotplots.&nbsp; We used a barchart condition as a baseline, considering its wide use to communicate group-level statistics.&nbsp; The injected random noise was presented as the difference in bar heights. In the dotplot conditions, dots were used to present original data and added random noise.<span>&nbsp; &nbsp;</span>Using the same health app data collection setting, we conducted an online study and found that participants' data-sharing rates were slightly better than chance and showed no difference across conditions.&nbsp; While participants indicated that the visual communication was helpful for them to understand DP, their objective comprehension of DP was still worse than chance, revealing the limited effect of such visual communication.<span>&nbsp; &nbsp;</span>We also explored the dotplot design with undergraduate students at Penn State and obtained similar results.<span>&nbsp;</span></p>\n<p class=\"p1\">b) explanative illustrations and heatmap for privacy-utility tradeoff</p>\n<p class=\"p1\">Considering barcharts and dotplots only showed the results of DP,<span>&nbsp; </span>we also developed explanative illustrations showing <em>how</em> DP enhances privacy protection (at an individual level) and heatmaps showing <em>utility cost</em>&nbsp;of DP (at an aggregated level).&nbsp; We proposed the illustrations and heatmaps for three DP models (Central DP, Local DP, and Shuffler DP) in the context of location privacy setting.&nbsp;&nbsp;</p>\n<p class=\"p1\">With the explanative illustrations, participants had accurate perception of the privacy protection of different DP models.&nbsp; Interesting, we found that participants' preference for models depended on the model's presentation order, suggesting the importance of making different trust models available for users' informed privacy decisions (Xiong et al., 2023).&nbsp; We provided the first empirical evidence showing people's acceptance of the Shuffler DP model for data-privacy protection.<span>&nbsp; </span>The participants preferred stronger protection for data sharing in the commercial-interests scenarios than for the public-good scenario, indicating the necessity to communicate different selection choices to end users.<span>&nbsp;</span></p>\n<p class=\"p2\">Recently, our heatmap design has been further explored by Ashena et al. (2024) to communicate epsilon values of DP in the COVID-19 setting.&nbsp;</p>\n<p class=\"p1\">3. Researchers&rsquo; understanding and reactions to DP application<span>&nbsp;</span></p>\n<p class=\"p1\">Since the deployment of DP in the data of the 2020 U.S. Census, researchers expressed concerns as to how much the application of DP would impact their research. We conducted an online survey with researchers who published studies based on the 2010 U.S. census data or the American Community Survey (ACS) data. We found that most researchers were concerned about the tradeoff between the privacy protection and the usefulness of statistics obtained from the data set to which DP has been applied. Our results suggest that a lack of training might have resulted in participants' incorrect understanding of the relation between DP and usefulness of group statistics.<span>&nbsp;</span></p><br>\n<p>\n Last Modified: 04/21/2024<br>\nModified by: Aiping&nbsp;Xiong</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nDifferential Privacy (DP) has been accepted as the de facto standard for data privacy in the research community and beyond. Companies and government agencies are starting to deploy DP technologies. To facilitate the broader deployments of DP technology, in this project, we aim to 1) advance the understanding of user-centered differential privacy (DP) and 2) understand the needs of different stakeholders in data privacy. To achieve the goals, we have investigated three topics and obtained significant results as follows.\n\n\n1. Textual communication of DP to end users\n\n\nUsing a health app data collection setting, we proposed different textual descriptions of central DP and local DP and evaluated online participants' comprehension of the concepts and their data disclosure rates as a function of the description. The overall results revealed that lay people have difficulty understanding the DP definitions, especially the perturbation processes of adding noise. However, communication of implications was effective, especially in helping the participants understand which technique provides better privacy protection.\n\n\nFollowing our findings, a few studies have further investigated communicating DP using text descriptions (e.g., Cummings et al., 2021; Franzen et al., 2022). In particular, Kuhtreiber et al. (2022) replicated our findings using a different sample in Germany. Our proposed descriptions have been used as control conditions in recent studies (e.g., Franze et al., 2020). In general, our proposed descriptions still show state-of-the-art performance.  \n\n\n2. Visual communication of DP to end users\n\n\nIn addition to textual descriptions, we have explored different visual communication of DP.\n\n\na) dotplots\n\n\nInformed by the health risk communication literature, we started our evaluation using a facts box with dotplots. We used a barchart condition as a baseline, considering its wide use to communicate group-level statistics. The injected random noise was presented as the difference in bar heights. In the dotplot conditions, dots were used to present original data and added random noise. Using the same health app data collection setting, we conducted an online study and found that participants' data-sharing rates were slightly better than chance and showed no difference across conditions. While participants indicated that the visual communication was helpful for them to understand DP, their objective comprehension of DP was still worse than chance, revealing the limited effect of such visual communication. We also explored the dotplot design with undergraduate students at Penn State and obtained similar results.\n\n\nb) explanative illustrations and heatmap for privacy-utility tradeoff\n\n\nConsidering barcharts and dotplots only showed the results of DP, we also developed explanative illustrations showing how DP enhances privacy protection (at an individual level) and heatmaps showing utility costof DP (at an aggregated level). We proposed the illustrations and heatmaps for three DP models (Central DP, Local DP, and Shuffler DP) in the context of location privacy setting.\n\n\nWith the explanative illustrations, participants had accurate perception of the privacy protection of different DP models. Interesting, we found that participants' preference for models depended on the model's presentation order, suggesting the importance of making different trust models available for users' informed privacy decisions (Xiong et al., 2023). We provided the first empirical evidence showing people's acceptance of the Shuffler DP model for data-privacy protection. The participants preferred stronger protection for data sharing in the commercial-interests scenarios than for the public-good scenario, indicating the necessity to communicate different selection choices to end users.\n\n\nRecently, our heatmap design has been further explored by Ashena et al. (2024) to communicate epsilon values of DP in the COVID-19 setting.\n\n\n3. Researchers understanding and reactions to DP application\n\n\nSince the deployment of DP in the data of the 2020 U.S. Census, researchers expressed concerns as to how much the application of DP would impact their research. We conducted an online survey with researchers who published studies based on the 2010 U.S. census data or the American Community Survey (ACS) data. We found that most researchers were concerned about the tradeoff between the privacy protection and the usefulness of statistics obtained from the data set to which DP has been applied. Our results suggest that a lack of training might have resulted in participants' incorrect understanding of the relation between DP and usefulness of group statistics.\t\t\t\t\tLast Modified: 04/21/2024\n\n\t\t\t\t\tSubmitted by: AipingXiong\n"
 }
}