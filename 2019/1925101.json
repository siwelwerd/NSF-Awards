{
 "awd_id": "1925101",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ATD: Collaborative Research: Automatic, Adaptive Detection and Description of Change in Time-Lapse Imagery",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032924885",
 "po_email": "tbartosz@nsf.gov",
 "po_sign_block_name": "Tomek Bartoszynski",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 255656.0,
 "awd_amount": 255656.0,
 "awd_min_amd_letter_date": "2019-07-09",
 "awd_max_amd_letter_date": "2019-07-09",
 "awd_abstract_narration": "This project will provide algorithms for automatic, adaptive detection and description of changes in time-lapse imagery - a series of images obtained from the same scene over a long time frame. We wish to identify when there are \"significant\" changes in the scene, and provide a text description of those changes in natural English, where a human analyst provides feedback to determine what kinds of changes are important (e.g., a building being built, deforestation) or unimportant (e.g., seasonal changes). We will in particular focus on satellite or aerial imagery, for which data sets commonly used to train image recognition systems are inadequate. This fundamental research has the potential to transform many application domains, including surveillance, autonomous robotics, monitoring of civil infrastructure, high-throughput microscopy, and climate science, in all of which change is a common and significant occurrence. Our work on novel formulations of change description will also impact on core areas of computer vision and natural language processing, where many similar problems arise. The project will involve graduate students training and postdoctoral associate mentoring.\r\n\r\nDetecting change is one of the fundamental abilities for an agent perceiving and interacting with the world. Describing changes in natural language is key to making human interaction with such an agent efficient, accurate and transparent. Our work will advance both the theoretical understanding of these goals and the practical methods for implementing them. Specifically, we will address the above challenges for developing novel mathematical frameworks for localizing gradual changes and describing those changes in natural language; we will develop theoretical and practical means to analyze and overcome corruption in observed imagery; and we will develop novel theory and methods for leveraging human feedback. This work will yield fundamental advances in the fields of change point detection and localization, image reconstruction using deep neural networks and limited training data, and multi-armed bandit methodology for adapting to human feedback.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rebecca",
   "pi_last_name": "Willett",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Rebecca M Willett",
   "pi_email_addr": "willett@g.uchicago.edu",
   "nsf_id": "000312123",
   "pi_start_date": "2019-07-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "5747 S. Ellis Ave.",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606371441",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": null,
 "pgm_ref": [
  {
   "pgm_ref_code": "6877",
   "pgm_ref_txt": "ALGORITHMS IN THREAT DETECTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 255656.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-d65d0012-7fff-e1b7-c98b-fb3f41ae192c\" style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This project was focused on developing novel machine learning tools for analyzing data from complex, dynamic environments. Examples include analyzing changes in a landscape captured by satellite imagery, recovering clean imagery from corrupted and indirect measurements, forecasting how an environment will change or evolve in coming days based on recent measurements, and automatically detecting subtle changes in complex, streaming data. Each of these tasks is complicated by the fact that data may be distorted so severely that human analysts cannot detect important characteristics without the support of sophisticated computer algorithms. Furthermore, some environments may be chaotic, so small perturbations in the current conditions can have outsize effects on future conditions. These and other challenges stymie off-the-shelf machine learning tools and necessitate the development of bespoke methodology. This project led to the development of a collection of new tools. One set of tools recovers high-quality images from corrupted data, such as data with missing or obscured pixels, blur, or indirect measurements such as those associated with radar imaging. Our work demonstrated how knowledge of the type of corruption can be integrated into machine learning pipelines to achieve higher accuracy with less training data. A second contribution involved learning how to make forecasts in a dynamic environment given only the current environment&rsquo;s state. Our work focused on settings with (a) indirect or corrupted measurements and (b) chaotic underlying processes with statistical properties that need to be preserved by the learned predictors. A third major thrust focused on change detection. Detecting when the underlying dynamics changes is a fundamental problem arising in a broad spectrum of threat detection applications, and our team developed a new theoretical understanding of how to approach such problems as well as novel algorithms and tools. Finally, these different efforts were integrated into new algorithms for automatic, adaptive detection and description of changes in time-lapse imagery. For instance, imagine a satellite passing over one location every day and taking a picture. We wish to identify when there are &ldquo;significant&rdquo; changes in the scene and provide a text description of those changes, where a human analyst provides feedback to determine what kinds of changes are important (e.g., a building being built) or unimportant (e.g., snow). One of our major outcomes was a learning-based approach to describing those changes in a manner that (a) improves the detection of changes beyond what is possible based solely on image analysis without change descriptions, (b) incorporates unlabeled data to yield strong performance even with a limited number of labeled samples, and (c) is robust to nuisance changes such as lighting or perspective shifts.</span></p><br>\n<p>\n Last Modified: 12/30/2023<br>\nModified by: Rebecca&nbsp;M&nbsp;Willett</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project was focused on developing novel machine learning tools for analyzing data from complex, dynamic environments. Examples include analyzing changes in a landscape captured by satellite imagery, recovering clean imagery from corrupted and indirect measurements, forecasting how an environment will change or evolve in coming days based on recent measurements, and automatically detecting subtle changes in complex, streaming data. Each of these tasks is complicated by the fact that data may be distorted so severely that human analysts cannot detect important characteristics without the support of sophisticated computer algorithms. Furthermore, some environments may be chaotic, so small perturbations in the current conditions can have outsize effects on future conditions. These and other challenges stymie off-the-shelf machine learning tools and necessitate the development of bespoke methodology. This project led to the development of a collection of new tools. One set of tools recovers high-quality images from corrupted data, such as data with missing or obscured pixels, blur, or indirect measurements such as those associated with radar imaging. Our work demonstrated how knowledge of the type of corruption can be integrated into machine learning pipelines to achieve higher accuracy with less training data. A second contribution involved learning how to make forecasts in a dynamic environment given only the current environments state. Our work focused on settings with (a) indirect or corrupted measurements and (b) chaotic underlying processes with statistical properties that need to be preserved by the learned predictors. A third major thrust focused on change detection. Detecting when the underlying dynamics changes is a fundamental problem arising in a broad spectrum of threat detection applications, and our team developed a new theoretical understanding of how to approach such problems as well as novel algorithms and tools. Finally, these different efforts were integrated into new algorithms for automatic, adaptive detection and description of changes in time-lapse imagery. For instance, imagine a satellite passing over one location every day and taking a picture. We wish to identify when there are significant changes in the scene and provide a text description of those changes, where a human analyst provides feedback to determine what kinds of changes are important (e.g., a building being built) or unimportant (e.g., snow). One of our major outcomes was a learning-based approach to describing those changes in a manner that (a) improves the detection of changes beyond what is possible based solely on image analysis without change descriptions, (b) incorporates unlabeled data to yield strong performance even with a limited number of labeled samples, and (c) is robust to nuisance changes such as lighting or perspective shifts.\t\t\t\t\tLast Modified: 12/30/2023\n\n\t\t\t\t\tSubmitted by: RebeccaMWillett\n"
 }
}