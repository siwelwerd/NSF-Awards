{
 "awd_id": "1936523",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Translating Compilers for Visual Computing in Dynamic Languages",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2018-07-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 20300.0,
 "awd_amount": 20300.0,
 "awd_min_amd_letter_date": "2019-06-24",
 "awd_max_amd_letter_date": "2019-06-24",
 "awd_abstract_narration": "This collaborative project is developing technologies to enable students, scientists, and other non-expert developers to use computer languages that facilitate rapid prototyping, and yet still automatically convert such programs to have high performance. In this research, the PI and co-PIs focus on programs that operate over visual data, such as programs in computer graphics, computer vision, and visualization. Visual data is important because visual datasets are rapidly growing in size, due to the use of cell-phone cameras, photo and video sharing online, and in scientific and medical imaging. The intellectual merits are that specialized program optimizations are being developed specifically for visual computing and for languages that enable rapid prototyping, alongside techniques that allow the computer to automatically search through different candidate optimizations and choose the fastest one. The project's broader significance and importance are that it will make the writing of computer programs that operate over visual datasets more accessible to novice programmers, make visual computing more accessible to a broader audience, permit faster research and development over visual programs, and make such programs themselves be more efficient.\r\n\r\nMore specifically, this research program is producing translating compilers that are specialized to handle programs that compute over visual data. The group led by the PI is researching new compilers that translate code from dynamic languages into highly efficient code in a target language. Dynamic languages are defined as those with a very dynamic run-time model, for example, MATLAB, Python, and Javascript. The target language is a language such as C that permits implementation of highly efficient programs. This research framework incorporates ideas from compilers, graphics, computer vision, visual perception, and formal and natural languages. The research will make a number of key intellectual contributions. First, new domain-specific translations and optimizations for visual computing will be formalized into manual rules that can be applied to any input program. Second, the team will research a novel approach of automatically learning translations, instead of using manually-coded rules. This can take the form of learning translation \"suggestions\" from humans, who can interactively suggest better output code. Third, a new search process based on offline auto-tuning will be used to select the translations that result in the fastest program. The success of the project will be verified against a comprehensive test suite of programs from computer vision and graphics.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Baishakhi",
   "pi_last_name": "Ray",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Baishakhi Ray",
   "pi_email_addr": "rayb@cs.columbia.edu",
   "nsf_id": "000701468",
   "pi_start_date": "2019-06-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "615 West 131st St.",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100277922",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 20300.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-574e309b-7fff-9516-0fd0-ca5967eb5e22\">\n<p dir=\"ltr\"><span>The proposal primarily aims to develop new compilers that translate code written in dynamic languages into highly efficient code in a target language. A secondary objective of the proposal was to search for necessary transformation from existing transformations and automatically learn them.&nbsp; There were four significant outcomes:</span></p>\n<p dir=\"ltr\"><span>[1] We build a novel domain-specific compiler, which translates visual computing programs written in dynamic languages (e.g., Python) to highly efficient code. Our compiler allows substantial performance gains (frequently orders of magnitude) over general compilers for dynamic languages by specializing the compiler for visual computation. Specifically, our compiler takes advantage of three key properties of visual computing programs, which permit optimizations: (1) many array data structures have small, constant, or bounded size, (2) many operations on visual data are supported in hardware or are embarrassingly parallel, and (3) humans are not sensitive to small numerical errors in visual outputs due to changing floating-point precisions. We show that dependent type analysis can be used to infer sizes and guide optimizations for many small-sized array operations that arise in visual programs. Programmers who are not experts on visual computation can use our compiler to produce more efficient Python programs than if they write manually parallelized C, with fewer lines of application logic.</span></p>\n<p dir=\"ltr\"><span>[2] We further introduce a general method to approximate the convolution of a program with a Gaussian kernel. This results in the program being smoothed. Our compiler framework models intermediate values in the program as random variables, by using mean and variance statistics. We decompose the input program into atomic parts and relate the statistics of the different parts of the smoothed program. We give several approximate smoothing rules that can be used for the parts of the program. We apply this framework to the problem of automatically band-limiting procedural shader programs. We evaluate our method on a variety of geometries and complex shaders, including shaders with parallax mapping, animation, and spatially varying statistics. The resulting smoothed shader programs outperform previous approaches both numerically and aesthetically.</span></p>\n<p dir=\"ltr\"><span>[3]&nbsp; We develop a technique to automate code translation by learning from existing translations.&nbsp; The advancement of Neural Machine Translation (NMT) and the availability of vast open-source evolutionary data open up the possibility of automatically learning translation templates from the wild. However, unlike natural languages, for which NMT techniques were originally devised, source code and its changes have certain properties. For instance, compared to natural language, source code vocabulary can be significantly larger. Further, good changes in code do not break its syntactic structure. Thus, deploying state-of-the-art NMT models without adapting the methods to the source code domain yields sub-optimal results. To this end, we propose a novel Tree-based NMT system to model source code changes and learn translation patterns from the wild. Our evaluation shows the effectiveness of the tool to automate code changes and generating bug fix patches.&nbsp;</span></p>\n<p dir=\"ltr\"><span>[4] The Michigan team focused on a two-pronged research effort: (1) translating compilers for hardware accelerators, and (2) bringing tool support for this new domain. For the former, significant research and industrial interest have focused on dealing with silicon limits and the end of Moore's Law and Dennard Scaling. One promising line of research is to favor hardware accelerators, such as GPUs, FPGAs, or custom Automata Processors, that admit a high degree of parallelism. Unfortunately, these devices can be difficult to program. Existing compilers, such as CUDA, are not always performance portable and do not always expose the right abstractions to programmers. We developed RAPID, a translating compiler for pattern-matching problems. RAPID is efficient, concise, and portable to multiple accelerator architectures. We also focused on reproducible research and broadening the impact of our advances through an open-source benchmark suite for this new field. Second, beyond translating compiler support, we also improved tool support for such new languages. Tools that automatically generate test inputs (e.g., fuzz testers like AFL or KLEE) and tools that automatically repair programs (e.g., Facebook's InFix, GenProg, etc.) are becoming increasingly popular. Such tools reduce the costs associated with software maintenance by helping to find bugs (testing) or remove them (automated program repair). However, such tool support can arrive slowly for new languages. In a strong theoretical result, we find that test input generation and template-based program repair are reducible problems, and thus tools developed for one can be used to solve the other, magnifying the impact and reach of both.</span></p>\n<p dir=\"ltr\"><span>We further leverage the knowledge gained from this project to advance the code search. We empirically evaluate how users search code as opposed to text in order to build a code search engine. We then build IR based techniques to search GitHub for relevant code. To this end, the interdisciplinary nature of the team helped bring together advances and applications in three different fields: Graphics, Software Engineering, and Machine Learning.&nbsp;</span></p>\n<br /></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/16/2020<br>\n\t\t\t\t\tModified by: Baishakhi&nbsp;Ray</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThe proposal primarily aims to develop new compilers that translate code written in dynamic languages into highly efficient code in a target language. A secondary objective of the proposal was to search for necessary transformation from existing transformations and automatically learn them.  There were four significant outcomes:\n[1] We build a novel domain-specific compiler, which translates visual computing programs written in dynamic languages (e.g., Python) to highly efficient code. Our compiler allows substantial performance gains (frequently orders of magnitude) over general compilers for dynamic languages by specializing the compiler for visual computation. Specifically, our compiler takes advantage of three key properties of visual computing programs, which permit optimizations: (1) many array data structures have small, constant, or bounded size, (2) many operations on visual data are supported in hardware or are embarrassingly parallel, and (3) humans are not sensitive to small numerical errors in visual outputs due to changing floating-point precisions. We show that dependent type analysis can be used to infer sizes and guide optimizations for many small-sized array operations that arise in visual programs. Programmers who are not experts on visual computation can use our compiler to produce more efficient Python programs than if they write manually parallelized C, with fewer lines of application logic.\n[2] We further introduce a general method to approximate the convolution of a program with a Gaussian kernel. This results in the program being smoothed. Our compiler framework models intermediate values in the program as random variables, by using mean and variance statistics. We decompose the input program into atomic parts and relate the statistics of the different parts of the smoothed program. We give several approximate smoothing rules that can be used for the parts of the program. We apply this framework to the problem of automatically band-limiting procedural shader programs. We evaluate our method on a variety of geometries and complex shaders, including shaders with parallax mapping, animation, and spatially varying statistics. The resulting smoothed shader programs outperform previous approaches both numerically and aesthetically.\n[3]  We develop a technique to automate code translation by learning from existing translations.  The advancement of Neural Machine Translation (NMT) and the availability of vast open-source evolutionary data open up the possibility of automatically learning translation templates from the wild. However, unlike natural languages, for which NMT techniques were originally devised, source code and its changes have certain properties. For instance, compared to natural language, source code vocabulary can be significantly larger. Further, good changes in code do not break its syntactic structure. Thus, deploying state-of-the-art NMT models without adapting the methods to the source code domain yields sub-optimal results. To this end, we propose a novel Tree-based NMT system to model source code changes and learn translation patterns from the wild. Our evaluation shows the effectiveness of the tool to automate code changes and generating bug fix patches. \n[4] The Michigan team focused on a two-pronged research effort: (1) translating compilers for hardware accelerators, and (2) bringing tool support for this new domain. For the former, significant research and industrial interest have focused on dealing with silicon limits and the end of Moore's Law and Dennard Scaling. One promising line of research is to favor hardware accelerators, such as GPUs, FPGAs, or custom Automata Processors, that admit a high degree of parallelism. Unfortunately, these devices can be difficult to program. Existing compilers, such as CUDA, are not always performance portable and do not always expose the right abstractions to programmers. We developed RAPID, a translating compiler for pattern-matching problems. RAPID is efficient, concise, and portable to multiple accelerator architectures. We also focused on reproducible research and broadening the impact of our advances through an open-source benchmark suite for this new field. Second, beyond translating compiler support, we also improved tool support for such new languages. Tools that automatically generate test inputs (e.g., fuzz testers like AFL or KLEE) and tools that automatically repair programs (e.g., Facebook's InFix, GenProg, etc.) are becoming increasingly popular. Such tools reduce the costs associated with software maintenance by helping to find bugs (testing) or remove them (automated program repair). However, such tool support can arrive slowly for new languages. In a strong theoretical result, we find that test input generation and template-based program repair are reducible problems, and thus tools developed for one can be used to solve the other, magnifying the impact and reach of both.\nWe further leverage the knowledge gained from this project to advance the code search. We empirically evaluate how users search code as opposed to text in order to build a code search engine. We then build IR based techniques to search GitHub for relevant code. To this end, the interdisciplinary nature of the team helped bring together advances and applications in three different fields: Graphics, Software Engineering, and Machine Learning. \n\n\n\n \n\n\t\t\t\t\tLast Modified: 03/16/2020\n\n\t\t\t\t\tSubmitted by: Baishakhi Ray"
 }
}