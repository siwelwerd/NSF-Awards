{
 "awd_id": "1929955",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CIF: RI: Small: Information-theoretic measures of dependencies and novel sample-based estimators",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2019-01-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2019-06-11",
 "awd_max_amd_letter_date": "2019-06-11",
 "awd_abstract_narration": "Measures of dependencies play central roles in discovering associations between variables that leads to scientific discoveries. In practice, analysts need to compute these measures from data, which can be challenging. The standard estimators can fail when, for example, the data has a mixture of continuous and discrete variables, or when the data lies on a complex space with abundant boundaries. The aim of this project is to address practical issues in estimating measures of dependencies, and provide novel estimators to overcome these challenges. The success of the proposed work will result in novel estimators for discovering new aspects of data. The immediate impact is in two specific contexts: discovering correlations in biological datasets and analyzing the inner-workings of deep neural networks; the lasting impact will be in diverse fields including genomic, biology, machine learning, and artificial intelligence. This project also integrates research with education through the creation of a graduate course on statistical learning. In addition, the project will offer undergraduates the opportunity to be involved in research.\r\n\r\nThis proposal addresses two fundamental questions: designing novel estimators for information theoretic measures and designing novel estimators for modern measures of correlation that is defined as a solution of optimization problems. In the former, two major challenges are addressed: variables of mixed type (continuous and discrete) and boundary biases. Borrowing techniques from local log-likelihood density estimators, nearest neighbor methods, and order statistics, this leads to a new estimator that can adapt to the local geometry of the distributions in a principled way, that improves significantly over existing estimators. In modern data analysis, several measures of correlations are naturally defined as solutions of optimization problems, making them challenging to estimate. This proposal aims to provide a principled approach and propose a new estimator borrowing insights from importance sampling and nearest neighbor methods. The proposed framework is applied to estimate hypercontractivity ratio, an information theoretic quantity that captures hidden correlations in the data and is naturally defined as a solution of an infinite dimensional optimization. The proposed measure of hypercontractivity  is shown to discover potential correlations that other standard measures are not able to, in canonical synthetic examples and real datasets.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sewoong",
   "pi_last_name": "Oh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sewoong Oh",
   "pi_email_addr": "sewoong@cs.washington.edu",
   "nsf_id": "000642594",
   "pi_start_date": "2019-06-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "185 Stevens Way",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981952350",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 1\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>Measures of dependencies play central roles in discovering associations between variables that leads to scientific discoveries. In practice, analysts need to compute those measures from given data, which can be challenging. The state-of-the-art estimators fail when, for example, the data has a mixed type of continuous and discrete variables, and when the data lies on complex manifold with abundant boundaries. Ad-hoc heuristics with delicate choices of hyperparameters are often used to handle such scenarios in practice. Further, several modern measures of correlations are defined as solutions to complex optimizations, making the estimation more challenging. We address these practical issues in estimating measures of dependencies, and provide novel estimators to overcome these challenges.&nbsp;</span></p>\n<p><span>This project address two fundamental questions: designing novel estimators for information theoretic measures and designing novel estimators for modern measures of correlation that is defined as a solution of optimization problems. In the former, principled approaches are developed borrowing techniques from local log-likelihood density estimators, nearest neighbor methods, and order statistics. In the latter, several recently proposed measures of correlations are naturally defined as solutions of optimization problems. P</span>rincipled approaches are developed using a new estimator borrowing insights from importance sampling and nearest neighbor methods.</p>\n<p>We use these information theoretic measurements and intuitions to develop technologies to build robust machine learning techniques. We highlight some of those in the following. These techniques benefit the public by providing&nbsp; machine learning techniques with improved privacy, security, and/or robustness guarantees. This further encourages participation in the data collection for those machine learning while maintaining the control of the data in the individual's hands.</p>\n<p>Generative adversarial networks (GANs) are a technique for learning generative models of complex data distributions from samples. Despite remarkable advances in generating realistic images, a major shortcoming of GANs is the fact that they tend to produce samples with little diversity, even when trained on diverse datasets. This phenomenon, known as mode collapse, has been the focus of much recent work. We study a principled approach to handling mode collapse, which we call packing. The main idea is to modify the discriminator to make decisions based on multiple samples from the same class, either real or artificially generated.&nbsp;<span>We show that packing naturally penalizes generators with mode collapse, thereby favoring generator distributions with less mode collapse during the training process.</span></p>\n<p><span>In statistical learning and analysis from shared data, which is increasingly widely adopted in platforms such as federated learning and meta-learning, there are two major concerns: privacy and robustness. Each participating individual should be able to contribute without the fear of leaking one's sensitive information. At the same time, the system should be robust in the presence of malicious participants inserting corrupted data. Recent algorithmic advances in learning from shared data focus on either one of these threats, leaving the system vulnerable to the other. We bridge this gap for the canonical problem of estimating the mean from i.i.d. samples. We introduce PRIME, which is the first efficient algorithm that achieves both privacy and robustness for a wide range of distributions.&nbsp;<br /></span></p>\n</div>\n</div>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2022<br>\n\t\t\t\t\tModified by: Sewoong&nbsp;Oh</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\n\nMeasures of dependencies play central roles in discovering associations between variables that leads to scientific discoveries. In practice, analysts need to compute those measures from given data, which can be challenging. The state-of-the-art estimators fail when, for example, the data has a mixed type of continuous and discrete variables, and when the data lies on complex manifold with abundant boundaries. Ad-hoc heuristics with delicate choices of hyperparameters are often used to handle such scenarios in practice. Further, several modern measures of correlations are defined as solutions to complex optimizations, making the estimation more challenging. We address these practical issues in estimating measures of dependencies, and provide novel estimators to overcome these challenges. \n\nThis project address two fundamental questions: designing novel estimators for information theoretic measures and designing novel estimators for modern measures of correlation that is defined as a solution of optimization problems. In the former, principled approaches are developed borrowing techniques from local log-likelihood density estimators, nearest neighbor methods, and order statistics. In the latter, several recently proposed measures of correlations are naturally defined as solutions of optimization problems. Principled approaches are developed using a new estimator borrowing insights from importance sampling and nearest neighbor methods.\n\nWe use these information theoretic measurements and intuitions to develop technologies to build robust machine learning techniques. We highlight some of those in the following. These techniques benefit the public by providing  machine learning techniques with improved privacy, security, and/or robustness guarantees. This further encourages participation in the data collection for those machine learning while maintaining the control of the data in the individual's hands.\n\nGenerative adversarial networks (GANs) are a technique for learning generative models of complex data distributions from samples. Despite remarkable advances in generating realistic images, a major shortcoming of GANs is the fact that they tend to produce samples with little diversity, even when trained on diverse datasets. This phenomenon, known as mode collapse, has been the focus of much recent work. We study a principled approach to handling mode collapse, which we call packing. The main idea is to modify the discriminator to make decisions based on multiple samples from the same class, either real or artificially generated. We show that packing naturally penalizes generators with mode collapse, thereby favoring generator distributions with less mode collapse during the training process.\n\nIn statistical learning and analysis from shared data, which is increasingly widely adopted in platforms such as federated learning and meta-learning, there are two major concerns: privacy and robustness. Each participating individual should be able to contribute without the fear of leaking one's sensitive information. At the same time, the system should be robust in the presence of malicious participants inserting corrupted data. Recent algorithmic advances in learning from shared data focus on either one of these threats, leaving the system vulnerable to the other. We bridge this gap for the canonical problem of estimating the mean from i.i.d. samples. We introduce PRIME, which is the first efficient algorithm that achieves both privacy and robustness for a wide range of distributions. \n\n\n\n\n\n\t\t\t\t\tLast Modified: 11/29/2022\n\n\t\t\t\t\tSubmitted by: Sewoong Oh"
 }
}