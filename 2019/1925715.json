{
 "awd_id": "1925715",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CCRI: Medium: Collaborative Research: Physical Robotic Manipulation Test Facility",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2025-01-31",
 "tot_intn_awd_amt": 810000.0,
 "awd_amount": 826000.0,
 "awd_min_amd_letter_date": "2019-08-30",
 "awd_max_amd_letter_date": "2024-06-13",
 "awd_abstract_narration": "The robotics community has a rich history of research and development in grasping and manipulation. However, it has proven to be very difficult to make grasping work in the real world (e.g., homes and small-scale industry). Part of the problem is the limited amount of testing that can be done in a lab. Testing requires specialized hardware and a very large number of trials, which is difficult for a single researcher to do on their own. The goal of this project is to set up dedicated test centers for grasping and manipulation that can be used by anyone with an internet connection. The test centers will provide standardized benchmarks, software and tutorials to teach people the basics of grasping, and hardware to perform the actual testing. This infrastructure will make it easier for people to share and compare results, and make it easier for people to contribute without needing to buy (and maintain) a large amount of specialized hardware.\r\n\r\nThere are four parts to this proposal; 1) Developing specialized hardware for testing and deploying in two facilities (one at Oregon State University, one at the University of Massachusetts Lowell) that have dedicated robotic arms and manipulators; 2) Software infrastructure to enable remote access for specifying tasks, running those tasks, then visualizing the results; 3) Implementing new and existing benchmark protocols (such as the ones developed at the National Institute of Standards and Technology (NIST)); and 4) Developing a community of users, including academic, industrial, and governmental institutions. The testbed approach should allow new and existing researchers a low cost method to participating in the grasping and manipulation scientific community and to provide standards from which the field can grow.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cindy",
   "pi_last_name": "Grimm",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Cindy M Grimm",
   "pi_email_addr": "grimmc@onid.orst.edu",
   "nsf_id": "000464868",
   "pi_start_date": "2019-08-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ravi",
   "pi_last_name": "Balasubramanian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ravi Balasubramanian",
   "pi_email_addr": "ravi.balasubramanian@oregonstate.edu",
   "nsf_id": "000602053",
   "pi_start_date": "2019-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Oregon State University",
  "inst_street_address": "1500 SW JEFFERSON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CORVALLIS",
  "inst_state_code": "OR",
  "inst_state_name": "Oregon",
  "inst_phone_num": "5417374933",
  "inst_zip_code": "973318655",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "OR04",
  "org_lgl_bus_name": "OREGON STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "MZ4DYXE1SL98"
 },
 "perf_inst": {
  "perf_inst_name": "Oregon State University",
  "perf_str_addr": "MIME Rogers Hall",
  "perf_city_name": "Corvallis",
  "perf_st_code": "OR",
  "perf_st_name": "Oregon",
  "perf_zip_code": "973316001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "OR04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "113900",
   "pgm_ele_name": "RSCH EXPER FOR UNDERGRAD SITES"
  },
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 810000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-82890cd9-7fff-5755-b58d-cd6a6890b50e\">\r\n<p dir=\"ltr\"><span>Through this project, the collaborative team at the University of Massachusetts Lowell (UML) and Oregon State University (OSU) have developed the Remote Experimentation of Manipulation for Online Test and Evaluation (REMOTE) testbed, which is a remotely accessible testbed for conducting repeatable robot grasping and manipulation tests using a set of standard robot hardware, benchmarking tasks (e.g., object grasping, door/drawer opening), software framework, test metrics, and external sensors for data collection. It consists of a set of robot manipulation hardware including commonly used interchangeable arms, end effectors, and wrist-mounted sensors to accommodate a variety of hardware configurations. The manipulators are installed at work stations with one of three available benchmarking tasks with automatic resetting capabilities in between trials: single object grasping with object position and orientation resets and door/drawer manipulation with closing resets.</span></p>\r\n<br />\r\n<p dir=\"ltr\"><span>The focus of the OSU team was the development of automated and sensorized hardware, along with visualization software. The visualization software replicates the hardware devices in a simulator, along with the data streams produced by the hardware. This enables replay of the grasping/manipulation pipeline. The hardware testbeds were: 1) An automated door and drawer, which automatically reset and recorded the state of the door and contact forces. 2) An object reset mechanism that automatically replaces the object at the desired position and orientation for supporting repeated grasping trials.</span></p>\r\n<br />\r\n<p dir=\"ltr\"><span>The code running the test stations uses a state machine to control the flow of each test for both the test apparatus (e.g., resetting to starting positions after each trial) and robot functionality (e.g., planning and executing grasp, retreating, moving to post grasp position, dropping object, etc.). The software framework used &ndash; running in the Robot Operating System (ROS 1; we are now in the process of transitioning to ROS 2) &ndash; is very flexible and allows for multiple robot embodiments to be used and for modules in the manipulation pipeline to be swapped in and out. The user develops code following conformance to the defined robot functionality architecture which is shared to our lab via GitHub, run through a build check in a Docker container, pulled down, and executed on one of the test stations.</span></p>\r\n<br />\r\n<p dir=\"ltr\"><span>During this project, several experiments were conducted to exercise the functionality of the architecture, including: (1) comparing the performance of one grasping algorithm across two robot embodiments, two objects, two lighting conditions, and two workspace elevations for a total of 640 grasps (conducted at UML), (2) comparing the integration of the software framework on the three physical test apparatuses (grasp, door, and drawer reset) between two physical testbed locations (UML and OSU), and (3) comparing the performance of four grasping algorithms across four robot embodiments, ten objects, two background textures, and two lighting conditions between two labs (UML and WPI). All of these experiments led to further improvements to the modularity of the architecture to allow for more variety of components that could be easily implemented within the pipeline. They also validated the functionality of the testbed to work with code contributed by other internal and external users.</span></p>\r\n<br />\r\n<p dir=\"ltr\"><span>The REMOTE testbed will continue to be utilized by both internal and external users to conduct robot manipulation experiments.</span></p>\r\n<div><span><br /></span></div>\r\n</span></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/06/2025<br>\nModified by: Cindy&nbsp;M&nbsp;Grimm</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/1925715/1925715_10639249_1738879922769_CCRI_REMOTE_Outcomes_Report_3--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1925715/1925715_10639249_1738879922769_CCRI_REMOTE_Outcomes_Report_3--rgov-800width.png\" title=\"Mechanisms in action\"><img src=\"/por/images/Reports/POR/2025/1925715/1925715_10639249_1738879922769_CCRI_REMOTE_Outcomes_Report_3--rgov-66x44.png\" alt=\"Mechanisms in action\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The door, drawer, and reset mechanisms in action</div>\n<div class=\"imageCredit\">UML</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Cindy&nbsp;M&nbsp;Grimm\n<div class=\"imageTitle\">Mechanisms in action</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1925715/1925715_10639249_1738879792584_CCRI_REMOTE_Outcomes_Report_2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1925715/1925715_10639249_1738879792584_CCRI_REMOTE_Outcomes_Report_2--rgov-800width.png\" title=\"Grasping algorithm comparison\"><img src=\"/por/images/Reports/POR/2025/1925715/1925715_10639249_1738879792584_CCRI_REMOTE_Outcomes_Report_2--rgov-66x44.png\" alt=\"Grasping algorithm comparison\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Comparison of different algorithms/hardware</div>\n<div class=\"imageCredit\">UML</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Cindy&nbsp;M&nbsp;Grimm\n<div class=\"imageTitle\">Grasping algorithm comparison</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/1925715/1925715_10639249_1738879858673_CCRI_REMOTE_Outcomes_Report_1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/1925715/1925715_10639249_1738879858673_CCRI_REMOTE_Outcomes_Report_1--rgov-800width.png\" title=\"Flex B pipeline\"><img src=\"/por/images/Reports/POR/2025/1925715/1925715_10639249_1738879858673_CCRI_REMOTE_Outcomes_Report_1--rgov-66x44.png\" alt=\"Flex B pipeline\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An example of using the Flex B pipeline to complete a task</div>\n<div class=\"imageCredit\">UML</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Cindy&nbsp;M&nbsp;Grimm\n<div class=\"imageTitle\">Flex B pipeline</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\n\r\n\n\nThrough this project, the collaborative team at the University of Massachusetts Lowell (UML) and Oregon State University (OSU) have developed the Remote Experimentation of Manipulation for Online Test and Evaluation (REMOTE) testbed, which is a remotely accessible testbed for conducting repeatable robot grasping and manipulation tests using a set of standard robot hardware, benchmarking tasks (e.g., object grasping, door/drawer opening), software framework, test metrics, and external sensors for data collection. It consists of a set of robot manipulation hardware including commonly used interchangeable arms, end effectors, and wrist-mounted sensors to accommodate a variety of hardware configurations. The manipulators are installed at work stations with one of three available benchmarking tasks with automatic resetting capabilities in between trials: single object grasping with object position and orientation resets and door/drawer manipulation with closing resets.\r\n\n\r\n\n\nThe focus of the OSU team was the development of automated and sensorized hardware, along with visualization software. The visualization software replicates the hardware devices in a simulator, along with the data streams produced by the hardware. This enables replay of the grasping/manipulation pipeline. The hardware testbeds were: 1) An automated door and drawer, which automatically reset and recorded the state of the door and contact forces. 2) An object reset mechanism that automatically replaces the object at the desired position and orientation for supporting repeated grasping trials.\r\n\n\r\n\n\nThe code running the test stations uses a state machine to control the flow of each test for both the test apparatus (e.g., resetting to starting positions after each trial) and robot functionality (e.g., planning and executing grasp, retreating, moving to post grasp position, dropping object, etc.). The software framework used  running in the Robot Operating System (ROS 1; we are now in the process of transitioning to ROS 2)  is very flexible and allows for multiple robot embodiments to be used and for modules in the manipulation pipeline to be swapped in and out. The user develops code following conformance to the defined robot functionality architecture which is shared to our lab via GitHub, run through a build check in a Docker container, pulled down, and executed on one of the test stations.\r\n\n\r\n\n\nDuring this project, several experiments were conducted to exercise the functionality of the architecture, including: (1) comparing the performance of one grasping algorithm across two robot embodiments, two objects, two lighting conditions, and two workspace elevations for a total of 640 grasps (conducted at UML), (2) comparing the integration of the software framework on the three physical test apparatuses (grasp, door, and drawer reset) between two physical testbed locations (UML and OSU), and (3) comparing the performance of four grasping algorithms across four robot embodiments, ten objects, two background textures, and two lighting conditions between two labs (UML and WPI). All of these experiments led to further improvements to the modularity of the architecture to allow for more variety of components that could be easily implemented within the pipeline. They also validated the functionality of the testbed to work with code contributed by other internal and external users.\r\n\n\r\n\n\nThe REMOTE testbed will continue to be utilized by both internal and external users to conduct robot manipulation experiments.\r\n\n\r\n\r\n\n\n\t\t\t\t\tLast Modified: 02/06/2025\n\n\t\t\t\t\tSubmitted by: CindyMGrimm\n"
 }
}