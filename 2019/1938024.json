{
 "awd_id": "1938024",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Comprehension Assessment via Spoken Dialog",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925126",
 "po_email": "abaylor@nsf.gov",
 "po_sign_block_name": "Amy Baylor",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2019-08-06",
 "awd_max_amd_letter_date": "2019-08-06",
 "awd_abstract_narration": "My Science Tutor (MyST) is an intelligent virtual tutor for elementary school students that has been developed over the last 10 years, with over 13,000 spoken dialog sessions in 8 areas of science. Its goal is to assess student understanding of concepts rather than facts, which is very important to prepare students and the future workforce in STEM.  This early-stage, exploratory EAGER project seeks to determine whether the analysis of a new corpora of data could advance the development and use of MyST so that teachers, curriculum developers and researchers could more easily develop automated assessments for new science topics. \r\n\r\nThe approach will apply recent advances in deep learning techniques to assess students' conceptual understanding of science during spoken dialogs with the virtual tutor. The project is motivated by the recent availability of a corpus of examples suitable for training and testing the proposed system. Successful outcomes of the proposed research will result in a novel, robust and portable method for extracting semantic representations from student responses and comparing these to reference statements to determine if conceptual relationships are correctly expressed. The approach has the potential to remove the primary impediments to developing dialog-based assessments: grammar development or topic-specific training.  This novel and untested approach is high-risk, but if successful, would have high-payoff, by allowing tutorial developers to only need to provide one example statement for each concept being discussed rather than having to explicitly specify all allowable ways that it could be expressed through development of grammars. This in turn could remove barriers to widespread development of spoken dialog systems and develop automated assessments for new topics using little or no training data.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Wayne",
   "pi_last_name": "Ward",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Wayne H Ward",
   "pi_email_addr": "wayne.ward@colorado.edu",
   "nsf_id": "000264998",
   "pi_start_date": "2019-08-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Colorado at Boulder",
  "inst_street_address": "3100 MARINE ST",
  "inst_street_address_2": "STE 481 572 UCB",
  "inst_city_name": "Boulder",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "3034926221",
  "inst_zip_code": "803090001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "THE REGENTS OF THE UNIVERSITY OF COLORADO",
  "org_prnt_uei_num": "",
  "org_uei_num": "SPVKK1RC2MZ3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Colorado at Boulder",
  "perf_str_addr": "3100 Marine Street, Room 481, 57",
  "perf_city_name": "Boulder",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "803031058",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>My Science Tutor (MyST) is a conversational virtual tutor for elementary school science. MyST uses a pattern-based semantic parser to extract semantic frames from student responses. One type of interaction important in science topics is discussing causal relations.</p>\n<p><em>If the switch is closed electricity flows</em></p>\n<p><em>&nbsp;</em>Frame: Cause</p>\n<p>Cause:&nbsp;<em>switch is closed</em></p>\n<p>Result:&nbsp;<em>electricity flows</em></p>\n<p>The system parses student responses into semantic frames and compares these to reference frames for correct statements. The goal of this project was to evaluate new algorithms that do not require annotating data to replace the current pattern-based role entailment mechanism.&nbsp;</p>\n<p>A phrase embedding is a fixed-length vector representing the features of a variable length input word string. The method used was to label semantic roles in student responses, represent the word string assigned to the role as an embedding vector, and train a classifier to accept or reject the response role vector as an acceptable role filler. &nbsp;Test transcripts were annotated with semantic roles and whether the role filler was correct.&nbsp;The training method used requires no data collected from users. A single example natural language statement is created for each point to be assessed, for example: &ldquo;If a circuit is complete electricity can flow&rdquo;. These statements are parsed into semantic frames. Each role was then expanded by adding one or two paraphrases, so that there were at least two positive examples. Then two or three negative examples were generated, often just a direct negation of the positive form.&nbsp;</p>\n<p>Frame Cause</p>\n<p>Cause: Complete_Circuit</p>\n<p>the circuit is closed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</p>\n<p>it&rsquo;s a complete circle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</p>\n<p>the circuit is not closed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</p>\n<p>it&rsquo;s not a complete circle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</p>\n<p>Result: On_Flow</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;electricity can flow&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;energy is moving&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;energy can&rsquo;t flow&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;energy is not moving&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</p>\n<p>Cause and Result are the roles (Cause is also the frame name). Phrases labelled 1 are positive examples and those labeled 0 are negative examples. For each role, an SVM is trained to differentiate between the positive and negative examples. For each of the training phrases for a role, the nltk toolkit was used to label parts of speech, then stop words were removed. Each phrase was then expanded using the python lemminflect library to create the following forms:</p>\n<p>noun: singular and plural</p>\n<p>verb: infinitive, present simple, present simple 3rd person, past simple, present participle (ing form), past participle</p>\n<p>adjective: comparative and superlative</p>\n<p>&nbsp;A series of Support Vector Machines (SVMs) were trained for each role, using successively fewer features. Two methods were used for feature selection:</p>\n<ol>\n<li>Scikit-learn&rsquo;s ANOVA_SVM python module was used to perform feature selection and then train a linear kernel SVM.&nbsp;</li>\n<li>The standard deviation of the positive training examples was computed for each dimension. Dimensions were ranked by standard deviation, and those dimensions with smallest std were kept.&nbsp;</li>\n</ol>\n<p>MyST transcripts for 1319 sessions from 3 topic areas&nbsp;&nbsp;were annotated for high-level dialog acts.&nbsp;The transcripts were also passed through the MyST parser to segment into semantic roles.</p>\n<p>A set of 14 roles were selected for detailed examination. The MyST parser output for these roles were hand corrected and labeled for correctness.</p>\n<p>Two types of publicly available pre-trained phrase embeddings were used:</p>\n<p>BERT &ndash; A 768-element vector is generated for the entire phrase in context</p>\n<p>GLOVE &ndash; A 300-element vector is generated by summing vectors for individual words</p>\n<p>For BERT embeddings, SVMs were trained for 768,500,300,200,100,50,25,10,5,1 dimensions</p>\n<p>For GLOVE embeddings, SVMs were trained for&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;300,200,100,50,25,10,5,1 dimensions&nbsp;</p>\n<p>For each role, separate SVMs were trained using each of the 2 feature reduction methods, for each of the embedding methods, for each of the dimension sets specified.&nbsp;</p>\n<p>When results are averaged across tags, there does appear to be some benefit from feature selection, with best performance using 100 dimensions for BERT and 200 for GLOVE. When performance is examined for individual role classifiers, there is considerable variety in feature selection results, with many showing good performance using only 1 dimension.&nbsp;</p>\n<p>The project goal was to determine the suitability of role phase embeddings as a basis for&nbsp;&nbsp;classifying the correctness of semantic role fillers. The classifiers showed an overall average of over 86% classification accuracy, with many roles have accuracy over 90%. A secondary goal was to determine how much training data must be collected. This evaluation used no training data collected from users, just 2-3 positive and negative examples of each role. These classifiers achieved results almost on par with the original MyST system which used patterns trained on large amounts of annotated data.</p>\n<p>These results&nbsp;&nbsp;uggest that information important for classifying roles can be restricted to relatively few dimensions. The feature set reductions are well behaved in the sense that each reduced set of dimensions is a proper subset of the next larger set.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/03/2021<br>\n\t\t\t\t\tModified by: Wayne&nbsp;H&nbsp;Ward</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMy Science Tutor (MyST) is a conversational virtual tutor for elementary school science. MyST uses a pattern-based semantic parser to extract semantic frames from student responses. One type of interaction important in science topics is discussing causal relations.\n\nIf the switch is closed electricity flows\n\n Frame: Cause\n\nCause: switch is closed\n\nResult: electricity flows\n\nThe system parses student responses into semantic frames and compares these to reference frames for correct statements. The goal of this project was to evaluate new algorithms that do not require annotating data to replace the current pattern-based role entailment mechanism. \n\nA phrase embedding is a fixed-length vector representing the features of a variable length input word string. The method used was to label semantic roles in student responses, represent the word string assigned to the role as an embedding vector, and train a classifier to accept or reject the response role vector as an acceptable role filler.  Test transcripts were annotated with semantic roles and whether the role filler was correct. The training method used requires no data collected from users. A single example natural language statement is created for each point to be assessed, for example: \"If a circuit is complete electricity can flow\". These statements are parsed into semantic frames. Each role was then expanded by adding one or two paraphrases, so that there were at least two positive examples. Then two or three negative examples were generated, often just a direct negation of the positive form. \n\nFrame Cause\n\nCause: Complete_Circuit\n\nthe circuit is closed                 1\n\nit\u2019s a complete circle              1\n\nthe circuit is not closed           0\n\nit\u2019s not a complete circle        0\n\nResult: On_Flow\n\n            electricity can flow                 1\n\n            energy is moving                    1\n\n            energy can\u2019t flow                    0\n\n            energy is not moving              0\n\nCause and Result are the roles (Cause is also the frame name). Phrases labelled 1 are positive examples and those labeled 0 are negative examples. For each role, an SVM is trained to differentiate between the positive and negative examples. For each of the training phrases for a role, the nltk toolkit was used to label parts of speech, then stop words were removed. Each phrase was then expanded using the python lemminflect library to create the following forms:\n\nnoun: singular and plural\n\nverb: infinitive, present simple, present simple 3rd person, past simple, present participle (ing form), past participle\n\nadjective: comparative and superlative\n\n A series of Support Vector Machines (SVMs) were trained for each role, using successively fewer features. Two methods were used for feature selection:\n\nScikit-learn\u2019s ANOVA_SVM python module was used to perform feature selection and then train a linear kernel SVM. \nThe standard deviation of the positive training examples was computed for each dimension. Dimensions were ranked by standard deviation, and those dimensions with smallest std were kept. \n\n\nMyST transcripts for 1319 sessions from 3 topic areas  were annotated for high-level dialog acts. The transcripts were also passed through the MyST parser to segment into semantic roles.\n\nA set of 14 roles were selected for detailed examination. The MyST parser output for these roles were hand corrected and labeled for correctness.\n\nTwo types of publicly available pre-trained phrase embeddings were used:\n\nBERT &ndash; A 768-element vector is generated for the entire phrase in context\n\nGLOVE &ndash; A 300-element vector is generated by summing vectors for individual words\n\nFor BERT embeddings, SVMs were trained for 768,500,300,200,100,50,25,10,5,1 dimensions\n\nFor GLOVE embeddings, SVMs were trained for            300,200,100,50,25,10,5,1 dimensions \n\nFor each role, separate SVMs were trained using each of the 2 feature reduction methods, for each of the embedding methods, for each of the dimension sets specified. \n\nWhen results are averaged across tags, there does appear to be some benefit from feature selection, with best performance using 100 dimensions for BERT and 200 for GLOVE. When performance is examined for individual role classifiers, there is considerable variety in feature selection results, with many showing good performance using only 1 dimension. \n\nThe project goal was to determine the suitability of role phase embeddings as a basis for  classifying the correctness of semantic role fillers. The classifiers showed an overall average of over 86% classification accuracy, with many roles have accuracy over 90%. A secondary goal was to determine how much training data must be collected. This evaluation used no training data collected from users, just 2-3 positive and negative examples of each role. These classifiers achieved results almost on par with the original MyST system which used patterns trained on large amounts of annotated data.\n\nThese results  uggest that information important for classifying roles can be restricted to relatively few dimensions. The feature set reductions are well behaved in the sense that each reduced set of dimensions is a proper subset of the next larger set.\n\n\t\t\t\t\tLast Modified: 10/03/2021\n\n\t\t\t\t\tSubmitted by: Wayne H Ward"
 }
}