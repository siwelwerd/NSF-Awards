{
 "awd_id": "1900676",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF: Medium: Rearchitecting Neural Networks for Verification",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922585",
 "po_email": "pprabhak@nsf.gov",
 "po_sign_block_name": "Pavithra Prabhakar",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 1255494.0,
 "awd_amount": 1271494.0,
 "awd_min_amd_letter_date": "2019-05-31",
 "awd_max_amd_letter_date": "2022-07-22",
 "awd_abstract_narration": "Machine learning has the potential to positively impact systems across society, for example, in agriculture, transportation, medicine, energy, and education.  To realize that potential, however, methods for assuring the safe operation of those systems are needed. This project addresses this pressing need. Consider the increasing presence of self-driving capabilities in automobiles.  They issue warnings when the car drifts outside of the lane and can initiate corrective steering actions.  To do this, they employ a neural network to analyze images from a forward-facing camera to detect, for example, the lines that demark lane boundaries.  A flaw in this neural network might, for instance, initiate a steering action in the wrong direction and thereby lead to vehicle damage or passenger injury.  This project develops techniques for assuring that machine learning produces neural networks that come with guarantees about their behavior.  Those guarantees can, in turn, be relied upon when determining that the overall system will operate safely.  \r\n\r\nTo achieve verifiably safe machine learning, this project leverages the growing body of work on symbolic verification algorithms for neural networks.  These algorithms are cost-prohibitive when applied to existing neural networks. The approach taken in this project searches for and automatically generates an alternative neural network architecture that allows for an appropriate balance between the accuracy of the network and the tractability of verification.  Once it finds such an architecture, it employs an iterative counterexample guided refinement approach to training the architecture which results in neural networks that meet essential safety guarantees. The project will organize an annual day-long \"Rising Stars\" forum for under-represented scholars working in formal methods, software engineering and machine learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Dwyer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew Dwyer",
   "pi_email_addr": "md3cn@virginia.edu",
   "nsf_id": "000103915",
   "pi_start_date": "2019-05-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sebastian",
   "pi_last_name": "Elbaum",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Sebastian G Elbaum",
   "pi_email_addr": "selbaum@virginia.edu",
   "nsf_id": "000412723",
   "pi_start_date": "2019-05-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yanjun",
   "pi_last_name": "Qi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yanjun Qi",
   "pi_email_addr": "yq2h@virginia.edu",
   "nsf_id": "000663606",
   "pi_start_date": "2019-05-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Virginia Main Campus",
  "inst_street_address": "1001 EMMET ST N",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTESVILLE",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "4349244270",
  "inst_zip_code": "229034833",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "VA05",
  "org_lgl_bus_name": "RECTOR & VISITORS OF THE UNIVERSITY OF VIRGINIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJG6HU8PA4S5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Virginia",
  "perf_str_addr": "85 Engineer's Way",
  "perf_city_name": "Charlottesville",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "229044740",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "VA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "8206",
   "pgm_ref_txt": "Formal Methods and Verification"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 923635.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 331859.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Neural networks are improving rapidly in their ability to accurately approximate complex functions and can exceed the performance of human-built solutions in a number of domains.&nbsp; To gain the benefits of increased performance, developers across a variety of sectors including: transportation, medicine, defense, and financial, are considering deploying neural networks as components of their systems.&nbsp; To do so confidently requires evidence that the networks work as intended.&nbsp; Recent research has adapted formal verification techniques to target the rigorous analysis of neural networks for this purpose, but these techniques are prohibitively expensive which makes them challenging to use in practice.<br /><br />To address challenge, one must first understand the factors that can influence verification technique cost and how those costs vary with different techniques.&nbsp; To support developing such an understanding, this project developed a suite of solutions that facilitate the evaluation of neural network verification techniques.&nbsp; First, it developed a system that integrated all of the existing verifiers into a single framework allowing them to be run on the same neural networks to promote controlled experimentation.&nbsp; Second, it developed a method to generate benchmarks that varied systematically in terms of 9 different factors that were shown to influence verifier performance.&nbsp; Third, it developed a systematic method for translating a broad class of verification problems into a simple form, thereby greatly simplifying the experimental space that researchers need to consider to understand performance.&nbsp; Finally, using these advances it conducted a range of experiments that revealed the relative performance strengths and weaknesses of existing neural network verifiers.<br /><br />Building on insights from the experimental findings of the project, the second phase of the project leveraged them to improve verifier performance.&nbsp;&nbsp; First, it developed a suite of three methods for adapting neural network training to minimize the cost of verifying trained networks without compromising the accuracy of their approximations.&nbsp;&nbsp; Second, it integrated new optimizations into state-of-the-art neural network verifiers to boost their performance by orders of magnitude in problem complexity.<br /><br />Project outcomes include a solid foundation for future researchers to conduct comprehensive evaluation of neural network verifiers, a novel verification tool tool whose performance can scale to realistic neural networks being considered for deployment, and freely available open-source implementations of all of the techniques developed on the project so that researchers and practitioners can use them.<br /><br />More broadly the project has advanced science and engineering in support of more trustworthy machine learning which is an important area of need for the nation</p><br>\n<p>\n Last Modified: 07/30/2024<br>\nModified by: Matthew&nbsp;Dwyer</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nNeural networks are improving rapidly in their ability to accurately approximate complex functions and can exceed the performance of human-built solutions in a number of domains. To gain the benefits of increased performance, developers across a variety of sectors including: transportation, medicine, defense, and financial, are considering deploying neural networks as components of their systems. To do so confidently requires evidence that the networks work as intended. Recent research has adapted formal verification techniques to target the rigorous analysis of neural networks for this purpose, but these techniques are prohibitively expensive which makes them challenging to use in practice.\n\nTo address challenge, one must first understand the factors that can influence verification technique cost and how those costs vary with different techniques. To support developing such an understanding, this project developed a suite of solutions that facilitate the evaluation of neural network verification techniques. First, it developed a system that integrated all of the existing verifiers into a single framework allowing them to be run on the same neural networks to promote controlled experimentation. Second, it developed a method to generate benchmarks that varied systematically in terms of 9 different factors that were shown to influence verifier performance. Third, it developed a systematic method for translating a broad class of verification problems into a simple form, thereby greatly simplifying the experimental space that researchers need to consider to understand performance. Finally, using these advances it conducted a range of experiments that revealed the relative performance strengths and weaknesses of existing neural network verifiers.\n\nBuilding on insights from the experimental findings of the project, the second phase of the project leveraged them to improve verifier performance. First, it developed a suite of three methods for adapting neural network training to minimize the cost of verifying trained networks without compromising the accuracy of their approximations. Second, it integrated new optimizations into state-of-the-art neural network verifiers to boost their performance by orders of magnitude in problem complexity.\n\nProject outcomes include a solid foundation for future researchers to conduct comprehensive evaluation of neural network verifiers, a novel verification tool tool whose performance can scale to realistic neural networks being considered for deployment, and freely available open-source implementations of all of the techniques developed on the project so that researchers and practitioners can use them.\n\nMore broadly the project has advanced science and engineering in support of more trustworthy machine learning which is an important area of need for the nation\t\t\t\t\tLast Modified: 07/30/2024\n\n\t\t\t\t\tSubmitted by: MatthewDwyer\n"
 }
}