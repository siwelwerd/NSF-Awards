{
 "awd_id": "1903783",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "US-French Collaboration: Collaborative Research: Neuro-Computational Models of Natural Language",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2018-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 309932.0,
 "awd_amount": 309932.0,
 "awd_min_amd_letter_date": "2018-11-16",
 "awd_max_amd_letter_date": "2022-05-25",
 "awd_abstract_narration": "Our society is built upon shared ideas, ideas that get from one person to another via language that is \"understood.\" But how do brains give us the ability to understand a stream of spoken words? This is a grand challenge question in computational neuroscience. This project addresses it using mathematical models of the language understanding process. These models reflect insights from computer science as well as linguistics. They allow investigators to ask: which process model best accounts for the signals from a particular brain region, at particular moment in time? The signals come from people listening to French and English versions of the same book.\u00a0 By comparing across models and across languages, the project seeks to differentiate between aspects of the understanding process that are language-specific and aspects that might be common to all humans. Increasingly precise modeling of this sort paves the way for future work with individuals who have trouble using language, such as those with Autism Spectrum Disorder. It could also lead to better computer systems, ones that use language in a brain-inspired way.\r\n\r\nBringing together computational linguists and cognitive neuroscientists, this project pursues two specific questions: (1) what aspects of sentence structure determine our expectations for upcoming words? and (2) what is the detailed balance between memorization and composition in natural language? Using electroencephalography (EEG) and functional Magnetic Resonance Imaging (fMRI) the PIs examine participants' neural responses to the spoken recitation of a literary work. These neural signals are fitted by time series predictors, themselves derived from linguistically plausible grammars and other language models. The project explores a family of such models, varying the size of grammatical units as well as the propensity for such units to be simply memorized as opposed to built up, step by step. Via information-theoretical complexity metrics, these theories derive quantitative predictions about the moment-by-moment neural responses of a person hearing a story.\u00a0 The approach as a whole leads to computationally explicit process models that are grounded in human brain responses to naturalistic text across two languages.\r\n\r\nA companion project is being funded by the French National Research Agency (ANR).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Hale",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "John T Hale",
   "pi_email_addr": "jthale@jhu.edu",
   "nsf_id": "000221519",
   "pi_start_date": "2018-11-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Georgia Research Foundation Inc",
  "inst_street_address": "310 E CAMPUS RD RM 409",
  "inst_street_address_2": "",
  "inst_city_name": "ATHENS",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "7065425939",
  "inst_zip_code": "306021589",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "GA10",
  "org_lgl_bus_name": "UNIVERSITY OF GEORGIA RESEARCH FOUNDATION, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "NMJHD63STRC5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Georgia",
  "perf_str_addr": "310 East Campus Rd",
  "perf_city_name": "Athens",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "306021589",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "GA10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  },
  {
   "pgm_ele_code": "732700",
   "pgm_ele_name": "CRCNS-Computation Neuroscience"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7327",
   "pgm_ref_txt": "CRCNS"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 235685.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 74245.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project delivered computational cognitive models of language processing, analyses of neural data that adjudicate between alternative theories of language understanding, and a novel multi-language open science data corpus of annotated linguistic and neural signals to facilitate future research. The work was conducted by combining neural signals while participants perform a more- or-less every-day task like listening to an audiobook story; data analysis was facilitated by using computational models to quantify the word-by-word dynamics of language processing (Figure 1 from Li et al. 2022)</p>\n<p><br />Advances in modeling include the development of a parser for recurrent neural network grammars (RNNG) that handles the ambiguities that are common in natural language syntax. The internal states of this model align with both electrophysiological and hemodynamic neural signals above-and-beyond recurrent neural network language models that lack an explicit account of syntax. Such alignment is most evident in both anterior and posterior foci of the left superior temporal gyrus. A report from this arm of the project received the \"Best Long Paper\" award from the 2018 meeting of the Association for Computational Linguistics. Examples of these results appear in Figure 2 (from Hale et al. 2018) and Figure 3 (from Brennan et al. 2020)</p>\n<p><br />Parallel efforts tested the balance of neural resources in composing complex linguistic expressions with the possibility of storing \"pre-built\" expressions for efficiency. Modeling so-called multiword expressions offered a novel benchmark to track the reduction in fronto-temporal \"language network\" processing load when even complex expressions are stored in memory, as shown in Figure 4.</p>\n<p><br />The award supported the collection, curation, and release of several datasets to the research community. (1) \"The Alice Datasets\" contain hemodynamic and electrophysiological signals collected from 75 individuals who listend to an audiobook chapter along with linguistic annotations for the audiobook. (2) \"The Little Prince Datasets\" contain hemodynamic signals collected from 112 individuals who listened to an audiobook story in one of three language (English, Mandarin, French.). The latter dataset is the first multilingual neurophysiological dataset released to the public to our knowledge. These datasets are summarized in papers appearing in \"Scientific Data\" and the 12th international Language Resources and Evaluation conference. An illustration of this multilingual dataset is given in Figure 5.</p>\n<p><br />Evidence for impact of the open data includes its incorporation into an evaluation of language-brain encoding methods (Beinborn et al. 2019 arXiv:1904.02547), applications to speech-decoding from non-invasive recordings (D&eacute;fossez et al. 2022 arXiv:2208.12266) and to social neuroscience (Thye et al 2023 doi:10.1016/j.neuroimage.2023.120204)</p>\n<p><br />The project's findings were promulgated in a dozen journal articles, a review paper, and numerous peer-reviewed conference papers. It supported postdoctoral and graduate training at both Cornell and the University of Georgia and impacted hundreds of undergraduates through the course _Language, Mind and Brain_. By bringing linguistics into the conversation, it enriched the discussion of natural language within the fields of cognitive neuroscience, computer science and artificial intelligence.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/19/2023<br>\n\t\t\t\t\tModified by: John&nbsp;T&nbsp;Hale</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695145949586_figure1-glm_methods--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695145949586_figure1-glm_methods--rgov-800width.jpg\" title=\"Figure 1: Overview of the approach\"><img src=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695145949586_figure1-glm_methods--rgov-66x44.jpg\" alt=\"Figure 1: Overview of the approach\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Schematic illustrating how word-by-word linguistic annotations are statistically fit against neural signals.</div>\n<div class=\"imageCredit\">Li et al 2022 Sci Data</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">John&nbsp;T&nbsp;Hale</div>\n<div class=\"imageTitle\">Figure 1: Overview of the approach</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695146357224_figure3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695146357224_figure3--rgov-800width.jpg\" title=\"Figure 3: fMRI correlates of parsing\"><img src=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695146357224_figure3--rgov-66x44.jpg\" alt=\"Figure 3: fMRI correlates of parsing\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Correlations between a family of model-derived features and fMRI signals from selected regions of interest; terms shown at the bottom reflect aspects of abstract syntactic structure that independently drive neural signals above-and-beyond \"control\" terms shown towards the top.</div>\n<div class=\"imageCredit\">Brennan et al 2020 Neuropsychologia</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">John&nbsp;T&nbsp;Hale</div>\n<div class=\"imageTitle\">Figure 3: fMRI correlates of parsing</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695147005065_fig2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695147005065_fig2--rgov-800width.jpg\" title=\"Figure 2: EEG correlates of parsing\"><img src=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695147005065_fig2--rgov-66x44.jpg\" alt=\"Figure 2: EEG correlates of parsing\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Regression results between EEG signals and model-derived metrics for syntactic structure (left) and next-word predictability (right).</div>\n<div class=\"imageCredit\">Hale et al 2018 Proceedings of the Association for Computational Linguistics</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">John&nbsp;T&nbsp;Hale</div>\n<div class=\"imageTitle\">Figure 2: EEG correlates of parsing</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695147108024_figure4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695147108024_figure4--rgov-800width.jpg\" title=\"Figure 4: Multiword expressions\"><img src=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695147108024_figure4--rgov-66x44.jpg\" alt=\"Figure 4: Multiword expressions\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">fMRI signals that correlate with the cohesion of words stored as multiword expressions</div>\n<div class=\"imageCredit\">Bhattasali et al 2018 Lang Cogn Neuroscience</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">John&nbsp;T&nbsp;Hale</div>\n<div class=\"imageTitle\">Figure 4: Multiword expressions</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695147237138_figure5-word-regions--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695147237138_figure5-word-regions--rgov-800width.jpg\" title=\"Figure 5: Multilingual fMRI datasets\"><img src=\"/por/images/Reports/POR/2023/1903783/1903783_10452064_1695147237138_figure5-word-regions--rgov-66x44.jpg\" alt=\"Figure 5: Multilingual fMRI datasets\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Example results from over 100 multilingual datasets showing shared and distinct patterns of neural activity for accessing words in sentences.</div>\n<div class=\"imageCredit\">Li et al 2022 Sci Data</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">John&nbsp;T&nbsp;Hale</div>\n<div class=\"imageTitle\">Figure 5: Multilingual fMRI datasets</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project delivered computational cognitive models of language processing, analyses of neural data that adjudicate between alternative theories of language understanding, and a novel multi-language open science data corpus of annotated linguistic and neural signals to facilitate future research. The work was conducted by combining neural signals while participants perform a more- or-less every-day task like listening to an audiobook story; data analysis was facilitated by using computational models to quantify the word-by-word dynamics of language processing (Figure 1 from Li et al. 2022)\n\n\nAdvances in modeling include the development of a parser for recurrent neural network grammars (RNNG) that handles the ambiguities that are common in natural language syntax. The internal states of this model align with both electrophysiological and hemodynamic neural signals above-and-beyond recurrent neural network language models that lack an explicit account of syntax. Such alignment is most evident in both anterior and posterior foci of the left superior temporal gyrus. A report from this arm of the project received the \"Best Long Paper\" award from the 2018 meeting of the Association for Computational Linguistics. Examples of these results appear in Figure 2 (from Hale et al. 2018) and Figure 3 (from Brennan et al. 2020)\n\n\nParallel efforts tested the balance of neural resources in composing complex linguistic expressions with the possibility of storing \"pre-built\" expressions for efficiency. Modeling so-called multiword expressions offered a novel benchmark to track the reduction in fronto-temporal \"language network\" processing load when even complex expressions are stored in memory, as shown in Figure 4.\n\n\nThe award supported the collection, curation, and release of several datasets to the research community. (1) \"The Alice Datasets\" contain hemodynamic and electrophysiological signals collected from 75 individuals who listend to an audiobook chapter along with linguistic annotations for the audiobook. (2) \"The Little Prince Datasets\" contain hemodynamic signals collected from 112 individuals who listened to an audiobook story in one of three language (English, Mandarin, French.). The latter dataset is the first multilingual neurophysiological dataset released to the public to our knowledge. These datasets are summarized in papers appearing in \"Scientific Data\" and the 12th international Language Resources and Evaluation conference. An illustration of this multilingual dataset is given in Figure 5.\n\n\nEvidence for impact of the open data includes its incorporation into an evaluation of language-brain encoding methods (Beinborn et al. 2019 arXiv:1904.02547), applications to speech-decoding from non-invasive recordings (D&eacute;fossez et al. 2022 arXiv:2208.12266) and to social neuroscience (Thye et al 2023 doi:10.1016/j.neuroimage.2023.120204)\n\n\nThe project's findings were promulgated in a dozen journal articles, a review paper, and numerous peer-reviewed conference papers. It supported postdoctoral and graduate training at both Cornell and the University of Georgia and impacted hundreds of undergraduates through the course _Language, Mind and Brain_. By bringing linguistics into the conversation, it enriched the discussion of natural language within the fields of cognitive neuroscience, computer science and artificial intelligence.\n\n\t\t\t\t\tLast Modified: 09/19/2023\n\n\t\t\t\t\tSubmitted by: John T Hale"
 }
}