{
 "awd_id": "1843485",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Development of a Multimodal Interface for improving independence of Blind and Visually-Impaired people",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Muralidharan Nair",
 "awd_eff_date": "2019-02-01",
 "awd_exp_date": "2020-01-31",
 "tot_intn_awd_amt": 225000.0,
 "awd_amount": 225000.0,
 "awd_min_amd_letter_date": "2019-01-29",
 "awd_max_amd_letter_date": "2019-01-29",
 "awd_abstract_narration": "The broader impact/commercial potential of this project will be to promote empowerment of millions of blind and visually-impaired (BVI) people by enabling greater independence, supporting increased educational attainment, proliferation of vocational opportunities, and enhancing their overall quality of life. There are currently no commercial solutions for providing BVI users with an assistive technology (AT) solution that allows BVI users to seamlessly access textual and graphical information via a unified system. Towards meeting this greater goal, this Phase I SBIR project addresses key challenges relating to technical feasibility in creating the core algorithms of Midlina and the functional viability proving that BVI users will find practical utility in its application. By providing a much-needed AT solution leveraging touchscreen devices such as smart phones as a platform (which is already owned and used by more than 80% of BVI users), this project has a high probability of user adoption and market acceptance when commercialized. Given that vision loss is expected to double in the next 20 years owing to age-related eye diseases experienced by the rapidly aging population, this project will have significant economic benefits for the State/Federal agencies providing support services to BVI and aging population.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project will show that a novel touchscreen-based information access software, called Midlina, will allow blind and visually-impaired (BVI) individuals to independently access textual and graphical information from digital media. The key innovation and strength of the proposed solution is in its ability to achieve this convergence of seamless text and graphical information access by integrating with native mobile operating systems (OS) used on smart touchscreen-based devices, the fastest growing computational platforms among BVI users. This project builds on strong theoretical underpinnings derived from 5-years of NSF-sponsored academic research involving hundreds of human testers and represents an excellent translational path towards commercialization. Two objectives will drive this Phase I project: (1) Developing a novel visual-to-multimodal conversion algorithm that is seamlessly integrated with a native mobile operating system, and (2) Establishing technical feasibility and practical usability of a prototype system through rigorous human user testing. A successful outcome of this Phase I project would lead to: (1) development of core algorithms for a novel touchscreen-based information access software, called Midlina, and (2) demonstrate feasibility that Midlina will enable BVI people to independently access both textual and graphical contents from digital media.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hari Prasath",
   "pi_last_name": "Palani",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hari Prasath Palani",
   "pi_email_addr": "ha.palani@northeastern.edu",
   "nsf_id": "000779011",
   "pi_start_date": "2019-01-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "UNAR LABS, LLC",
  "inst_street_address": "1486 BROADWAY",
  "inst_street_address_2": "",
  "inst_city_name": "SOUTH PORTLAND",
  "inst_state_code": "ME",
  "inst_state_name": "Maine",
  "inst_phone_num": "2074041587",
  "inst_zip_code": "041062602",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "ME01",
  "org_lgl_bus_name": "UNAR LABS LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "KKMALRX3T5C3"
 },
 "perf_inst": {
  "perf_inst_name": "UNAR LABS, LLC",
  "perf_str_addr": "20 Godfrey Drive",
  "perf_city_name": "Orono",
  "perf_st_code": "ME",
  "perf_st_name": "Maine",
  "perf_zip_code": "044733610",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "ME02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5371",
   "pgm_ref_txt": "SMALL BUSINESS PHASE I"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  },
  {
   "pgm_ref_code": "8035",
   "pgm_ref_txt": "Hardware Devices"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 225000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Graphical materials such as graphs and maps are extremely important for education, employment, independent living, and safe navigation for both sighted and visually-impaired (BVI) individuals. However, BVI individuals face significant challenges in accessing this wealth of information due to its visual nature. Through this Small Business Innovation Research project, UNAR Labs LLC seeks to address this long-standing, unmet need by providing BVI people with real-time and independent access to digital text and graphical materials via commercial smartphones and tablets. To date, there is no approach that has the potential to provide both text and graphical materials in a seamless manner, which is the de-facto experience gained by sighted users. To fill this gap, UNAR Labs has developed an intuitive information access solution called Midlina, which will automatically translate visual information in to multisensory equivalent and deliver it to BVI users via smart touchscreen-based computing devices. This Phase I SBIR project builds on past NSF-sponsored research and represents an excellent translational path from academic research to a real-world system built from the ground up on solid theoretical underpinnings and empirical findings from studies on multimodal human information processing. The core technology - Midlina, builds on 5-years of NSF-sponsored academic research involving hundreds of human testers. The activities of this SBIR Phase I were designed to apply findings from the customer interviews and from past NSF-sponsored academic research to build an intuitive system that convey combined textual and graphical information via a multisensory interface and prove that BVI end-users can utilize the system to gain access to otherwise inaccessible digital media materials.</p>\n<p>The Phase I SBIR project was driven by two objectives: (1) the design and development of a software algorithm that integrates with existing native mobile operating systems to dynamically extract, analyze, and perform visual-to multimodal graphic conversion, and (2) demonstrating usability of the unified system in supporting BVI end-users in real-world usage scenarios. Using a set of bar graphs as the testbed, a prototype Midlina system (an IOS app) was developed and the functional utility of the system was investigated through human studies involving six BVI end-users and more than twelve blindfolded-sighted users. The study assessed the efficacy and feasibility of the system by comparing it against the traditional paper-based embossed graphs (the current gold-standard approach). Results demonstrated that participants were able to access and use the graphs well enough and at similar speeds across conditions to accurately answer the questions posed. Results from the post-study survey revealed that five out of six BVI participants preferred our new touchscreen-based multisensory graph as opposed to the traditional paper-based embossed graphs.</p>\n<p>The BVI demographic is estimated to be 23.7 million people (14.4 million women and 9.3 million men) in the U.S. and 285 million globally. Readily available and affordable access to informative materials will promote independence and increase productivity. The outcome of this Phase I research (i.e., demonstration that Midlina is commercially viable) clearly suggests that once commercialized, Midlina will significantly aid in reducing the detrimental effects experienced by BVI people on their educational, vocational, and social opportunities.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/24/2020<br>\n\t\t\t\t\tModified by: Hari Prasath&nbsp;Palani</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nGraphical materials such as graphs and maps are extremely important for education, employment, independent living, and safe navigation for both sighted and visually-impaired (BVI) individuals. However, BVI individuals face significant challenges in accessing this wealth of information due to its visual nature. Through this Small Business Innovation Research project, UNAR Labs LLC seeks to address this long-standing, unmet need by providing BVI people with real-time and independent access to digital text and graphical materials via commercial smartphones and tablets. To date, there is no approach that has the potential to provide both text and graphical materials in a seamless manner, which is the de-facto experience gained by sighted users. To fill this gap, UNAR Labs has developed an intuitive information access solution called Midlina, which will automatically translate visual information in to multisensory equivalent and deliver it to BVI users via smart touchscreen-based computing devices. This Phase I SBIR project builds on past NSF-sponsored research and represents an excellent translational path from academic research to a real-world system built from the ground up on solid theoretical underpinnings and empirical findings from studies on multimodal human information processing. The core technology - Midlina, builds on 5-years of NSF-sponsored academic research involving hundreds of human testers. The activities of this SBIR Phase I were designed to apply findings from the customer interviews and from past NSF-sponsored academic research to build an intuitive system that convey combined textual and graphical information via a multisensory interface and prove that BVI end-users can utilize the system to gain access to otherwise inaccessible digital media materials.\n\nThe Phase I SBIR project was driven by two objectives: (1) the design and development of a software algorithm that integrates with existing native mobile operating systems to dynamically extract, analyze, and perform visual-to multimodal graphic conversion, and (2) demonstrating usability of the unified system in supporting BVI end-users in real-world usage scenarios. Using a set of bar graphs as the testbed, a prototype Midlina system (an IOS app) was developed and the functional utility of the system was investigated through human studies involving six BVI end-users and more than twelve blindfolded-sighted users. The study assessed the efficacy and feasibility of the system by comparing it against the traditional paper-based embossed graphs (the current gold-standard approach). Results demonstrated that participants were able to access and use the graphs well enough and at similar speeds across conditions to accurately answer the questions posed. Results from the post-study survey revealed that five out of six BVI participants preferred our new touchscreen-based multisensory graph as opposed to the traditional paper-based embossed graphs.\n\nThe BVI demographic is estimated to be 23.7 million people (14.4 million women and 9.3 million men) in the U.S. and 285 million globally. Readily available and affordable access to informative materials will promote independence and increase productivity. The outcome of this Phase I research (i.e., demonstration that Midlina is commercially viable) clearly suggests that once commercialized, Midlina will significantly aid in reducing the detrimental effects experienced by BVI people on their educational, vocational, and social opportunities.\n\n \n\n\t\t\t\t\tLast Modified: 03/24/2020\n\n\t\t\t\t\tSubmitted by: Hari Prasath Palani"
 }
}