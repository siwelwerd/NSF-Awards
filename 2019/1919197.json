{
 "awd_id": "1919197",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SPX: Write Once, Run on Anything: Verified, Tuned Accelerator Kernels from High Level Specifications",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 1250000.0,
 "awd_amount": 1250000.0,
 "awd_min_amd_letter_date": "2019-07-26",
 "awd_max_amd_letter_date": "2020-09-17",
 "awd_abstract_narration": "Two trends in computation have conspired to make efficient exploitation of computational resources difficult. First, the applications for which domain experts are interested in deploying computational power--computational genomics, video processing, data analytics--are increasingly irregular, with patterns of computation and data access that are difficult to reason about. Second, the computational platforms that domain experts want to exploit are increasingly heterogeneous, built around accelerators that present vastly different performance characteristics, programming models, and efficiency tradeoffs. Most worryingly, these accelerators often require careful mapping of computation and data access to achieve maximum performance--exactly the task that is difficult in irregular computations. This project's novelties are creating new domain-specific languages (DSLs) to allow programmers to express complex computations in a high-level, easy-to-understand way, then mapping those DSLs to novel intermediate representations that allow programs in different domains to be expressed in a common representation for optimization. This intermediate representation will then be transformed using provably safe transformations to improve performance without sacrificing correctness guarantees. Finally, the transformed programs will be automatically tuned for accelerators, with that tuning dependent on the specific resource profile of the accelerator and the resource demands of the application. This project's impacts will be unlocking the power of accelerator-based platforms to a broader group of programmers and scientists and providing a DSL and the associated compilation framework to two rich problem domains (streaming video processing and computational genomics) and to new accelerators.\r\n\r\nWhile different problem domains require different abstractions to effectively capture their computations--string-processing kernels for computational genomics, filtering and transformation kernels for video processing--these abstractions can often effectively be mapped to a common intermediate representation that nevertheless captures high-level properties of program execution such as data-access patterns and parallelism properties. This intermediate representation forms the basis for domain-agnostic transformations that can restructure computation to templates that fit different accelerator paradigms (for example, choosing wide parallelism for accelerators like Graphics Processing Units (GPUs), or narrower parallelism for vector units in multi-cores). This project will then use machine learning to develop accelerator models that allow these templates to be instantiated with accelerator-specific parameters for each application (e.g., tuning block size in a GPU kernel), and therefore maximize performance. Finally, to ensure that this transformation and tuning pipeline is sound, this project will develop novel verification techniques to ensure that each translation preserves correctness. These tools will allow programmers to write accelerator programs without concerning themselves with the details of the accelerators they are targeting for correctness or performance.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Milind",
   "pi_last_name": "Kulkarni",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Milind Kulkarni",
   "pi_email_addr": "milind@purdue.edu",
   "nsf_id": "000549148",
   "pi_start_date": "2019-07-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Saurabh",
   "pi_last_name": "Bagchi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Saurabh Bagchi",
   "pi_email_addr": "sbagchi@purdue.edu",
   "nsf_id": "000309372",
   "pi_start_date": "2019-07-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Felix Xiaozhu",
   "pi_last_name": "Lin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Felix Xiaozhu Lin",
   "pi_email_addr": "felixlin@virginia.edu",
   "nsf_id": "000677143",
   "pi_start_date": "2019-07-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Xiaokang",
   "pi_last_name": "Qiu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaokang Qiu",
   "pi_email_addr": "xkqiu@purdue.edu",
   "nsf_id": "000728102",
   "pi_start_date": "2019-07-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "465 Northwestern Ave",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072035",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 1250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project focuses on efficient code execution and programmability for various heterogeneous accelerators, which are standard in modern computing platforms. As machine learning (ML) and artificial intelligence (AI) become central to technology, accelerators like GPUs gain increasing importance.</p>\r\n<p>Through novel software research, the investigators have optimized the software stack supporting modern accelerators. This stack spans the GPU device driver, GPU runtime software, and user-level machine learning frameworks utilizing GPUs. In response to breakthroughs in generative AI, they have specifically optimized the accelerator's software stack for efficient execution of language models, speech models, and diffusion.</p>\r\n<p><strong>Project Outcomes</strong></p>\r\n<p>The project has produced the following new software concepts and designs:</p>\r\n<ul>\r\n<li>Fast GPU kernel launches using record/replay techniques.</li>\r\n<li>An efficient CPU/GPU framework for deep speech understanding on resource-constrained devices ranging from microcontrollers to mobile devices.</li>\r\n<li>Efficient data selection for training large language models on accelerators.</li>\r\n<li>A new execution framework for RWKV, which is a novel RNN family of large language models. </li>\r\n</ul>\r\n<p>The project has resulted in a number of publications and multiple open-source codebases.</p>\r\n<p><strong>Broader Impacts: </strong>The PI has trained research assistants in accelerator-centric programming and engaged undergraduate RAs, including many underrepresented minorities. The project outcomes have been integrated into OS curricula at both graduate and undergraduate levels at the University of Virginia. These technologies are expected to drive the development of accelerator software. As AI fuels the modern economy and accelerators are essential for AI, this project contributes to the greater social good.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/03/2024<br>\nModified by: Felix Xiaozhu&nbsp;Lin</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project focuses on efficient code execution and programmability for various heterogeneous accelerators, which are standard in modern computing platforms. As machine learning (ML) and artificial intelligence (AI) become central to technology, accelerators like GPUs gain increasing importance.\r\n\n\nThrough novel software research, the investigators have optimized the software stack supporting modern accelerators. This stack spans the GPU device driver, GPU runtime software, and user-level machine learning frameworks utilizing GPUs. In response to breakthroughs in generative AI, they have specifically optimized the accelerator's software stack for efficient execution of language models, speech models, and diffusion.\r\n\n\nProject Outcomes\r\n\n\nThe project has produced the following new software concepts and designs:\r\n\r\nFast GPU kernel launches using record/replay techniques.\r\nAn efficient CPU/GPU framework for deep speech understanding on resource-constrained devices ranging from microcontrollers to mobile devices.\r\nEfficient data selection for training large language models on accelerators.\r\nA new execution framework for RWKV, which is a novel RNN family of large language models. \r\n\r\n\n\nThe project has resulted in a number of publications and multiple open-source codebases.\r\n\n\nBroader Impacts: The PI has trained research assistants in accelerator-centric programming and engaged undergraduate RAs, including many underrepresented minorities. The project outcomes have been integrated into OS curricula at both graduate and undergraduate levels at the University of Virginia. These technologies are expected to drive the development of accelerator software. As AI fuels the modern economy and accelerators are essential for AI, this project contributes to the greater social good.\r\n\n\n\t\t\t\t\tLast Modified: 12/03/2024\n\n\t\t\t\t\tSubmitted by: Felix XiaozhuLin\n"
 }
}