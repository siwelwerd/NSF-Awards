{
 "awd_id": "1850149",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: RI: RUI: Performance guarantees for online apprenticeship learning with unknown features",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Roger Mailler",
 "awd_eff_date": "2019-05-01",
 "awd_exp_date": "2022-04-30",
 "tot_intn_awd_amt": 158283.0,
 "awd_amount": 158283.0,
 "awd_min_amd_letter_date": "2019-04-22",
 "awd_max_amd_letter_date": "2019-04-22",
 "awd_abstract_narration": "The surge of interest in robots that can be trained to perform in industries such as manufacturing and healthcare increases the need for improved learning methods.  In one such method, apprenticeship learning, a robot learns to perform a task by watching an expert. This project's goals are to decrease the time required to set up the robot for learning and to offer college students hands-on robotic research activities. Most related work describes techniques that require the robot's programmer to identify features of the task. This project will reduce the programmer's setup work by using automatically generated features. A new method ensures the accuracy of the robotic learner by determining the number of observations required of the expert. \r\n\r\nMaximum Causal Entropy Inverse-Reinforcement Learning learns feature weights from demonstration, and like other maximum entropy models, offers strong performance guarantees and analysis possibilities. Proven generalization bounds are available that allow an estimate on the number of observed samples needed for a given expected level of error.  However, they require knowledge of the covering number or complexity of the feature functions and/or known limits on the feature weights. When features are automatically extracted from a robot's sensor stream it is likely that many spurious features will be selected for use which could greatly increase the estimated number of samples needed, rendering the technique impractical.  This project is developing an iterative, online variant of the maximum causal inverse-reinforcement learning algorithm that runs during the demonstrations and selects high-valued features as a critical subset which are then used to calculate the sample bounds. Once the required number of samples have been observed an offline inverse-reinforcement learning technique is run to ensure the feature weights are learned accurately.  The new algorithm will be evaluated on a robot tasked with sorting previously-unknown objects. In this task, students will demonstrate the sorting of objects, then the robot will be required to do the same. Afterwards, the robot will be reset and the experiment repeats with a new set of objects. Critically, the software on the robot should not be changed or updated between these tasks.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kenneth",
   "pi_last_name": "Bogert",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kenneth Bogert",
   "pi_email_addr": "kbogert@unca.edu",
   "nsf_id": "000741083",
   "pi_start_date": "2019-04-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Asheville",
  "inst_street_address": "1 UNIVERSITY HEIGHTS",
  "inst_street_address_2": "",
  "inst_city_name": "ASHEVILLE",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "8282516476",
  "inst_zip_code": "288043251",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "NC11",
  "org_lgl_bus_name": "THE UNIVERSITY OF NORTH CAROLINA AT ASHEVILLE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LX38ZHATFGN5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Asheville",
  "perf_str_addr": "One University Heights",
  "perf_city_name": "Asheville",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "288048503",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "NC11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9229",
   "pgm_ref_txt": "RES IN UNDERGRAD INST-RESEARCH"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 158283.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p style=\"margin-bottom: 0in; line-height: 100%;\">This project had two main goals:</p>\n<p style=\"margin-bottom: 0in; line-height: 100%;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in; line-height: 100%;\">First, as this is an early career grant, fund the purchase of some needed equipment and pay the salaries (and tuition) of some undergraduate researchers.  With this grant I was able to buy a small industrial robot arm, a server for running computations, and some smaller needed items.  The arm in particular serves as a recruiting tool as I am able to attract new students to my school's computer science department with demonstrations and talks about it.</p>\n<p style=\"margin-bottom: 0in; line-height: 100%;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in; line-height: 100%;\">I was able to support four undergraduate researchers with the grant funds, for most of them this included their tuition.  These students developed the code underlying the robotic and machine learning portions of this project.  I was able to take two of them to a robot conference in the fall of 2019 at which they met researchers and other contacts in the industry.  Some of these students have gone on to mechatronics and engineering jobs after they graduated.  They gained valuable experience on this project and I am proud of the work they have accomplished, especially with the added difficultly of the pandemic.</p>\n<p style=\"margin-bottom: 0in; line-height: 100%;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in; line-height: 100%;\">Second, our technical contribution was to find a way to use a machine learning algorithm (Inverse Reinforcement Learning) to teach a robot arm to sort things just by demonstrating it for them.  Most importantly, the robot had very little knowledge of what we were going to be sorting ahead of time.  The bulk of the technology needed to do this exists already, but one important thing that was missing is the ability to know how many demonstrations the robot needs in order to accurately learn the task.  So our idea was to develop a way to do it during the demonstrations such that once the robot computed that it had seen enough, using what it had learned so far to fill in the unknown parts, it would tell us to stop.</p>\n<p style=\"margin-bottom: 0in; line-height: 100%;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in; line-height: 100%;\">However, once we started testing our code with some small toy problems, we noticed that the predicted number of demonstrations needed didn't depend upon the unknown parts of the problem at all!  This is a good thing for this task, as it means that the demonstrator can know how many times they will have to demonstrate the task before they even start.  Unfortunately, the time it took to verify this result with some larger experiments meant that we couldn't attempt the sorting on the actual robot before the grant ended.</p>\n<!-- p { margin-bottom: 0.1in; line-height: 115%; background: transparent } --><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/28/2022<br>\n\t\t\t\t\tModified by: Kenneth&nbsp;Bogert</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "This project had two main goals:\n \nFirst, as this is an early career grant, fund the purchase of some needed equipment and pay the salaries (and tuition) of some undergraduate researchers.  With this grant I was able to buy a small industrial robot arm, a server for running computations, and some smaller needed items.  The arm in particular serves as a recruiting tool as I am able to attract new students to my school's computer science department with demonstrations and talks about it.\n \nI was able to support four undergraduate researchers with the grant funds, for most of them this included their tuition.  These students developed the code underlying the robotic and machine learning portions of this project.  I was able to take two of them to a robot conference in the fall of 2019 at which they met researchers and other contacts in the industry.  Some of these students have gone on to mechatronics and engineering jobs after they graduated.  They gained valuable experience on this project and I am proud of the work they have accomplished, especially with the added difficultly of the pandemic.\n \nSecond, our technical contribution was to find a way to use a machine learning algorithm (Inverse Reinforcement Learning) to teach a robot arm to sort things just by demonstrating it for them.  Most importantly, the robot had very little knowledge of what we were going to be sorting ahead of time.  The bulk of the technology needed to do this exists already, but one important thing that was missing is the ability to know how many demonstrations the robot needs in order to accurately learn the task.  So our idea was to develop a way to do it during the demonstrations such that once the robot computed that it had seen enough, using what it had learned so far to fill in the unknown parts, it would tell us to stop.\n \nHowever, once we started testing our code with some small toy problems, we noticed that the predicted number of demonstrations needed didn't depend upon the unknown parts of the problem at all!  This is a good thing for this task, as it means that the demonstrator can know how many times they will have to demonstrate the task before they even start.  Unfortunately, the time it took to verify this result with some larger experiments meant that we couldn't attempt the sorting on the actual robot before the grant ended.\n\n\n\t\t\t\t\tLast Modified: 08/28/2022\n\n\t\t\t\t\tSubmitted by: Kenneth Bogert"
 }
}