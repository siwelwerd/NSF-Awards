{
 "awd_id": "1914373",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Blockchain-Enabled Machine Learning on Confidential Data",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Anna Brady-Estevez",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2019-12-31",
 "tot_intn_awd_amt": 224634.0,
 "awd_amount": 224634.0,
 "awd_min_amd_letter_date": "2019-06-21",
 "awd_max_amd_letter_date": "2019-06-21",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) project includes advances in scientific understanding and substantial societal and commercial impacts. In an era with seemingly endless data breaches, the project offers a way of applying the power of machine learning while never disclosing sensitive raw data. Decentralized computation can increase the scale of models that may be trained, which will allow the use of deep learning on more complicated problems across a range of fields. Additionally, allowing confidential data to be used will allow more rapid research advances in fields with sensitive data, such as biomedicine. Furthermore, decentralized computation offers the promise of lower cost than existing computational infrastructures such as cloud providers. This greater, and more democratic, power will push the boundaries of the state-of-the-art and also enable more people to leverage large-scale machine learning.\r\n\r\nThis SBIR Phase I project proposes to advance knowledge in the area of coordinating decentralized secure machine learning with a blockchain in a manner that maintains data confidentiality and ensures verifiability. The R&D will also advance understanding and practicality of zero knowledge computational verification and homomorphic neural networks. While deep neural networks have yielded astounding results in recent years, there has been limited progress towards achieving a practical solution to training models in a decentralized context while both maintaining data confidentiality and ensuring verifiability. This is the key challenge and it is anticipated that this project will yield a solution. The proposed approach involves defining a protocol for training amongst untrusted parties that is mediated by a decentralized ledger and involves the use of homomorphic encryption and a computational verification technique.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Guha",
   "pi_last_name": "Jayachandran",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Guha Jayachandran",
   "pi_email_addr": "info@onai.com",
   "nsf_id": "000740909",
   "pi_start_date": "2019-06-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Onai Inc.",
  "inst_street_address": "7291 CORONADO DR",
  "inst_street_address_2": "STE 5",
  "inst_city_name": "SAN JOSE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6504298622",
  "inst_zip_code": "951294582",
  "inst_country_name": "United States",
  "cong_dist_code": "17",
  "st_cong_dist_code": "CA17",
  "org_lgl_bus_name": "ONAI INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "CLR5VEPH3MC1"
 },
 "perf_inst": {
  "perf_inst_name": "Onu Technology, Inc.",
  "perf_str_addr": "7280 Blue Hill Dr., Suite 10",
  "perf_city_name": "San Jose",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "951293624",
  "perf_ctry_code": "US",
  "perf_cong_dist": "17",
  "perf_st_cong_dist": "CA17",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8030",
   "pgm_ref_txt": "Chemical Technology"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 224634.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-ce21f877-7fff-7d63-9fff-556ed20fc0a8\"> </span></p>\n<p dir=\"ltr\"><span>We achieved the aims set out for Phase I, related to performing machine learning in a manner that does not expose sensitive data. Machine learning allows models to be trained on data such that those models can then be used to make predictions about other inputs. A particular machine learning technique, deep learning, has proven revolutionary over the past several years in its capabilities. But in many problem domains, the data involved may be sensitive.</span></p>\n<p dir=\"ltr\"><span>The various techniques investigated and/or developed in this project enable an entity to train a model on encrypted data provided by another party, without needing to be able to decrypt or read the encrypted data; enable multiple parties to jointly train a model without exposing any sensitive data to each other; and allow a model to be evaluated on encrypted input without needing to decrypt that input. We tested and benchmarked all of these scenarios during Phase I.&nbsp;</span></p>\n<p dir=\"ltr\"><span>The project also entailed enabling a method that can allow participants and third parties mediated by a blockchain to verify that training was faithfully performed, even without being able to view the input data. For example, a company can send encrypted training data to a provider of computation to train a model. The provider cannot read the data but is able to train a model. Only the original data owner can decrypt and utilize the model but anyone can verify the training was properly performed.</span></p>\n<p dir=\"ltr\"><span>These types of techniques enable a world where the power of deep learning can be harnessed with reliable safeguards for maintaining the confidentiality of sensitive data and ensuring verifiability. Both these aspects--confidentiality and verifiability--are required for performing machine learning on sensitive data in a decentralized or many-party context.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Accomplishing this vision will increase the safety of data associated with all of us. Better allowing proprietary or confidential data to be used will allow more rapid research advances in fields with sensitive data, such as biomedicine. Furthermore, decentralized computation can increase the scale of models that may be trained, which will allow the use of deep learning on more complicated problems across a range of fields.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/19/2020<br>\n\t\t\t\t\tModified by: Guha&nbsp;Jayachandran</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nWe achieved the aims set out for Phase I, related to performing machine learning in a manner that does not expose sensitive data. Machine learning allows models to be trained on data such that those models can then be used to make predictions about other inputs. A particular machine learning technique, deep learning, has proven revolutionary over the past several years in its capabilities. But in many problem domains, the data involved may be sensitive.\nThe various techniques investigated and/or developed in this project enable an entity to train a model on encrypted data provided by another party, without needing to be able to decrypt or read the encrypted data; enable multiple parties to jointly train a model without exposing any sensitive data to each other; and allow a model to be evaluated on encrypted input without needing to decrypt that input. We tested and benchmarked all of these scenarios during Phase I. \nThe project also entailed enabling a method that can allow participants and third parties mediated by a blockchain to verify that training was faithfully performed, even without being able to view the input data. For example, a company can send encrypted training data to a provider of computation to train a model. The provider cannot read the data but is able to train a model. Only the original data owner can decrypt and utilize the model but anyone can verify the training was properly performed.\nThese types of techniques enable a world where the power of deep learning can be harnessed with reliable safeguards for maintaining the confidentiality of sensitive data and ensuring verifiability. Both these aspects--confidentiality and verifiability--are required for performing machine learning on sensitive data in a decentralized or many-party context. \nAccomplishing this vision will increase the safety of data associated with all of us. Better allowing proprietary or confidential data to be used will allow more rapid research advances in fields with sensitive data, such as biomedicine. Furthermore, decentralized computation can increase the scale of models that may be trained, which will allow the use of deep learning on more complicated problems across a range of fields.\n\n\t\t\t\t\tLast Modified: 02/19/2020\n\n\t\t\t\t\tSubmitted by: Guha Jayachandran"
 }
}