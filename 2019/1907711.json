{
 "awd_id": "1907711",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Medium: Collaborative Research: Toward Extreme Scale Fault-Tolerance: Exploration Methods, Comparative Studies and Decision Processes",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2017-09-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 342000.0,
 "awd_amount": 342000.0,
 "awd_min_amd_letter_date": "2018-12-14",
 "awd_max_amd_letter_date": "2018-12-14",
 "awd_abstract_narration": "Current high-performance computing (HPC) research target computer systems with exaflop (1018 or a quintillion floating point operations per second) capabilities. Such computational power will enable new, important discoveries across all basic science domains. Application resilience to computer faults and failures is a major challenge to the realization of extreme scale computing systems. This project, Simulation and Modeling for Understanding Resilience and Faults at Scale (SMURFS), addresses this challenge by developing methods to improve our predictive understanding of the complex interactions amongst a given application, a given real or hypothetical hardware and software system environment, and a given fault-tolerance strategy at extreme scale. Specifically, SMURFS develops:\r\n1.\tNew simulation and modeling capabilities for studying application resilience at scale;\r\n2.\tCapabilities to execute a comprehensive set of comparative fault-tolerance studies; and\r\n3.\tEffective prescriptions to guide application developers, hardware architects and system designers to realize efficient, resilient extreme scale capabilities.\r\n\r\nSMURFS explores the impact of faults and failures, fault mitigation strategies and emerging technologies by providing new analytical and component models for predicting fault-tolerant application behavior at scale. The Iron simulation framework integrates these models for validation and comprehensive performance studies over a wide range of representative applications, application proxies, fault-tolerance protocols and hardware configurations. These studies inform a rule-based system for prescribing best fault-tolerance practices and configurations for new candidate applications and scenarios.\r\n\r\nSMURFS renders (1) new simulation and analytical models that predict application performance at scale; (2) detailed understandings of how application features interplay with different fault-tolerance strategies and hardware technologies; (3) new knowledge about application behavior at scale; and (4) valuable insight and prescriptions for designing, developing and deploying future extreme scale HPC systems.\r\n\r\nMore broadly, artifacts like the Iron framework and the public suite of application traces will be valuable to the HPC research, engineering, development, procurement and administrative communities. Researchers can use these artifacts for their own research that can impact the HPC exploration and design space.  For example, this framework can be instrumental in the co-design of cohesive extreme scale applications, software environments and hardware platforms. Additionally, Iron-based research can inform and improve scientific computing practices, accelerating the rate of scientific discovery.  Finally, Iron will be useful as an instructional device to teach about HPC issues both in classroom and tutorial contexts and other programs that engage diverse populations of middle, high school and college students in New Mexico and Tennessee.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dorian",
   "pi_last_name": "Arnold",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Dorian C Arnold",
   "pi_email_addr": "dorian.arnold@emory.edu",
   "nsf_id": "000527625",
   "pi_start_date": "2018-12-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Emory University",
  "inst_street_address": "201 DOWMAN DR NE",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4047272503",
  "inst_zip_code": "303221061",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "EMORY UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "S352L5PJLMP8"
 },
 "perf_inst": {
  "perf_inst_name": "Emory University",
  "perf_str_addr": "1599 Clifton Rd NE",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303224250",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 342000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">The major outcomes of this project extend our understanding of how faults, failures and fault-tolerance strategies impact the performance of different types of application workloads at scale. Specifically:</p>\n<p>Using modeling and simulation techniques, developed in the context of this project, we demonstrated that asynchronous checkpointing strategies can mask entirely the inter-application I/O contentions caused by frequent checkpointing and that checkpointing approaches that use local storage or in-memory/multi-staging have the capacity to provide high scalability. Also, we showed that by combining optimal checkpointing periods with contention-aware system-level I/O scheduling strategies, we can significantly improve overall application performance and maximize the system throughput. Further, specialized hardware like burst buffers can help to mitigate the I/O contention problem.</p>\n<p>Our study of fault-tolerance methods for the detection and correction of floating-point errors in matrix-matrix multiplication, including Algorithm-Based Fault Tolerance (ABFT) and residual checking (RC), revealed similar execution times for the core of each method, but ABFT requires embedding the checksum in the user data in order to benefit from the high-performance kernel implementation, while RC does not. This work also showed that the flexibility of RC becomes very important when error rates are high, because RC can adapt a posteriori to the number of errors encountered within each particular execution.</p>\n<p>We introduced a new rollback/recovery strategy ?the restart strategy?which consists of restarting all failed processes at the beginning of each checkpoint period. This rejuvenation allows the system to remain in the same conditions at the beginning of each checkpointing period, allowing the development of accurate performance model and the derivation of the optimal checkpointing period for this strategy. This optimal period is much longer than the one used with the no-restart strategy, hence reducing significantly the I/O pressure introduced by checkpoints and improving the overall time-to-solution. Another key advantage of the restart strategy is its robustness: the range of periods in which its performance is close to optimal is much larger than for the no-restart strategy, making it a better practical choice to target unreliable platforms where the key elements (MTBF and checkpoint duration) are difficult to estimate.</p>\n<p><br />Our study of current and emerging exascale machine architectures projected that for CPU machines, system efficiency for many workloads can remain above 90% as checkpoint and restart latencies increase, but can drop to as low as 40% for codes that are highly parallelizable. Likewise for projected accelerator based machines, this efficiency can drop to as low as 35%. Summarily, we project that checkpoint/restart methods can still be a viable option for many contemporary exascale architectures, but as the level of parallelizability of the workload increases, other solutions for fault-tolerance may be more suitable.</p>\n<p><br />Lastly, in the project we have demonstrated that it may be feasible to use machine learning approaches like generative adversarial networks to generate synthetic traces that are statistically indistinguishable from real traces and can be used for simulation based studies that depend on application performance traces. When the collection of real application traces is untenable, such synthesis will be valuable for these types of studies and others.</p>\n<ol> </ol><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/10/2023<br>\n\t\t\t\t\tModified by: Dorian&nbsp;C&nbsp;Arnold</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "The major outcomes of this project extend our understanding of how faults, failures and fault-tolerance strategies impact the performance of different types of application workloads at scale. Specifically:\n\nUsing modeling and simulation techniques, developed in the context of this project, we demonstrated that asynchronous checkpointing strategies can mask entirely the inter-application I/O contentions caused by frequent checkpointing and that checkpointing approaches that use local storage or in-memory/multi-staging have the capacity to provide high scalability. Also, we showed that by combining optimal checkpointing periods with contention-aware system-level I/O scheduling strategies, we can significantly improve overall application performance and maximize the system throughput. Further, specialized hardware like burst buffers can help to mitigate the I/O contention problem.\n\nOur study of fault-tolerance methods for the detection and correction of floating-point errors in matrix-matrix multiplication, including Algorithm-Based Fault Tolerance (ABFT) and residual checking (RC), revealed similar execution times for the core of each method, but ABFT requires embedding the checksum in the user data in order to benefit from the high-performance kernel implementation, while RC does not. This work also showed that the flexibility of RC becomes very important when error rates are high, because RC can adapt a posteriori to the number of errors encountered within each particular execution.\n\nWe introduced a new rollback/recovery strategy ?the restart strategy?which consists of restarting all failed processes at the beginning of each checkpoint period. This rejuvenation allows the system to remain in the same conditions at the beginning of each checkpointing period, allowing the development of accurate performance model and the derivation of the optimal checkpointing period for this strategy. This optimal period is much longer than the one used with the no-restart strategy, hence reducing significantly the I/O pressure introduced by checkpoints and improving the overall time-to-solution. Another key advantage of the restart strategy is its robustness: the range of periods in which its performance is close to optimal is much larger than for the no-restart strategy, making it a better practical choice to target unreliable platforms where the key elements (MTBF and checkpoint duration) are difficult to estimate.\n\n\nOur study of current and emerging exascale machine architectures projected that for CPU machines, system efficiency for many workloads can remain above 90% as checkpoint and restart latencies increase, but can drop to as low as 40% for codes that are highly parallelizable. Likewise for projected accelerator based machines, this efficiency can drop to as low as 35%. Summarily, we project that checkpoint/restart methods can still be a viable option for many contemporary exascale architectures, but as the level of parallelizability of the workload increases, other solutions for fault-tolerance may be more suitable.\n\n\nLastly, in the project we have demonstrated that it may be feasible to use machine learning approaches like generative adversarial networks to generate synthetic traces that are statistically indistinguishable from real traces and can be used for simulation based studies that depend on application performance traces. When the collection of real application traces is untenable, such synthesis will be valuable for these types of studies and others.\n \n\n\t\t\t\t\tLast Modified: 01/10/2023\n\n\t\t\t\t\tSubmitted by: Dorian C Arnold"
 }
}