{
 "awd_id": "1844960",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Learning Symbolic Representations for Robot Manipulation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2019-04-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 549988.0,
 "awd_amount": 565988.0,
 "awd_min_amd_letter_date": "2019-03-25",
 "awd_max_amd_letter_date": "2021-07-07",
 "awd_abstract_narration": "Recent years have seen a dramatic improvement in the quality and cost of general-purpose robot hardware. However, programming that hardware to solve any non-trivial task is extremely hard. It would be far preferable if robots could plan to reach user-specified goals on their own, without requiring highly detailed programming. A key challenge here is dealing with the low-level details of sensing and perception, while also reasoning at a high-level about the task to be completed. This project aims to develop a framework that allows robots to learn how to manipulate objects, how to usefully represent those objects abstractly, and how to generalize across objects that appear different but have the same functionality (e.g., different microwaves). This project will develop new algorithms that will enable robots to reason and plan in complex scenarios in the real world; it could therefore substantially accelerate the deployment of complex robots in semi-structured environments like the home, hospitals, light manufacturing facilities, and space. \r\n\r\nThis project aims to enable robots to autonomously learn reusable object-centric motor skills and the portable symbolic representations that support planning with those skills.  Learning motor skills to manipulate, and abstract representations to reason about, objects in the world---while generalizing across objects of similar functionality---will enable robots to generate intelligent, goal-directed mobile manipulation behavior. The project will 1) design practical algorithms that discover motor skills for manipulating objects by interacting with them, 2) design algorithms for generalizing those skills across objects with different appearances but similar functionality, and 3) develop a theoretically sound framework for learning object-centric abstract representations that support goal-directed planning using those skills, and demonstrate its use on a mobile manipulation robot.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "George",
   "pi_last_name": "Konidaris",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "George D Konidaris",
   "pi_email_addr": "George_konidaris@brown.edu",
   "nsf_id": "000732307",
   "pi_start_date": "2019-03-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "Office of Sponsored Projects",
  "perf_city_name": "Providence",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029129093",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 112323.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 131533.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 322132.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The major goal of this project was to enable robots to autonomously learn reusable object-centric motor skills and the portable symbolic representations that support planning with those skills, in order to solve complex mobile manipulation tasks. In the course of the project, w<span>e succeeded in substantially advancing the state of the art in several areas of robotics. We developed more efficiently learning robot motor skills, by bootstrapping them from demonstration or motion planning, by representing them using a new controller policy class, and by improving the efficiency of learning algorithms. For representing and interacting with objects, we developed new algorithms for automatically understanding how objects move from just visual data, and from interaction with them, and for generalizing motor skills (e.g., \"open\") across classes of similar objects (e.g., across all doors, having only learned on a single door). Finaly, we developed new ways for robots to internally represent their manipulation tasks, which will allow them to reason and plan more effectively, including specifically methods for representing objects abstractly, in a way that enables generalization across classes of similar objects.&nbsp;&nbsp;Taken together, these results substantially advance robots' ability to interactively learn how to use objects, and how to reuse that knowledge across new (but similar) objects without having to learn again from scratch.<br /><br /></span></span>Finally, this project also supported the PI's<span>&nbsp;in designing a teaching portfolio that completes and strengthens Brown's offerings. The PI's introductory AI course became a well-entrenched gateway to more specific,&nbsp; advanced courses in various subfields of AI and machine learning, and was then switched&nbsp; to a sophomore level course that became a pre-requisite for more advanced AI courses, and became a required course on the AI pathway. The PI also taught a graduate level&nbsp;</span><span>&nbsp;Reintegrating AI course, which is structured as a way for students to think about how various aspects of AI that have been previously siloed can now be brought back together.</span></p><br>\n<p>\n Last Modified: 02/04/2025<br>\nModified by: George&nbsp;D&nbsp;Konidaris</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe major goal of this project was to enable robots to autonomously learn reusable object-centric motor skills and the portable symbolic representations that support planning with those skills, in order to solve complex mobile manipulation tasks. In the course of the project, we succeeded in substantially advancing the state of the art in several areas of robotics. We developed more efficiently learning robot motor skills, by bootstrapping them from demonstration or motion planning, by representing them using a new controller policy class, and by improving the efficiency of learning algorithms. For representing and interacting with objects, we developed new algorithms for automatically understanding how objects move from just visual data, and from interaction with them, and for generalizing motor skills (e.g., \"open\") across classes of similar objects (e.g., across all doors, having only learned on a single door). Finaly, we developed new ways for robots to internally represent their manipulation tasks, which will allow them to reason and plan more effectively, including specifically methods for representing objects abstractly, in a way that enables generalization across classes of similar objects.Taken together, these results substantially advance robots' ability to interactively learn how to use objects, and how to reuse that knowledge across new (but similar) objects without having to learn again from scratch.\n\nFinally, this project also supported the PI'sin designing a teaching portfolio that completes and strengthens Brown's offerings. The PI's introductory AI course became a well-entrenched gateway to more specific, advanced courses in various subfields of AI and machine learning, and was then switched to a sophomore level course that became a pre-requisite for more advanced AI courses, and became a required course on the AI pathway. The PI also taught a graduate levelReintegrating AI course, which is structured as a way for students to think about how various aspects of AI that have been previously siloed can now be brought back together.\t\t\t\t\tLast Modified: 02/04/2025\n\n\t\t\t\t\tSubmitted by: GeorgeDKonidaris\n"
 }
}