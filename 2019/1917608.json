{
 "awd_id": "1917608",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Learning words and speech sounds in infancy",
 "cfda_num": "47.075",
 "org_code": "04010000",
 "po_phone": "7032927878",
 "po_email": "slim@nsf.gov",
 "po_sign_block_name": "Soo-Siang Lim",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 710801.0,
 "awd_amount": 710801.0,
 "awd_min_amd_letter_date": "2019-07-30",
 "awd_max_amd_letter_date": "2023-08-08",
 "awd_abstract_narration": "This project aims to discover how infants begin to learn words and speech sounds in the first year.  When infants first hear speech, they do not know what parts of each sentence correspond to individual words. They probably do not even have the idea that words exist, but must discover it. This project uses what is known about infants' speech perception and memory to test what infants can learn from the speech signal. This will be done by making and annotating recordings of mothers at home speaking to their infants. The researchers will carefully measure the acoustics of words and speech sounds like consonants and vowels, and will use computer models to estimate what language information could be available to the naive infant.  By linking together these estimates, and infants' language accomplishments (like vocabulary) as toddlers, it is possible to test how the maternal language environment provides for infant learning, and will permit discovery of what features make learning easiest for babies. The project will measure a diverse sample of mothers and children from Philadelphia and from elsewhere in the country. Understanding how language learning begins in young infants is important for understanding variability in young children's language related outcomes. It is also important for giving parents guidance about how to encourage language skill even in their very young children. Ultimately this will give us a better understanding of the beginnings of language development.\r\n\r\nThis project aims to discover how infants begin to learn words and speech sounds in the first year.  In doing so the project will flesh out and challenge the proposal that infants learn speech sounds by learning the forms of words, contra the dominant view that infant phonetic learning is initially independent of the nascent lexicon. Central to the project is the de novo creation of a longitudinal corpus of infant-directed speech in African-American (AA) families, and the coordinated annotation of lexical and phonetic features in both this AA corpus and in the mainstream-English Seedlings corpus. The project will allow characterization, in unprecedented detail, of the consequences of specific maternal behaviors for specific learning outcomes in children, down to the individual word level. The research will evaluate the degree to which these relationships hold in both low and high SES families. The project will also use sensitive laboratory methods, including eye-tracking analysis of infants' fixation to named pictures, to evaluate the phonetic specificity of infants' early representations of words. The result will be a quantitatively specified characterization of how infants begin to learn how their language works.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SMA",
 "org_div_long_name": "SBE Office of Multidisciplinary Activities",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Swingley",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel Swingley",
   "pi_email_addr": "swingley@psych.upenn.edu",
   "nsf_id": "000177927",
   "pi_start_date": "2019-07-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "425 S. University Ave",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046018",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "004Y00",
   "pgm_ele_name": "Science of Learning"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "059Z",
   "pgm_ref_txt": "Science of Learning"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 710801.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research project was about how children begin to learn their language, starting in infancy. Our project had two goals: first, to measure what children actually know at very young ages; and second, to understand how they learn, by carefully measuring their speech environment.</p>\n<p>To measure what children know, we invited parents to participate in studies with their infants. In one study, 6-14 month olds were shown pairs of images on a computer screen, while a prerecorded voice named one of the images (&ldquo;Look at the bottle.&rdquo;). From about 9 months onward, children indeed looked more at the named picture, which tells us that they understood the word for it.&nbsp;&nbsp;They looked at this picture less, though, when we spoke the first consonant differently (&ldquo;Look at the nottle.&rdquo;). This means that even at 9 months, when children are mostly just babbling, they know how familiar words are supposed to sound. In another study, older children (18-24 months) were tested as they followed along with a spoken story, choosing to look at the pictures matching the story. Children recognized words (looked at the right pictures) when the words were emphasized (&ldquo;She takes the&nbsp;<em><span style=\"text-decoration: underline;\">apple</span></em>&nbsp;out of the fridge.&rdquo; But surprisingly, they didn&rsquo;t recognize words at all when words were pronounced more quickly and casually. Adults given exactly the same task were equally perfect at both emphasized and reduced pronunciations. This surprising result tells us that the phonetic clarity of speech really matters for children&rsquo;s understanding. We showed that children have excellent knowledge of words and speech sounds; but, from instance to instance, there is probably a lot of speech that they do not understand. To help measure this, we invented a new procedure for evaluating word recognition in infants while they play with their parent. Toddlers wear eyetracking glasses, and we measure where they look next whenever parents name an object that the child isn&rsquo;t already looking at. Toddlers frequently look to the named object and gaze longer at it than when they happen to look at a different object. This new procedure allows us to measure which nouns toddlers understand while they are playing, in real-life conversation.&nbsp;</p>\n<p>The fact that even typically-developing children know so much and yet struggle with much of the speech they hear makes it all the more important to characterize the speech directed to infants. When is speech clear enough for children to learn from and understand? We found that parents use words more clearly when the thing they are talking about is more obvious in the scene, and less clearly when their referential focus is more obscure. Parents don&rsquo;t compensate for confusing referential situations by making their speech phonetically clearer. Instead, they seem to present to infants some really good learning instances, and many quite poor learning instances. Most theories of language acquisition treat all the learning examples as equally valuable, but they are not. We also evaluated the details of parental speech by asking adults to identify speech sounds (consonants) in short speech clips.&nbsp;&nbsp;We found that only about half of the consonants in infant-directed speech are consistently identifiable. As adults, we understand sentences because we can &ldquo;fill in&rdquo; what isn&rsquo;t articulatorily clear. But babies do not have an adult understanding yet and cannot &ldquo;fill in&rdquo; this way.&nbsp;</p>\n<p>How, then, do infants succeed? The way to find out is by carefully documenting and examining what language they hear, and building models of the learning process. We made hour-long recordings of parents speaking to their infants of 6, 10, and 14 months (longitudinally), and have begun to transcribe this speech, noting not only which words infants heard, but also how parents pronounced those words sound by sound. Our new recordings were all of African-American/Black parents living in and around Philadelphia, helping to redress imbalances in the composition of existing research datasets. As of this writing we have more than 3,000 utterances transcribed from our Philadelphia sample. We have also annotated a comparison set of more than 2,000 utterances transcribed from a previous corpus of White upstate-NY parents. Together this makes the largest phonetically annotated dataset for the study of parental speech in any language. Under the current project we have developed methods for testing exactly when parental speech presents the sort of clarity and careful articulation that is apparently necessary for infants and toddlers to understand speech well, and when it does not.</p>\n<p>To summarize, infants have good knowledge of words and sounds, but their skills of interpretation in-the-moment are relatively underdeveloped, and their language environments are less supportive than is usually imagined. We have created new empirical tools and unique research datasets that will allow researchers to develop more accurate quantitative models of how language acquisition begins in infants.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 07/30/2024<br>\nModified by: Daniel&nbsp;Swingley</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis research project was about how children begin to learn their language, starting in infancy. Our project had two goals: first, to measure what children actually know at very young ages; and second, to understand how they learn, by carefully measuring their speech environment.\n\n\nTo measure what children know, we invited parents to participate in studies with their infants. In one study, 6-14 month olds were shown pairs of images on a computer screen, while a prerecorded voice named one of the images (Look at the bottle.). From about 9 months onward, children indeed looked more at the named picture, which tells us that they understood the word for it.They looked at this picture less, though, when we spoke the first consonant differently (Look at the nottle.). This means that even at 9 months, when children are mostly just babbling, they know how familiar words are supposed to sound. In another study, older children (18-24 months) were tested as they followed along with a spoken story, choosing to look at the pictures matching the story. Children recognized words (looked at the right pictures) when the words were emphasized (She takes theappleout of the fridge. But surprisingly, they didnt recognize words at all when words were pronounced more quickly and casually. Adults given exactly the same task were equally perfect at both emphasized and reduced pronunciations. This surprising result tells us that the phonetic clarity of speech really matters for childrens understanding. We showed that children have excellent knowledge of words and speech sounds; but, from instance to instance, there is probably a lot of speech that they do not understand. To help measure this, we invented a new procedure for evaluating word recognition in infants while they play with their parent. Toddlers wear eyetracking glasses, and we measure where they look next whenever parents name an object that the child isnt already looking at. Toddlers frequently look to the named object and gaze longer at it than when they happen to look at a different object. This new procedure allows us to measure which nouns toddlers understand while they are playing, in real-life conversation.\n\n\nThe fact that even typically-developing children know so much and yet struggle with much of the speech they hear makes it all the more important to characterize the speech directed to infants. When is speech clear enough for children to learn from and understand? We found that parents use words more clearly when the thing they are talking about is more obvious in the scene, and less clearly when their referential focus is more obscure. Parents dont compensate for confusing referential situations by making their speech phonetically clearer. Instead, they seem to present to infants some really good learning instances, and many quite poor learning instances. Most theories of language acquisition treat all the learning examples as equally valuable, but they are not. We also evaluated the details of parental speech by asking adults to identify speech sounds (consonants) in short speech clips.We found that only about half of the consonants in infant-directed speech are consistently identifiable. As adults, we understand sentences because we can fill in what isnt articulatorily clear. But babies do not have an adult understanding yet and cannot fill in this way.\n\n\nHow, then, do infants succeed? The way to find out is by carefully documenting and examining what language they hear, and building models of the learning process. We made hour-long recordings of parents speaking to their infants of 6, 10, and 14 months (longitudinally), and have begun to transcribe this speech, noting not only which words infants heard, but also how parents pronounced those words sound by sound. Our new recordings were all of African-American/Black parents living in and around Philadelphia, helping to redress imbalances in the composition of existing research datasets. As of this writing we have more than 3,000 utterances transcribed from our Philadelphia sample. We have also annotated a comparison set of more than 2,000 utterances transcribed from a previous corpus of White upstate-NY parents. Together this makes the largest phonetically annotated dataset for the study of parental speech in any language. Under the current project we have developed methods for testing exactly when parental speech presents the sort of clarity and careful articulation that is apparently necessary for infants and toddlers to understand speech well, and when it does not.\n\n\nTo summarize, infants have good knowledge of words and sounds, but their skills of interpretation in-the-moment are relatively underdeveloped, and their language environments are less supportive than is usually imagined. We have created new empirical tools and unique research datasets that will allow researchers to develop more accurate quantitative models of how language acquisition begins in infants.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 07/30/2024\n\n\t\t\t\t\tSubmitted by: DanielSwingley\n"
 }
}