{
 "awd_id": "1926174",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Standard: Ethics-in-the-Making: Changing Practices in Data Science",
 "cfda_num": "47.075",
 "org_code": "04010000",
 "po_phone": "7032925034",
 "po_email": "wbauchsp@nsf.gov",
 "po_sign_block_name": "Wenda K. Bauchspies",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 352121.0,
 "awd_amount": 352121.0,
 "awd_min_amd_letter_date": "2019-07-31",
 "awd_max_amd_letter_date": "2019-07-31",
 "awd_abstract_narration": "A nontechnical description of the project, which explains the project's significance and importance.  \r\n\r\nThis award supports a research project that studies the phenomenon of ethics-in-the-making in data science and machine learning. Specifically, the project will focus on both research and development contexts where prediction and classification models are used to study risks, especially health and financial risks. The research team will provide an account of how ethics emerges in practice in these contexts, and it will identify points where different ways of envisioning and doing ethics diverge and converge. The analysis will shed light on the production, reception, and influence of the prediction and classification systems and research practices that express specific understandings of what it means to do ethical data science and machine learning projects. Understanding the dynamics of ethical change in prediction and classification research is of utmost importance given how fast these models are being woven into the fabric of society. Changes introduced via ethics-in-the-making can strengthen, weaken, or otherwise affect the moral and structural integrity of science and the political legitimacy of scientific institutions.\r\n\r\nThe researchers propose to use qualitative research methods to investigate empirically how ethical standards and practices are being reconfigured in prediction and classification research and development. The research team will study the process of building ethically significant forms of accountability and control into prediction and classification research practices; and the team will examine the ways that prediction and classification researchers conceptualize ethical issues in their work. Of special interest is what practices and systems researchers consider ethically problematic or unproblematic, and why. The study will provide a timely basis for cultivating ethical practice in contemporary data science. Specifically, the project will document existing and potentially uncover new ethical challenges and opportunities; disseminate findings in academic journals; contribute to societal debate with perspective pieces in scientific journals; produce a white paper for data scientists and practitioners in academia and industry; and develop a set of pedagogical case studies intended to help students and professionals reflect on data science ethics. Finally, the findings will be incorporated into a curriculum development project, the 'Data Science & Society Lab,' which will be made available on an open access basis.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SMA",
 "org_div_long_name": "SBE Office of Multidisciplinary Activities",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Stephen",
   "pi_last_name": "Hilgartner",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Stephen Hilgartner",
   "pi_email_addr": "shh6@cornell.edu",
   "nsf_id": "000172468",
   "pi_start_date": "2019-07-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Bruce",
   "pi_last_name": "Lewenstein",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Bruce V Lewenstein",
   "pi_email_addr": "BVL1@cornell.edu",
   "nsf_id": "000461220",
   "pi_start_date": "2019-07-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Malte",
   "pi_last_name": "Ziewitz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Malte Ziewitz",
   "pi_email_addr": "mcz35@cornell.edu",
   "nsf_id": "000695136",
   "pi_start_date": "2019-07-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kim",
   "pi_last_name": "Overby",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Kim J Overby",
   "pi_email_addr": "kjo46@cornell.edu",
   "nsf_id": "000798448",
   "pi_start_date": "2019-07-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "303 Morrill Hall",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148534701",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "125300",
   "pgm_ele_name": "OFFICE OF MULTIDISCIPLINARY AC"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 352121.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The purpose of this project was to investigate how decisions with ethical dimensions are being made as data science and machine learning (ML) research and development (R&amp;D) takes place. Our goal was to understand &ldquo;ethics-in-the-making&rdquo; during the R&amp;D process. Rather than thinking of ethical and policy decisions as something taking place only after ML and AI technologies are fully formed, the ethics-in-the-making approach looks at how forms of accountability, control, and responsibility were built into research practices, technologies and applications during R&amp;D. We also interviewed ML researchers about how they conceptualize ethical issues relevant to their work. We sought to develop empirically grounded theory about ethics-in-the-making in ML and AI not only because they are important, fast-moving areas of R&amp;D and application but also because we expected that the findings would be relevant to other areas of contemporary STEM.</p>\r\n<p>The project used several interconnected research methods, including interviewing scientists, engineers, and others involved in developing this technology, attending and observing several relevant scientific meetings, examining documents and websites, and conducting a systematic analysis of media coverage. As planned, we built a research team that included graduate students, as well as undergraduate research assistants, and all these students got valuable, hands-on research experience. Our planned outcomes included producing academic publications, training PhD students, engaging with data scientists and practitioners in academia and industry, and developing a white paper and other pedagogical materials to make available on an open access basis. Work was delayed by the pandemic, but we were able to complete the research.</p>\r\n<p>The project found that the ethics-in-the-making approach (1) could use these research methods to identify cases in which decisions of societal importance were being incorporated into emerging systems, and (2) could make alternatives and options visible. Specific cases examined include automated pain management technology, credibility of AI in high-stakes contexts, cheating and its detection and management, and chatbots in human communication. Analysis of project data continues. So far, two academic papers are in press in edited volumes, and two more are under review in top journals in this area. One PhD student partially supported by the project has completed his dissertation, and a second student is expected to complete his PhD dissertation in spring 2025. Additional graduate and undergraduate students received training in research methods. A peer-reviewed, open-access white paper/primer has been made available. Additional papers by members of the research team are expected to be submitted for publication soon.</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/20/2025<br>\nModified by: Stephen&nbsp;Hilgartner</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe purpose of this project was to investigate how decisions with ethical dimensions are being made as data science and machine learning (ML) research and development (R&D) takes place. Our goal was to understand ethics-in-the-making during the R&D process. Rather than thinking of ethical and policy decisions as something taking place only after ML and AI technologies are fully formed, the ethics-in-the-making approach looks at how forms of accountability, control, and responsibility were built into research practices, technologies and applications during R&D. We also interviewed ML researchers about how they conceptualize ethical issues relevant to their work. We sought to develop empirically grounded theory about ethics-in-the-making in ML and AI not only because they are important, fast-moving areas of R&D and application but also because we expected that the findings would be relevant to other areas of contemporary STEM.\r\n\n\nThe project used several interconnected research methods, including interviewing scientists, engineers, and others involved in developing this technology, attending and observing several relevant scientific meetings, examining documents and websites, and conducting a systematic analysis of media coverage. As planned, we built a research team that included graduate students, as well as undergraduate research assistants, and all these students got valuable, hands-on research experience. Our planned outcomes included producing academic publications, training PhD students, engaging with data scientists and practitioners in academia and industry, and developing a white paper and other pedagogical materials to make available on an open access basis. Work was delayed by the pandemic, but we were able to complete the research.\r\n\n\nThe project found that the ethics-in-the-making approach (1) could use these research methods to identify cases in which decisions of societal importance were being incorporated into emerging systems, and (2) could make alternatives and options visible. Specific cases examined include automated pain management technology, credibility of AI in high-stakes contexts, cheating and its detection and management, and chatbots in human communication. Analysis of project data continues. So far, two academic papers are in press in edited volumes, and two more are under review in top journals in this area. One PhD student partially supported by the project has completed his dissertation, and a second student is expected to complete his PhD dissertation in spring 2025. Additional graduate and undergraduate students received training in research methods. A peer-reviewed, open-access white paper/primer has been made available. Additional papers by members of the research team are expected to be submitted for publication soon.\r\n\n\n\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 02/20/2025\n\n\t\t\t\t\tSubmitted by: StephenHilgartner\n"
 }
}