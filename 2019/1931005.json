{
 "awd_id": "1931005",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SaTC: CORE: Small: Collaborative: Understanding and Mitigating Adversarial Manipulation of Content Curation Algorithms",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2019-01-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 249999.0,
 "awd_amount": 249999.0,
 "awd_min_amd_letter_date": "2019-06-10",
 "awd_max_amd_letter_date": "2019-06-10",
 "awd_abstract_narration": "Online social networks (OSNs) have fundamentally transformed how billions of people use the Internet. These users are increasingly discovering books, music bands, TV shows, movies, news articles, products, and other content through posts from trusted users that they follow. All major OSNs have deployed content curation algorithms that are designed to increase interaction and act as the \"gatekeepers\" of what users see. While this curation and filtering is useful and necessary given the amount of content available, it has also exposed people and platforms to manipulation attacks whereby bad actors attempt to promote content people would otherwise prefer not to see. This has driven the creation of an underground ecosystem that provides services and techniques tailored towards subverting OSNs' content curation algorithms for economic and ideological gains. This project will conduct open research to improve our understanding of current algorithmic curation attackers. The team will devise content curation algorithms and defenses which are hardened against manipulation and that can be adopted by these OSN platforms, providing a systematic approach to improving design and practice in an area of critical national importance. Technology transfer from this project will protect the integrity of social media discourse from adversarial manipulation. This project will train students with expertise in security and machine learning, areas of broad national need, and produce educational materials to engage both high school students and the public in these critical questions.\r\n \r\nThe team will holistically explore the economic, social, and technical perspectives of machine learning-based content curation algorithms' weaknesses. The research comprises three main activities: 1) understand how OSNs are currently being successfully manipulated at large scales, 2) investigate the defenses OSNs have in place, and 3) design more resilient defenses. The team will build the first-ever taxonomy of manipulation services and techniques that are actively used to manipulate curation algorithms. Another thrust of the project is to create a framework for the external evaluation of deployed manipulation defenses based on the collection of both public data from the OSN's platform and external data to compare it against. The team will then develop robust and scalable algorithms to detect OSN manipulation within the collected data. Finally, the team will use the insights from the taxonomy of effective manipulation techniques and the exploration of the limitation of current defenses to design fundamentally resilient content curation algorithms. The project will explore both new curation algorithms and more effective mitigation techniques for existing algorithms. The project's findings will deepen our understanding of social network manipulation and adversarial learning and produce reliable approaches to algorithmic content curation.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rachel",
   "pi_last_name": "Greenstadt",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rachel Greenstadt",
   "pi_email_addr": "greenstadt@nyu.edu",
   "nsf_id": "000514368",
   "pi_start_date": "2019-06-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "2 MetroTech Center",
  "perf_city_name": "Brooklyn",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "112013846",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "NY07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 249999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-c3dc3afb-7fff-d8e6-4ac0-1259f96d2818\">\n<p dir=\"ltr\"><span>Social Media and Online Advertising Networks have become the de facto town square for public discourse. The content curation algorithms deployed by these networks are the arbiters of what messages are seen by people using social media. Thus, it is of paramount importance that these content curation algorithms be robust against adversarial manipulation.</span></p>\n<br />\n<p dir=\"ltr\"><span>Our project has leveraged cutting-edge machine-learning techniques to detect and mitigate attacks against these content curation algorithms. We have developed frameworks that consist of privacy-preserving data collection and machine-learning models that enable independent detection of content curation algorithm manipulations. </span><span>We have conducted large, carefully designed case studies validating our approaches (e.g., misinformation, news sources, financial groups, and influencers). Our approaches are able to detect collusion networks that engage in reciprocal interactions. We have also created techniques to detect sockpuppet attacks where an adversary creates multiple accounts to fabricate conversations and engagement aimed at promoting content. In addition, we have studied how misinformation often attracts more engagement which often results in content-curation algorithms amplifying the spread of misinformation. In collaboration with Meta, we also developed a pipeline to detect adversarial text perturbations and created a model that is robust to these attacks. Finally, we have shown how utilizing cutting-edge data science approaches allows us to design techniques that are able to produce more robust content curation algorithms. Together, this work has validated our core idea that machine-learning approaches can significantly improve how we detect and mitigate a wide range of content curation algorithm attacks.</span></p>\n<br />\n<p dir=\"ltr\"><span>We have been able to conduct our work both independently through privacy-preserving data collection and through an industry research collaboration with Meta. As a consequence, we have been able to independently explore parts of the problem that are difficult for industry to study. In addition, we have been able to transition parts of our work to industry through students interning with Meta. Our findings have also been integrated into numerous journalists&rsquo; articles which have helped educate the public about these security issues. The work has also created numerous educational opportunities, including undergraduate and graduate education as well as workforce education for K-12 teachers, civil society groups, and journalists.</span></p>\n<br />\n<p dir=\"ltr\"><span>We have affirmed the thesis of this project that content curation algorithms can be improved by creating techniques based on cutting-edge data science. The detection and mitigation approaches that we created have been released as open source so that they can be adopted by social media networks, online ad networks, and other independent third-party auditors. </span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/31/2022<br>\n\t\t\t\t\tModified by: Rachel&nbsp;Greenstadt</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nSocial Media and Online Advertising Networks have become the de facto town square for public discourse. The content curation algorithms deployed by these networks are the arbiters of what messages are seen by people using social media. Thus, it is of paramount importance that these content curation algorithms be robust against adversarial manipulation.\n\n\nOur project has leveraged cutting-edge machine-learning techniques to detect and mitigate attacks against these content curation algorithms. We have developed frameworks that consist of privacy-preserving data collection and machine-learning models that enable independent detection of content curation algorithm manipulations. We have conducted large, carefully designed case studies validating our approaches (e.g., misinformation, news sources, financial groups, and influencers). Our approaches are able to detect collusion networks that engage in reciprocal interactions. We have also created techniques to detect sockpuppet attacks where an adversary creates multiple accounts to fabricate conversations and engagement aimed at promoting content. In addition, we have studied how misinformation often attracts more engagement which often results in content-curation algorithms amplifying the spread of misinformation. In collaboration with Meta, we also developed a pipeline to detect adversarial text perturbations and created a model that is robust to these attacks. Finally, we have shown how utilizing cutting-edge data science approaches allows us to design techniques that are able to produce more robust content curation algorithms. Together, this work has validated our core idea that machine-learning approaches can significantly improve how we detect and mitigate a wide range of content curation algorithm attacks.\n\n\nWe have been able to conduct our work both independently through privacy-preserving data collection and through an industry research collaboration with Meta. As a consequence, we have been able to independently explore parts of the problem that are difficult for industry to study. In addition, we have been able to transition parts of our work to industry through students interning with Meta. Our findings have also been integrated into numerous journalists\u2019 articles which have helped educate the public about these security issues. The work has also created numerous educational opportunities, including undergraduate and graduate education as well as workforce education for K-12 teachers, civil society groups, and journalists.\n\n\nWe have affirmed the thesis of this project that content curation algorithms can be improved by creating techniques based on cutting-edge data science. The detection and mitigation approaches that we created have been released as open source so that they can be adopted by social media networks, online ad networks, and other independent third-party auditors. \n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 10/31/2022\n\n\t\t\t\t\tSubmitted by: Rachel Greenstadt"
 }
}