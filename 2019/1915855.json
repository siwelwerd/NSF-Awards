{
 "awd_id": "1915855",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "A Unifying Framework for High-Dimensional Additive Modeling",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 219993.0,
 "awd_amount": 219993.0,
 "awd_min_amd_letter_date": "2019-07-25",
 "awd_max_amd_letter_date": "2019-07-25",
 "awd_abstract_narration": "Recent technological advances have provided researchers with a wealth of data. Unlocking the potential of these vast data sources often involves linking a response variable (e.g., the presence of a disease, or a positive response to a treatment) to a large number of potential features of interest (e.g. gene expression levels or activities of brain regions). It is increasingly common to measure a large number of features (thousands or more), on a small number of subjects (or patients). Generally, only a small number of these features are related to the response variable. To determine those relevant features, statistical/machine-learning modelling algorithms are used to automatically select a small subset of features that are most predictive of response. Many of these algorithms enforce strong restrictions on the models they allow; e.g. linearity. In scientific domains, where only a small number of subjects are measured, these restrictions can be useful: building more complex models requires more subjects. However, they are sometimes overly restrictive. In this project, a framework to estimate less restrictive (additive) models that employ variable selection in high-dimensional problems will be developed. This framework will help overcome a number of computational challenges. It will additionally lay a theoretical foundation for analyzing the statistical behavior of such high dimensional estimators (that will include the impact of finite computational resources). A publicly available software implementation for flexible high-dimensional modeling will also be developed.\r\n\r\nThis project engages seminal questions in nonparametric estimation and penalized regression. Generally, the computational and theoretical challenges of sparse nonparametric regression in high dimensions are studied separately: Iterative algorithms are constructed that eventually get within a prespecified tolerance of the minimum, while statistical properties (e.g. convergence rates) of the exact minimizer are studied. In addition, for non-parametric problems, existing theoretical studies have often focused on statistical properties when the structure implied by the objective (e.g., sparsity) holds exactly. This project aims to merge the study of computational and statistical optimality, in the setting of high-dimensional additive, and more general nonparametric, models. More specifically, it aims to analyze the statistical properties of approximate, rather than exact, minimizers; from there, it characterizes the number of descent iterations needed to obtain estimators with optimality guarantees. In addition, the project aims to extend these ideas to settings where the structure/smoothness may be misspecified. To address these challenges, the project brings together ideas from convex optimization, empirical process theory, penalized regression, and approximation theory, and will serve as a template for engaging those bodies of knowledge together.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Noah",
   "pi_last_name": "Simon",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Noah Simon",
   "pi_email_addr": "nrsimon@uw.edu",
   "nsf_id": "000682576",
   "pi_start_date": "2019-07-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ali",
   "pi_last_name": "Shojaie",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ali Shojaie",
   "pi_email_addr": "ashojaie@uw.edu",
   "nsf_id": "000601330",
   "pi_start_date": "2019-07-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "1705 NE Pacific St, F600 HSB",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981957232",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 219993.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project we developed mathematical methods, computational algorithms and open source software for fitting flexible methods to learn about associations between potentially high dimensional feature variables and outcomes (eg. how genetic and genomic information might relate to various observable phenotypes, including risk of developing various diseases). In addition to the development of these methods and algorithms, we identified and proved theoretical results that show, in some cases, these methods are \"optimal\" (ie. cannot be improved upon given the type of data that they are engaging with). These results were disseminated with published papers and software. These methods can be applied to a broad range of problems in, eg. genomics, neurology, computational immunology, epidemiology among other areas; they can also be combined with contemporary advances in causal inference with machine learning to give a powerful toolset for learning from data.</p>\n<p>In addition, we supported the equitable development of a data-savvy workforce by 1) running and engaging with summer programs aimed to training students from underserved groups in data science ideas and methods; 2) teaching a variety of short courses on data science, machine learning, and computational biology; and 3) developing publicly available videos and curricula for training data scientists.</p>\n<p>We also supported this effort by direct mentorship of graduate students and staff scientists.</p><br>\n<p>\n Last Modified: 02/10/2024<br>\nModified by: Noah&nbsp;Simon</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn this project we developed mathematical methods, computational algorithms and open source software for fitting flexible methods to learn about associations between potentially high dimensional feature variables and outcomes (eg. how genetic and genomic information might relate to various observable phenotypes, including risk of developing various diseases). In addition to the development of these methods and algorithms, we identified and proved theoretical results that show, in some cases, these methods are \"optimal\" (ie. cannot be improved upon given the type of data that they are engaging with). These results were disseminated with published papers and software. These methods can be applied to a broad range of problems in, eg. genomics, neurology, computational immunology, epidemiology among other areas; they can also be combined with contemporary advances in causal inference with machine learning to give a powerful toolset for learning from data.\n\n\nIn addition, we supported the equitable development of a data-savvy workforce by 1) running and engaging with summer programs aimed to training students from underserved groups in data science ideas and methods; 2) teaching a variety of short courses on data science, machine learning, and computational biology; and 3) developing publicly available videos and curricula for training data scientists.\n\n\nWe also supported this effort by direct mentorship of graduate students and staff scientists.\t\t\t\t\tLast Modified: 02/10/2024\n\n\t\t\t\t\tSubmitted by: NoahSimon\n"
 }
}