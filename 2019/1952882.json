{
 "awd_id": "1952882",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Machine Learning in Macroeconomic Modeling",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927280",
 "po_email": "nlutz@nsf.gov",
 "po_sign_block_name": "Nancy Lutz",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 252054.0,
 "awd_amount": 252054.0,
 "awd_min_amd_letter_date": "2019-09-18",
 "awd_max_amd_letter_date": "2019-09-18",
 "awd_abstract_narration": "This award funds research that will examine whether incorporating machine learning algorithms into macroeconomic models can result in better ways to understand modern economies.  The project will begin by assuming that individual consumers, workers, and firms can be modeled as making their decisions according to a particular type of machine learning algorithm (a boosting algorithm). The project seeks to understand the conditions under which a machine learning algorithm can emulate the decision-making process of a rational individual. The team will also analyze likely long run economic outcomes when these algorithms are used under various institutional and informational assumptions. The project, therefore, may develop a valuable new technique for modeling individual decisions in the context of an entire economic system. It could also help us understand how future economic outcomes may be affected by the increased use of machine learning methods to aid or even substitute for human decision making. The project could therefore help guide efforts to improve the competitiveness of the US economy.\r\n\r\nThe research team will exploit one of the central components of the machine learning algorithm, called the boosting algorithm, to build a highly accurate forecasting rule from a collection of rudimentary and possibly inaccurate forecasting rules. The usual approach in economic models is to assume that the agents (individuals, firms, etc.) are typically endowed with misspecified models. When this is the case, an individual or firm's decision-making process typically relies on simple, yet well fit, forecasting rules, which can differ from the true data generating process. The team aim to understand whether an agent endowed with flawed but well fit models can behave as if she knows the true data generating process.  The team plans to pursue this objective in two steps. In the first part of the project, the team will examine learning dynamics under misspecified models.  As an example, it examines a new class of learning models in which the agent has to learn the growth rate instead of the level of a variable of interest. In many macroeconomic models, the growth rate (e.g., inflation rate) rather than the level of a variable (e.g., price) is the main focus of the investigation.  Assuming that the agent learns the growth rate through a recursive learning process rather than rational expectations may result in better explanations of important macroeconomic dynamics, such as recurrent hyperinflation and stock price volatility. The second step in the research plan investigates the dynamics of a specific machine learning algorithm with two research objectives:  [1] if an agent is endowed with misspecified models, how the decision maker can test and build a new model to improve the forecast, and [2] what are the asymptotic properties of the processes of constructing new models, in particular whether the agent can emulate the rational agent in the long run.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "In-Koo",
   "pi_last_name": "Cho",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "In-Koo Cho",
   "pi_email_addr": "in-koo.cho@emory.edu",
   "nsf_id": "000198663",
   "pi_start_date": "2019-09-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Emory University",
  "inst_street_address": "201 DOWMAN DR NE",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4047272503",
  "inst_zip_code": "303221061",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "EMORY UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "S352L5PJLMP8"
 },
 "perf_inst": {
  "perf_inst_name": "Emory University",
  "perf_str_addr": "",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303224250",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132000",
   "pgm_ele_name": "Economics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 252054.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>PI has pursued three major research projects, inspired by machine learning and artificial intelligence (AI), covering a broad range of economic problems such as model averaging, decision-making under uncertainty, monopoly and oligopolistic markets.</p>\n<p><strong>Learning with misspecified models.</strong> In the joint project with Ravikumar, we explore the foundation of the equilibrium selection rule based on the stability of the learning dynamics. The two papers with Ravikumar illustrate a challenge in analyzing the learning algorithms resulting in second-order difference equations. In a simple monetary model, we show that the learning dynamics do not converge to the rational expectations of a monetary steady state. To guarantee convergence, the gain parameter used in the learning rule has to be restricted based on economic fundamentals in the monetary model. The learning model's stability is often considered an important criterion for equilibrium selection, especially when multiple rational expectations equilibria exist. We apply the stability of learning equilibrium as a criterion in a simple monetary economy featuring multiple rational-expectations steady states to select a steady state. A seemingly minor variation in the information assumption on prices could lead to a different learning equilibrium and can drastically alter the conclusion. We present a cautionary note that the widely used selection rule based on the stability of learning dynamics is not stable with respect to a slight change in specification.</p>\n<p><strong>Algorithms play games</strong>. The joint project with Libgober is inspired by machine learning models, particularly the boosting algorithm that constructs an elaborate model specification from a collection of simple, potentially misspecified models in response to the data. Since rational expectations require excessively elaborate forecasting rules for a decision-maker, the boosting algorithm offers an intuitive way to explain how a decision-maker with limited computational capability can learn to behave as if he is a rational player. We analyze how algorithms can induce rational play in settings featuring sequential moves and exogenous uncertainty. Our goal is to examine whether a decision-maker can learn to play an optimal action when he possesses an underspecified model. As a laboratory, we choose a monopoly market where the monopolist is initially endowed with a partial specification of the true demand curve. We formulate the learning dynamics as an algorithm that chooses the specification of the demand curve in response to the history of outcomes. We represent the monopolist's decision problem as a zero-sum game against nature, which chooses the true demand curve, while the monopolist chooses an algorithm to maximize the long-run average payoff. Instead of the maxmin strategy, the monopolist seeks a dominant algorithm that learns the profit-maximizing outcome against any true demand. We construct a dominant algorithm that is the simplest among all dominant algorithms. For the set of demand curves with strictly decreasing uniformly Lipschitz continuous marginal revenue curve, our algorithm recursively estimates the slope and intercept of a linear demand curve, even if the actual demand curve is not linear. The monopolist chooses a misspecified model to save computational cost. A misspecified model is not an evidence of biased perception or behavioral constraints but a representation of procedural rationality.</p>\n<p><strong>Collusion through algorithm</strong>. The joint project with Noah Williams examines a simple duopoly market populated by two myopic firms producing strategic complements with (unknown) linear demand curves. Each firm entertains two different hypotheses about the opponent's response: a fixed but unknown action (Nash behavior) and a linear reaction function to its price. Instead of committing to a particular hypothesis, a firm hedges against model uncertainty by mixing the two hypotheses but adjusting the probability weight to each model according to the profit generated under the hypothesis. Based on the data, each firm updates the coefficient of each hypothesis. If each firm is committed to believing in the Nash hypothesis, then the Nash equilibrium is realized, eliminating any possibility of a collusive outcome. If so, a collusive outcome is evidence of collusion between the two firms. However, if each firm is averaging the forecasts of the two hypotheses, the long-run probability weight assigned to the reaction function hypothesis converges to 1 and generates a sample path that regularly deviates from the Nash equilibrium outcome (competitive outcome) to the cartel outcome (collusive outcome) and returns to Nash equilibrium outcome. We rigorously eliminate any channel of collusion by shutting down communication among players and blocking any possible punishment for a deviation. Nevertheless, the market outcome appears to indicate that the two firms regularly collude. It would be wrong to conclude that the collusive outcomes among algorithmic players imply implicit or explicit collusion among firms without other evidence. The endogenous selection of forecasting rules in response to the data lets the duopolists behave as if they collude, which is the central property of a machine learning algorithm.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/01/2023<br>\n\t\t\t\t\tModified by: In-Koo&nbsp;Cho</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nPI has pursued three major research projects, inspired by machine learning and artificial intelligence (AI), covering a broad range of economic problems such as model averaging, decision-making under uncertainty, monopoly and oligopolistic markets.\n\nLearning with misspecified models. In the joint project with Ravikumar, we explore the foundation of the equilibrium selection rule based on the stability of the learning dynamics. The two papers with Ravikumar illustrate a challenge in analyzing the learning algorithms resulting in second-order difference equations. In a simple monetary model, we show that the learning dynamics do not converge to the rational expectations of a monetary steady state. To guarantee convergence, the gain parameter used in the learning rule has to be restricted based on economic fundamentals in the monetary model. The learning model's stability is often considered an important criterion for equilibrium selection, especially when multiple rational expectations equilibria exist. We apply the stability of learning equilibrium as a criterion in a simple monetary economy featuring multiple rational-expectations steady states to select a steady state. A seemingly minor variation in the information assumption on prices could lead to a different learning equilibrium and can drastically alter the conclusion. We present a cautionary note that the widely used selection rule based on the stability of learning dynamics is not stable with respect to a slight change in specification.\n\nAlgorithms play games. The joint project with Libgober is inspired by machine learning models, particularly the boosting algorithm that constructs an elaborate model specification from a collection of simple, potentially misspecified models in response to the data. Since rational expectations require excessively elaborate forecasting rules for a decision-maker, the boosting algorithm offers an intuitive way to explain how a decision-maker with limited computational capability can learn to behave as if he is a rational player. We analyze how algorithms can induce rational play in settings featuring sequential moves and exogenous uncertainty. Our goal is to examine whether a decision-maker can learn to play an optimal action when he possesses an underspecified model. As a laboratory, we choose a monopoly market where the monopolist is initially endowed with a partial specification of the true demand curve. We formulate the learning dynamics as an algorithm that chooses the specification of the demand curve in response to the history of outcomes. We represent the monopolist's decision problem as a zero-sum game against nature, which chooses the true demand curve, while the monopolist chooses an algorithm to maximize the long-run average payoff. Instead of the maxmin strategy, the monopolist seeks a dominant algorithm that learns the profit-maximizing outcome against any true demand. We construct a dominant algorithm that is the simplest among all dominant algorithms. For the set of demand curves with strictly decreasing uniformly Lipschitz continuous marginal revenue curve, our algorithm recursively estimates the slope and intercept of a linear demand curve, even if the actual demand curve is not linear. The monopolist chooses a misspecified model to save computational cost. A misspecified model is not an evidence of biased perception or behavioral constraints but a representation of procedural rationality.\n\nCollusion through algorithm. The joint project with Noah Williams examines a simple duopoly market populated by two myopic firms producing strategic complements with (unknown) linear demand curves. Each firm entertains two different hypotheses about the opponent's response: a fixed but unknown action (Nash behavior) and a linear reaction function to its price. Instead of committing to a particular hypothesis, a firm hedges against model uncertainty by mixing the two hypotheses but adjusting the probability weight to each model according to the profit generated under the hypothesis. Based on the data, each firm updates the coefficient of each hypothesis. If each firm is committed to believing in the Nash hypothesis, then the Nash equilibrium is realized, eliminating any possibility of a collusive outcome. If so, a collusive outcome is evidence of collusion between the two firms. However, if each firm is averaging the forecasts of the two hypotheses, the long-run probability weight assigned to the reaction function hypothesis converges to 1 and generates a sample path that regularly deviates from the Nash equilibrium outcome (competitive outcome) to the cartel outcome (collusive outcome) and returns to Nash equilibrium outcome. We rigorously eliminate any channel of collusion by shutting down communication among players and blocking any possible punishment for a deviation. Nevertheless, the market outcome appears to indicate that the two firms regularly collude. It would be wrong to conclude that the collusive outcomes among algorithmic players imply implicit or explicit collusion among firms without other evidence. The endogenous selection of forecasting rules in response to the data lets the duopolists behave as if they collude, which is the central property of a machine learning algorithm.\n\n\t\t\t\t\tLast Modified: 10/01/2023\n\n\t\t\t\t\tSubmitted by: In-Koo Cho"
 }
}