{
 "awd_id": "1910794",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Small: TIDES: Trustworthy Interactive DEcision-making Using Symbolic Planning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-02-29",
 "tot_intn_awd_amt": 418170.0,
 "awd_amount": 418170.0,
 "awd_min_amd_letter_date": "2019-08-05",
 "awd_max_amd_letter_date": "2022-09-12",
 "awd_abstract_narration": "Innovations in autonomy continue to produce systems that perceive, learn, decide, and act on their own. Many companies are now building self-driving vehicles and medical robots, and the development of advanced autonomous systems is already a billion-dollar industry. These new technologies offer oversight, advanced automation, and autonomous instruments, and they are adaptable to changing situations, knowledge, and constraints. However, introducing new technologies into our technical and social infrastructures has profound implications, and thus requires establishing confidence in their behavior to avoid potential harm. The effectiveness and broader acceptability of autonomous smart systems therefore rely on the ability of these systems to explain their decisions. Building trust in artificial intelligence (AI) systems is a critical requirement in human-robot interaction, and essential for realizing the full spectrum of societal and industrial benefits from AI. \r\n \r\nThis proposal identifies two critical factors for establishing the trustworthiness of autonomous systems: explainability and risk-awareness. The proposed research will provide new algorithms and guidance to enable real-world applications, opening trustworthy reinforcement-learning techniques to a wide variety of practical applications such as control, robotics, e-commerce, and medical treatment. Overall, this research will produce, first, an explainable and data-efficient hierarchical sequential decision-making framework based on symbolic planning and hierarchical reinforcement learning; second, an explainable policy-search framework that can learn explainable policies via integrating inductive logic programming and reinforcement learning; and third, improved approaches to risk-sensitive policy search that are easy to use (for example, without the burden of tuning multi-timescale stepsizes). The theoretical contribution of this research is to significantly improve data-driven policy search in interactive sequential decision-making systems by developing a theory of trust that facilitates and informs smart interactive learning processes.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Levent",
   "pi_last_name": "Yilmaz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Levent Yilmaz",
   "pi_email_addr": "yilmaz@auburn.edu",
   "nsf_id": "000242144",
   "pi_start_date": "2022-09-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Bo",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bo Liu",
   "pi_email_addr": "boliu@auburn.edu",
   "nsf_id": "000727926",
   "pi_start_date": "2019-08-05",
   "pi_end_date": "2022-09-12"
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Levent",
   "pi_last_name": "Yilmaz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Levent Yilmaz",
   "pi_email_addr": "yilmaz@auburn.edu",
   "nsf_id": "000242144",
   "pi_start_date": "2019-08-05",
   "pi_end_date": "2022-09-12"
  }
 ],
 "inst": {
  "inst_name": "Auburn University",
  "inst_street_address": "321-A INGRAM HALL",
  "inst_street_address_2": "",
  "inst_city_name": "AUBURN",
  "inst_state_code": "AL",
  "inst_state_name": "Alabama",
  "inst_phone_num": "3348444438",
  "inst_zip_code": "368490001",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "AL03",
  "org_lgl_bus_name": "AUBURN UNIVERSITY",
  "org_prnt_uei_num": "DMQNDJDHTDG4",
  "org_uei_num": "DMQNDJDHTDG4"
 },
 "perf_inst": {
  "perf_inst_name": "Auburn University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "AL",
  "perf_st_name": "Alabama",
  "perf_zip_code": "368490001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "AL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 126525.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 291645.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Vehicles with partially autonomous driving capabilities have recently become available to the general public. Dozens of companies are involved in building self-driving automobiles, and advanced (partially) autonomous driving systems are already a billion-dollar business. However, before these intelligent systems can become widespread, it is necessary to help drivers establish an appropriate level of trust in automated vehicles. Trust is a key concept in modern interaction systems, and building trust in AI systems is a fundamental task for realizing the full spectrum of societal and industrial benefits from AI. Inappropriate calibration of trust in an automated system can lead to misuse (over-trust) and disuse (under-trust), resulting in decreased performance and less adoption.</span></p>\n<p><span>A case in point is the Tesla autopilot system, along with other advanced driver assistance systems (ADAS), where imperfections are common. As such, a critical issue is the degree of trust in these automated systems. If a driver relies entirely on the capabilities of these vehicles, negative consequences during automation failures are inevitable, such as recent fatal Tesla crashes. On the other hand, if drivers rely too little on the system, they will fail to take advantage of its full capabilities or even unnecessarily interfere with its operation. This can potentially risk lives under circumstances where an ADAS system is superior. Establishing an appropriate level of trust is, therefore, critical in helping humans understand and interact with smart AI systems.</span></p>\n<p><span>Motivated by the pressing need to build trust in smart interactive systems, this project aims to increase trust in such systems by improving explainability and risk awareness. With this in mind, we established a trustworthy interactive decision support system comprised of human end-users, smart agents, and the environment. The project produced the following outcomes:</span></p>\n<ol>\n<li><span>Introduced a theory of trust that facilitates and informs smart interactive learning processes, such as sequential decision-making.</span></li>\n<li><span>Developed an explainable sequential decision-making framework based on symbolic planning that is explainable in task decomposition and data-efficient.</span></li>\n<li><span>Developed an explainable policy search framework based on inductive logic programming that can learn explainable policies.</span></li>\n<li><span>Developed improved approaches to risk-sensitive policy search without the burden of tuning multiple stepsizes and performed computational experiments demonstrating the efficacy of the new algorithms developed on benchmark problems.</span></li>\n</ol>\n<p><span>The research provided new algorithms and practical guidance to enable real-world applications, opening trustworthy reinforcement learning techniques to a broad range of practical applications, including control, robotics, e-commerce, and medical treatment. The theoretical contribution of this research will also significantly improve the data-driven policy search in interactive sequential decision-making systems. All domain areas that exploit decision-making under uncertainties will potentially benefit from using the proposed trustworthy reinforcement learning framework.</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/16/2024<br>\nModified by: Levent&nbsp;Yilmaz</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1910794/1910794_10630272_1698620366807_Tasks--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1910794/1910794_10630272_1698620366807_Tasks--rgov-800width.jpg\" title=\"Project Tasks\"><img src=\"/por/images/Reports/POR/2023/1910794/1910794_10630272_1698620366807_Tasks--rgov-66x44.jpg\" alt=\"Project Tasks\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The Key Elements for Trust in Interactive Decision-making</div>\n<div class=\"imageCredit\">AUSIM</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Levent&nbsp;Yilmaz\n<div class=\"imageTitle\">Project Tasks</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/1910794/1910794_10630272_1698620438717_Architecture--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1910794/1910794_10630272_1698620438717_Architecture--rgov-800width.jpg\" title=\"Architecture\"><img src=\"/por/images/Reports/POR/2023/1910794/1910794_10630272_1698620438717_Architecture--rgov-66x44.jpg\" alt=\"Architecture\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">System Architecture</div>\n<div class=\"imageCredit\">AUSIM</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Levent&nbsp;Yilmaz\n<div class=\"imageTitle\">Architecture</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nVehicles with partially autonomous driving capabilities have recently become available to the general public. Dozens of companies are involved in building self-driving automobiles, and advanced (partially) autonomous driving systems are already a billion-dollar business. However, before these intelligent systems can become widespread, it is necessary to help drivers establish an appropriate level of trust in automated vehicles. Trust is a key concept in modern interaction systems, and building trust in AI systems is a fundamental task for realizing the full spectrum of societal and industrial benefits from AI. Inappropriate calibration of trust in an automated system can lead to misuse (over-trust) and disuse (under-trust), resulting in decreased performance and less adoption.\n\n\nA case in point is the Tesla autopilot system, along with other advanced driver assistance systems (ADAS), where imperfections are common. As such, a critical issue is the degree of trust in these automated systems. If a driver relies entirely on the capabilities of these vehicles, negative consequences during automation failures are inevitable, such as recent fatal Tesla crashes. On the other hand, if drivers rely too little on the system, they will fail to take advantage of its full capabilities or even unnecessarily interfere with its operation. This can potentially risk lives under circumstances where an ADAS system is superior. Establishing an appropriate level of trust is, therefore, critical in helping humans understand and interact with smart AI systems.\n\n\nMotivated by the pressing need to build trust in smart interactive systems, this project aims to increase trust in such systems by improving explainability and risk awareness. With this in mind, we established a trustworthy interactive decision support system comprised of human end-users, smart agents, and the environment. The project produced the following outcomes:\n\nIntroduced a theory of trust that facilitates and informs smart interactive learning processes, such as sequential decision-making.\nDeveloped an explainable sequential decision-making framework based on symbolic planning that is explainable in task decomposition and data-efficient.\nDeveloped an explainable policy search framework based on inductive logic programming that can learn explainable policies.\nDeveloped improved approaches to risk-sensitive policy search without the burden of tuning multiple stepsizes and performed computational experiments demonstrating the efficacy of the new algorithms developed on benchmark problems.\n\n\n\nThe research provided new algorithms and practical guidance to enable real-world applications, opening trustworthy reinforcement learning techniques to a broad range of practical applications, including control, robotics, e-commerce, and medical treatment. The theoretical contribution of this research will also significantly improve the data-driven policy search in interactive sequential decision-making systems. All domain areas that exploit decision-making under uncertainties will potentially benefit from using the proposed trustworthy reinforcement learning framework.\n\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 03/16/2024\n\n\t\t\t\t\tSubmitted by: LeventYilmaz\n"
 }
}