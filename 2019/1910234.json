{
 "awd_id": "1910234",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS Core: Small: Designing Networks for Stringent Performance Requirements",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922935",
 "po_email": "dmedhi@nsf.gov",
 "po_sign_block_name": "Deepankar Medhi",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-08-07",
 "awd_max_amd_letter_date": "2019-08-07",
 "awd_abstract_narration": "With the wide-spread adoption of online and cloud-based services, it is critical that the underlying computer network infrastructure meet increasingly stringent performance requirements (e.g., sustain throughput for business-critical applications). These requirements must be met despite failures that are the norm given the global scale of Internet service provider (ISP) and cloud provider networks, and their rapid pace of evolution. This project will tackle these challenges by  developing novel techniques that enable network architects to plan their network designs (e.g., design topology, provision capacity, algorithms for re-routing traffic on failures) so that performance is acceptable over a large set of scenarios the network may encounter.\r\n\r\nThe project will bring together expertise in network systems, and optimization theory, and advance the state-of-the-art in two key ways. First, the project will develop (i) new mechanisms that may be deployed in the network to respond to failures, and (ii) frameworks that can certify that the resulting performance is acceptable over specified failure states. A novelty of the framework is the ability to model rich and flexible network mechanisms. Second, unlike existing methods that only consider worst-case performance, and may be overly conservative, this project will develop novel ways to design for requirements that must be satisfactory for a desired percentage of scenarios.\r\n\r\nThe project will enable significant real-world impact by ensuring that networks comply with Service Level Objectives in the face of failures, and lead to networks with lower cost, better performance, and higher reliability. By making fundamental advances in optimization, the project will impact other scientific disciplines beyond networking. The project will engage with industry and network operator forums, and extensively involve doctoral, Masters, and undergraduate students in the research. The project will incorporate inter-disciplinary material in networking and optimization courses, and will involve active participation in K-12 outreach activities.\r\n\r\nThe results from the project will be available at: https://engineering.purdue.edu/~isl/certifiabledesign.html. The results will be available throughout the duration of the project, and for three years after.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanjay",
   "pi_last_name": "Rao",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Sanjay G Rao",
   "pi_email_addr": "sanjay@purdue.edu",
   "nsf_id": "000227316",
   "pi_start_date": "2019-08-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mohit",
   "pi_last_name": "Tawarmalani",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mohit Tawarmalani",
   "pi_email_addr": "mtawarma@purdue.edu",
   "nsf_id": "000295915",
   "pi_start_date": "2019-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "465 Northwestern Avenue",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072035",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>A network may be required to meet goals such as \"ensure a desired bandwidth for latency-sensitive traffic between New York and San Francisco 99.9% of the time\". The requirements of flows (a term we use to represent traffic between a pair of sites belonging to a given priority class) must be met taking into account the likelihood that the network may experience different failure states (e.g., a particular set of link failures), and the performance that is feasible under each failure state.</p>\n<p><br />Many existing approaches to designing networks for failures (i) only focus on availability, resulting in poor performance on failures; (ii) only consider a small number of failure states, and do not scale as the number of possible failure states increase; or (iii) rely on ad-hoc simulation-based testing. While tools for software and hardware synthesis and testing is a thriving multi-billion dollar industry, the state of practice in certifying and synthesizing network designs is only in its nascent stages.</p>\n<p>The project has tackled these challenges by developing novel techniques that enable architects to plan their network designs so performance is acceptable over a large set of scenarios the network may encounter. The project is distinguished by a focus on performance (not just availability), designing for multiple concurrent failures, and designs with provable performance guarantees for a given set of failure scenarios.<br /><br />Notable outcomes include:</p>\n<p>1) Design for percentile requirements.</p>\n<p>Several works have explored the use of robust approaches where the primary goal is to optimize the worst-case performance of a network across a range of possible failure scenarios. Unfortunately, worst-case design may be unduly conservative since a small number of bad failure scenarios may be expensive or even infeasible to design for. We developed Lancet, a framework to bridge the gap between existing theory that focuses on worst-case performance, and practical requirements that require that performance is acceptable for scenarios that occur with a desired probability. Specifically, Lancet analyzes which failure scenarios a network is intrinsically capable of tackling, and enables the design of a protection routing that can protect against most scenarios with <em>f</em> or fewer link failure scenarios when infeasible to protect against all such scenarios. Evaluations on real network topologies show Lancet's effectiveness -- in some cases, Lancet can support nearly all 2- and 3-failure scenarios while in contrast, state-of-the-art schemes only handles 46.1% of 2-failure and no 3-failure scenarios.</p>\n<p>We also developed a subsequent system Flexile which ensures all flows see as low a loss as possible at a desired percentile by allowing flows to meet their bandwidth requirements in a possibly different subset of critical states that occur with sufficient probability. Although this couples bandwidth allocation decisions across failure states, Flexile decouples them by identifying critical states for each flow in an offline phase. Then, on failure, Flexile efficiently allocates bandwidth online, while paying more attention to critical flows. Flexile outperforms prior work by reducing flow loss at desired percentiles by 46% or more.</p>\n<p>&nbsp;</p>\n<p>2) PCF(Provably Congestion-free and resilient Flexible Routing).</p>\n<p>There is much interest in the research community on traffic engineering mechanisms that proactively ensure thatthe network is congestion-free (i.e., ensure that no link carries more traffic than its capacity) under typical failure scenarios. We have shown that prior congestion-free schemes perform much worse than optimal, and present deeper insights into the underlying reasons. We have developed PCF, a set of novel mechanisms that ensure the network is provably congestion-free under failures, while performing closer to the network's intrinsic capability. PCF achieves these goals by better modeling network structure, and through more flexible response strategies. Empirical evaluations over 21 network topologies show that PCF can sustain higher throughput than prior work by a factor of 1.11X to 1.5X on average across the topologies, while providing a benefit of 2.6X in some cases.<br /><br /></p>\n<p>Broader Impact.</p>\n<p>The techniques developed by the project inform the design of networks with higher performance, lower cost and greaterreliability which can comply with Service Level Objectives in the face of failures. The project has (i) trained multiple Ph.D students; (ii) led to publications in top scientific conferences such as ACM Sigcomm, ACM Sigmetrics, and ACM CoNext; (iii) involved interactions with industry; and (iv) led to the release of open source artifacts available at:</p>\n<p><a href=\"https://purdue-isl.github.io/projects_pages/Synthesizing-Network-Designs\">https://purdue-isl.github.io/projects_pages/Synthesizing-Network-Designs</a></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/22/2024<br>\nModified by: Sanjay&nbsp;G&nbsp;Rao</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nA network may be required to meet goals such as \"ensure a desired bandwidth for latency-sensitive traffic between New York and San Francisco 99.9% of the time\". The requirements of flows (a term we use to represent traffic between a pair of sites belonging to a given priority class) must be met taking into account the likelihood that the network may experience different failure states (e.g., a particular set of link failures), and the performance that is feasible under each failure state.\n\n\n\nMany existing approaches to designing networks for failures (i) only focus on availability, resulting in poor performance on failures; (ii) only consider a small number of failure states, and do not scale as the number of possible failure states increase; or (iii) rely on ad-hoc simulation-based testing. While tools for software and hardware synthesis and testing is a thriving multi-billion dollar industry, the state of practice in certifying and synthesizing network designs is only in its nascent stages.\n\n\nThe project has tackled these challenges by developing novel techniques that enable architects to plan their network designs so performance is acceptable over a large set of scenarios the network may encounter. The project is distinguished by a focus on performance (not just availability), designing for multiple concurrent failures, and designs with provable performance guarantees for a given set of failure scenarios.\n\nNotable outcomes include:\n\n\n1) Design for percentile requirements.\n\n\nSeveral works have explored the use of robust approaches where the primary goal is to optimize the worst-case performance of a network across a range of possible failure scenarios. Unfortunately, worst-case design may be unduly conservative since a small number of bad failure scenarios may be expensive or even infeasible to design for. We developed Lancet, a framework to bridge the gap between existing theory that focuses on worst-case performance, and practical requirements that require that performance is acceptable for scenarios that occur with a desired probability. Specifically, Lancet analyzes which failure scenarios a network is intrinsically capable of tackling, and enables the design of a protection routing that can protect against most scenarios with f or fewer link failure scenarios when infeasible to protect against all such scenarios. Evaluations on real network topologies show Lancet's effectiveness -- in some cases, Lancet can support nearly all 2- and 3-failure scenarios while in contrast, state-of-the-art schemes only handles 46.1% of 2-failure and no 3-failure scenarios.\n\n\nWe also developed a subsequent system Flexile which ensures all flows see as low a loss as possible at a desired percentile by allowing flows to meet their bandwidth requirements in a possibly different subset of critical states that occur with sufficient probability. Although this couples bandwidth allocation decisions across failure states, Flexile decouples them by identifying critical states for each flow in an offline phase. Then, on failure, Flexile efficiently allocates bandwidth online, while paying more attention to critical flows. Flexile outperforms prior work by reducing flow loss at desired percentiles by 46% or more.\n\n\n\n\n\n2) PCF(Provably Congestion-free and resilient Flexible Routing).\n\n\nThere is much interest in the research community on traffic engineering mechanisms that proactively ensure thatthe network is congestion-free (i.e., ensure that no link carries more traffic than its capacity) under typical failure scenarios. We have shown that prior congestion-free schemes perform much worse than optimal, and present deeper insights into the underlying reasons. We have developed PCF, a set of novel mechanisms that ensure the network is provably congestion-free under failures, while performing closer to the network's intrinsic capability. PCF achieves these goals by better modeling network structure, and through more flexible response strategies. Empirical evaluations over 21 network topologies show that PCF can sustain higher throughput than prior work by a factor of 1.11X to 1.5X on average across the topologies, while providing a benefit of 2.6X in some cases.\n\n\n\n\nBroader Impact.\n\n\nThe techniques developed by the project inform the design of networks with higher performance, lower cost and greaterreliability which can comply with Service Level Objectives in the face of failures. The project has (i) trained multiple Ph.D students; (ii) led to publications in top scientific conferences such as ACM Sigcomm, ACM Sigmetrics, and ACM CoNext; (iii) involved interactions with industry; and (iv) led to the release of open source artifacts available at:\n\n\nhttps://purdue-isl.github.io/projects_pages/Synthesizing-Network-Designs\n\n\n\t\t\t\t\tLast Modified: 02/22/2024\n\n\t\t\t\t\tSubmitted by: SanjayGRao\n"
 }
}