{
 "awd_id": "1937403",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RTML: Large: Real-Time Autonomic Decision Making on Sparsity-Aware Accelerated Hardware via Online Machine Learning and Approximation",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 1400000.0,
 "awd_amount": 1695998.0,
 "awd_min_amd_letter_date": "2019-09-08",
 "awd_max_amd_letter_date": "2023-05-01",
 "awd_abstract_narration": "Real-time smart and autonomic decision making involves two major stages, sensing (of sensor data and then transformation into actionable knowledge) and planning (taking decisions using this knowledge). These two stages happen in both internal and external operations of an Intelligent Physical System (IPS). In case of internal operations, sensing refers to reading data from on-board sensors and planning refers to smart execution of the firmware running on the IPS. In case of external operations, sensing refers to sensing data from externally-mounted sensors and planning refers to executing the software that constitutes an application. In the sensing stage, an IPS should be able to cope with different forms of uncertainty, especially data and model uncertainties. The goal of this research project is to achieve the objectives of online autonomic decision making on sparsity-aware accelerated hardware via Real-Time Machine Learning (RTML) and approximation for a group of IPSs such as drones performing data collection and/or multi-object tracking/classification and operating in a highly dynamic environment that is difficult to model. Remarkably, the  techniques adopted in this project generalize well as they can be applied to a variety of IPS domains including natural calamities, man-made disasters, and terrorist attacks. The drone-based distributed multi-object tracking/classification will enable stakeholders such as citizens, government bodies, rescue agencies, and industries to comprehend the extent of damage, and to develop more effective mitigation policies. The research will also train students including minority and underrepresented students in the field.\r\n\r\nThere are three specific tasks in this project. In Task 1, a real-time decision-making approach will be proposed via online deep reinforcement learning with inherent distributed training capability; temporal and spatial correlation in streaming video will then be exploited towards real-time multi-object tracking/detection. In Task 2, novel hardware architectures will be designed to support sparse Convolution Neural Networks (CNN). Considering the dual benefits of sparsity on both lower computational and space complexity for Deep Neural Network (DNN) models, a sparsity-aware CNN accelerator can achieve significant hardware performance improvements in term of latency, throughput, and energy efficiency over non-sparsity-aware techniques. Finally, in Task 3, hardware-aware software engineering solutions will be studied for accelerated execution. The idea of leveraging compiler optimization and the underlying hardware features in combination will be investigated in order to optimize execution performance; then, data-driven modeling techniques will be presented to replace the time-consuming segments of the ML software packages with their equivalent data-driven models, namely micro-neural networks. Once these three research tasks are validated individually via principled experimentation in terms of their stated goals, they will be integrated into a unified framework, which will be thoroughly studied via multiple trials on complementary field scenarios. The project will also collaborate with a synergistic DARPA program for related hardware development.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dario",
   "pi_last_name": "Pompili",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dario Pompili",
   "pi_email_addr": "pompili@rutgers.edu",
   "nsf_id": "000501685",
   "pi_start_date": "2019-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Saman",
   "pi_last_name": "Zonouz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Saman Zonouz",
   "pi_email_addr": "szonouz6@gatech.edu",
   "nsf_id": "000602787",
   "pi_start_date": "2019-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Bo",
   "pi_last_name": "Yuan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bo Yuan",
   "pi_email_addr": "bo.yuan@soe.rutgers.edu",
   "nsf_id": "000704451",
   "pi_start_date": "2019-09-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Department of ECE",
  "perf_str_addr": "Frelinghuysen Road",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088543925",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "082Z",
   "pgm_ref_txt": "RTML-Real Time Machine Learning"
  },
  {
   "pgm_ref_code": "2878",
   "pgm_ref_txt": "SPECIAL PROJECTS - CCF"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 1400000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 279998.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-9e29fce0-7fff-820c-7a1b-a3ad073c0ad4\"> </span></p>\r\n<p dir=\"ltr\">The scope of this research project is to develop novel engineering solutions to enable real-time autonomic decision making on sparsity-aware accelerated hardware via online Machine Learning (ML) and approximation. Our research focuses on ultra-low power computing and real-time processing across multiple domains including aerial robotics, healthcare monitoring, and IoT systems. The project addresses key challenges in implementing sophisticated real-time and data-driven computing capabilities within strict power and resource limitations. This includes developing battery-less solutions for continuous monitoring, context-aware computational frameworks for drones, and efficient Neural Network (NN) architectures for resource-constrained devices. The designs are intentionally kept fundamental and theoretically solid to ensure their applicability across various cyber-physical platforms, such as autonomous driving and critical infrastructure operations including industrial control and smart grid systems.</p>\r\n<p dir=\"ltr\"><span>The primary objectives include: (1) Developing real-time decision-making capabilities through online Deep Reinforcement Learning (DRL) for multi-drone coordination, focusing on extending Deep Q-Networks (DQN) and Deep Deterministic Policy Gradient (DDPG) algorithms for continuous domains; (2) Creating data-aware methods that leverage temporal and spatial correlation in streaming video for efficient object tracking and detection; (3) Designing sparsity-aware dataflow architectures for CNN inference, particularly for complex CNN architectures with shortcuts and interconnections; (4) Developing sparsity-aware architectures for real-time CNN training, including efficient DRAM access schemes for backward propagation; (5) Optimizing ML software through performance-aware runtime reconfiguration and hardware-specific optimizations; (6) Implementing approximate computing solutions to accelerate execution through dynamic library loading and neural network approximation models; and (7) Creating reliable multi-agent coordination mechanisms to address challenges including local optima, absence of global environmental information, and inconsistent communication in complex environments. These objectives collectively address the challenge of enabling real-time autonomic decision-making on resource-constrained hardware while maintaining computational efficiency.</span></p>\r\n<p dir=\"ltr\"><span>Our research has yielded several breakthrough results with significant practical implications: (1) Successfully demonstrated battery-less operation for implantable EEG monitoring devices; (2) Achieved significant improvements in drone resource utilization and real-time performance, validated through hardware-in-the-loop emulations on NVIDIA Jetson TX2 GPU using the Microsoft AirSim simulator; (3) Developed an analog Folded Neural Network achieving optimal performance for cardiovascular monitoring with 6 layers and a hidden size of 30; (4) Created a crowd monitoring system processing patterns in just 2 milliseconds, representing a 45x speed improvement; (5) Achieved 55% reduction in computation for face authentication while maintaining security, with encryption time savings of 20 to 55 times; (6) Demonstrated superior performance in multi-agent coordination for complex Search And Rescue (SAR) operations. These advances have broad applications in healthcare, surveillance, disaster response, and IoT systems, making sophisticated AI capabilities more accessible and energy efficient. Additionally, the research has contributed to underwater joint source-channel coding, helping democratize acoustic underwater communications.</span></p>\r\n<p dir=\"ltr\"><span>The project has made significant contributions to education and community development through: (1) Training graduate students in deep learning, hardware architecture design, and NN optimization; (2) Mentoring undergraduate students in robotics, underwater acoustics, AI, and ML through programs like the Aresty Program and departmental summer internships; (3) Organizing educational events like the HackRU Capture The Flag Hackathon focusing on cyber-physical drone security; (4) Creating new courses, such as Co-PI Yuan's course on advanced digital systems for ML and signal processing, and incorporating research findings into existing curricula; (5) Supporting minority student outreach programs and hosting diverse student internships; (6) Developing STEM literacy and workforce skills related to smart and autonomous drones for disaster response. Additionally, our research has resulted in several provisional patents filed through Rutgers University. The technology developed also shows promise in precise agriculture applications for early pest detection and disease intervention.</span></p>\r\n<div><span><br /></span></div>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/10/2025<br>\nModified by: Dario&nbsp;Pompili</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \r\n\n\nThe scope of this research project is to develop novel engineering solutions to enable real-time autonomic decision making on sparsity-aware accelerated hardware via online Machine Learning (ML) and approximation. Our research focuses on ultra-low power computing and real-time processing across multiple domains including aerial robotics, healthcare monitoring, and IoT systems. The project addresses key challenges in implementing sophisticated real-time and data-driven computing capabilities within strict power and resource limitations. This includes developing battery-less solutions for continuous monitoring, context-aware computational frameworks for drones, and efficient Neural Network (NN) architectures for resource-constrained devices. The designs are intentionally kept fundamental and theoretically solid to ensure their applicability across various cyber-physical platforms, such as autonomous driving and critical infrastructure operations including industrial control and smart grid systems.\r\n\n\nThe primary objectives include: (1) Developing real-time decision-making capabilities through online Deep Reinforcement Learning (DRL) for multi-drone coordination, focusing on extending Deep Q-Networks (DQN) and Deep Deterministic Policy Gradient (DDPG) algorithms for continuous domains; (2) Creating data-aware methods that leverage temporal and spatial correlation in streaming video for efficient object tracking and detection; (3) Designing sparsity-aware dataflow architectures for CNN inference, particularly for complex CNN architectures with shortcuts and interconnections; (4) Developing sparsity-aware architectures for real-time CNN training, including efficient DRAM access schemes for backward propagation; (5) Optimizing ML software through performance-aware runtime reconfiguration and hardware-specific optimizations; (6) Implementing approximate computing solutions to accelerate execution through dynamic library loading and neural network approximation models; and (7) Creating reliable multi-agent coordination mechanisms to address challenges including local optima, absence of global environmental information, and inconsistent communication in complex environments. These objectives collectively address the challenge of enabling real-time autonomic decision-making on resource-constrained hardware while maintaining computational efficiency.\r\n\n\nOur research has yielded several breakthrough results with significant practical implications: (1) Successfully demonstrated battery-less operation for implantable EEG monitoring devices; (2) Achieved significant improvements in drone resource utilization and real-time performance, validated through hardware-in-the-loop emulations on NVIDIA Jetson TX2 GPU using the Microsoft AirSim simulator; (3) Developed an analog Folded Neural Network achieving optimal performance for cardiovascular monitoring with 6 layers and a hidden size of 30; (4) Created a crowd monitoring system processing patterns in just 2 milliseconds, representing a 45x speed improvement; (5) Achieved 55% reduction in computation for face authentication while maintaining security, with encryption time savings of 20 to 55 times; (6) Demonstrated superior performance in multi-agent coordination for complex Search And Rescue (SAR) operations. These advances have broad applications in healthcare, surveillance, disaster response, and IoT systems, making sophisticated AI capabilities more accessible and energy efficient. Additionally, the research has contributed to underwater joint source-channel coding, helping democratize acoustic underwater communications.\r\n\n\nThe project has made significant contributions to education and community development through: (1) Training graduate students in deep learning, hardware architecture design, and NN optimization; (2) Mentoring undergraduate students in robotics, underwater acoustics, AI, and ML through programs like the Aresty Program and departmental summer internships; (3) Organizing educational events like the HackRU Capture The Flag Hackathon focusing on cyber-physical drone security; (4) Creating new courses, such as Co-PI Yuan's course on advanced digital systems for ML and signal processing, and incorporating research findings into existing curricula; (5) Supporting minority student outreach programs and hosting diverse student internships; (6) Developing STEM literacy and workforce skills related to smart and autonomous drones for disaster response. Additionally, our research has resulted in several provisional patents filed through Rutgers University. The technology developed also shows promise in precise agriculture applications for early pest detection and disease intervention.\r\n\n\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 02/10/2025\n\n\t\t\t\t\tSubmitted by: DarioPompili\n"
 }
}