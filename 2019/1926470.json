{
 "awd_id": "1926470",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AI-DCL: EAGER: Bias and Discrimination in City Predictive Analytics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 297652.0,
 "awd_amount": 297652.0,
 "awd_min_amd_letter_date": "2019-09-03",
 "awd_max_amd_letter_date": "2019-09-03",
 "awd_abstract_narration": "Citizen-generated 311 reports are used by cities to identify service needs such as infrastructure repair, rodent infestations, heating outages, and illegal building use.  Because citizen reports provide real-time condition assessment, city agencies analyze these data to understand and forecast problems and service demands.  However, citizen reporting in response to conditions is not uniform; instead reporting frequency varies by socioeconomic and demographic group, cultural difference, differences in government trust, and access to e-government systems.  That is, such reporting data carry systematic biases resulting from persistent spatial, racial, and economic inequalities.  Consequently, predictive urban analytics based on citizen complaint data can result in discriminatory urban policy, planning, and decision-making, and misallocation of city resources, further reinforcing biases about neighborhood quality.  This project seeks to improve efficacy of urban analytics based on citizen complaints (through 311 reports) by building statistical machine learning models to estimate reporting rate biases; providing tools to city decision makers, policy makers, and planers to visualize the spatial and socio-economic dependence of biases; and correct for the biases in responding to complaints --- leading to more just resource allocation.\r\n\r\nThis project involves three inter-related objectives: (1) to analyze the socio-spatial variance in the propensity to complain through the 311 system, (2) to understand the relationship between socioeconomic, demographic, and cultural factors and complaint behavior, and (3) to provide a methodology for city agencies to account for observed reporting biases, both in terms of reporting rate and potential severity of problems. To do so, the investigators develop a new methodological framework, integrating multiple data sources and incorporating approaches from machine learning and economics, for assessing, quantifying, and correcting reporting bias. Leveraging collaborations with New York City 311 (NYC311) and the Kansas City Office of Performance Management (DataKC), the research team will use data of more than 8,000,000 geo-located 311 reports annually in NYC and Kansas City from 2012 to 2017, code enforcement and building violation records (as validation data), neighborhood condition assessments, and a detailed citizen satisfaction survey of 21,046 individual responses from 2014 to 2017 covering all of Kansas City. These datasets will be integrated with detailed building and property data, socioeconomic and demographic data, and measures of community organization, social infrastructure, and political participation. Project outputs include: (1) a model to assess the probability of citizen reporting based on demographic, socioeconomic, cultural, and neighborhood factors, (2) a model to estimate under- and over-reporting behavior by neighborhood and to weight self-reported data for model training that accounts for observed biases, and (3) an interactive visualization tool to assist city managers, community organizations, and the general public in understanding spatial patterns of complaint reporting, the nature of reported problems, and the likelihood of under- and over-reporting. The insights of this project will form the basis for identifying, evaluating, and accounting for bias in citizen self-reported data, and produce transformative results that can contribute to the efficient and fair delivery of city services by leveraging predictive analytics and artificial intelligence.  By modeling and improving the quality of citizen-generated data, the project provides a methodological basis for increasing citizens' participation (e.g. in governance, citizen science, and collaborative knowledge production) while ensuring that the data produced by such participation is representative, reliable, and useful.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Constantine",
   "pi_last_name": "Kontokosta",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Constantine E Kontokosta",
   "pi_email_addr": "ckontokosta@nyu.edu",
   "nsf_id": "000649995",
   "pi_start_date": "2019-09-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Neill",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel B Neill",
   "pi_email_addr": "daniel.neill@nyu.edu",
   "nsf_id": "000484498",
   "pi_start_date": "2019-09-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "70 Washington Square S",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 297652.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Resident-reported 311 complaints carry systemic biases resulting from persistent spatial, racial, and economic inequalities in cities. Consequently, predictive urban analytics trained on complaint data can result in discriminatory decision-making processes and a misallocation of city resources, further reinforcing disparities in neighborhood quality. This project addressed bias in 311 complaint data to improve the fairness of data-driven decision-making in the urban context by (1) building statistical machine learning models to estimate reporting rate biases; (2) providing tools to city decision makers, policy makers, and planners to understand and visualize the spatial and socioeconomic dependence of reporting behaviors; and (3) developing methods to account for observed biases in responding to resident reports. The project utilized 311 complaint data from 27 cities in the United States and Canada, with a particular focus on New York City and Kansas City, Missouri, and integrates many other datasets, including large-scale mobility data, building and neighborhood characteristics, and resident survey data, among others. We developed our methods in the context of housing, street infrastructure, social distancing compliance associated with the COVID-19 pandemic, and multi-city data standardization, and in each case utilize different approaches to account for ?ground-truth? conditions:</p>\n<p><strong>Under-reporting of heat and hot water problems:</strong> We successfully defined the under-reporting of heating and hot water problems to the NYC311 system and developed a machine learning method to estimate under-reporting. Our machine learning models estimate both the probability of an underlying heating problem conditional on building characteristics, and the probability of reporting an issue to the e-government system conditional on resident characteristics. We also analyzed ?less-than-expected? reporting: buildings with fewer 311 calls than expected as compared to similarly-sized buildings with similar estimated problem durations. We modeled the neighborhood-level demographic, socioeconomic, and political characteristics that are predictive of under-reporting of heating problems (manuscript to be submitted for publication).</p>\n<p><strong>Disparities in street condition reports and allocation of resources:</strong> We examined bias in resident complaints regarding street conditions by analyzing socio-spatial disparities in 311 reporting behavior in Kansas City, Missouri. We utilized data from detailed 311 reports and a comprehensive resident satisfaction survey, together with code enforcement violations, neighborhood characteristics, and street pavement assessments as a measure of actual conditions. We identified disparities in resident-government interactions associated with demographic and socioeconomic characteristics of residents, and developed a model to classify neighborhoods as under- and over-reporting. Despite greater need based on both objective and subjective measures, lower-income and minority neighborhoods were found to be less likely to report street condition or ?nuisance? issues, while prioritizing life safety problems, such as heating issues described above (Kontokosta and Hong 2021).</p>\n<p><strong>Sensitivity to social distancing and complaint reporting during COVID-19:</strong> Given the challenge in monitoring and enforcing social distancing guidelines, several jurisdictions have turned to 311 reporting platforms to engage the public in reporting non-compliance, but differences in sensitivity to social distancing behaviors can lead to a mis-allocation of resources and increased health risks. Using hourly visit data to designated establishments and more than 71,000 social distancing complaints in New York City during the first wave of the pandemic, we developed a method to quantify neighborhood sensitivity to assess how tolerance to social distancing infractions impacted complaint reporting behaviors, and how sensitivity varied with neighborhood characteristics. We found that sensitivity to non-compliance is lower in minority and low-income neighborhoods, resulting in fewer reported complaints than expected given measured levels of overcrowding (manuscript to be submitted for publication).</p>\n<p><strong>Standardized reporting classification and cross-city comparative analysis:</strong> To address the lack of standardization across reporting schema, we acquired 311 data for 27 North American cities covering more than 7,900 unique report categories. By using a rule-based model that extracts similar complaint categories and <em>k</em>-means clustering based on a TF-IDF vector, we generated a standardized 311 reporting framework across the studied cities and analyzed comparative reporting activity at high spatial-temporal resolutions using cosine similarity, clustering algorithms, and spatial modeling. This data processing and standardization will enable future studies of complaint behavior across a diversity of regions and cities (manuscript to be submitted for publication).</p>\n<p>The methods, tools, and findings of this project have been incorporated into the curricula of both the PI?s and co-PI?s educational programs, and disseminated through papers and presentations. This includes the PI?s ?Civic Analytics and Urban Intelligence? course (under development) and the Co-PI?s ?Machine Learning for Cities? course in NYU?s MS in Applied Urban Science and Informatics program. In addition, the project supported the work of several graduate students and a postdoctoral associate. Project outputs have been disseminated to a wide array of audiences, including city agencies, community organizations, and researchers in fields ranging from computer science to public policy and urban planning.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/28/2022<br>\n\t\t\t\t\tModified by: Constantine&nbsp;E&nbsp;Kontokosta</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nResident-reported 311 complaints carry systemic biases resulting from persistent spatial, racial, and economic inequalities in cities. Consequently, predictive urban analytics trained on complaint data can result in discriminatory decision-making processes and a misallocation of city resources, further reinforcing disparities in neighborhood quality. This project addressed bias in 311 complaint data to improve the fairness of data-driven decision-making in the urban context by (1) building statistical machine learning models to estimate reporting rate biases; (2) providing tools to city decision makers, policy makers, and planners to understand and visualize the spatial and socioeconomic dependence of reporting behaviors; and (3) developing methods to account for observed biases in responding to resident reports. The project utilized 311 complaint data from 27 cities in the United States and Canada, with a particular focus on New York City and Kansas City, Missouri, and integrates many other datasets, including large-scale mobility data, building and neighborhood characteristics, and resident survey data, among others. We developed our methods in the context of housing, street infrastructure, social distancing compliance associated with the COVID-19 pandemic, and multi-city data standardization, and in each case utilize different approaches to account for ?ground-truth? conditions:\n\nUnder-reporting of heat and hot water problems: We successfully defined the under-reporting of heating and hot water problems to the NYC311 system and developed a machine learning method to estimate under-reporting. Our machine learning models estimate both the probability of an underlying heating problem conditional on building characteristics, and the probability of reporting an issue to the e-government system conditional on resident characteristics. We also analyzed ?less-than-expected? reporting: buildings with fewer 311 calls than expected as compared to similarly-sized buildings with similar estimated problem durations. We modeled the neighborhood-level demographic, socioeconomic, and political characteristics that are predictive of under-reporting of heating problems (manuscript to be submitted for publication).\n\nDisparities in street condition reports and allocation of resources: We examined bias in resident complaints regarding street conditions by analyzing socio-spatial disparities in 311 reporting behavior in Kansas City, Missouri. We utilized data from detailed 311 reports and a comprehensive resident satisfaction survey, together with code enforcement violations, neighborhood characteristics, and street pavement assessments as a measure of actual conditions. We identified disparities in resident-government interactions associated with demographic and socioeconomic characteristics of residents, and developed a model to classify neighborhoods as under- and over-reporting. Despite greater need based on both objective and subjective measures, lower-income and minority neighborhoods were found to be less likely to report street condition or ?nuisance? issues, while prioritizing life safety problems, such as heating issues described above (Kontokosta and Hong 2021).\n\nSensitivity to social distancing and complaint reporting during COVID-19: Given the challenge in monitoring and enforcing social distancing guidelines, several jurisdictions have turned to 311 reporting platforms to engage the public in reporting non-compliance, but differences in sensitivity to social distancing behaviors can lead to a mis-allocation of resources and increased health risks. Using hourly visit data to designated establishments and more than 71,000 social distancing complaints in New York City during the first wave of the pandemic, we developed a method to quantify neighborhood sensitivity to assess how tolerance to social distancing infractions impacted complaint reporting behaviors, and how sensitivity varied with neighborhood characteristics. We found that sensitivity to non-compliance is lower in minority and low-income neighborhoods, resulting in fewer reported complaints than expected given measured levels of overcrowding (manuscript to be submitted for publication).\n\nStandardized reporting classification and cross-city comparative analysis: To address the lack of standardization across reporting schema, we acquired 311 data for 27 North American cities covering more than 7,900 unique report categories. By using a rule-based model that extracts similar complaint categories and k-means clustering based on a TF-IDF vector, we generated a standardized 311 reporting framework across the studied cities and analyzed comparative reporting activity at high spatial-temporal resolutions using cosine similarity, clustering algorithms, and spatial modeling. This data processing and standardization will enable future studies of complaint behavior across a diversity of regions and cities (manuscript to be submitted for publication).\n\nThe methods, tools, and findings of this project have been incorporated into the curricula of both the PI?s and co-PI?s educational programs, and disseminated through papers and presentations. This includes the PI?s ?Civic Analytics and Urban Intelligence? course (under development) and the Co-PI?s ?Machine Learning for Cities? course in NYU?s MS in Applied Urban Science and Informatics program. In addition, the project supported the work of several graduate students and a postdoctoral associate. Project outputs have been disseminated to a wide array of audiences, including city agencies, community organizations, and researchers in fields ranging from computer science to public policy and urban planning.\n\n\t\t\t\t\tLast Modified: 01/28/2022\n\n\t\t\t\t\tSubmitted by: Constantine E Kontokosta"
 }
}