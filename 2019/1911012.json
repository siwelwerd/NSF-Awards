{
 "awd_id": "1911012",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS Core: Small: Robust Performance Guarantee of Containerized Microservices in the Cloud",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 243940.0,
 "awd_amount": 243940.0,
 "awd_min_amd_letter_date": "2019-05-30",
 "awd_max_amd_letter_date": "2019-05-30",
 "awd_abstract_narration": "Large-scale web services are increasingly being built with many small modular components (microservices), which can be deployed, updated and scaled seamlessly. These microservices are packaged to run in a lightweight isolated execution environment (containers) and deployed on compute resources rented from cloud providers. However, the complex interactions and the contention of shared hardware resources in cloud datacenters pose significant challenges in managing web service performance. This project will develop novel performance models and resource management solutions that can enable cloud platforms to provide robust performance guarantee for large-scale web services.\r\n\r\nThis project will leverage multi-layered data collected from container-level resource usage metrics and virtual machine-level hardware performance counter metrics for accurate performance modeling. It will (1) develop probabilistic machine learning-based performance models that can quickly adapt to changing system dynamics and directly provide confidence bounds in the predictions even when the data is noisy and sparse. (2) It will directly incorporate predictive uncertainty obtained from the proposed models into the design and development of a robust resource scaling system and interference-aware container scheduling algorithm to manage the end-to-end tail latency of microservice request workflows in a resource efficient manner. \r\n\r\nThe project will improve the performance, cost-efficiency, and scalability of a broad range of cloud-native applications. This can spur innovation in large-scale application development through increased adoption of cloud computing and cloud-native design principles. To this end, the project will develop open-source solutions for platforms such as Kubernetes. It will advance interdisciplinary education by developing a new course, which will contribute to a Cloud Computing Certificate jointly created by the University of Texas at San Antonio Colleges of Science, Engineering and Business.\r\n\r\nData produced as a result of this project, including algorithms, models, software solutions, publications, and courseware, will be made publicly available at the project repository: http://www.cs.utsa.edu/~plama/microservices.html. The project data will be maintained and made available during the execution of the project and minimum three years after the project's ending date. Data will be stored on the host institution's dedicated web servers.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Palden",
   "pi_last_name": "Lama",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Palden Lama",
   "pi_email_addr": "Palden.Lama@UTSA.EDU",
   "nsf_id": "000653134",
   "pi_start_date": "2019-05-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at San Antonio",
  "inst_street_address": "1 UTSA CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SAN ANTONIO",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "2104584340",
  "inst_zip_code": "782491644",
  "inst_country_name": "United States",
  "cong_dist_code": "20",
  "st_cong_dist_code": "TX20",
  "org_lgl_bus_name": "THE UNIVERSITY OF TEXAS AT SAN ANTONIO",
  "org_prnt_uei_num": "U44ZMVYU52U6",
  "org_uei_num": "U44ZMVYU52U6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at San Antonio",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "782491644",
  "perf_ctry_code": "US",
  "perf_cong_dist": "20",
  "perf_st_cong_dist": "TX20",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 243940.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In the realm of large-scale web services spanning diverse application domains, the prevalent approach involves constructing systems with numerous small, modular components known as microservices. These microservices are designed for seamless deployment, updating, and scaling. Utilizing a lightweight and isolated execution environment, often in the form of containers, these microservices can be efficiently deployed across a spectrum of platforms, ranging from cloud servers to resource-constrained edge nodes. This project analyzed the performance issues and resource-scaling challenges of both cloud-based web services and event-driven stream processing microservices deployed at the edge. The complex interactions between microservices and the contention of shared hardware resources pose significant challenges in managing application performance. Furthermore, existing resource management techniques are too slow to adapt to changing system dynamics resulting in Service Level Objective (SLO) violations of end-to-end application performance.</p>\n<p>To address these challenges, this project developed robust performance models based on a probabilistic machine learning approach, Gaussian Process (GP) regression, which can predict the end-to-end tail latency of microservice workflows and efficiently estimate the confidence bounds of prediction. For cloud-based web services, the models leveraged multi-layered data collected from container-level resource usage metrics and virtual machine-level hardware performance counter metrics. In the case of stream processing microservices deployed in a mobile edge computing environment, the models were based on the computing resources allocated to each container. The project further developed a resource scaling system that manages end-to-end tail latency by incorporating predictive uncertainty into the resource allocation problem. Additionally, an SLO-aware resource allocation technique based on Bayesian Optimization (BO) was introduced to quickly identify and deploy near-optimal resource configurations for stream processing microservices.</p>\n<p>The project evaluated the proposed techniques using an open-source microservices benchmark, Robot Shop, and a real-time IoT benchmark for distributed stream processing platforms (RIoTBench). These benchmark applications were containerized with Docker and orchestrated with Kubernetes. Our experimental results demonstrated the superior prediction accuracy and adaptiveness of our modeling approach compared to popular machine learning techniques. Compared to our modeling technique, deriving the 95% confidence interval for a deterministic neural-network model based prediction (using bootstratpping method) has 4X more overhead for the same size of dataset. Our study showcased the adaptability of these performance models to the ever-shifting system dynamics including fluctuations in workload over time, variations in input data types, and unpredictable shifts of network conditions in the context of a mobile edge environment. Furthemore, our robust resource scaling technique proved effective in meeting end-to-end tail latency target of microservice workflows even in the face of multi-tenant performance interference and changing system dynamics.&nbsp;</p>\n<p>To date, the project has produced four peer-reviewed publications, and several papers are under review. Data produced by the project is publicly available. The project has played a pivotal role in the development of the CS 5573 Cloud Computing course, contributing to a Cloud Computing Certificate jointly created by the Colleges of Science, Engineering and Business at the University of Texas at San Antonio. Several graduate and undergraduate students were trained in cloud computing, machine learning (ML) for systems, and system performance analysis. The impact of our findings is anticipated to influence researchers in the computer systems domain, encouraging further exploration and adoption of the developed performance modeling and resource scaling techniques.&nbsp;</p><br>\n<p>\n Last Modified: 01/20/2024<br>\nModified by: Palden&nbsp;Lama</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1911012/1911012_10608074_1705764140136_rscale--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1911012/1911012_10608074_1705764140136_rscale--rgov-800width.png\" title=\"RScale Architecture\"><img src=\"/por/images/Reports/POR/2024/1911012/1911012_10608074_1705764140136_rscale--rgov-66x44.png\" alt=\"RScale Architecture\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Robust resource scaling of containerized microservices</div>\n<div class=\"imageCredit\">Kang, Peng and Lama, Palden \"Robust Resource Scaling of Containerized Microservices with Probabilistic Machine learning\" 2020 IEEE/ACM 13th International Conference on Utility and Cloud Computing, 2020</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Palden&nbsp;Lama\n<div class=\"imageTitle\">RScale Architecture</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1911012/1911012_10608074_1705764847823_vrebalance--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1911012/1911012_10608074_1705764847823_vrebalance--rgov-800width.png\" title=\"BO-based Virtual Rebalance\"><img src=\"/por/images/Reports/POR/2024/1911012/1911012_10608074_1705764847823_vrebalance--rgov-66x44.png\" alt=\"BO-based Virtual Rebalance\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">SLO-aware virtual resource\norchestrator based on Bayesian Optimization.</div>\n<div class=\"imageCredit\">Kang, Peng and Lama, Palden and Khan, Samee U. \"SLO-aware Virtual Rebalancing for Edge Stream Processing\" IEEE International Conference on Cloud Engineering, 2021</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Palden&nbsp;Lama\n<div class=\"imageTitle\">BO-based Virtual Rebalance</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn the realm of large-scale web services spanning diverse application domains, the prevalent approach involves constructing systems with numerous small, modular components known as microservices. These microservices are designed for seamless deployment, updating, and scaling. Utilizing a lightweight and isolated execution environment, often in the form of containers, these microservices can be efficiently deployed across a spectrum of platforms, ranging from cloud servers to resource-constrained edge nodes. This project analyzed the performance issues and resource-scaling challenges of both cloud-based web services and event-driven stream processing microservices deployed at the edge. The complex interactions between microservices and the contention of shared hardware resources pose significant challenges in managing application performance. Furthermore, existing resource management techniques are too slow to adapt to changing system dynamics resulting in Service Level Objective (SLO) violations of end-to-end application performance.\n\n\nTo address these challenges, this project developed robust performance models based on a probabilistic machine learning approach, Gaussian Process (GP) regression, which can predict the end-to-end tail latency of microservice workflows and efficiently estimate the confidence bounds of prediction. For cloud-based web services, the models leveraged multi-layered data collected from container-level resource usage metrics and virtual machine-level hardware performance counter metrics. In the case of stream processing microservices deployed in a mobile edge computing environment, the models were based on the computing resources allocated to each container. The project further developed a resource scaling system that manages end-to-end tail latency by incorporating predictive uncertainty into the resource allocation problem. Additionally, an SLO-aware resource allocation technique based on Bayesian Optimization (BO) was introduced to quickly identify and deploy near-optimal resource configurations for stream processing microservices.\n\n\nThe project evaluated the proposed techniques using an open-source microservices benchmark, Robot Shop, and a real-time IoT benchmark for distributed stream processing platforms (RIoTBench). These benchmark applications were containerized with Docker and orchestrated with Kubernetes. Our experimental results demonstrated the superior prediction accuracy and adaptiveness of our modeling approach compared to popular machine learning techniques. Compared to our modeling technique, deriving the 95% confidence interval for a deterministic neural-network model based prediction (using bootstratpping method) has 4X more overhead for the same size of dataset. Our study showcased the adaptability of these performance models to the ever-shifting system dynamics including fluctuations in workload over time, variations in input data types, and unpredictable shifts of network conditions in the context of a mobile edge environment. Furthemore, our robust resource scaling technique proved effective in meeting end-to-end tail latency target of microservice workflows even in the face of multi-tenant performance interference and changing system dynamics.\n\n\nTo date, the project has produced four peer-reviewed publications, and several papers are under review. Data produced by the project is publicly available. The project has played a pivotal role in the development of the CS 5573 Cloud Computing course, contributing to a Cloud Computing Certificate jointly created by the Colleges of Science, Engineering and Business at the University of Texas at San Antonio. Several graduate and undergraduate students were trained in cloud computing, machine learning (ML) for systems, and system performance analysis. The impact of our findings is anticipated to influence researchers in the computer systems domain, encouraging further exploration and adoption of the developed performance modeling and resource scaling techniques.\t\t\t\t\tLast Modified: 01/20/2024\n\n\t\t\t\t\tSubmitted by: PaldenLama\n"
 }
}