{
 "awd_id": "1908536",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS Core: Small: Optimizing Distributed Machine Learning for Transient Resources using Loose Synchronization",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-07-23",
 "awd_max_amd_letter_date": "2019-07-23",
 "awd_abstract_narration": "The availability of large-scale data sets in many domains has driven the growth of large-scale distributed machine learning (ML) workloads on cloud platforms to derive insights from this data.  To reduce the cost of executing these workloads, cloud platforms have begun to offer transient servers for a highly discounted price.   Unfortunately, cloud platforms may revoke transient servers at any time, which can decrease distributed ML performance and eliminate any cost benefit.  High revocation rates are especially problematic for distributed ML workloads that support synchronous processing, since revoked servers block others from continuing past predefined synchronization barriers until a replacement server can reach the barrier.  While asynchronous processing eliminates this blocking and improves performance, it does not maintain the algorithmic properties of synchronous algorithms, resulting in slower algorithmic convergence or possibly preventing convergence. To maintain performance on low-cost transient servers, this project proposes re-designing traditional distributed ML algorithms to use looser forms of synchrony.  Such loose synchronization minds the gap between synchronous and asynchronous processing by maintaining the algorithmic convergence properties of synchronous processing, while enabling some asynchronous processing to avoid blocking. The project combines this loose synchronization approach with adaptive policies for selecting transient servers based on their performance, cost, and volatility to significantly reduce the cost of executing large-scale distributed ML workloads on cloud platforms.\r\n\r\nDistributed machine learning (ML) workloads that derive insights from large-scale data sets have become the foundation for numerous advances across multiple industry sectors. This project has the potential to accelerate these advances by significantly decreasing the cost and improving the efficiency of executing distributed ML workloads on cloud platforms using transient servers. To benefit the broader community, the project will publicly release its software artifacts as open source. The project will incorporate topics on transient servers and distributed ML into graduate and undergraduate courses on distributed and operation systems.  The project will also involve undergraduates in research through related summer research experience projects and undergraduate theses.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Irwin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Irwin",
   "pi_email_addr": "irwin@ecs.umass.edu",
   "nsf_id": "000619679",
   "pi_start_date": "2019-07-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Lixin",
   "pi_last_name": "Gao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lixin Gao",
   "pi_email_addr": "lgao@ecs.umass.edu",
   "nsf_id": "000483181",
   "pi_start_date": "2019-07-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Prashant",
   "pi_last_name": "Shenoy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Prashant Shenoy",
   "pi_email_addr": "shenoy@cs.umass.edu",
   "nsf_id": "000492611",
   "pi_start_date": "2019-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "",
  "perf_city_name": "Amherst",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010039292",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Machine learning (ML) has emerged as an important workload for cloud platforms and data centers given its wide variety of compelling use-cases, such as weather prediction, intelligent chatbots, self-driving cars, coding and debugging, and many others. &nbsp;Training machine learning models is expensive, as it often requires processing large-scale datasets across many distributed servers for long periods. Thus, training large-scale ML models is often done on cloud platforms, which have access to the necessary resources. &nbsp;To reduce cost, cloud platforms offer transient servers, which they may revoke at any time, but are 70-90% cheaper than traditional on-demand servers. Transience may also arise in other contexts, such as in edge devices with unreliable energy sources or network connectivity. Unfortunately, leveraging low-cost transient servers introduces challenges for training distributed ML, as it often uses a bulk-synchronous processing model, which causes revoked servers to block others from continuing past pre-defined synchronization barriers until a newly provisioned replacement server reaches the barrier. &nbsp;Unfortunately, while asynchronous processing can eliminate this blocking and improve system performance, it does not maintain the algorithmic properties of synchronous algorithms. &nbsp;To address the problem, this project developed models, algorithms, and frameworks for both understanding and optimizing distributed ML training on transient servers. Specifically, the project developed 1) a number of models that quantify the impact of transient servers on distributed ML in various contexts as a function of revocation rates, degree of parallelism, synchronization method, and straggler mitigation technique; 2) multiple frameworks that use different synchronization models and fault-tolerance techniques for mitigating the performance impact of transient server revocations, including asynchronous and flexible synchronous models; 3) implementations using the frameworks of a number of common ML algorithms to demonstrate their performance improvement under transient server revocations. &nbsp;The techniques the project developed increased the understanding of how to optimize distributed ML when running on cheap transient servers in the cloud with frequent revocations, which can significantly reduce the cost of training ML models.&nbsp;</p>\r\n<p>Broader impacts of the project included advancing the state-of-the-art in training ML models at low-cost, which is increasingly important given the accelerating demand for ML since the project's inception. The project's results were disseminated to the community through a large number of presentations and publications on the project's models, algorithms, and frameworks in multiple contexts. &nbsp;The project also supported the incorporation of topics on transient servers, distributed ML, and synchronization methods into undergraduate and graduate courses. The project supported lectures each year on cloud computing for multiple high school summer programs for students interested in computer science and engineering. The project partially supported seven research assistants. &nbsp;One doctoral student supported through this award received the department's Outstanding Dissertation Award and joined industry as software engineer after graduation.&nbsp;</p><br>\n<p>\n Last Modified: 01/27/2025<br>\nModified by: David&nbsp;Irwin</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nMachine learning (ML) has emerged as an important workload for cloud platforms and data centers given its wide variety of compelling use-cases, such as weather prediction, intelligent chatbots, self-driving cars, coding and debugging, and many others. Training machine learning models is expensive, as it often requires processing large-scale datasets across many distributed servers for long periods. Thus, training large-scale ML models is often done on cloud platforms, which have access to the necessary resources. To reduce cost, cloud platforms offer transient servers, which they may revoke at any time, but are 70-90% cheaper than traditional on-demand servers. Transience may also arise in other contexts, such as in edge devices with unreliable energy sources or network connectivity. Unfortunately, leveraging low-cost transient servers introduces challenges for training distributed ML, as it often uses a bulk-synchronous processing model, which causes revoked servers to block others from continuing past pre-defined synchronization barriers until a newly provisioned replacement server reaches the barrier. Unfortunately, while asynchronous processing can eliminate this blocking and improve system performance, it does not maintain the algorithmic properties of synchronous algorithms. To address the problem, this project developed models, algorithms, and frameworks for both understanding and optimizing distributed ML training on transient servers. Specifically, the project developed 1) a number of models that quantify the impact of transient servers on distributed ML in various contexts as a function of revocation rates, degree of parallelism, synchronization method, and straggler mitigation technique; 2) multiple frameworks that use different synchronization models and fault-tolerance techniques for mitigating the performance impact of transient server revocations, including asynchronous and flexible synchronous models; 3) implementations using the frameworks of a number of common ML algorithms to demonstrate their performance improvement under transient server revocations. The techniques the project developed increased the understanding of how to optimize distributed ML when running on cheap transient servers in the cloud with frequent revocations, which can significantly reduce the cost of training ML models.\r\n\n\nBroader impacts of the project included advancing the state-of-the-art in training ML models at low-cost, which is increasingly important given the accelerating demand for ML since the project's inception. The project's results were disseminated to the community through a large number of presentations and publications on the project's models, algorithms, and frameworks in multiple contexts. The project also supported the incorporation of topics on transient servers, distributed ML, and synchronization methods into undergraduate and graduate courses. The project supported lectures each year on cloud computing for multiple high school summer programs for students interested in computer science and engineering. The project partially supported seven research assistants. One doctoral student supported through this award received the department's Outstanding Dissertation Award and joined industry as software engineer after graduation.\t\t\t\t\tLast Modified: 01/27/2025\n\n\t\t\t\t\tSubmitted by: DavidIrwin\n"
 }
}