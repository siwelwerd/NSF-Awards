{
 "awd_id": "1943365",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Workshops on NASA Apollo Mission Audio as a Community Research Resource",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2020-04-30",
 "tot_intn_awd_amt": 30906.0,
 "awd_amount": 30906.0,
 "awd_min_amd_letter_date": "2019-08-16",
 "awd_max_amd_letter_date": "2019-08-16",
 "awd_abstract_narration": "The ability for human teams to work collaboratively together to solve complex problems relies on effective communications, typically relying on vocal communications. Unfortunately, the availability of naturalistic team/task-oriented communications for research in speech and language processing, as well as human factors and psychology for problem solving and team dynamics does not exist today. This project will involve the organization of a series of mini-workshops to advance the development of a future community resource based on the first massively large corpus of naturalistic data spanning years from hundreds of individuals working on Apollo missions, which solved one of humanity's greatest challenges -- placing a man on the moon and returning him to Earth safely. This future community resource will benefit research communities spanning technology, science, education, and history of technology. A clear added benefit is the preservation of the voices of 1000's of scientists, engineers, and technicians who made one of humanity's greatest technical achievements possible. \r\n\r\nThis project will conduct mini-workshops to collect research community input for the development of the first massively large community resource of naturalistic audio data spanning years from hundreds of individuals working on Apollo missions. This corpus, called FEARLESS STEPS, was created as a result of a previous NSF award and represents a real-world, multi-subject, problem-solving communications corpus that is real and not simulated. The collected feedback from these mini-workshops will inform the team that created the original corpus of the community users' current needs and requirements for the future community resource. These mini-workshops would include events organized at: (i) ISCA INTERSPEECH-19, (ii) U.S. Library of Congress (Audio Preservation Day), (iii) ASA-19 Acoustical Society, (iv) NASA Human Performance Meeting, and (v) Education/Historian visits. The technical goals of the mini-workshops are: (i) conducting community outreach mini-workshops to collect feedback from the science and technology communities, as well as those in historical and educational domains; (ii) developing a platform for collecting and analyzing feedback from the research community; and (iii) providing infrastructure support to develop example FEARLESS STEPS Apollo audio sets to be shared at workshop/meetings for continued community outreach. Research advancements today in speech and language technology rest on advanced machine learning concepts, which require extensive audio data for training effective models, and it is imperative that the academic community have access to massive audio data which is naturalistic, real-world, multi-speaker, task directed, and freely available to all.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Hansen",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "John H Hansen",
   "pi_email_addr": "John.Hansen@utdallas.edu",
   "nsf_id": "000197424",
   "pi_start_date": "2019-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Dallas",
  "inst_street_address": "800 WEST CAMPBELL RD.",
  "inst_street_address_2": "SP2.25",
  "inst_city_name": "RICHARDSON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9728832313",
  "inst_zip_code": "750803021",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "TX24",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT DALLAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "EJCVPNN1WFS5"
 },
 "perf_inst": {
  "perf_inst_name": "CRSS: Center for Robust Speech Systems (UTDallas)",
  "perf_str_addr": "800 W Campbell Road, Erik Jonsso",
  "perf_city_name": "Richardson",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "750803021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "TX24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 30906.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong><span style=\"text-decoration: underline;\">Part A: Technical Description: </span></strong></p>\n<p>The project has focused on establishing and sequence of mini-workshops specifically to gather and assessment the needs of users from (i) speech/language technology, (ii) speech communication science, (iii) historical, educational, and psychology of small group teams, in order to establish a future community resource based on a massive, naturalistic, real world, multi-speaker, task directed and freely available Fearless Steps APOLLO corpus. The input from the community will be used to develop the largest naturalistic audio corpus that will be made available to the public: Fearless Steps FS-2. The FEARLESS STEPS FS-2 effort would involve recovering all Apollo naturalistic and task/mission driven audio communications data (estimated +150,000 hours) communications from the entire NASA Apollo program. The task was accomplished by conducting a series of mini-workshops intending to capture user research interests and educational &amp; community needs. The series of mini-workshops were conducted from invited talks and targeted conferences that consisted of diverse domains such as technology, education/historical, and science. &nbsp;In particular, the mini-workshops were conducted at: (1) ISCA INTERSPEECH-2019 (Graz, Austria; Sept. 15-19, 2019) [mostly speech technology based], (2) ASA Acoustical Society of America Meeting (San Diego, CA; Dec. 2-6, 2019) [mostly speech science based], (3) ASRU Automatic Speech Recognition and Understanding (14-18 December 2019, Sentosa, Singapore) [mostly technology based] (4) JSALT [mostly technology based] (5) NASA Human Performance Conf. (Galveston, TX; Jan. 2020) [mostly human factors, psychology based], and (6) invited keynote talk at Dallas Public Library (50<sup>th</sup> Anniv., July 20, 2019). These six venues allowed for obtaining maximum coverage and diversity of feedback from the various communities to assess needs and benefits for future research with FEARLESS STEPS. The effort allowed for feedback on benefits to engineers/technology specialists working in speech and language processing, scientists working on individual and team-based projects involving communications for human factors, cognitive challenges, team based problem solving, as well as historians and others, with added interest in developing long-term team based solutions for future deep-space scenarios. Gathering community input was achieved by developing a web application/forum <a href=\"http://fearlesssteps.exploreapollo.org/\">http://fearlesssteps.exploreapollo.org/</a> to create feedback forms accessed by researchers worldwide to provide suggestions, and comments on points to further improve an expanded Fearless Steps Community Resource. To obtain input and encourage questions during workshop events, a questionnaire was also developed for establish and advance goals of the Community Research Corpus development and diarization (who spoke what and when) efforts. The following domains were addressed during the workshop: (i) Types of metadata and transcription required, (ii) different research domains of interest, (iii) applications on speech and language technology, (iv)science and human factors, (v) education and history applications, (vi) health and behavioral applications, (vii) group engagement and identifying human traits. More than 200 formal feedback evaluations were collected. A comprehensive evaluation of the feedback gathered was used to establish community needs action play for a follow-on NSF Community Resource submission.</p>\n<p><strong><span style=\"text-decoration: underline;\">Part B: Project?s Broader Impact</span></strong><span style=\"text-decoration: underline;\">:</span></p>\n<p>Understanding the needs of the academic, educational, and industry has a major impact in developing real world, naturalistic, task directed corpora that meets these three broad community needs, while being freely available to the public. &nbsp;The gathered feedback has established a clear community resource need and set of action requirements to establish this proposed large-scale massive multi-channel, multi-speaker, naturalistic and synchronized audio corpus which would be made freely available to the community. Feedback suggests it would provide researchers a unique opportunity to advance technology for multi-speaker task-based communications, offering new opportunities to develop next generation models for the following disciplines: (i) speech/language technology, (ii) speech/language scientists, (iii) human factors / psychology of teams, and (iv) historians and educators. With access to +150khrs of audio, researchers will be able to develop state of the art tools to effectively search and recover specific audio segments/speaker/speech of interest across individual Apollo missions, as well as link them across missions. The web based platform http://app.exploreapollo.org that currently contains curated moments/stories from Apollo-11, was found to be an effective starting point from feedback, and should serve as the basis to expand moments from the complete NASA Apollo missions. There was overwhelming consensus that the potential community resource would enable the public, historians, libraries and schools to access and navigate the nature of data, while browsing, visualizing and linking interesting aspects across the Apollo missions. Another benefit cited from feedback is the preservation of the voices of 1000?s of scientists, engineers, and technicians who made this technological accomplishment possible. A new generation of scientists will be able to study how NASA engineers worked collaboratively together to overcome mission challenges, and the corpus will serve to recognize the countless ?Heroes Behind the Heroes of Apollo?.</p>\n<p><strong><span style=\"text-decoration: underline;\">Key Words</span></strong><strong>:</strong> Knowledge Integration, Metadata Extraction, Event Reconstruction, Multi-Channel Audio, Conversational Interaction Analysis, Naturalistic Data, Apollo Missions.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/08/2020<br>\n\t\t\t\t\tModified by: John H. L.&nbsp;Hansen</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599548813036_Fig1-Summary--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599548813036_Fig1-Summary--rgov-800width.jpg\" title=\"Summary - Mini-Workshops\"><img src=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599548813036_Fig1-Summary--rgov-66x44.jpg\" alt=\"Summary - Mini-Workshops\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Summary Mini Workshops</div>\n<div class=\"imageCredit\">Pictures taken by CRSS-UTDallas</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">John H. L.&nbsp;Hansen</div>\n<div class=\"imageTitle\">Summary - Mini-Workshops</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599548917685_Fig2-Interspeech2019--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599548917685_Fig2-Interspeech2019--rgov-800width.jpg\" title=\"Workshop#1: ISCA (Interspeech-2019)\"><img src=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599548917685_Fig2-Interspeech2019--rgov-66x44.jpg\" alt=\"Workshop#1: ISCA (Interspeech-2019)\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Workshop#1: ISCA (Interspeech-2019) [Graz, Austria; Sept. 15-19, 2019]: CRSS-UTDallas NSF Apollo Workshop; Targeted Invitation Only; Top Field Experts Speech/Language  Technology; 27-30 attendees (Sept 17, 2019)</div>\n<div class=\"imageCredit\">Pictures taken by CRSS-UTDallas</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">John H. L.&nbsp;Hansen</div>\n<div class=\"imageTitle\">Workshop#1: ISCA (Interspeech-2019)</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599549141764_Fig3-ASA-19_ASRU-19--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599549141764_Fig3-ASA-19_ASRU-19--rgov-800width.jpg\" title=\"Workshop#2: Acoustical Society Annual Meeting (ASA-2019) &amp; Workshop#3: IEEE  ASRU-2019: Automatic Speech Recog. &amp; Understanding Workshop;\"><img src=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599549141764_Fig3-ASA-19_ASRU-19--rgov-66x44.jpg\" alt=\"Workshop#2: Acoustical Society Annual Meeting (ASA-2019) &amp; Workshop#3: IEEE  ASRU-2019: Automatic Speech Recog. &amp; Understanding Workshop;\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Workshop#2: Acoustical Society Annual Meeting (ASA-2019); Workshop#3: IEEE  ASRU-2019: Automatic Speech Recog. & Understanding Workshop</div>\n<div class=\"imageCredit\">Pictures taken by CRSS-UTDallas</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">John H. L.&nbsp;Hansen</div>\n<div class=\"imageTitle\">Workshop#2: Acoustical Society Annual Meeting (ASA-2019) & Workshop#3: IEEE  ASRU-2019: Automatic Speech Recog. & Understanding Workshop;</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599549242064_Fig4-NASA-HPC-2020_DallasPublicLIbrary-2019--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599549242064_Fig4-NASA-HPC-2020_DallasPublicLIbrary-2019--rgov-800width.jpg\" title=\"Workshop#5: NASA Human Performance Conf.; &amp; Meeting#6: Dallas Public Library: [Dallas, TX; July 20, 2019]\"><img src=\"/por/images/Reports/POR/2020/1943365/1943365_10634945_1599549242064_Fig4-NASA-HPC-2020_DallasPublicLIbrary-2019--rgov-66x44.jpg\" alt=\"Workshop#5: NASA Human Performance Conf.; &amp; Meeting#6: Dallas Public Library: [Dallas, TX; July 20, 2019]\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Workshop#5: NASA Human Performance Conf.: [Galveston, TX; Jan.  26, 2019]Meeting#6: Dallas Public Library: [Dallas, TX; July 20, 2019]   Focus: General community presentation & Demo/discussions;  50th Anniv. Apollo-11 Moon Landing; ~50-60 attendees</div>\n<div class=\"imageCredit\">Pictures taken by CRSS-UTDallas</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">John H. L.&nbsp;Hansen</div>\n<div class=\"imageTitle\">Workshop#5: NASA Human Performance Conf.; & Meeting#6: Dallas Public Library: [Dallas, TX; July 20, 2019]</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nPart A: Technical Description: \n\nThe project has focused on establishing and sequence of mini-workshops specifically to gather and assessment the needs of users from (i) speech/language technology, (ii) speech communication science, (iii) historical, educational, and psychology of small group teams, in order to establish a future community resource based on a massive, naturalistic, real world, multi-speaker, task directed and freely available Fearless Steps APOLLO corpus. The input from the community will be used to develop the largest naturalistic audio corpus that will be made available to the public: Fearless Steps FS-2. The FEARLESS STEPS FS-2 effort would involve recovering all Apollo naturalistic and task/mission driven audio communications data (estimated +150,000 hours) communications from the entire NASA Apollo program. The task was accomplished by conducting a series of mini-workshops intending to capture user research interests and educational &amp; community needs. The series of mini-workshops were conducted from invited talks and targeted conferences that consisted of diverse domains such as technology, education/historical, and science.  In particular, the mini-workshops were conducted at: (1) ISCA INTERSPEECH-2019 (Graz, Austria; Sept. 15-19, 2019) [mostly speech technology based], (2) ASA Acoustical Society of America Meeting (San Diego, CA; Dec. 2-6, 2019) [mostly speech science based], (3) ASRU Automatic Speech Recognition and Understanding (14-18 December 2019, Sentosa, Singapore) [mostly technology based] (4) JSALT [mostly technology based] (5) NASA Human Performance Conf. (Galveston, TX; Jan. 2020) [mostly human factors, psychology based], and (6) invited keynote talk at Dallas Public Library (50th Anniv., July 20, 2019). These six venues allowed for obtaining maximum coverage and diversity of feedback from the various communities to assess needs and benefits for future research with FEARLESS STEPS. The effort allowed for feedback on benefits to engineers/technology specialists working in speech and language processing, scientists working on individual and team-based projects involving communications for human factors, cognitive challenges, team based problem solving, as well as historians and others, with added interest in developing long-term team based solutions for future deep-space scenarios. Gathering community input was achieved by developing a web application/forum http://fearlesssteps.exploreapollo.org/ to create feedback forms accessed by researchers worldwide to provide suggestions, and comments on points to further improve an expanded Fearless Steps Community Resource. To obtain input and encourage questions during workshop events, a questionnaire was also developed for establish and advance goals of the Community Research Corpus development and diarization (who spoke what and when) efforts. The following domains were addressed during the workshop: (i) Types of metadata and transcription required, (ii) different research domains of interest, (iii) applications on speech and language technology, (iv)science and human factors, (v) education and history applications, (vi) health and behavioral applications, (vii) group engagement and identifying human traits. More than 200 formal feedback evaluations were collected. A comprehensive evaluation of the feedback gathered was used to establish community needs action play for a follow-on NSF Community Resource submission.\n\nPart B: Project?s Broader Impact:\n\nUnderstanding the needs of the academic, educational, and industry has a major impact in developing real world, naturalistic, task directed corpora that meets these three broad community needs, while being freely available to the public.  The gathered feedback has established a clear community resource need and set of action requirements to establish this proposed large-scale massive multi-channel, multi-speaker, naturalistic and synchronized audio corpus which would be made freely available to the community. Feedback suggests it would provide researchers a unique opportunity to advance technology for multi-speaker task-based communications, offering new opportunities to develop next generation models for the following disciplines: (i) speech/language technology, (ii) speech/language scientists, (iii) human factors / psychology of teams, and (iv) historians and educators. With access to +150khrs of audio, researchers will be able to develop state of the art tools to effectively search and recover specific audio segments/speaker/speech of interest across individual Apollo missions, as well as link them across missions. The web based platform http://app.exploreapollo.org that currently contains curated moments/stories from Apollo-11, was found to be an effective starting point from feedback, and should serve as the basis to expand moments from the complete NASA Apollo missions. There was overwhelming consensus that the potential community resource would enable the public, historians, libraries and schools to access and navigate the nature of data, while browsing, visualizing and linking interesting aspects across the Apollo missions. Another benefit cited from feedback is the preservation of the voices of 1000?s of scientists, engineers, and technicians who made this technological accomplishment possible. A new generation of scientists will be able to study how NASA engineers worked collaboratively together to overcome mission challenges, and the corpus will serve to recognize the countless ?Heroes Behind the Heroes of Apollo?.\n\nKey Words: Knowledge Integration, Metadata Extraction, Event Reconstruction, Multi-Channel Audio, Conversational Interaction Analysis, Naturalistic Data, Apollo Missions.\n\n \n\n\t\t\t\t\tLast Modified: 09/08/2020\n\n\t\t\t\t\tSubmitted by: John H. L. Hansen"
 }
}