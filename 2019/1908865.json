{
 "awd_id": "1908865",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Small: Speaker-Specific Articulatory Strategies",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2019-08-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 474013.0,
 "awd_amount": 474013.0,
 "awd_min_amd_letter_date": "2019-07-17",
 "awd_max_amd_letter_date": "2021-06-24",
 "awd_abstract_narration": "Speech is a uniquely human act that involves the conversion of discrete cognitive, linguistic representations to continuous, complex movements of speech articulators. By helping to understand better the variability and constraints of this conversion mechanism in healthy speech production, this project contributes to assessing speech disorders associated with neurological disease, such as apraxia. Moreover, it paves the way for novel science-driven paradigms to automatic synthesis of speech from text; a technology of increasing importance for social inclusion. It also provides a unique interdisciplinary training opportunity for students, integrating exposure to various facets of speech science research. Novel dynamic imaging data of speech production, analysis results, and derived models are shared with the broader research community.\r\n\r\nThe focus of this project is on the coordinative patterns governing the movement of speech articulators toward the achievement of speech production goals (articulatory strategies). The aim to develop a toolset for characterizing this variability, that will also enable mapping phonological representations to speaker-specific dynamics of the vocal tract. The project builds upon the frameworks of Articulatory Phonology and Task Dynamics that provide a model for generating vocal-tract dynamics from linguistic structures, in which the formation of linguistically relevant constrictions in the vocal tract is governed by the temporal deployment of dynamical systems: critically damped oscillators that are characterized temporally by parameters including targets (end goals of articulatory movements) and natural frequencies (time-course of the movement trajectories). This model is updated using vocal-tract real-time magnetic resonance imaging data from 32 speakers, in order to characterize their speech production behavior at three levels: (i) the vocal-tract deformations put forth in the act of speaking; (ii) the relative contributions of those deformations towards the achievement of phonological goals; and (iii) the temporal coordination of articulatory gestures for the production of well-formed utterances. Such characterizations of individual, speaker-specific articulatory strategies, as directly observed using state-of-the-art vocal-tract imaging technology, significantly contributes to our understanding of what underlies phonological constancy and what drives individual variability via phonetic context, speaker anatomy, and speaking style.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shrikanth",
   "pi_last_name": "Narayanan",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Shrikanth S Narayanan",
   "pi_email_addr": "shri@sipi.usc.edu",
   "nsf_id": "000377152",
   "pi_start_date": "2021-06-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Asterios",
   "pi_last_name": "Toutios",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Asterios Toutios",
   "pi_email_addr": "toutios@usc.edu",
   "nsf_id": "000791391",
   "pi_start_date": "2019-07-17",
   "pi_end_date": "2021-06-24"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Louis",
   "pi_last_name": "Goldstein",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Louis M Goldstein",
   "pi_email_addr": "louisgol@usc.edu",
   "nsf_id": "000106083",
   "pi_start_date": "2019-07-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3740 McClintock Ave, EEB 427",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900892564",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 152708.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 321305.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>When we speak, the organs of our vocal tract, the tongue, the lips, the jaw, move in a coordinated fashion to produce the speech sounds that we hear. It is like a choreography of dance steps. This dance is critical for human communication. All of our messages are transmitted from a speaker to a hearer by means of it. So to understand communication, we have to understand the principles underlying that dance, including how it can vary across individuals and yet convey the same linguistic information. This understanding can be in vital in evaluating and possibly ameliorating cases where communication breaks down because of disease, aging, or surgery to one or more of the vocal organs, or conversely fails to be adequately established in the learning process.</p>\n<p>To understand these principles, we need a precise mathematical model of how the appropriate steps of the dance, or speech gestures, are recruited and coordinated in service of particular linguistic messages. One theory that does that in a principled way is Articulatory Phonology, but until now its implementation in the Task Dynamic model has been very limited to a very schematic vocal tract that does not generate movements produced by real human speakers with vocal tracts that differ in their anatomy and flexibility. And obviously being able to model varying vocal tract anatomy and flexibility is crucial to cases of communication breakdown and learning in children (whose anatomies and flexibilities are undergoing continuous changes).</p>\n<p>Our project has addressed this need by developing a more flexible model that can generalize to different vocal tract anatomies. To do so required us to first develop new tools that helped us to analyze a rich set of data from 8 speakers collected using real-time MR imaging, so as to mathematically characterize the motion of the articulators as the speakers talked using a small number of parameters. We then developed a machine-leaning &ldquo;forward&rdquo; model of how local changes in the articulator parameters of each speaker&rsquo;s articulators would contribute to changes in the vocal tract dimensions that define to the linguistic goals of particular speech gestures in a speaker-independent way, like the firm compression of the lips at the beginning of a word like &ldquo;beach&rdquo; that can be defined as a goal along the dimension of inter-lip distance. This forward model was then incorporated into a dynamical model that produces movements of the articulators in response to the representation of the intended message as a sequence of goal values.</p>\n<p>The model and the analysis techniques we developed were then applied to help understand particular problems in speech production. Among typical speakers, we examined how variation in overall vocal tract anatomy contributes to the wide variation demonstrated in the vocal tract shapes that American English speakers use to produce &ldquo;r.&rdquo;&nbsp; Length of the oral cavity roof and degree of inclination of the jaw contributed significantly to differences in shape across speakers. We also analyzed the speech and articulator movements of two speakers with radically atypical anatomies: a speaker who was tongue growth was congenitally stunted and who has no functioning tongue tip, and two speakers who have undergone partial glossectomies of the tongue to treat cancer. In all of these cases, we discovered that speakers can find novel ways of moving articulators to achieve the linguistic goals. This enriches our understanding of variety of articulatory movement patterns that can be recruited to achieve linguist goals and can contribute to training protocols for speech rehabilitation.</p>\n<p>Intellectual Impact: Bridging the cognitive representations involved in speech production with the observable physical movements of speech articulators is crucial to achieve progress towards a better understanding of speech as a uniquely human act and its potential breakdowns at several cognitive and neuromotor levels. The characterizations and models of individual, speaker-specific articulatory behavior, as directly observed using state-of-the-art vocal tract imaging technology, that we developed will significantly contribute to our understanding of what underlies speakers&rsquo; abilities to communicate linguistic messages with different anatomical and neuromotor systems. More generally, the models we developed can be used to help model other types of variation, beyond that of anatomy, such as emotional state and speaking rate.&nbsp;</p>\n<p>Broader Impact: Results of data analysis and models built will be made freely available to the research community. They may help pave way for a novel paradigm for text-to-speech synthesis by principled simulation of speaker-specific vocal tracts. By helping understand better the variability and constraints of healthy speech production, the models developed can also contribute to assessing speech disorders, such as apraxia or ALS, and to help with the remediation of disorders or with childhood difficulties in speech learning. Finally, the project provided a unique interdisciplinary training opportunity for students, integrating exposure to various facets of speech science research.&nbsp;</p><br>\n<p>\n Last Modified: 01/06/2024<br>\nModified by: Shrikanth&nbsp;S&nbsp;Narayanan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nWhen we speak, the organs of our vocal tract, the tongue, the lips, the jaw, move in a coordinated fashion to produce the speech sounds that we hear. It is like a choreography of dance steps. This dance is critical for human communication. All of our messages are transmitted from a speaker to a hearer by means of it. So to understand communication, we have to understand the principles underlying that dance, including how it can vary across individuals and yet convey the same linguistic information. This understanding can be in vital in evaluating and possibly ameliorating cases where communication breaks down because of disease, aging, or surgery to one or more of the vocal organs, or conversely fails to be adequately established in the learning process.\n\n\nTo understand these principles, we need a precise mathematical model of how the appropriate steps of the dance, or speech gestures, are recruited and coordinated in service of particular linguistic messages. One theory that does that in a principled way is Articulatory Phonology, but until now its implementation in the Task Dynamic model has been very limited to a very schematic vocal tract that does not generate movements produced by real human speakers with vocal tracts that differ in their anatomy and flexibility. And obviously being able to model varying vocal tract anatomy and flexibility is crucial to cases of communication breakdown and learning in children (whose anatomies and flexibilities are undergoing continuous changes).\n\n\nOur project has addressed this need by developing a more flexible model that can generalize to different vocal tract anatomies. To do so required us to first develop new tools that helped us to analyze a rich set of data from 8 speakers collected using real-time MR imaging, so as to mathematically characterize the motion of the articulators as the speakers talked using a small number of parameters. We then developed a machine-leaning forward model of how local changes in the articulator parameters of each speakers articulators would contribute to changes in the vocal tract dimensions that define to the linguistic goals of particular speech gestures in a speaker-independent way, like the firm compression of the lips at the beginning of a word like beach that can be defined as a goal along the dimension of inter-lip distance. This forward model was then incorporated into a dynamical model that produces movements of the articulators in response to the representation of the intended message as a sequence of goal values.\n\n\nThe model and the analysis techniques we developed were then applied to help understand particular problems in speech production. Among typical speakers, we examined how variation in overall vocal tract anatomy contributes to the wide variation demonstrated in the vocal tract shapes that American English speakers use to produce r. Length of the oral cavity roof and degree of inclination of the jaw contributed significantly to differences in shape across speakers. We also analyzed the speech and articulator movements of two speakers with radically atypical anatomies: a speaker who was tongue growth was congenitally stunted and who has no functioning tongue tip, and two speakers who have undergone partial glossectomies of the tongue to treat cancer. In all of these cases, we discovered that speakers can find novel ways of moving articulators to achieve the linguistic goals. This enriches our understanding of variety of articulatory movement patterns that can be recruited to achieve linguist goals and can contribute to training protocols for speech rehabilitation.\n\n\nIntellectual Impact: Bridging the cognitive representations involved in speech production with the observable physical movements of speech articulators is crucial to achieve progress towards a better understanding of speech as a uniquely human act and its potential breakdowns at several cognitive and neuromotor levels. The characterizations and models of individual, speaker-specific articulatory behavior, as directly observed using state-of-the-art vocal tract imaging technology, that we developed will significantly contribute to our understanding of what underlies speakers abilities to communicate linguistic messages with different anatomical and neuromotor systems. More generally, the models we developed can be used to help model other types of variation, beyond that of anatomy, such as emotional state and speaking rate.\n\n\nBroader Impact: Results of data analysis and models built will be made freely available to the research community. They may help pave way for a novel paradigm for text-to-speech synthesis by principled simulation of speaker-specific vocal tracts. By helping understand better the variability and constraints of healthy speech production, the models developed can also contribute to assessing speech disorders, such as apraxia or ALS, and to help with the remediation of disorders or with childhood difficulties in speech learning. Finally, the project provided a unique interdisciplinary training opportunity for students, integrating exposure to various facets of speech science research.\t\t\t\t\tLast Modified: 01/06/2024\n\n\t\t\t\t\tSubmitted by: ShrikanthSNarayanan\n"
 }
}