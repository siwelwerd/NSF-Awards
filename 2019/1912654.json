{
 "awd_id": "1912654",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Solving Multiscale Problems and Data Classification with Subsampled Data by Integrating Partial Differential Equation Analysis with Data Science",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922113",
 "po_email": "ygorb@nsf.gov",
 "po_sign_block_name": "Yuliya Gorb",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2019-07-25",
 "awd_max_amd_letter_date": "2019-07-25",
 "awd_abstract_narration": "In many practical applications, one often needs to provide solutions to quantities of interest to a large-scale problem but with only subsampled data and partial information of the physical model.  Existing computational solvers cannot be used directly for this purpose. On the other hand, many powerful techniques have been developed in data science to represent and compress data for useful information with extreme efficiency and low computational complexities. A crucial factor for the success of these methods is to exploit some special features in these high-dimensional data. The purpose of this project is to integrate physical models with data science to develop a new generation of computational methods that can solve large-scale physical or data science problems using only subsampled data and partial knowledge of the physical model. The mathematical analysis will help reveal certain important solution structures so that one can use techniques from data science to give accurate approximations for those quantities of interest. Without identifying these special solution structures and using the physical model as a constraint, the current techniques from data science cannot be used directly to achieve PI's goal. This project can have a substantial impact for the computational science and data science communities, for national technology and society. Additional impact will be the involvement of graduate students. This research provides a solid training in mathematical analysis, physical modeling, and data science. The interdisciplinary training they receive in this project will be very important for their future careers in mathematics and science.\r\n  \r\nThe recent advances in data science offer tremendous opportunities for computational sciences. A key to the success in data science is to exploit some special features in the high-dimensional data. Traditional PDE solvers have not taken full advantage of the special solution structures. PDE analysis and data science complement each other. PDE analysis can identify some important solution structures that can help the PI to design a more effective deep generative network to solve the physical problem. Without the guidance from the PDE analysis, naive application of current machine learning algorithms to multiscale problems would fail. The solution of the nonconvex optimization problem can easily get stuck in local minimum and may converge to the wrong solution. The PI will identify some key ingredients that would make such integration successful, investigate what type of PDEs can be compressed and what algorithms can be used to approximate quantities of interest with a small percentage of subsampled data and partial knowledge of the physical model. This research will also provide valuable theoretical understanding of some deep learning methods for solving multiscale problems. The PI will consider both inverse and forward problems. For the forward problem, he will develop a novel multiscale method based on subsampled data to reconstruct the solution with guaranteed accuracy.  For the inverse problem, the PI will post it as a Bayesian inverse problem and use Deep Generative Networks. An essential ingredient in this approach is to introduce a novel multiscale invertible flow to approximate the transport map, which enables the PI to develop an efficient sampling algorithm to capture the multiple modes in the posterior distribution.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thomas",
   "pi_last_name": "Hou",
   "pi_mid_init": "Y",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas Y Hou",
   "pi_email_addr": "hou@acm.caltech.edu",
   "nsf_id": "000443265",
   "pi_start_date": "2019-07-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "California Institute of Technology",
  "inst_street_address": "1200 E CALIFORNIA BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "PASADENA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6263956219",
  "inst_zip_code": "911250001",
  "inst_country_name": "United States",
  "cong_dist_code": "28",
  "st_cong_dist_code": "CA28",
  "org_lgl_bus_name": "CALIFORNIA INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "U2JMKHNS5TG4"
 },
 "perf_inst": {
  "perf_inst_name": "California Institute of Technology",
  "perf_str_addr": "1200 E California Blvd., MC 104-",
  "perf_city_name": "Pasadena",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "911250001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "28",
  "perf_st_cong_dist": "CA28",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>We have witnessed explosive developments in machine learning and data science during the past decade. While there have been many exciting algorithmic developments and experimental results to demonstrate the powerfulness of various machine learning methods, there is still a lack of systematic understanding why these methods work so well, what are the hidden assumptions on the geometry or topology of the energy landscape of the loss function,&nbsp;what are their limitations and when they may fail. The methodologies that we have developed in this project provide some valuable insight to these questions through several challenging applications in both physical sciences and data sciences. Our methodologies not only complement the existing methods in physical sciences and allow us to attack more challenging problems, they also shed useful light on how to design a more systematic neural network using a multiscale and multilevel approach, which makes the training of a high dimensional neural network more efficient with better generalization properties. Our multiscale invertible deep generative neural network also&nbsp;yields great interpretability of its neurons in intermediate layers.&nbsp;</p>\n<p>In many practical applications, we often need to provide solutions to quantities of interest to a large-scale problem but with only subsampled data and partial information of the physical model.&nbsp;Traditional numerical methods for solving partial differential equations cannot be used directly for this purpose.&nbsp; On the other hand, many powerful techniques have been developed in data science to represent and compress data for useful information with extreme efficiency and low computational complexities. A crucial factor for the success of these methods is to exploit some low rank or sparsity structures in these high-dimensional data.&nbsp;By integrating our domain knowledge in physical science with that in data science, we are in a better position to make substantial progress in both areas.&nbsp;</p>\n<p>We consider two classes of applications in this project: (1) a multiscale physical problem with subsampled data and (2) a low rank matrix recovery from limited measurements. For the multiscale problem, both inverse and forward problems are considered. For the forward problem, we develop a novel multiscale method based on subsampled data to reconstruct the solution with guaranteed accuracy. This is made possible by establishing a novel idea using only the average of the solution over a tiny fine grid cell within each coarse grid cell with optimal approximation property. For the inverse problem, we post it as a Bayesian inverse problem and use Deep Generative Networks. An essential ingredient in our approach is to introduce a novel multiscale invertible flow to approximate the transport map, which enables us to develop an efficient sampling algorithm to capture the multiple modes in the posterior distribution.&nbsp; For the low rank matrix recovery problem, we study the manifold optimization problem and show that&nbsp;the basic manifold gradient descent method, named projected gradient descent, asymptotically escapes from strict saddles and converge to minima.&nbsp; Moreover, we show that the&nbsp;projected gradient descent converges to the global minimum with a random initialization with a very high probability. This helps explain why the performance of the projected gradient descent is so robust in low rank matrix recovery.</p>\n<p>Our work on the potential singular behavior of the Navier-Stokes equations is of great importance to weather forecasting, travel safety by air or by sea, and national interest. It represents a significant progress toward the longstanding open question on the Clay Millnennium Problem on the Navier-Stokes equations.</p>\n<p>&nbsp;This project also helps train the next generation of scientists who are knowledgeable in both physical science and data science. They are in an excellent position to make substantial advances in both of these areas. Several graduate students were involved in this project. They got a first hand experience to develop cutting edge techniques to solve challenging partial differential equations using techniques from data science. The positive feedback that was generated from our published papers and conference presentations further enhances their confidence that you are able to make original and fundamental contributions in this challenging field, which in turn convinces them that they have the potential to develop into a first rate researcher.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/06/2022<br>\n\t\t\t\t\tModified by: Thomas&nbsp;Y&nbsp;Hou</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWe have witnessed explosive developments in machine learning and data science during the past decade. While there have been many exciting algorithmic developments and experimental results to demonstrate the powerfulness of various machine learning methods, there is still a lack of systematic understanding why these methods work so well, what are the hidden assumptions on the geometry or topology of the energy landscape of the loss function, what are their limitations and when they may fail. The methodologies that we have developed in this project provide some valuable insight to these questions through several challenging applications in both physical sciences and data sciences. Our methodologies not only complement the existing methods in physical sciences and allow us to attack more challenging problems, they also shed useful light on how to design a more systematic neural network using a multiscale and multilevel approach, which makes the training of a high dimensional neural network more efficient with better generalization properties. Our multiscale invertible deep generative neural network also yields great interpretability of its neurons in intermediate layers. \n\nIn many practical applications, we often need to provide solutions to quantities of interest to a large-scale problem but with only subsampled data and partial information of the physical model. Traditional numerical methods for solving partial differential equations cannot be used directly for this purpose.  On the other hand, many powerful techniques have been developed in data science to represent and compress data for useful information with extreme efficiency and low computational complexities. A crucial factor for the success of these methods is to exploit some low rank or sparsity structures in these high-dimensional data. By integrating our domain knowledge in physical science with that in data science, we are in a better position to make substantial progress in both areas. \n\nWe consider two classes of applications in this project: (1) a multiscale physical problem with subsampled data and (2) a low rank matrix recovery from limited measurements. For the multiscale problem, both inverse and forward problems are considered. For the forward problem, we develop a novel multiscale method based on subsampled data to reconstruct the solution with guaranteed accuracy. This is made possible by establishing a novel idea using only the average of the solution over a tiny fine grid cell within each coarse grid cell with optimal approximation property. For the inverse problem, we post it as a Bayesian inverse problem and use Deep Generative Networks. An essential ingredient in our approach is to introduce a novel multiscale invertible flow to approximate the transport map, which enables us to develop an efficient sampling algorithm to capture the multiple modes in the posterior distribution.  For the low rank matrix recovery problem, we study the manifold optimization problem and show that the basic manifold gradient descent method, named projected gradient descent, asymptotically escapes from strict saddles and converge to minima.  Moreover, we show that the projected gradient descent converges to the global minimum with a random initialization with a very high probability. This helps explain why the performance of the projected gradient descent is so robust in low rank matrix recovery.\n\nOur work on the potential singular behavior of the Navier-Stokes equations is of great importance to weather forecasting, travel safety by air or by sea, and national interest. It represents a significant progress toward the longstanding open question on the Clay Millnennium Problem on the Navier-Stokes equations.\n\n This project also helps train the next generation of scientists who are knowledgeable in both physical science and data science. They are in an excellent position to make substantial advances in both of these areas. Several graduate students were involved in this project. They got a first hand experience to develop cutting edge techniques to solve challenging partial differential equations using techniques from data science. The positive feedback that was generated from our published papers and conference presentations further enhances their confidence that you are able to make original and fundamental contributions in this challenging field, which in turn convinces them that they have the potential to develop into a first rate researcher. \n\n \n\n \n\n\t\t\t\t\tLast Modified: 09/06/2022\n\n\t\t\t\t\tSubmitted by: Thomas Y Hou"
 }
}