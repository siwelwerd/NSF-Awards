{
 "awd_id": "1916245",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Innovations for Bayesian Tree Ensemble Methodology",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2019-07-15",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 149999.0,
 "awd_amount": 149999.0,
 "awd_min_amd_letter_date": "2019-07-10",
 "awd_max_amd_letter_date": "2019-07-10",
 "awd_abstract_narration": "An essential goal of modern statistical analyses across many disciplines is to gain insight into the behavior of real-world processes both to identify important correlates of variation and to obtain improved predictions.  For example in marketing, the statistician may be interested in learning the purchasing behavior of consumers from an analysis of a database of consumer transactions that includes various consumer descriptors (e.g. age, income level, geographic location) as well as  purchase amounts. The statistician would then typically attempt to build a mathematical model that characterizes the relationship between the consumer descriptors and the expenditure amount.  In doing so, however, certain issues bear strongly on the model's value and effectiveness.  First, the validity of a model may strongly depend on prior assumptions about the nature of the modeled process, information that can be difficult to ascertain. For instance, a consumer behavior model which builds in a simple assumption that consumers with higher income levels are always expected to purchase more, may be inadvertently ignoring subtleties that violate this assumption when other factors are simultaneously taken into account.  Second, sometimes even a valid and effective model may be such a complicated object that the extraction of meaningful information can itself be very challenging.  For example, after establishing particular set of predictors as important drivers of consumer purchasing power, it will still be of key interest how to best measure their relative importance in the model.  Focusing on the powerful and flexible approach of Bayesian regression tree ensemble modeling, the main thrust of this project will be to innovate this methodology to address these and other modeling avenues.  This new methodology will enable practitioners to address their research questions in an assumption-lean framework that allows the ensemble models to make use of their data to adaptively and flexibly incorporate contextual modeling assumptions. To greatly enhance interpretability, it will also provide automatic, information based summaries of variable importance to help the practitioner understand and interpret the available descriptor information.  In addition to these and further methodological contributions, the project will develop software for the implementation of this methodology as a freely available R package, enabling practitioners to more easily leverage our developments in their practical work. This is where the graduate student supported by this award will help. \r\n\r\n\r\nThe research will focus on three general innovations to Bayesian ensemble modeling to further enhance its ability to extract meaning from complex data within an assumption lean framework.    The first contribution will develop theoretically valid measures of variable importance.  These measures will provide computationally efficient calculation of indices which meaningfully gauge the relative importance of predictor variables, both marginally and in terms of interactions.  The second contribution will provide an approach to monotone shape constrained inference which does not require any prior assumption of monotonicity.  This multidimensional nonparametric regression approach will enable the discovery and estimation of any and all the monotone components of the regression function, and to do so with no constraint assumptions whatsoever.  The third contribution will vastly extend the applicability of Bayesian ensemble modeling by developing a generalization of BART for arbitrary response data distributions, such as dichotomous responses and count data.  This major technical innovation will be based on a conjugacy-free formulation that will extend the reach of BART to many new application areas and problem types than were previously possible.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Edward",
   "pi_last_name": "George",
   "pi_mid_init": "I",
   "pi_sufx_name": "",
   "pi_full_name": "Edward I George",
   "pi_email_addr": "edgeorge@wharton.upenn.edu",
   "nsf_id": "000153580",
   "pi_start_date": "2019-07-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "Wharton School, Dept of Statistics",
  "perf_str_addr": "3730 Walnut St, Suite 400",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191043615",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 149999.0
  }
 ],
 "por": null
}