{
 "awd_id": "1908774",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Small: Learning From Diverse Populations: A Complexity-Theoretic Perspective",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-09-04",
 "awd_max_amd_letter_date": "2019-09-19",
 "awd_abstract_narration": "Despite the successes of machine learning at complex prediction and classification tasks (such as which add a reader will click? or which word a speaker pronounced?), there is growing evidence that \"state-of-the-art\" predictors can perform significantly less accurately on minority populations than on the majority population. Indeed, a notable study of three commercial face recognition systems, known as the \"Gender Shades\" project demonstrated significant performance gaps across different subpopulations at natural classification tasks. Systematic errors on underrepresented subpopulations limit the overall utility of machine-learned prediction systems and may cause material harm to individuals from minority groups. To address accuracy disparity and systematic biases throughout machine learning, the project pursue a principled study of learning in the presence of diverse populations. The project puts high value on education, service to the research community, and wide dissemination of knowledge. The research activities will be accompanied by and integrated with curriculum development, research advising (for students at all levels), service, and outreach to other scientific communities and in popular writing. In addition, in the age of machine-learning and big data, the project's societal impact is twofold: making sure that algorithms work for everyone but also making sure algorithms uncover all potential talent, which exists in all communities.\r\n\r\nThe project combines theoretical and empirical investigations to develop algorithmic tools for mitigating systematic bias across subpopulations and to answer basic scientific questions about why discrepancy in accuracy across subpopulations emerges in the first place. Specifically, the project aims to ask and resolve questions that arise in the context of learning from diverse populations along three main axes: (1) Improving predictions for underrepresented populations: Can learning algorithms be developed that provably do not overlook significant subpopulations, (2) Representing individuals to improve the ability to audit and repair models, (3) Understanding the causes for biases in machine common learning models and algorithms.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Omer",
   "pi_last_name": "Reingold",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Omer Reingold",
   "pi_email_addr": "omreing@stanford.edu",
   "nsf_id": "000721860",
   "pi_start_date": "2019-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "353 Serra Mall, Gates 462",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943055008",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Multigroup fairness is a family of fairness notions proposed in the last five years. Instead of providing aggregate statistical guarantees for a few protected categories (defined by race, ethnicity, gender, age, and so on), these definitions suggest giving such guarantees to a large (often exponential) number of sets. The main goal of this project was to adapt multi-group notions of fairness, and specifically multicalibration (where the guarantee to each set is calibration), from the algorithmic fairness literature towards classic objectives of statistical validity and robustness for heterogeneous populations. The results throughout the lifetime of this project suggest major paradigm shifts (relying on multicalibration) which are highlighted at a very high-level here:</p>\n<p>&nbsp;</p>\n<p><strong>A computational perspective on the meaning of individual probabilities.</strong> Predictors assign probabilities to individuals such as the probability that an individual will repay a loan, will have a heart attack in the next decade, will commit a crime, will graduate in four years. Such &ldquo;probabilities&rdquo; are used to make decisions with dramatic consequences to individuals (such as loan approval, medical intervention, bail decision or university admissions). But the idea of individual probabilities is under fierce debate by statisticians as it is not clear for example what is the meaning of &ldquo;this specific individual has a 3% chance of a heart attack in the next decade. What is the probability space? Given the scale of automated decision making a computational perspective on this question is needed, with the purpose placing the validity of learning predictors on a rigorous foundation. The notion of outcome indistinguishability introduced here gives such a perspective. An outcome-indistinguishable predictor can be viewed as giving a model of events that cannot be refuted from empirical evidence within some computational bound.&nbsp;Outcome indistinguishability has been very well accepted and has already seen numerous subsequent works by others and in this project. The applicability of such predictors stems from the fact that they can replace the Bayes-optimal predictor in many settings.</p>\n<p>&nbsp;</p>\n<p><strong>A new paradigm for loss minimization in machine learning, through the notion of omnipredictors</strong>. The prevailing paradigm in loss minimization requires the loss function to be known and determined in time a predictor is learned. In natural and common examples, learning to optimize for one loss function would imply a completely different predictor than learning to optimize for another (and one predictor cannot be learned from the other). The problem with this paradigm is that we may not know what the appropriate loss function is (for example, a prediction of the probability of a medical condition may be used to determine a medical intervention that may not even exist in the time of learning) or it may be the case that we need to consider a collection of loss functions. The project suggested a different paradigm where a single predictor is learned and when deciding on an action it can be used to minimize any one of a very wide collection of loss functions. This notion too was met with excitement and seen several subsequent works by others and in this project. <br /> <br /></p>\n<p>A new paradigm for <strong>adapting a statistical study on one probability distribution to another</strong>, which is blind to the target distribution at the time of inference and is competitive with wide-spread methods based on propensity scoring. Transferring statistical findings between populations that are distributed differently is an extremely foundational problem in statistics and learning theory. For example, transferring a medical study from one hospital to another. The prevailing paradigm is learning what is known as a propensity score which is meant to translate one distribution to another. This requires having samples from both distributions in time of learning. This project proposed a new method that does not require learning a propensity score and is still competitive with any propensity score learned from a class of potential scores. This work has helped spread the impact of this project towards additional communities within statistics and led for example to the development of an R package for multicalibration (the notion that stands at the heart of this work).</p>\n<p>&nbsp;</p>\n<p>We focused on these three big threads as they have been incredibly well received, and promoted implications of multi-group fairness to learning that could not have been foreseen. These results are the focus of courses (by the PI and by others) and scientific meetings, and we are confident that their impact will only increase.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/13/2023<br>\n\t\t\t\t\tModified by: Omer&nbsp;Reingold</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMultigroup fairness is a family of fairness notions proposed in the last five years. Instead of providing aggregate statistical guarantees for a few protected categories (defined by race, ethnicity, gender, age, and so on), these definitions suggest giving such guarantees to a large (often exponential) number of sets. The main goal of this project was to adapt multi-group notions of fairness, and specifically multicalibration (where the guarantee to each set is calibration), from the algorithmic fairness literature towards classic objectives of statistical validity and robustness for heterogeneous populations. The results throughout the lifetime of this project suggest major paradigm shifts (relying on multicalibration) which are highlighted at a very high-level here:\n\n \n\nA computational perspective on the meaning of individual probabilities. Predictors assign probabilities to individuals such as the probability that an individual will repay a loan, will have a heart attack in the next decade, will commit a crime, will graduate in four years. Such \"probabilities\" are used to make decisions with dramatic consequences to individuals (such as loan approval, medical intervention, bail decision or university admissions). But the idea of individual probabilities is under fierce debate by statisticians as it is not clear for example what is the meaning of \"this specific individual has a 3% chance of a heart attack in the next decade. What is the probability space? Given the scale of automated decision making a computational perspective on this question is needed, with the purpose placing the validity of learning predictors on a rigorous foundation. The notion of outcome indistinguishability introduced here gives such a perspective. An outcome-indistinguishable predictor can be viewed as giving a model of events that cannot be refuted from empirical evidence within some computational bound. Outcome indistinguishability has been very well accepted and has already seen numerous subsequent works by others and in this project. The applicability of such predictors stems from the fact that they can replace the Bayes-optimal predictor in many settings.\n\n \n\nA new paradigm for loss minimization in machine learning, through the notion of omnipredictors. The prevailing paradigm in loss minimization requires the loss function to be known and determined in time a predictor is learned. In natural and common examples, learning to optimize for one loss function would imply a completely different predictor than learning to optimize for another (and one predictor cannot be learned from the other). The problem with this paradigm is that we may not know what the appropriate loss function is (for example, a prediction of the probability of a medical condition may be used to determine a medical intervention that may not even exist in the time of learning) or it may be the case that we need to consider a collection of loss functions. The project suggested a different paradigm where a single predictor is learned and when deciding on an action it can be used to minimize any one of a very wide collection of loss functions. This notion too was met with excitement and seen several subsequent works by others and in this project. \n \n\n\nA new paradigm for adapting a statistical study on one probability distribution to another, which is blind to the target distribution at the time of inference and is competitive with wide-spread methods based on propensity scoring. Transferring statistical findings between populations that are distributed differently is an extremely foundational problem in statistics and learning theory. For example, transferring a medical study from one hospital to another. The prevailing paradigm is learning what is known as a propensity score which is meant to translate one distribution to another. This requires having samples from both distributions in time of learning. This project proposed a new method that does not require learning a propensity score and is still competitive with any propensity score learned from a class of potential scores. This work has helped spread the impact of this project towards additional communities within statistics and led for example to the development of an R package for multicalibration (the notion that stands at the heart of this work).\n\n \n\nWe focused on these three big threads as they have been incredibly well received, and promoted implications of multi-group fairness to learning that could not have been foreseen. These results are the focus of courses (by the PI and by others) and scientific meetings, and we are confident that their impact will only increase. \n\n \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 07/13/2023\n\n\t\t\t\t\tSubmitted by: Omer Reingold"
 }
}