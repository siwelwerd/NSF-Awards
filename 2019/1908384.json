{
 "awd_id": "1908384",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Collaborative Research: Rigorous Approaches for Scalable Privacy-preserving Deep Learning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922182",
 "po_email": "pbrass@nsf.gov",
 "po_sign_block_name": "Peter Brass",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 81889.0,
 "awd_amount": 81889.0,
 "awd_min_amd_letter_date": "2019-07-12",
 "awd_max_amd_letter_date": "2021-06-08",
 "awd_abstract_narration": "One of the most salient features of this time is the dissemination of massive amounts of personal and sensitive data. Despite their enormous societal benefits, the powerful tools of modern machine learning, especially deep learning, can pose real threats to personal privacy. For example, over the last few years, it has become evident that deep neural networks have a remarkable power in learning even the finest details from large complex data sets. With such powerful tools, the need for robust and rigorous guarantees for privacy protection has become more crucial. The last decade has witnessed the rise of a sound mathematical theory, known as differential privacy, that enables designing data-analysis algorithms with rigorous privacy guarantees for their input data sets. Despite the noticeable success of this theory, existing tools from differential privacy are severely limited in offering acceptable utility guarantees when dealing with complex models like those arising in deep learning. This project will address those limitations by offering new principled approaches for designing differentially-private deep-learning algorithms that can scale to industrial workloads. The project will also involve collaboration with industry, which will facilitate the evaluation of the developed algorithms on real-world datasets and the development of open-source software tools. The products of this project have the potential to transform the way massive sets of sensitive data are used in modern machine-learning systems, which will impact the way these systems are designed and implemented in practice. The activities of this project will also aim at promoting diversity in computing by recruiting women and members of underrepresented groups.\r\n\r\nThe investigators will develop a rigorous, multi-faceted design paradigm for scalable, practical, differentially private algorithms for modern machine learning. This paradigm is based on two general strategies: (i) exploiting realistic and useful properties of the data and the machine-learning models to circumvent existing limitations in the literature on differential privacy, and (ii) leveraging a limited amount of public data (that has no privacy constraints) to boost the utility of the algorithms. Based on these strategies, the project will pursue following directions: (1) developing a new, generic framework for utilizing public data in privacy-preserving machine learning, (2) designing improved iterative training algorithms that can bypass the standard use of the so-called \"composition theorem\" of differential privacy, and (3) designing new differentially private stochastic-gradient methods tuned specifically to non-convex and over-parameterized machine-learning problems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "C Sesh",
   "pi_last_name": "Seshadhri",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "C Sesh Seshadhri",
   "pi_email_addr": "sesh@ucsc.edu",
   "nsf_id": "000684757",
   "pi_start_date": "2021-06-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Abhradeep",
   "pi_last_name": "Guha Thakurta",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Abhradeep Guha Thakurta",
   "pi_email_addr": "aguhatha@ucsc.edu",
   "nsf_id": "000779238",
   "pi_start_date": "2019-07-12",
   "pi_end_date": "2021-06-08"
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Cruz",
  "inst_street_address": "1156 HIGH ST",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA CRUZ",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8314595278",
  "inst_zip_code": "950641077",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "CA19",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA SANTA CRUZ",
  "org_prnt_uei_num": "",
  "org_uei_num": "VXUFPE4MCZH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Cruz",
  "perf_str_addr": "1156 High Street",
  "perf_city_name": "Santa Cruz",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "950641077",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "CA19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 81889.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\"><span class=\"s1\">Machine Learning (ML) and Artificial Intelligence (AI) systems are a central part of human society. These AI/ML systems are impacting numerous decisions of our society and shape our behavior. These&nbsp;</span>societal implications are as a diverse as who we interact with online, what we shop, the information we see, credit decisions, how we spend money, and even medical decisions. As these AI/ML systems become more and more complex, it is critical to ensure that they are trustworthy. We need to be able to measure these systems critically and ensure that they behave how we want. From a scientific standpoint, we need quality metrics and measurements to evaluate AI/ML systems. These metrics are routinely used while \"tuning\" and deploying AI/ML systems.</p>\n<p class=\"p2\"><span class=\"s1\">&nbsp;</span></p>\n<p class=\"p1\"><span class=\"s1\">This project is on building mathematical foundations to understand these AI/ML systems, and focuses on how to measure their behavior. We discover that commonly used metrics for evaluating AI/ML systems are fundamentally flawed. Based on mathematical principles, we show how these metrics miss some key limitations of existing AI/ML systems. Our research leads us to new kinds of measurements that avoid these problems. W</span>ith these new measurements, we show that many existing AI/ML algorithms perform quite poorly. This questions the common wisdom on the efficacy of these algorithms.</p>\n<p class=\"p1\"><span class=\"s1\">We believe that our research will lead to more trustworthy AI/ML. Our new metrics will guide scientists and engineers to develop more accurate AI/ML systems.</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/01/2024<br>\nModified by: C Sesh&nbsp;Seshadhri</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nMachine Learning (ML) and Artificial Intelligence (AI) systems are a central part of human society. These AI/ML systems are impacting numerous decisions of our society and shape our behavior. Thesesocietal implications are as a diverse as who we interact with online, what we shop, the information we see, credit decisions, how we spend money, and even medical decisions. As these AI/ML systems become more and more complex, it is critical to ensure that they are trustworthy. We need to be able to measure these systems critically and ensure that they behave how we want. From a scientific standpoint, we need quality metrics and measurements to evaluate AI/ML systems. These metrics are routinely used while \"tuning\" and deploying AI/ML systems.\n\n\n\n\n\nThis project is on building mathematical foundations to understand these AI/ML systems, and focuses on how to measure their behavior. We discover that commonly used metrics for evaluating AI/ML systems are fundamentally flawed. Based on mathematical principles, we show how these metrics miss some key limitations of existing AI/ML systems. Our research leads us to new kinds of measurements that avoid these problems. With these new measurements, we show that many existing AI/ML algorithms perform quite poorly. This questions the common wisdom on the efficacy of these algorithms.\n\n\nWe believe that our research will lead to more trustworthy AI/ML. Our new metrics will guide scientists and engineers to develop more accurate AI/ML systems.\n\n\n\t\t\t\t\tLast Modified: 02/01/2024\n\n\t\t\t\t\tSubmitted by: C SeshSeshadhri\n"
 }
}