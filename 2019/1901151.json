{
 "awd_id": "1901151",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Medium: Collaborative Research: Charting a Research Agenda in Artificial Intelligence-Mediated Communication",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 800098.0,
 "awd_amount": 800098.0,
 "awd_min_amd_letter_date": "2019-08-16",
 "awd_max_amd_letter_date": "2022-08-17",
 "awd_abstract_narration": "Artificial Intelligence (AI) algorithms are increasingly augmenting interpersonal communication. What used to be Computer-Mediated Communication (CMC) increasingly involves AI-Mediated Communication (AI-MC): interpersonal communication not simply transmitted by technology but augmented --- or even generated --- by algorithms to achieve specific outcomes. While some simple forms of AI-MC are already prevalent, recent advances in Natural Language Processing provide new directions for augmenting communication online by, for example, modifying texts to include more formal language or enhancing resumes to make them more professional. The advances are not limited to text: increasingly, photos and videos can be automatically manipulated with AI, leading to deep fakes, in which people are shown to act or behave in ways that they never did. Indeed, if a communication is mediated, AI can potentially modify, augment, or even generate the message. AI-MC is therefore likely to have a profound effect on how we communicate, greatly complicating our understanding of technology-mediated human interactions. The project will inform the development of systems that implement AI-mediated communication in a socially desirable and ethically responsible manner.                                        \r\n\r\nThe technical objectives of this project are to develop a framework that charts how AI-MC will impact cyber-human systems research and inform the design of AI-MC technologies. The project will provide some of the first investigations in key areas of AI-MC: 1) the design and perception of AI-MC systems; 2) the potential impact of AI-MC on communication dynamics; 3) the impact of AI-MC on social-psychological dynamics of online self-presentation, with a focus on impression formation and trust, including malicious contexts; and 4) understanding ethical concerns and opportunities around issues like bias, manipulation, and transparency in AI-MC technologies. These objectives will be accomplished through a series of novel empirical studies employing approaches including computational, behavioral, and qualitative methods. These activities will include online and lab experiments that examine behavioral processes and outcomes associated with various forms of AI-MC, the design and development of an AI-MC research platform, as well as a qualitative study of developers, engineers, and designers working with AI-MC systems. In addition, this project will build on the public attention and intrigue around AI to offer design and technology workshops to K-12 students in New York City public schools, using AI-MC to connect the ideas of AI to technologies students use in their everyday lives.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mor",
   "pi_last_name": "Naaman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mor Naaman",
   "pi_email_addr": "mor.naaman@cornell.edu",
   "nsf_id": "000515060",
   "pi_start_date": "2019-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Malte",
   "pi_last_name": "Jung",
   "pi_mid_init": "F",
   "pi_sufx_name": "",
   "pi_full_name": "Malte F Jung",
   "pi_email_addr": "mfj28@cornell.edu",
   "nsf_id": "000654925",
   "pi_start_date": "2019-08-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Karen",
   "pi_last_name": "Levy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Karen Levy",
   "pi_email_addr": "karen.levy@cornell.edu",
   "nsf_id": "000745185",
   "pi_start_date": "2019-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell Tech",
  "perf_str_addr": "2 West Loop Road",
  "perf_city_name": "NEW YORK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100441501",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NY12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 525000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 102044.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 173054.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-2e1ba372-7fff-e479-9637-25de118f61f4\"> </span></p>\r\n<p dir=\"ltr\"><span>With this project, the PIs defined and introduced the field of study of AI-Mediated Communication (AI-MC), interpersonal communication are not simply transmitted by technology but augmented---or even generated---by algorithms to achieve specific communicative or relational outcomes.&nbsp;</span></p>\r\n<p>&nbsp;</p>\r\n<p dir=\"ltr\"><span>This research project has advanced our understanding on two core effects of AI-MC: communicators&rsquo; production, consumption and evaluation of content, and communicators&rsquo; perceptions and evaluations of self and others when AI is a part of a communication process.&nbsp;</span></p>\r\n<p>&nbsp;</p>\r\n<p dir=\"ltr\"><span>The research provided robust evidence that communicators have implicit bias toward AI. We show that people believe that AI technology is more beneficial and more helpful for others than for themselves. Furthermore, our research showed that receivers of communication reduce their evaluations of others when they suspect the others of using AI. We demonstrated this effect in multiple settings including chat, self-presentation, online dating, and public health. The project&rsquo;s research also showed that people have specific heuristics when they try to detect AI-written text, but they are often wrong, and can be easily misled by AI which can create communications that are &ldquo;more human than human&rdquo;. More recent research on the project investigated and demonstrated potential harms to different groups resulting from such evaluations and suspicion, showing, for example, that some demographic groups may be more readily suspected than others of using AI when evaluated for a job.</span></p>\r\n<p>&nbsp;</p>\r\n<p dir=\"ltr\"><span>Looking at content creation and interpersonal impressions, the research in this project showed that writing with AI suggestions (like autocomplete and smart replies) can impact language, content, and even shift attitudes of the writers. For example, work on this project was first to demonstrate that writing with AI suggestions (smart replies) results in the use of more positive language. Perhaps most troubling, this project&rsquo;s research had shown that when writing about important societal issues, biased AI-driven autocomplete suggestions can shift not only what people write about, but also their attitudes toward these issues&mdash;which shifts in the suggestion of the AI bias.&nbsp;</span></p>\r\n<p>&nbsp;</p>\r\n<p dir=\"ltr\"><span>The project started in 2019, well before the wide-scale introduction of Large Language Models (and three years before the launch of ChatGPT). Since then, the relevance of the work and its findings to our society and tech landscape has become increasingly clear. The impact on the academic world has been significant: since 2020, the term &ldquo;AI-Mediated Communication&rdquo;, coined in this work, has been used in over 900 scholarly publications (almost half of those were published in 2024 alone), with the publications produced in this project collectively gathering thousands of citations in that period.</span></p>\r\n<p>&nbsp;</p>\r\n<p dir=\"ltr\"><span>The project also had an impact on policy and on industry. The work on the potential of AI autocomplete to shift attitudes was featured in a US Senate Committee on the Judiciary hearing (Subcommittee on Privacy, Technology, And The Law) on Oversight of A.I.: Rules for Artificial Intelligence (March 26, 2023). The work was cited in multiple policy reports in the US and abroad. The work in this project had been widely reported and covered, and was featured in multiple venues including the Wall Street Journal. The work has been presented at multiple organizations, including research and product groups that are working on relevant technologies, including at Microsoft, Slack (Salesforce), LinkedIn (Microsoft), Google, Invesco, BetterUp, Miro, GenRe and others. </span></p>\r\n<div><span><br /></span></div>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/22/2025<br>\nModified by: Mor&nbsp;Naaman</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \r\n\n\nWith this project, the PIs defined and introduced the field of study of AI-Mediated Communication (AI-MC), interpersonal communication are not simply transmitted by technology but augmented---or even generated---by algorithms to achieve specific communicative or relational outcomes.\r\n\n\n\r\n\n\nThis research project has advanced our understanding on two core effects of AI-MC: communicators production, consumption and evaluation of content, and communicators perceptions and evaluations of self and others when AI is a part of a communication process.\r\n\n\n\r\n\n\nThe research provided robust evidence that communicators have implicit bias toward AI. We show that people believe that AI technology is more beneficial and more helpful for others than for themselves. Furthermore, our research showed that receivers of communication reduce their evaluations of others when they suspect the others of using AI. We demonstrated this effect in multiple settings including chat, self-presentation, online dating, and public health. The projects research also showed that people have specific heuristics when they try to detect AI-written text, but they are often wrong, and can be easily misled by AI which can create communications that are more human than human. More recent research on the project investigated and demonstrated potential harms to different groups resulting from such evaluations and suspicion, showing, for example, that some demographic groups may be more readily suspected than others of using AI when evaluated for a job.\r\n\n\n\r\n\n\nLooking at content creation and interpersonal impressions, the research in this project showed that writing with AI suggestions (like autocomplete and smart replies) can impact language, content, and even shift attitudes of the writers. For example, work on this project was first to demonstrate that writing with AI suggestions (smart replies) results in the use of more positive language. Perhaps most troubling, this projects research had shown that when writing about important societal issues, biased AI-driven autocomplete suggestions can shift not only what people write about, but also their attitudes toward these issueswhich shifts in the suggestion of the AI bias.\r\n\n\n\r\n\n\nThe project started in 2019, well before the wide-scale introduction of Large Language Models (and three years before the launch of ChatGPT). Since then, the relevance of the work and its findings to our society and tech landscape has become increasingly clear. The impact on the academic world has been significant: since 2020, the term AI-Mediated Communication, coined in this work, has been used in over 900 scholarly publications (almost half of those were published in 2024 alone), with the publications produced in this project collectively gathering thousands of citations in that period.\r\n\n\n\r\n\n\nThe project also had an impact on policy and on industry. The work on the potential of AI autocomplete to shift attitudes was featured in a US Senate Committee on the Judiciary hearing (Subcommittee on Privacy, Technology, And The Law) on Oversight of A.I.: Rules for Artificial Intelligence (March 26, 2023). The work was cited in multiple policy reports in the US and abroad. The work in this project had been widely reported and covered, and was featured in multiple venues including the Wall Street Journal. The work has been presented at multiple organizations, including research and product groups that are working on relevant technologies, including at Microsoft, Slack (Salesforce), LinkedIn (Microsoft), Google, Invesco, BetterUp, Miro, GenRe and others. \r\n\n\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 01/22/2025\n\n\t\t\t\t\tSubmitted by: MorNaaman\n"
 }
}