{
 "awd_id": "1913911",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Integration Of Anatomical Hydrogel Phantoms With Augmented Reality And Deep Learning To Enable Automated Independent Surgical Training",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2019-06-01",
 "awd_exp_date": "2020-11-30",
 "tot_intn_awd_amt": 224964.0,
 "awd_amount": 224964.0,
 "awd_min_amd_letter_date": "2019-06-18",
 "awd_max_amd_letter_date": "2019-06-18",
 "awd_abstract_narration": "This SBIR Phase 1 project will develop novel technology to more efficiently train surgeons and reduce the risk to patients in the operating room. Current surgical education is inadequate, and as a result inexperienced surgeons inevitably end up operating on live patients during their training. The proposed work will be performed outside of the operating room and allow them to train in a simulated, educational environment on non-patient specific models. This work carries enormous potential for public benefit as it seeks to reduce surgical error and increase the health and safety of all patients undergoing surgery. The proposed work will integrate technology with surgical simulation in an unprecedented manner, combining educational hardware/software packages with physical anatomical models to create an immersive, highly effective training experience. The project carries high potential to broadly improve training for all medical fields, as the educational hardware/software packages developed can be used to teach any complex task or procedure. The commercialization of the prototype developed in the project will generate substantial income for those involved in its production, sale, and usage; additionally, the project will improve both the well-being of the public as well as the educational and training of the healthcare industry. \r\n\r\nThe project will develop a prototype hardware and software training system that delivers educational content in real time, guiding a training surgeon through a simulated surgical procedure. The developed prototype will visually recognize state changes and objects in three-dimensional space, using these cues to trigger prompts and deliver instructions, guidance, and medical curricula in a timely manner as the surgeon interacts with a non-patient specific physical models; this product will require the integration of physical models with software and augmented reality technology on a level unparalleled on the market today. The project will directly test and validate the assembled hardware and programmed software and apply statistical testing to develop an initial product that performs within acceptable parameters. The proposed work will yield an assembled prototype, a combination of hardware and software that can guide a surgeon through a complete training procedure performed on a synthetic anatomical model. This prototype will have undergone technical validation and an initial round of educational validation, in preparation for the broader clinical and educational validation planned in Phase 2.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Steven",
   "pi_last_name": "Griffith",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Steven H Griffith",
   "pi_email_addr": "steve@griffithconsult.com",
   "nsf_id": "000781131",
   "pi_start_date": "2019-06-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Simulated Inanimate Models LLC",
  "inst_street_address": "160 OFFICE PARK WAY STE 1",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSFORD",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "8453233412",
  "inst_zip_code": "145341759",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "SIMULATED INANIMATE MODELS LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "DJANDTMJDD36"
 },
 "perf_inst": {
  "perf_inst_name": "Simulated Inanimate Models LLC",
  "perf_str_addr": "160 Office Park Way",
  "perf_city_name": "Pittsford",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "145341700",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5371",
   "pgm_ref_txt": "SMALL BUSINESS PHASE I"
  },
  {
   "pgm_ref_code": "8031",
   "pgm_ref_txt": "Education Products"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 224964.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this Phase I SBIR project, we developed an augmented reality (AR) surgical training system that works in conjunction with our hydrogel kidney phantom to teach&nbsp; surgical technique for performing a partial nephrectomy procedure. We designed and tested a hardware and software platform that detects user progress during a simulated procedure and provides appropriately timed curricular content. The hardware consists of an augmented reality headset and wired computer that permits delivery of curricula in a hands free, heads up display and provides a continuous recorded video feed througha simulated endoscopic camera for determining users progress. Two separate software elements were developed; 1) to detect user state through the use of machine learninig and 2) to display appropriate instructional content based the current state of the procedure. A custom deep learning architecture was deployed in real-time to analyze the video feed and determine user progress. A gaming engine was implemented to provide the user with appropriately timed multimedia instructional prompts through the heads up display based on output from the machine learning model.</p>\n<p>We focused on a critical step of the partial nephrectomy procedure to provide proof of concept and demonstrate a minimum viable product for our augmented reality training system. The machine learning model was trained to determine application of a bulldog clamp to a blood vessel in order to advance curricular content. In our simulation prototype, the participating user must place the surgical clamp correctly on the artery and not the renal vein or ureter. Instead of simple binary classification between success and no success, the computer determined one of four states based on the object clamped (off or no-clamp, and clamp on vein, artery, or ureter) to simulate real circumstances, provide appropriate instructions and track errors committed. Using machine learning to determine users progress allows the system to provide accurate real-time instruction and also permits objective assessment of performance for grading.</p>\n<p>The output from the machine learning model is delivered to a secondary software element called Workflow Automation (WA). The WA uses the Unity gaming engine and provides decision tree processing that decides which instruction to display to the user. For our generalized system, each type of procedure has a unique Surgical Training Scenario (STS) that is built with specific curricular content for the particular training scenario. Based on the machine learning output, the WA displays appropriate User Interface (UI) prompts and training material through our custom AR glasses. The Workflow Automation software effectively provides a simple approach for non-technical users to generate their own procedures and have full access to its technical capabilities.</p>\n<p>We initially attempted to use off the shelf augmented reality headset to run our educational system. We ran into several issues including cumbersome USB driver, limited field of view and insufficient computing power. After looking extensively at what was available on the market, we elected to design our own headset with specifications necessary to perform machine learning in real-time. Using development boards for the display and computation electronics, we tested several component systems and ultimately selected the 1080p (Full HD) optical engine, with an Android System On Module (SoM) that runs the presentation layer. We used a desktop computer for the machine learning Hardware Accelerator for the focus group. The real-time inference model state is transmitted to the Android platform to display appropriate curricular content presented by the WA software.</p>\n<p>Th provide objective evidence that our training system is effective, we employed a focus group of 16 surgeons, surgical sales reps and surgical technicians. A photo of our augemnted reality training system the day of the focus group is shown in the image captioned&nbsp;Focus Group Training Hardware Setup.</p>\n<p>All of this culminated in a focus group test of an alpha prototype that received excellent rating. See table 1 below:</p>\n<p><strong>Table 1: Survey Questions and Results from Customer Focus Group</strong></p>\n<table class=\"GridTable2Accent5\" border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"684\">\n<tbody>\n<tr>\n<td width=\"480\">\n<p><strong>Survey   Question</strong></p>\n</td>\n<td colspan=\"2\" width=\"204\">\n<p><strong>Agree   or Strongly Agree (%)</strong></p>\n</td>\n</tr>\n<tr>\n<td width=\"480\" valign=\"top\">&nbsp;</td>\n<td width=\"96\">\n<p><strong>Intended Users</strong></p>\n</td>\n<td width=\"108\">\n<p><strong>All Users</strong></p>\n</td>\n</tr>\n<tr>\n<td width=\"480\">\n<p><em>This   system is an ideal teaching tool for the procedure or device function.</em></p>\n</td>\n<td width=\"96\">\n<p>9/11 (82%)</p>\n</td>\n<td width=\"108\">\n<p>12/15 (80%)</p>\n</td>\n</tr>\n<tr>\n<td width=\"480\">\n<p><em>This   delivered prompts were helpful for guidance through the procedure.</em></p>\n</td>\n<td width=\"96\">\n<p>8/10 (80%)</p>\n</td>\n<td width=\"108\">\n<p>12/15 (80%)</p>\n</td>\n</tr>\n<tr>\n<td width=\"480\">\n<p><em>Practice   with this system would be more effective than practice with a physical   phantom alone.</em></p>\n</td>\n<td width=\"96\">\n<p>10/11 (91%)</p>\n</td>\n<td width=\"108\">\n<p>13/16 (81%)</p>\n</td>\n</tr>\n<tr>\n<td width=\"480\">\n<p><em>Practice   with this system would be more effective than practice with a VR simulator   alone.</em></p>\n</td>\n<td width=\"96\">\n<p>11/11 (100%)</p>\n</td>\n<td width=\"108\">\n<p>15/15 (100%)</p>\n</td>\n</tr>\n<tr>\n<td width=\"480\">\n<p><em>The   system mimicked an expert surgeon standing beside the user and speaking   instructions.</em></p>\n</td>\n<td width=\"96\">\n<p>4/10 (40%)</p>\n</td>\n<td width=\"108\">\n<p>7/14 (50%)</p>\n</td>\n</tr>\n<tr>\n<td width=\"480\">\n<p><em>The   real time delivery of medical curricula improves the educational value of   this system.</em></p>\n</td>\n<td width=\"96\">\n<p>9/11 (82%)</p>\n</td>\n<td width=\"108\">\n<p>13/16 (81%)</p>\n</td>\n</tr>\n<tr>\n<td width=\"480\">\n<p><em>The   system would be a preferred educational tool for practicing a new device or   procedure.</em></p>\n</td>\n<td width=\"96\">\n<p>10/11 (91%)</p>\n</td>\n<td width=\"108\">\n<p>15/16 (94%)</p>\n</td>\n</tr>\n<tr>\n<td width=\"480\">\n<p><em>The   system would be valuable for training surgeons at a hands-on workshop.</em></p>\n</td>\n<td width=\"96\">\n<p>10/10 (100%)</p>\n</td>\n<td width=\"108\">\n<p>16/16 (100%)</p>\n</td>\n</tr>\n<tr>\n<td width=\"480\">\n<p><em>The   system has high educational value for surgical training.</em></p>\n</td>\n<td width=\"96\">\n<p>10/10 (100%)</p>\n</td>\n<td width=\"108\">\n<p>16/16 (100%)</p>\n</td>\n</tr>\n</tbody>\n</table>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/31/2020<br>\n\t\t\t\t\tModified by: Steven&nbsp;H&nbsp;Griffith</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609291148608_ARTrainingSystemSetup--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609291148608_ARTrainingSystemSetup--rgov-800width.jpg\" title=\"Focus Group Training Hardware Setup\"><img src=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609291148608_ARTrainingSystemSetup--rgov-66x44.jpg\" alt=\"Focus Group Training Hardware Setup\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This photo shows ESIST (Educational System For Instructorless Training ) components that were used  during our surgical focus group. The ESIST AR HEadset is shown in the lower left hand side of the image.</div>\n<div class=\"imageCredit\">Simulated Inanimate Models LLC</div>\n<div class=\"imageSubmitted\">Steven&nbsp;H&nbsp;Griffith</div>\n<div class=\"imageTitle\">Focus Group Training Hardware Setup</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609291633160_SurgeonUsingAugmentedRealityTrainingSystem--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609291633160_SurgeonUsingAugmentedRealityTrainingSystem--rgov-800width.jpg\" title=\"Surgeon Using Augmented Reality Training System\"><img src=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609291633160_SurgeonUsingAugmentedRealityTrainingSystem--rgov-66x44.jpg\" alt=\"Surgeon Using Augmented Reality Training System\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Surgeon in focus group placing a clamp on the renal artery, as part of a partial nephrectomy procedure. Surgeon is using our  ESIST (Educational System For Instructorless Training ) AR Headset developed during this SBIR program..</div>\n<div class=\"imageCredit\">Simulated Inanimate Models LLC</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Steven&nbsp;H&nbsp;Griffith</div>\n<div class=\"imageTitle\">Surgeon Using Augmented Reality Training System</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609293454126_Surgicalfocusgroupparticipantfillingoutsurvey--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609293454126_Surgicalfocusgroupparticipantfillingoutsurvey--rgov-800width.jpg\" title=\"Surgical focus group participant filling out focus group survey\"><img src=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609293454126_Surgicalfocusgroupparticipantfillingoutsurvey--rgov-66x44.jpg\" alt=\"Surgical focus group participant filling out focus group survey\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Surgical focus group participant shown with AR headset and laparoscopic training simulator containing simulated kidney phantom filling out survey.</div>\n<div class=\"imageCredit\">Simulated Inanimate Models LLC</div>\n<div class=\"imageSubmitted\">Steven&nbsp;H&nbsp;Griffith</div>\n<div class=\"imageTitle\">Surgical focus group participant filling out focus group survey</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609294429309_ClampPlacedOnVein--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609294429309_ClampPlacedOnVein--rgov-800width.jpg\" title=\"Clamp Incorrectly Place on Vein\"><img src=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609294429309_ClampPlacedOnVein--rgov-66x44.jpg\" alt=\"Clamp Incorrectly Place on Vein\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">In this image, the clamp is deliberately incorrectly placed on the renal vein. The prompt shown as seen by the trainee through the ESIST augmented reality headset instructs the trainee that the clamp is incorrectly placed on the renal vein, and to move the clamp to the renal artery.</div>\n<div class=\"imageCredit\">Simulated Inanimate Models LLC</div>\n<div class=\"imageSubmitted\">Steven&nbsp;H&nbsp;Griffith</div>\n<div class=\"imageTitle\">Clamp Incorrectly Place on Vein</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609295245054_Placeclamponrenalartery--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609295245054_Placeclamponrenalartery--rgov-800width.jpg\" title=\"Place Clamp On Renal Artery\"><img src=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609295245054_Placeclamponrenalartery--rgov-66x44.jpg\" alt=\"Place Clamp On Renal Artery\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">In this image, the ESIST system prompts the user to place the clamp on the renal vein. This simulated endoscopic camera image is classified by the machine learning algorithm to be one of four classes - no clamp, clamp on vein, artery or uter.</div>\n<div class=\"imageCredit\">Simulated Inanimate Models LLC</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Steven&nbsp;H&nbsp;Griffith</div>\n<div class=\"imageTitle\">Place Clamp On Renal Artery</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609296003703_FinalGradeARHeadsetOverlay--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609296003703_FinalGradeARHeadsetOverlay--rgov-800width.jpg\" title=\"Final Grade and Statistics for Surgical Training Scenario\"><img src=\"/por/images/Reports/POR/2020/1913911/1913911_10612001_1609296003703_FinalGradeARHeadsetOverlay--rgov-66x44.jpg\" alt=\"Final Grade and Statistics for Surgical Training Scenario\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">In this image, the ESIST system displays the trainees final grade. Note that the total elapsed time is displayed and the grade is 75%. Also note that points (25) were deducted because the student incorrectly placed the clamp on the renal vein instead of the renal artery.</div>\n<div class=\"imageCredit\">Simulated Inanimate Models LLC</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Steven&nbsp;H&nbsp;Griffith</div>\n<div class=\"imageTitle\">Final Grade and Statistics for Surgical Training Scenario</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n      In this Phase I SBIR project, we developed an augmented reality (AR) surgical training system that works in conjunction with our hydrogel kidney phantom to teach  surgical technique for performing a partial nephrectomy procedure. We designed and tested a hardware and software platform that detects user progress during a simulated procedure and provides appropriately timed curricular content. The hardware consists of an augmented reality headset and wired computer that permits delivery of curricula in a hands free, heads up display and provides a continuous recorded video feed througha simulated endoscopic camera for determining users progress. Two separate software elements were developed; 1) to detect user state through the use of machine learninig and 2) to display appropriate instructional content based the current state of the procedure. A custom deep learning architecture was deployed in real-time to analyze the video feed and determine user progress. A gaming engine was implemented to provide the user with appropriately timed multimedia instructional prompts through the heads up display based on output from the machine learning model.\n\nWe focused on a critical step of the partial nephrectomy procedure to provide proof of concept and demonstrate a minimum viable product for our augmented reality training system. The machine learning model was trained to determine application of a bulldog clamp to a blood vessel in order to advance curricular content. In our simulation prototype, the participating user must place the surgical clamp correctly on the artery and not the renal vein or ureter. Instead of simple binary classification between success and no success, the computer determined one of four states based on the object clamped (off or no-clamp, and clamp on vein, artery, or ureter) to simulate real circumstances, provide appropriate instructions and track errors committed. Using machine learning to determine users progress allows the system to provide accurate real-time instruction and also permits objective assessment of performance for grading.\n\nThe output from the machine learning model is delivered to a secondary software element called Workflow Automation (WA). The WA uses the Unity gaming engine and provides decision tree processing that decides which instruction to display to the user. For our generalized system, each type of procedure has a unique Surgical Training Scenario (STS) that is built with specific curricular content for the particular training scenario. Based on the machine learning output, the WA displays appropriate User Interface (UI) prompts and training material through our custom AR glasses. The Workflow Automation software effectively provides a simple approach for non-technical users to generate their own procedures and have full access to its technical capabilities.\n\nWe initially attempted to use off the shelf augmented reality headset to run our educational system. We ran into several issues including cumbersome USB driver, limited field of view and insufficient computing power. After looking extensively at what was available on the market, we elected to design our own headset with specifications necessary to perform machine learning in real-time. Using development boards for the display and computation electronics, we tested several component systems and ultimately selected the 1080p (Full HD) optical engine, with an Android System On Module (SoM) that runs the presentation layer. We used a desktop computer for the machine learning Hardware Accelerator for the focus group. The real-time inference model state is transmitted to the Android platform to display appropriate curricular content presented by the WA software.\n\nTh provide objective evidence that our training system is effective, we employed a focus group of 16 surgeons, surgical sales reps and surgical technicians. A photo of our augemnted reality training system the day of the focus group is shown in the image captioned Focus Group Training Hardware Setup.\n\nAll of this culminated in a focus group test of an alpha prototype that received excellent rating. See table 1 below:\n\nTable 1: Survey Questions and Results from Customer Focus Group\n\n\n\n\n\nSurvey   Question\n\n\n\nAgree   or Strongly Agree (%)\n\n\n\n \n\n\nIntended Users\n\n\n\nAll Users\n\n\n\n\n\nThis   system is an ideal teaching tool for the procedure or device function.\n\n\n\n9/11 (82%)\n\n\n\n12/15 (80%)\n\n\n\n\n\nThis   delivered prompts were helpful for guidance through the procedure.\n\n\n\n8/10 (80%)\n\n\n\n12/15 (80%)\n\n\n\n\n\nPractice   with this system would be more effective than practice with a physical   phantom alone.\n\n\n\n10/11 (91%)\n\n\n\n13/16 (81%)\n\n\n\n\n\nPractice   with this system would be more effective than practice with a VR simulator   alone.\n\n\n\n11/11 (100%)\n\n\n\n15/15 (100%)\n\n\n\n\n\nThe   system mimicked an expert surgeon standing beside the user and speaking   instructions.\n\n\n\n4/10 (40%)\n\n\n\n7/14 (50%)\n\n\n\n\n\nThe   real time delivery of medical curricula improves the educational value of   this system.\n\n\n\n9/11 (82%)\n\n\n\n13/16 (81%)\n\n\n\n\n\nThe   system would be a preferred educational tool for practicing a new device or   procedure.\n\n\n\n10/11 (91%)\n\n\n\n15/16 (94%)\n\n\n\n\n\nThe   system would be valuable for training surgeons at a hands-on workshop.\n\n\n\n10/10 (100%)\n\n\n\n16/16 (100%)\n\n\n\n\n\nThe   system has high educational value for surgical training.\n\n\n\n10/10 (100%)\n\n\n\n16/16 (100%)\n\n\n\n\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/31/2020\n\n\t\t\t\t\tSubmitted by: Steven H Griffith"
 }
}