{
 "awd_id": "1909816",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Non-parametric Machine Learning in the Age of Deep and High-Dimensional Models",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 449915.0,
 "awd_amount": 449915.0,
 "awd_min_amd_letter_date": "2019-08-01",
 "awd_max_amd_letter_date": "2019-08-01",
 "awd_abstract_narration": "The empirical successes of machine learning in recent years are due, in a large part, to models that are highly flexible (such as deep neural networks), which can tackle complex tasks (such as predicting whether a medical image is indicative of cancer). These models learn from large  datasets and require a lot of empirical engineering expertise. The current belief is that a better understanding of this engineering practice might help us gain insights into the relationship between the models and the sample size of the datasets. Taking inspirations for deep neural networks, the research in this project formulates broader classes of models and algorithms that learn from fewer samples but do not require complex engineering expertise. The research enables learning highly flexible models in a more rigorous and reproducible manner; consequently, the users may have greater trust in the resulting applications.\r\n\r\nMore specifically, the research in this project leverages insights from deep and high-dimensional models to develop a new class of non-parametric prediction as well as density functions. The project develops novel extensions of parametric structural sparsity constraints to the non-parametric estimation setting. By treating the multivariate prediction functions as functional generalizations of tensors, the project develops novel extensions of structural sparsity constraints designed for parametric model parameters to novel counterparts for prediction functions. The project also investigates a \"destructive learning\" approach to learning deep compositional models, which have a similar compositional form to deep neural network models. The project develops stage-wise algorithms to learn such deep compositional models, similar to boosting, by iteratively finding and destroying information in the data using well-studied shallow learning algorithms in each stage.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Pradeep",
   "pi_last_name": "Ravikumar",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Pradeep K Ravikumar",
   "pi_email_addr": "pradeepr@cs.cmu.edu",
   "nsf_id": "000553653",
   "pi_start_date": "2019-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 449915.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Modern deep neural models achieve their considerable empirical successes at the cost of a large amount of data, and compute, and finicky engineering and tuning that is empirically rather than rigorously justified. Rather than focusing on deep neural networks specifically, the research in this project looks at the broader problem of how to learn flexible models with fewer samples, and less compute, and in a more rigorous and reproducible manner, and consequently, so that users have greater trust in the resulting machine learning applications.</p>\n<p><br />The project advanced this goal by combining tools from two fields of classical non-parametric and high-dimensional statistical machine learning. The field of non-parametric learning is concerned with the question of developing such highly flexible models that \"grow\" with the data, but does so via function-analytic constraints that are swing from being either too restrictive for modern prediction problems, to too relaxed so that the number of samples they require is too large even for big data era scales of data. The field of high-dimensional learning imposes regularity constraints that enable tractable learning even when we have very few samples relative to the complexity of the problem, but impose specific parametric structures on the data that might not hold. By carefully drawing from their respective mathematical tools, we were able to develop novel classes of flexible models that moreover come with strong rigorous guarantees.&nbsp;</p>\n<p><br />The project developed two new frameworks towards the central goal of the grant of learning deep compositional models with strong theoretical guarantees. In the first, we termed \"destructive learning,\" we iteratively find and destroy information in the data using well-studied shallow learning algorithms in each stage, and combine all the destroyed information back together to yield a deep compositional model. In the second, we termed \"generalized boosting,\" we iteratively improved upon the existing feature representations via a nuanced modification of the classical boosting idea of carefully re-weighting the data to focus the attention of the learning algorithm on where the current model is the weakest. We next investigated the natural pitfalls of flexible models with respect to various responsible AI desiderata such as robustness and worst-case risk. We showed that when training very flexible models using modern responsible AI objectives, the resulting models are no better with respect to responsible AI risks than standard trained ML models. We showed that we can address this gap by moving to the space of randomized estimators, and provided a practical algorithm to learn such randomized non-parametric estimators via a reduction to a boosting game. We next addressed the question of identifiability, where we ensure that there exist a unique set of model representations given the training data. In the absence of such identifiability, which model we learn could depend on seemingly inconsequential choices such as random seeds used when training the models, with highly variable impact on test-time performance. We provided a large suite of constraints that can ensure identifiability. We next tackled the seemingly impossible question of ensuring that the extracted model representations are causal rather than merely associational. Our breakthrough results showed that this is indeed possible under certain conditions given multiple data distributions that correspond to causal interventions.</p>\n<p><br />Overall, the developments from this project have bolstered the foundations of the learning of performant flexible models with strong guarantees, which is a critical requirement for the use of such models in high-stakes settings such as healthcare and law and broader consumer-facing settings.&nbsp;</p><br>\n<p>\n Last Modified: 12/17/2023<br>\nModified by: Pradeep&nbsp;K&nbsp;Ravikumar</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nModern deep neural models achieve their considerable empirical successes at the cost of a large amount of data, and compute, and finicky engineering and tuning that is empirically rather than rigorously justified. Rather than focusing on deep neural networks specifically, the research in this project looks at the broader problem of how to learn flexible models with fewer samples, and less compute, and in a more rigorous and reproducible manner, and consequently, so that users have greater trust in the resulting machine learning applications.\n\n\n\nThe project advanced this goal by combining tools from two fields of classical non-parametric and high-dimensional statistical machine learning. The field of non-parametric learning is concerned with the question of developing such highly flexible models that \"grow\" with the data, but does so via function-analytic constraints that are swing from being either too restrictive for modern prediction problems, to too relaxed so that the number of samples they require is too large even for big data era scales of data. The field of high-dimensional learning imposes regularity constraints that enable tractable learning even when we have very few samples relative to the complexity of the problem, but impose specific parametric structures on the data that might not hold. By carefully drawing from their respective mathematical tools, we were able to develop novel classes of flexible models that moreover come with strong rigorous guarantees.\n\n\n\nThe project developed two new frameworks towards the central goal of the grant of learning deep compositional models with strong theoretical guarantees. In the first, we termed \"destructive learning,\" we iteratively find and destroy information in the data using well-studied shallow learning algorithms in each stage, and combine all the destroyed information back together to yield a deep compositional model. In the second, we termed \"generalized boosting,\" we iteratively improved upon the existing feature representations via a nuanced modification of the classical boosting idea of carefully re-weighting the data to focus the attention of the learning algorithm on where the current model is the weakest. We next investigated the natural pitfalls of flexible models with respect to various responsible AI desiderata such as robustness and worst-case risk. We showed that when training very flexible models using modern responsible AI objectives, the resulting models are no better with respect to responsible AI risks than standard trained ML models. We showed that we can address this gap by moving to the space of randomized estimators, and provided a practical algorithm to learn such randomized non-parametric estimators via a reduction to a boosting game. We next addressed the question of identifiability, where we ensure that there exist a unique set of model representations given the training data. In the absence of such identifiability, which model we learn could depend on seemingly inconsequential choices such as random seeds used when training the models, with highly variable impact on test-time performance. We provided a large suite of constraints that can ensure identifiability. We next tackled the seemingly impossible question of ensuring that the extracted model representations are causal rather than merely associational. Our breakthrough results showed that this is indeed possible under certain conditions given multiple data distributions that correspond to causal interventions.\n\n\n\nOverall, the developments from this project have bolstered the foundations of the learning of performant flexible models with strong guarantees, which is a critical requirement for the use of such models in high-stakes settings such as healthcare and law and broader consumer-facing settings.\t\t\t\t\tLast Modified: 12/17/2023\n\n\t\t\t\t\tSubmitted by: PradeepKRavikumar\n"
 }
}