{
 "awd_id": "1910299",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FET: Small: RESONANCE: Accelerating Speech/Language Processing through Collective Training using Commodity ReRAM Chips",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-07-24",
 "awd_max_amd_letter_date": "2019-07-24",
 "awd_abstract_narration": "Moving machine learning techniques from the computing cloud down to edge computing nodes closer to the user is highly desirable in many use cases that require quick responses from the collected data sets. A typical use scenario is multi-task applications where a cloud server retains well-trained large-scale models, which are deployed in edge devices based on specific local needs.  Examples include language translation or speech recognition with accents in multi-language audio conferences. However, supporting multi-task application on edge devices is challenging due to the associated high computational cost and large variety of involved models. Very little effort has been spent on the corresponding hardware design, especially for supporting multi-task speech and natural language processing (NLP) applications on edge compute devices. This research aims to design a novel computing system dedicated to such multi-task applications, particularly on accelerating speech/NLP, by combining innovations in both algorithm and hardware domains. The study benefits big data research, and industry at large by inspiring an interactive design philosophy between the designs of speech/NLP algorithms and the corresponding computing platforms. Undergraduate and graduate students involved in this research will be trained for the next-generation information technology workforce. \r\n\r\nDifferent from conventional edge computing devices that mainly focuses on balancing the workloads between the cloud and the edge devices and optimizing the communication in between, this project concentrates on how to efficiently decompose and compress the task-specific sub-models extracted from a large multi-task model in the cloud so that deployment of the edge devices meet the functionality and performance needs under the specific hardware constraint. More specifically, the algorithm-level innovations enable a decomposable speech/NLP model that always assures proper function and performance in resource-limited edge devices, while the hardware-level innovations allow these devices to efficiently support speech/NLP multi-task applications and unleash the great potential of Resistive Random Access Memory (ReRAM)-based computing platforms. During the real-time operation, the model on the edge device can be scaled-up or shrunk-down to accommodate the dynamic hardware environment and user needs. The research leads to a holistic methodology across algorithm redesign, hardware acceleration, and an integrated software/hardware co-design.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hai",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hai Li",
   "pi_email_addr": "hai.li@duke.edu",
   "nsf_id": "000538107",
   "pi_start_date": "2019-07-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yiran",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yiran Chen",
   "pi_email_addr": "yiran.chen@duke.edu",
   "nsf_id": "000575362",
   "pi_start_date": "2019-07-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "",
  "perf_city_name": "Durham,",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277054010",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "076Z",
   "pgm_ref_txt": "FET: Foundations of Emerging Technologie"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aims to expedite speech/language processing through collective training utilizing ReRAM chips. Our objective is to facilitate the deployment of large language models at the edge while satisfying functionality and performance requirements. We adopted a combined software and hardware approach. Specifically, algorithm-level innovations enable a decomposable speech/language processing model, ensuring proper function and performance on resource-limited edge devices. Concurrently, hardware-level innovations enable efficient support for speech/language processing applications on ReRAM-based computing platforms, unlocking their potential.</p>\n<p>We pursued the project through multiple approaches. Firstly, our work on far-field speaker recognition focused on developing a speaker recognition system robust to far-field channel conditions, employing advanced model training methodologies. Additionally, we designed the system for simple inference using ultra-low-power accelerators like the Intel GNA. Experimental results demonstrated a 60% reduction in parameters and over a 1.5x speedup. This work was published at the 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).</p>\n<p>At the architectural level, we started with ReRAM accelerator design and introduced AccPar. AccPar aims to enable a principled and systematic approach to determining tensor partition among heterogeneous accelerator arrays. Compared to prior empirical or unsystematic methods, AccPar considers the complete tensor partition space, unveiling previously unknown parallelism configurations. The enhanced flexibility of tensor partitioning allows for the flexible distribution of computations among accelerators with varying performances. A conference paper detailing AccPar has been published and presented in the Proceedings of the IEEE International Symposium on High-Performance Computer Architecture (HPCA&rsquo;20).</p>\n<p>As Transformers have emerged as popular neural network models for language processing applications, their scaled dot-product attention mechanism poses inference performance bottlenecks. Addressing this challenge, we proposed ReTransformer in our work published in ICCAD 2020&mdash;an architecture leveraging ReRAM-based Processing-in-Memory (PIM) to accelerate the scaled dot-product attention of Transformers. Due to the inherent variations, we also analyzed the nonidealities of ReRAM devices on the model performance.</p>\n<p>At the circuit level, we introduced SpikeSen, the first in-sensor processing design directly processing photocurrents and computing the 1st layer of BNNs in the spike frequency domain. Our research led to journal publications in IEEE Transactions on Circuits and Systems II (TCAS-II) in 2023. Additionally, we recently completed chip design tapeout, achieving satisfactory testing results.</p>\n<p>Our research stands to benefit big data research and industry by fostering an interactive design philosophy between speech/language processing algorithm designs and corresponding computation platforms. The outcomes of this research will directly impact future language model processing and acceleration systems. Furthermore, opportunities provided by our collaborators offer versatile training for undergraduate and graduate students, serving as an ideal initial step in technology transfer.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/11/2024<br>\nModified by: Hai&nbsp;Li</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project aims to expedite speech/language processing through collective training utilizing ReRAM chips. Our objective is to facilitate the deployment of large language models at the edge while satisfying functionality and performance requirements. We adopted a combined software and hardware approach. Specifically, algorithm-level innovations enable a decomposable speech/language processing model, ensuring proper function and performance on resource-limited edge devices. Concurrently, hardware-level innovations enable efficient support for speech/language processing applications on ReRAM-based computing platforms, unlocking their potential.\n\n\nWe pursued the project through multiple approaches. Firstly, our work on far-field speaker recognition focused on developing a speaker recognition system robust to far-field channel conditions, employing advanced model training methodologies. Additionally, we designed the system for simple inference using ultra-low-power accelerators like the Intel GNA. Experimental results demonstrated a 60% reduction in parameters and over a 1.5x speedup. This work was published at the 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).\n\n\nAt the architectural level, we started with ReRAM accelerator design and introduced AccPar. AccPar aims to enable a principled and systematic approach to determining tensor partition among heterogeneous accelerator arrays. Compared to prior empirical or unsystematic methods, AccPar considers the complete tensor partition space, unveiling previously unknown parallelism configurations. The enhanced flexibility of tensor partitioning allows for the flexible distribution of computations among accelerators with varying performances. A conference paper detailing AccPar has been published and presented in the Proceedings of the IEEE International Symposium on High-Performance Computer Architecture (HPCA20).\n\n\nAs Transformers have emerged as popular neural network models for language processing applications, their scaled dot-product attention mechanism poses inference performance bottlenecks. Addressing this challenge, we proposed ReTransformer in our work published in ICCAD 2020an architecture leveraging ReRAM-based Processing-in-Memory (PIM) to accelerate the scaled dot-product attention of Transformers. Due to the inherent variations, we also analyzed the nonidealities of ReRAM devices on the model performance.\n\n\nAt the circuit level, we introduced SpikeSen, the first in-sensor processing design directly processing photocurrents and computing the 1st layer of BNNs in the spike frequency domain. Our research led to journal publications in IEEE Transactions on Circuits and Systems II (TCAS-II) in 2023. Additionally, we recently completed chip design tapeout, achieving satisfactory testing results.\n\n\nOur research stands to benefit big data research and industry by fostering an interactive design philosophy between speech/language processing algorithm designs and corresponding computation platforms. The outcomes of this research will directly impact future language model processing and acceleration systems. Furthermore, opportunities provided by our collaborators offer versatile training for undergraduate and graduate students, serving as an ideal initial step in technology transfer.\n\n\n\t\t\t\t\tLast Modified: 03/11/2024\n\n\t\t\t\t\tSubmitted by: HaiLi\n"
 }
}