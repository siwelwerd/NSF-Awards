{
 "awd_id": "1909429",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small:  Average-Case Fine-Grained Complexity",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-06-24",
 "awd_max_amd_letter_date": "2019-06-24",
 "awd_abstract_narration": "The modern world would be impossible without digital cryptography: email, electronic and ATM transactions, operations in the cloud, mobile phone calls, and many more interactions rely heavily on encryption and cryptographic protocols to ensure that the operations are performed securely and confidentially. While the commonly used cryptographic protocols are believed to be secure, their security is based on unproven (though widely believed) mathematical assumptions. If some of these assumptions were false, the protocols would be broken and secure transactions that the world relies on would be compromised. Because of this, cryptography is typically based on a variety of different believable assumptions. Nevertheless, practically all these assumptions require that P is not equal to NP, a widely believed but infamously difficult conjecture in theoretical computer science and mathematics. If complexity classes P and NP were equal, it is expected that practically all of modern cryptography would fail. A major part of this project is to investigate what types of secure cryptographic protocols are still possible, even if P=NP (an unlikely event, but it has not been ruled out). The main goal will be to develop average-case fine-grained complexity, which has many more applications beyond developing new cryptography, such as new algorithmic approaches to the Boolean satisfiability problem and the minimum circuit size problem.\r\n\r\nFine-grained complexity studies the time complexity of problems in a more fine-grained way than traditional computational complexity, seeking to classify problems into those solvable in nearly-linear, subquadratic, subcubic runtime and so on, versus those that require essentially quadratic, cubic and more runtime, under plausible assumptions. While fine-grained complexity has had huge successes and is a more practically relevant notion of complexity, it has only been developed for worst-case running time. This project will study average-case notions of fine-grained complexity, from which one can build weak forms of cryptography from alternative foundations: one-way functions, public key cryptography and more, secure against (say) O(n^5)-time bounded adversaries. For very large n, such cryptography would still be secure in practice; more importantly, one could develop cryptography even if traditional foundations failed to provide secure cryptosystems (e.g., P = NP). Among the goals of this project are improved algorithms for average-case versions of Boolean Satisfiability and other important problems, worst-case to average-case fine-grained reductions for key problems in fine-grained complexity, and development of cryptographic primitives such as public-key cryptography based on fine-grained complexity assumptions.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Virginia",
   "pi_last_name": "Williams",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Virginia V Williams",
   "pi_email_addr": "virgito@gmail.com",
   "nsf_id": "000640555",
   "pi_start_date": "2019-06-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ryan",
   "pi_last_name": "Williams",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ryan Williams",
   "pi_email_addr": "rrw@mit.edu",
   "nsf_id": "000606346",
   "pi_start_date": "2019-06-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Ave",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7927",
   "pgm_ref_txt": "COMPLEXITY & CRYPTOGRAPHY"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goals of this project were (1) to develop methods to solve important computational problems that work well on ``most'' instances (algorithms that work well in the ``average case''), and (2) to develop cryptographic protocols that can provide online security even if the traditional assumptions of modern cryptography no longer hold.<br /><br /><br />Under the first goal, the primary problem was the Boolean Satisfiability (SAT) problem. SAT is a classic computer science problem with a multitude of applications in important areas such as hardware and software verification, computational biology, and cybersecurity.&nbsp; Significant advances in SAT algorithms would excite hundreds of researchers across many disciplines. <br /><br />In practice, the SAT instances that need to be solved are not arbitrary: they are not designed by a worst-case adversary. Rather, they arise from special random distributions. This is one of the motivations for studying how quickly one can solve SAT in the average case, as opposed to the worst case. Two papers by the investigators and students provide the first average-case algorithms for SAT that are provably faster than what is known for the worst case. The algorithms refute a recent hypothesis about the complexity of SAT (the Super Strong Exponential Time Hypothesis), in the average case.<br /><br />In another line of work, deep connections have been found between the limitations of logical circuits, and SAT algorithms for circuits. These connections were strengthened by the investigators and their students, proving limitations on using restricted circuits to solve problems in the average case. Such limitations are a starting point for developing provably-secure cryptography.<br /><br /><br />The second goal of the project centered around new notions of cryptography that could be mathematically proven to be secure, even if standard assumptions about computing no longer hold. Cryptography drives the modern online world: it is required for secure communication via email, electronic commerce, chip-based credit card transactions, password based security, digital currencies and so on. However, cryptography also relies on unproven mathematical assumptions such as \"P is not equal to NP\" and many more. If these assumptions turned out to be incorrect, then the world as we know it will drastically change. It is thus important to build cryptographic primitives that rely on the soundest possible assumptions, ones which would remain plausible even if the standard assumptions are broken.<br /><br />This project took steps towards the design of cryptography from central assumptions in fine-grained complexity, a field that has been developing over the last two decades that is built on radically different assumptions from the standard ones in cryptography. To develop cryptographic protocols, it is necessary to pinpoint computational problems that require significant computation time, even if their instances are sampled from some distribution. Assumptions from fine-grained complexity, however, only promise that for certain key computational problems, there are some instances on which the problems are difficult to solve. Random instances are not promised to be hard. In fact, for some of the key problems such as SAT, it is known that when the instances are sampled at random, they can be solved faster (this was part of the outcomes of the first project goal). <br /><br />The investigators and their students provided \"worst-case to average-case reductions\" for fine-grained problems: assuming certain fine-grained problems are hard to solve in the worst case, they showed how to construct new fine-grained problems that require a lot of computation even in the average case, on random instances. These results identify suitable problems for building cryptographic primitives from fine-grained assumptions. They also demonstrated how to build a new cryptographic key-exchange protocol, assuming that certain fine-grained problems are difficult in the average case and have a few extra properties. Key exchange is essential for secure Internet communication. It allows two honest agents to communicate in the clear, and quickly agree on a secret string that is common to both of them. In addition, any malicious agent intercepting the communication between the parties must spend a noticeably longer amount of time to figure out the secret for themselves. The new key exchange from this project has weaker guarantees than standard protocols: standard assumptions in cryptography lead to protocols that require the malicious agent to spend significantly more time to decipher the secret. The security of the new protocol, however, relies on entirely new assumptions. The project shows that parts of cryptography remain viable, even if all standard cryptography assumptions fail. <br /><br />Other outcomes include further average case algorithms, surprisingly fast algorithms for variants of SAT that were previously thought to be hard, and more. Three Ph.D. students were supported by the project. One of them has started a tenure track position, another is a postdoctoral scholar, and the third is soon to graduate. Results from this project are being incorporated in lecture notes for the course on fine-grained complexity taught by the investigators. These notes are freely available on the investigators' websites.<br /><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/23/2023<br>\n\t\t\t\t\tModified by: Virginia&nbsp;V&nbsp;Williams</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goals of this project were (1) to develop methods to solve important computational problems that work well on ``most'' instances (algorithms that work well in the ``average case''), and (2) to develop cryptographic protocols that can provide online security even if the traditional assumptions of modern cryptography no longer hold.\n\n\nUnder the first goal, the primary problem was the Boolean Satisfiability (SAT) problem. SAT is a classic computer science problem with a multitude of applications in important areas such as hardware and software verification, computational biology, and cybersecurity.  Significant advances in SAT algorithms would excite hundreds of researchers across many disciplines. \n\nIn practice, the SAT instances that need to be solved are not arbitrary: they are not designed by a worst-case adversary. Rather, they arise from special random distributions. This is one of the motivations for studying how quickly one can solve SAT in the average case, as opposed to the worst case. Two papers by the investigators and students provide the first average-case algorithms for SAT that are provably faster than what is known for the worst case. The algorithms refute a recent hypothesis about the complexity of SAT (the Super Strong Exponential Time Hypothesis), in the average case.\n\nIn another line of work, deep connections have been found between the limitations of logical circuits, and SAT algorithms for circuits. These connections were strengthened by the investigators and their students, proving limitations on using restricted circuits to solve problems in the average case. Such limitations are a starting point for developing provably-secure cryptography.\n\n\nThe second goal of the project centered around new notions of cryptography that could be mathematically proven to be secure, even if standard assumptions about computing no longer hold. Cryptography drives the modern online world: it is required for secure communication via email, electronic commerce, chip-based credit card transactions, password based security, digital currencies and so on. However, cryptography also relies on unproven mathematical assumptions such as \"P is not equal to NP\" and many more. If these assumptions turned out to be incorrect, then the world as we know it will drastically change. It is thus important to build cryptographic primitives that rely on the soundest possible assumptions, ones which would remain plausible even if the standard assumptions are broken.\n\nThis project took steps towards the design of cryptography from central assumptions in fine-grained complexity, a field that has been developing over the last two decades that is built on radically different assumptions from the standard ones in cryptography. To develop cryptographic protocols, it is necessary to pinpoint computational problems that require significant computation time, even if their instances are sampled from some distribution. Assumptions from fine-grained complexity, however, only promise that for certain key computational problems, there are some instances on which the problems are difficult to solve. Random instances are not promised to be hard. In fact, for some of the key problems such as SAT, it is known that when the instances are sampled at random, they can be solved faster (this was part of the outcomes of the first project goal). \n\nThe investigators and their students provided \"worst-case to average-case reductions\" for fine-grained problems: assuming certain fine-grained problems are hard to solve in the worst case, they showed how to construct new fine-grained problems that require a lot of computation even in the average case, on random instances. These results identify suitable problems for building cryptographic primitives from fine-grained assumptions. They also demonstrated how to build a new cryptographic key-exchange protocol, assuming that certain fine-grained problems are difficult in the average case and have a few extra properties. Key exchange is essential for secure Internet communication. It allows two honest agents to communicate in the clear, and quickly agree on a secret string that is common to both of them. In addition, any malicious agent intercepting the communication between the parties must spend a noticeably longer amount of time to figure out the secret for themselves. The new key exchange from this project has weaker guarantees than standard protocols: standard assumptions in cryptography lead to protocols that require the malicious agent to spend significantly more time to decipher the secret. The security of the new protocol, however, relies on entirely new assumptions. The project shows that parts of cryptography remain viable, even if all standard cryptography assumptions fail. \n\nOther outcomes include further average case algorithms, surprisingly fast algorithms for variants of SAT that were previously thought to be hard, and more. Three Ph.D. students were supported by the project. One of them has started a tenure track position, another is a postdoctoral scholar, and the third is soon to graduate. Results from this project are being incorporated in lecture notes for the course on fine-grained complexity taught by the investigators. These notes are freely available on the investigators' websites.\n\n\n\n\n\t\t\t\t\tLast Modified: 06/23/2023\n\n\t\t\t\t\tSubmitted by: Virginia V Williams"
 }
}