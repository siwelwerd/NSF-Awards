{
 "awd_id": "1926465",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Gated Synaptic Memory Devices with Adaptive Short-Term States for Neuromorphic Computing",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": "7032928103",
 "po_email": "rlukasze@nsf.gov",
 "po_sign_block_name": "Ale Lukaszew",
 "awd_eff_date": "2019-09-15",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 348000.0,
 "awd_min_amd_letter_date": "2019-07-31",
 "awd_max_amd_letter_date": "2022-04-25",
 "awd_abstract_narration": "Artificial Intelligence (AI) techniques for big data analytics are becoming very important. However, AI software algorithms are computation resource intensive which imposes limitations on their practical applications as the currently available data processors are not well-suited for these needs. For example, training algorithms for AI can take several hours to days for completing the training process. Additionally, some of the other challenges, such as the requirement for huge training datasets, lack of real-time training and multi-modal data fusion capabilities, and limitations for the system to make decisions reliably with limited input data are well-recognized. Many of these problems can be addressed if brain-inspired neuromorphic data processors can be developed. However, it is a non-trivial task because of two primary reasons. First, the cortical circuits in brain is not fully understood and still is a topic of research in the neuroscience community. Second, artificial neuromimetic components for integration in brain-inspired architectures are not yet developed to match the computational efficiency and diversity of biological-brains.  It has been identified from current understanding of cortical circuits in biological-brain that a synapse which is a reconfigurable connection between neurons, play pivotal a role in learning and memory formation. The focus of this project is to develop artificial nanoelectronic synaptic devices that can be integrated in neuromorphic architectures. The project provides significant opportunities for training graduate and undergraduate students in understanding and developing neuromorphic processors for AI. A new course on \"Neuromorphic Computers for AI\" at the graduate level will be developed. Efforts will be made to increase participation of underrepresented groups in STEM by leveraging the program on \"Nurturing Educational Readiness and Development from the Start (NERDS)\" and through local Association for Computing Machinery (ACM) chapter.  \r\n\r\nThe nanoelectronic synaptic device will be developed by exploiting time-dependent trap dynamics in oxides in conjunction with the transport of intrinsic or extrinsic dopants in a novel gated-Synaptic Memory Device (gated-SMD) configuration. These dynamics will result in an analog potentiation (increase in conductance) and depression (decrease in conductance) as a function of the temporal sequences of voltage-pulses on gate that can be explored for implementing bio-inspired learning algorithms. The objective of the proposed research will be achieved by executing the following specific aims: (1) fabricating gated-SMDs and studying the device characteristics, including potentiation and depression of resistive states on different time-scales as a function of gate-bias and modeling it; (2) understanding the scalability of these devices by large-scale layout designs and comparing and benchmarking the cell sizes against other candidate memory technologies; and (3) developing  novel real-time learning algorithms and implementing bio-inspired learning schemes using gated-SMDs for neuromorphic architectures. The intellectual significance of the proposed research lies in knowledge base and a device platform to provide a solution of nanoelectronic synapses for neuromorphic circuits. If successful, the project will yield the following outcomes: (i) a fundamental understanding of gated-SMDs and device models benchmarked against experimental data, (ii) strategies to control potentiation and depression rates of resistive states in gated-SMD by engineering the device parameters, (iii) real-time learning algorithms tailored for gated-SMDs, and (iv) large-scale integration routes for gated-SMDs and scalability data. The achievement of these outcomes will have transformative impact on developing neuromorphic data processors for AI.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rashmi",
   "pi_last_name": "Jha",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rashmi Jha",
   "pi_email_addr": "jhari@ucmail.uc.edu",
   "nsf_id": "000505218",
   "pi_start_date": "2019-07-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Cincinnati Main Campus",
  "inst_street_address": "2600 CLIFTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CINCINNATI",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "5135564358",
  "inst_zip_code": "452202872",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "OH01",
  "org_lgl_bus_name": "CINCINNATI UNIV OF",
  "org_prnt_uei_num": "DZ4YCZ3QSPR5",
  "org_uei_num": "DZ4YCZ3QSPR5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Cincinnati Main Campus",
  "perf_str_addr": "2851 Woodside Drive",
  "perf_city_name": "Cincinnati",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "452210222",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "OH01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "151700",
   "pgm_ele_name": "EPMD-ElectrnPhoton&MagnDevices"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "107E",
   "pgm_ref_txt": "Magnetics and spin electronics"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 300000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Energy-efficient microprocessors are needed to implement Artificial Intelligence (AI) algorithms as they are becoming pervasive in various aspects of our lives. Currently available computing architectures suffer from memory-wall bottleneck due to unique computing requirement for AI algorithms that needs tremendous amount of memory close to the processing units. The existing memory technologies, such as Dynamic Randon Access Memory (DRAM) and Static Randon Access Memory (SRAM), suffer from scaling and power limitations. Therefore, there is an urgent need to develop new memory technologies that can support the computing architecture requirements for implementing AI algorithms. The objective of this project was to develop a new class of memory device, called \"synaptic memory devices\", that can enable brain-inspired computing architectures for implementing AI algorithms. These memory devices enabled novel computing approaches, such as in-memory computing, capable of implementing energy-efficient AI accelerators. The project made significant contributions on demonstrating gated-Resistive Random Access Memory (gated-RRAM) as synaptic memory devices. These are non-volatile memory devices that can store data even when the power is turned off.</p>\r\n<p>The devices, developed in this project, consisted of a switching oxide sandwiched between top- and bottom-electrodes. A gate terminal was also provided that was separated from switching oxide using a gate oxide. The state of switching oxide was programmed by applying bias on gate-terminal while the state was read by applying bias between top-and bottom-electrodes. Unlike two terminal RRAMs, these devices offered independent control of the read/write process that helped in developing novel computing strategies. From device-physics perspectives, the devices offered both short-term and long-term states, analogous to biological synapses, thus, placing them in the category of synaptic memory devices. The short-terms states were achieved by capitalizing on the defect dynamics of charge trapping and de-trapping in switching oxide or interfaces. The long-term states were achieved by creation and annihilation of new defects in the switching oxides with applied bias.</p>\r\n<p>Using these devices, two types of computing approaches were demonstrated- (i) dendritic computing, and (ii) unsupervised learning based on the concepts of self-organizing feature mapping (SOFM). SOFMs produce a topographic map of the data like what is observed in the sensory cortices or somatosensory cortices of the brain. These cortices can map the data observed by our ears and eyes in clusters which react to physically similar stimuli. These sensory maps allow for the data observed in the lifetime of an organism to be summarized and available via the neurons in the map. Gated-RRAMs, developed in this work, was used to control the decay rate of learning by calculating the Manhattan distance. To implement Manhattan distance attenuation, conductance of gated-RRAM was programmed by applying a bias to the gate terminal. The output voltages of the voltage dividers were the neighborhood function outputs, for corresponding neuron, computed in-memory by the gated-RRAM devices and fixed value resistors. Allowing the conductive state of these gated-RRAM devices to passively decay. This resulted in a time-variant self-decaying neighborhood function found in the SOFM algorithm. This decay was modeled as an exponential decay in Python model of the architecture. For efficient utilization of the neuron map and biological parallelism, we implemented inter-neuronal connections. These connections can be loosely related to the behavior of passive dendrites in biological neural networks. We believe this is significant as it allowed for the implementation of clustering algorithms in energy-efficient manner which is critical for advancing AI. This work resulted in several publications in peer-reviewed conferences and journals and one patent. Additional research challenges were identified that included reducing the operating voltages of these devices and demonstrating large arrays with the underlying Complementary Metal Oxide Semiconductor (CMOS) Integrated Circuits.</p>\r\n<p>The project also made significant contributions towards training and workforce development in semiconductors. High-school students were brought on campus and were made aware of various semiconductor technologies and given tours to the Cleanroom Microfabrication Facility. Several graduate and undergraduate students were trained on advanced semiconductor manufacturing, electrical testing, simulations, programming, and data analysis. Students were also trained on concepts of domain specific neuromorphic computing and AI.</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/29/2025<br>\nModified by: Rashmi&nbsp;Jha</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nEnergy-efficient microprocessors are needed to implement Artificial Intelligence (AI) algorithms as they are becoming pervasive in various aspects of our lives. Currently available computing architectures suffer from memory-wall bottleneck due to unique computing requirement for AI algorithms that needs tremendous amount of memory close to the processing units. The existing memory technologies, such as Dynamic Randon Access Memory (DRAM) and Static Randon Access Memory (SRAM), suffer from scaling and power limitations. Therefore, there is an urgent need to develop new memory technologies that can support the computing architecture requirements for implementing AI algorithms. The objective of this project was to develop a new class of memory device, called \"synaptic memory devices\", that can enable brain-inspired computing architectures for implementing AI algorithms. These memory devices enabled novel computing approaches, such as in-memory computing, capable of implementing energy-efficient AI accelerators. The project made significant contributions on demonstrating gated-Resistive Random Access Memory (gated-RRAM) as synaptic memory devices. These are non-volatile memory devices that can store data even when the power is turned off.\r\n\n\nThe devices, developed in this project, consisted of a switching oxide sandwiched between top- and bottom-electrodes. A gate terminal was also provided that was separated from switching oxide using a gate oxide. The state of switching oxide was programmed by applying bias on gate-terminal while the state was read by applying bias between top-and bottom-electrodes. Unlike two terminal RRAMs, these devices offered independent control of the read/write process that helped in developing novel computing strategies. From device-physics perspectives, the devices offered both short-term and long-term states, analogous to biological synapses, thus, placing them in the category of synaptic memory devices. The short-terms states were achieved by capitalizing on the defect dynamics of charge trapping and de-trapping in switching oxide or interfaces. The long-term states were achieved by creation and annihilation of new defects in the switching oxides with applied bias.\r\n\n\nUsing these devices, two types of computing approaches were demonstrated- (i) dendritic computing, and (ii) unsupervised learning based on the concepts of self-organizing feature mapping (SOFM). SOFMs produce a topographic map of the data like what is observed in the sensory cortices or somatosensory cortices of the brain. These cortices can map the data observed by our ears and eyes in clusters which react to physically similar stimuli. These sensory maps allow for the data observed in the lifetime of an organism to be summarized and available via the neurons in the map. Gated-RRAMs, developed in this work, was used to control the decay rate of learning by calculating the Manhattan distance. To implement Manhattan distance attenuation, conductance of gated-RRAM was programmed by applying a bias to the gate terminal. The output voltages of the voltage dividers were the neighborhood function outputs, for corresponding neuron, computed in-memory by the gated-RRAM devices and fixed value resistors. Allowing the conductive state of these gated-RRAM devices to passively decay. This resulted in a time-variant self-decaying neighborhood function found in the SOFM algorithm. This decay was modeled as an exponential decay in Python model of the architecture. For efficient utilization of the neuron map and biological parallelism, we implemented inter-neuronal connections. These connections can be loosely related to the behavior of passive dendrites in biological neural networks. We believe this is significant as it allowed for the implementation of clustering algorithms in energy-efficient manner which is critical for advancing AI. This work resulted in several publications in peer-reviewed conferences and journals and one patent. Additional research challenges were identified that included reducing the operating voltages of these devices and demonstrating large arrays with the underlying Complementary Metal Oxide Semiconductor (CMOS) Integrated Circuits.\r\n\n\nThe project also made significant contributions towards training and workforce development in semiconductors. High-school students were brought on campus and were made aware of various semiconductor technologies and given tours to the Cleanroom Microfabrication Facility. Several graduate and undergraduate students were trained on advanced semiconductor manufacturing, electrical testing, simulations, programming, and data analysis. Students were also trained on concepts of domain specific neuromorphic computing and AI.\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 01/29/2025\n\n\t\t\t\t\tSubmitted by: RashmiJha\n"
 }
}