{
 "awd_id": "1909244",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Enabling New Machine-Learning Usage Scenarios with Software-Defined Hardware for Symbolic Regression",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 499519.0,
 "awd_amount": 499519.0,
 "awd_min_amd_letter_date": "2019-08-23",
 "awd_max_amd_letter_date": "2024-04-19",
 "awd_abstract_narration": "Despite the widespread success of machine learning, existing techniques have limitations and/or unattractive trade-offs that prohibit important usage scenarios, particularly in embedded and real-time systems. For example, artificial neural nets provide sufficient accuracy for many applications, but can be too computationally expensive for embedded usage and may require large training data sets that are impractical to collect for some applications. Even when executed with cloud computing, neural nets often require graphics-processing unit acceleration, which greatly increases power costs that can already dominate the total cost of ownership in large-scale data centers and supercomputers. Similarly, linear regression is a widely used machine-learning technique, but generally requires model specification or guidance by the user, which is prohibitive for difficult-to-understand phenomena and/or many-dimensional problems. This project shows that symbolic regression complements existing machine-learning techniques by providing attractive Pareto-optimal trade-offs that enable new machine-learning usage scenarios where existing technologies are prohibitive. These symbolic-regression benefits come from three key advantages: 1) automatic model discovery, 2) computational efficiency with minimal loss in capability compared to existing techniques, and 3) lower sensitivity to training set size. \r\n\r\nDespite being studied for decades, symbolic regression is generally limited to toy examples due to the challenge of searching an infinite solution space with numerous local optima. This project presents a solution that significantly advances the state-of-the-art via two primary contributions: 1) 1,000,000x acceleration of the symbolic-regression exploration process, and 2) fundamentally new exploration algorithms that are only possible with such significant acceleration. To accelerate the symbolic-regression exploration process, the investigators introduce software-defined hardware that re-configures every cycle to provide a solution-specific pipeline implemented as a virtual hardware overlay on field-programmable gate arrays. Although this acceleration by itself improves upon the state-of-the-art in symbolic regression considerably, the more important contribution is the enabling of new exploration algorithms that are not feasible without massive increases in performance. The investigators use this performance improvement to introduce a new hybrid exploration algorithm that performs multiple concurrent searches using different configurations of genetic programming and deterministic heuristics, combined with two new prediction mechanisms to avoid local optima: sub-tree look-ahead prediction and operator correlation.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jose",
   "pi_last_name": "Principe",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Jose C Principe",
   "pi_email_addr": "principe@cnel.ufl.edu",
   "nsf_id": "000266366",
   "pi_start_date": "2024-04-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Greg",
   "pi_last_name": "Stitt",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Greg M Stitt",
   "pi_email_addr": "gstitt@ece.ufl.edu",
   "nsf_id": "000508517",
   "pi_start_date": "2019-08-23",
   "pi_end_date": "2024-04-19"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ann",
   "pi_last_name": "Ramirez",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ann Ramirez",
   "pi_email_addr": "ann@ece.ufl.edu",
   "nsf_id": "000502544",
   "pi_start_date": "2019-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1 University of Florida",
  "perf_city_name": "Gainesville",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326112001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 499519.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Automatically evolving programs instead of writing programs from scratch has been a goal in computer science for many years. Evolutionary theory has become more mature and advances in evolutionary computation and computer hardware have enabled the opportunity to evolve programs in field programmable gate arrays (FPGAs).&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<p>The main objective of this project is to push the boundaries of symbolic regression and enhance the efficiency of machine learning techniques. More precisely, it seeks to significantly accelerate symbolic regression search algorithms using FPGAs, achieving a substantial speedup with respect to graphical processing units (GPUs) that are not optimized for the evaluation stage of genetic programming, which must run numerous distinct programs with the same dataset. &nbsp;</p>\r\n<p>In our research, we introduced a \"tree accelerator\" capable of reconfiguring itself every cycle to execute various programs as required in symbolic regression. The tree accelerator incorporates configurable processing elements, which are application-specific Arithmetic Logic Units (ALUs). Complementing the tree accelerator is a compiler that dynamically takes programs generated during the evolutionary stages of genetic programming and translates them into configuration bits for the processing elements.</p>\r\n<p>By providing a rapidly reconfigurable tree structure, we can effectively evaluate a multitude of innovative search algorithms that were previously unattainable using conventional architectures. While we didn't consistently outperform every tool in terms of average speedup, our single-FPGA accelerator proved to be the fastest in several specific scenarios. Additionally, we identified five prospective enhancements that could potentially yield a speedup ranging from 128&times; to 576&times; compared to our current design.&nbsp;</p>\r\n<p>The project has promoted extensive collaboration among students, engaging four graduate students and a five undergraduates, who completed senior projects linked to this research.</p>\r\n<p>We have published 1 journal paper and 4 refereed conference proceedings, and are working on two more journal and two more conference papers.</p>\r\n<p>Furthermore, the project has granted students exposure to research settings at Microsoft Research and NASA Goddard, and with researchers within the Operon genetic programming tool consorcium.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/29/2024<br>\nModified by: Jose&nbsp;C&nbsp;Principe</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nAutomatically evolving programs instead of writing programs from scratch has been a goal in computer science for many years. Evolutionary theory has become more mature and advances in evolutionary computation and computer hardware have enabled the opportunity to evolve programs in field programmable gate arrays (FPGAs).\r\n\n\n\r\n\n\nThe main objective of this project is to push the boundaries of symbolic regression and enhance the efficiency of machine learning techniques. More precisely, it seeks to significantly accelerate symbolic regression search algorithms using FPGAs, achieving a substantial speedup with respect to graphical processing units (GPUs) that are not optimized for the evaluation stage of genetic programming, which must run numerous distinct programs with the same dataset. \r\n\n\nIn our research, we introduced a \"tree accelerator\" capable of reconfiguring itself every cycle to execute various programs as required in symbolic regression. The tree accelerator incorporates configurable processing elements, which are application-specific Arithmetic Logic Units (ALUs). Complementing the tree accelerator is a compiler that dynamically takes programs generated during the evolutionary stages of genetic programming and translates them into configuration bits for the processing elements.\r\n\n\nBy providing a rapidly reconfigurable tree structure, we can effectively evaluate a multitude of innovative search algorithms that were previously unattainable using conventional architectures. While we didn't consistently outperform every tool in terms of average speedup, our single-FPGA accelerator proved to be the fastest in several specific scenarios. Additionally, we identified five prospective enhancements that could potentially yield a speedup ranging from 128 to 576 compared to our current design.\r\n\n\nThe project has promoted extensive collaboration among students, engaging four graduate students and a five undergraduates, who completed senior projects linked to this research.\r\n\n\nWe have published 1 journal paper and 4 refereed conference proceedings, and are working on two more journal and two more conference papers.\r\n\n\nFurthermore, the project has granted students exposure to research settings at Microsoft Research and NASA Goddard, and with researchers within the Operon genetic programming tool consorcium.\r\n\n\n\t\t\t\t\tLast Modified: 12/29/2024\n\n\t\t\t\t\tSubmitted by: JoseCPrincipe\n"
 }
}