{
 "awd_id": "1900904",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF: Medium: Collaborative Research: Enhancing Mobile VR/AR User Experience: An Integrated Architecture-System Approach",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Danella Zhao",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2019-07-03",
 "awd_max_amd_letter_date": "2021-06-25",
 "awd_abstract_narration": "Virtual reality (VR) and augmented reality (AR) are now experiencing rapid growth and debuting into mainstream markets driven by the significant performance improvement of computing hardware and the revolution of graphics and display technologies. Both VR and AR are increasingly adopted in smartphones for providing rich experience to mobile users. However, the limited hardware resources in mobile devices can barely support the tremendous resource requirements by VR/AR technology and the demand for a good user experience. There are several key challenges that dramatically degrade user experience when enabling VR/AR apps on smartphones. For example, when the VR user shifts her/his eyes slightly, the computer is unable to provide an image that corresponds to the new view in a timely manner. This delay causes motion anomalies and unsatisfying user experience. Other challenges for mobile VR/AR are limited battery life and increased heat dissipation. The investigators on this project are leveraging the unique features of VR/AR and exploring a synergetic architecture-system program to tackle the above performance, battery life, and thermal challenges, thus, enhancing mobile VR/AR user experience. This project will open the door for next generation mobile platforms that provide high-quality low-power VR/AR services to satisfy mobile users. This project will also contribute to society through engaging under-represented groups, and outreach to high-school students, curriculum development on Internet of Things, and disseminating research infrastructure for education and training.\r\n\r\nThis project contains four objectives, including (1) approximate computing to eliminate unnecessary workloads in mobile AR/VR to achieve threefold benefits on performance, power, and thermal without sacrificing the user perceived image quality and output accuracy; (2) emerging technologies (e.g., processing-in-memory, multiple chip module (MCM)-GPU) enabled mobile VR/AR for performance/power optimization; (3) exploiting dynamic thermal energy harvesting to cool hotspots, prolong battery life and improve performance; and (4) integration of the key research innovations and cross-technology optimizations to maximize the performance/power/thermal enhancement.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xin",
   "pi_last_name": "Fu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xin Fu",
   "pi_email_addr": "xfu8@central.uh.edu",
   "nsf_id": "000583715",
   "pi_start_date": "2019-07-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Houston",
  "inst_street_address": "4300 MARTIN LUTHER KING BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "HOUSTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7137435773",
  "inst_zip_code": "772043067",
  "inst_country_name": "United States",
  "cong_dist_code": "18",
  "st_cong_dist_code": "TX18",
  "org_lgl_bus_name": "UNIVERSITY OF HOUSTON SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "QKWEF8XLMTT3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Houston",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "772042015",
  "perf_ctry_code": "US",
  "perf_cong_dist": "18",
  "perf_st_cong_dist": "TX18",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The objective of this research is to explore a synergetic architecture-system research program to holistically and cooperatively enhance mobile VR/AR (Virtual Reality/Augmented Reality) user experience. Especially, we intend to simultaneously improve performance, power, and security while also providing guaranteed perception/accuracy for mobile VR/AR users. We have made the following major achievements:</p>\n<p>(1)&nbsp;&nbsp; &nbsp;Enabling Universal Realistic Rendering for Modern Mobile VR: To provide users with a fully immersive environment, VR post-processing, which adds numerous realistic effects on the frame after rendering, plays a key role in modern VR systems. Current post-processing is processed separately from normal rendering by the graphics processing unit (GPU). As a result, the GPU need to first render a high-resolution frame and then add the post-processing effects within a very short time frame. Our in-depth experimental results on commercial VR products demonstrate that the post-processing in VR applications extends the VR frame time by approximately 2X on average. Furthermore, the ever-increasing resolution requirements of modern VR significantly increase the workloads for post-processing in the execution pipeline. This long delay causes VR real-time execution to frequently miss the critical frame-time deadline, thus hurting users' quality of experience. Based on the analysis of VR post-processing workflow and its common realistic effects, we observe that post-processing shares the same hardware pipeline with normal rendering, and even reuses the intermediate data produced by normal rendering. To fully utilize this hardware-level similarity and capture the data locality, we propose a novel universal realistic rendering architecture for VR, named Post0-VR, which eliminates post-processing by directly merging the common realistic effects into the normal rendering process. Based on our newly proposed VR architecture design, we further propose a dynamic accuracy adjustment method to simplify the normal rendering without hurting users' perception.</p>\n<p>(2)&nbsp;&nbsp; Exploring Fast and Lightweight Mobile Multi-User AR: Multi-user augmented reality (MuAR) enables different users to interact with the same virtual object and continuously exchange environment information between users. The state-of-the-art MuAR uses the 3D point cloud as the backbone to support real-world analysis, view synchronization between users, virtual object rendering, and movement tracking. Although the 3D point cloud could achieve high potential accuracy and simplify position tracking, the complex data structure of the 3D point cloud costs extensive generating and processing time which contributes to the major latencies in modern MuAR systems. As a result, commercial AR frameworks need a long startup overhead to prepare the environment and long run-time latency to deliver virtual objects for users. Based on the analysis of the MuAR workflow and its synchronization mechanism, we observe that in a stable environment, maintaining the facing side of the real-world scene already provides enough information to support virtual object placement and rendering in the MuAR system. Thus, to provide the user with a smooth experience, we use the quadtree structure, which represents the 2D scene using semantics segmentation and depth information to replace the expensive 3D point cloud. To handle the potential virtual objects placement shift during the view synchronization of users, we further propose a novel correction method by collaboratively analyzing the real-world environment and maintaining the virtual object synchronization among users. Combining all designs, we implement a fast and lightweight multi-user AR framework, named AR-Light in a common-used AR platform.</p>\n<p>(3)&nbsp;&nbsp;&nbsp; Encryption of Streaming Video for Security:To provide video streaming with security, privacy and copyright protection, encryption is necessary. However, delay, memory and compute requirements pose serious challenges to efficient transmission. The situation becomes more challenging when multiple users stream concurrently. We present a solution to this problem by offloading encryption to the memory side using Processing-In-Memory (PIM) architecture. Advanced Encryption Standard is used due to its security and flexibility. Encryption performance is improved significantly compared to non-PIM CPU implementation. The best performance was obtained by aggressively applying user parallelism and improving QoS by balancing the workload. Streaming parallel data/video that is encrypted benefits AR/VR systems as well as commercial streaming systems.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/14/2023<br>\nModified by: Xin&nbsp;Fu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe objective of this research is to explore a synergetic architecture-system research program to holistically and cooperatively enhance mobile VR/AR (Virtual Reality/Augmented Reality) user experience. Especially, we intend to simultaneously improve performance, power, and security while also providing guaranteed perception/accuracy for mobile VR/AR users. We have made the following major achievements:\n\n\n(1) Enabling Universal Realistic Rendering for Modern Mobile VR: To provide users with a fully immersive environment, VR post-processing, which adds numerous realistic effects on the frame after rendering, plays a key role in modern VR systems. Current post-processing is processed separately from normal rendering by the graphics processing unit (GPU). As a result, the GPU need to first render a high-resolution frame and then add the post-processing effects within a very short time frame. Our in-depth experimental results on commercial VR products demonstrate that the post-processing in VR applications extends the VR frame time by approximately 2X on average. Furthermore, the ever-increasing resolution requirements of modern VR significantly increase the workloads for post-processing in the execution pipeline. This long delay causes VR real-time execution to frequently miss the critical frame-time deadline, thus hurting users' quality of experience. Based on the analysis of VR post-processing workflow and its common realistic effects, we observe that post-processing shares the same hardware pipeline with normal rendering, and even reuses the intermediate data produced by normal rendering. To fully utilize this hardware-level similarity and capture the data locality, we propose a novel universal realistic rendering architecture for VR, named Post0-VR, which eliminates post-processing by directly merging the common realistic effects into the normal rendering process. Based on our newly proposed VR architecture design, we further propose a dynamic accuracy adjustment method to simplify the normal rendering without hurting users' perception.\n\n\n(2) Exploring Fast and Lightweight Mobile Multi-User AR: Multi-user augmented reality (MuAR) enables different users to interact with the same virtual object and continuously exchange environment information between users. The state-of-the-art MuAR uses the 3D point cloud as the backbone to support real-world analysis, view synchronization between users, virtual object rendering, and movement tracking. Although the 3D point cloud could achieve high potential accuracy and simplify position tracking, the complex data structure of the 3D point cloud costs extensive generating and processing time which contributes to the major latencies in modern MuAR systems. As a result, commercial AR frameworks need a long startup overhead to prepare the environment and long run-time latency to deliver virtual objects for users. Based on the analysis of the MuAR workflow and its synchronization mechanism, we observe that in a stable environment, maintaining the facing side of the real-world scene already provides enough information to support virtual object placement and rendering in the MuAR system. Thus, to provide the user with a smooth experience, we use the quadtree structure, which represents the 2D scene using semantics segmentation and depth information to replace the expensive 3D point cloud. To handle the potential virtual objects placement shift during the view synchronization of users, we further propose a novel correction method by collaboratively analyzing the real-world environment and maintaining the virtual object synchronization among users. Combining all designs, we implement a fast and lightweight multi-user AR framework, named AR-Light in a common-used AR platform.\n\n\n(3) Encryption of Streaming Video for Security:To provide video streaming with security, privacy and copyright protection, encryption is necessary. However, delay, memory and compute requirements pose serious challenges to efficient transmission. The situation becomes more challenging when multiple users stream concurrently. We present a solution to this problem by offloading encryption to the memory side using Processing-In-Memory (PIM) architecture. Advanced Encryption Standard is used due to its security and flexibility. Encryption performance is improved significantly compared to non-PIM CPU implementation. The best performance was obtained by aggressively applying user parallelism and improving QoS by balancing the workload. Streaming parallel data/video that is encrypted benefits AR/VR systems as well as commercial streaming systems.\n\n\n\t\t\t\t\tLast Modified: 12/14/2023\n\n\t\t\t\t\tSubmitted by: XinFu\n"
 }
}