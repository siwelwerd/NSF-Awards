{
 "awd_id": "1908691",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "OAC Core: Small: Higher Order Solvers for Training Machine Learning Models",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032922625",
 "po_email": "jjli@nsf.gov",
 "po_sign_block_name": "Juan Li",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 495699.0,
 "awd_amount": 495699.0,
 "awd_min_amd_letter_date": "2019-06-26",
 "awd_max_amd_letter_date": "2019-06-26",
 "awd_abstract_narration": "Machine learning (ML) techniques have emerged as a key enabling technology for a broad class of applications, from business enterprises to engineering design. These techniques rely on complex models that must be suitably trained on large amounts of data. This training process takes the form of mathematical optimization, which minimizes the error between model output and known output, for training data. Owing to the large number of degrees of freedom in the model, the complexity of the objective function being minimized, and the volume of training data, the process of effectively and efficiently training ML models is a critical step in machine learning.  The goal of this project is to develop novel optimization techniques, their implementations on large scale parallel platforms with GPU accelerators, validation in the context of diverse ML applications, and development of highly optimized, robust, and usable software tools and libraries. These software tools will be specialized to various ML models, and incorporated into commonly used software frameworks such as TensorFlow -- thus making them seamlessly accessible to a very large and diverse user community.  The robustness, performance, and scalability of the software provide unique capabilities, with the potential to redefine the state of the art in ML applications, in terms of supporting significantly more complex ML models, enhancing generalizability from training to test data, and significantly reducing training time. Building on these intellectual and broader impact goals, the project integrates a number of activities aimed at broadening participation and creating educational opportunities and content.  These include summer schools for undergraduate students to channel them into research careers, providing research opportunities for undergraduates through the school year, development of new educational material that integrates learning with hands-on use of software, and motivating novel formulations and methods in machine learning.\r\n\r\nThe technical goals of the project are accomplished through a combination of novel numerical methods, statistical sampling techniques, highly scalable parallel implementations, and efficient use of GPUs. The project has the following specific aims: (i) development of second order Newton-type methods for non-convex problems. Specifically, the project focuses on Trust Region (TR) and Cubic Regularization (CR) based methods that rely on approximations to the Hessian and Fisher information matrices to deliver highly efficient solvers; (ii) development of a complete Higher Order Optimization Procedures (HOOP) toolkit, including unbiased and biased sampled Hessians, block diagonal approximations of the Fisher matrix, efficient and effective preconditioners for the Conjugate Gradient (CG) and CG-Steihaug solvers, and problem-specific optimizations; (iii) development of efficient parallel methods based on a combination of Alternating Direction Method of Multipliers (ADMM) and parallel matrix solvers, for scalable hardware platforms with GPU accelerators, as well as an integration of the software into TensorFlow. The software will also be made available as containerized executables that can be instantiated at clients with minimal effort, as libraries that can be used to build new ML applications, and as web accessible services for education and training; and (iv) demonstration of the effectiveness of the new methods on important application classes, including solution of large-scale semi-definite programs (SDP), problems in matrix factorization and distance metric learning, and training of deep neural networks.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ananth",
   "pi_last_name": "Grama",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ananth Grama",
   "pi_email_addr": "ayg@cs.purdue.edu",
   "nsf_id": "000319590",
   "pi_start_date": "2019-06-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "305 N. University Street",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072107",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "090Y00",
   "pgm_ele_name": "OAC-Advanced Cyberinfrast Core"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 495699.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project resulted in theoretical underpinnings, algorithms, software, and applications of novel methodologies in Artificial Intelligence (AI) and Machine Learning (ML) systems. It established the theoretical underpinnings of a broad class of problem formulations, methods, and application contexts. These include: (i) learning in adversarial settings, where it established bounds on optimality and developed methods that achieve these bounds; (ii) learning with noisy data, where it was shown that denoising can be integrated into the learning process, and the conditions under which one can learn optimally; (iii) learning from privatized data, where it showed that techniques like differential privacy can still enable effective learning; (iv) learning in the presence of hardware faults, where it developed an entirely new model for analyzing hardware faults and how one can train models on faulty hardware; and (v) learning when underlying data distributions are changing.</p>\n<p>With respect to algorithms and software, the project resulted in second-order solvers capable of training machine learning models much faster than conventional optimization procedures. In addition to their faster convergence, empirical results showed that models trained using these new methods have better generalization properties than existing optimizers. The project also resulted in a new class of fault-tolerance mechanisms based on the innovative concept of erasure coded computations. Erasure coding is conventionally used in data storage to efficiently recover from data loss (erasures). Its computational analog, developed as part of this project, augments input data with suitably coded blocks and executes the computation on this augmented input data in a fault-oblivious manner. In the event of hardware failures, the true solution is recovered from the solution from the potentially faulty execution on augmented data through a computationally inexpensive procedure. The project demonstrated erasure coded computations in the context of important learning kernels such as eigenvalue computations and showed that this enables learning at massive scales in faulty environments, where existing techniques would not be feasible due to their storage or bandwidth requirements.</p>\n<p>The models, methods, and software developed as part of the project have been validated in diverse application contexts. In particular, it demonstrated robust AI-enabled controllers for Internet of Thing (IoT) devices and Autonomous systems, real-time anomaly detection in critical systems, patient specific interventions through large-scale clinical data analytics, and process and quality optimization in advanced manufacturing. These applications have involved industry collaborators, as well as domain experts.</p>\n<p>The project also enabled a number of important contributions to education and outreach. Technical outcomes of the project were incorporated into two large courses at Purdue on Numerical Analysis and Parallel Computing. It also enabled the PI to serve as a mentor for the Horizons program for first time college attendees, and the Emerging Leaders Science Scholars program for students from underrepresented groups. It also enabled the PI to contribute to programs designed to recruit, prepare, and mentor students from underrepresented groups into the graduate computer science program at Purdue.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 07/07/2024<br>\nModified by: Ananth&nbsp;Grama</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project resulted in theoretical underpinnings, algorithms, software, and applications of novel methodologies in Artificial Intelligence (AI) and Machine Learning (ML) systems. It established the theoretical underpinnings of a broad class of problem formulations, methods, and application contexts. These include: (i) learning in adversarial settings, where it established bounds on optimality and developed methods that achieve these bounds; (ii) learning with noisy data, where it was shown that denoising can be integrated into the learning process, and the conditions under which one can learn optimally; (iii) learning from privatized data, where it showed that techniques like differential privacy can still enable effective learning; (iv) learning in the presence of hardware faults, where it developed an entirely new model for analyzing hardware faults and how one can train models on faulty hardware; and (v) learning when underlying data distributions are changing.\n\n\nWith respect to algorithms and software, the project resulted in second-order solvers capable of training machine learning models much faster than conventional optimization procedures. In addition to their faster convergence, empirical results showed that models trained using these new methods have better generalization properties than existing optimizers. The project also resulted in a new class of fault-tolerance mechanisms based on the innovative concept of erasure coded computations. Erasure coding is conventionally used in data storage to efficiently recover from data loss (erasures). Its computational analog, developed as part of this project, augments input data with suitably coded blocks and executes the computation on this augmented input data in a fault-oblivious manner. In the event of hardware failures, the true solution is recovered from the solution from the potentially faulty execution on augmented data through a computationally inexpensive procedure. The project demonstrated erasure coded computations in the context of important learning kernels such as eigenvalue computations and showed that this enables learning at massive scales in faulty environments, where existing techniques would not be feasible due to their storage or bandwidth requirements.\n\n\nThe models, methods, and software developed as part of the project have been validated in diverse application contexts. In particular, it demonstrated robust AI-enabled controllers for Internet of Thing (IoT) devices and Autonomous systems, real-time anomaly detection in critical systems, patient specific interventions through large-scale clinical data analytics, and process and quality optimization in advanced manufacturing. These applications have involved industry collaborators, as well as domain experts.\n\n\nThe project also enabled a number of important contributions to education and outreach. Technical outcomes of the project were incorporated into two large courses at Purdue on Numerical Analysis and Parallel Computing. It also enabled the PI to serve as a mentor for the Horizons program for first time college attendees, and the Emerging Leaders Science Scholars program for students from underrepresented groups. It also enabled the PI to contribute to programs designed to recruit, prepare, and mentor students from underrepresented groups into the graduate computer science program at Purdue.\n\n\n\t\t\t\t\tLast Modified: 07/07/2024\n\n\t\t\t\t\tSubmitted by: AnanthGrama\n"
 }
}