{
 "awd_id": "1946976",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER:Scalable Photonic AI Accelerators Based on Photoelectric Multiplication",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ann Von Lehmen",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2019-08-23",
 "awd_max_amd_letter_date": "2019-08-23",
 "awd_abstract_narration": "One of the deepest questions in science is how biological cognition works.  Traditionally the purview of neuroscience and psychology, in recent years computer science have shed light on it through the field of 'deep learning'.  Deep learning uses computer algorithms called neural networks to perform various tasks-e.g. face recognition, medical diagnosis, automobile driving--that have long been considered difficult for computers, and is transforming many industries including logistics, manufacturing, healthcare, and finance.  However, neural networks are very costly to run even on modern computers.  To unlock deep learning's full potential, this research will investigate a new concept: Optical Neural Networks.  By running neural networks on dedicated optical hardware, there is a potential to increase speed and reduce energy consumption by at least 1000x.  This program will study the feasibility of this concept to pave the way for more extensive technology development in the future.  If realized, Optical Neural Networks will allow researchers to develop significantly larger, more complex deep learning models that may open up entirely new deep learning applications that are beyond the capabilities of present-day computers.   \r\n\r\nArtificial intelligence (AI) based on deep neural networks (DNNs) has revolutionized a wide range of fields, but at a cost: DNNs are very compute- and power-intensive.  Driving the AI revolution has been an exponential growth in the available compute performance, which has enabled the application of DNNs to increasingly complex tasks.  However, as Moore's Law runs out of steam, this trend cannot continue for long; therefore, the development of alternative platforms for AI hardware has become especially urgent.  This EAGER will study a class of optical neural networks (ONNs) that harness the unique advantages of photonics and promise orders-of-magnitude throughput- and energy-consumption improvements over conventional electronics.  Three key tasks are: (i) a system-level architecture study to predict the ONN's performance gains on realistic workloads, (ii) a hardware analysis and feasibility study, and (iii) an investigation into the fundamental limits of ONNs.  Research activities include modeling, numerical analysis, and benchmarking.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dirk",
   "pi_last_name": "Englund",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Dirk R Englund",
   "pi_email_addr": "englund@mit.edu",
   "nsf_id": "000550729",
   "pi_start_date": "2019-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Avenue",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  },
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-502eb9aa-7fff-94a3-6e8a-7654db1bad00\">\n<p dir=\"ltr\">As deep neural network (DNN) models grow ever-larger, they can achieve higher accuracy and solve more complex problems. This trend has been enabled by an increase in available compute power; however, efforts to continue to scale electronic processors are impeded by the costs of communication, thermal management, power delivery and clocking. Optical computing systems may be able to meet these domain-specific needs. Photonics has several inherent advantages, namely: high bandwidth, low power consumption, and efficient data movement. However, despite half a century of research, general purpose optical computing systems have yet to mature into a practical technology. Artificial intelligence inference, however, especially for visual computing applications, may offer opportunities for inference based on optical and photonic systems.&nbsp;</p>\n<br /><br />\n<p dir=\"ltr\"><span>To improve scalability, we propose a digital optical neural network (DONN) with intralayer optical interconnects and reconfigurable input values. The near path-length-independence of optical energy consumption enables information locality between a transmitter and arbitrarily arranged receivers, which allows greater flexibility in architecture design to circumvent scaling limitations. We performed the classification of 500 MNIST images with a 3-layer, fully-connected network using an optical multicast for a proof-of-concept experiment. We also explored the regimes where optical data transfer outperforms electronics.&nbsp;</span></p>\n<br />\n<p dir=\"ltr\"><span>In addition, we have demonstrated an incoherent single-shot optical neural network (Scalable Ultralow-Latency Photonic Tensor Processor, ScULPT) based Fourier-plane optical fanout and weighting.&nbsp; This scheme has a number of advantages over the coherent-detection scheme, including stability to phase fluctuations, single-shot operation, and compatibility with non-batched instances (matrix-vector multiplication). Experimental results show accuracy comparable to ground-truth values for multi-layer classification of MNIST handwritten digits, Fashion-MNIST fashion items and QuickDraw crowdsourced doodles. We also sought to explore the fundamental throughput bounds of this architecture through measurements of classification accuracy with a spectrally broad source. Our results indicate that exascale throughput is theoretically achievable before significant accuracy degradation.</span></p>\n<p dir=\"ltr\"><span>We also compare leading photonic AI platforms based on beamsplitter mesh networks, weight banks, and photoelectric multiplication. While the theoretical performance can be orders of magnitude beyond current state of the art, practical issues of chip area, input / output, and crosstalk paint a more nuanced near-term picture of photonic AI acceleration. Both fundamental and near-term limitations to energy efficiency are addressed, and bandwidth limitations due to temporal crosstalk are analyzed. </span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/10/2023<br>\n\t\t\t\t\tModified by: Dirk&nbsp;R&nbsp;Englund</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nAs deep neural network (DNN) models grow ever-larger, they can achieve higher accuracy and solve more complex problems. This trend has been enabled by an increase in available compute power; however, efforts to continue to scale electronic processors are impeded by the costs of communication, thermal management, power delivery and clocking. Optical computing systems may be able to meet these domain-specific needs. Photonics has several inherent advantages, namely: high bandwidth, low power consumption, and efficient data movement. However, despite half a century of research, general purpose optical computing systems have yet to mature into a practical technology. Artificial intelligence inference, however, especially for visual computing applications, may offer opportunities for inference based on optical and photonic systems. \n\n\n\nTo improve scalability, we propose a digital optical neural network (DONN) with intralayer optical interconnects and reconfigurable input values. The near path-length-independence of optical energy consumption enables information locality between a transmitter and arbitrarily arranged receivers, which allows greater flexibility in architecture design to circumvent scaling limitations. We performed the classification of 500 MNIST images with a 3-layer, fully-connected network using an optical multicast for a proof-of-concept experiment. We also explored the regimes where optical data transfer outperforms electronics. \n\n\nIn addition, we have demonstrated an incoherent single-shot optical neural network (Scalable Ultralow-Latency Photonic Tensor Processor, ScULPT) based Fourier-plane optical fanout and weighting.  This scheme has a number of advantages over the coherent-detection scheme, including stability to phase fluctuations, single-shot operation, and compatibility with non-batched instances (matrix-vector multiplication). Experimental results show accuracy comparable to ground-truth values for multi-layer classification of MNIST handwritten digits, Fashion-MNIST fashion items and QuickDraw crowdsourced doodles. We also sought to explore the fundamental throughput bounds of this architecture through measurements of classification accuracy with a spectrally broad source. Our results indicate that exascale throughput is theoretically achievable before significant accuracy degradation.\nWe also compare leading photonic AI platforms based on beamsplitter mesh networks, weight banks, and photoelectric multiplication. While the theoretical performance can be orders of magnitude beyond current state of the art, practical issues of chip area, input / output, and crosstalk paint a more nuanced near-term picture of photonic AI acceleration. Both fundamental and near-term limitations to energy efficiency are addressed, and bandwidth limitations due to temporal crosstalk are analyzed. \n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 02/10/2023\n\n\t\t\t\t\tSubmitted by: Dirk R Englund"
 }
}