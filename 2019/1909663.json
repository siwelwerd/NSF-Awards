{
 "awd_id": "1909663",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: Software-Defined Imaging for Energy-Efficient Visual Computing",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 332999.0,
 "awd_amount": 348999.0,
 "awd_min_amd_letter_date": "2019-07-27",
 "awd_max_amd_letter_date": "2020-04-07",
 "awd_abstract_narration": "Image sensors are becoming ubiquitous in daily life as they are incorporated in future intelligent systems including autonomous navigation, health monitoring, and robotics. A central challenge in these camera-driven applications is the inflexibility of current sensor designs and their consequent energy cost. This project designs a new category of image sensors which exploit hardware -- software co-design to attain better sensing at lower cost. The project advances a vertically-integrated design from the mixed-signal sensor circuitry to the computational architecture and the operating system software support. The project's impacts are the creation of new, flexible image sensor systems that can be used for a variety of visual computing applications. The project further seeks to include broadening access to education and research through curriculum material which emphasize smart cameras of the future, outreach to middle and high school students in a summer program to discover imaging applications, and industry engagement through workshops on software-defined imaging. \r\n\r\nThe project focuses on designing software-defined image sensors, which offer new dimensions of configurability along with system support and programming abstractions to support application-specific needs. To achieve this, the project focuses on three main objectives: (1) Design and implementation of configurable sensor primitives, including programmable regions of interest with custom exposure, readout, and quantization, (2) architectures to control these sensor primitives, and to accelerate image signal processing and vision workloads, and (3) operating system services for scheduling the memory needs for our new sensor primitives, and OS interfaces that enable low-latency reactive sensor control for key applications. These innovations are evaluated in an integrative evaluation testbed that includes a fabricated software-defined image sensor prototype and a Field Programmable Gate Array (FPGA)-based system to measure energy and performance for a set of end-to-end visual applications.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Suren",
   "pi_last_name": "Jayasuriya",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Suren Jayasuriya",
   "pi_email_addr": "sjayasur@asu.edu",
   "nsf_id": "000753682",
   "pi_start_date": "2019-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "LiKamWa",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Robert LiKamWa",
   "pi_email_addr": "likamwa@asu.edu",
   "nsf_id": "000724741",
   "pi_start_date": "2019-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona Board of Regents on behalf of Arizona State University",
  "perf_str_addr": "P.O. Box 876011",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852876011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 332999.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research project has developed research on software-defined imaging through the hardware-software co-design of imaging systems. This concept was introduced to the research community through a survey article entitled 'Software-Defined Imaging: A Survey' published in the journal Proceedings of the IEEE in 2023 and featured on the cover page of the magazine in May 2023. In the theme of software-defined imaging, this project has developed a series of hardware-software camera prototypes for energy-efficient object tracking by leveraging intelligent selection of the region-of-interest (ROI) for the image sensor. This includes a conference publication in the IEEE International Conference on Image Processing in 2020 where the system was first demonstrated in a field-programmable gate array (FPGA) prototype, and then extended to a journal article entitled 'Adaptive Subsampling for ROI-based Visual Tracking: Algorithms and FPGA Implementation' published in IEEE Access in 2022. Subsequently a deep reinforcement learning strategy was introduced to achieve even better ROI tracking published in a journal article in IEEE Access in 2023.</p>\r\n<p>In addition, this project has focused on software and operating system controls for image sensors to enable better efficiency and performance. The concept of 'rhythmic pixel regions' was introduced for image sensors where these regions allowed for flexible expression of areas of interest with varying spatial resolution and temporal resolution requirements. This project designed and implemented a custom hardware encoder and decoder as well as a software decoder on an FPGA board and were able to demonstrate high performance on vision tasks with significant memory savings, which was published in the ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) 2021. Further, this project developed the technique of 'squint imaging' where the energy bottleneck in image sensing was addressed by aggressively scaling the analog voltage supplied to the camera. By characterizing the impact of analog voltage scaling on off-the-shelf sensors, the project demonstrated that this approach significantly reduces sensor power consumption at the expense of image quality degradation and developed a visual streaming pipeline and voltage controller, which can dynamically adapt sensor voltage on a frame-by-frame basis, enhancing the power-efficiency of vision applications. These results were published in the Annual International Conference on Mobile Computing and Networking (MobiCom) 2023.</p>\r\n<p>The project has also spurred other research avenues in computational photography, event-based cameras, and mobile systems. In addition to scholarly research, this project had broader impacts including programming at the Digital Culture Summer Institute that featured activities surrounding computational cameras and photography for middle school teachers and students and integration of research topics into courses taught at Arizona State University including EEE 515: Machine Vision and Pattern Recognition and EEE 598 Mobile Systems Architecture. &nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/13/2025<br>\nModified by: Suren&nbsp;Jayasuriya</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis research project has developed research on software-defined imaging through the hardware-software co-design of imaging systems. This concept was introduced to the research community through a survey article entitled 'Software-Defined Imaging: A Survey' published in the journal Proceedings of the IEEE in 2023 and featured on the cover page of the magazine in May 2023. In the theme of software-defined imaging, this project has developed a series of hardware-software camera prototypes for energy-efficient object tracking by leveraging intelligent selection of the region-of-interest (ROI) for the image sensor. This includes a conference publication in the IEEE International Conference on Image Processing in 2020 where the system was first demonstrated in a field-programmable gate array (FPGA) prototype, and then extended to a journal article entitled 'Adaptive Subsampling for ROI-based Visual Tracking: Algorithms and FPGA Implementation' published in IEEE Access in 2022. Subsequently a deep reinforcement learning strategy was introduced to achieve even better ROI tracking published in a journal article in IEEE Access in 2023.\r\n\n\nIn addition, this project has focused on software and operating system controls for image sensors to enable better efficiency and performance. The concept of 'rhythmic pixel regions' was introduced for image sensors where these regions allowed for flexible expression of areas of interest with varying spatial resolution and temporal resolution requirements. This project designed and implemented a custom hardware encoder and decoder as well as a software decoder on an FPGA board and were able to demonstrate high performance on vision tasks with significant memory savings, which was published in the ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) 2021. Further, this project developed the technique of 'squint imaging' where the energy bottleneck in image sensing was addressed by aggressively scaling the analog voltage supplied to the camera. By characterizing the impact of analog voltage scaling on off-the-shelf sensors, the project demonstrated that this approach significantly reduces sensor power consumption at the expense of image quality degradation and developed a visual streaming pipeline and voltage controller, which can dynamically adapt sensor voltage on a frame-by-frame basis, enhancing the power-efficiency of vision applications. These results were published in the Annual International Conference on Mobile Computing and Networking (MobiCom) 2023.\r\n\n\nThe project has also spurred other research avenues in computational photography, event-based cameras, and mobile systems. In addition to scholarly research, this project had broader impacts including programming at the Digital Culture Summer Institute that featured activities surrounding computational cameras and photography for middle school teachers and students and integration of research topics into courses taught at Arizona State University including EEE 515: Machine Vision and Pattern Recognition and EEE 598 Mobile Systems Architecture. \r\n\n\n\t\t\t\t\tLast Modified: 01/13/2025\n\n\t\t\t\t\tSubmitted by: SurenJayasuriya\n"
 }
}