{
 "awd_id": "1907401",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Locality Aware Scheduling in Multi-GPU Systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 431586.0,
 "awd_amount": 431586.0,
 "awd_min_amd_letter_date": "2019-07-29",
 "awd_max_amd_letter_date": "2019-07-29",
 "awd_abstract_narration": "Heterogeneous multiprocessor architectures consisting of Central Processing Units (CPUs) and Graphical Processing Units (GPUs) are increasingly used to accelerate parallel workloads like High Performance Computing (HPC) and cloud computing. GPUs provide significant improvements in performance compared to traditional multi-core CPUs, and therefore, are heavily used as accelerators. Multiple GPUs are employed to further speed up the execution and improve storage capacity. Current multi-GPU architectures, such as DGX, provide ultra-high bandwidth NVLink communication to transfer the data directly between the GPUs. However, partitioning those computations and data in multi-GPUs based on various memory and communication models poses a tremendous challenge to the programmers. This project develops graph-based partitioning techniques for different applications considering data locality among the computations in the GPUs. Secondly, the current literature on heterogeneous scheduling does not consider processing inside the GPU, leaving it to the manufacturer. This project also develops a locality-based Thread Block (TB) scheduler by extending the same graph-based technique to cache block sharing.\r\n\r\nThe project is carried out in several steps. First, it develops micro-benchmarks for measuring the computation and communication cost for execution in a multi-GPU architecture. A profiling tool is developed to measure the data sharing among the TBs for GPU execution. Second, an adjacency graph is designed for the multi-GPU data partition, where the vertices represent the computation, and edges represent the communication cost between the vertices. A similar graph model is also developed for data sharing inside a GPU, where vertices represent the TBs and edges represent the number of shared blocks between the TBs. Third, a recursive bi-partitioning technique is developed for the adjacency graph using known heuristics and software  to achieve load balance among the partitions and minimize the communication cost between the partitions in a multi-GPU system. TB scheduling is also proposed considering the L2 cache size and the resource limit inside a GPU. Fourth, the technique is extended to partition data and computations between CPUs and GPUs in a heterogeneous multiprocessor. Finally, two regular applications, LU decomposition and Wavefront, are analyzed, and multi-GPU scheduling is developed through real implementation using GPU architectures. Some irregular applications from the Rodinia and CUDA-SDK benchmarks are also analyzed to develop graph models and execute them on the GPGPUSim for verification of the TB scheduling inside the GPU.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Laxmi",
   "pi_last_name": "Bhuyan",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Laxmi N Bhuyan",
   "pi_email_addr": "bhuyan@cs.ucr.edu",
   "nsf_id": "000318919",
   "pi_start_date": "2019-07-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Riverside",
  "inst_street_address": "200 UNIVERSTY OFC BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "RIVERSIDE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9518275535",
  "inst_zip_code": "925210001",
  "inst_country_name": "United States",
  "cong_dist_code": "39",
  "st_cong_dist_code": "CA39",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA AT RIVERSIDE",
  "org_prnt_uei_num": "",
  "org_uei_num": "MR5QC5FCAVH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Riverside",
  "perf_str_addr": "Department of Computer Science a",
  "perf_city_name": "Riverside",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "925210001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "39",
  "perf_st_cong_dist": "CA39",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 431586.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>SHF: SMALL: LOCALITY AWARE SCHEDULING IN MULTI-GPU SYSTEMS</strong></p>\r\n<p><strong>Intellectual Merit:</strong> GPUs provide significant improvements in performance compared to traditional multicore CPUs, and therefore, are heavily used as accelerators. Multiple GPUs are employed to further speed up the execution and improve storage capacity. The aim of this project is to develop different techniques to improve performance and to reduce energy consumption during the execution of an application on single and multiple GPUs. The project develops locality aware scheduling techniques to distribute thread blocks (TBs) among SMs based on graph portioning. The technique is also extended to distribute the tasks among multiple GPUs to obtain a large gain in performance. The current trend of performance growth in HPC systems is accompanied by a massive increase in energy consumption. This project develops GreenMD, an energy-efficient framework for heterogeneous systems for LU factorization utilizing multi-GPUs. The aim is to apply DVFS by leveraging slacks intelligently on both CPUs and multiple GPUs. To predict the slack times, accurate performance models are developed separately for both CPUs and GPUs based on the algorithmic knowledge and manufacturer&rsquo;s specifications. Since DVFS does not reduce static energy consumption, undervolting techniques for both CPUs and GPUs are also developed. Besides the scientific applications, the project has also addressed performance and energy issues in training the LLM applications. &nbsp;It has been observed that the inter-GPU communication, like All Reduce, consumes a significant amount of time and energy during the training. The project develops a power aware communication library that can apply DVFS during communication and save energy consumption. All the techniques developed in this project have been published in high quality journals and conferences, such as ACM TACO, ACM TOPC, PPoPP, ICS, NAS and ICCD, over the last few years.</p>\r\n<p>&nbsp;</p>\r\n<p><strong>Broader Impact:</strong> The project has had a significant broader impact in terms of research publications, and graduate student supervision. Two Ph.D. students have graduated under the project, one joined in academics, and another joined in an industry designing high-performance computers and applications for the future. One female graduate student was supported under this project and completed her Ph.D. thesis. Besides, one MS student and two undergraduate students also worked on the project.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/02/2025<br>\nModified by: Laxmi&nbsp;N&nbsp;Bhuyan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nSHF: SMALL: LOCALITY AWARE SCHEDULING IN MULTI-GPU SYSTEMS\r\n\n\nIntellectual Merit: GPUs provide significant improvements in performance compared to traditional multicore CPUs, and therefore, are heavily used as accelerators. Multiple GPUs are employed to further speed up the execution and improve storage capacity. The aim of this project is to develop different techniques to improve performance and to reduce energy consumption during the execution of an application on single and multiple GPUs. The project develops locality aware scheduling techniques to distribute thread blocks (TBs) among SMs based on graph portioning. The technique is also extended to distribute the tasks among multiple GPUs to obtain a large gain in performance. The current trend of performance growth in HPC systems is accompanied by a massive increase in energy consumption. This project develops GreenMD, an energy-efficient framework for heterogeneous systems for LU factorization utilizing multi-GPUs. The aim is to apply DVFS by leveraging slacks intelligently on both CPUs and multiple GPUs. To predict the slack times, accurate performance models are developed separately for both CPUs and GPUs based on the algorithmic knowledge and manufacturers specifications. Since DVFS does not reduce static energy consumption, undervolting techniques for both CPUs and GPUs are also developed. Besides the scientific applications, the project has also addressed performance and energy issues in training the LLM applications. It has been observed that the inter-GPU communication, like All Reduce, consumes a significant amount of time and energy during the training. The project develops a power aware communication library that can apply DVFS during communication and save energy consumption. All the techniques developed in this project have been published in high quality journals and conferences, such as ACM TACO, ACM TOPC, PPoPP, ICS, NAS and ICCD, over the last few years.\r\n\n\n\r\n\n\nBroader Impact: The project has had a significant broader impact in terms of research publications, and graduate student supervision. Two Ph.D. students have graduated under the project, one joined in academics, and another joined in an industry designing high-performance computers and applications for the future. One female graduate student was supported under this project and completed her Ph.D. thesis. Besides, one MS student and two undergraduate students also worked on the project.\r\n\n\n\t\t\t\t\tLast Modified: 01/02/2025\n\n\t\t\t\t\tSubmitted by: LaxmiNBhuyan\n"
 }
}