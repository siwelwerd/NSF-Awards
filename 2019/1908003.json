{
 "awd_id": "1908003",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Deep Learning for Information Theory- Tackling Algorithm Deficit",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 458388.0,
 "awd_amount": 458388.0,
 "awd_min_amd_letter_date": "2019-06-27",
 "awd_max_amd_letter_date": "2019-06-27",
 "awd_abstract_narration": "Information theory provides the mathematical underpinning on how to optimally communicate, compress and process information. The underlying algorithms, including codes for communication, have been invented using  human ingenuity and proved to be optimal using deep  mathematical reasoning. The rise of deep-learning methods, a branch of machine learning, presents an opportunity to revisit the paradigm for discovering new algorithms. This project studies how to utilize deep-learning for accelerating algorithm discovery in long-standing information-theoretic problems. On a broader scale, this project will promote a stronger interface between deep-learning and information theory, benefiting both research communities. The outcomes of this project will also help create a theory explaining the gains derived by deep-learning algorithms in many application domains, thus addressing an important scientific gap in our understanding of machine-learning.\r\n\r\nThis project studies three problems at the interface of deep-learning and information theory. (1) Deep-Learning based Code Design: This thrust studies the problem of code design, where the code is used to tackle the noise in the communication medium. This involves first replicating the previous successes in code design using this new paradigm, as well as inventing novel codes  in unsolved problems -- requiring novel network architectures that can have application beyond codes. (2) Statistical Property Testing with Deep-Learning: How deep-learning can help in information estimation (such as mutual-information estimation) and statistical property testing (such as independence testing) will be studied. Solutions to high-dimensional property testing will require novel p-value guarantees, which will be explored. (3) Information-theoretic Underpinnings of Deep-Learning: The fundamental information theoretic principles underlying deep-learning, such as the sample complexity and optimal training algorithms for recurrent neural networks will be studied.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sreeram",
   "pi_last_name": "Kannan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sreeram Kannan",
   "pi_email_addr": "ksreeram@uw.edu",
   "nsf_id": "000727520",
   "pi_start_date": "2019-06-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "4333 Brooklyn Ave NE",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981950001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 458388.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 2\">\n<div class=\"section\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>Information theory provides the mathematical underpinning on how to optimally communicate, compresss and processinformation. The underlying algorithms, including codes for communication, have been invented using human ingenuity and proved to be optimal using deep mathematical reasoning. The rise of deep learning methods presents an opportunity to revisit the paradigm for discovering new algorithms. In this project, we studied how to utilize deep-learning for accelerating algorithm discovery in long-standing information-theoretic problems, as well as applied information theoretic methods to deep learning.\ufffd</span></p>\n<p>The project made progress on two major directions:</p>\n<p><span>(1) Deep Learning based Code Design: The project proposed several new error correcting codes invented via deep learning. The series of works produced from this research direction have had significant impact on the research direction, with papers in this thrust garnering a total of over 200 research citations.\ufffd</span></p>\n<p>(2) Information theoretic methods for deep learning: Ideas from information theory were utlized for improving deep learning algorithms. Novel methods for neural network based estimators for information theoretic quantities were built, and applied to genomic datasets. As one example in this direction, Scrambler networks were proposed which can interpret the importance of each DNA nucleotide in making predictions about how the correpsonding proteins fold (this paper was published in Nature Machine Intelligence). Finally, personalization protocols for federated learning were studied, which brought information theoretic methods to empower machine learning methods across multiple users without data leaving the user devices. A key paper in this direction garnered more than 500 citations demonstrating significant research impact.\ufffd</p>\n<p>The project has produced several educational materials at the intersection of \"Deep learning and Information Theory,\" including tutorials on this subject at research conferences. The project also enabled training of phd students who have gone on to take industrial research roles in the intersection of deep learning and information theory.\ufffd</p>\n<p>\ufffd</p>\n</div>\n</div>\n</div>\n</div><br>\n<p>\n Last Modified: 02/26/2024<br>\nModified by: Sreeram&nbsp;Kannan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\n\nInformation theory provides the mathematical underpinning on how to optimally communicate, compresss and processinformation. The underlying algorithms, including codes for communication, have been invented using human ingenuity and proved to be optimal using deep mathematical reasoning. The rise of deep learning methods presents an opportunity to revisit the paradigm for discovering new algorithms. In this project, we studied how to utilize deep-learning for accelerating algorithm discovery in long-standing information-theoretic problems, as well as applied information theoretic methods to deep learning.\ufffd\n\n\nThe project made progress on two major directions:\n\n\n(1) Deep Learning based Code Design: The project proposed several new error correcting codes invented via deep learning. The series of works produced from this research direction have had significant impact on the research direction, with papers in this thrust garnering a total of over 200 research citations.\ufffd\n\n\n(2) Information theoretic methods for deep learning: Ideas from information theory were utlized for improving deep learning algorithms. Novel methods for neural network based estimators for information theoretic quantities were built, and applied to genomic datasets. As one example in this direction, Scrambler networks were proposed which can interpret the importance of each DNA nucleotide in making predictions about how the correpsonding proteins fold (this paper was published in Nature Machine Intelligence). Finally, personalization protocols for federated learning were studied, which brought information theoretic methods to empower machine learning methods across multiple users without data leaving the user devices. A key paper in this direction garnered more than 500 citations demonstrating significant research impact.\ufffd\n\n\nThe project has produced several educational materials at the intersection of \"Deep learning and Information Theory,\" including tutorials on this subject at research conferences. The project also enabled training of phd students who have gone on to take industrial research roles in the intersection of deep learning and information theory.\ufffd\n\n\n\ufffd\n\n\n\n\t\t\t\t\tLast Modified: 02/26/2024\n\n\t\t\t\t\tSubmitted by: SreeramKannan\n"
 }
}