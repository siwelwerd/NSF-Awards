{
 "awd_id": "1915065",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SCH: INT: Collaborative Research: Detection, Assessment and Rehabilitation of Stroke-Induced Visual Neglect Using Augmented Reality (AR) and Electroencephalography (EEG)",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 394163.0,
 "awd_amount": 394163.0,
 "awd_min_amd_letter_date": "2019-07-30",
 "awd_max_amd_letter_date": "2019-07-30",
 "awd_abstract_narration": "Unilateral spatial neglect is a perceptual disorder that is one of the most common consequences of right-side brain damage after stroke, occurring in 29% of the 15 million people who sustain stroke worldwide. Patients with neglect demonstrate inattention to objects or events on the side that is opposite to the damaged part of the brain. They often miss food on one side of the plate, missing words on one side of the page, bumping into the left door jamb, getting confused by moving objects, and being fearful of walking in crowded places. The current gold standard for detecting and rehabilitating neglect lacks generalizability to dynamic tasks and contexts encountered during activities of daily living (ADL). The investigators in this project will develop a brain-computer interface (BCI) system that will be implemented in augmented reality (AR) environment for detection, assessment and rehabilitation of unilateral neglect during ADL.  More specifically, the system will in real-time monitor the brain activity recorded through electroencephalography (EEG) for the detection and assessment of visually neglected extra-personal space. Moreover, the system will also include haptic, auditory and visual stimulation while the users are engaged in real-world tasks conducted during rehabilitation for reducing neglect-related disabilities. It is also anticipated that the novel scientific discoveries and engineering enhancements of this project will have effects on the current practice on BCIs: (i) enabling design and implementation of such systems in more naturalistic environments providing more immersive experiences; and (ii) expansion of the use of BCIs in the design of intervention and rehabilitation techniques for other neurological disorders. This project will promote STEM education and provide rigorous training and variety of hands-on experiences to researchers from K-12 to graduate level.\r\n\r\nThe research objective of this project is to introduce a prototype for stroke-induced neglect detection, assessment, and rehabilitation system, featuring: (i) seamless integration of EEG and AR in the design of visually evoked EEG-based BCIs to operate during activities of daily living; (ii) accurate and continuous EEG event related potential detection for neglect assessment and mapping through Bayesian inference models; (iii) information theoretic optimum design of neglect intervention focusing on activities of daily living; and (iv) multimodal real-time feedback for rehabilitation of neglect related disabilities during intervention. Unlike the common computerized neglect assessment methods, EEG will not require any physical responses from the patient. Also, the use of EEG permits automation, making it an ideal method to guide a personalized and automated neglect intervention. It is known that one common element among the existing interventions that have shown promise for reducing neglect is multimodal stimulation to the neglected side of the body or environment. Timely feedback to the user when neglect is detected during the continuous EEG monitoring will enable this stimulation. Finally, used in conjunction with AR headset and skill-based training during acute inpatient rehabilitation, the planned system will provide the opportunity to deliver high-intensity repetitive stimulation with progression during meaningful everyday activities. The outcomes of this project will be disseminated to the scientific community through technical reports,  journal publications and conference presentations. All software developed through this project will be publicly available through archival repositories.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sarah",
   "pi_last_name": "Ostadabbas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sarah Ostadabbas",
   "pi_email_addr": "ostadabbas@ece.neu.edu",
   "nsf_id": "000704085",
   "pi_start_date": "2019-07-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Avenue",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  },
  {
   "pgm_ref_code": "8062",
   "pgm_ref_txt": "SCH Type II: INT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 394163.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Unilateral spatial neglect is a perceptual disorder that is one of the most common consequences of right-side brain damage after stroke, occurring in 29% of the 15 million people who sustain stroke worldwide. Patients with neglect demonstrate inattention to objects or events on the side that is opposite to the damaged part of the brain. They often get confused by moving objects and are fearful of walking in crowded places. The current gold standard for detecting and rehabilitating neglect lacks generalizability to dynamic tasks and contexts encountered during activities of daily living (ADL). This project includes the University of Pittsburgh and Northeastern University as collaborating institutions, and aim is to develop a brain-computer interface system that will be implemented in an augmented reality (AR) environment for detection, assessment and rehabilitation of unilateral visual neglect during ADL which we denote as the AREEN system.&nbsp; The AREEN system in real-time monitors the brain activity recorded through electroencephalography (EEG) for the detection and assessment of visually neglected extra-personal space of stroke patients. The AREEN system could be used to supplement traditional clinical assessments such as the BIT-C to improve neglect detection accuracy. The outcomes may also extend to other areas of interest such as identification of cognitive impairments, including attention deficits and executive function impairments. Attention and executive function impairments are prevalent among many clinical populations including individuals with learning and developmental disabilities, brain injury, hypoxia, and neurodegenerative disorders.</p>\r\n<p>This project supported a total of 5 PhD students at the collaborating institutions with different levels of support between September 2019 and August 2024. The research resulted in a total of 9 refereed articles (6 journal and 3 conference).&nbsp; Developed AREEN system is illustrated in Figure 1. EEG data were collected using the AREEN system from 21 stroke patients (University of Pittsburgh IRB STUDY19060390).&nbsp; 11 stroke patients had neglect (SN) and 10 of them were without neglect (WSN). Each participant attended to two sessions of data collection, and completed two tests in each session based on visual stimuli presentation on the AR (Hololens) canvas through a modified Starry Night paradigm:&nbsp; (1) Clicker-Based Assessment for EEG data ground truth generation by identifying the neglected locations in response to the visual stimuli; and (2) EEG-Based Assessment to assess both existence and severity of neglect by analyzing the recorded participant EEG in response to visual stimuli. For neglect detection we developed a scalable, plug-and-play system that can be used by any stroke patient to diagnose neglect in a clinical setting. Accordingly, we explored both statistical and machine learning models to identify the optimal algorithm for neglect detection. For neglect detection, bandpowers for delta (0-4 Hz), theta (5-8 Hz), alpha (9-13 Hz), beta (14-30 Hz), and gamma (31-45 Hz) bands were calculated for each EEG signal extracted time-locked to the presentation of each visual stimulus and corrected using a baseline segment at each electrode channel. The powers of the ipsilesional responses and contralesional responses were combined from all the participants in this analysis.&nbsp; At each electrode-band location, a power ratio was calculated such that each ipsilesional response power was divided by the average contralesional response power.&nbsp; The log of these ratios was taken for analyses.&nbsp; This ratio represents neural activation in the ipsilesional response normalized with respect to the average contralesional response (Figure 2).&nbsp; The significant (p&lt;0.05) electrode-band locations are spatial-spectral features that were used as the features in the following models for binary classification (neglect or no neglect): logistic regression, linear discriminant analysis, random forest, and boosted tree. The models were cross-validated and boosted tree was the method that demonstrated the highest performance up to 80% accuracy of identifying stroke patients with neglect. To estimate patient-specific neglected visual field of view (FOV), we developed a neural network architecture (ESTNet) to analyze the EEG data time synchronized to the presentation of the target stimuli based on the above-mentioned Starry Night paradigm. ESTNet was based on two parallel deep convolutional neural networks that were finally fused and combined in a Bayesian manner with the output of the Clicker-based Assessment to generate the visual maps for each stroke patients with neglect (Figure 3). Additionally, ESTNet enables interpretation of the contributions of time and frequency domain EEG data in neglected FOV estimation (Figure 4).&nbsp;&nbsp; Estimated FOV demonstrates the extent of neglect for each stroke patient (Figure 5), which is a novel contribution to the existing neglect detection methods. ESTNet achieved average accuracy: 79.62%, specificity: 86.36% and sensitivity: 76.71% for neglected FOV estimation, and results were very promising when we compared the ESTNet with other state-of-the-art neural network architectures. Our team also was awarded an NSF PFI grant (# 2234346) in 2023 to work on the commercialization of the AREEN system, incorporating best practices from rehabilitation intervention research and state-of-the-art technologies that will be cost-effective to be implemented in rehabilitation clinics.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/10/2024<br>\nModified by: Sarah&nbsp;Ostadabbas</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859059331_Figure1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859059331_Figure1--rgov-800width.png\" title=\"Figure1\"><img src=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859059331_Figure1--rgov-66x44.png\" alt=\"Figure1\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Participant experimental set up with the AREEN system, participant performing task in a hospital room. The room is still visible through the HoloLens; the task is digitally overlaid.</div>\n<div class=\"imageCredit\">Figure1</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Sarah&nbsp;Ostadabbas\n<div class=\"imageTitle\">Figure1</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859151758_Figure3--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859151758_Figure3--rgov-800width.png\" title=\"Figure 3\"><img src=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859151758_Figure3--rgov-66x44.png\" alt=\"Figure 3\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A general flowchart of patient-specific neglected field of view (FOV) estimation using a time and frequency based deep learning architecture (ESTNet) and FOV correction including a representational drawing of ESTNet. Output class is either neglect or no-neglect.</div>\n<div class=\"imageCredit\">Figure 3</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Sarah&nbsp;Ostadabbas\n<div class=\"imageTitle\">Figure 3</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859229677_Figure5--rgov-214x142.PNG\" original=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859229677_Figure5--rgov-800width.PNG\" title=\"Figure 5\"><img src=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859229677_Figure5--rgov-66x44.PNG\" alt=\"Figure 5\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The estimated neglected field of view plots from two participants, exemplifying moderate prediction accuracy (a) and high prediction accuracy (b). The grids show the canvas with the 72 locations in which targets appear. The colors correspond to the predictions of \"fast\" or \"slow\" at each l</div>\n<div class=\"imageCredit\">Figure 5</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Sarah&nbsp;Ostadabbas\n<div class=\"imageTitle\">Figure 5</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859193821_Figure4--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859193821_Figure4--rgov-800width.png\" title=\"Figure 4\"><img src=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859193821_Figure4--rgov-66x44.png\" alt=\"Figure 4\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Top: Average saliency maps for a) time domain and over 50ms long windows and b) frequency domain EEG data over EEG bands delta (0-4Hz), theta (0-8Hz), alpha (8-13Hz), beta (13-30Hz) and gamma (30-40 Hz) for ESTNet. Bottom: Topography maps per frequency bands based on model gradients.</div>\n<div class=\"imageCredit\">Figure 4</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Sarah&nbsp;Ostadabbas\n<div class=\"imageTitle\">Figure 4</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859095061_Figure2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859095061_Figure2--rgov-800width.png\" title=\"Figure 2\"><img src=\"/por/images/Reports/POR/2024/1915065/1915065_10627662_1733859095061_Figure2--rgov-66x44.png\" alt=\"Figure 2\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Normalized response to contralesional targets across frequency bands and groups. Brighter colors indicate areas of higher power. Values are a ratio of bandpower of the brain\ufffds response to a target appearing in contralesional space to that of a target appearing in ipsilesional space.</div>\n<div class=\"imageCredit\">Figure 2</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Sarah&nbsp;Ostadabbas\n<div class=\"imageTitle\">Figure 2</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nUnilateral spatial neglect is a perceptual disorder that is one of the most common consequences of right-side brain damage after stroke, occurring in 29% of the 15 million people who sustain stroke worldwide. Patients with neglect demonstrate inattention to objects or events on the side that is opposite to the damaged part of the brain. They often get confused by moving objects and are fearful of walking in crowded places. The current gold standard for detecting and rehabilitating neglect lacks generalizability to dynamic tasks and contexts encountered during activities of daily living (ADL). This project includes the University of Pittsburgh and Northeastern University as collaborating institutions, and aim is to develop a brain-computer interface system that will be implemented in an augmented reality (AR) environment for detection, assessment and rehabilitation of unilateral visual neglect during ADL which we denote as the AREEN system. The AREEN system in real-time monitors the brain activity recorded through electroencephalography (EEG) for the detection and assessment of visually neglected extra-personal space of stroke patients. The AREEN system could be used to supplement traditional clinical assessments such as the BIT-C to improve neglect detection accuracy. The outcomes may also extend to other areas of interest such as identification of cognitive impairments, including attention deficits and executive function impairments. Attention and executive function impairments are prevalent among many clinical populations including individuals with learning and developmental disabilities, brain injury, hypoxia, and neurodegenerative disorders.\r\n\n\nThis project supported a total of 5 PhD students at the collaborating institutions with different levels of support between September 2019 and August 2024. The research resulted in a total of 9 refereed articles (6 journal and 3 conference). Developed AREEN system is illustrated in Figure 1. EEG data were collected using the AREEN system from 21 stroke patients (University of Pittsburgh IRB STUDY19060390). 11 stroke patients had neglect (SN) and 10 of them were without neglect (WSN). Each participant attended to two sessions of data collection, and completed two tests in each session based on visual stimuli presentation on the AR (Hololens) canvas through a modified Starry Night paradigm: (1) Clicker-Based Assessment for EEG data ground truth generation by identifying the neglected locations in response to the visual stimuli; and (2) EEG-Based Assessment to assess both existence and severity of neglect by analyzing the recorded participant EEG in response to visual stimuli. For neglect detection we developed a scalable, plug-and-play system that can be used by any stroke patient to diagnose neglect in a clinical setting. Accordingly, we explored both statistical and machine learning models to identify the optimal algorithm for neglect detection. For neglect detection, bandpowers for delta (0-4 Hz), theta (5-8 Hz), alpha (9-13 Hz), beta (14-30 Hz), and gamma (31-45 Hz) bands were calculated for each EEG signal extracted time-locked to the presentation of each visual stimulus and corrected using a baseline segment at each electrode channel. The powers of the ipsilesional responses and contralesional responses were combined from all the participants in this analysis. At each electrode-band location, a power ratio was calculated such that each ipsilesional response power was divided by the average contralesional response power. The log of these ratios was taken for analyses. This ratio represents neural activation in the ipsilesional response normalized with respect to the average contralesional response (Figure 2). The significant (p\r\n\n\n\t\t\t\t\tLast Modified: 12/10/2024\n\n\t\t\t\t\tSubmitted by: SarahOstadabbas\n"
 }
}