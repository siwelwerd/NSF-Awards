{
 "awd_id": "1910803",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Declarative Recursive Computation on a Database System",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2019-08-15",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-08-15",
 "awd_max_amd_letter_date": "2019-08-15",
 "awd_abstract_narration": "Machine learning (ML) will have a huge economic and scientific impact over the upcoming decades. But despite the growing importance of ML, there has been relatively little work focused on asking what systems to support machine learning should look like. The result is that it is difficult to apply ML to non-standard cases: Big Data, large or complex models that take a long time to train or require more RAM than is available on a graphics processing unit (GPU), or learning problems with hard training time constraints, to name a few. The proposed project aims to address such deficiencies by applying ideas from relational database systems to the design and implementation of systems for ML.  Building an ML system on top of a relational-style engine will enable the design of ML systems that are able to automatically generate compute plans for specific ML tasks with little programmer effort.  Those plans will be optimized and executed to match the data size, layout, and the compute hardware. The code to implement an ML algorithm will be the same no matter whether the computation is run on a local machine, or in a distributed environment.  If successful, the project will radically expand the ease-of-use and applicability of ML.\r\n\r\nThere are a number of technical questions that need to be answered for ML computations to be run on top of a relational system, and answering such questions will be at the heart of the project.  For example: How can ML primitives (convolutions, recurrent modules, etc.) be mapped onto relational primitives?  How can large objects (matrices/tensors) be chucked into records so relational implementations run efficiently?  And since a developer of ML algorithms is unlikely to accept SQL as a programming language: How to translate Karas-like Python programs into relational algebra?\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Jermaine",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher M Jermaine",
   "pi_email_addr": "Christopher.m.jermaine@rice.edu",
   "nsf_id": "000439407",
   "pi_start_date": "2019-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "William Marsh Rice University",
  "inst_street_address": "6100 MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "Houston",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7133484820",
  "inst_zip_code": "770051827",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "TX09",
  "org_lgl_bus_name": "WILLIAM MARSH RICE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "K51LECU1G8N3"
 },
 "perf_inst": {
  "perf_inst_name": "Rice University",
  "perf_str_addr": "6100 Main St",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "770051827",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "TX09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">Over the four years of the project, machine learning (ML) and artificial intelligence (AI) have grown in importance, especially with the advent of generative AI. At the same time, ML/AI models have grown more complex and much larger, as have the computational demands for running the models. It is now common for the largest models to have hundreds of billions of parameters, and to need large numbers of expensive processors (such as GPUs) to run effectively.</p>\n<p class=\"p1\">However, widely-used computer systems for ML/AI such as PyTorch and TensorFlow have not changed fundamentally over the last few years,. As a result, it has bcome increasingly difficult to run the most modern models on standard hardware. Problems such as out-of-memory errors plague ML/AI programmers. As models grow in sizr and complexity, it has become much harder and also far more important to figure out how to effectively use multiple machines to run the models.</p>\n<p class=\"p1\">This project has generated research results that point to a new paradigm for ML/AI system design, where a programmer specifies the ML/AI model at a high level, using a programming language that simply describes the mathematics that needs to be performed to execute the model. Then, the system analyzes the math and automatically figures out how to decompose the mathematical computation into parts. The system maps those parts to machines in such a way as to avoid costly communication, and to avoid out-of-memory problems, and ensure efficient utilization of the hardware. In contrast to existing systems such as PyTorch and TensorFlow, the system simply ``figures it out&rsquo;&rsquo; with minimal human involvment. This could have the effect of democratizing access and use of the largest, most effective ML/AI models, by allowing more individuals and organizations to use them effectively, even on limited hardware.</p><br>\n<p>\n Last Modified: 02/01/2024<br>\nModified by: Christopher&nbsp;M&nbsp;Jermaine</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nOver the four years of the project, machine learning (ML) and artificial intelligence (AI) have grown in importance, especially with the advent of generative AI. At the same time, ML/AI models have grown more complex and much larger, as have the computational demands for running the models. It is now common for the largest models to have hundreds of billions of parameters, and to need large numbers of expensive processors (such as GPUs) to run effectively.\n\n\nHowever, widely-used computer systems for ML/AI such as PyTorch and TensorFlow have not changed fundamentally over the last few years,. As a result, it has bcome increasingly difficult to run the most modern models on standard hardware. Problems such as out-of-memory errors plague ML/AI programmers. As models grow in sizr and complexity, it has become much harder and also far more important to figure out how to effectively use multiple machines to run the models.\n\n\nThis project has generated research results that point to a new paradigm for ML/AI system design, where a programmer specifies the ML/AI model at a high level, using a programming language that simply describes the mathematics that needs to be performed to execute the model. Then, the system analyzes the math and automatically figures out how to decompose the mathematical computation into parts. The system maps those parts to machines in such a way as to avoid costly communication, and to avoid out-of-memory problems, and ensure efficient utilization of the hardware. In contrast to existing systems such as PyTorch and TensorFlow, the system simply ``figures it out with minimal human involvment. This could have the effect of democratizing access and use of the largest, most effective ML/AI models, by allowing more individuals and organizations to use them effectively, even on limited hardware.\t\t\t\t\tLast Modified: 02/01/2024\n\n\t\t\t\t\tSubmitted by: ChristopherMJermaine\n"
 }
}