{
 "awd_id": "1919130",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SPX: Collaborative Research: Intelligent Communication Fabrics to Facilitate Extreme Scale Computing",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 440536.0,
 "awd_amount": 456536.0,
 "awd_min_amd_letter_date": "2019-08-26",
 "awd_max_amd_letter_date": "2020-07-13",
 "awd_abstract_narration": "Advances in High-Performance Computing over the last several decades have enabled various important applications throughout science and engineering. Semiconductor technology increasingly faces fundamental physical limits. New approaches to hardware/software co-design are now achieving higher performance at extreme scales. This project will explore two new approaches: configurability and integration. Configurability enables hardware to map better to applications. Integration enables system components that have generally been single function to gain additional functionality. An example is a network for the transport of data. Such a network might also operate on that data as it is being transported. Integration enables compute everywhere in the architecture and network. Configurability and integration will lead to much more efficient use of computing resources. Such resources include high-performance computers. Another focus of this project will be in the use of Field Programmable Gate Arrays (FPGAs). FPGAs are a widely used type of integrated circuit. In FPGAs the hardware can be configured to match the application. FPGAs will allow the deployment of the research products into production systems. They will also allow evaluation of changes in system design. This work will advance extreme-scale computing applications. Such applications include medicine and new drug discovery. This project will also include training of graduate and undergraduate students. It will focus on students belonging to groups underrepresented in STEM disciplines\r\n\r\nThe central theme of this project is that emerging centrality of hardware configurability and integration means that at least two old systems abstractions must be broken. First, this project will demonstrate that computation and communication should no longer comprise separate silos. Second, it will demonstrate that applications should no longer be mapped to fixed hardware. In their place, new hardware-software abstractions must necessarily be built around the idea of the application-centric system. This project will identify new computing modes -- computation distribution/offload and configurable hardware -- that will be application aware with tight mapping of applications to computer systems. This improved mapping, in turn, will require deploying a number of mechanisms, starting with improved compilers and high-quality application libraries but extending to lighter-weight yet intelligent middleware (for instance, improved Message Passing Interface middleware), automated application modification, dynamic autotuning, and machine learning assisting in all of these components.   The project will consider all of these concerns in due course.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Martin",
   "pi_last_name": "Herbordt",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Martin C Herbordt",
   "pi_email_addr": "herbordt@bu.edu",
   "nsf_id": "000112548",
   "pi_start_date": "2019-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Trustees of Boston University",
  "inst_street_address": "1 SILBER WAY",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173534365",
  "inst_zip_code": "022151703",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "TRUSTEES OF BOSTON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "THL6A6JLE1S7"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of Boston University",
  "perf_str_addr": "881 Commonwealth Avenue",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "022151300",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 440536.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Advances in High-Performance Computing over the last several decades have enabled various important applications throughout science and engineering and also the emergence of Artificial Intelligence (AI) and Machine Learning (ML). Semiconductor technology increasingly faces fundamental physical limits. New approaches to hardware/software co-design are now achieving higher performance at extreme scales. This project explored two new approaches: configurability and integration. Configurability enables hardware to map better to applications. Integration enables system components that have generally been single function to gain additional functionality. An example is a network for the transport of data. Such a network might also operate on that data as it is being transported. Integration enables compute everywhere in the architecture and network. Configurability and integration lead to much more efficient use of computing resources. Such resources include high-performance computers. This work advances extreme-scale computing applications. Such applications include medicine and new drug discovery, AI and ML, and performing such computations in such a way that privacy of shared data is preserved. This project has also trained graduate and undergraduate students.</p>\r\n<p>The central theme of this project is that the emerging centrality of hardware configurability and integration means that old system abstractions must be broken. The project demonstrates that computation and communication should no longer comprise separate silos. This integration has numerous advantages. For example, data in different parts of the system that must be combined need not be sent to compute nodes for processing. Rather, this combining can be done in the network while the data are being transferred. The overall benefits are that the time spent on communication is reduced, as is the overall volume of data that needs to be transferred over the network. The first of these leads to to improved computation times, which enable getting higher quality solutions more quickly. The second reduces certain network requirements, and therefore the network cost, and also the energy required per computation.</p>\r\n<p>The research had several aspects or thrusts, all of which resulted in both fundamental findings and practical extensions, including follow-on collaborations with various industrial and national lab partners.</p>\r\n<p>The first was to develop new capabilities for communication devices that integrate computation. It had two parts. The first was to augment ordinary network switches to support application processing. There were a number of advances. The first was to allow the programmer to specify complex operations. The second was to allow complex data flows. The third was to enable the fusion of multiple communication operations. The fourth was to enable the network itself to control the computation. &nbsp;The second new capability was to improve the interface between the compute elements and the network. A goal was to improve the efficiency of computations involving large amounts of complex data as are needed when creating AI applications. Our solution is for the interface itself to be the center of control by serving as an intermediate layer that seamlessly connects the heterogeneous compute components.</p>\r\n<p>The second thrust was to create software that supports these new capabilities without the need for programmer intervention. This software automatically extracts from user code the operations to be executed by the network components. It then integrates these operations into existing support software such as the Message Passing Interface (MPI). Finally, it delivers instructions to the network components about the processing that needs to be done.</p>\r\n<p>The third thrust was to improve the benefits of the augmented networks by increasing the execution efficiency of distributed applications. We created software that executes in the background at runtime and provides fungibility for unused compute cycles. This is done without degrading the performance of the applications already running.</p>\r\n<p>The fourth thrust was to demonstrate these new technologies by creating testbeds and model applications. The latter included modeling molecules for drug discovery and machine learning such as for building recommendation systems.</p>\r\n<p>The broader impacts, besides the technical broader impacts already described, include training and outreach. Supported directly by this project were four graduate students, six undergraduates, and one high school student.</p><br>\n<p>\n Last Modified: 02/08/2025<br>\nModified by: Martin&nbsp;C&nbsp;Herbordt</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nAdvances in High-Performance Computing over the last several decades have enabled various important applications throughout science and engineering and also the emergence of Artificial Intelligence (AI) and Machine Learning (ML). Semiconductor technology increasingly faces fundamental physical limits. New approaches to hardware/software co-design are now achieving higher performance at extreme scales. This project explored two new approaches: configurability and integration. Configurability enables hardware to map better to applications. Integration enables system components that have generally been single function to gain additional functionality. An example is a network for the transport of data. Such a network might also operate on that data as it is being transported. Integration enables compute everywhere in the architecture and network. Configurability and integration lead to much more efficient use of computing resources. Such resources include high-performance computers. This work advances extreme-scale computing applications. Such applications include medicine and new drug discovery, AI and ML, and performing such computations in such a way that privacy of shared data is preserved. This project has also trained graduate and undergraduate students.\r\n\n\nThe central theme of this project is that the emerging centrality of hardware configurability and integration means that old system abstractions must be broken. The project demonstrates that computation and communication should no longer comprise separate silos. This integration has numerous advantages. For example, data in different parts of the system that must be combined need not be sent to compute nodes for processing. Rather, this combining can be done in the network while the data are being transferred. The overall benefits are that the time spent on communication is reduced, as is the overall volume of data that needs to be transferred over the network. The first of these leads to to improved computation times, which enable getting higher quality solutions more quickly. The second reduces certain network requirements, and therefore the network cost, and also the energy required per computation.\r\n\n\nThe research had several aspects or thrusts, all of which resulted in both fundamental findings and practical extensions, including follow-on collaborations with various industrial and national lab partners.\r\n\n\nThe first was to develop new capabilities for communication devices that integrate computation. It had two parts. The first was to augment ordinary network switches to support application processing. There were a number of advances. The first was to allow the programmer to specify complex operations. The second was to allow complex data flows. The third was to enable the fusion of multiple communication operations. The fourth was to enable the network itself to control the computation. The second new capability was to improve the interface between the compute elements and the network. A goal was to improve the efficiency of computations involving large amounts of complex data as are needed when creating AI applications. Our solution is for the interface itself to be the center of control by serving as an intermediate layer that seamlessly connects the heterogeneous compute components.\r\n\n\nThe second thrust was to create software that supports these new capabilities without the need for programmer intervention. This software automatically extracts from user code the operations to be executed by the network components. It then integrates these operations into existing support software such as the Message Passing Interface (MPI). Finally, it delivers instructions to the network components about the processing that needs to be done.\r\n\n\nThe third thrust was to improve the benefits of the augmented networks by increasing the execution efficiency of distributed applications. We created software that executes in the background at runtime and provides fungibility for unused compute cycles. This is done without degrading the performance of the applications already running.\r\n\n\nThe fourth thrust was to demonstrate these new technologies by creating testbeds and model applications. The latter included modeling molecules for drug discovery and machine learning such as for building recommendation systems.\r\n\n\nThe broader impacts, besides the technical broader impacts already described, include training and outreach. Supported directly by this project were four graduate students, six undergraduates, and one high school student.\t\t\t\t\tLast Modified: 02/08/2025\n\n\t\t\t\t\tSubmitted by: MartinCHerbordt\n"
 }
}