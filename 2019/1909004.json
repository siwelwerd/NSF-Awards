{
 "awd_id": "1909004",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS Core: Small: A Multi-Stakeholder Integrated Approach to Reduce Tail Latency Using Heterogeneity",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-07-23",
 "awd_max_amd_letter_date": "2019-07-23",
 "awd_abstract_narration": "There are many different types of computer hardware.  Examples include mobile cell phone processors, machine learning accelerators, traditional server processors, gaming platforms, and so forth, but these resources are specialized and primarily utilized within a single domain. As cloud computing providers broaden their markets and start offering more types of hardware, it opens an opportunity to design heterogeneity-aware computing systems, which combine different types of resources that are synergistic. This research will investigate techniques for intentionally utilizing heterogeneity as a controllable parameter for improving performance. Specifically, the research will focus on the tail latency performance metric, which has been identified by industry as an important performance metric affecting the responsiveness of user-facing Internet services. To deploy and harness the right heterogeneity at the right time, this research will consider the unique problems faced by three key stakeholders (Application Deployer, Resource Manager, and Infrastructure Provider). From the Application Deployer's perspective, the research will consider how to decompose an application into phases/sub-components that can benefit from different types of resources. From the Resource Manager's perspective, the research will determine the right quantity and mixture of resource types as well as how to schedule across these resources to minimize tail latency. From the Infrastructure Provider's perspective, the research will consider issues arising from sharing a mixture of different resources between multiple applications. Additionally, the research will leverage cross-stakeholder information towards a unified strategy for deploying and harnessing heterogeneity.\r\n\r\nThis research will be applicable to both providers of data centers, such as cloud providers, as well as businesses that use that infrastructure. For the provider, the research can improve the performance and lower the cost of data centers, which are critical components of the national infrastructure and economy. For the user, the research can enable emerging interactive applications, such as complex data analytics and real-time machine learning, to achieve high performance at low cost. This research promotes using diverse mixtures of resources, which could spur the development of new types of hardware and software. In addition to the broader research impacts, there is a plan to enhance the undergraduate and graduate courses with ideas and software generated by this research.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "Zhu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy Zhu",
   "pi_email_addr": "tuz68@psu.edu",
   "nsf_id": "000761675",
   "pi_start_date": "2019-07-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Anand",
   "pi_last_name": "Sivasubramaniam",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anand Sivasubramaniam",
   "pi_email_addr": "axs53@psu.edu",
   "nsf_id": "000258710",
   "pi_start_date": "2019-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "110 Technology Center Building",
  "perf_city_name": "University Park",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168027000",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "PA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Intentionally utilizing a diverse and heterogeneous mixture of hardware and/or software resources can lead to more efficient system designs, both in terms of cost and performance. This project's research has produced multiple heterogeneous system designs that demonstrate these benefits in terms of managing resources, developing applications, and providing infrastructure.<br /><br />In terms of managing resources, the research has developed two techniques for optimizing cost and performance using heterogeneity. In the fast and frugal work, the results show how to determine the right mixture of fast, expensive resources with cheap, slow resources along with how to schedule a workload across these resources. With this technique, the performance (e.g., tail latency metric) can be improved by as much as 45% while maintaining a fixed cost budget. In the AutoBurst work, the research shows how to integrate a cheap, but limited cloud resource type known as burstable instances with regular instances. While maintaining latency performance goals, AutoBurst has been shown to reduce cost by up to 25% over the state-of-the-art solution.<br /><br />In terms of developing applications, the research has developed two approaches for effectively utilizing both GPU and CPU resources. In the SIR+ work, the research shows how to take existing deep learning inference workloads and spread the tasks across both types of resources. The results demonstrate improvement in performance (&gt; 10% latency improvement, &gt; 19% throughput improvement) and memory cost (&gt; 9.8% GPU memory usage savings). In the SplitRPC work, the research expands to consider networking resources in addition to GPU and CPU resources. With the growth in smart networking hardware, there is potential for optimizing the transport and execution of GPU-based workloads, and the research demonstrates that smart networking, GPU, and CPU resources all need to work in conjunction to operate effectively. The research shows how traditional approaches that transfer data from the network to the CPU and then the GPU is inefficient due to multiple data transfers. State-of-the-art approaches that directly transfer data from the network to the GPU are also inefficient due to limitations in launching workloads on the GPU. SplitRPC shows how the heterogeneous combination of GPU and CPU resources is ideal, with the control path data being&nbsp;transferred to the CPU and the datapath data being&nbsp;transferred directly to the GPU, resulting in 52% improvements for execution time and up to 2.4x gains in throughput.<br /><br />In terms of providing infrastructure, this project has supported a research collaboration with Microsoft Azure for managing the heterogeneity in their large cloud infrastructure. In this Kerveros work, the research develops a novel admission control system that can effectively manage high degrees of heterogeneity to provide scalable and accurate admission control decisions. The system has been successfully deployed in Microsoft Azure. In the Deep Neural Network estimation work, the research develops a new methodology for estimating the performance of this popular class of workloads. The estimation methodology is suitable across diverse hardware platforms, including hypothetical hardware that may not exist. This provides a good first order approximation that can help infrastructure providers decide what types of hardware to procure or develop in the future and what types of heterogeneity would be beneficial.<br /><br />This project's research has resulted in the development and evaluation of multiple ideas for intentionally utilizing heterogeneity to improve the performance and/or cost of datacenter applications. One of these has been integrated and deployed in the large Microsoft Azure cloud infrastructure, and research prototypes have been released as open-source software for any interested parties to apply to their applications and systems. The project has also resulted in enhancing the PIs' courses where heterogeneity concepts and ideas have been introduced in lectures and assignments. This project has supported many students' research at both the graduate and undergraduate levels.</p><br>\n<p>\n Last Modified: 12/27/2024<br>\nModified by: Timothy&nbsp;Zhu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIntentionally utilizing a diverse and heterogeneous mixture of hardware and/or software resources can lead to more efficient system designs, both in terms of cost and performance. This project's research has produced multiple heterogeneous system designs that demonstrate these benefits in terms of managing resources, developing applications, and providing infrastructure.\n\nIn terms of managing resources, the research has developed two techniques for optimizing cost and performance using heterogeneity. In the fast and frugal work, the results show how to determine the right mixture of fast, expensive resources with cheap, slow resources along with how to schedule a workload across these resources. With this technique, the performance (e.g., tail latency metric) can be improved by as much as 45% while maintaining a fixed cost budget. In the AutoBurst work, the research shows how to integrate a cheap, but limited cloud resource type known as burstable instances with regular instances. While maintaining latency performance goals, AutoBurst has been shown to reduce cost by up to 25% over the state-of-the-art solution.\n\nIn terms of developing applications, the research has developed two approaches for effectively utilizing both GPU and CPU resources. In the SIR+ work, the research shows how to take existing deep learning inference workloads and spread the tasks across both types of resources. The results demonstrate improvement in performance ( 10% latency improvement,  19% throughput improvement) and memory cost ( 9.8% GPU memory usage savings). In the SplitRPC work, the research expands to consider networking resources in addition to GPU and CPU resources. With the growth in smart networking hardware, there is potential for optimizing the transport and execution of GPU-based workloads, and the research demonstrates that smart networking, GPU, and CPU resources all need to work in conjunction to operate effectively. The research shows how traditional approaches that transfer data from the network to the CPU and then the GPU is inefficient due to multiple data transfers. State-of-the-art approaches that directly transfer data from the network to the GPU are also inefficient due to limitations in launching workloads on the GPU. SplitRPC shows how the heterogeneous combination of GPU and CPU resources is ideal, with the control path data beingtransferred to the CPU and the datapath data beingtransferred directly to the GPU, resulting in 52% improvements for execution time and up to 2.4x gains in throughput.\n\nIn terms of providing infrastructure, this project has supported a research collaboration with Microsoft Azure for managing the heterogeneity in their large cloud infrastructure. In this Kerveros work, the research develops a novel admission control system that can effectively manage high degrees of heterogeneity to provide scalable and accurate admission control decisions. The system has been successfully deployed in Microsoft Azure. In the Deep Neural Network estimation work, the research develops a new methodology for estimating the performance of this popular class of workloads. The estimation methodology is suitable across diverse hardware platforms, including hypothetical hardware that may not exist. This provides a good first order approximation that can help infrastructure providers decide what types of hardware to procure or develop in the future and what types of heterogeneity would be beneficial.\n\nThis project's research has resulted in the development and evaluation of multiple ideas for intentionally utilizing heterogeneity to improve the performance and/or cost of datacenter applications. One of these has been integrated and deployed in the large Microsoft Azure cloud infrastructure, and research prototypes have been released as open-source software for any interested parties to apply to their applications and systems. The project has also resulted in enhancing the PIs' courses where heterogeneity concepts and ideas have been introduced in lectures and assignments. This project has supported many students' research at both the graduate and undergraduate levels.\t\t\t\t\tLast Modified: 12/27/2024\n\n\t\t\t\t\tSubmitted by: TimothyZhu\n"
 }
}