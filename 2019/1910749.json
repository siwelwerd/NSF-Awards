{
 "awd_id": "1910749",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Collaborative Research: Cost-Efficient Sampling and Estimation from Large-Scale Networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2019-09-07",
 "awd_max_amd_letter_date": "2019-09-07",
 "awd_abstract_narration": "Sampling and estimating structural information from \r\nlarge-scale networks or graphs has been central to our \r\nunderstanding of the network dynamics and its rich set \r\nof applications. Markov Chain Monte Carlo (MCMC) has \r\nbeen the key enabler for a broader context of graph \r\nsampling, including estimating the properties of large \r\ngraphs, sampling the corpus of documents indexed by \r\nsearch engines, sampling records from hidden databases \r\nbehind Web forms, identifying subgraphs of certain \r\ncharacteristics and frequent graph pattern matching. \r\nDespite versatile applications of the MCMC methods and \r\ntheir customized algorithms for analyzing \r\ngraph-structured data in various forms, there still \r\nexist critical challenges and limitations in the \r\nliterature centered around the MCMC methods. One is the \r\n'cost' consumption/constraints associated with the \r\nsampling operation, which limits the size of total \r\nsamples obtained and negatively affects the accuracy of \r\nany estimator based on the obtained samples. Another \r\nlimitation is that the recent advances in MCMC, \r\nespecially built up on favorable non-reversible Markov \r\nchains, cannot be leveraged to the various large-graph \r\nsampling tasks, due to their required global knowledge \r\nof the underlying state space, lack of distribution \r\nimplementation, unconstrained state space, as well as \r\nthe simplified cost assumption. The goal of this research is to fully exploit the \r\npotentials of a set of crawling samplers by making the samplers adaptive and possibly \r\ninteractive on a properly constructed graph domain, to \r\ntranscend the current status-quo in the wide range of \r\ngraph sampling tasks. \r\n\r\nSpecifically, the project aims to: (i) build a theoretical framework to \r\nconstruct a suite of cost-efficient sampling policies \r\nby optimally balancing the tradeoff between the sample \r\nquality and quantity under challenged access \r\nenvironments with a given cost budget, (ii) design a \r\nclass of adaptive random walks by fully exploiting the \r\npast information to achieve minimal temporal \r\ncorrelations over the obtained samples and by \r\ncontrolling the random walks collectively to enable \r\nmaximal space exploration, and (iii) extend the \r\nstandard MCMC toolkits toward faster and more \r\ncost-efficient exploration of feasible \r\nsubgraphs/configurations and computing/optimization on \r\na graph, along with extensive validations to create \r\npractical and usable solutions in reality. This \r\nresearch has a high potential impact on a vast range of \r\nmulti-disciplinary applications, including sampling \r\nlarge-scale graphs for statistical inference and \r\nefficient estimation and randomized algorithms for \r\ncombinatorial optimizations in various disciplines, \r\nwhere the standard MCMC methods have been dominant but \r\nalso constrained our understanding.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Do Young",
   "pi_last_name": "Eun",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Do Young Eun",
   "pi_email_addr": "dyeun@ncsu.edu",
   "nsf_id": "000291413",
   "pi_start_date": "2019-09-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "",
  "perf_city_name": "Raleigh",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276957911",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has focused on developing various efficient algorithms for sampling and estimation over large graphs in multiple application domains. The outcome of this project are as follows.</p>\r\n<p>First, we have developed distributed random-walk-based algorithms to estimate the Fiedler vector of a graph,&nbsp;namely the eigenvector corresponding to the second smallest eigenvalue of a&nbsp;graph Laplacian matrix, as it plays an important role in spectral graph theory with applications to graph partitioning. Such graphs arise in many disciplines including wireless multi-hop networks, social networks, or networked large-scale datasets. Algorithms designed to estimate this quantity usually rely on a priori knowledge of the entire graph, and employ techniques such as graph sparsification and power iterations, which have obvious shortcomings in cases where the graph is unknown, or changing dynamically. To this end, we have developed a framework in which we construct a stochastic process based on a set of interacting random walks on a graph and show that a suitably scaled version of our stochastic process converges to the Fiedler vector for a sufficiently large number of walks. Like other techniques based on exploratory random walks and on-the-fly computations, such as Markov Chain Monte Carlo (MCMC), our algorithm overcomes challenges typically faced by power iteration-based approaches. But, unlike any existing random walk-based method such as MCMCs where the focus is on the leading eigenvector, our framework with interacting random walks converges to the Fiedler vector (second eigenvector).</p>\r\n<p>Second, partially motivated by our earlier investigation into the multi-armed bandit approach for opportunistic spectrum access (OSA) and general online optimization methods, we have also looked into the general purpose of stochastic gradient descent (SGD) algorithms and developing a way to make it always more efficient, by feeding more statistically efficient Markov chain input. We have also demonstrated that the so-called finite time error bound is not always the right descriptor, and one should also take into account the asymptotic statistical behavior of the SGD iterates through the central limit theorem. Our framework includes a number of random-walk driven SGD, SGD with various types of shuffling, and demonstrates how to make these more efficient by, for instance, replacing the random walk on the graph with a non-backtracking random walk (shown to be more statistically efficient than the simple random walk), and also deduce the same conclusion in the literature around shuffling for SGD under weaker assumptions.</p>\r\n<p>Third, we have developed a self-repellent random walk (SRRW) on any general graph, where the random walker utilizes past history (number of visits to a node so far) into account, when deciding next move on the graph. By utilizing nonlinear Markov chain tecehniques and stochastic approximation theory along with mean-field ODE based analysis for its stability and central limit theorem, we have shown that SRRW can achieve near-zero (minimal) variance in any sampling applications on any graph, with almost no additional computational cost that would be required for any general-purpose random walk such as Metropolis-Hastings random walk on graph. What's more surprising is that this SRRW can achieve asymptotic variance even smaller than that of ideal iid counterpart which can jump to any other node instantaneously, while SRRW is still \"walking\" on the graph. This work has been published&nbsp;in International Conference on Machine Learning (ICML) 2023, and received the \"outstanding paper awards\", one of 6 award winners out of over 1800 papers presented in the conference.&nbsp;</p>\r\n<p>Fourth, we have shown that for token-based distributed optimization problems, utilizing our previously developed self-repellent random walk (SRRW) for general stochastic approximation (SA) (including stochastic gradient descent) using distributed datasets, can achieve near-zero variance of the iterates, ensuring faster convergence to the global optima with smaller errors, with its rates being 1/\\alpha^2, where the effect of self-repellency (\\alpha) is amplified from the sampling application (where the rate was 1/\\alpha). With this theoretical result, we have developed a general SA framework driven by SRRW, named SA-SRRW.&nbsp;This work has been published&nbsp;in International Conference on Representation Learning (ICLR) 2024, and recognized with \"oral presentation\".&nbsp; We have also extended the framework we utilized in this SA-SRRW, by viewing it as a two-timescale stochastic approximation (TTSA) with state-dependent Markovian noise - the most general scenario so far, and established its convergence and central limit theorem.</p><br>\n<p>\n Last Modified: 12/31/2024<br>\nModified by: Do Young&nbsp;Eun</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project has focused on developing various efficient algorithms for sampling and estimation over large graphs in multiple application domains. The outcome of this project are as follows.\r\n\n\nFirst, we have developed distributed random-walk-based algorithms to estimate the Fiedler vector of a graph,namely the eigenvector corresponding to the second smallest eigenvalue of agraph Laplacian matrix, as it plays an important role in spectral graph theory with applications to graph partitioning. Such graphs arise in many disciplines including wireless multi-hop networks, social networks, or networked large-scale datasets. Algorithms designed to estimate this quantity usually rely on a priori knowledge of the entire graph, and employ techniques such as graph sparsification and power iterations, which have obvious shortcomings in cases where the graph is unknown, or changing dynamically. To this end, we have developed a framework in which we construct a stochastic process based on a set of interacting random walks on a graph and show that a suitably scaled version of our stochastic process converges to the Fiedler vector for a sufficiently large number of walks. Like other techniques based on exploratory random walks and on-the-fly computations, such as Markov Chain Monte Carlo (MCMC), our algorithm overcomes challenges typically faced by power iteration-based approaches. But, unlike any existing random walk-based method such as MCMCs where the focus is on the leading eigenvector, our framework with interacting random walks converges to the Fiedler vector (second eigenvector).\r\n\n\nSecond, partially motivated by our earlier investigation into the multi-armed bandit approach for opportunistic spectrum access (OSA) and general online optimization methods, we have also looked into the general purpose of stochastic gradient descent (SGD) algorithms and developing a way to make it always more efficient, by feeding more statistically efficient Markov chain input. We have also demonstrated that the so-called finite time error bound is not always the right descriptor, and one should also take into account the asymptotic statistical behavior of the SGD iterates through the central limit theorem. Our framework includes a number of random-walk driven SGD, SGD with various types of shuffling, and demonstrates how to make these more efficient by, for instance, replacing the random walk on the graph with a non-backtracking random walk (shown to be more statistically efficient than the simple random walk), and also deduce the same conclusion in the literature around shuffling for SGD under weaker assumptions.\r\n\n\nThird, we have developed a self-repellent random walk (SRRW) on any general graph, where the random walker utilizes past history (number of visits to a node so far) into account, when deciding next move on the graph. By utilizing nonlinear Markov chain tecehniques and stochastic approximation theory along with mean-field ODE based analysis for its stability and central limit theorem, we have shown that SRRW can achieve near-zero (minimal) variance in any sampling applications on any graph, with almost no additional computational cost that would be required for any general-purpose random walk such as Metropolis-Hastings random walk on graph. What's more surprising is that this SRRW can achieve asymptotic variance even smaller than that of ideal iid counterpart which can jump to any other node instantaneously, while SRRW is still \"walking\" on the graph. This work has been publishedin International Conference on Machine Learning (ICML) 2023, and received the \"outstanding paper awards\", one of 6 award winners out of over 1800 papers presented in the conference.\r\n\n\nFourth, we have shown that for token-based distributed optimization problems, utilizing our previously developed self-repellent random walk (SRRW) for general stochastic approximation (SA) (including stochastic gradient descent) using distributed datasets, can achieve near-zero variance of the iterates, ensuring faster convergence to the global optima with smaller errors, with its rates being 1/\\alpha^2, where the effect of self-repellency (\\alpha) is amplified from the sampling application (where the rate was 1/\\alpha). With this theoretical result, we have developed a general SA framework driven by SRRW, named SA-SRRW.This work has been publishedin International Conference on Representation Learning (ICLR) 2024, and recognized with \"oral presentation\". We have also extended the framework we utilized in this SA-SRRW, by viewing it as a two-timescale stochastic approximation (TTSA) with state-dependent Markovian noise - the most general scenario so far, and established its convergence and central limit theorem.\t\t\t\t\tLast Modified: 12/31/2024\n\n\t\t\t\t\tSubmitted by: Do YoungEun\n"
 }
}