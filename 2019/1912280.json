{
 "awd_id": "1912280",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRCNS US-France Research Proposal: Oscillatory processes for visual reasoning in deep neural networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2019-12-01",
 "awd_exp_date": "2023-11-30",
 "tot_intn_awd_amt": 548809.0,
 "awd_amount": 548809.0,
 "awd_min_amd_letter_date": "2019-08-30",
 "awd_max_amd_letter_date": "2019-08-30",
 "awd_abstract_narration": "The development of deep convolutional networks (DCNs) has recently led to great successes in machine vision. Despite these successes, to date, the most impressive results have been obtained for image categorization tasks such as indicating whether an image contains a particular object. However, DCNs ability to solve more complex visual reasoning problems such as understanding the visual relations between objects remains limited. Interestingly, much work in computer vision is currently being devoted to extending DCNs, but these models are still outmatched by the power and versatility of the brain, perhaps in part due to the richer neuronal computations available to cortical circuits. The challenge is to identify which neuronal mechanisms are relevant and to find suitable abstractions to model them. One promising set of candidates is the neural oscillations that are found throughout the brain.  This project seeks to identify the key oscillatory components and characterize the neural computations underlying humans ability to solve visual reasoning tasks, and to use similar strategies in modern deep learning architectures.\r\n\r\nThis project will use existing computational models to develop tasks and stimuli to be used in EEG studies to identify the key oscillatory components underlying human visual reasoning ability. The analysis of these EEG data will be guided by the development of a biophysically-realistic computational neuroscience model. This will inform the development of hypotheses on the circuit mechanisms underlying the oscillatory clusters and relate these mechanisms to neural computations. Finally, the project will develop novel machine learning idealizations of these neural computations, which are trainable with current deep learning methods but still interpretable at the neural circuit level.  In particular, the project will further develop initial machine learning formulation of oscillations based on complex-valued neuronal units, thus extending the approach and demonstrating its ability to qualitatively capture key oscillatory processes underlying visual reasoning. \r\n\r\nA companion project is being funded by the French National Research Agency (ANR).\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thomas",
   "pi_last_name": "Serre",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas Serre",
   "pi_email_addr": "Thomas_Serre@brown.edu",
   "nsf_id": "000561441",
   "pi_start_date": "2019-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029129002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  },
  {
   "pgm_ele_code": "732700",
   "pgm_ele_name": "CRCNS-Computation Neuroscience"
  },
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7327",
   "pgm_ref_txt": "CRCNS"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 548809.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The robust and efficient recognition of visual relations in complex scenes is a hallmark of biological vision. Despite recent progress in visual recognition, modern machine vision algorithms, specifically deep convolutional networks, are significantly limited in their ability to learn visual relations from images.</p>\n<p>We have demonstrated that these fundamental limitations are due to the reliance of current models primarily, or exclusively, on feedforward processing. This type of processing cannot represent multiple competing stimuli simultaneously, a challenge known as the \"binding problem,\" which necessitates top-down memory and attention mechanisms.</p>\n<p>Specifically, we have developed novel visual reasoning tasks and stimuli, which were utilized in human behavioral and electroencephalography (EEG) studies to identify the key neural computations underpinning our visual reasoning capabilities. We have shown that certain visual reasoning problems require memory and attention mechanisms through top-down feedback. We have introduced new visual reasoning challenges and highlighted the limitations of state-of-the-art deep neural networks. Furthermore, we have developed novel machine learning models based on these neural computations, which are trainable with current deep learning methods but remain interpretable at the neural circuit level. We have demonstrated that equipping deep neural networks with attention and memory mechanisms significantly enhances their generalization capabilities and sample efficiency.</p>\n<p>Overall, this project has significantly advanced our scientific understanding of the computational mechanisms underlying visual reasoning. In the process, we have also developed rigorous computational models that cover multiple levels of analysis, from circuits to the system, capable of predicting human behavioral data during visual reasoning tasks and competing with state-of-the-art computer vision systems. We have facilitated a bridge between computational neuroscience and artificial intelligence, representing a substantial leap forward in our understanding of visual cognition.</p>\n<p>This project was interdisciplinary and contributed to the education of undergraduate and graduate students. The research was incorporated into undergraduate courses taught by the Principal Investigator (PI) at Brown University and summer courses. It was also widely disseminated at computational neuroscience and machine learning conferences, impacting multiple disciplines including human perception, psychology, neuromorphic engineering, and artificial intelligence.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/24/2024<br>\nModified by: Thomas&nbsp;Serre</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe robust and efficient recognition of visual relations in complex scenes is a hallmark of biological vision. Despite recent progress in visual recognition, modern machine vision algorithms, specifically deep convolutional networks, are significantly limited in their ability to learn visual relations from images.\n\n\nWe have demonstrated that these fundamental limitations are due to the reliance of current models primarily, or exclusively, on feedforward processing. This type of processing cannot represent multiple competing stimuli simultaneously, a challenge known as the \"binding problem,\" which necessitates top-down memory and attention mechanisms.\n\n\nSpecifically, we have developed novel visual reasoning tasks and stimuli, which were utilized in human behavioral and electroencephalography (EEG) studies to identify the key neural computations underpinning our visual reasoning capabilities. We have shown that certain visual reasoning problems require memory and attention mechanisms through top-down feedback. We have introduced new visual reasoning challenges and highlighted the limitations of state-of-the-art deep neural networks. Furthermore, we have developed novel machine learning models based on these neural computations, which are trainable with current deep learning methods but remain interpretable at the neural circuit level. We have demonstrated that equipping deep neural networks with attention and memory mechanisms significantly enhances their generalization capabilities and sample efficiency.\n\n\nOverall, this project has significantly advanced our scientific understanding of the computational mechanisms underlying visual reasoning. In the process, we have also developed rigorous computational models that cover multiple levels of analysis, from circuits to the system, capable of predicting human behavioral data during visual reasoning tasks and competing with state-of-the-art computer vision systems. We have facilitated a bridge between computational neuroscience and artificial intelligence, representing a substantial leap forward in our understanding of visual cognition.\n\n\nThis project was interdisciplinary and contributed to the education of undergraduate and graduate students. The research was incorporated into undergraduate courses taught by the Principal Investigator (PI) at Brown University and summer courses. It was also widely disseminated at computational neuroscience and machine learning conferences, impacting multiple disciplines including human perception, psychology, neuromorphic engineering, and artificial intelligence.\n\n\n\t\t\t\t\tLast Modified: 02/24/2024\n\n\t\t\t\t\tSubmitted by: ThomasSerre\n"
 }
}