{
 "awd_id": "1910492",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Novel Geometric Algorithms for Learning from Big Biomedical Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 499999.0,
 "awd_amount": 499999.0,
 "awd_min_amd_letter_date": "2019-08-31",
 "awd_max_amd_letter_date": "2019-08-31",
 "awd_abstract_narration": "Big biomedical data has become a key resource for discovery in biomedicine. However, due to their distributed nature and the existence of sensitive and noisy data, they are not utilized to their full potential. For example, lots of biomedical data are generated and stored at different sites such as hospitals, pharmacies, and biomedical labs, numerous challenges could arise when gathering, integrating, and utilizing them. Thus, more suitable and effective techniques are urgently needed to integrate and analyze them. This project aims to design a set of novel algorithmic tools for several fundamental data analytics problems commonly encountered in big biomedical data. \r\n\r\nThis project could potentially increase the ability of gathering and integrating big biomedical data, effectively exploiting such data, and handling unreliable and sensitive biomedical data.  Specifically, the project will focus on four data analysis problems: distributed truth discovery, distributed classification, distributed clustering, and differentially private learning. Each of these problems has already been recognized as critical tools in data analysis and information integration. The project addresses a number of challenging issues (such as communication cost, data reliability, robustness, computational cost, and privacy-preserving), and aim to achieve highly efficient and quality guaranteed solutions for each of these problems. These four research aims will be evaluated based on their effectiveness, efficiency, and the practicality on specific biomedical datasets. Furthermore, this research will provide educational and research opportunities to both graduate and undergraduate students including students from underrepresented groups.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jinhui",
   "pi_last_name": "Xu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jinhui Xu",
   "pi_email_addr": "jinhui@buffalo.edu",
   "nsf_id": "000484275",
   "pi_start_date": "2019-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mingchen",
   "pi_last_name": "Gao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mingchen Gao",
   "pi_email_addr": "mgao8@buffalo.edu",
   "nsf_id": "000785286",
   "pi_start_date": "2019-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Buffalo",
  "inst_street_address": "520 LEE ENTRANCE STE 211",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "7166452634",
  "inst_zip_code": "142282577",
  "inst_country_name": "United States",
  "cong_dist_code": "26",
  "st_cong_dist_code": "NY26",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "GMZUKXFDJMA9",
  "org_uei_num": "LMCJKRFW5R81"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Buffalo",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "142602500",
  "perf_ctry_code": "US",
  "perf_cong_dist": "26",
  "perf_st_cong_dist": "NY26",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 499999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;</p>\n<div>\n<div>Big biomedical data has emerged as a vital resource for diagnosing patients and advancing discoveries. Nevertheless, its true potential remains underutilized due to its decentralized nature and the presence of sensitive and noisy data. For instance, a significant volume of biomedical data is generated and stored across various locations, such as hospitals, pharmacies, and biomedical laboratories. This dispersion presents numerous challenges in collecting, integrating, and harnessing these data effectively. Consequently, there is an urgent need for more suitable and efficient techniques to facilitate the integration and analysis of this wealth of information.</div>\n<div>This project has developed a novel set of algorithmic tools to address several fundamental data analytics challenges commonly encountered in the realm of big biomedical data. The primary objectives of this project include enhancing the capability to collect and integrate large-scale biomedical data, maximizing the utility of such data, and managing unreliable and sensitive biomedical information while protecting privacy. Specifically, the project has focused on four key data analysis issues: distributed truth discovery, distributed classification, distributed clustering, and differentially private learning. Each of these problems is already recognized as essential tools in data analysis and information integration.</div>\n<div>The research outcome of this project has demonstrated to improve the usage of biomedical data in the following aspects: communication costs, data reliability, robustness, computational expenses, and privacy preservation. The effectiveness, efficiency, and practicality of these four research objectives have been evaluated in real-world biomedical datasets, such as chest X-ray report understanding, rare hereditary retinal disease recognition, skin cancer diagnosis, brain tumor segmentation. Additionally, this research initiative has created educational and research opportunities for both graduate and undergraduate students, with a particular focus on including students from underrepresented groups.</div>\n</div>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/28/2024<br>\nModified by: Jinhui&nbsp;Xu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\nBig biomedical data has emerged as a vital resource for diagnosing patients and advancing discoveries. Nevertheless, its true potential remains underutilized due to its decentralized nature and the presence of sensitive and noisy data. For instance, a significant volume of biomedical data is generated and stored across various locations, such as hospitals, pharmacies, and biomedical laboratories. This dispersion presents numerous challenges in collecting, integrating, and harnessing these data effectively. Consequently, there is an urgent need for more suitable and efficient techniques to facilitate the integration and analysis of this wealth of information.\nThis project has developed a novel set of algorithmic tools to address several fundamental data analytics challenges commonly encountered in the realm of big biomedical data. The primary objectives of this project include enhancing the capability to collect and integrate large-scale biomedical data, maximizing the utility of such data, and managing unreliable and sensitive biomedical information while protecting privacy. Specifically, the project has focused on four key data analysis issues: distributed truth discovery, distributed classification, distributed clustering, and differentially private learning. Each of these problems is already recognized as essential tools in data analysis and information integration.\nThe research outcome of this project has demonstrated to improve the usage of biomedical data in the following aspects: communication costs, data reliability, robustness, computational expenses, and privacy preservation. The effectiveness, efficiency, and practicality of these four research objectives have been evaluated in real-world biomedical datasets, such as chest X-ray report understanding, rare hereditary retinal disease recognition, skin cancer diagnosis, brain tumor segmentation. Additionally, this research initiative has created educational and research opportunities for both graduate and undergraduate students, with a particular focus on including students from underrepresented groups.\n\n\n\n\t\t\t\t\tLast Modified: 01/28/2024\n\n\t\t\t\t\tSubmitted by: JinhuiXu\n"
 }
}