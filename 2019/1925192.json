{
 "awd_id": "1925192",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CC* Compute: Building a state-of-the-art campus compute resource at Franklin & Marshall College",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924220",
 "po_email": "kthompso@nsf.gov",
 "po_sign_block_name": "Kevin Thompson",
 "awd_eff_date": "2019-07-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2019-06-25",
 "awd_max_amd_letter_date": "2020-07-14",
 "awd_abstract_narration": "Franklin & Marshall College (F&M) is building and deploying a campus cluster resource to better meet the needs of our researchers and their students who need greater access to high performance compute resources to support intensive data analysis and computation. This project provides much needed local compute nodes for F&M's researchers and students while also contributing to the growing fabric of shared computing clusters across the country. This project contributes these new resources to the Open Science Grid (OSG) which is a national, distributed computing partnership that allows participants to share their resources with other researchers to maximize the impact these investments have on scientific research and discovery.  As an institution, F&M has many top-tier scientific researchers who also partner with students in research that is regularly funded by public and private agencies.  Providing substantially improved infrastructure to support this research will advance and expand the institution's capacity to support important investigations, from the search for pulsars to brain science. F&M has a demonstrated commitment to recruiting and supporting STEM students and this infrastructure improvement and investment allows the institution to continue to be a leader in this arena, providing access to the best resources and opportunities for future scientists.  This project, similar to other recent initiatives, demonstrates how it is possible to design and implement significant research infrastructure, even at a smaller institution, that advances scientific discovery both on and beyond our campus.\r\n\r\nThe compute cluster maximizes available resources for research that requires both HPC and HTC solutions. It consists of a head node and a login node, both running dual 20 core Xeon Gold 6230 2.10GHz CPUs with 192GB of 2666 MHz ECC memory, and 38TB of SSD NVMe storage. There are 36 standard compute nodes, each using dual 20 core Xeon Gold 6230 2.10 GHz CPUs with 192GB of 2666 MHz ECC memory and 1.8TB NVMe SSD for OS and local scratch. There is one GPU node for use with software that takes advantage of cuda compiled software and GPU co-processing. It mirrors the same specs as the standard compute node, but includes four Nvidia V100 GPU cards featuring 32 GB HBM2 memory and 5120 stream processors.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Carrie",
   "pi_last_name": "Rampp",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Carrie Rampp",
   "pi_email_addr": "crampp@fandm.edu",
   "nsf_id": "000693784",
   "pi_start_date": "2019-06-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Fields",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Peter A Fields",
   "pi_email_addr": "peter.fields@fandm.edu",
   "nsf_id": "000163222",
   "pi_start_date": "2019-06-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Christina",
   "pi_last_name": "Weaver",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Christina M Weaver",
   "pi_email_addr": "christina.weaver@fandm.edu",
   "nsf_id": "000542982",
   "pi_start_date": "2019-06-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Fronefield",
   "pi_last_name": "Crawford",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Fronefield Crawford",
   "pi_email_addr": "fronefield.crawford@fandm.edu",
   "nsf_id": "000547778",
   "pi_start_date": "2019-06-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Joshua",
   "pi_last_name": "Booth",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Joshua D Booth",
   "pi_email_addr": "joshua.booth@uah.edu",
   "nsf_id": "000786858",
   "pi_start_date": "2019-06-25",
   "pi_end_date": "2020-07-14"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jason",
   "pi_last_name": "Brooks",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Jason B Brooks",
   "pi_email_addr": "jbrooks1@fandm.edu",
   "nsf_id": "000830785",
   "pi_start_date": "2020-07-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Franklin and Marshall College",
  "inst_street_address": "415 HARRISBURG AVE",
  "inst_street_address_2": "",
  "inst_city_name": "LANCASTER",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "7173584517",
  "inst_zip_code": "176032827",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "PA11",
  "org_lgl_bus_name": "FRANKLIN AND MARSHALL COLLEGE",
  "org_prnt_uei_num": "P4NXVGAJNQK3",
  "org_uei_num": "P4NXVGAJNQK3"
 },
 "perf_inst": {
  "perf_inst_name": "Franklin and Marshall College",
  "perf_str_addr": "415 Harrisburg Ave",
  "perf_city_name": "Lancaster",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "176043003",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "PA11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808000",
   "pgm_ele_name": "Campus Cyberinfrastructure"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Computational Results</span><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br />This award allowed Franklin &amp; Marshall College to purchase and provision a shared, centralized, multi-node compute cluster which significantly enhanced existing research, and increased research potential by faculty and undergraduates across a wide range of academic disciplines.&nbsp; Some of the direct results of our use of the campus cluster include:</span></p>\n<ul>\n<li><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The ability to handle large computationally intensive problems which could not be handled previously, given our former lack of resources. </span></li>\n</ul>\n<ul>\n<li><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Completing end to end research computations faster, both because of the compute power of the cluster, and because of the ability to run jobs in parallel.&nbsp;</span></li>\n</ul>\n<ul>\n<li><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The ability to run scientific software on Graphics Processing Units (GPUs), a newer type of processor, has also resulted in much faster run times compared to typical methods for computation using Central Processing Units (CPUs).&nbsp;</span></li>\n</ul>\n<p><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Many of our researchers use software that allows full or partial work flow transfer to the cluster's GPUs to process data, speeding up calculations.&nbsp; Our cluster has four GPUs so multiple jobs can be performed simultaneously, or in some cases single jobs can use multiple GPUs.  <span id=\"docs-internal-guid-12e9d870-7fff-c7ee-db74-204753bec82f\" style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This addition of the new technology has been an incredible benefit, </span>and changes not only how certain research work flows are done, but also what kind of research we can now support (Data Science, Machine Learning).</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Management of Resources</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">From the standpoint of infrastructure support, we are now able to focus management of a single centralized multi-node compute resource, rather than on multiple systems distributed across campus.&nbsp; <span id=\"docs-internal-guid-79a99d37-7fff-048c-578a-80184b2e23c8\" style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">We have been able to migrate several users off of older workstations and onto the new cluster. </span>This management step is especially important since we have just a small number of people dedicated to meeting the computational needs of faculty research.<br /><br /></span></p>\n<p><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Educational Benefits</span><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br />At Franklin &amp; Marshall, we have many undergraduate student researchers that collaborate with faculty, and who also have access to the cluster.  Furthermore, students who come to us with their own research projects, and who need access to more than a workstation or laptop, are also able to use this resource. </span></p>\n<p><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Students from several classes can now use the cluster as a resource for their course and lab work.&nbsp; What better way to learn parallel computing than to see your projects run on a high performance cluster in parallel?&nbsp; Students in classes like Metabolic Biochemistry, Statistical Models, Computational Math, and Computational Methods of Physics can use remote access via their web browser to call cluster software packages such as Jupyter Notebooks, R, VMD, and Matlab, or submit group jobs to the cluster via its job manager.&nbsp;</span><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;<br /></span></p>\n<p><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Finally, we can use it as a resource for planning future courses or curriculum that require the use of this technology to be successful. </span><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Scientific Community</span><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><br /><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><span id=\"docs-internal-guid-e11a49cd-7fff-9fe5-60bd-5a0fce04ebbe\" style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">In addition to our faculty, students, and their collaborators, we provide cluster access to Open Science Grid (OSG). OSG provides High Throughput Computing (running multiple independent jobs on distributed systems simultaneously) services to researchers throughout the U.S., especially those researchers who may not have direct access to local computing resources.</span>&nbsp;</span></p>\n<p><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">In a typical week we process 200-300 jobs from OSG, equating to about 50-60 days worth of computations.&nbsp; We are happy to be able to share this resource with the wider scientific community.&nbsp;</span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Additional Benefits</span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Building on our previous NSF grant, the cluster has incorporated Globus, a file transfer service, and attached data storage locations to give researchers, their students, and collaborators, easy access to their data.  This allows them to run jobs without having to move files to and from multiple storage repositories. <br /></span></p>\n<p id=\"docs-internal-guid-44f7dd4c-7fff-1fee-797f-8cea8779d970\" style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Being an accelerated research and shared resource, use of the the cluster has been included in several recent faculty grant application proposals and renewal requests.&nbsp; We also consider it a valuable addition to our infrastructure for any prospective students and new faculty considering research at Franklin &amp; Marshall College. </span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/28/2022<br>\n\t\t\t\t\tModified by: Jason&nbsp;B&nbsp;Brooks</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nComputational Results\nThis award allowed Franklin &amp; Marshall College to purchase and provision a shared, centralized, multi-node compute cluster which significantly enhanced existing research, and increased research potential by faculty and undergraduates across a wide range of academic disciplines.  Some of the direct results of our use of the campus cluster include:\n\nThe ability to handle large computationally intensive problems which could not be handled previously, given our former lack of resources. \n\n\nCompleting end to end research computations faster, both because of the compute power of the cluster, and because of the ability to run jobs in parallel. \n\n\nThe ability to run scientific software on Graphics Processing Units (GPUs), a newer type of processor, has also resulted in much faster run times compared to typical methods for computation using Central Processing Units (CPUs). \n\n\nMany of our researchers use software that allows full or partial work flow transfer to the cluster's GPUs to process data, speeding up calculations.  Our cluster has four GPUs so multiple jobs can be performed simultaneously, or in some cases single jobs can use multiple GPUs.  This addition of the new technology has been an incredible benefit, and changes not only how certain research work flows are done, but also what kind of research we can now support (Data Science, Machine Learning).\nManagement of Resources\nFrom the standpoint of infrastructure support, we are now able to focus management of a single centralized multi-node compute resource, rather than on multiple systems distributed across campus.  We have been able to migrate several users off of older workstations and onto the new cluster. This management step is especially important since we have just a small number of people dedicated to meeting the computational needs of faculty research.\n\n\n\nEducational Benefits \nAt Franklin &amp; Marshall, we have many undergraduate student researchers that collaborate with faculty, and who also have access to the cluster.  Furthermore, students who come to us with their own research projects, and who need access to more than a workstation or laptop, are also able to use this resource. \n\nStudents from several classes can now use the cluster as a resource for their course and lab work.  What better way to learn parallel computing than to see your projects run on a high performance cluster in parallel?  Students in classes like Metabolic Biochemistry, Statistical Models, Computational Math, and Computational Methods of Physics can use remote access via their web browser to call cluster software packages such as Jupyter Notebooks, R, VMD, and Matlab, or submit group jobs to the cluster via its job manager.  \n\n\nFinally, we can use it as a resource for planning future courses or curriculum that require the use of this technology to be successful. \n\n\nScientific Community  \nIn addition to our faculty, students, and their collaborators, we provide cluster access to Open Science Grid (OSG). OSG provides High Throughput Computing (running multiple independent jobs on distributed systems simultaneously) services to researchers throughout the U.S., especially those researchers who may not have direct access to local computing resources. \n\nIn a typical week we process 200-300 jobs from OSG, equating to about 50-60 days worth of computations.  We are happy to be able to share this resource with the wider scientific community. \nAdditional Benefits\nBuilding on our previous NSF grant, the cluster has incorporated Globus, a file transfer service, and attached data storage locations to give researchers, their students, and collaborators, easy access to their data.  This allows them to run jobs without having to move files to and from multiple storage repositories. \n\n \nBeing an accelerated research and shared resource, use of the the cluster has been included in several recent faculty grant application proposals and renewal requests.  We also consider it a valuable addition to our infrastructure for any prospective students and new faculty considering research at Franklin &amp; Marshall College. \n\n\t\t\t\t\tLast Modified: 10/28/2022\n\n\t\t\t\t\tSubmitted by: Jason B Brooks"
 }
}