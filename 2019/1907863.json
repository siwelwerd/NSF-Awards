{
 "awd_id": "1907863",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: Accelerated Data Transformation:  A Software-Hardware Stack for Transducers",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 258000.0,
 "awd_amount": 258000.0,
 "awd_min_amd_letter_date": "2019-07-17",
 "awd_max_amd_letter_date": "2019-07-17",
 "awd_abstract_narration": "Recent years have seen an explosive rise of \"big data\" and data-intensive computing.  Many scientific and data analytics applications that operate on large data sets perform data transformation at their core.  For example, many genomics applications translate DNA sequences into protein sequences and must perform this transformation on large volumes of data (petabytes) generated by DNA sequencers. Recent studies have shown that popular data analytics systems spend significant amount of time performing data transformation operations such as data compression, decompression, serialization, deserialization and error correction.  While application-specific hardware accelerators can be useful, their narrow applicability can significantly limit their impact. On the other hand, accelerating a common computation at the core of many applications can have a broader impact, and benefit not only existing, but also future applications. This research targets the problem of general acceleration of data transformation. More specifically, to allow breadth of utility, the project aims to provide a software-hardware stack to accelerate the computational abstraction at the core of data transformation, namely, finite-state transducers. Given the societal importance of big data computing, a significant broader impact of this work is the uptake of research ideas and technology into the scientific base, and their resulting impact on a wide range of 'big data' applications for science, industry, and society. In addition, this project allows students to experience in first hand how abstract concepts such as finite-state transducers can be applied to practical problems, connecting elements of theory of computation, algorithm design and optimization, applications and systems architecture.\r\n\r\nThe research investigates the transducers computational model and its efficient implementation with the goal of providing performance and energy-efficiency gains in data analytics systems  all of which rely on data transformation. In particular, this work aims to reduce transducer theory to practical use by mapping transducer programs onto emerging data processing accelerators. To this end, this work targets the following issues. First, design a software stack to map transducers onto novel hardware accelerators. In particular, the investigators build on their previous work on the design and implementation of the Unstructured Data Processor, a novel hardware accelerator for data transformation shown to give high performance, but that at present lacks a high-level programming model. Accomplishing this goal requires investigating a set of platform-independent and platform-specific optimizations aimed to minimize the code size, minimize the memory utilization, and leverage the coarse- and fine-grained parallelism inherent in the computation. Second, improve and extend the underlying hardware accelerator based on the insights acquired in the design of the software stack. Third, extend the transducer model to express the full range of data transformations in popular data analytics systems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michela",
   "pi_last_name": "Becchi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michela Becchi",
   "pi_email_addr": "mbecchi@ncsu.edu",
   "nsf_id": "000573363",
   "pi_start_date": "2019-07-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "3054 Engineering Building II",
  "perf_city_name": "Raleigh",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276957911",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 258000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-3ad4cbee-7fff-d0f2-5114-db94a9154d11\"> </span></p>\n<p dir=\"ltr\"><span>Data transformation is one of the core processing steps in many data analytics and scientific applications. For example, Extract-Transform-Load (ETL) workloads require extracting information from a variety of formats, transforming the data, and loading them&nbsp;</span>into a target format. Data transformation tasks performed by these workloads include data encoding/decoding, data compression and serialization for communication and storage density, data analysis, and query of structured or unstructured data (using popular data formats such as CSV and JSON). In addition, scientific applications operating on matrices and graphs often require data conversion between different matrix formats. Performing these data transformations efficiently is crucial to application performance. The rapidly increasing data sizes of data analytics and scientific applications has caused data transformation to increasingly become a performance bottleneck.</p>\n<p dir=\"ltr\"><span>&nbsp;</span></p>\n<p dir=\"ltr\"><span>Existing approaches to address this problem &ndash; such as custom library implementations and hardware accelerators of specific data transformations &ndash; lack flexibility and generalizability. This project has aimed to provide a flexible solution to efficient data transformation by relying on a solid computational abstraction and putting it to practice. To this end, we have designed a software/hardware stack relying on the transducer&rsquo;s abstraction.</span></p>\n<p dir=\"ltr\"><span>&nbsp;</span></p>\n<p dir=\"ltr\"><span>This project has made the following contributions. First, we have proposed novel transducer models (extensions of deterministic and pushdown transducers) that support a wide variety of data transformation tasks while enabling efficient implementation on existing and novel accelerators (such as GPUs, FPGAs and our proposed unified data processor). Second, we have mapped a variety of data transformation tasks &ndash; such as data encoding/decoding, sparse matrix transformation, data statistics, data querying, data prediction and data filtering &ndash; onto the proposed transducers models. Third, we have proposed programming frameworks to map data transformation tasks onto a variety of transducer models. Our frameworks include platform agnostic programming languages to code transducer programs using intuitive programming constructs, and compilers that, given high-level programs, generate efficient transducer processing engines for a variety of hardware platforms. The compilers include platform-agnostic and platform-specific optimizations. Our results show performance that on par or better than those achieved by popular CPU and GPU libraries implementing specific data transformations. </span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/17/2024<br>\nModified by: Michela&nbsp;Becchi</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nData transformation is one of the core processing steps in many data analytics and scientific applications. For example, Extract-Transform-Load (ETL) workloads require extracting information from a variety of formats, transforming the data, and loading theminto a target format. Data transformation tasks performed by these workloads include data encoding/decoding, data compression and serialization for communication and storage density, data analysis, and query of structured or unstructured data (using popular data formats such as CSV and JSON). In addition, scientific applications operating on matrices and graphs often require data conversion between different matrix formats. Performing these data transformations efficiently is crucial to application performance. The rapidly increasing data sizes of data analytics and scientific applications has caused data transformation to increasingly become a performance bottleneck.\n\n\n\n\n\nExisting approaches to address this problem  such as custom library implementations and hardware accelerators of specific data transformations  lack flexibility and generalizability. This project has aimed to provide a flexible solution to efficient data transformation by relying on a solid computational abstraction and putting it to practice. To this end, we have designed a software/hardware stack relying on the transducers abstraction.\n\n\n\n\n\nThis project has made the following contributions. First, we have proposed novel transducer models (extensions of deterministic and pushdown transducers) that support a wide variety of data transformation tasks while enabling efficient implementation on existing and novel accelerators (such as GPUs, FPGAs and our proposed unified data processor). Second, we have mapped a variety of data transformation tasks  such as data encoding/decoding, sparse matrix transformation, data statistics, data querying, data prediction and data filtering  onto the proposed transducers models. Third, we have proposed programming frameworks to map data transformation tasks onto a variety of transducer models. Our frameworks include platform agnostic programming languages to code transducer programs using intuitive programming constructs, and compilers that, given high-level programs, generate efficient transducer processing engines for a variety of hardware platforms. The compilers include platform-agnostic and platform-specific optimizations. Our results show performance that on par or better than those achieved by popular CPU and GPU libraries implementing specific data transformations. \n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 10/17/2024\n\n\t\t\t\t\tSubmitted by: MichelaBecchi\n"
 }
}