{
 "awd_id": "1940202",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: MEMONET: Understanding memory in neuronal networks through a brain-inspired spin-based artificial intelligence",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 435478.0,
 "awd_amount": 435478.0,
 "awd_min_amd_letter_date": "2019-09-17",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "The brain is arguably the most sophisticated and the most efficient computational machine in the universe. The human brain, for example, comprises about 100 billion neurons that form an interconnected circuit with well over 100 trillion connections. Understanding how a multitude of brain functions emerge from the underlying neuronal circuit will give insights into the operating principles of the brain. In this award, a multidisciplinary team of systems biologist, computational biologist, material scientist, neuroscientist, and machine learning expert will work synergistically to leverage the data revolution in neuroscience to answer a fundamental question: How does the brain learn, store, and process information?  The team will develop and apply advanced data analysis algorithms to harness the great volume of neuronal data generated by the latest imaging and molecular profiling technologies, for elucidating the neuronal circuits driving brain functions. Computer simulations of a spin-electronic (spintronic) device will further serve as a platform to validate and emulate important operational characteristics of such neuronal circuits. The award sets the groundwork for an interdisciplinary data science research and educational program that will bring a new and powerful paradigm for studying brain functions as well as for designing transformative brain-inspired devices for information processing, data storage, computing, and decision making.\r\n\r\nThe project has a specific focus on an essential function of the brain: motor-skill learning. This function emerges from the underlying circuitry of neurons that governs the activities of molecular signal transmission and neuronal firing. Importantly, the neuronal circuit in a mammalian brain is highly plastic and dynamic, features that endow animals with the ability to respond to myriad external stimulations through learning. By harnessing the latest data revolution in neuronal imaging, single neuron molecular profiling, spintronic device simulation, network inference, and machine learning, a team of multidisciplinary investigators will be supported by this award to investigate the fundamental principle of neuronal circuit rewiring that drives brain?s learning function. More specifically, the team sets out to achieve the following specific tasks: (A) Infer learning-induced rewiring of large-scale neuronal networks from two-photon calcium imaging data through the development of novel and powerful network inference algorithms; (B) Build biochemical-based models of neuronal circuits by integrating molecular profiling with neuron firing and connectome dynamics; and (C) Develop a spintronic material network model that emulates learning and memory formation by exploiting the spin dynamics in spintronic materials. The project seeks to lay the foundation for the creation of an interdisciplinary data-intensive brain-to-materials initiative that will be applied to understand and emulate the operational principles of brain neuronal circuits underlying learning, cognition, memory formation, and other behaviors. The outcomes of the initiative will have a paramount impact on the society, not only in our understanding of the brain and its functions, but also in overcoming current bottlenecks of existing computing architectures.  This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Takaki",
   "pi_last_name": "Komiyama",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Takaki Komiyama",
   "pi_email_addr": "tkomiyama@ucsd.edu",
   "nsf_id": "000606192",
   "pi_start_date": "2019-09-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 Gilman Dr MC 0634",
  "perf_city_name": "La Jolla",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930634",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "099y00",
   "pgm_ele_name": "HDR-Harnessing the Data Revolu"
  },
  {
   "pgm_ele_code": "099Y00",
   "pgm_ele_name": "HDR-Harnessing the Data Revolu"
  },
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "062Z",
   "pgm_ref_txt": "Harnessing the Data Revolution"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 241287.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 194191.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-97abdcd5-7fff-79d1-24dc-7036bc5cded8\"> </span></p>\n<p dir=\"ltr\"><span>In this collaborative project, a multidisciplinary team of systems biologist, computational biologist, material scientist, neuroscientist, and machine learning experts worked together to leverage the data revolution in neuroscience to answer a fundamental question: How does the brain learn, store, and process information? The primary goal is to study the operating principle behind learning in the brain, using motor-skill learning as a representative case, and to emulate this principle in an artificial brain using spin-based electronics (spintronics) as neurons.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>In Task 1, we analyzed neuronal activity data taken during motor skill learning to elucidate how learning rewires the functional connectivity among neurons. Our analyses revealed connectivity rewiring dynamics that occur in phases, involving the maximization of motor performance in the first phase and the maximization of network efficiency in the second phase. Further, we applied deep learning algorithms to model neural decoders that map neuronal activity to movements and showed that these decoders remain relatively stable during motor learning above.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>In Task 2, we used molecular and biochemical profiles to infer the function of individual neurons during learning. Combining machine learning, pattern recognition, and unsupervised classification, we identified subgroups of neurons that carried distinct gene expression states during learning, including a state that may indicate engram-like signatures.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>In Task 3 we designed a stable artificial neuron device based on a topological quasi-1D excitation trapped in a pinned domain wall. The device has been analyzed regarding its topological protection and material parameters were identified to enable fast and energy-efficient operation. We were able to mimic the behavior as described by the leaky integrate and fire model for neuron activity.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>The project resulted in the training of workforce in the area of data science, machine learning, neuroscience, and solid-state physics, totaling 2 postdoctoral, 7 PhD, and 1 MS students, the majority (6 out of 10) of whom are from an under-represented group in STEM. Further, we engaged the interdisciplinary communities of neuroscientists, data scientists, material scientists, physicists, and computer scientists through the organization of a virtual symposium on brain-inspired computing architecture and materials.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span><span>&nbsp;</span></span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/10/2023<br>\n\t\t\t\t\tModified by: Takaki&nbsp;Komiyama</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nIn this collaborative project, a multidisciplinary team of systems biologist, computational biologist, material scientist, neuroscientist, and machine learning experts worked together to leverage the data revolution in neuroscience to answer a fundamental question: How does the brain learn, store, and process information? The primary goal is to study the operating principle behind learning in the brain, using motor-skill learning as a representative case, and to emulate this principle in an artificial brain using spin-based electronics (spintronics) as neurons. \n\n \nIn Task 1, we analyzed neuronal activity data taken during motor skill learning to elucidate how learning rewires the functional connectivity among neurons. Our analyses revealed connectivity rewiring dynamics that occur in phases, involving the maximization of motor performance in the first phase and the maximization of network efficiency in the second phase. Further, we applied deep learning algorithms to model neural decoders that map neuronal activity to movements and showed that these decoders remain relatively stable during motor learning above. \n\n \nIn Task 2, we used molecular and biochemical profiles to infer the function of individual neurons during learning. Combining machine learning, pattern recognition, and unsupervised classification, we identified subgroups of neurons that carried distinct gene expression states during learning, including a state that may indicate engram-like signatures.\n\n \nIn Task 3 we designed a stable artificial neuron device based on a topological quasi-1D excitation trapped in a pinned domain wall. The device has been analyzed regarding its topological protection and material parameters were identified to enable fast and energy-efficient operation. We were able to mimic the behavior as described by the leaky integrate and fire model for neuron activity.\n\n \nThe project resulted in the training of workforce in the area of data science, machine learning, neuroscience, and solid-state physics, totaling 2 postdoctoral, 7 PhD, and 1 MS students, the majority (6 out of 10) of whom are from an under-represented group in STEM. Further, we engaged the interdisciplinary communities of neuroscientists, data scientists, material scientists, physicists, and computer scientists through the organization of a virtual symposium on brain-inspired computing architecture and materials. \n\n \n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 02/10/2023\n\n\t\t\t\t\tSubmitted by: Takaki Komiyama"
 }
}