{
 "awd_id": "1908617",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CISE: RI: Small: Amortized Inference for Large-Scale Graphical Models",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 399923.0,
 "awd_amount": 399923.0,
 "awd_min_amd_letter_date": "2019-08-31",
 "awd_max_amd_letter_date": "2019-08-31",
 "awd_abstract_narration": "Probabilistic graphical models offer a mathematical framework to describe spatial and temporal relationships between entities. From some observable measurements, inferences can be made about other connected hidden factors. When applied to big datasets, however, standard inference methods are prohibitively time-consuming, requiring a large number of iterative updates to infer each variable. To avoid these updates, amortized inference uses a neural network to directly compute an approximate solution for every variable, which is much faster. Amortized inference works well for simpler models but not for models that capture more correlations between data. This project's goal is to generalize amortization to models that have dependent local connectivity between data. Findings from this project may be applicable to many useful large-scale applications, such as spatial modeling of bird sightings across North America and spatiotemporal modeling of opioid overdoses across neighborhood, state, and regional scales in the U.S. to inform more effective public health interventions. This research will further support the development of a project-based college-level course on probabilistic graphical models, as well as open-source software packages that make the project's new inference methods available to non-experts.\r\n\r\nThe project's technical contribution will bring the efficiencies of amortized inference from models that make strong conditional independence assumptions about data to a wider class of probabilistic graphical models that capture more realistic structured dependencies between data. Across three common inference algorithms -- structured Variational Inference (VI), Loopy Belief Propagation (LBP), and Expectation Propagation (EP) -- two key technical innovations will be applied: (1) decomposition of the optimization objective to allow scalable neighborhood-by-neighborhood processing, and (2) identification of reusable neighborhood substructure that can be fed into an amortizing neural network to produce approximate local posterior distributions. These innovations are challenging because most straightforward attempts would encounter an intractable entropy term (VI) or not maintain consistency between local marginal distributions of random variables (LBP or EP). These challenges may be met by developing improved bounds and parameterizations that enforce consistency, leading to amortized inference in which the number of parameters remains fixed and affordable even when applied to large graphical models that include millions of variables.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Liping",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Liping Liu",
   "pi_email_addr": "liping.liu@tufts.edu",
   "nsf_id": "000754600",
   "pi_start_date": "2019-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Hughes",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Michael C Hughes",
   "pi_email_addr": "michael.hughes@tufts.edu",
   "nsf_id": "000786606",
   "pi_start_date": "2019-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Thomas",
   "pi_last_name": "Stopka",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas J Stopka",
   "pi_email_addr": "thomas.stopka@tufts.edu",
   "nsf_id": "000792289",
   "pi_start_date": "2019-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Tufts University",
  "inst_street_address": "80 GEORGE ST",
  "inst_street_address_2": "",
  "inst_city_name": "MEDFORD",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6176273696",
  "inst_zip_code": "021555519",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "TRUSTEES OF TUFTS COLLEGE",
  "org_prnt_uei_num": "WL9FLBRVPJJ7",
  "org_uei_num": "WL9FLBRVPJJ7"
 },
 "perf_inst": {
  "perf_inst_name": "Tufts University School of Engineering",
  "perf_str_addr": "200 College Ave",
  "perf_city_name": "Medford",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021555530",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 399923.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div>\n<p>Inference on large graphs is an indispensable step in many learning problems but is well known to be computationally expensive. This project has generalized amortized inference developed for independent data to inference problems on large graphs. The main approach is to train a neural network to perform approximate inference for variables associated with graph nodes or edges. The underlying neural network learns shared knowledge when inferring variables in the graph. The study indicates that this approach greatly speeds up the inference procedure over traditional methods.&nbsp;This project has applied this approach to problems with rich node information (e.g. citation networks) and&nbsp;shown an extra benefit of the new approach: the learned network can perform inference for nodes not in the training graph. This project has further treated optimization problems (e.g. graph matching) on graphs as inference problems and developed new models for them. It learns a neural network that directly predicts good solutions (e.g. matchings) to these optimization problems.&nbsp;Then the solution for a new problem can be obtained from the neural network, instead of being optimized separately.&nbsp; &nbsp; It is shown to be very useful in applications that have many such optimization problems but do not require optimal solutions. To make the training objective differentiable, the project has devised a neural network that predicts a distribution of solutions instead of a single solution and then used the expected objective value as the training objective. Then the neural network can be learned through stochastic optimization. The study indicates that this new method significantly reduces the computation time and outperforms over previous neural methods.&nbsp;</p>\n<p>Besides the research activities summarized above, this project has also addressed an inference problem on generalized linear models (GLMs) of categorical data. In particular, it has a new design of GLMs and associated variational optimization methods. The new design improves the scalability and tractability of Bayesian inference for GLMs of categorical data.</p>\n<p>With these new inference tools, the project has developed a new model to analyze opioid overdose data to improve the forecasting of where opioid-related overdose deaths are likely to occur in the near future. The joint work between machine learning researchers and public health researchers has deepened the understanding of such data. The developed model can be integrated into public health programs to provide interventions to targeted areas, and the improved predicting accuracy has the potential to save more lives.&nbsp;&nbsp;</p>\n<p>&nbsp;</p>\n</div>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/06/2023<br>\n\t\t\t\t\tModified by: Liping&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nInference on large graphs is an indispensable step in many learning problems but is well known to be computationally expensive. This project has generalized amortized inference developed for independent data to inference problems on large graphs. The main approach is to train a neural network to perform approximate inference for variables associated with graph nodes or edges. The underlying neural network learns shared knowledge when inferring variables in the graph. The study indicates that this approach greatly speeds up the inference procedure over traditional methods. This project has applied this approach to problems with rich node information (e.g. citation networks) and shown an extra benefit of the new approach: the learned network can perform inference for nodes not in the training graph. This project has further treated optimization problems (e.g. graph matching) on graphs as inference problems and developed new models for them. It learns a neural network that directly predicts good solutions (e.g. matchings) to these optimization problems. Then the solution for a new problem can be obtained from the neural network, instead of being optimized separately.    It is shown to be very useful in applications that have many such optimization problems but do not require optimal solutions. To make the training objective differentiable, the project has devised a neural network that predicts a distribution of solutions instead of a single solution and then used the expected objective value as the training objective. Then the neural network can be learned through stochastic optimization. The study indicates that this new method significantly reduces the computation time and outperforms over previous neural methods. \n\nBesides the research activities summarized above, this project has also addressed an inference problem on generalized linear models (GLMs) of categorical data. In particular, it has a new design of GLMs and associated variational optimization methods. The new design improves the scalability and tractability of Bayesian inference for GLMs of categorical data.\n\nWith these new inference tools, the project has developed a new model to analyze opioid overdose data to improve the forecasting of where opioid-related overdose deaths are likely to occur in the near future. The joint work between machine learning researchers and public health researchers has deepened the understanding of such data. The developed model can be integrated into public health programs to provide interventions to targeted areas, and the improved predicting accuracy has the potential to save more lives.  \n\n \n\n\n \n\n\t\t\t\t\tLast Modified: 01/06/2023\n\n\t\t\t\t\tSubmitted by: Liping Liu"
 }
}