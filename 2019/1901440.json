{
 "awd_id": "1901440",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF: Medium: Collaborative Research: ADMM-NN: A Unified Software/Hardware Framework of DNN Computation and Storage Reduction Using ADMM",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2019-06-01",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 449998.0,
 "awd_amount": 449998.0,
 "awd_min_amd_letter_date": "2019-05-31",
 "awd_max_amd_letter_date": "2021-06-03",
 "awd_abstract_narration": "Deep neural networks (DNNs) have been employed in wide application domains thanks to their extraordinary performance. Hardware implementations of DNNs are of critical importance for the ubiquitous embedded and Internet of Things (IoT) devices, which call for high performance in energy and resource constrained systems. This project aims to address the challenges when mapping complicated DNN models into hardware for energy-efficient and performance-driven implementations. The proposed techniques will promote wider adoptions of deep learning into both high-performance and low-power computing systems. The project will also enhance economic opportunities and have significant societal benefits via solutions that support broader adoption of intelligent systems for big data analytics, weather modeling and forecasting, disease diagnosis and drug delivery, and medical image processing. The research advances will be incorporated into coursework taught by the investigators. Activities on engaging underrepresented, undergraduate, and K12 students will be designed in collaboration with the Northeastern University Center of STEM Education and University of Southern California's Viterbi Center for Engineering Diversity. All software code from the project will be released via GitHub and educational modules and tutorials will be make available to the research community, industry, and government.\r\n \r\nExploring the inherent model redundancy of DNNs, this project will develop an algorithm-hardware co-optimization framework for greatly reducing DNN computation and storage requirements by leveraging ADMM (alternating direction method of multipliers), a powerful optimization technique. This project first solves the challenge in the application of ADMM due to the non-convex objective function in DNN training, and thereby lack of guarantees on solution feasibility, solution quality, and low runtime. Therefore, an integrated framework of ADMM regularization and masked mapping and retraining will be developed and further improvements on solution quality, performance-driven computation/storage reduction, and hardware feasibility will be investigated. Next, the project proposes a unified weight and intermediate result pruning and quantization technique that explores all four redundancy sources of DNN models. Due to the impact on energy efficiency of hardware implementations of DNNs, nearly all DNN models, or at least the most computationally intensive convolutional layers can be then placed on a single chip. Finally, design-time parameterization and algorithm-hardware co-design solutions will be developed for efficient utilization of available hardware resources, achieving high performance, energy efficiency, and adaptation capability. Extensive experimentation and evaluation will be performed to validate and tune the proposed technique with prototype systems using FPGA devices.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Massoud",
   "pi_last_name": "Pedram",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Massoud Pedram",
   "pi_email_addr": "pedram@usc.edu",
   "nsf_id": "000266845",
   "pi_start_date": "2019-05-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3720 S. Flower St.",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900890001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 145128.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 148727.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 156143.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project focused on developing methods and automation tools to facilitate the design of deep learning or deep neural network (DNN) accelerators. The research led to notable advancements in several technical areas:</p>\n<p>(i) A framework was devised for the joint pruning and quantization of DNN weights, enhancing model efficiency.</p>\n<p>(ii) An algorithm-hardware co-design framework was established for mapping DNNs to FPGA hardware. This framework emphasized resource utilization, online adaptivity, performance, and energy efficiency.</p>\n<p>(iii) The development and demonstration of the concept of sparse periodic systolic (SPS) dataflow for accelerating DNNs.</p>\n<p>(iv) The introduction of design techniques for approximate data path computing, particularly applicable to DNN inference.</p>\n<p>(v) The proposition of DNN accelerator design optimization techniques, incorporating mixed-precision quantization, operation packing, and loop reordering to strike a balance between memory footprint and I/O bandwidth, ultimately enhancing overall throughput within the constraints of FPGA resources.</p>\n<p>The research conducted under this NSF grant not only contributed to technological advancement but also expanded economic opportunities in the United States. The solutions developed pave the way for broader adoption of intelligent systems in various domains, including big data analytics, cognitive systems, speech recognition, natural language processing, and time series prediction and analysis. Given the increasing importance of neural networks, deep learning, and machine intelligence in addressing societal challenges such as weather modeling, disease diagnosis, drug delivery, and medical image processing, this research is poised to deliver significant societal benefits.</p>\n<p>Furthermore, the techniques devised for reducing DNN computation and storage requirements can be extrapolated to other types of machine intelligence systems across diverse software and hardware platforms. This will facilitate the wider adoption of deep learning across a spectrum of computing systems, spanning high-performance and low-power devices such as wearables, IoT devices, autonomous systems, unmanned vehicles, and aerial systems.</p>\n<p>Notably, this research has also had a positive impact on education and workforce development, as evidenced by the graduation of two PhD students and two MS students who received partial support from this NSF grant. Their contributions to the field are a testament to the broader impacts of this research endeavor.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/26/2023<br>\n\t\t\t\t\tModified by: Massoud&nbsp;Pedram</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1901440/1901440_10608292_1695746208483_ADMM-NN-Viewgraph-Pedram--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1901440/1901440_10608292_1695746208483_ADMM-NN-Viewgraph-Pedram--rgov-800width.jpg\" title=\"ADMM-NN Project Summary Slide\"><img src=\"/por/images/Reports/POR/2023/1901440/1901440_10608292_1695746208483_ADMM-NN-Viewgraph-Pedram--rgov-66x44.jpg\" alt=\"ADMM-NN Project Summary Slide\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This viewgraph describes the flow used to optimize and map a DNN inference model onto an SoC-class FPGA device</div>\n<div class=\"imageCredit\">Massoud Pedram</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Massoud&nbsp;Pedram</div>\n<div class=\"imageTitle\">ADMM-NN Project Summary Slide</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project focused on developing methods and automation tools to facilitate the design of deep learning or deep neural network (DNN) accelerators. The research led to notable advancements in several technical areas:\n\n(i) A framework was devised for the joint pruning and quantization of DNN weights, enhancing model efficiency.\n\n(ii) An algorithm-hardware co-design framework was established for mapping DNNs to FPGA hardware. This framework emphasized resource utilization, online adaptivity, performance, and energy efficiency.\n\n(iii) The development and demonstration of the concept of sparse periodic systolic (SPS) dataflow for accelerating DNNs.\n\n(iv) The introduction of design techniques for approximate data path computing, particularly applicable to DNN inference.\n\n(v) The proposition of DNN accelerator design optimization techniques, incorporating mixed-precision quantization, operation packing, and loop reordering to strike a balance between memory footprint and I/O bandwidth, ultimately enhancing overall throughput within the constraints of FPGA resources.\n\nThe research conducted under this NSF grant not only contributed to technological advancement but also expanded economic opportunities in the United States. The solutions developed pave the way for broader adoption of intelligent systems in various domains, including big data analytics, cognitive systems, speech recognition, natural language processing, and time series prediction and analysis. Given the increasing importance of neural networks, deep learning, and machine intelligence in addressing societal challenges such as weather modeling, disease diagnosis, drug delivery, and medical image processing, this research is poised to deliver significant societal benefits.\n\nFurthermore, the techniques devised for reducing DNN computation and storage requirements can be extrapolated to other types of machine intelligence systems across diverse software and hardware platforms. This will facilitate the wider adoption of deep learning across a spectrum of computing systems, spanning high-performance and low-power devices such as wearables, IoT devices, autonomous systems, unmanned vehicles, and aerial systems.\n\nNotably, this research has also had a positive impact on education and workforce development, as evidenced by the graduation of two PhD students and two MS students who received partial support from this NSF grant. Their contributions to the field are a testament to the broader impacts of this research endeavor.\n\n \n\n\t\t\t\t\tLast Modified: 09/26/2023\n\n\t\t\t\t\tSubmitted by: Massoud Pedram"
 }
}