{
 "awd_id": "1940109",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Collaborative Research: Inexactness and Data-Awareness in Network Stacks for Distributed Machine Learning",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Darleen Fisher",
 "awd_eff_date": "2019-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2019-08-22",
 "awd_max_amd_letter_date": "2019-08-22",
 "awd_abstract_narration": "The architectures underlying modern network hardware and software have their roots in designs that were developed decades ago. Even though these architectures have evolved in many ways over the years, they remain unchanged in two key aspects: (1) They support ?exact? or complete/absolute reliable communication (either hop-by-hop, or end-to-end, or both); (2) They adhere to strict layering, and the resulting encapsulation and interfaces hide from lower network layers the semantics of the data applications transmit over the network.\r\n\r\nThese design principles place serious impediments for emerging distributed machine learning (ML) training and inference applications. These applications are seeing adoption in a wide variety of important domains, such as, computer vision, robotics, data science, graphics, and speech recognition. Two distinguishing attributes of these applications are: (1) their computations are intrinsically inexact in nature, because these applications rely on computing or utilizing statistical models, and (2) their input and intermediate data have well-defined structure, i.e., tensors, or multi-dimensional arrays of typed data. Give these attributes, enforcing exact communication in a data semantics-unaware fashion limits the potentially enormous benefits of embracing inexactness in these approximate applications.\r\n\r\nThis project explores co-designing ML applications with layers of the network software and hardware stack to allow application-driven cross-layer optimization for energy efficiency, hardware density/capacity, and performance. Given an application-provided overall inexactness budget, this research will explore both how to systematically apportion the budget across network layers, and how different layers can reconfigure their functionality to achieve different levels of approximation.\r\n\t\r\nThis project will develop strawman approaches to encoding structured data and to achieving budget-driven inexact computation over it. The research will use experiments, simulations, and analysis to identify performance benefits to ML applications, and fundamental trade-offs that determine the feasibility of this approach. The resulting inexactness-aware ML software stack could drive hitherto unseen performance and accuracy improvements, and potentially drive future innovations in ML algorithms, systems, and applications.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aditya",
   "pi_last_name": "Akella",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aditya Akella",
   "pi_email_addr": "akella@cs.utexas.edu",
   "nsf_id": "000204197",
   "pi_start_date": "2019-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "1210 W Dayton St",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537061613",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-639a8964-7fff-993b-8779-a8271903ae0a\">\n<p dir=\"ltr\"><span>The architectures underlying modern network hardware and software have their roots in designs that were developed decades ago. These architectures have evolved in many ways over the years, e.g., with new congestion control algorithms, novel approaches to loss and error recovery, novel active queue management techniques, novel switching and dataplane hardware, etc. But they remain unchanged in two key aspects: (1) They strive to support&nbsp; &ldquo;exact&rdquo; or complete/absolute reliable communication (either hop-by-hop, or end-to-end, or both); (2) They adhere to strict layering, and the resulting encapsulation and interfaces hides from lower network layers the semantics of the data inserted into the network by higher network layers.</span></p>\n<p dir=\"ltr\"><span>These traditional design principles, coupled with other architectural ideas and advancements, have proved instrumental in spurring the explosive growth of traditional networked applications, including the Web, social networking applications, Internet video, gaming, etc. However, we argue that for emerging class of datacenter networking applications, e.g., distributed machine learning and inference, these design principles place serious impediments. These applications are seeing adoption in a wide variety of important domains, such as, computer vision, robotics, data science, graphics, and speech recognition. Machine learning models and predictions form the backends driving many user-facing crucial applications.&nbsp;</span></p>\n<p dir=\"ltr\"><span>This project explores&nbsp;</span>co-designing machine learning applications with layers of the network software and hardware stack to allow application-driven cross-layer optimization such that the performance of machine learning algorithms will improve substantially. This project will undertake an examination of the tradeoffs in core mechanisms for, and the benefits of, designing network hardware and software with tuneable inexactness and cross-layer data visibility as first-class primitives in support of distributed machine learning based applications.&nbsp;</p>\n<p dir=\"ltr\">Intellectual Merit: This project explored the novel idea of alleviating the mismatch between the semantics required by the applications, and those supported by the network protocols and algorithms, by exploiting approximate networking and data-aware interface between network layers. It shed initial light on a variety of fundamental issues, such as, how much inexactness at each layer is tolerable for a machine learning application; how to optimally apportion approximation budget; how to achieve cross-layer coordination; and, how much can the application benefit as a result. The project has laid the foundation for faster, more flexible, and more energy and cost efficient machine learning applications and infrastructure, and spur innovation in machine learning.</p>\n<span id=\"docs-internal-guid-33b29f54-7fff-4dea-723b-d98787d30af5\">\n<div>Broader Impact: Results from this research were incorporated into graduate and undergraduate classes at UW-Madison and Cornell. The PI sought advice and feedback from industry collaborators at Microsoft and Google on key ideas and identified pontential benefits and avenues for future collaboration and integration into production machine learning systems.</div>\n</span></span></p>\n<p><span id=\"docs-internal-guid-9247c5d7-7fff-11eb-8f25-a62059d9fff6\">\n<div><span><br /></span></div>\n</span></p>\n<p><span id=\"docs-internal-guid-639a8964-7fff-993b-8779-a8271903ae0a\"><span id=\"docs-internal-guid-33b29f54-7fff-4dea-723b-d98787d30af5\"> </span><span id=\"docs-internal-guid-6c2e0f86-7fff-0d4b-5fca-eb0fd67ebbaa\">\n<div><span><br /></span></div>\n</span>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/06/2021<br>\n\t\t\t\t\tModified by: Aditya&nbsp;Akella</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThe architectures underlying modern network hardware and software have their roots in designs that were developed decades ago. These architectures have evolved in many ways over the years, e.g., with new congestion control algorithms, novel approaches to loss and error recovery, novel active queue management techniques, novel switching and dataplane hardware, etc. But they remain unchanged in two key aspects: (1) They strive to support  \"exact\" or complete/absolute reliable communication (either hop-by-hop, or end-to-end, or both); (2) They adhere to strict layering, and the resulting encapsulation and interfaces hides from lower network layers the semantics of the data inserted into the network by higher network layers.\nThese traditional design principles, coupled with other architectural ideas and advancements, have proved instrumental in spurring the explosive growth of traditional networked applications, including the Web, social networking applications, Internet video, gaming, etc. However, we argue that for emerging class of datacenter networking applications, e.g., distributed machine learning and inference, these design principles place serious impediments. These applications are seeing adoption in a wide variety of important domains, such as, computer vision, robotics, data science, graphics, and speech recognition. Machine learning models and predictions form the backends driving many user-facing crucial applications. \nThis project explores co-designing machine learning applications with layers of the network software and hardware stack to allow application-driven cross-layer optimization such that the performance of machine learning algorithms will improve substantially. This project will undertake an examination of the tradeoffs in core mechanisms for, and the benefits of, designing network hardware and software with tuneable inexactness and cross-layer data visibility as first-class primitives in support of distributed machine learning based applications. \nIntellectual Merit: This project explored the novel idea of alleviating the mismatch between the semantics required by the applications, and those supported by the network protocols and algorithms, by exploiting approximate networking and data-aware interface between network layers. It shed initial light on a variety of fundamental issues, such as, how much inexactness at each layer is tolerable for a machine learning application; how to optimally apportion approximation budget; how to achieve cross-layer coordination; and, how much can the application benefit as a result. The project has laid the foundation for faster, more flexible, and more energy and cost efficient machine learning applications and infrastructure, and spur innovation in machine learning.\n\nBroader Impact: Results from this research were incorporated into graduate and undergraduate classes at UW-Madison and Cornell. The PI sought advice and feedback from industry collaborators at Microsoft and Google on key ideas and identified pontential benefits and avenues for future collaboration and integration into production machine learning systems.\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 12/06/2021\n\n\t\t\t\t\tSubmitted by: Aditya Akella"
 }
}