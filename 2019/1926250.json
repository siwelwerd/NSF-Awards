{
 "awd_id": "1926250",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: F: Collaborative Research: Foundations of Responsible Data Management",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2019-01-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 230950.0,
 "awd_amount": 230950.0,
 "awd_min_amd_letter_date": "2019-03-14",
 "awd_max_amd_letter_date": "2019-03-14",
 "awd_abstract_narration": "Big Data technology promises to improve people's lives, accelerate scientific discovery and innovation, and bring about positive societal change. Yet, if not used responsibly, this same technology can reinforce inequity, limit accountability and infringe on the privacy of individuals: irreproducible results can influence global economic policy; algorithmic changes in search engines can sway elections and incite violence; models based on biased data can legitimize and amplify discrimination in the criminal justice system; algorithmic hiring practices can silently reinforce diversity issues and potentially violate the law; privacy and security violations can erode the trust of users and expose companies to legal and financial consequences. The focus of this project is on using Big Data technology responsibly -- in accordance with ethical and moral norms, and legal and policy considerations. This project establishes a foundational new role for data management technology, in which managing the responsible use of data across the lifecycle becomes a core system requirement. The broader goal of this project is to help usher in a new phase of data science, in which the technology considers not only the accuracy of the model but also ensures that the data on which it depends respect the relevant laws, societal norms, and impacts on humans. \r\n\r\nThis project defines properties of responsible data management, which include fairness (and the related concepts of representativeness and diversity), transparency (and accountability), and data protection. It complements what is done in the data mining and machine learning communities, where the focus is on analyzing fairness, accountability and transparency of the final step in the data analysis lifecycle, and considers the problems that can be introduced upstream from data analysis: during dataset selection, cleaning, pre-processing, integration, and sharing. This project develops conceptual frameworks and algorithmic techniques that support fairness, transparency and data protection properties through all stages of the data usage lifecycle: beginning with data discovery and acquisition, through cleaning, integration, querying, and ultimately analysis. The contributions are structured along three aims. Aim 1 considers responsible dataset discovery, profiling, and integration. Aim 2 considers responsible query processing and develops a general framework for declarative specification, checking and enforcement of fairness, representativeness and diversity. Aim 3 incorporates data protection into the lifecycle, develops techniques to facilitate sharing of sensitive data, and considers the tradeoffs between privacy and transparency. This project is poised to establish a multidisciplinary research agenda around responsible data management as a critical factor in enabling fairness, accountability and transparency in decision-making and prediction systems. Additional information about the project is available at DataResponsibly.com.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Julia",
   "pi_last_name": "Stoyanovich",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Julia Stoyanovich",
   "pi_email_addr": "stoyanovich@nyu.edu",
   "nsf_id": "000624075",
   "pi_start_date": "2019-03-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "70 Washington Square S.",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  },
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "8060",
   "pgm_ref_txt": "SEES Unsolicited"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 230950.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-fe7258f7-7fff-829f-934d-3f597b6afc4a\"> </span></p>\n<p dir=\"ltr\"><span>The goal of this project was to establish the foundations of responsible data management, where ethical and legal considerations are operationalized as core requirements of data-intensive systems.&nbsp; Towards this goal, the PIs developed conceptual frameworks and algorithmic techniques that operationalize fairness, diversity and representativeness, transparency and accountability, and privacy and data protection across the data usage lifecycle.&nbsp; This work was published in premier computer science venues, received best-paper awards at ACM SIGMOD and InfoVis, was shared with the technical community through numerous keynote presentations and invited talks, and was disseminated to the communities of target users in the form of open-source tools and prototypes.</span></p>\n<p dir=\"ltr\"><span>Specific technical contributions of this project included novel methods for dataset discovery, profiling and integration, where the goal was to identify and mitigate inadequate data coverage for historically under-represented subgroups, and to improve accuracy and fairness of down-stream data analysis for such groups.&nbsp; The PIs also developed methods and released tools for debugging data distributions, where the impact of specific preprocessing operators on representation and performance is traced automatically through a series of data transformations.&nbsp; Further, the PIs proposed techniques for identifying misleading assertions, allowing the recipient of the information to challenge cherry-picked results. The PIs also organized a new research direction in AI for public interest technology, designing fairness metrics for spatio-temporal data, using them in new architectures for learning fair, integrated representations of multi-modal urban datasets.&nbsp; These learned representations, called equitensors, improve accuracy on downstream prediction tasks while reducing risk of discrimination, and help us interpolate and extrapolate data in new contexts for scenario-specific training and testing of predictive models.&nbsp;&nbsp;</span></p>\n<p dir=\"ltr\"><span>This project also resulted in technical contributions to the responsible design and analysis of ranking methods.&nbsp; The PIs proposed algorithms that interrogate and enhance different aspects of fairness, diversity and stability of algorithmic rankers.&nbsp; The specific methods drew from, and advanced, the state of the art in a range of computer science and data science disciplines, from computational geometry, to game theory, to causal inference.&nbsp; Further, using the nutritional label metaphor, the PIs developed techniques and built tools that explain the ranking methodology and its results to a range of stakeholders. This metaphor was then used to meet the transparency and interpretability requirements beyond algorithmic ranking.</span></p>\n<p dir=\"ltr\"><span>Motivated by the observation that data too sensitive to be \"open\" for analysis typically remains \"closed\" as proprietary information, undermining efforts to make algorithmic systems more fair, transparent and accountable, the PIs made technical contributions in support of safe, privacy-preserving, and responsible data sharing, including new models and methods forfor generating synthetic datasets for testing and early-stage research to preserve privacy and ensure fairness.&nbsp;</span></p>\n<p dir=\"ltr\"><span>In addition to the technical contributions, PIs engaged in high-impact educational, policy and dissemination activities, delivering results of this work into communities of practice in science, government and non-profit contexts. This work resulted in the establishment of a responsible&nbsp;</span>data science ?pillar? at the Michigan Institute for Data Science, and formed the basis for a first of its kind comprehensive responsible data science curriculum at New York University. &nbsp; The PIs also spearheaded efforts to make responsible data science available and accessible to a broad range of participants, by creating a ?Data Science Ethics? MOOC that is carried by several platforms, and a peer-learning course ?We are AI? that is offered by public libraries to the broader public.&nbsp; Finally, the work of this project helped inform ongoing policy and regulation efforts around ?automated decision systems? nationally and internationally.&nbsp;</p>\n<p dir=\"ltr\">Last but not least, this project helped make ethics and legal compliance mainstream topics at data management venues.&nbsp; The PIs, their students and collaborators, and the data management research community at large, are continuing to build a rich technical, educational, and policy agenda around the topics of this proposal, with much progress expected in years to come.&nbsp;</p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/23/2021<br>\n\t\t\t\t\tModified by: Julia&nbsp;Stoyanovich</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThe goal of this project was to establish the foundations of responsible data management, where ethical and legal considerations are operationalized as core requirements of data-intensive systems.  Towards this goal, the PIs developed conceptual frameworks and algorithmic techniques that operationalize fairness, diversity and representativeness, transparency and accountability, and privacy and data protection across the data usage lifecycle.  This work was published in premier computer science venues, received best-paper awards at ACM SIGMOD and InfoVis, was shared with the technical community through numerous keynote presentations and invited talks, and was disseminated to the communities of target users in the form of open-source tools and prototypes.\nSpecific technical contributions of this project included novel methods for dataset discovery, profiling and integration, where the goal was to identify and mitigate inadequate data coverage for historically under-represented subgroups, and to improve accuracy and fairness of down-stream data analysis for such groups.  The PIs also developed methods and released tools for debugging data distributions, where the impact of specific preprocessing operators on representation and performance is traced automatically through a series of data transformations.  Further, the PIs proposed techniques for identifying misleading assertions, allowing the recipient of the information to challenge cherry-picked results. The PIs also organized a new research direction in AI for public interest technology, designing fairness metrics for spatio-temporal data, using them in new architectures for learning fair, integrated representations of multi-modal urban datasets.  These learned representations, called equitensors, improve accuracy on downstream prediction tasks while reducing risk of discrimination, and help us interpolate and extrapolate data in new contexts for scenario-specific training and testing of predictive models.  \nThis project also resulted in technical contributions to the responsible design and analysis of ranking methods.  The PIs proposed algorithms that interrogate and enhance different aspects of fairness, diversity and stability of algorithmic rankers.  The specific methods drew from, and advanced, the state of the art in a range of computer science and data science disciplines, from computational geometry, to game theory, to causal inference.  Further, using the nutritional label metaphor, the PIs developed techniques and built tools that explain the ranking methodology and its results to a range of stakeholders. This metaphor was then used to meet the transparency and interpretability requirements beyond algorithmic ranking.\nMotivated by the observation that data too sensitive to be \"open\" for analysis typically remains \"closed\" as proprietary information, undermining efforts to make algorithmic systems more fair, transparent and accountable, the PIs made technical contributions in support of safe, privacy-preserving, and responsible data sharing, including new models and methods forfor generating synthetic datasets for testing and early-stage research to preserve privacy and ensure fairness. \nIn addition to the technical contributions, PIs engaged in high-impact educational, policy and dissemination activities, delivering results of this work into communities of practice in science, government and non-profit contexts. This work resulted in the establishment of a responsible data science ?pillar? at the Michigan Institute for Data Science, and formed the basis for a first of its kind comprehensive responsible data science curriculum at New York University.   The PIs also spearheaded efforts to make responsible data science available and accessible to a broad range of participants, by creating a ?Data Science Ethics? MOOC that is carried by several platforms, and a peer-learning course ?We are AI? that is offered by public libraries to the broader public.  Finally, the work of this project helped inform ongoing policy and regulation efforts around ?automated decision systems? nationally and internationally. \nLast but not least, this project helped make ethics and legal compliance mainstream topics at data management venues.  The PIs, their students and collaborators, and the data management research community at large, are continuing to build a rich technical, educational, and policy agenda around the topics of this proposal, with much progress expected in years to come. \n\n\n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/23/2021\n\n\t\t\t\t\tSubmitted by: Julia Stoyanovich"
 }
}