{
 "awd_id": "1903207",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Protecting Social Choice Mechanisms from Malicious Influence",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2019-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 368178.0,
 "awd_amount": 376178.0,
 "awd_min_amd_letter_date": "2019-07-26",
 "awd_max_amd_letter_date": "2020-04-24",
 "awd_abstract_narration": "Vulnerability of social choice mechanisms to malicious influence is a long-standing concern. An increasingly important means of malicious influence involves digital media platforms through the use of fake or highly misleading information. The net effect of such influence is to change the attitudes of mechanism participants about the relative importance of issues, as well as their perception of candidates and their views and, as a consequence, change social choice outcomes.  This proposal aims to develop systematic quantitative and algorithmic approaches for studying control of social choice mechanisms when manipulation targets perceptions about and views on issues. Consequently, this research has the potential to significantly contribute to the broader interdisciplinary study of vulnerability of social choice mechanisms to malicious influence.  \r\n\r\nSpecifically, this research will investigate a novel model of control of social choice mechanisms which builds on the spatial theory of voting in which voters' preferences over candidates are generated based on their relative similarity on issues. In this model, the primary target of manipulation is perception of issues, both in terms of their relative importance, as well as perception of candidates' views. Algorithmically, this opens several new classes of problems with little prior research, such as the problem of issue selection, where the malicious party may select which issues are most salient, or opinion manipulation where a malicious actor aims to mislead mechanism participants about where the candidates stand on issues. Conceptually, this problem has a more direct connection to common means of subversion of social choice mechanism in reality, such as advertising and campaigning, both on social and conventional media. Furthermore, this project will study the dual problem of protecting social choice mechanisms in the spatial model, providing a series of novel modeling and algorithmic contributions for this problem.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yevgeniy",
   "pi_last_name": "Vorobeychik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yevgeniy Vorobeychik",
   "pi_email_addr": "yvorobeychik@wustl.edu",
   "nsf_id": "000667978",
   "pi_start_date": "2019-07-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Washington University",
  "inst_street_address": "1 BROOKINGS DR",
  "inst_street_address_2": "",
  "inst_city_name": "SAINT LOUIS",
  "inst_state_code": "MO",
  "inst_state_name": "Missouri",
  "inst_phone_num": "3147474134",
  "inst_zip_code": "631304862",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MO01",
  "org_lgl_bus_name": "WASHINGTON UNIVERSITY, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "L6NFUM28LQM5"
 },
 "perf_inst": {
  "perf_inst_name": "Washington University",
  "perf_str_addr": "1 Brookings Drive",
  "perf_city_name": "St. Louis",
  "perf_st_code": "MO",
  "perf_st_name": "Missouri",
  "perf_zip_code": "631304899",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "MO01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 368178.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-39d965e6-7fff-b029-accc-f518936cb3ca\">\n<p dir=\"ltr\"><span>The vulnerability of social choice mechanisms to malicious influence is a long-standing concern. This issue has recently gained special importance in the field of value alignment research, where pairwise comparison preferences from individuals are aggregated through the learning of a utility function, which effectively serves as a social choice mechanism used to better align policies (such as responses to prompts in the case of LLMs) with human values (for example, improving helpfulness and reducing harm). This project, therefore, had two broad goals: (1) to investigate the vulnerabilities of social choice mechanisms to various forms of malicious tampering, and (2) to develop robust approaches for preference aggregation at scale.</span></p>\n<p dir=\"ltr\"><span>To achieve these goals, we made foundational advances on both fronts, addressing classical forms of social choice mechanisms, such as those using positional scoring, as well as methods that implicitly aggregate preferences by learning a representative utility function from individual preference rankings. Specifically, much of our focus was on preference aggregation within the spatial model of social choice, where individuals express preferences based on their similarity to a fixed and finite set of available options, evaluated by individual attributes. One key insight was that preference diversity is crucial to achieving robustness: when preferences cluster into a small number of distinct categories with broad homogeneity within each, malicious tampering becomes computationally easy. However, when preferences are highly diverse, tampering becomes intractable. Additionally, we tackled the problem of learning preferences from preference rankings, demonstrating that actively selecting preference ranking queries (from a potentially infinite set of possibilities) enables successful preference aggregation where it would otherwise be intractable. Furthermore, we found that typical preference aggregation schemes used in value alignment are highly vulnerable to malicious data tampering. However, spreading data collection among a large number of annotators and ensuring sufficient redundancy can significantly reduce this risk.</span></p>\n<p dir=\"ltr\"><span>This project trained five PhD students (four female and one male), and one MS student. The PhD students made significant advances in the design and analysis of social choice mechanisms in both the traditional model (with a fixed set of outcomes under consideration) and the modern setting of value alignment (where the set of outcomes corresponds to a real vector space). Moreover, this project contributed to the development of educational materials for several undergraduate and graduate courses, including </span><span>AI and Society</span><span>, an undergraduate course at Washington University in St. Louis (WashU), and </span><span>Adversarial AI</span><span>, a graduate course at WashU. For example, the </span><span>Adversarial AI</span><span> course introduced a module on adversarial considerations in computational social choice, co-taught by a PhD student, providing valuable educational training. The </span><span>AI and Society</span><span> course includes a module on moral philosophy and ethics, aiming to bridge theoretical concepts from moral philosophy with the practical development and analysis of algorithms. The materials for these courses, particularly those involving in-class discussions, were strongly influenced by the research conducted as part of this project.</span></p>\n</span></p><br>\n<p>\n Last Modified: 09/30/2024<br>\nModified by: Yevgeniy&nbsp;Vorobeychik</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\nThe vulnerability of social choice mechanisms to malicious influence is a long-standing concern. This issue has recently gained special importance in the field of value alignment research, where pairwise comparison preferences from individuals are aggregated through the learning of a utility function, which effectively serves as a social choice mechanism used to better align policies (such as responses to prompts in the case of LLMs) with human values (for example, improving helpfulness and reducing harm). This project, therefore, had two broad goals: (1) to investigate the vulnerabilities of social choice mechanisms to various forms of malicious tampering, and (2) to develop robust approaches for preference aggregation at scale.\n\n\nTo achieve these goals, we made foundational advances on both fronts, addressing classical forms of social choice mechanisms, such as those using positional scoring, as well as methods that implicitly aggregate preferences by learning a representative utility function from individual preference rankings. Specifically, much of our focus was on preference aggregation within the spatial model of social choice, where individuals express preferences based on their similarity to a fixed and finite set of available options, evaluated by individual attributes. One key insight was that preference diversity is crucial to achieving robustness: when preferences cluster into a small number of distinct categories with broad homogeneity within each, malicious tampering becomes computationally easy. However, when preferences are highly diverse, tampering becomes intractable. Additionally, we tackled the problem of learning preferences from preference rankings, demonstrating that actively selecting preference ranking queries (from a potentially infinite set of possibilities) enables successful preference aggregation where it would otherwise be intractable. Furthermore, we found that typical preference aggregation schemes used in value alignment are highly vulnerable to malicious data tampering. However, spreading data collection among a large number of annotators and ensuring sufficient redundancy can significantly reduce this risk.\n\n\nThis project trained five PhD students (four female and one male), and one MS student. The PhD students made significant advances in the design and analysis of social choice mechanisms in both the traditional model (with a fixed set of outcomes under consideration) and the modern setting of value alignment (where the set of outcomes corresponds to a real vector space). Moreover, this project contributed to the development of educational materials for several undergraduate and graduate courses, including AI and Society, an undergraduate course at Washington University in St. Louis (WashU), and Adversarial AI, a graduate course at WashU. For example, the Adversarial AI course introduced a module on adversarial considerations in computational social choice, co-taught by a PhD student, providing valuable educational training. The AI and Society course includes a module on moral philosophy and ethics, aiming to bridge theoretical concepts from moral philosophy with the practical development and analysis of algorithms. The materials for these courses, particularly those involving in-class discussions, were strongly influenced by the research conducted as part of this project.\n\t\t\t\t\tLast Modified: 09/30/2024\n\n\t\t\t\t\tSubmitted by: YevgeniyVorobeychik\n"
 }
}