{
 "awd_id": "1919453",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Attitude towards information in multi-agent settings: Understanding and mitigating Avoidance and Over-Evaluation",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032924710",
 "po_email": "clagonza@nsf.gov",
 "po_sign_block_name": "Claudia Gonzalez-Vallejo",
 "awd_eff_date": "2019-08-15",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2019-08-14",
 "awd_max_amd_letter_date": "2021-09-14",
 "awd_abstract_narration": "New technologies in sensing, data communication and processing allow for extensive instrumentation of the built environment, and the massive flow of information collectable by sensors can transform the operation and the functionality of urban systems. However, this development depends also on the attitude of citizens and stakeholders toward information. This project investigates how interacting agents take decisions about collecting information, with focus on users and managers of urban systems interacting with public policies. For rational and isolated agents acting without external constraints, \"information never hurts\" and data with low impact on the agents' belief have a small value. This implies, for example, that these agents are always willing to install free (or cheap) sensors, and to install expensive ones only if they provide high-impact information. However, these intuitive properties do not hold true in multi-agent settings, when agents compete one against each other, nor for agents acting under external constraints as those imposed by regulations. Integrating analysis in social science, engineering and computer science, the project will develop a framework for modeling the attitude towards information in these contexts, depending on the agents' preference and the external regulations.\r\n\r\nThe goals of the project are: 1) To develop a framework for assessing the Value of Information in multi-agent settings, modeling the interaction between policy makers and decision makers following external regulations, 2) to gather and analyze empirical data about the attitude toward information, using surveys and interviews among users, and calibrate the models developed in (1), 3) to design mechanisms alleviating Information Avoidance and Over Evaluation, and assess their effectiveness.  The project integrates probabilistic models of quantities to be measured and of sensor performance, agents' utility functions and external constraints, optimization methods and behavior modeling, to assess the Value or Information via Bayesian pre-posterior analysis. Such approach will allow understanding how Information Avoidance and Over Evaluation arise, and how appropriate mechanisms of incentives and regulations can mitigate them. The project's outcomes will be key for a better empirical understanding of the attitude towards information, for developing effective large-scale monitor of the built environment and public policies promoting effective information collection, integrating societal and agents' utilities.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matteo",
   "pi_last_name": "Pozzi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matteo Pozzi",
   "pi_email_addr": "mpozzi@cmu.edu",
   "nsf_id": "000636326",
   "pi_start_date": "2019-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Maria-Florina",
   "pi_last_name": "Balcan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maria-Florina Balcan",
   "pi_email_addr": "ninamf@cs.cmu.edu",
   "nsf_id": "000537870",
   "pi_start_date": "2019-08-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Silvia",
   "pi_last_name": "Saccardo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Silvia Saccardo",
   "pi_email_addr": "ssaccard@andrew.cmu.edu",
   "nsf_id": "000768949",
   "pi_start_date": "2019-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 Forbes Ave",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132100",
   "pgm_ele_name": "Decision, Risk & Mgmt Sci"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 413934.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 86066.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>A rational decision maker, when acting in isolation, should always collect free information, according to the principle that \"information never hurts.\" However, when multiple agents interact, in some settings they can find appropriate to avoid free information: this is the phenomenon of \"Information Avoidance\" (IA). Better understanding IA is crucial for promoting a sustainable and efficient integration of sensors in urban systems, since examples of IA (i.e. of cases when system managers or users \"prefer not to know\") have been observed in many circumstances.</p>\r\n<p>This project has investigated how IA emerges from the interaction among agents: we have focused on two related problems. In the first one, an agent is taking decisions under \"epistemic constraints,\" as those imposed by societal regulations. For example, a policy may impose on the owner of an asset to repair it when its probability of failure (that is an epistemic quantity) is high. The typical decision problem is illustrated in Figure 1, where the \"agent\" and \"society\" take different actions and got different losses. In the second problem, multiple agents compete or cooperate while managing different parts of a system.</p>\r\n<p>Overcoming the impact of selfish behavior of rational players in multiagent systems, as that related to IA, is a fundamental problem in game theory. In the context of these problems, the main achievements of this project have been:</p>\r\n<p>An analysis, via Partially Observable Markov Decision Processes, of IA in sequential decision making, under epistemic constraints. We have shown how to assess VoI in this context, for the value of collecting information at current time, and of that of collecting sequential information in time. We have illustrated how these values are interrelated and how IA can occur, depending on the specific constraints.</p>\r\n<p>An analysis of the VoI for inspecting components in systems managed by multiple agents, using game theory and Nash equilibrium. We have focused on binary systems made up of binary components, where agents taking maintenance actions are responsible for the repair costs of their own components, and the penalty for system failure is shared among all agents. We show how, for example, when the information is perfect, for simple systems such as series and parallel systems, under the assumption that the global Nash equilibrium is selected, the VoI of revealing one component's status is always non-negative. When a local equilibrium is selected, we illustrate that the VoI can be negative, and so IA can occur. For general systems, even in cases when the \"best\" equilibrium is selected, we have found out, quite surprisingly, that the VoI can be negative for all the agents involved in the game. This happens when the information can trigger a Prisoner-Dilemma configuration. Realizing this, all agents prefer to avoid information (i.e., they prefer not to inspect).</p>\r\n<p>We have shown how subsidies can alleviate IA. Subsidies can reduce the so-called \"price of anarchy\" for the system; this ensures that the harmful effect of the selfish behavior and lack of coordination of the agents on the social cost is minimized. But subsidies can also remove the occurrence of IA, forcing the VoI to be positive. We have shown that the design of appropriate subsidies is computationally hard but, by processing data about the behavior of the agents, a good subsidy mechanism can be designed with a relatively small computational effort.</p>\r\n<p>We also explored behavioral factors that drive IA. Specifically, we examined how salience, perceived importance, and the valence of anticipated beliefs shape individuals' willingness to seek or avoid information. These psychological mechanisms provide further insight into when agents may prefer to remain uninformed (even when information is freely available).</p>\r\n<p>Overall, the outcomes of this project will be relevant for promoting a better integration between public policies and the instrumentation of urban systems. Our framework allows the identification of effective schemes for information collection that account for preferences and utilities of agents, as common citizens and public managers, including their tendency to IA. Also, it provides guidelines to policy makers, identifying appropriate mechanisms to alleviate IA, using appropriate subsidy schemes.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/29/2025<br>\nModified by: Matteo&nbsp;Pozzi</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/1919453/1919453_10633808_1738186167749_DM_epistemic--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2025/1919453/1919453_10633808_1738186167749_DM_epistemic--rgov-800width.jpg\" title=\"DM_Epistemic\"><img src=\"/por/images/Reports/POR/2025/1919453/1919453_10633808_1738186167749_DM_epistemic--rgov-66x44.jpg\" alt=\"DM_Epistemic\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Scheme for decision making of an agent acting under the constraints of society.</div>\n<div class=\"imageCredit\">PI and Co-PIs</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Matteo&nbsp;Pozzi\n<div class=\"imageTitle\">DM_Epistemic</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nA rational decision maker, when acting in isolation, should always collect free information, according to the principle that \"information never hurts.\" However, when multiple agents interact, in some settings they can find appropriate to avoid free information: this is the phenomenon of \"Information Avoidance\" (IA). Better understanding IA is crucial for promoting a sustainable and efficient integration of sensors in urban systems, since examples of IA (i.e. of cases when system managers or users \"prefer not to know\") have been observed in many circumstances.\r\n\n\nThis project has investigated how IA emerges from the interaction among agents: we have focused on two related problems. In the first one, an agent is taking decisions under \"epistemic constraints,\" as those imposed by societal regulations. For example, a policy may impose on the owner of an asset to repair it when its probability of failure (that is an epistemic quantity) is high. The typical decision problem is illustrated in Figure 1, where the \"agent\" and \"society\" take different actions and got different losses. In the second problem, multiple agents compete or cooperate while managing different parts of a system.\r\n\n\nOvercoming the impact of selfish behavior of rational players in multiagent systems, as that related to IA, is a fundamental problem in game theory. In the context of these problems, the main achievements of this project have been:\r\n\n\nAn analysis, via Partially Observable Markov Decision Processes, of IA in sequential decision making, under epistemic constraints. We have shown how to assess VoI in this context, for the value of collecting information at current time, and of that of collecting sequential information in time. We have illustrated how these values are interrelated and how IA can occur, depending on the specific constraints.\r\n\n\nAn analysis of the VoI for inspecting components in systems managed by multiple agents, using game theory and Nash equilibrium. We have focused on binary systems made up of binary components, where agents taking maintenance actions are responsible for the repair costs of their own components, and the penalty for system failure is shared among all agents. We show how, for example, when the information is perfect, for simple systems such as series and parallel systems, under the assumption that the global Nash equilibrium is selected, the VoI of revealing one component's status is always non-negative. When a local equilibrium is selected, we illustrate that the VoI can be negative, and so IA can occur. For general systems, even in cases when the \"best\" equilibrium is selected, we have found out, quite surprisingly, that the VoI can be negative for all the agents involved in the game. This happens when the information can trigger a Prisoner-Dilemma configuration. Realizing this, all agents prefer to avoid information (i.e., they prefer not to inspect).\r\n\n\nWe have shown how subsidies can alleviate IA. Subsidies can reduce the so-called \"price of anarchy\" for the system; this ensures that the harmful effect of the selfish behavior and lack of coordination of the agents on the social cost is minimized. But subsidies can also remove the occurrence of IA, forcing the VoI to be positive. We have shown that the design of appropriate subsidies is computationally hard but, by processing data about the behavior of the agents, a good subsidy mechanism can be designed with a relatively small computational effort.\r\n\n\nWe also explored behavioral factors that drive IA. Specifically, we examined how salience, perceived importance, and the valence of anticipated beliefs shape individuals' willingness to seek or avoid information. These psychological mechanisms provide further insight into when agents may prefer to remain uninformed (even when information is freely available).\r\n\n\nOverall, the outcomes of this project will be relevant for promoting a better integration between public policies and the instrumentation of urban systems. Our framework allows the identification of effective schemes for information collection that account for preferences and utilities of agents, as common citizens and public managers, including their tendency to IA. Also, it provides guidelines to policy makers, identifying appropriate mechanisms to alleviate IA, using appropriate subsidy schemes.\r\n\n\n\t\t\t\t\tLast Modified: 01/29/2025\n\n\t\t\t\t\tSubmitted by: MatteoPozzi\n"
 }
}