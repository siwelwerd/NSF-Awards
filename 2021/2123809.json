{
 "awd_id": "2123809",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: SCH: Trustworthy and Explainable AI for Neurodegenerative Diseases",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2025-09-30",
 "tot_intn_awd_amt": 840000.0,
 "awd_amount": 856000.0,
 "awd_min_amd_letter_date": "2021-09-09",
 "awd_max_amd_letter_date": "2023-07-31",
 "awd_abstract_narration": "Driven by its performance accuracy, machine learning (ML) has been used extensively for various applications in the healthcare domain. Despite its promising performance, researchers and the public have grown alarmed by two unsettling deficiencies of these otherwise useful and powerful models. First, there is a lack of trustworthiness - ML models are prone to interference or deception and exhibit erratic behaviors when in action dealing with unseen data, despite good practice during the training phase. Second, there is a lack of interpretability - ML models have been described as 'black-boxes' because there is little explanation for why the models make the predictions they do. This has called into question the applicability of ML to decision-making in critical scenarios such as image-based disease diagnostics or medical treatment recommendation. The ultimate goal of this project is to develop computational foundation for trustworthy and explainable Artificial Intelligence (AI), and offer a low-cost and non-invasive ML-based approach to early diagnosis of neurodegenerative diseases. In particular, the project aims to develop computational theories, ML algorithms, and prototype systems. The project includes developing principled solutions to trustworthy ML and making the ML prediction process transparent to end-users. The later will focus on explaining how and why an ML model makes such a prediction, while dissecting its underlying structure for deeper understanding. The proposed models are further extended to a multi-modal and spatial-temporal framework, an important aspect of applying ML models to healthcare. A verification framework with end-users is defined, which will further enhance the trustworthiness of the prototype systems. This project will benefit a variety of high-impact AI-based applications in terms of their explainability, trustworthy, and verifiability. It not only advances the research fronts of deep learning and AI, but also supports transformations in diagnosing neurodegenerative diseases. \r\n\r\nThis project will develop the computational foundation for trustworthy and explainable AI with several innovations. First, the project will systematically study the trustworthiness of ML systems. This will be measured by novel metrics such as, adversarial robustness and semantic saliency, and will be carried out to establish the theoretical basis and practical limits of trustworthiness of ML algorithms. Second, the project provides a paradigm shift for explainable AI, explaining how and why a ML model makes its prediction, moving away from ad-hoc explanations (i.e. what features are important to the prediction). A proof-based approach, which probes all the hidden layers of a given model to identify critical layers and neurons involved in a prediction from a local point of view, will be devised. Third, a verification framework, where users can verify the model's performance and explanations with proofs, will be designed to further enhance the trustworthiness of the system. Finally, the project also advances the frontier of neurodegenerative diseases early diagnosis from multimodal imaging and longitudinal data by: (i) identifying retinal vasculature biomarkers using proof-based probing in biomarker graph networks; (ii) connecting biomarkers of the retina and the brain vasculature via cross- modality explainable AI model; and, (iii) recognizing the longitudinal trajectory of vasculature biomarkers via a spatio-temporal recurrent explainable model. This synergistic effort between computer science and medicine will enable a wide range of applications to trustworthy and explainable AI for healthcare. The results of this project will be assimilated into the courses and summer programs that the research team have developed with specially designed projects to train students with trustworthy and explainable AI.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "My",
   "pi_last_name": "Thai",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "My T Thai",
   "pi_email_addr": "mythai@cise.ufl.edu",
   "nsf_id": "000391957",
   "pi_start_date": "2021-09-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ruogu",
   "pi_last_name": "Fang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ruogu Fang",
   "pi_email_addr": "ruogu.fang@bme.ufl.edu",
   "nsf_id": "000678411",
   "pi_start_date": "2021-09-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Adolfo",
   "pi_last_name": "Ramirez-Zamora",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Adolfo Ramirez-Zamora",
   "pi_email_addr": "adolfo.ramirez-zamora@neurology.ufl.edu",
   "nsf_id": "000850090",
   "pi_start_date": "2021-09-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1 University of Florida",
  "perf_city_name": "Gainesville",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326112002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  },
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 840000.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": null
}