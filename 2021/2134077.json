{
 "awd_id": "2134077",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: New Perspectives on Deep Learning: Bridging Approximation, Statistical, and Algorithmic Theories",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922948",
 "po_email": "slevine@nsf.gov",
 "po_sign_block_name": "Stacey Levine",
 "awd_eff_date": "2021-11-01",
 "awd_exp_date": "2024-10-31",
 "tot_intn_awd_amt": 225000.0,
 "awd_amount": 225000.0,
 "awd_min_amd_letter_date": "2021-08-03",
 "awd_max_amd_letter_date": "2021-08-03",
 "awd_abstract_narration": "Deep Learning (DL) has led to a renaissance in neural network methods in data-driven science and engineering. The development of DL systems and applications, including computer vision and natural language understanding, has been led primarily by experiments and engineering practice. Mathematical analysis has only begun to provide insights into these complex machine learning systems. The lack of basic understanding has contributed to serious challenges and shortcomings ranging from the fragility and susceptibility to corrupted data to their uninterpretable behaviors.  These problems can be traced to fundamental gaps in the mathematical understanding of DL. This project tackles this challenge by bringing approximation, statistical, and algorithmic theories together to develop new mathematical foundations for DL. The goals of the project are to mathematically characterize the strengths and limitations of DL models, and to understand the properties of DL models trained using examples of desired behavior (training data) as well as the  tradeoffs between the performance of DL systems and the training dataset size. While DL is already in widespread use, the continued success of DL requires far more complete mathematical understandings and principled approaches to guide its use and reliable application. The project will provide practitioners with clearer guidance on the strengths, limitations, and best approaches to using DL. Broader impacts of the project also include education and mentoring, including the training of graduate students in mathematical fields such as approximation theory, signal processing, statistics, and machine learning and, most importantly, how these fields collectively inform the theory and practice of DL.\r\n\r\nDL seeks to learn an unknown function from data using compositions (layers) of linear combinations of simple functions (neurons). The shortcomings of DL can be traced to fundamental gaps in its mathematical theory including the following issues. The function spaces that capture the salient properties of DL applications are poorly understood. The characteristics of functions learned through neural network training are mysterious. The ability of DL models to discriminate between data distributions has not yet been quantified satisfactorily. Understanding of the tradeoffs between accuracy and training set size is lacking. This project tackles these challenges by bringing approximation, statistical, and algorithmic theories together to develop new theoretical foundations for DL. This project builds innovative bridges between approximation theory, nonparametric statistics, learning theory and algorithms to develop new mathematical foundations for DL. This includes the development of new model classes of functions that are naturally suited to characterize the properties, strengths, and limitations of deep neural network architectures and applications; novel approaches to understand the roles of regularization and sparsity in DL; fundamental frameworks to quantify the discrimination power of DL and generalized adversarial networks; and innovative theory to make DL algorithms more data efficient through the use of side-information, partial differential equations, and richer forms of data than the conventional function evaluations.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Guergana",
   "pi_last_name": "Petrova",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Guergana Petrova",
   "pi_email_addr": "gpetrova@math.tamu.edu",
   "nsf_id": "000256375",
   "pi_start_date": "2021-08-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ronald",
   "pi_last_name": "DeVore",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Ronald A DeVore",
   "pi_email_addr": "rdevore@math.tamu.edu",
   "nsf_id": "000329812",
   "pi_start_date": "2021-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M University",
  "inst_street_address": "400 HARVEY MITCHELL PKY S STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778454375",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A & M UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JF6XLNB4CDJ5"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M University",
  "perf_str_addr": "3368 TAMU",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433368",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "125300",
   "pgm_ele_name": "OFFICE OF MULTIDISCIPLINARY AC"
  },
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  },
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 225000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-c6671602-7fff-63e2-39fa-72bc8c513d19\" style=\"line-height: 1.38; margin-top: 12pt; margin-bottom: 12pt;\" dir=\"ltr\"><span style=\"font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Deep Learning (DL) methods are widely used across engineering, science, and many other fields. However, for DL to continue its practical success, a deeper mathematical understanding of DL concepts and algorithms is required.  In particular, approaches based on rigorous mathematics are essential to ensure its reliable application. Therefore, the questions of when DL should be employed and whether there is a guaranteed performance need to be answered through thorough mathematical analysis.</span></p>\r\n<p style=\"line-height: 1.38; margin-top: 12pt; margin-bottom: 12pt;\" dir=\"ltr\"><span style=\"font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This research project&nbsp; enhanced the understanding and efficacy of DL through:</span></p>\r\n<ul style=\"margin-top: 0; margin-bottom: 0; padding-inline-start: 48px;\">\r\n<li style=\"list-style-type: disc; font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;\" dir=\"ltr\">\r\n<p style=\"line-height: 1.38; margin-top: 12pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">New mathematical characterizations of the types of functions deep learning methods produce, providing a clearer picture of their strengths and limitations.</span></p>\r\n</li>\r\n<li style=\"list-style-type: disc; font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;\" dir=\"ltr\">\r\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Enhanced algorithms for designing more effective deep learning systems. </span></p>\r\n</li>\r\n<li style=\"list-style-type: disc; font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;\" dir=\"ltr\">\r\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Innovative applications of deep learning for data analysis and scientific hypothesis testing.</span></p>\r\n</li>\r\n<li style=\"list-style-type: disc; font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;\" dir=\"ltr\">\r\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 12pt;\" dir=\"ltr\"><span style=\"font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Improved numerical methods for solving complex equations using deep learning techniques.</span></p>\r\n</li>\r\n<li style=\"list-style-type: disc; font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;\" dir=\"ltr\">\r\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 12pt;\" dir=\"ltr\"><span style=\"font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Mathematical theorems that rigorously quantifieed the optimal learning possible from data obseration.<br /></span></p>\r\n</li>\r\n</ul>\r\n<p style=\"line-height: 1.38; margin-top: 12pt; margin-bottom: 12pt;\" dir=\"ltr\"><span style=\"font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">These contributions equip practitioners with more powerful DL tools and offer clearer guidance on how to best utilize them, including their strengths and limitations.</span></p>\r\n<p style=\"line-height: 1.38; margin-top: 12pt; margin-bottom: 12pt;\" dir=\"ltr\"><span style=\"font-size: 10.5pt; font-family: Arial,sans-serif; color: #9900ff; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The project also has broader impacts in education and mentoring. It has led to the development of new course materials and the training of graduate students in fields like approximation theory, signal processing, statistics, and machine learning, highlighting how these disciplines collectively inform both the theory and practice of deep learning.</span></p><br>\n<p>\n Last Modified: 01/05/2025<br>\nModified by: Guergana&nbsp;Petrova</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nDeep Learning (DL) methods are widely used across engineering, science, and many other fields. However, for DL to continue its practical success, a deeper mathematical understanding of DL concepts and algorithms is required.  In particular, approaches based on rigorous mathematics are essential to ensure its reliable application. Therefore, the questions of when DL should be employed and whether there is a guaranteed performance need to be answered through thorough mathematical analysis.\r\n\n\nThis research project enhanced the understanding and efficacy of DL through:\r\n\r\n\r\n\n\nNew mathematical characterizations of the types of functions deep learning methods produce, providing a clearer picture of their strengths and limitations.\r\n\r\n\r\n\n\nEnhanced algorithms for designing more effective deep learning systems. \r\n\r\n\r\n\n\nInnovative applications of deep learning for data analysis and scientific hypothesis testing.\r\n\r\n\r\n\n\nImproved numerical methods for solving complex equations using deep learning techniques.\r\n\r\n\r\n\n\nMathematical theorems that rigorously quantifieed the optimal learning possible from data obseration.\n\r\n\r\n\r\n\n\nThese contributions equip practitioners with more powerful DL tools and offer clearer guidance on how to best utilize them, including their strengths and limitations.\r\n\n\nThe project also has broader impacts in education and mentoring. It has led to the development of new course materials and the training of graduate students in fields like approximation theory, signal processing, statistics, and machine learning, highlighting how these disciplines collectively inform both the theory and practice of deep learning.\t\t\t\t\tLast Modified: 01/05/2025\n\n\t\t\t\t\tSubmitted by: GuerganaPetrova\n"
 }
}