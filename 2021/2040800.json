{
 "awd_id": "2040800",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FAI: Fairness in Machine Learning with Human in the Loop",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2021-02-01",
 "awd_exp_date": "2026-01-31",
 "tot_intn_awd_amt": 625000.0,
 "awd_amount": 625000.0,
 "awd_min_amd_letter_date": "2021-01-25",
 "awd_max_amd_letter_date": "2024-04-24",
 "awd_abstract_narration": "Despite early successes and significant potential, algorithmic decision-making systems often inherit and encode biases that exist in the training data and/or the training process.  It is thus important to understand the consequences of deploying and using machine learning models and provide algorithmic treatments to ensure that such techniques will ultimately serve the social good. While recent works have looked into the fairness issues in AI concerning the \u201cshort-term\u201d measures, the long-term consequences and impacts of automated decision making remain unclear. The understanding of the long-term impact of a fair decision provides guidelines to policy-makers when deploying an algorithmic model in a dynamic environment and is critical to its trustworthiness and adoption. It will also drive the design of algorithms with an eye toward the welfare of both the makers and the users of these algorithms, with an ultimate goal of achieving more equitable outcomes. \r\n \r\nThis project aims to understand the long-term impact of fair decisions made by automated machine learning algorithms via establishing an analytical, algorithmic, and experimental framework that captures the sequential learning and decision process, the actions and dynamics of the underlying user population, and its welfare. This knowledge will help design the right fairness criteria and intervention mechanisms throughout the life cycle of the decision-action loop to ensure long-term equitable outcomes. Central to this project\u2019s intellectual inquiry is the focus on human in the loop, i.e., an AI-human feedback loop with automated decision-making that involves human participation. Our focus on the long-term impacts of fair algorithmic decision-making while explicitly modeling and incorporating human agents in the loop provides a theoretically rigorous framework to understand how an algorithmic decision-maker fares in the foreseeable future.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yang",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yang Liu",
   "pi_email_addr": "yangliu@ucsc.edu",
   "nsf_id": "000787350",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mingyan",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mingyan Liu",
   "pi_email_addr": "mingyan@eecs.umich.edu",
   "nsf_id": "000230014",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ming",
   "pi_last_name": "Yin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ming Yin",
   "pi_email_addr": "mingyin@purdue.edu",
   "nsf_id": "000784929",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Parinaz",
   "pi_last_name": "Naghizadeh Ardabili",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Parinaz Naghizadeh Ardabili",
   "pi_email_addr": "pnaghizadeh@ucsd.edu",
   "nsf_id": "000818835",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Cruz",
  "inst_street_address": "1156 HIGH ST",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA CRUZ",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8314595278",
  "inst_zip_code": "950641077",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "CA19",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA SANTA CRUZ",
  "org_prnt_uei_num": "",
  "org_uei_num": "VXUFPE4MCZH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Cruz",
  "perf_str_addr": "SOE 3, UC Santa Cruz, 1156 High",
  "perf_city_name": "Santa Cruz",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "950641100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "CA19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "114Y00",
   "pgm_ele_name": "Fairness in Artificial Intelli"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 625000.0
  }
 ],
 "por": null
}