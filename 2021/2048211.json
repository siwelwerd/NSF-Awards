{
 "awd_id": "2048211",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Teaching Machines through Human Explanation for Information Extraction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922232",
 "po_email": "sdraghic@nsf.gov",
 "po_sign_block_name": "Sorin Draghici",
 "awd_eff_date": "2021-05-15",
 "awd_exp_date": "2026-04-30",
 "tot_intn_awd_amt": 513058.0,
 "awd_amount": 513058.0,
 "awd_min_amd_letter_date": "2021-04-29",
 "awd_max_amd_letter_date": "2022-07-26",
 "awd_abstract_narration": "The majority of data being generated by society is free-form textual data. As the volume of text data continues to grow, humans alone cannot hope to be able to understand every piece of textual information published. Hence, a need for machine-based methods to extract salient entities along with their relationships from massive textual data is needed. While efforts to develop such methods have proven successful in academia, that success rarely translates over to practitioners employing extraction systems to solve real-world problems. A significant cause of this failure in translation is the requirement of copious amounts of training examples for a machine to learn extraction models. Even when a sufficient number of examples exist, machines learn very rigid methods, such that even a slight misspelling can cause a failure. Therefore, a re-think of how we develop, refine and maintain such machine-based extraction methods is required. This project proposes a new methodology based around the idea of providing explanations for both correct and incorrect decisions made by a machine, with the intention of requiring far fewer examples for machine training, as well as providing a process of softening the rigidity of current extraction methods. \r\n\r\nTo achieve this goal, this project will solicit (from humans) natural language explanations on how a machine should reason about their task, as well as explanations correcting erroneous reasoning and an alerting system for when a machine\u2019s rationale is possibly going wrong. Rather than treating humans as merely a \u201csource of labels\u201d, this project aims at developing a new learning framework that directly models a human\u2019s natural language explanations to either provide a machine with labeling rationale or correct an observed erroneous rationale. The project will develop explanation-based learning methods that can capture the compositional nature of human natural language explanations, and study explanation-guided model refinement methods to update model parameters based on the provided human explanations regarding undesirable behaviors. To adapt to changing data distribution, this project will formulate a human-in-the-loop continual model refinement framework where problematic model behavioral patterns are automatically identified, and human feedback is solicited to correct the model. With these advancements, the project looks to fundamentally change the way models are trained, refined and updated, and look to do it by exploiting the expert knowledge contained within human explanations.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiang",
   "pi_last_name": "Ren",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiang Ren",
   "pi_email_addr": "xiangren@usc.edu",
   "nsf_id": "000759793",
   "pi_start_date": "2021-04-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3720 S. Flower St.",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900890001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 414595.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 98463.0
  }
 ],
 "por": null
}