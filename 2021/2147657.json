{
 "awd_id": "2147657",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: SaTC: Data Privacy for Strategic Agents",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "James Joshi",
 "awd_eff_date": "2021-07-15",
 "awd_exp_date": "2022-04-30",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 40667.0,
 "awd_min_amd_letter_date": "2021-09-19",
 "awd_max_amd_letter_date": "2021-09-19",
 "awd_abstract_narration": "This project lays the groundwork for understanding how existing tools for privacy-preserving data analysis interact with strategic and human aspects of practical privacy guarantees. When strategic individuals have privacy concerns about the use of their data, they may modify their behavior to ensure less, or perhaps more favorable, information is revealed.  The project's novelties are an interdisciplinary approach, which combines tools from algorithm design, machine learning, and economics. The broader significance and importance of this work is to provide a critical step for society's ability to collect useful data and to interpret data via existing algorithms. As more personal data are collected, stored, and used in algorithmic decision making, these results are useful in the legal and policy landscape of personal data management. \r\n\r\nThis work has two main technical thrusts.  First, this project studies how privacy technologies can be designed and deployed to manage privacy concerns of strategic individuals. This yields insight into the design of optimal privacy technologies for strategic individuals in practical application areas. Second, this project develops data analysis techniques for settings where data are generated by privacy-aware individuals. This yields tools for the design and analysis of algorithms to efficiently learn and optimize from a strategic individual's data.  This project also includes a significant educational and outreach component, including curriculum development, mentorship of students, and workshop organization.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rachel",
   "pi_last_name": "Cummings",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rachel Cummings",
   "pi_email_addr": "rac2239@columbia.edu",
   "nsf_id": "000750751",
   "pi_start_date": "2021-09-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "2960 Broadway",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100270420",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "026Y00",
   "pgm_ele_name": "CRII CISE Research Initiation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 40667.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">Privacy-preserving tools for data analysis are often used for optimization and learning in settings where individuals provide data for analysis. These individuals may have privacy concerns about the use of their data, and they may also have the ability to manipulate their reported data. This award has developed tools for providing privacy while enabling accurate learning in these settings.</p>\n<p class=\"p1\">One collection of results resulting from this project addressed the problem of managing incentives for users providing data for analysis purposes. This included publications on economic environments such as price discrimination, prediction markets, behavioral response to privacy, and institutional incentives for sharing data. In each environment, the users providing data have incentives to manipulate their data in order to secure more desirable economic outcomes. We provided privacy technologies that can be used to manage these incentives and ensure both accurate learning for the analyst and privacy protections for the users.</p>\n<p class=\"p1\">Another collection of results from this project focused on the interaction between privacy and accuracy when learning from user-generated data. This included publications on accurate private learning for statistical, learning, and optimization tasks such as changepoint detection, submodular optimization, synthetic data generation, and multiple hypothesis testing. For each data analysis task, we created and analyzed algorithms with provable privacy and accuracy guarantees.</p>\n<p class=\"p1\">Additionally this award supported: the PI's development of a new graduate course on the foundations of data privacy; the PI's organization of a workshop on data science for social good, in order to increase diversity in the graduate admissions pipeline; the PI's training and mentorship of multiple graduate and undergraduate researchers; and broad dissemination of the results to the privacy, algorithms, economics, machine learning, and statistics communities.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/23/2022<br>\n\t\t\t\t\tModified by: Rachel&nbsp;Cummings</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Privacy-preserving tools for data analysis are often used for optimization and learning in settings where individuals provide data for analysis. These individuals may have privacy concerns about the use of their data, and they may also have the ability to manipulate their reported data. This award has developed tools for providing privacy while enabling accurate learning in these settings.\nOne collection of results resulting from this project addressed the problem of managing incentives for users providing data for analysis purposes. This included publications on economic environments such as price discrimination, prediction markets, behavioral response to privacy, and institutional incentives for sharing data. In each environment, the users providing data have incentives to manipulate their data in order to secure more desirable economic outcomes. We provided privacy technologies that can be used to manage these incentives and ensure both accurate learning for the analyst and privacy protections for the users.\nAnother collection of results from this project focused on the interaction between privacy and accuracy when learning from user-generated data. This included publications on accurate private learning for statistical, learning, and optimization tasks such as changepoint detection, submodular optimization, synthetic data generation, and multiple hypothesis testing. For each data analysis task, we created and analyzed algorithms with provable privacy and accuracy guarantees.\nAdditionally this award supported: the PI's development of a new graduate course on the foundations of data privacy; the PI's organization of a workshop on data science for social good, in order to increase diversity in the graduate admissions pipeline; the PI's training and mentorship of multiple graduate and undergraduate researchers; and broad dissemination of the results to the privacy, algorithms, economics, machine learning, and statistics communities.\n\n \n\n\t\t\t\t\tLast Modified: 07/23/2022\n\n\t\t\t\t\tSubmitted by: Rachel Cummings"
 }
}