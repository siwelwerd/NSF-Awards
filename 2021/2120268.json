{
 "awd_id": "2120268",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CCRI: Planning: InfraStructure for Photorealistic Image and Environment Synthesis (I-SPIES)",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 9160.0,
 "awd_amount": 9160.0,
 "awd_min_amd_letter_date": "2021-08-10",
 "awd_max_amd_letter_date": "2021-08-10",
 "awd_abstract_narration": "Numerous Computer and Information Science and Engineering (CISE) research communities leverage datasets comprised of visual images or 3D virtual environments to conduct research in computer vision, robotics, multimedia systems, virtual reality, and mixed reality. Many of these datasets consist of either images previously captured with cameras and other optical sensors, or synthetic images previously rendered from 3D virtual environments. The static nature of these datasets limits their usefulness and potential applications. Recently, some researchers have provided datasets and tools for synthesizing new images from 3D virtual environments using customizable virtual camera positions, which broadens their research applications. However, many of these datasets consist of lower-fidelity indoor virtual environments that yield non-photorealistic images. Furthermore, such datasets are missing outdoor virtual environments, and tools for sharing custom camera positions within the research community are not currently available.\r\n\r\nThis planning project prepares to address the limitations of prior datasets by investigating the feasibility of using high-quality terrestrial laser scanners to capture and create high-fidelity, photorealistic virtual environments of real-world locations, both indoor and outdoor. This will be coupled with surveys of the relevant CISE research communities through workshops held at top academic conferences. This project will result in the development of two preliminary datasets, one indoor and one outdoor, using the proposed laser-scanner methodology, and the identification of community needs, priorities, and support for the proposed InfraStructure for Photorealistic Images and Environment Synthesis (I-SPIES). Undergraduate students will be engaged in the development of the preliminary datasets through the University of Central Florida\u2019s EXCEL STEM program, a former NSF STEP program\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ravi",
   "pi_last_name": "Prakash",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ravi Prakash",
   "pi_email_addr": "ravip@utdallas.edu",
   "nsf_id": "000275377",
   "pi_start_date": "2021-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Dallas",
  "inst_street_address": "800 WEST CAMPBELL RD.",
  "inst_street_address_2": "SP2.25",
  "inst_city_name": "RICHARDSON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9728832313",
  "inst_zip_code": "750803021",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "TX24",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT DALLAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "EJCVPNN1WFS5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Dallas",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "750803021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "TX24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 9160.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>As part of this planning grant awarded to UT Dallas, we organized the First Workshop on Photorealistic Image and Environment Synthesis for MultimediaExperiments (PIES-ME)&nbsp; in October 2022 in conjunction with the 30<sup>th</sup> ACM International Conference on Multimedia (ACM MM) in Lisbon, Portugal. The organizing committee consisted of PI Ryan McMahan, co-PI Ravi Prakash, and Marcelo Carvalho and Mylene Farias, both of the University of Brasilia in Brasis. It was a day long, in-person workshop with five refereed research papers, a keynote speech, PIES-ME project data reveal, and a panel discussion: all on issues relevant to the NSF-funded planning grant.</p>\n<p>&nbsp;</p>\n<p>The following research papers were presented at the workshop:</p>\n<ol>\n<li><strong>Delving into Light-Dark Semantic Segmentation for Indoor Scenes Understanding. </strong>Xiaowen Ying (Lehigh University), Bo Lang (Lehigh University), Zhihao Zheng (Lehigh University), Mooi Choo Chuah (Lehigh University)<strong>&nbsp;</strong></li>\n<li><strong>Language-guided Semantic Style Transfer of 3D Indoor Scenes. </strong>Bu Jin (University of Chinese Academy of Sciences), Beiwen Tian (Tsinghua University), Hao Zhao (Peking University), Guyue Zhou (Tsinghua University)<strong>&nbsp;</strong></li>\n<li><strong>Towards a Calibrated 360 Stereoscopic HDR Image Dataset for Architectural Lighting Studies. </strong>Mich&egrave;le Ati&eacute; (Nantes Universit&eacute;), Toinon Vigier (Nantes Universit&eacute;), Fran&ccedil;ois Eymond (Universit&eacute; de Lyon), C&eacute;line Drozd (Nantes Universit&eacute;), Rapha&euml;l Labayrade (Universit&eacute; de Lyon), Daniel Siret (Nantes Universit&eacute;), Yannick Sutter (Nantes Universit&eacute;)</li>\n<li><strong>Subjective Study of the Impact of Compression, Framerate, and Navigation Trajectories on the Quality of Free-Viewpoint Video. </strong>Jes&uacute;s Guti&eacute;rrez (Universidad Polit&eacute;cnica de Madrid), Adriana Gal&aacute;n (Universidad Polit&eacute;cnica de Madrid), Pablo P&eacute;rez (Nokia), Daniel Corregidor (Universidad Polit&eacute;cnica de Madrid), Teresa Hernando (Universidad Polit&eacute;cnica de Madrid), Javier Us&oacute;n (Universidad Polit&eacute;cnica de Madrid), Daniel Berj&oacute;n (Universidad Polit&eacute;cnica de Madrid), Juli&aacute;n Cabrera (Universidad Polit&eacute;cnica de Madrid), Narciso Garc&iacute;a (Universidad Polit&eacute;cnica de Madrid)<strong>&nbsp;</strong></li>\n<li><strong>Comparative Evaluation of Temporal Pooling Methods for No-Reference Quality Assessment of Dynamic Point Clouds. </strong>Pedro G. Freitas (University of Bras&iacute;lia), Giovani D. Lucafo (University of S&atilde;o Paulo), Mateus Gon&ccedil;alves (University of Bras&iacute;lia), Johann Homonnai (University of Bras&iacute;lia), Rafael Diniz (University of Bras&iacute;lia), Myl&egrave;ne C.Q. Farias (University of Bras&iacute;lia)<strong></strong></li>\n</ol>\n<p>&nbsp;</p>\n<p>The keynote speech, titled &ldquo;<strong>Hyper-Realistic and Immersive Imaging for Enhanced Quality of Experience &ldquo;</strong>was delivered by Frederic Dufaux &nbsp;of Universit&eacute; Paris-Saclay, CNRS, CentraleSup&eacute;lec.<strong></strong></p>\n<p>Project PI, Ryan McMahan joined the workshop remotely&nbsp; and presented the point-cloud dataset created as part of the NSF-funded project. This generated questions from the audience and productive discussion on the types of datasets of interest to researchers working in the field of multimedia content creation and streaming. About fifteen attendees were present during the data reveal. A survey was distributed among the attendees. Only two completed survey responses were received from them.</p>\n<p>&nbsp;</p>\n<p>With the data reveal fresh in the minds of participants, the next session was devoted to a panel discussion titled <strong>\"Photorealistic datasets to enable multimedia research: creation, curation and use.\" </strong>Project co-PI, Ravi Prakash was the panel moderator, while the panelists were Frederic Dufaux (Universit&eacute; Paris-Saclay, CNRS, CentraleSup&eacute;lec, France), Jes&uacute;s Guti&eacute;rrez (Universidad Polit&eacute;cnica de Madrid, Spain), and Fernando Pereira (Instituto Superior Tecnico, Portugal).</p><br>\n<p>\n Last Modified: 02/01/2024<br>\nModified by: Ravi&nbsp;Prakash</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nAs part of this planning grant awarded to UT Dallas, we organized the First Workshop on Photorealistic Image and Environment Synthesis for MultimediaExperiments (PIES-ME) in October 2022 in conjunction with the 30th ACM International Conference on Multimedia (ACM MM) in Lisbon, Portugal. The organizing committee consisted of PI Ryan McMahan, co-PI Ravi Prakash, and Marcelo Carvalho and Mylene Farias, both of the University of Brasilia in Brasis. It was a day long, in-person workshop with five refereed research papers, a keynote speech, PIES-ME project data reveal, and a panel discussion: all on issues relevant to the NSF-funded planning grant.\n\n\n\n\n\nThe following research papers were presented at the workshop:\n\nDelving into Light-Dark Semantic Segmentation for Indoor Scenes Understanding. Xiaowen Ying (Lehigh University), Bo Lang (Lehigh University), Zhihao Zheng (Lehigh University), Mooi Choo Chuah (Lehigh University)\nLanguage-guided Semantic Style Transfer of 3D Indoor Scenes. Bu Jin (University of Chinese Academy of Sciences), Beiwen Tian (Tsinghua University), Hao Zhao (Peking University), Guyue Zhou (Tsinghua University)\nTowards a Calibrated 360 Stereoscopic HDR Image Dataset for Architectural Lighting Studies. Michle Ati (Nantes Universit), Toinon Vigier (Nantes Universit), Franois Eymond (Universit de Lyon), Cline Drozd (Nantes Universit), Raphal Labayrade (Universit de Lyon), Daniel Siret (Nantes Universit), Yannick Sutter (Nantes Universit)\nSubjective Study of the Impact of Compression, Framerate, and Navigation Trajectories on the Quality of Free-Viewpoint Video. Jess Gutirrez (Universidad Politcnica de Madrid), Adriana Galn (Universidad Politcnica de Madrid), Pablo Prez (Nokia), Daniel Corregidor (Universidad Politcnica de Madrid), Teresa Hernando (Universidad Politcnica de Madrid), Javier Usn (Universidad Politcnica de Madrid), Daniel Berjn (Universidad Politcnica de Madrid), Julin Cabrera (Universidad Politcnica de Madrid), Narciso Garca (Universidad Politcnica de Madrid)\nComparative Evaluation of Temporal Pooling Methods for No-Reference Quality Assessment of Dynamic Point Clouds. Pedro G. Freitas (University of Braslia), Giovani D. Lucafo (University of So Paulo), Mateus Gonalves (University of Braslia), Johann Homonnai (University of Braslia), Rafael Diniz (University of Braslia), Mylne C.Q. Farias (University of Braslia)\n\n\n\n\n\n\nThe keynote speech, titled Hyper-Realistic and Immersive Imaging for Enhanced Quality of Experience was delivered by Frederic Dufaux of Universit Paris-Saclay, CNRS, CentraleSuplec.\n\n\nProject PI, Ryan McMahan joined the workshop remotely and presented the point-cloud dataset created as part of the NSF-funded project. This generated questions from the audience and productive discussion on the types of datasets of interest to researchers working in the field of multimedia content creation and streaming. About fifteen attendees were present during the data reveal. A survey was distributed among the attendees. Only two completed survey responses were received from them.\n\n\n\n\n\nWith the data reveal fresh in the minds of participants, the next session was devoted to a panel discussion titled \"Photorealistic datasets to enable multimedia research: creation, curation and use.\" Project co-PI, Ravi Prakash was the panel moderator, while the panelists were Frederic Dufaux (Universit Paris-Saclay, CNRS, CentraleSuplec, France), Jess Gutirrez (Universidad Politcnica de Madrid, Spain), and Fernando Pereira (Instituto Superior Tecnico, Portugal).\t\t\t\t\tLast Modified: 02/01/2024\n\n\t\t\t\t\tSubmitted by: RaviPrakash\n"
 }
}