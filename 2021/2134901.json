{
 "awd_id": "2134901",
 "agcy_id": "NSF",
 "tran_type": "CoopAgrmnt",
 "awd_istr_txt": "Cooperative Agreement",
 "awd_titl_txt": "Track-D: Data-Driven Disease Prevention and Control in Animal Health",
 "cfda_num": "47.084",
 "org_code": "15020000",
 "po_phone": "7032928326",
 "po_email": "mreksula@nsf.gov",
 "po_sign_block_name": "Michael Reksulak",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 4990591.0,
 "awd_amount": 4990591.0,
 "awd_min_amd_letter_date": "2021-09-15",
 "awd_max_amd_letter_date": "2022-09-06",
 "awd_abstract_narration": "This project seeks to address the maintenance of good livestock health, high productivity, and efficiency are key to the sustainability and success of the livestock industry. \r\n\r\nTo do this the project aims to converge data, knowledge and individuals across the animal production and health spaces to develop a multilevel data collection and processing pipeline and advanced AI analytical, visualization, and decision support tools to facilitate and improve the \u201cpersonalized\u201d or \u201cprecision\u201d management of animal health and system optimization, namely precision epidemiology.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "ITE",
 "org_div_long_name": "Innovation and Technology Ecosystems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Beatriz",
   "pi_last_name": "Martinez Lopez",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Beatriz Martinez Lopez",
   "pi_email_addr": "beamartinezlopez@ucdavis.edu",
   "nsf_id": "000681677",
   "pi_start_date": "2021-09-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Spirtes",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Peter L Spirtes",
   "pi_email_addr": "ps7z@andrew.cmu.edu",
   "nsf_id": "000220824",
   "pi_start_date": "2021-11-22",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Xin",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xin Liu",
   "pi_email_addr": "liu@cs.ucdavis.edu",
   "nsf_id": "000289050",
   "pi_start_date": "2021-09-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Kun",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kun Zhang",
   "pi_email_addr": "kunz1@andrew.cmu.edu",
   "nsf_id": "000709961",
   "pi_start_date": "2021-09-15",
   "pi_end_date": "2021-11-22"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Maria",
   "pi_last_name": "Clavijo",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Maria J Clavijo",
   "pi_email_addr": "Mclavijo@iastate.edu",
   "nsf_id": "000827608",
   "pi_start_date": "2021-09-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Davis",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956186134",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131Y00",
   "pgm_ele_name": "Convergence Accelerator Resrch"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 2993881.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 1996710.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>o&nbsp;&nbsp; <strong>Major Activities:</strong></p>\r\n<p>The CMU Causality Group focuses on developing AI tools capable of automatically learning causal relationships from observational data and exploiting them to inform novel interventions, guide policy-making, and improve prediction in nonstationary environments.</p>\r\n<p>&nbsp;Specifically, the group focused on basic research of developing principled approaches to reveal the underlying causal process, including hidden causal variables and the involved causal relations from various types of observational data. In addition, We formulated and leveraged causal principles to enhance generative AI approaches, enabling capabilities such as extrapolation and reliable counterfactual generation. Most of the developments led to publications and publicly available source code. We also tailored transformer-based architecture to predict the chance for particular swines to develop prolapses from induvial-level time series.</p>\r\n<p>&nbsp;o&nbsp;&nbsp; <strong>Specific Objectives:</strong></p>\r\n<p>Our objectives include</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Develop reliable, data-driven tools to understand causality from observational data;</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Using causal perspective to improve prediction, interpretability, and generative AI;</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Using causal tools to improve the understanding of the prolapse issue and suggest novel interventions.</p>\r\n<p>&nbsp;o&nbsp;&nbsp; <strong>Significant results:</strong></p>\r\n<p>The CMU team achieved significant advancements in causal discovery and causal representation learning and successfully dealt with various real-world problems with novel perspectives and results. In particular, in addition to investigating fundamental assumptions of causal discovery, such as whether causal discovery from temporally aggregated data can reveal true causality (Fan et al., 2024), and identifying and addressing potential issues with continuous optimization-based causal discovery (Ng et al., 2024b), the team proposed novel frameworks or algorithms for</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Learning hidden causal variables and the involved causal relations from independent and identically distributed (i.i.d.) data, focusing on linear models with applications to psychometric analysis (Dong et al., 2024a; Dong et al., 2024b; Jin et al., 2024; Ng et al., 2024a; Dai et al., 2024; Li et al., 2024c; Chen et al., 2024), concept learning from images (Kong et al., 2024a; 2024b; 2023; Chen et al., 2024), video understanding (Chen et al., 2024a; 2024b), interpretable state representation learning for world model construction in deep reinforcement learning (Liu et al, 2023), and how to exploit sparsity to establish identifiability results in nonparametric cases (Zheng et al., 2023; Ng. et al., 2023);</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Learning the underlying hidden causal variables and changing causal relations from heterogeneous data (Zhang et al., 2024; Song et al., 2024; Song et al., 2023);</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Learning latent variable dynamic models for personalized reinforcement learning (Sun et al., 2024a; Zeng et al., 2024);</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Causal discovery in the presence of deterministic causal relations, in light of the &ldquo;monotonicity&rdquo; principle that having access to more variable will not hurt causal discovery results (Li et al., 2024a);</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Identifying dependence patterns generated by selection bias in temporal data (Zheng et al., 2024; Qiu et al., 2024);</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Learning subtasks from demonstration trajectories for causal understanding and generating novel solutions by framing subtasks as selection problems (Qiu et al., 2024).</p>\r\n<p>Moreover, we have made use of causal principles for the purposes of</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Leveraging large language models and causal discovery for automated knowledge discovery (Liu et al., 2024);</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Achieving extrapolation ability in image generation and other generative AI tasks (Kong et al., 2024b) or counterfactual generation (Hao et al., 2024; Yan et al., 2023; Sun et al., 2024b);</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Advancing the understanding and implementation of fairness in machine learning (Tang et al., 2024; Li et al., 2024b);</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Adaptive prediction in nonstationary environments (Li et al., 2023).</p>\r\n<p>&nbsp;o&nbsp;&nbsp; <strong>Key outcomes or Other achievements:</strong></p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Publications at top machine learning or artificial intelligence venues;</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Contributing learning principles and methods to tackle real problems in psychology and computer vision;</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Open-source software for causal discovery and causal representation learning;</p>\r\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Open-source software for counterfactual generation and editing of images.</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/05/2024<br>\nModified by: Peter&nbsp;L&nbsp;Spirtes</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\no Major Activities:\r\n\n\nThe CMU Causality Group focuses on developing AI tools capable of automatically learning causal relationships from observational data and exploiting them to inform novel interventions, guide policy-making, and improve prediction in nonstationary environments.\r\n\n\nSpecifically, the group focused on basic research of developing principled approaches to reveal the underlying causal process, including hidden causal variables and the involved causal relations from various types of observational data. In addition, We formulated and leveraged causal principles to enhance generative AI approaches, enabling capabilities such as extrapolation and reliable counterfactual generation. Most of the developments led to publications and publicly available source code. We also tailored transformer-based architecture to predict the chance for particular swines to develop prolapses from induvial-level time series.\r\n\n\no Specific Objectives:\r\n\n\nOur objectives include\r\n\n\n- Develop reliable, data-driven tools to understand causality from observational data;\r\n\n\n- Using causal perspective to improve prediction, interpretability, and generative AI;\r\n\n\n- Using causal tools to improve the understanding of the prolapse issue and suggest novel interventions.\r\n\n\no Significant results:\r\n\n\nThe CMU team achieved significant advancements in causal discovery and causal representation learning and successfully dealt with various real-world problems with novel perspectives and results. In particular, in addition to investigating fundamental assumptions of causal discovery, such as whether causal discovery from temporally aggregated data can reveal true causality (Fan et al., 2024), and identifying and addressing potential issues with continuous optimization-based causal discovery (Ng et al., 2024b), the team proposed novel frameworks or algorithms for\r\n\n\n- Learning hidden causal variables and the involved causal relations from independent and identically distributed (i.i.d.) data, focusing on linear models with applications to psychometric analysis (Dong et al., 2024a; Dong et al., 2024b; Jin et al., 2024; Ng et al., 2024a; Dai et al., 2024; Li et al., 2024c; Chen et al., 2024), concept learning from images (Kong et al., 2024a; 2024b; 2023; Chen et al., 2024), video understanding (Chen et al., 2024a; 2024b), interpretable state representation learning for world model construction in deep reinforcement learning (Liu et al, 2023), and how to exploit sparsity to establish identifiability results in nonparametric cases (Zheng et al., 2023; Ng. et al., 2023);\r\n\n\n- Learning the underlying hidden causal variables and changing causal relations from heterogeneous data (Zhang et al., 2024; Song et al., 2024; Song et al., 2023);\r\n\n\n- Learning latent variable dynamic models for personalized reinforcement learning (Sun et al., 2024a; Zeng et al., 2024);\r\n\n\n- Causal discovery in the presence of deterministic causal relations, in light of the monotonicity principle that having access to more variable will not hurt causal discovery results (Li et al., 2024a);\r\n\n\n- Identifying dependence patterns generated by selection bias in temporal data (Zheng et al., 2024; Qiu et al., 2024);\r\n\n\n- Learning subtasks from demonstration trajectories for causal understanding and generating novel solutions by framing subtasks as selection problems (Qiu et al., 2024).\r\n\n\nMoreover, we have made use of causal principles for the purposes of\r\n\n\n- Leveraging large language models and causal discovery for automated knowledge discovery (Liu et al., 2024);\r\n\n\n- Achieving extrapolation ability in image generation and other generative AI tasks (Kong et al., 2024b) or counterfactual generation (Hao et al., 2024; Yan et al., 2023; Sun et al., 2024b);\r\n\n\n- Advancing the understanding and implementation of fairness in machine learning (Tang et al., 2024; Li et al., 2024b);\r\n\n\n- Adaptive prediction in nonstationary environments (Li et al., 2023).\r\n\n\no Key outcomes or Other achievements:\r\n\n\n- Publications at top machine learning or artificial intelligence venues;\r\n\n\n- Contributing learning principles and methods to tackle real problems in psychology and computer vision;\r\n\n\n- Open-source software for causal discovery and causal representation learning;\r\n\n\n- Open-source software for counterfactual generation and editing of images.\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 12/05/2024\n\n\t\t\t\t\tSubmitted by: PeterLSpirtes\n"
 }
}