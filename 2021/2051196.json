{
 "awd_id": "2051196",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Evaluating the Impacts of Machine Learning Algorithms on Human Decisions",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927269",
 "po_email": "ceavey@nsf.gov",
 "po_sign_block_name": "Cheryl Eavey",
 "awd_eff_date": "2021-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 330000.0,
 "awd_amount": 330000.0,
 "awd_min_amd_letter_date": "2021-05-24",
 "awd_max_amd_letter_date": "2023-03-29",
 "awd_abstract_narration": "This research project will develop a methodological framework and set of tools for experimentally evaluating the impacts of machine learning algorithms on human decisions. In today's data-driven society, decisions often are based at least in part on algorithmic recommendations. Whenever choosing movies to watch or shopping for clothes to wear, online sites are constantly feeding consumers with such information. The project will develop methodologies to evaluate whether algorithmic recommendations help human decision makers achieve their goals and how they affect the fairness of such decisions. The new methodologies will help researchers empirically evaluate the efficacy of algorithm-assisted human decision making in a wide range of settings. These settings include individual decisions such as online shopping as well as decisions in medicine, finance, and judicial systems that have the potential to affect the lives of many in society. The investigators will apply the new methods to a randomized evaluation of pretrial risk assessment instruments on judicial decisions. An open-source software package will be developed, and the databases used in this research will be made publicly available.\r\n\r\nThis project will develop tools for experimentally evaluating whether algorithmic recommendations help human decision makers achieve their goals and how such recommendations affect the fairness of such decisions. On the methodological front, the project will show how to evaluate the impacts of machine learning algorithms on the accuracy and fairness of human decisions. Although there exists a growing literature on algorithmic fairness, existing research almost exclusively focuses on the evaluation of accuracy and fairness of the algorithms themselves. Machines and humans have their own biases, however, and these biases may interact in unexpected ways to influence ultimate decisions. Also, the existing definitions of fairness do not account for the fact that decisions may influence individuals. The methodological framework to be developed will address these open problems. On the substantive front, the project will analyze data on original, real-world randomized controlled trials (RCTs) in collaboration with several jurisdictions in the United States. The project will analyze these RCTs to evaluate the impacts of pretrial risk assessment instruments (PRAIs) on judicial decisions. There has been a growing concern in the academic and public-policy communities about the potential racial bias of these PRAIs. This research will develop and implement rigorous evaluation methodologies to answer policy-relevant questions so that direct contributions can be made to this important public policy debate.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kosuke",
   "pi_last_name": "Imai",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kosuke Imai",
   "pi_email_addr": "imai@harvard.edu",
   "nsf_id": "000319058",
   "pi_start_date": "2021-05-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Greiner",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "James Greiner",
   "pi_email_addr": "jgreiner@law.harvard.edu",
   "nsf_id": "000646622",
   "pi_start_date": "2021-05-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Zhichao",
   "pi_last_name": "Jiang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zhichao Jiang",
   "pi_email_addr": "zhichaojiang@umass.edu",
   "nsf_id": "000836090",
   "pi_start_date": "2021-05-24",
   "pi_end_date": "2023-03-29"
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University",
  "perf_str_addr": "1737 Cambridge Street",
  "perf_city_name": "CAMBRIDGE",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021383016",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "128Y00",
   "pgm_ele_name": "Law & Science"
  },
  {
   "pgm_ele_code": "133300",
   "pgm_ele_name": "Methodology, Measuremt & Stats"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 330000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-1c4684d2-7fff-3467-768b-74389247a16d\">\n<p dir=\"ltr\"><span>This project has produced several outcomes.&nbsp; First, we have developed a set of statistical methods that can be used to evaluate how AI recommendations affect human decisions.&nbsp; Second, we have developed a new statistical fairness criteria based on the notion of causality.&nbsp; This is important because to evaluate the fairness of any decision made by humans and algorithms we have to consider the impacts of such decisions.&nbsp; Third, we have developed a new statistical method to improve algorithmic recommendations.&nbsp; The proposed methodology achieves this safely in a sense that it has a theoretical guarantee in terms of ensuring that the outcome will not be worse off than the current status quo algorithmic recommendation system.&nbsp; Fourth, we have produced an open-source software package that enables other researchers to apply the methods we have developed.&nbsp; This package can be freely downloaded from a public software repository.&nbsp; Fifth, we have applied the methodology, and related methods spun off from these efforts, in public and informal presentations to government officials and philanthropic stakeholders, and have incorporated them into the corresponding reports.&nbsp; Finally, we demonstrate the usefulness of these methods in the context of our own randomized controlled trials that assess the impacts of risk assessment scores in the criminal justice system.&nbsp; This application is of interest to many researchers and we have made part of the data publicly available so that other researchers can make further methodological and substantive developments. &nbsp; The project had a major impact on the academic community.&nbsp; One of the papers was published as a discussion paper and was read during a meeting at the Royal Statistical Society.&nbsp; Two discussants commented on the paper at the meeting and many scholars around the world contributed commentaries to the journal issue when our paper was published.&nbsp; The open-source software has also been downloaded more than 3000 times even though the software was uploaded to the repository only a few months ago.</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 06/16/2024<br>\nModified by: Kosuke&nbsp;Imai</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\nThis project has produced several outcomes. First, we have developed a set of statistical methods that can be used to evaluate how AI recommendations affect human decisions. Second, we have developed a new statistical fairness criteria based on the notion of causality. This is important because to evaluate the fairness of any decision made by humans and algorithms we have to consider the impacts of such decisions. Third, we have developed a new statistical method to improve algorithmic recommendations. The proposed methodology achieves this safely in a sense that it has a theoretical guarantee in terms of ensuring that the outcome will not be worse off than the current status quo algorithmic recommendation system. Fourth, we have produced an open-source software package that enables other researchers to apply the methods we have developed. This package can be freely downloaded from a public software repository. Fifth, we have applied the methodology, and related methods spun off from these efforts, in public and informal presentations to government officials and philanthropic stakeholders, and have incorporated them into the corresponding reports. Finally, we demonstrate the usefulness of these methods in the context of our own randomized controlled trials that assess the impacts of risk assessment scores in the criminal justice system. This application is of interest to many researchers and we have made part of the data publicly available so that other researchers can make further methodological and substantive developments.  The project had a major impact on the academic community. One of the papers was published as a discussion paper and was read during a meeting at the Royal Statistical Society. Two discussants commented on the paper at the meeting and many scholars around the world contributed commentaries to the journal issue when our paper was published. The open-source software has also been downloaded more than 3000 times even though the software was uploaded to the repository only a few months ago.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 06/16/2024\n\n\t\t\t\t\tSubmitted by: KosukeImai\n"
 }
}