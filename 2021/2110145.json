{
 "awd_id": "2110145",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: ATD: Robust, Accurate and Efficient Graph-Structured RNN for Spatio-Temporal Forecasting and Anomaly Detection",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032924885",
 "po_email": "tbartosz@nsf.gov",
 "po_sign_block_name": "Tomek Bartoszynski",
 "awd_eff_date": "2021-01-15",
 "awd_exp_date": "2022-12-31",
 "tot_intn_awd_amt": 120000.0,
 "awd_amount": 104794.0,
 "awd_min_amd_letter_date": "2021-01-19",
 "awd_max_amd_letter_date": "2021-01-19",
 "awd_abstract_narration": "The project aims to develop robust, efficient, and transferrable deep learning algorithms for prediction and anomaly detection in human spatio-temporal dynamics. This will be a fundamental step in providing  reliable and speedy decision support for mitigating infectious diseases and countering threats in a time varying and spatially complex environment.  The project shall advance recent computational tools (deep neural networks) in adversarial conditions and on resource limited (low cost, low energy) platform, thereby contribute to information technology in adversarial learning, mobile computing and effective decision making. A broad range of applications include threat detection and prediction for traffic and public transportation networks, security and privacy critical data analysis and prediction, threat detection and error correction for hydraulic, electrical and nuclear power systems.  \r\n\r\nThe approaches to be used involve novel techniques in high dimensional non-smooth non-convex optimization and graph representation. Specifically, the project shall study (1) multi-scale graph-structured recurrent neural networks for spatio-temporal data modeling, prediction and anomaly detection;  (2) adversarially robust, accurate, and transferable deep learning algorithms based on advection-diffusion equations; (3)  efficient quantization algorithms under adversarial conditions to reduce the latency of deep networks. The projects shall train a diverse body of graduate and undergraduate students at the Irvine and Los Angeles campuses of University of California through collaborative education and research activities in applied mathematics, computer science, data science and social science.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bao",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bao Wang",
   "pi_email_addr": "bwang@math.utah.edu",
   "nsf_id": "000797442",
   "pi_start_date": "2021-01-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "The University of Utah",
  "perf_str_addr": "75 South 2000 East",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841128930",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "046Y00",
   "pgm_ele_name": "ATD-Algorithms for Threat Dete"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "6877",
   "pgm_ref_txt": "ALGORITHMS IN THREAT DETECTION"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 104794.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p dir=\"ltr\">In this project, we have developed robust, efficient, and transferrable deep learning algorithms for prediction and anomaly detection in human spatiotemporal dynamics. In particular, we have the following major achievements -- with all results and code being made publicly available -- funded by this NSF-funded project: 1) We have developed a new class of recurrent neural networks, named MomentumRNN, to learn the intrinsic patterns from complex time series with theoretical guarantees. 2) We have proposed a novel class of heavy-ball neural ODEs, which enjoy computational efficiency and learning expressivity for learning irregularly-sampled time series. 3) To learn long-range dependencies and learning time series concurrently with computational efficiency, we have proposed FMMformer and Glassoformer leveraging the low-rank and sparse approximation and the structured sparsity techniques in classical computational math and statistics. 4) To learn multivariate time series, we have developed continuous-depth deep graph neural networks based on random walk interpretation of diffusion process on graphs, which is particularly suitable for learning with limited supervision. 5) To achieve trustworthy machine learning, we have developed algorithms for robust and private machine learning algorithms with superior expressivity. We have applied our developed algorithms to the epidemic and power-grid fault predictions and anomaly detections. Our results have been published in top machine learning conferences and applied math journals, including NeurIPS, ICLR, ICML, and various SIAM Journals. To disseminate our results, we have also released all codes of the algorithms and tests to the community. Moreover, we have also presented these results in different seminars, workshops, and conferences. We have won first place in the 2020 ATD challenge and we have also won the best paper award at LOD 2021.</p>\n<p><br /><br /></p>\n<p dir=\"ltr\">Many of the research results have been integrated into the Mathematics of Data Science course at the University of Utah (Math 5750/6880), a course developed by the PI for graduate and senior undergraduate students. In particular, we have lectures on heavy-ball neural ODEs, the connection between diffusion equations on graphs and GNNs, and efficient transformers. Moreover, we have also created manageable course projects on designing new continuous-depth GNNs and efficient transformers accompanied by theories. The lecture slides and course projects can be found at: http://www.math.utah.edu/~bwang/pages/mathds.html. We have shared the course material with the community to increase the impact on more students that are interested in data science and data-driven scientific discovery.&nbsp; The project has trained a diverse body of graduate and undergraduate students at the University of Utah and SUNY Albany through collaborative education and research activities in applied mathematics, computer science, data science, and social science.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/06/2023<br>\n\t\t\t\t\tModified by: Bao&nbsp;Wang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "In this project, we have developed robust, efficient, and transferrable deep learning algorithms for prediction and anomaly detection in human spatiotemporal dynamics. In particular, we have the following major achievements -- with all results and code being made publicly available -- funded by this NSF-funded project: 1) We have developed a new class of recurrent neural networks, named MomentumRNN, to learn the intrinsic patterns from complex time series with theoretical guarantees. 2) We have proposed a novel class of heavy-ball neural ODEs, which enjoy computational efficiency and learning expressivity for learning irregularly-sampled time series. 3) To learn long-range dependencies and learning time series concurrently with computational efficiency, we have proposed FMMformer and Glassoformer leveraging the low-rank and sparse approximation and the structured sparsity techniques in classical computational math and statistics. 4) To learn multivariate time series, we have developed continuous-depth deep graph neural networks based on random walk interpretation of diffusion process on graphs, which is particularly suitable for learning with limited supervision. 5) To achieve trustworthy machine learning, we have developed algorithms for robust and private machine learning algorithms with superior expressivity. We have applied our developed algorithms to the epidemic and power-grid fault predictions and anomaly detections. Our results have been published in top machine learning conferences and applied math journals, including NeurIPS, ICLR, ICML, and various SIAM Journals. To disseminate our results, we have also released all codes of the algorithms and tests to the community. Moreover, we have also presented these results in different seminars, workshops, and conferences. We have won first place in the 2020 ATD challenge and we have also won the best paper award at LOD 2021.\n\n\n\n\nMany of the research results have been integrated into the Mathematics of Data Science course at the University of Utah (Math 5750/6880), a course developed by the PI for graduate and senior undergraduate students. In particular, we have lectures on heavy-ball neural ODEs, the connection between diffusion equations on graphs and GNNs, and efficient transformers. Moreover, we have also created manageable course projects on designing new continuous-depth GNNs and efficient transformers accompanied by theories. The lecture slides and course projects can be found at: http://www.math.utah.edu/~bwang/pages/mathds.html. We have shared the course material with the community to increase the impact on more students that are interested in data science and data-driven scientific discovery.  The project has trained a diverse body of graduate and undergraduate students at the University of Utah and SUNY Albany through collaborative education and research activities in applied mathematics, computer science, data science, and social science.\n\n \n\n\t\t\t\t\tLast Modified: 03/06/2023\n\n\t\t\t\t\tSubmitted by: Bao Wang"
 }
}