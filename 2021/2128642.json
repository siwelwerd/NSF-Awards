{
 "awd_id": "2128642",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: SaTC: Early-Stage Interdisciplinary Collaboration: Designing Trustworthy and Transparent Information Platforms",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2021-03-01",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 299966.0,
 "awd_amount": 264077.0,
 "awd_min_amd_letter_date": "2021-04-08",
 "awd_max_amd_letter_date": "2021-04-08",
 "awd_abstract_narration": "Defined as openness to the information creation and reporting process, transparency is a way for information institutions that have an online presence to reconnect with citizens and establish their legitimacy. This research will conduct a series of design investigations to illuminate the critical new phenomenon of transparency to rebuild public trust in one such information institution--journalistic organizations. Marrying mass communications research with human-centered computing, this research will take a novel interdisciplinary approach to answer the following questions. How can online information platforms effectively embrace the ideal of transparency as a means to increase trust? How can news organizations effectively demonstrate to the public the primary features that make a story trustworthy and the core aspects that govern the production and reporting of a news story?\r\n \r\nThe research will be conducted along three phases. The first involves understanding the current practices of online news production and consumption with respect to trustworthiness. Phase 1 will result in a rich description of what constitutes trustworthy information online and inform the development of a brand new, transformative class of transparency artifacts. In the second phase, this project will appropriate theories from Communications research and combine with data mining and natural language-based techniques from the Computing field, to build transparency features highlighting key aspects of news reporting. Specifically, it will explore two classes of transparency tools: disclosure and participatory. Disclosure transparency will communicate the production, framing, and journalistic standards around news reports. Participatory transparency will aim at getting users involved in the news cycle through two channel-based interactive features: commenting capability and hovering to see additional information. Finally, phase 3 includes interface evaluations via experiments followed by participatory design workshops with the two primary stakeholders of an online news system--journalists and news readers.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tanushree",
   "pi_last_name": "Mitra",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tanushree Mitra",
   "pi_email_addr": "tmitra@uw.edu",
   "nsf_id": "000750147",
   "pi_start_date": "2021-04-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "4333 Brooklyn Ave NE",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981950001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "065Z",
   "pgm_ref_txt": "Human factors for security research"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 264076.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Public trust in our nation's leading news organizations have steadily declined by 15% in the last decade. The effects of declining levels of trust pose several challenges for the American democracy, including, increased feelings of partisanship, difficulty in reaching consensus on public issues and opportunities for foreign interests to exploit that mistrust to spread misinformation online and increase social unrest. Yet most solutions to digital misinformation is heavily focused on finding technical fixes to <em>production-side </em>issues; for example, developing algorithms to identify and automatically restrict sources producing and propagating false information. Instead, <em>reception-side </em>remedies, where the goal is to enhance receptor&rsquo;s news reading experience, awareness, and perceptions of trust, can offer more robust solutions to digital misinformation. Critics argue that the most effective way is to adopt greater levels of transparency regarding the news-making process. Online news platforms can offer novel interfaces for supporting transparency and restoring trust, by allowing reporters to communicate with their audience and introduce background information. This project investigated how <em>online news platforms can effectively embrace the ideal of \"transparency\" to restore trust. </em>The long-term goal<strong> </strong>is to improve news-reading experience and restore public trust.</p>\n<p>The work was conducted along three phases. The goal of phase 1 was to develop a deep understanding of current practices of online news production and consumption and its relation to trust. For phase 1, we conducted extensive rounds of interviews with both news producers as well as receivers. Our first set of interviews was with a diverse pool of journalists and news consumers where we leveraged a Scenario-based design approach&mdash;a user-centered design approach that employs prototype mockups and descriptions to help end-users envision a future system and how they will use it. Stimulated by our scenario, participants recommended various transparency cues capturing source and message characteristics to address the reasons for underlying distrust. In our next set of interviews, we involved a diverse group of fact-checkers from across the world which resulted in a deep understanding of the fact-checking process, specifically the infrastructures&mdash;both human and technological&mdash;that support and shape online fact-checking work.</p>\n<p>Informed by insights from phase 1, for phase 2, our aim was to build tools that highlight key aspects of news reporting and fact-checking work and those that support better information consumption from online sources. Towards this goal, we built multiple systems and innovated on various methods, both for the producer as well as the consumer of information. For example, to support efficient and balanced news consumption by users, we developed and deployed <em>NewsComp</em>&mdash;a prototype system that enables comparative annotation while reading news from diverse news sources on the same topic. We found that comparative annotation affects users&rsquo; perceptions of article credibility and quality. With respect to helping the information producer, we built <em>YouCred</em>&mdash;a fact-checking system for a video platform, YouTube. YouCred assists fact-checkers in discovering dubious information by automatically generating search queries for topics of interest to fact-checkers. It also provides an intuitive interface for credibility assessment. YouCred not only addresses the real-world needs of fact-checking but harnesses their unique assets---indigenous knowledge and expertise. In parallel, we also innovated on several computational methods to represent and extract information that facilitates sensemaking. For example, we developed narrative maps&mdash;a powerful visual representation method to communicate complex narratives to individuals. As a sensemaking tool, narrative maps have applications in intelligence analysis, misinformation modeling, and computational journalism.</p>\n<p>Finally, the goal of phase 3 was to evaluate the efficacy of our tools and systems. To do so, we involved journalists, fact-checkers and news consumers to reflect on our interface design and critique our conclusions. For example, YouCred was built through a 2-year long collaboration with a fact-checking organization and then deployed for 9-months to closely monitor and evaluate its usage. Our evaluation revealed that fact-checkers found YouCred to be a valuable tool. It provided them with a wealth of information that would otherwise be challenging to obtain manually, enhancing their fact-checking capabilities on YouTube. For evaluating NewsComp, we conducted a between-subjects experiment with 109 users to examine how users&rsquo; annotations compare to experts&rsquo;, and how comparative annotation affects users&rsquo; perceptions of article credibility and quality. We found that comparative annotation can marginally impact users&rsquo; credibility perceptions. The comparison process also led users to notice differences in information placement and depth, degree of factuality/opinion, and empathetic/inflammatory language use.</p>\n<p>This research also led to the training of multiple students by incorporating more than 3 undergraduates and 4 graduate students through research assistantships, for-credit research positions, and undergraduate REU engagements. More than half of these students were from traditionally underrepresented populations in computing. In addition to training non-traditional computer science students (e.g. journalism majors, mass-communication majors), our work has also heavily influenced training and performance improvement of fact-checkers, many from the Global South with very little computing background.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 05/21/2024<br>\nModified by: Tanushree&nbsp;Mitra</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nPublic trust in our nation's leading news organizations have steadily declined by 15% in the last decade. The effects of declining levels of trust pose several challenges for the American democracy, including, increased feelings of partisanship, difficulty in reaching consensus on public issues and opportunities for foreign interests to exploit that mistrust to spread misinformation online and increase social unrest. Yet most solutions to digital misinformation is heavily focused on finding technical fixes to production-side issues; for example, developing algorithms to identify and automatically restrict sources producing and propagating false information. Instead, reception-side remedies, where the goal is to enhance receptors news reading experience, awareness, and perceptions of trust, can offer more robust solutions to digital misinformation. Critics argue that the most effective way is to adopt greater levels of transparency regarding the news-making process. Online news platforms can offer novel interfaces for supporting transparency and restoring trust, by allowing reporters to communicate with their audience and introduce background information. This project investigated how online news platforms can effectively embrace the ideal of \"transparency\" to restore trust. The long-term goal is to improve news-reading experience and restore public trust.\n\n\nThe work was conducted along three phases. The goal of phase 1 was to develop a deep understanding of current practices of online news production and consumption and its relation to trust. For phase 1, we conducted extensive rounds of interviews with both news producers as well as receivers. Our first set of interviews was with a diverse pool of journalists and news consumers where we leveraged a Scenario-based design approacha user-centered design approach that employs prototype mockups and descriptions to help end-users envision a future system and how they will use it. Stimulated by our scenario, participants recommended various transparency cues capturing source and message characteristics to address the reasons for underlying distrust. In our next set of interviews, we involved a diverse group of fact-checkers from across the world which resulted in a deep understanding of the fact-checking process, specifically the infrastructuresboth human and technologicalthat support and shape online fact-checking work.\n\n\nInformed by insights from phase 1, for phase 2, our aim was to build tools that highlight key aspects of news reporting and fact-checking work and those that support better information consumption from online sources. Towards this goal, we built multiple systems and innovated on various methods, both for the producer as well as the consumer of information. For example, to support efficient and balanced news consumption by users, we developed and deployed NewsCompa prototype system that enables comparative annotation while reading news from diverse news sources on the same topic. We found that comparative annotation affects users perceptions of article credibility and quality. With respect to helping the information producer, we built YouCreda fact-checking system for a video platform, YouTube. YouCred assists fact-checkers in discovering dubious information by automatically generating search queries for topics of interest to fact-checkers. It also provides an intuitive interface for credibility assessment. YouCred not only addresses the real-world needs of fact-checking but harnesses their unique assets---indigenous knowledge and expertise. In parallel, we also innovated on several computational methods to represent and extract information that facilitates sensemaking. For example, we developed narrative mapsa powerful visual representation method to communicate complex narratives to individuals. As a sensemaking tool, narrative maps have applications in intelligence analysis, misinformation modeling, and computational journalism.\n\n\nFinally, the goal of phase 3 was to evaluate the efficacy of our tools and systems. To do so, we involved journalists, fact-checkers and news consumers to reflect on our interface design and critique our conclusions. For example, YouCred was built through a 2-year long collaboration with a fact-checking organization and then deployed for 9-months to closely monitor and evaluate its usage. Our evaluation revealed that fact-checkers found YouCred to be a valuable tool. It provided them with a wealth of information that would otherwise be challenging to obtain manually, enhancing their fact-checking capabilities on YouTube. For evaluating NewsComp, we conducted a between-subjects experiment with 109 users to examine how users annotations compare to experts, and how comparative annotation affects users perceptions of article credibility and quality. We found that comparative annotation can marginally impact users credibility perceptions. The comparison process also led users to notice differences in information placement and depth, degree of factuality/opinion, and empathetic/inflammatory language use.\n\n\nThis research also led to the training of multiple students by incorporating more than 3 undergraduates and 4 graduate students through research assistantships, for-credit research positions, and undergraduate REU engagements. More than half of these students were from traditionally underrepresented populations in computing. In addition to training non-traditional computer science students (e.g. journalism majors, mass-communication majors), our work has also heavily influenced training and performance improvement of fact-checkers, many from the Global South with very little computing background.\n\n\n\t\t\t\t\tLast Modified: 05/21/2024\n\n\t\t\t\t\tSubmitted by: TanushreeMitra\n"
 }
}