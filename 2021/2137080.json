{
 "awd_id": "2137080",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps:  Algorithm-Hardware Co-Design for Large-Scale Machine Learning",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032924749",
 "po_email": "mwasko@nsf.gov",
 "po_sign_block_name": "Molly Wasko",
 "awd_eff_date": "2021-06-15",
 "awd_exp_date": "2023-11-30",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2021-07-16",
 "awd_max_amd_letter_date": "2021-07-16",
 "awd_abstract_narration": "The broader impact/commercial potential of this I-Corps project is the reduction of the economic and technical barriers preventing the adoption of current and future advancements in machine learning technologies.  Advances in artificial intelligence (AI) have pushed machine learning models to be computationally larger and larger.  Relatively few organizations currently have access to the most sophisticated models due to the necessary computational and memory requirements required to train and deploy such models. This lack of access results in high costs for researchers and businesses attempting to apply AI in applications such as robotics, natural language processing, drug discovery, and computer vision. The technology developed here reduces the size of the models and optimizes hardware so that large-scale models can be used on existing systems.  Improved access to state-of-the-art models will accelerate adoption of AI in the economy and potentially drive more rapid improvements in cutting edge AI-based discoveries.\r\n\r\nThis I-Corps project develops a combination of several innovations in the field of machine learning acceleration. The innovation is aimed at simultaneous optimization at the hardware and software levels. By targeting both levels simultaneously, the technology enables speeds which are not possible by combining existing technologies individually.  The core technology combines model compression techniques, custom kernels and hardware utilization designs for acceleration, and cloud orchestration algorithms. Prior results have shown capabilities to significantly reduce model sizes and speed inference results.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gu-Yeon",
   "pi_last_name": "Wei",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gu-Yeon Wei",
   "pi_email_addr": "guyeon@eecs.harvard.edu",
   "nsf_id": "000086808",
   "pi_start_date": "2021-07-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University",
  "perf_str_addr": "150 Western Ave.",
  "perf_city_name": "Allston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021341037",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6856",
   "pgm_ref_txt": "ARTIFICIAL INTELL & COGNIT SCI"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of the NSF I-Corps program is to train academics to <em>get out of the building</em> and explore the possible commercialization of basic research projects. As part of the program, we initially explored the market potential of a probabilistic computer, one of our main research projects.</p>\n<p>Probabilistic computing is often used as an optimization tool (similar to quantum computing) or an inference engine for Bayesian inference, which is a widely used algorithm in machine learning for problems that require explainability and estimation of the entire distribution, not just a point estimate. We interviewed over 100 companies to learn more about the challenges associated with adoption of new hardware, how big the market is, and the willingness to pay for the innovation. Via customer discovery, we learned that the market size was not large enough to justify the time and cost of building custom hardware dedicated to probabilistic computing. Further, the process of procurement for new hardware was prohibitively long and difficult.</p>\n<p>During the customer discovery phase, we also learned that many companies were evaluating transformer-based language models as a useful and robust method of processing large amounts of text data. Transformer-based speech NLP engine was another one of our research projects and we pivoted towards this research and technology via another round of customer discovery.</p>\n<p>We interviewed over 100 companies solely focusing on the large language models and found it offered a much more diverse and promising set of applications. It also was growing in popularity with many companies working on internal proof-of-concept development efforts to explore the potential use of the technology in their products. The path to production was also simpler as it did not require new special hardware. The algorithm could be accelerated on GPUs, obviating new hardware design. We could focus on optimizing the software stack. A software-only solution also meant that scalability was significantly better and the technology was readily more accessible.</p>\n<p>Research members, Glenn Ko and Yuji Chai, co-founded a company called <em>Stochastic</em> to take the technology from the lab to the market. Stochastic is building an AI platform that helps companies easily employ domain-specific AI agents that augment their employees to work more efficiently and automate mundane tasks saving them hours of time every day. Stochastic has several design partners that they are working with to target real pain points of large enterprises and leverage their data and in-production performance to improve Stochastic&rsquo;s product.</p>\n<p>The I-Corps program provides something that cannot readily be learned from academia or anywhere else. It encourages researchers to think out of the box and focus more on the process and challenges of translation technologies and potential economic impact of commercialization. The lessons learned from the program will not only be helpful in the lab-to-market process but the academic research itself as the researchers will have an expanded view of the potential impact as they think about research directions and what they work on.</p><br>\n<p>\n Last Modified: 03/25/2024<br>\nModified by: Gu-Yeon&nbsp;Wei</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe goal of the NSF I-Corps program is to train academics to get out of the building and explore the possible commercialization of basic research projects. As part of the program, we initially explored the market potential of a probabilistic computer, one of our main research projects.\n\n\nProbabilistic computing is often used as an optimization tool (similar to quantum computing) or an inference engine for Bayesian inference, which is a widely used algorithm in machine learning for problems that require explainability and estimation of the entire distribution, not just a point estimate. We interviewed over 100 companies to learn more about the challenges associated with adoption of new hardware, how big the market is, and the willingness to pay for the innovation. Via customer discovery, we learned that the market size was not large enough to justify the time and cost of building custom hardware dedicated to probabilistic computing. Further, the process of procurement for new hardware was prohibitively long and difficult.\n\n\nDuring the customer discovery phase, we also learned that many companies were evaluating transformer-based language models as a useful and robust method of processing large amounts of text data. Transformer-based speech NLP engine was another one of our research projects and we pivoted towards this research and technology via another round of customer discovery.\n\n\nWe interviewed over 100 companies solely focusing on the large language models and found it offered a much more diverse and promising set of applications. It also was growing in popularity with many companies working on internal proof-of-concept development efforts to explore the potential use of the technology in their products. The path to production was also simpler as it did not require new special hardware. The algorithm could be accelerated on GPUs, obviating new hardware design. We could focus on optimizing the software stack. A software-only solution also meant that scalability was significantly better and the technology was readily more accessible.\n\n\nResearch members, Glenn Ko and Yuji Chai, co-founded a company called Stochastic to take the technology from the lab to the market. Stochastic is building an AI platform that helps companies easily employ domain-specific AI agents that augment their employees to work more efficiently and automate mundane tasks saving them hours of time every day. Stochastic has several design partners that they are working with to target real pain points of large enterprises and leverage their data and in-production performance to improve Stochastics product.\n\n\nThe I-Corps program provides something that cannot readily be learned from academia or anywhere else. It encourages researchers to think out of the box and focus more on the process and challenges of translation technologies and potential economic impact of commercialization. The lessons learned from the program will not only be helpful in the lab-to-market process but the academic research itself as the researchers will have an expanded view of the potential impact as they think about research directions and what they work on.\t\t\t\t\tLast Modified: 03/25/2024\n\n\t\t\t\t\tSubmitted by: Gu-YeonWei\n"
 }
}