{
 "awd_id": "2053493",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Information-Based Complexity Analysis and Optimal Methods for Saddle-Point Structured Optimization",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2021-06-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 249972.0,
 "awd_amount": 249972.0,
 "awd_min_amd_letter_date": "2021-02-26",
 "awd_max_amd_letter_date": "2023-04-28",
 "awd_abstract_narration": "With the increasing volumes of data involved in modern-day research, it is important to build new mathematical and statistical tools that are applicable to huge-scale datasets and do not require large computation time. Optimization algorithms are an important computational tool for data analysis in various disciplines, and many modern applications require these optimization algorithms to handle very large-scale, highly nonlinear, and non-smooth problems. These features bring great challenges to computing solutions in a scalable and efficient way. This project aims at addressing the computational difficulties in optimization algorithms that arise from large-scale data analysis problems. Undergraduate and graduate students will be trained and involved in this project.  \r\n\r\nIn the big data era, scalability is one most important factor in designing computational algorithms. This feature motivates the recent rapid development of first-order methods. This project focuses on the development and the understanding of fundamental limits of novel first-order algorithms for solving saddle-point structured optimization problems. Specifically, the project aims at advancing saddle-point structured non-smooth optimization techniques applicable to large-scale data analysis problems. With problem-specific information on structure that a first-order method can acquire, information-based complexity analysis will be conducted to reveal the intrinsic difficulty of the specified class of problems, and numerical approaches will be designed. Deterministic first-order methods, randomized and greedy block gradient methods, stochastic first-order methods, and their asynchronous parallel versions adequate for multi-core machines or clusters will be developed. For each class of proposed methods lower complexity bounds will be established, and optimal numerical algorithms will be designed to reach these bounds.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yangyang",
   "pi_last_name": "Xu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yangyang Xu",
   "pi_email_addr": "xuy21@rpi.edu",
   "nsf_id": "000730012",
   "pi_start_date": "2021-02-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rensselaer Polytechnic Institute",
  "inst_street_address": "110 8TH ST",
  "inst_street_address_2": "",
  "inst_city_name": "TROY",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5182766000",
  "inst_zip_code": "121803590",
  "inst_country_name": "United States",
  "cong_dist_code": "20",
  "st_cong_dist_code": "NY20",
  "org_lgl_bus_name": "RENSSELAER POLYTECHNIC INSTITUTE",
  "org_prnt_uei_num": "",
  "org_uei_num": "U5WBFKEBLMX3"
 },
 "perf_inst": {
  "perf_inst_name": "Rensselaer Polytechnic Institute",
  "perf_str_addr": "110 8th Street",
  "perf_city_name": "Troy",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "121803522",
  "perf_ctry_code": "US",
  "perf_cong_dist": "20",
  "perf_st_cong_dist": "NY20",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 80468.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 83460.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 86044.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>During the project period, the PI has finished 14 papers, partly supported by this NSF grant. He also attended several conferences, including SIAM Conference on Mathematics of Data Science 2022, SIAM Conference on Optimization 2023, INFORMS Annual Meeting 2021-2023, and International Symposium on Mathematical Programming 2024 to disseminate the findings from this project. Two RPI PhD students have been mentored to work on proposed topics of this project, and one undergraduate student has participated in this project by performing numerical simulations of the proposed algorithms.&nbsp;&nbsp;<br />The PI and participating students have developed several algorithms that were proposed in this project for solving saddle-point structured optimization and constrained optimization problems. An adaptive primal-dual stochastic subgradient method has been developed for solving expectation constrained optimization and stochastic convex-concave saddle-point problems. A MATLAB code package for this method has been released in GitHub. An inexact accelerated proximal gradient method was developed to solve structured convex optimization. It was then applied to reduce the complexity of first-order methods for solving linearly constrained optimization and convex-concave saddle point problems. Two primal-dual methods were developed for constrained optimization problems, and a Python code package was released in GitHub.<br />Furthermore, the PI has incorporated some numerical methods developed from this project into optimization courses that the PI taught, such as ``Computational Optimization'' and ``Stochastic Optimization and Reinforcement Learning''. Through teaching and organizing an online seminar, the PI has exposed to RPI undergraduate and graduate students several algorithms that are developed from this project.</p><br>\n<p>\n Last Modified: 10/17/2024<br>\nModified by: Yangyang&nbsp;Xu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nDuring the project period, the PI has finished 14 papers, partly supported by this NSF grant. He also attended several conferences, including SIAM Conference on Mathematics of Data Science 2022, SIAM Conference on Optimization 2023, INFORMS Annual Meeting 2021-2023, and International Symposium on Mathematical Programming 2024 to disseminate the findings from this project. Two RPI PhD students have been mentored to work on proposed topics of this project, and one undergraduate student has participated in this project by performing numerical simulations of the proposed algorithms.\nThe PI and participating students have developed several algorithms that were proposed in this project for solving saddle-point structured optimization and constrained optimization problems. An adaptive primal-dual stochastic subgradient method has been developed for solving expectation constrained optimization and stochastic convex-concave saddle-point problems. A MATLAB code package for this method has been released in GitHub. An inexact accelerated proximal gradient method was developed to solve structured convex optimization. It was then applied to reduce the complexity of first-order methods for solving linearly constrained optimization and convex-concave saddle point problems. Two primal-dual methods were developed for constrained optimization problems, and a Python code package was released in GitHub.\nFurthermore, the PI has incorporated some numerical methods developed from this project into optimization courses that the PI taught, such as ``Computational Optimization'' and ``Stochastic Optimization and Reinforcement Learning''. Through teaching and organizing an online seminar, the PI has exposed to RPI undergraduate and graduate students several algorithms that are developed from this project.\t\t\t\t\tLast Modified: 10/17/2024\n\n\t\t\t\t\tSubmitted by: YangyangXu\n"
 }
}