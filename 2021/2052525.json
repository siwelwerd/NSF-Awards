{
 "awd_id": "2052525",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CDS&E: Applied Geometry and Harmonic Analysis in Deep Learning Regularization: Theory and Applications",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2020-06-30",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 51600.0,
 "awd_amount": 51600.0,
 "awd_min_amd_letter_date": "2020-11-05",
 "awd_max_amd_letter_date": "2020-11-05",
 "awd_abstract_narration": "In this era of Big Data, deep learning has become a burgeoning domain with immense potential to advance science, technology, and human life. Despite the tremendous practical success of deep neural networks (DNNs) in various data-intensive machine learning applications, there still remain many open problems to be addressed: (1) DNNs tend to suffer from overfitting when the available training data are scarce, which renders them less effective in the small data regime. (2) DNNs have shown to have the capability of perfectly \u201cmemorizing\u201d random training samples, making them less trustworthy when the training data are noisy and corrupted. (3) While symmetry is ubiquitous in machine learning (e.g., in image classification, the class label of an image remains the same if the image is spatially rescaled and translated,) generic DNN architectures typically destroy such symmetry in the representation, which leads to significant redundancy in the model to \u201cmemorize\u201d such information from the data. The goal of this project is to address these challenges in deep learning by exploiting the low-dimensional geometry and symmetry within the data and their network representations, aiming at developing new theories and methodologies for deep learning regularization that can lead to tangible advances in machine learning and artificial intelligence especially in the small/corrupted data regime. In addition the project also provides research training opportunities for graduate students.\r\n\r\nThe overarching theme of this project is to leverage recent progress in mathematical methods from differential geometry and applied harmonic analysis to improve the stability, reliability, data-efficiency, and interpretability of deep learning. This will involve the development of both foundational theories and efficient algorithms to achieve the following three objectives: (1) The development of manifold-based DNN regularizations with significantly improved generalization performance by focusing on the topology and geometry of both the input data and their representations. This will unlock the potential of deep learning in the small data regime.  (2) Establishing and analyzing an innovative framework of imposing geometric constraint in deep learning that has immense potential of limiting the memorizing capacity of DNN. The mathematical analysis of the training dynamics of such model will shed light on the understanding of the fundamental difference between \u201cmemorization\u201d and generalization in deep learning. (3) The construction of deformation robust symmetry-preserving DNN architectures for various symmetry transformations on different data domains. By \"hardwiring\" the symmetry information into the deformation robust representations, the regularized DNN models will have improved performance and interpretability with reduced redundancy and model size. In terms of application, the project will demonstrate and deploy the proposed theories in real-world machine learning tasks, such as object recognition, localization, and segmentation. The techniques developed in this project will be widely applicable across different disciplines, providing fundamental building blocks for the next generation of mathematical tools for the computational modeling of Big Data.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Wei",
   "pi_last_name": "Zhu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wei Zhu",
   "pi_email_addr": "weizhu@gatech.edu",
   "nsf_id": "000790713",
   "pi_start_date": "2020-11-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "Research Administration Building",
  "perf_city_name": "Hadley",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010359450",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 51600.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">During the funding period, the PI and collaborators successfully completed 17 academic papers, with 12 published in leading machine learning conferences and applied mathematics journals. These publications include 1 paper in ICLR, 1 in ICCV, 2 in NeurIPS, 1 in JMLR, and 2 in ICML, while five additional papers are currently under review.&nbsp;</p>\n<p class=\"p1\">The project met its three primary <strong>Intellectual Merit</strong> objectives:</p>\n<p class=\"p2\">&nbsp;1. <strong>Data-Dependent Regularization for Deep Neural Networks (DNNs):</strong> The team developed innovative regularization techniques grounded in data geometry. These methods significantly enhanced the generalization performance of DNN models, particularly in scenarios where training data was scarce.</p>\n<p class=\"p2\">&nbsp;2. <strong>Geometry-Based Regularization for DNNs with Corrupted Data:</strong> We refined a regularization approach that mitigates the tendency of DNNs to overfit or \"memorize\" noisy or corrupted training data. This technique enhances the robustness of DNNs in practical applications where data quality may be compromised.</p>\n<p class=\"p2\">&nbsp;3. <strong>Deformation-Robust, Symmetry-Preserving DNN Framework:</strong> The team established a general framework for designing DNNs that are resistant to data deformations while maintaining inherent symmetries. The performance improvements of these models were rigorously measured, and the framework was extended beyond predictive models to encompass structure-preserving generative models, expanding its range of applications.</p>\n<p class=\"p2\">&nbsp;In terms of <strong>Broader Impact</strong>, the project provided significant educational and research opportunities. Several undergraduate students participated through summer REU programs, and graduate students and postdoctoral researchers also benefited from the project&rsquo;s support. Additionally, the PI co-developed and taught a year-long graduate course, &ldquo;<em>Mathematical Foundations of Machine Learning</em>&rdquo;, at UMass Amherst. This course was designed for graduate students and advanced undergraduates interested in the theoretical foundations of machine learning. The PI also served as a key instructor for &ldquo;<em>Introduction to Foundations of Data Science</em>&rdquo;, a two-week summer course offered to high school students at UMass Amherst. This course introduced students to data science and encouraged them to pursue STEM degrees in college. The research outcomes from the project were seamlessly incorporated into these educational programs, providing students with hands-on experience in cutting-edge machine learning techniques.</p>\n<p class=\"p2\">&nbsp;All software and datasets generated from the project have been made publicly available, ensuring that the broader research community can benefit from the tools and insights developed.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/20/2024<br>\nModified by: Wei&nbsp;Zhu</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nDuring the funding period, the PI and collaborators successfully completed 17 academic papers, with 12 published in leading machine learning conferences and applied mathematics journals. These publications include 1 paper in ICLR, 1 in ICCV, 2 in NeurIPS, 1 in JMLR, and 2 in ICML, while five additional papers are currently under review.\n\n\nThe project met its three primary Intellectual Merit objectives:\n\n\n1. Data-Dependent Regularization for Deep Neural Networks (DNNs): The team developed innovative regularization techniques grounded in data geometry. These methods significantly enhanced the generalization performance of DNN models, particularly in scenarios where training data was scarce.\n\n\n2. Geometry-Based Regularization for DNNs with Corrupted Data: We refined a regularization approach that mitigates the tendency of DNNs to overfit or \"memorize\" noisy or corrupted training data. This technique enhances the robustness of DNNs in practical applications where data quality may be compromised.\n\n\n3. Deformation-Robust, Symmetry-Preserving DNN Framework: The team established a general framework for designing DNNs that are resistant to data deformations while maintaining inherent symmetries. The performance improvements of these models were rigorously measured, and the framework was extended beyond predictive models to encompass structure-preserving generative models, expanding its range of applications.\n\n\nIn terms of Broader Impact, the project provided significant educational and research opportunities. Several undergraduate students participated through summer REU programs, and graduate students and postdoctoral researchers also benefited from the projects support. Additionally, the PI co-developed and taught a year-long graduate course, Mathematical Foundations of Machine Learning, at UMass Amherst. This course was designed for graduate students and advanced undergraduates interested in the theoretical foundations of machine learning. The PI also served as a key instructor for Introduction to Foundations of Data Science, a two-week summer course offered to high school students at UMass Amherst. This course introduced students to data science and encouraged them to pursue STEM degrees in college. The research outcomes from the project were seamlessly incorporated into these educational programs, providing students with hands-on experience in cutting-edge machine learning techniques.\n\n\nAll software and datasets generated from the project have been made publicly available, ensuring that the broader research community can benefit from the tools and insights developed.\n\n\n\t\t\t\t\tLast Modified: 10/20/2024\n\n\t\t\t\t\tSubmitted by: WeiZhu\n"
 }
}