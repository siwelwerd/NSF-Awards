{
 "awd_id": "2120235",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CCRI: Planning: InfraStructure for Photorealistic Image and Environment Synthesis (I-SPIES)",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 12916.0,
 "awd_amount": 12916.0,
 "awd_min_amd_letter_date": "2021-08-10",
 "awd_max_amd_letter_date": "2021-08-10",
 "awd_abstract_narration": "Numerous Computer and Information Science and Engineering (CISE) research communities leverage datasets comprised of visual images or 3D virtual environments to conduct research in computer vision, robotics, multimedia systems, virtual reality, and mixed reality. Many of these datasets consist of either images previously captured with cameras and other optical sensors, or synthetic images previously rendered from 3D virtual environments. The static nature of these datasets limits their usefulness and potential applications. Recently, some researchers have provided datasets and tools for synthesizing new images from 3D virtual environments using customizable virtual camera positions, which broadens their research applications. However, many of these datasets consist of lower-fidelity indoor virtual environments that yield non-photorealistic images. Furthermore, such datasets are missing outdoor virtual environments, and tools for sharing custom camera positions within the research community are not currently available.\r\n\r\nThis planning project prepares to address the limitations of prior datasets by investigating the feasibility of using high-quality terrestrial laser scanners to capture and create high-fidelity, photorealistic virtual environments of real-world locations, both indoor and outdoor. This will be coupled with surveys of the relevant CISE research communities through workshops held at top academic conferences. This project will result in the development of two preliminary datasets, one indoor and one outdoor, using the proposed laser-scanner methodology, and the identification of community needs, priorities, and support for the proposed InfraStructure for Photorealistic Images and Environment Synthesis (I-SPIES). Undergraduate students will be engaged in the development of the preliminary datasets through the University of Central Florida\u2019s EXCEL STEM program, a former NSF STEP program\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nicholas",
   "pi_last_name": "Gans",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nicholas Gans",
   "pi_email_addr": "nicholas.gans@uta.edu",
   "nsf_id": "000564957",
   "pi_start_date": "2021-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Arlington",
  "inst_street_address": "701 S NEDDERMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "ARLINGTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "8172722105",
  "inst_zip_code": "760199800",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT ARLINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "LMLUKUPJJ9N3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Arlington",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "761187115",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "TX12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 12916.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Overview</strong></p>\n<p><strong>&nbsp;</strong>This planning project investigated the feasibility of using high-quality laser scanners to capture and generate high-fidelity, photorealistic virtual environments of real-world locations, both indoor and outdoor.&nbsp; The objective was to propose a new infrastructure for multiple Computer and Information Science and Engineering (CISE) research communities. The project yielded two preliminary datasets, one indoor and one outdoor, using the proposed method. Additionally, an open-source tool named \"RecolorCloud\" was developed to enhance the colors of 3D point clouds, which are sets of colored 3D points representing real-world objects and surroundings. Moreover, four academic workshops were organized and hosted, focusing on the synthesis of photorealistic images of environments. These workshops helped identify the needs and priorities of four CISE research communities (multimedia, mixed reality, computer vision, and robotics) in relation to the proposed infrastructure.</p>\n<p>&nbsp;</p>\n<p><strong>Intellectual Merit</strong></p>\n<p>This project established a pipeline for synthesizing photorealistic images from high-quality laser scans. This pipeline consists of four steps:</p>\n<ol>\n<li>refining the point clouds captured by the laser scanners to remove erroneous points and artifacts</li>\n<li>segmenting the point clouds into relevant sections (e.g., trees, buildings, etc.</li>\n<li>using the &ldquo;RecolorCloud&rdquo; tool to alter and/or correct the colors of the point clouds based on the segments</li>\n<li>using a raytracing computer-graphics rendering technique to produce photorealistic images from the corrected point clouds.</li>\n</ol>\n<p>&nbsp;</p>\n<p><strong>Broader Impacts</strong></p>\n<p>Through this project, we have &nbsp;introduced a new open-source tool, &ldquo;RecolorCloud,&rdquo; designed for editing and refining point clouds captured with laser scanners called. &nbsp;This tool is accessible to the public through GitHub. Additionally, we have made available examples of datasets that have been enhanced using \"RecolorCloud\" on the Open Science Framework. &nbsp;Furthermore, the project has played a direct role in the professional development and training of a Research Scientist at the University of Texas at Arlington, and a Ph.D. candidate and an undergraduate student at the University of Central Florida (UCF).</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/13/2024<br>\nModified by: Nicholas&nbsp;Gans</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nOverview\n\n\nThis planning project investigated the feasibility of using high-quality laser scanners to capture and generate high-fidelity, photorealistic virtual environments of real-world locations, both indoor and outdoor. The objective was to propose a new infrastructure for multiple Computer and Information Science and Engineering (CISE) research communities. The project yielded two preliminary datasets, one indoor and one outdoor, using the proposed method. Additionally, an open-source tool named \"RecolorCloud\" was developed to enhance the colors of 3D point clouds, which are sets of colored 3D points representing real-world objects and surroundings. Moreover, four academic workshops were organized and hosted, focusing on the synthesis of photorealistic images of environments. These workshops helped identify the needs and priorities of four CISE research communities (multimedia, mixed reality, computer vision, and robotics) in relation to the proposed infrastructure.\n\n\n\n\n\nIntellectual Merit\n\n\nThis project established a pipeline for synthesizing photorealistic images from high-quality laser scans. This pipeline consists of four steps:\n\nrefining the point clouds captured by the laser scanners to remove erroneous points and artifacts\nsegmenting the point clouds into relevant sections (e.g., trees, buildings, etc.\nusing the RecolorCloud tool to alter and/or correct the colors of the point clouds based on the segments\nusing a raytracing computer-graphics rendering technique to produce photorealistic images from the corrected point clouds.\n\n\n\n\n\n\nBroader Impacts\n\n\nThrough this project, we have introduced a new open-source tool, RecolorCloud, designed for editing and refining point clouds captured with laser scanners called. This tool is accessible to the public through GitHub. Additionally, we have made available examples of datasets that have been enhanced using \"RecolorCloud\" on the Open Science Framework. Furthermore, the project has played a direct role in the professional development and training of a Research Scientist at the University of Texas at Arlington, and a Ph.D. candidate and an undergraduate student at the University of Central Florida (UCF).\n\n\n\t\t\t\t\tLast Modified: 02/13/2024\n\n\t\t\t\t\tSubmitted by: NicholasGans\n"
 }
}