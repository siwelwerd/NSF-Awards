{
 "awd_id": "2127797",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps: Probabilistic artificial intelligence (AI)-based software for proactive data quality assessment",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032924749",
 "po_email": "mwasko@nsf.gov",
 "po_sign_block_name": "Molly Wasko",
 "awd_eff_date": "2021-05-15",
 "awd_exp_date": "2023-10-31",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2021-06-03",
 "awd_max_amd_letter_date": "2021-06-03",
 "awd_abstract_narration": "The broader impact/commercial potential of this I-Corps project is the development of a solution that identifies and corrects data data entry errors. The accelerating adoption of e-commerce and digital systems has increased the use of digital data entry systems. This may create challenges for providing equitable service to people with low income and education levels. The proposed data quality software finds and eliminates user errors at the point of data entry, providing proactive, secure and convenient support for users while filling in forms.  The solution may also provide accurate data for companies. Compared to existing data quality solutions, this product eliminates the need for time-consuming and costly post data collection cleaning. The solution may benefit data-centric domains such as health care, finance, e-commerce, and tax and government benefit application systems where data errors can be costly. The goal is to provide users with proactive help that may reduce incorrect processing and potential issues with timely access. This proposed real-time, error alert and correction technology may benefit data entry specialists and consumers through corrective capability, while the companies that process the digital documents and online forms/web submissions may benefit from the cost-savings in terms of both post-submission corrective costs and potential damage control costs.\r\n\r\nThis I-Corps project is based on the development of an artificial intelligence-driven analytical process and smart software that helps users submit mistake-free information at the time of data entry. The algorithms analyze the data to reveal unusual entries through the use of basic format checks, data matching, and probabilistic machine learning algorithms. Context based and personalized probabilistic analytical methods enable both variable and data accuracy assessment. The Bayesian nature of these algorithms allows incorporation of expert opinion and user feedback. The proposed software provides an interface that uses the analytical output and works with the user to verify their data entry before submission. This interface helps users fix mistakes at the time of data entry. Use of probabilistic algorithms allow the use of relative occurrence weights instead of computing over the whole data base. This makes the process faster with diminished privacy and security concerns over raw data transfer. The proposed technology involves multiple research areas including Bayesian statistics, data analytics, and software development. This project aims to verify a secure, trustworthy, and validated approach based on a proactive data quality paradigm and a suite of algorithms including probabilistic methods.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tahir",
   "pi_last_name": "Ekin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tahir Ekin",
   "pi_email_addr": "tahirekin@txstate.edu",
   "nsf_id": "000853125",
   "pi_start_date": "2021-06-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Greg",
   "pi_last_name": "LaKomski",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Greg LaKomski",
   "pi_email_addr": "greg@txstate.edu",
   "nsf_id": "000853134",
   "pi_start_date": "2021-06-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas State University - San Marcos",
  "inst_street_address": "601 UNIVERSITY DR",
  "inst_street_address_2": "",
  "inst_city_name": "SAN MARCOS",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5122452314",
  "inst_zip_code": "786664684",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "TX15",
  "org_lgl_bus_name": "TEXAS STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HS5HWWK1AAU5"
 },
 "perf_inst": {
  "perf_inst_name": "Texas State University - San Marcos",
  "perf_str_addr": "601 University Drive",
  "perf_city_name": "San Marcos",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "786664684",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "TX15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Project Overview: This project focused on assessing the commercial potential of innovative data quality processes, software, and algorithms developed at Texas State University. Drawing from expertise in Bayesian statistics, data analytics, and software development, we aimed to create a secure, trustworthy, and validated approach to proactive data quality management. Through participation in an I-Corps training program, we conducted extensive market and customer discovery, conducting over a hundred interviews to gauge product-market fit. While initially targeting the healthcare and banking/finance sectors, feedback from customer interviews led us to pivot towards defense and security applications. We attended conferences, exhibitions, and gave presentations to gather feedback, refine algorithms, and ultimately founded a small business to address the identified needs.</p>\n<p>Intellectual Merit: Our project leveraged interdisciplinary research to develop cutting-edge solutions for proactive data quality management. By integrating Bayesian statistics, data analytics, and software development, we devised a novel approach to identify and address data errors in real-time, enhancing the trustworthiness and reliability of digital systems. Through rigorous evaluation and iterations, we aimed to demonstrate the feasibility and effectiveness of our approach, laying the groundwork for future advancements in data quality management across various domains.</p>\n<p>Broader Impacts: The outcomes of our project hold significant potential for various data-centric industries, including healthcare, finance, e-commerce, and government services. By providing real-time error alert and correction technology, we aim to empower users with the tools to mitigate processing errors and ensure timely access to accurate information. This not only benefits data entry specialists and consumers but also enables companies to streamline processes, reduce corrective costs, and mitigate potential damage from data errors. Additionally, our efforts contribute to addressing the digital divide by ensuring equitable access to digital services, particularly for underserved populations with low income and education levels.</p>\n<p>Moving forward, we are committed to furthering the commercialization of our technology and exploring opportunities to secure funding for continued research and development efforts. By bridging the gap between research and market application, we strive to make meaningful contributions to the advancement of data quality management and its broader societal impact<span>.</span></p><br>\n<p>\n Last Modified: 02/29/2024<br>\nModified by: Tahir&nbsp;Ekin</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nProject Overview: This project focused on assessing the commercial potential of innovative data quality processes, software, and algorithms developed at Texas State University. Drawing from expertise in Bayesian statistics, data analytics, and software development, we aimed to create a secure, trustworthy, and validated approach to proactive data quality management. Through participation in an I-Corps training program, we conducted extensive market and customer discovery, conducting over a hundred interviews to gauge product-market fit. While initially targeting the healthcare and banking/finance sectors, feedback from customer interviews led us to pivot towards defense and security applications. We attended conferences, exhibitions, and gave presentations to gather feedback, refine algorithms, and ultimately founded a small business to address the identified needs.\n\n\nIntellectual Merit: Our project leveraged interdisciplinary research to develop cutting-edge solutions for proactive data quality management. By integrating Bayesian statistics, data analytics, and software development, we devised a novel approach to identify and address data errors in real-time, enhancing the trustworthiness and reliability of digital systems. Through rigorous evaluation and iterations, we aimed to demonstrate the feasibility and effectiveness of our approach, laying the groundwork for future advancements in data quality management across various domains.\n\n\nBroader Impacts: The outcomes of our project hold significant potential for various data-centric industries, including healthcare, finance, e-commerce, and government services. By providing real-time error alert and correction technology, we aim to empower users with the tools to mitigate processing errors and ensure timely access to accurate information. This not only benefits data entry specialists and consumers but also enables companies to streamline processes, reduce corrective costs, and mitigate potential damage from data errors. Additionally, our efforts contribute to addressing the digital divide by ensuring equitable access to digital services, particularly for underserved populations with low income and education levels.\n\n\nMoving forward, we are committed to furthering the commercialization of our technology and exploring opportunities to secure funding for continued research and development efforts. By bridging the gap between research and market application, we strive to make meaningful contributions to the advancement of data quality management and its broader societal impact.\t\t\t\t\tLast Modified: 02/29/2024\n\n\t\t\t\t\tSubmitted by: TahirEkin\n"
 }
}