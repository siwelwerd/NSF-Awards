{
 "awd_id": "2114952",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: SaTC AI-Cybersecurity: Faking It: Facilitating Public Awareness of Cybersecurity Issues in AI",
 "cfda_num": "47.076",
 "org_code": "11010000",
 "po_phone": "7032927353",
 "po_email": "cxin@nsf.gov",
 "po_sign_block_name": "ChunSheng Xin",
 "awd_eff_date": "2021-07-15",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2021-07-06",
 "awd_max_amd_letter_date": "2021-07-06",
 "awd_abstract_narration": "The lack of a strong public understanding of artificial intelligence (AI) technologies represents both a threat to national security and an opportunity for the development of new approaches to cybersecurity education and research. The project intends to develop and support a series of publicly accessible AI challenge competitions aimed at facilitating the public\u2019s understanding of AI technologies and cybersecurity. All challenges will additionally serve as large-scale data collection platforms, assisting researchers in better understanding the trustworthiness and interpretability of AI systems. Project plans include creating lesson plans and challenges designed simultaneously to broaden understanding of cybersecurity issues in AI and provide an on-ramp for students interested in AI and cybersecurity across K-12 and higher education. Overall, the project team hopes to contribute to and scale ongoing efforts to develop and administer freely available online curricula that fosters public awareness of AI.\r\n\r\nThere is a clear and urgent need to connect research, education, and workforce development efforts at the intersection of AI and cybersecurity due to the highly interdisciplinary nature of AI and machine learning challenges, as well as the rapid development and adoption of AI technologies. This project will address these urgent challenges through the following research questions: First, how do individuals identify trustworthy AI systems and outputs? Second, how do AI/Cybersecurity concepts align with current educational standards? Last, how can public understanding and trust of AI be enhanced further? To answer these questions, the project will develop scaffolded challenges at the intersection of cybersecurity and AI entitled \u201cDeeperfakes\u201d and \u201cP0150N\u201d. The project team will work with the non-profit AI Education Project, working specifically to include modules on deep fakes and the role of AI in the cybersecurity workforce. The Deeperfakes challenges will ask participants to verify a series of AI-generated images and media, explaining their reasoning for either accepting or rejecting various media as real or fabricated. Similarly, the P0150N challenges will pit students against simple AI systems modeling those that detect denial of service attacks. This will allow students to experiment with mechanisms to poison the AI and successfully carry out an attack. The challenges will also serve as data collection tools and produce a large, open dataset for AI and cybersecurity research. This dataset will provide AI and cybersecurity researchers with information on how people read \u201cfaked\u201d algorithmic media as real or fabricated. \r\n\r\nThis project is supported by a special initiative of the Secure and Trustworthy Cyberspace (SaTC) program to foster new, previously unexplored, collaborations between the fields of cybersecurity, artificial intelligence, and education. The SaTC program aligns with the Federal Cybersecurity Research and Development Strategic Plan and the National Privacy Research Strategy to protect and preserve the growing social and economic benefits of cyber systems while ensuring security and privacy.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DGE",
 "org_div_long_name": "Division Of Graduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nathan",
   "pi_last_name": "Fisk",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Nathan W Fisk",
   "pi_email_addr": "fisk@usf.edu",
   "nsf_id": "000537800",
   "pi_start_date": "2021-07-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sudeep",
   "pi_last_name": "Sarkar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sudeep Sarkar",
   "pi_email_addr": "sarkar@usf.edu",
   "nsf_id": "000285699",
   "pi_start_date": "2021-07-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sriram",
   "pi_last_name": "Chellappan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sriram Chellappan",
   "pi_email_addr": "sriramc@usf.edu",
   "nsf_id": "000508634",
   "pi_start_date": "2021-07-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of South Florida",
  "inst_street_address": "4202 E FOWLER AVE",
  "inst_street_address_2": "",
  "inst_city_name": "TAMPA",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "8139742897",
  "inst_zip_code": "336205800",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "FL15",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTH FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NKAZLXLL7Z91"
 },
 "perf_inst": {
  "perf_inst_name": "University of South Florida",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "336205650",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "FL15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "093Z",
   "pgm_ref_txt": "AI Education/Workforce Develop"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0421",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002122DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Project Outcomes Reportfor the General Public</p>\n<p>Faking human intelligence, artificial intelligence (AI) has become increasinglypervasive in everyday life &mdash; from chat bots, recommendation engines, andsummaries of search results to assisting with creative tasks, including writing andcreation of media. But as with every technology, AI may be leveraged both for goodand in a way that can cause harm.&ldquo;Faking It: Facilitating Public Awareness of Cybersecurity Issues in AI&rdquo; is a researchproject that aims to increase public awareness of AI technologies and their role increating or preventing cyber-, physical, and social risks to security. AI systems canbe designed to achieve various goals, and therefore need to be explored fromvarious perspectives. &ldquo;Faking It&rdquo; is a collaboration between the fields ofcybersecurity, artificial intelligence, and education.One of the major activities in this project is the development of data collectionmechanism for research study &mdash; an image annotation platform where participantsare presented with a series of both real and AI-generated images, and asked toindicate their perceptions. The platform is embedded within a survey whereparticipants in the study can provide consent, annotate images and answerquestions about their background and experiences with AI. The project team plansto carry out data collection and analysis in 2025, with hopes that the project will yetyield significant impacts on the development of the principal disciplines.A product of the project is the development of freely available online curricula thatfocuses on AI and the future of work along with driving social awareness ofalgorithmic processes in everyday life.&ldquo;Faking It: Cybersecurity Issues in AI&rdquo; consists of seven bite-sized lessons thatexplore what AI is, how it works and the ways it&rsquo;s implemented in society. Eachlesson begins with a brief statement &ldquo;by AI&rdquo; followed by introduction of the topic,real-world examples, a media literacy tip, and a relevant practical activity. Thecurricula will be openly available via partnering organizations, including: The 502Project and The Poynter Institute for Media Studies, with the goal of reachingdiverse audiences from different disciplines.The 502 Project is an initiative funded by the NSA Centers of Academic Excellencethat aims to increase participation in the cybersecurity community. Currently, the502 Project includes over 700 cybersecurity professionals and students &mdash; fromhigh school to career-transitioning adults &mdash; nationwide via custom-developedDiscord server. The 502 Project also hosts freely available curricula on the web viathe Cybersecurity Labs and Resource Knowledge-base (CLARK), reachingcybersecurity educators and general users.The Poynter Institute for Media Studies is a global nonprofit that strengthensdemocracy by improving the relevance, ethical practice and value of journalism. Itssocial-first digital media literacy initiative MediaWise teaches people of all ages andbackgrounds how to responsibly engage with online content in the age ofinformation overload.Both partnering organizations support the availability of open educationalresources for educators and learners alike, and foster communities of peer-to-peerlearning in their respective fields. The project team welcomes the involvement ofother partners who may be interested in publishing and distributing the curricula.</p><br>\n<p>\n Last Modified: 11/01/2024<br>\nModified by: Nathan&nbsp;W&nbsp;Fisk</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nProject Outcomes Reportfor the General Public\n\n\nFaking human intelligence, artificial intelligence (AI) has become increasinglypervasive in everyday life  from chat bots, recommendation engines, andsummaries of search results to assisting with creative tasks, including writing andcreation of media. But as with every technology, AI may be leveraged both for goodand in a way that can cause harm.Faking It: Facilitating Public Awareness of Cybersecurity Issues in AI is a researchproject that aims to increase public awareness of AI technologies and their role increating or preventing cyber-, physical, and social risks to security. AI systems canbe designed to achieve various goals, and therefore need to be explored fromvarious perspectives. Faking It is a collaboration between the fields ofcybersecurity, artificial intelligence, and education.One of the major activities in this project is the development of data collectionmechanism for research study  an image annotation platform where participantsare presented with a series of both real and AI-generated images, and asked toindicate their perceptions. The platform is embedded within a survey whereparticipants in the study can provide consent, annotate images and answerquestions about their background and experiences with AI. The project team plansto carry out data collection and analysis in 2025, with hopes that the project will yetyield significant impacts on the development of the principal disciplines.A product of the project is the development of freely available online curricula thatfocuses on AI and the future of work along with driving social awareness ofalgorithmic processes in everyday life.Faking It: Cybersecurity Issues in AI consists of seven bite-sized lessons thatexplore what AI is, how it works and the ways its implemented in society. Eachlesson begins with a brief statement by AI followed by introduction of the topic,real-world examples, a media literacy tip, and a relevant practical activity. Thecurricula will be openly available via partnering organizations, including: The 502Project and The Poynter Institute for Media Studies, with the goal of reachingdiverse audiences from different disciplines.The 502 Project is an initiative funded by the NSA Centers of Academic Excellencethat aims to increase participation in the cybersecurity community. Currently, the502 Project includes over 700 cybersecurity professionals and students  fromhigh school to career-transitioning adults  nationwide via custom-developedDiscord server. The 502 Project also hosts freely available curricula on the web viathe Cybersecurity Labs and Resource Knowledge-base (CLARK), reachingcybersecurity educators and general users.The Poynter Institute for Media Studies is a global nonprofit that strengthensdemocracy by improving the relevance, ethical practice and value of journalism. Itssocial-first digital media literacy initiative MediaWise teaches people of all ages andbackgrounds how to responsibly engage with online content in the age ofinformation overload.Both partnering organizations support the availability of open educationalresources for educators and learners alike, and foster communities of peer-to-peerlearning in their respective fields. The project team welcomes the involvement ofother partners who may be interested in publishing and distributing the curricula.\t\t\t\t\tLast Modified: 11/01/2024\n\n\t\t\t\t\tSubmitted by: NathanWFisk\n"
 }
}