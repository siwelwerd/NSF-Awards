{
 "awd_id": "2116376",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Doctoral Dissertation Research: Articulatory Dynamics and Stability of Multi-gesture Complexes",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032924770",
 "po_email": "rtheodor@nsf.gov",
 "po_sign_block_name": "Rachel M. Theodore",
 "awd_eff_date": "2021-07-15",
 "awd_exp_date": "2023-12-31",
 "tot_intn_awd_amt": 18962.0,
 "awd_amount": 18962.0,
 "awd_min_amd_letter_date": "2021-07-08",
 "awd_max_amd_letter_date": "2021-07-08",
 "awd_abstract_narration": "This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2).\r\n\r\nSpoken language production involves combined and coordinated articulatory actions of the tongue, lips, nasal port, and larynx; yet the natural variation in speech and the difficulty of \"seeing\" events occurring inside the human vocal tract mean that the elegant choreography of these articulatory events critical to the formation of spoken words remains mysterious. This project is a study of speech production using real-time Magnetic Resonance Imaging (rtMRI)\u2014a technique that can image vocal tract movement during speech. The project's goal is to characterize the dynamics of articulatory actions as they are organized into coordinated complexes such as speech segments (roughly \u2018alphabetic-sized\u2019 units). The investigation of stabilities in coordination will help scientists understand the cognitive representation of the linguistic units that are used to structure and say the words we know. Ultimately such an understanding has implications for language in breakdown (e.g., due to stoke or disease), for language acquisition, for language and dialect diversity, and for technologies that synthesize and recognize human speech.\r\n\r\nThis dissertation undertakes real-time MRI experiments on speech production and concomitant computational modeling to examine how the smallest movement 'atoms' of speech segments are systematically coordinated. The project tests the hypothesis that vocal tract movements composing a segmental unit are tightly coordinated with one another. Therefore, their coordination is predicted to be stable across natural contextual variations in speech such as phrase boundaries and emphasis, unlike other movement sequences spanning across segments, which have been shown to exhibit more plastic coordination. Using data from two under-studied languages, both larynx-oral coordination in glottalic consonants and velum-oral coordination in nasal consonants are dynamically imaged, and vocal tract movements are tracked to analyze articulatory patterning and coordination in space and time. Empirical findings are computationally assessed using a model of dynamical coupling with which degrees of stability can emerge from certain coupling structures. The project seeks to incorporate coordination relations into linguistic cognitive representations and thereby illuminate the dynamic and emergent nature of speech segments in the encoding system of the phonological units that form words.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dani",
   "pi_last_name": "Byrd",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dani Byrd",
   "pi_email_addr": "dbyrd@usc.edu",
   "nsf_id": "000117105",
   "pi_start_date": "2021-07-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Miran",
   "pi_last_name": "Oh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Miran Oh",
   "pi_email_addr": "miranoh@usc.edu",
   "nsf_id": "000845453",
   "pi_start_date": "2021-07-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "900 W 36th St, GFS 301",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900891693",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "837400",
   "pgm_ele_name": "DDRI Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "102Z",
   "pgm_ref_txt": "COVID-Disproportionate Impcts Inst-Indiv"
  },
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "1V21",
   "app_name": "R&RA ARP Act DEFC V",
   "app_symb_id": "040100",
   "fund_code": "010V2122DB",
   "fund_name": "R&RA ARP Act DEFC V",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 18962.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project incorporates real-time Magnetic Resonance Imaging (rtMRI) for human speech production experiments and modeling analyses of stability (and variability) in articulatory timing. The project investigates whether the degree of cohesiveness of articulatory timing can be informative as to, or serve as evidence for, linguistic properties and phonological patterns that we observe in human speech.&nbsp;The thesis undertakes an examination of kinematic timing stability in the production of consonants, such as ejectives and implosives spoken by Hausa native speakers, and of nasals in varying word positions in the speech of Korean native speakers. Of particular note, this vocal tract imaging project examines vertical larynx and velum actions in speech, which have not been widely studied due to a lack of available methodologies for capturing their dynamic movements.</span></p>\n<p><span>The project proposes that speech segment act as &lsquo;molecules&rsquo; whose articulatory components (called &lsquo;gestures&rsquo;) are coordinated so as to have high stability due to a strong intergestural coupling strength. The thesis instantiates this via a coupling architecture or &lsquo;graph&rsquo; among the component actions. Moreover, non-pulmonic consonants, e.g., implosives and ejectives, may exhibit more stable intergestural timing compared to their more common pulmonic counterparts because they may possess critical temporal constraints required to generate their distinct aero-acoustic properties. This project's empirical findings show that non-pulmonic consonants differ from plain consonants in having distinct intergestural timing (i.e., a crucial anti-phase relations between their component oral and vertical larynx gestures) but also that non-pulmonics exhibit less variation across prosodic contexts in their internal oral-to-non-oral timing coordination.&nbsp;</span></p>\n<p><span>Next, nasal consonants (like [n]) in syllable onset and coda positions in Korean display a well-known phonological phenomenon in Korean of de-nasalization specific to the onset position. The thesis uses real-time vocal tract imaging to demonstrate that velum lowering and oral gestures in onset nasals are synchronized in their timing, whereas such gestures in coda nasals are sequential, rendering a shorter period of nasality for onset nasals. This different patterning of relative timing is further accompanied by the novel finding of greater timing variability in syllable onset nasals compared to nasals in the coda position. These results thus reveal articulatory grounding for Korean nasal weakening or denasalization observed only in the onset position.</span></p>\n<p><span>Extending the empirical real-time imaging studies, the thesis proposes a relative phase model analysis to examine whether an intrinsic coupling architecture can generate the observed variations in relative timing stability. In this relative phase model, the oral, velum and vowel gesture&rsquo;s phasing degrees are initially set to replicate the timing relations observed in Korean onset and coda nasals. The results indicate that initially inharmonious coupling structures inevitably create competition among coupling relations impairing the entire structure from reaching a stable state; thus this initial unstable coupling structure results in greater relative phase variability than do harmonious coupling graphs. In other words, a set of gestures that intrinsically have a dis-harmonized, anti-phase relation will yield strong variability in timing, which explains onset nasals&rsquo; observed unstable intergestural timing.</span></p>\n<p><span>In sum, this thesis investigates speech timing and stability within complex segments and models the role of articulatory timing in encoding phonologically distinct linguistic speech articulatory actions. It further extends an account of the modulation of gestural coordination to varying prosodic contexts. The project drives novel research in kinematic speech production and in the theory of Articulatory Phonology by providing first-of-a-kind methods to obtain kinematic information on non-oral articulatory gestures in addition to oral constriction gestures, using rtMRI vocal tract imaging data and object tracking analysis tools. Moreover, the experiments incorporate speech production data from under-resourced and under-documented language to broaden the scope of accessible data sources on human speech variation. The findings from this project have potential to further our knowledge of how basic atomic actions of speech are structurally organized to encode and convey linguistically distinct and meaningful information in human speech production.</span></p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/05/2024<br>\nModified by: Miran&nbsp;Oh</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2116376/2116376_10746326_1709685605302_Figure5--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2116376/2116376_10746326_1709685605302_Figure5--rgov-800width.jpg\" title=\"Centroid tracking on vertical larynx and velum actions\"><img src=\"/por/images/Reports/POR/2024/2116376/2116376_10746326_1709685605302_Figure5--rgov-66x44.jpg\" alt=\"Centroid tracking on vertical larynx and velum actions\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Centroid tracking output in the production of a VCV sequence /&#593;&#608;&#593;/, showing larynx lowering and velum raising (1st Vocal Tract Region [VTR]: larynx, 2nd VTR: velum)</div>\n<div class=\"imageCredit\">Miran Oh</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Miran&nbsp;Oh\n<div class=\"imageTitle\">Centroid tracking on vertical larynx and velum actions</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project incorporates real-time Magnetic Resonance Imaging (rtMRI) for human speech production experiments and modeling analyses of stability (and variability) in articulatory timing. The project investigates whether the degree of cohesiveness of articulatory timing can be informative as to, or serve as evidence for, linguistic properties and phonological patterns that we observe in human speech.The thesis undertakes an examination of kinematic timing stability in the production of consonants, such as ejectives and implosives spoken by Hausa native speakers, and of nasals in varying word positions in the speech of Korean native speakers. Of particular note, this vocal tract imaging project examines vertical larynx and velum actions in speech, which have not been widely studied due to a lack of available methodologies for capturing their dynamic movements.\n\n\nThe project proposes that speech segment act as molecules whose articulatory components (called gestures) are coordinated so as to have high stability due to a strong intergestural coupling strength. The thesis instantiates this via a coupling architecture or graph among the component actions. Moreover, non-pulmonic consonants, e.g., implosives and ejectives, may exhibit more stable intergestural timing compared to their more common pulmonic counterparts because they may possess critical temporal constraints required to generate their distinct aero-acoustic properties. This project's empirical findings show that non-pulmonic consonants differ from plain consonants in having distinct intergestural timing (i.e., a crucial anti-phase relations between their component oral and vertical larynx gestures) but also that non-pulmonics exhibit less variation across prosodic contexts in their internal oral-to-non-oral timing coordination.\n\n\nNext, nasal consonants (like [n]) in syllable onset and coda positions in Korean display a well-known phonological phenomenon in Korean of de-nasalization specific to the onset position. The thesis uses real-time vocal tract imaging to demonstrate that velum lowering and oral gestures in onset nasals are synchronized in their timing, whereas such gestures in coda nasals are sequential, rendering a shorter period of nasality for onset nasals. This different patterning of relative timing is further accompanied by the novel finding of greater timing variability in syllable onset nasals compared to nasals in the coda position. These results thus reveal articulatory grounding for Korean nasal weakening or denasalization observed only in the onset position.\n\n\nExtending the empirical real-time imaging studies, the thesis proposes a relative phase model analysis to examine whether an intrinsic coupling architecture can generate the observed variations in relative timing stability. In this relative phase model, the oral, velum and vowel gestures phasing degrees are initially set to replicate the timing relations observed in Korean onset and coda nasals. The results indicate that initially inharmonious coupling structures inevitably create competition among coupling relations impairing the entire structure from reaching a stable state; thus this initial unstable coupling structure results in greater relative phase variability than do harmonious coupling graphs. In other words, a set of gestures that intrinsically have a dis-harmonized, anti-phase relation will yield strong variability in timing, which explains onset nasals observed unstable intergestural timing.\n\n\nIn sum, this thesis investigates speech timing and stability within complex segments and models the role of articulatory timing in encoding phonologically distinct linguistic speech articulatory actions. It further extends an account of the modulation of gestural coordination to varying prosodic contexts. The project drives novel research in kinematic speech production and in the theory of Articulatory Phonology by providing first-of-a-kind methods to obtain kinematic information on non-oral articulatory gestures in addition to oral constriction gestures, using rtMRI vocal tract imaging data and object tracking analysis tools. Moreover, the experiments incorporate speech production data from under-resourced and under-documented language to broaden the scope of accessible data sources on human speech variation. The findings from this project have potential to further our knowledge of how basic atomic actions of speech are structurally organized to encode and convey linguistically distinct and meaningful information in human speech production.\n\n\n\t\t\t\t\tLast Modified: 03/05/2024\n\n\t\t\t\t\tSubmitted by: MiranOh\n"
 }
}