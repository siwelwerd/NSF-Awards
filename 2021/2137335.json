{
 "awd_id": "2137335",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Towards Fair Regression under Sample Selection Bias",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2021-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2021-08-18",
 "awd_max_amd_letter_date": "2021-08-18",
 "awd_abstract_narration": "Decision making models are ubiquitous in applications like employment, credit, and insurance. Increasingly, there are worries of inaccurate decisions or even discrimination from predictive decision models that have been trained on a collection of data. Fair machine learning has been an increasingly important topic. Fair machine learning models aim to learn a function for a target variable while ensuring the predicted value is fair based on a given fairness criterion.  Much of the existing work focuses on fair classification. This project researches fair regression where the decision such as loan amount is continuous and focuses on the scenario where the existing data for building the model have different distributions from the model's future data.  In particular, this project deals with the sample selection bias where the values for the dependent variable from the training dataset are missing.  The project aims to develop a unified framework and practical solutions for achieving rigorous fairness and high accuracy of the built regression model via bias correction and optimization techniques.  \r\n\r\nThe technical aims of this project are divided into three thrusts. The first thrust develops the unified framework for fair regression under sample selection bias. The framework adopts the classic Heckman model to correct bias and enforces multiple advanced fairness notions via constrained optimization. The second thrust applies the Lagrange duality theory and develops reduction approaches to solve constrained optimization. Theoretical studies of achieving strong duality for fairness notions and research of deriving approximation techniques for efficient optimization will be conducted in this thrust. The third thrust conducts empirical evaluation of the developed framework and algorithms in terms of prediction accuracy and fairness with benchmark datasets and real applications, implements and integrates the algorithms into open source libraries for fair machine learning.  The research findings expect to advance theoretical understanding of fair regression, improve its applicability for handling sample selection bias, and help transition of fair regression algorithms to use in real systems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xintao",
   "pi_last_name": "Wu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xintao Wu",
   "pi_email_addr": "xintaowu@uark.edu",
   "nsf_id": "000244983",
   "pi_start_date": "2021-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Arkansas",
  "inst_street_address": "1125 W MAPLE ST STE 316",
  "inst_street_address_2": "",
  "inst_city_name": "FAYETTEVILLE",
  "inst_state_code": "AR",
  "inst_state_name": "Arkansas",
  "inst_phone_num": "4795753845",
  "inst_zip_code": "727013124",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "AR03",
  "org_lgl_bus_name": "UNIVERSITY OF ARKANSAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "MECEHTM8DB17"
 },
 "perf_inst": {
  "perf_inst_name": "University of Arkansas",
  "perf_str_addr": "516 J.B. Hunt Building",
  "perf_city_name": "Fayetteville",
  "perf_st_code": "AR",
  "perf_st_name": "Arkansas",
  "perf_zip_code": "727011201",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "AR03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Decision making models are ubiquitous in applications like employment, credit, and insurance. There are increasing worries of inaccurate decisions or discrimination from predictive decision models that are trained over a collection of data records. Fair and robust machine learning has been an increasingly important topic. This project researches fair regression where the decision such as loan amount is continuous and focuses on the scenario where the existing data for building the model have different distributions from the future data using the model.&nbsp; In particular, this project deals with the sample selection bias when the dependent variable values of a set of samples from the training dataset are missing.&nbsp;&nbsp;</p>\n<p>The major goals of the project are 1) developing a unifying framework for fair regression under sample selection bias based on Heckman model when dependent variable values of a set of samples are missing; 2) conducting theoretical analysis of optimization for fair regression with different fairness constraints; and 3) building a prototype and conducting empirical evaluations with benchmark datasets.</p>\n<p>We conducted research on fair and robust machine learning models and developed 1) a robust and fair regression model under sample selection bias based on the classic Heckman model; 2) an effective approach of dynamically selecting prediction features in the Heckman model; 3) a robust logistic regression model under sample selection bias based on the Green model; and 4) a robust federated learning under sample selection heterogeneity. We conducted both theoretical and empirical studies and demonstrated the effectiveness and efficiency of our developed models.&nbsp; &nbsp;</p>\n<p>Our research findings pushed the state-of-the-art in the area of fairness aware machine learning and advanced theoretical understanding of fundamental issues related to fair regression and contribute to the limited base of knowledge in the area of using statistical models, e.g., Heckman and Green models, for fair and robust learning. The techniques we developed can also contribute to other research fields such as economics and health when sample selection bias is present.&nbsp; We outreached to the broader community of computer science, data science, and social science, wrote survey/position papers, and presented work at major conferences, workshops, and campus showcase on data analytics. This project has also contributed to training graduate students and postdocs in computer science at University of Arkansas.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/28/2023<br>\nModified by: Xintao&nbsp;Wu</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/2137335/2137335_10763687_1703797913652_FL_MNAR_problem_setup_6--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/2137335/2137335_10763687_1703797913652_FL_MNAR_problem_setup_6--rgov-800width.png\" title=\"Illustration of FL-MNAR\"><img src=\"/por/images/Reports/POR/2023/2137335/2137335_10763687_1703797913652_FL_MNAR_problem_setup_6--rgov-66x44.png\" alt=\"Illustration of FL-MNAR\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Illustration of federated learning under missing not at random.</div>\n<div class=\"imageCredit\">Huy Mai and Xintao Wu</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xintao&nbsp;Wu\n<div class=\"imageTitle\">Illustration of FL-MNAR</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/2137335/2137335_10763687_1703798213803_illustrativefigure2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/2137335/2137335_10763687_1703798213803_illustrativefigure2--rgov-800width.png\" title=\"Illustration of the effect of MNAR sample se- lection bias on a classifier\ufffds predictions.\"><img src=\"/por/images/Reports/POR/2023/2137335/2137335_10763687_1703798213803_illustrativefigure2--rgov-66x44.png\" alt=\"Illustration of the effect of MNAR sample se- lection bias on a classifier\ufffds predictions.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Illustration of the effect of MNAR sample selection bias on a classifier\ufffds predictions. Solid (dashed) line represents the decision boundary of the classifier trained on the biased (unbiased and fully observed) set.</div>\n<div class=\"imageCredit\">Huy Mai and Xintao Wu</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Xintao&nbsp;Wu\n<div class=\"imageTitle\">Illustration of the effect of MNAR sample se- lection bias on a classifier\ufffds predictions.</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nDecision making models are ubiquitous in applications like employment, credit, and insurance. There are increasing worries of inaccurate decisions or discrimination from predictive decision models that are trained over a collection of data records. Fair and robust machine learning has been an increasingly important topic. This project researches fair regression where the decision such as loan amount is continuous and focuses on the scenario where the existing data for building the model have different distributions from the future data using the model. In particular, this project deals with the sample selection bias when the dependent variable values of a set of samples from the training dataset are missing.\n\n\nThe major goals of the project are 1) developing a unifying framework for fair regression under sample selection bias based on Heckman model when dependent variable values of a set of samples are missing; 2) conducting theoretical analysis of optimization for fair regression with different fairness constraints; and 3) building a prototype and conducting empirical evaluations with benchmark datasets.\n\n\nWe conducted research on fair and robust machine learning models and developed 1) a robust and fair regression model under sample selection bias based on the classic Heckman model; 2) an effective approach of dynamically selecting prediction features in the Heckman model; 3) a robust logistic regression model under sample selection bias based on the Green model; and 4) a robust federated learning under sample selection heterogeneity. We conducted both theoretical and empirical studies and demonstrated the effectiveness and efficiency of our developed models. \n\n\nOur research findings pushed the state-of-the-art in the area of fairness aware machine learning and advanced theoretical understanding of fundamental issues related to fair regression and contribute to the limited base of knowledge in the area of using statistical models, e.g., Heckman and Green models, for fair and robust learning. The techniques we developed can also contribute to other research fields such as economics and health when sample selection bias is present. We outreached to the broader community of computer science, data science, and social science, wrote survey/position papers, and presented work at major conferences, workshops, and campus showcase on data analytics. This project has also contributed to training graduate students and postdocs in computer science at University of Arkansas.\n\n\n\t\t\t\t\tLast Modified: 12/28/2023\n\n\t\t\t\t\tSubmitted by: XintaoWu\n"
 }
}