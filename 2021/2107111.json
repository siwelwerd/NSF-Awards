{
 "awd_id": "2107111",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "HCC: Medium: Cultural Differences in Driving Interaction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 800000.0,
 "awd_amount": 816000.0,
 "awd_min_amd_letter_date": "2021-09-08",
 "awd_max_amd_letter_date": "2022-06-06",
 "awd_abstract_narration": "This research will work to capture and understand the ways that drivers communicate and coordinate with others on the road, and to assess how these driving interactions differ across cultures. Drivers communicate and negotiate with other drivers and road users through the movement of their cars, as well as through honking, verbal communication, body language, and eye-gaze. By using a multi-person virtual-reality driving simulator to conduct driving interaction studies in different countries, the research team will gather data to understand how drivers interact with one another in different driving situations. The research is expected to contribute to improving driving safety and reducing on-road accidents, particularly involving autonomous vehicles, by helping to identify mismatches in perception, understanding, and action among road users. It is expected to benefit society by considering different cultures in the development of advanced technologies to reduce risks associated with poor design, cultural bias, and unnecessary on-road testing.\r\n\r\nThe scientific goal of this research is to develop new models of driving interaction that characterize the implicit and explicit communication and negotiation patterns that occur between road users. The research team will conduct controlled experiments using a multi-person virtual-reality driving simulator--in the US, in Israel, and in China--to study how drivers from different locations and cultures interact in different on-road driving situations.  The instrumented virtual reality driving simulation environment will enable capture, replay and both qualitative and quantitative analysis of vehicle movement and signaling, as well as driver gaze, head orientation and body movement. The experimental design will also enable contextualized deployment of surveys to capture insight into each driver\u2019s situation awareness. Data from the studies and subsequent analysis will be used to train models to elucidate parametric similarities and differences in driving interactions. By capturing how participants communicate with other drivers to coordinate joint action, implicitly through the movements of their virtual car or bodily movement, as well as explicitly through verbal or gestural exchange, this project is expected to develop new understandings of how driving interactions are likely to unfold differently across diverse situations and cultures.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Wendy",
   "pi_last_name": "Ju",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wendy Ju",
   "pi_email_addr": "wendyju@cornell.edu",
   "nsf_id": "000746785",
   "pi_start_date": "2021-09-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Qian",
   "pi_last_name": "Yang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Qian Yang",
   "pi_email_addr": "qy242@cornell.edu",
   "nsf_id": "000842317",
   "pi_start_date": "2021-09-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "2 West Loop Rd",
  "perf_city_name": "New York City",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100441501",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NY12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 800000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-1b901210-7fff-e4ed-c315-ce6f758b2d4f\">\r\n<p>This research project created new models of how drivers implicitly communicate and coordinate with others on the road, and assessed how these driving interactions differ across cultures. To this end, we invented a virtual driving simulation platform to elicit communicative driving behaviors between participants in different simulated driving contexts. By understanding how driving interactions differ across cultures and contexts, we better understand the role that local driving norms play in automotive safety.</p>\r\n<p>One of the key outcomes of this project was the concept of Social Situation Awareness in driving. This highlights the importance of perception, comprehension, and modeling of the different interactants in driving scenarios to safe and efficient interactions. As part of this contribution, we developed a Social Situation Awareness Questionnaire, and models to highlight what aspects of the social driving situation influenced drivers from different cultures. We also modeled the trajectory of the driving in different driving cultures. This approach enabled us to generate critical data about typical driving trajectories, which vary by driving culture, and about the role that implicit signalling, for example through the movement of the car, plays in automotive interaction.</p>\r\n<p>This work advances our understanding of situation awareness to highlight the role that social situation awareness--the perception, understanding and actions of other drivers on the road--play in determining the behaviors of drivers themselves. The techniques from this research provide new ways to gain empirical data about the perception, understanding and action of people in different cultures under comparable contexts; the data from these studies has been demonstrated to be able to create models of these differences in perception and action. Combined, this impact addresses a key roadblock in our path to developing safe interactions with autonomous vehicles on the shared road.</p>\r\n<p dir=\"ltr\">&nbsp;</p>\r\n</span></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/02/2025<br>\nModified by: Wendy&nbsp;Ju</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\r\n\n\nThis research project created new models of how drivers implicitly communicate and coordinate with others on the road, and assessed how these driving interactions differ across cultures. To this end, we invented a virtual driving simulation platform to elicit communicative driving behaviors between participants in different simulated driving contexts. By understanding how driving interactions differ across cultures and contexts, we better understand the role that local driving norms play in automotive safety.\r\n\n\nOne of the key outcomes of this project was the concept of Social Situation Awareness in driving. This highlights the importance of perception, comprehension, and modeling of the different interactants in driving scenarios to safe and efficient interactions. As part of this contribution, we developed a Social Situation Awareness Questionnaire, and models to highlight what aspects of the social driving situation influenced drivers from different cultures. We also modeled the trajectory of the driving in different driving cultures. This approach enabled us to generate critical data about typical driving trajectories, which vary by driving culture, and about the role that implicit signalling, for example through the movement of the car, plays in automotive interaction.\r\n\n\nThis work advances our understanding of situation awareness to highlight the role that social situation awareness--the perception, understanding and actions of other drivers on the road--play in determining the behaviors of drivers themselves. The techniques from this research provide new ways to gain empirical data about the perception, understanding and action of people in different cultures under comparable contexts; the data from these studies has been demonstrated to be able to create models of these differences in perception and action. Combined, this impact addresses a key roadblock in our path to developing safe interactions with autonomous vehicles on the shared road.\r\n\n\n\r\n\r\n\n\n\t\t\t\t\tLast Modified: 02/02/2025\n\n\t\t\t\t\tSubmitted by: WendyJu\n"
 }
}