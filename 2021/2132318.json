{
 "awd_id": "2132318",
 "agcy_id": "NSF",
 "tran_type": "CoopAgrmnt",
 "awd_istr_txt": "Cooperative Agreement",
 "awd_titl_txt": "A1: Knowledge Network Development Infrastructure with Application to COVID-19 Science and Economics",
 "cfda_num": "47.084",
 "org_code": "15020000",
 "po_phone": "7032922251",
 "po_email": "jgeorge@nsf.gov",
 "po_sign_block_name": "Jemin George",
 "awd_eff_date": "2021-05-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 4994542.0,
 "awd_amount": 4960313.0,
 "awd_min_amd_letter_date": "2021-06-30",
 "awd_max_amd_letter_date": "2021-09-14",
 "awd_abstract_narration": "The NSF Convergence Accelerator supports use-inspired, team-based, multidisciplinary efforts that address challenges of national importance and will produce deliverables of value to society in the near future.\r\n\r\nThe goal of this project is to build infrastructure for efficient construction of knowledge networks and applications, as well as to demonstrate the system with concrete knowledge networks that describe COVID-19 science and economics. In the short term, this work will lead to high accuracy data resources that will be useful to scientists and policy makers in addressing the virus and its economic impact. Sample goals include enabling a medical researcher to quickly identify relevant candidate drugs, and a policy maker to quickly evaluate the likely impacts of a novel law. The project will create programming tools that will make knowledge networks and their applications far less expensive to build. This infrastructure of programming tools will facilitate the creation of a large and novel set of informational tools and will also significantly expand the set of people who can participate in creating knowledge network resources. Because knowledge networks combine unique data analysis qualities with the topical breadth of the entire World Wide Web, the potential growth of knowledge tools is very large and potentially transformative.  \r\n\r\nThis project includes partnerships with a strong set of non-academic and academic partners. This convergence research team will integrate their multidisciplinary expertise in data management, artificial intelligence, programming languages, biomedical topics relevant to COVID-19, and economics, with the other domains represented in the projects funded in the Track A Phase II cohort. \r\n\r\nCreating this knowledge programming infrastructure and concrete knowledge networks will require solving several technical challenges. The first is an intelligent \u201cknowledge compilation layer\u201d that makes useful but rapidly-changing knowledge networks appear to be stable enough for programmers to use them when writing reliable code. The second is the creation of a mechanism for transparently sharing knowledge resources and debugging information within and across organizations. The third is a method for collecting knowledge provenance metadata \u2014 details about how every individual data element was created \u2014 via automatic instrumentation of user software. A last challenge is the creation of knowledge-from-document systems that can produce high accuracy knowledge networks with very little explicit human oversight.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "ITE",
 "org_div_long_name": "Innovation and Technology Ecosystems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Cafarella",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Cafarella",
   "pi_email_addr": "michjc@umich.edu",
   "nsf_id": "000544946",
   "pi_start_date": "2021-06-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "095Y00",
   "pgm_ele_name": "CA-HDR: Convergence Accelerato"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 2958919.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 4002788.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">Open Knowledge Networks (OKNs) are an exciting method for representing data that has been growing rapidly. For example, the Wikidata knowledge network grew from roughly 50M facts in 2014 to about 1.2B facts in 2020. Despite this massive growth, OKNs have been difficult to build, and they power few apps beyond structured web search and voice agents. We believe knowledge networks are having far less impact than they should due to poor developer infrastructure.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">OKNs also have a synergistic relationship with Artificial Intelligence. They can help AI systems generate answers that are more accurate and complete. We can also use AI systems to build better OKNs.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">This project aimed to research and build novel software infrastructure that makes it dramatically easier to build and use OKNs. As part of this work, we also built several OKNs, notably the CORD-19 OKN for describing Covid research.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">Here are a few of the major accomplishments of this work:</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">CORD-19: CORD-19 was an OKN describing academic papers about COVID-19 and related coronavirus research. It was curated and maintained by a collaborator on this project, the Semantic Scholar team at the Allen Institute for AI. The final version of CORD-19 was released on June 2, 2022. Since we launched the dataset on March 13, 2020, we have released an updated version of the dataset almost every week. Starting from around 40K articles in its first version, the dataset grew to index over 1M papers, and includes full text content for nearly 370K papers.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">The Knowledge Network Programming System, or KNPS: We built a programming system for collecting and sharing provenance information. Provenance information describes how a dataset or answer is generated: what were the inputs, processing steps, and human operations that led to the result?<span>&nbsp; </span>KNPS includes a system for processing logs and watching desktops to collect provenance information. This information is then centralized, cleaned, and shared. This system is able to collect partial log information and infer missing components. The promise of this system is that many data quality problems can be answered only by examining the provenance data, so anything that collects provenance information can be extremely worthwhile. This system is no longer under development, but many of the ideas are even more useful for AI data systems. We are exploring whether aspects of KNPS can be adapted to current AI workflows.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">Layout-Aware Language Models:<span>&nbsp; </span>Automatically constructing knowledge networks for science requires extracting structured content from PDF documents. Recent methods have shown that using both textual and visual features can be helpful for this task, but this typically requires expensive pretraining on layout-rich documents, making it prohibitive to use the techniques as new models are introduced. We introduced VILA, a new layout-aware modeling approach that uses simple indicators of layout (text lines or visual blocks) within existing text-based pretrained models, improving performance over layout-unaware baselines without the need for expensive pretraining (reducing training cost by 95% over competing approaches). Further, to help build training and evaluation data sets for visual PDF-processing tasks, we introduced the PAWLS annotation platform that makes PDF annotation easy. This work helps scientific AI understand past research papers more accurately, making AI-enabled scientific discovery more affordable and practical.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">We also pursued projects in causal reasoning, which help users understand *why* a phenomenon in the data took place; and in efficient AI inference methods.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p class=\"p1\">Overall, the intellectual merit of this project involved progress on a number of fronts: new discovery of information extraction methods, AI inference methods, and software methods for provenance collection.<span>&nbsp;</span></p>\r\n<p class=\"p1\"><br />The broader impact of this project involved shipping a number of practical pieces of software around provenance collection and natural language processing. Most notably, it produced the CORD-19 dataset.</p>\r\n<p class=\"p2\">&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 04/23/2025<br>\nModified by: Michael&nbsp;Cafarella</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nOpen Knowledge Networks (OKNs) are an exciting method for representing data that has been growing rapidly. For example, the Wikidata knowledge network grew from roughly 50M facts in 2014 to about 1.2B facts in 2020. Despite this massive growth, OKNs have been difficult to build, and they power few apps beyond structured web search and voice agents. We believe knowledge networks are having far less impact than they should due to poor developer infrastructure.\r\n\n\n\r\n\n\nOKNs also have a synergistic relationship with Artificial Intelligence. They can help AI systems generate answers that are more accurate and complete. We can also use AI systems to build better OKNs.\r\n\n\n\r\n\n\nThis project aimed to research and build novel software infrastructure that makes it dramatically easier to build and use OKNs. As part of this work, we also built several OKNs, notably the CORD-19 OKN for describing Covid research.\r\n\n\n\r\n\n\nHere are a few of the major accomplishments of this work:\r\n\n\n\r\n\n\nCORD-19: CORD-19 was an OKN describing academic papers about COVID-19 and related coronavirus research. It was curated and maintained by a collaborator on this project, the Semantic Scholar team at the Allen Institute for AI. The final version of CORD-19 was released on June 2, 2022. Since we launched the dataset on March 13, 2020, we have released an updated version of the dataset almost every week. Starting from around 40K articles in its first version, the dataset grew to index over 1M papers, and includes full text content for nearly 370K papers.\r\n\n\n\r\n\n\nThe Knowledge Network Programming System, or KNPS: We built a programming system for collecting and sharing provenance information. Provenance information describes how a dataset or answer is generated: what were the inputs, processing steps, and human operations that led to the result? KNPS includes a system for processing logs and watching desktops to collect provenance information. This information is then centralized, cleaned, and shared. This system is able to collect partial log information and infer missing components. The promise of this system is that many data quality problems can be answered only by examining the provenance data, so anything that collects provenance information can be extremely worthwhile. This system is no longer under development, but many of the ideas are even more useful for AI data systems. We are exploring whether aspects of KNPS can be adapted to current AI workflows.\r\n\n\n\r\n\n\nLayout-Aware Language Models: Automatically constructing knowledge networks for science requires extracting structured content from PDF documents. Recent methods have shown that using both textual and visual features can be helpful for this task, but this typically requires expensive pretraining on layout-rich documents, making it prohibitive to use the techniques as new models are introduced. We introduced VILA, a new layout-aware modeling approach that uses simple indicators of layout (text lines or visual blocks) within existing text-based pretrained models, improving performance over layout-unaware baselines without the need for expensive pretraining (reducing training cost by 95% over competing approaches). Further, to help build training and evaluation data sets for visual PDF-processing tasks, we introduced the PAWLS annotation platform that makes PDF annotation easy. This work helps scientific AI understand past research papers more accurately, making AI-enabled scientific discovery more affordable and practical.\r\n\n\n\r\n\n\nWe also pursued projects in causal reasoning, which help users understand *why* a phenomenon in the data took place; and in efficient AI inference methods.\r\n\n\n\r\n\n\nOverall, the intellectual merit of this project involved progress on a number of fronts: new discovery of information extraction methods, AI inference methods, and software methods for provenance collection.\r\n\n\n\nThe broader impact of this project involved shipping a number of practical pieces of software around provenance collection and natural language processing. Most notably, it produced the CORD-19 dataset.\r\n\n\n\r\n\n\n\t\t\t\t\tLast Modified: 04/23/2025\n\n\t\t\t\t\tSubmitted by: MichaelCafarella\n"
 }
}