{
 "awd_id": "2053172",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CDS&E-MSS: Optimal Recovery in the Age of Data Science",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2021-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 149783.0,
 "awd_amount": 149783.0,
 "awd_min_amd_letter_date": "2021-05-18",
 "awd_max_amd_letter_date": "2021-05-18",
 "awd_abstract_narration": "Machine learning techniques have proved to be successful, leading society to a modern era enhanced by data science. These techniques usually rely on statistical assumptions and provide solutions that are guaranteed to work approximately well most of the time. However, these assumptions and limitations are insufficient to meet the demands of areas critically important to the Unites States, such as defense, medicine, and transportation. In these applications a failure, however infrequent, is not an option. This project focuses on data science algorithms with certified guarantees valid in a worst-case setting. Its theoretical outcomes will have implications in any field of science involving data not favorably captured by random models. Students will be involved in research and receive training in next generation data science tools. \r\n\r\nThe project will develop methods within a subfield of approximation theory called Optimal Recovery with focus on improving their computational practicality rather than on abstract theory.  In particular, purely analytic approaches will be replaced by a more computation-embracing perspective exploiting modern optimization theory. Another breakaway from traditional theory consists in modeling real-world functions not by their smoothness properties but by their approximability properties which is relevant for numerical approaches, e.g., those based on neural networks. The project has several facets: a theoretical facet expanding the scope of optimal recovery to ensure the properties of volume, veracity, velocity, and variety which are desirable in modern data science; a computational facet that consists in implementing recovery methods as efficient algorithms made publicly available; a practical facet that consists in transferring the theoretical findings in applied fields such as in system identification; and an educational facet that consists in integrating novel concepts into the culture of the next scientific generation.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Simon",
   "pi_last_name": "Foucart",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Simon Foucart",
   "pi_email_addr": "foucart@tamu.edu",
   "nsf_id": "000662067",
   "pi_start_date": "2021-05-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M University",
  "inst_street_address": "400 HARVEY MITCHELL PKY S STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778454375",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A & M UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JF6XLNB4CDJ5"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M University",
  "perf_str_addr": "3368 TAMU",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433368",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 149783.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The field of Optimal Recovery can be viewed as an analytical learning theory which is trustworthy by design, since it targets certified guarantees valid in a worst-case setting. Its framework is therefore fitted to critical areas such as defense, medicine, and transportation. The objective of this project was to modernize the mathematics of Optimal Recovery by making the field more responsive to novel data-focused questions and by integrating computational solutions into the theory. This objective was achieved on several fronts, three of them to be highlighted below.&nbsp;</p>\n<p><br />In a first scenario, where random errors corrupt the observed data, it was shown that linear maps are near-optimal for the estimation of linear functionals of objects belonging to fairly common model sets, so long as the randomness is log-concave. In a second scenario, still involving corrupted data but this time nonrandom ones, it was established that, in the usual confines of Hilbert spaces, linear maps are genuinely optimal for the recovery of the whole object. Furthermore, optimal recovery maps were found to come from regularization. Importantly, the parameter of the regularization can be selected in a principled way by solving a semidefinite optimization program. In a third scenario, the observed data are exact but more involved model sets are introduced. For each of them, again leveraging modern optimization techniques, optimal recovery maps (linear, to boot) were provided through algorithmic constructions.</p>\n<p><br />These and other outcomes were disseminated as traditional journal publications which are also publicly available on the arXiv repository. Reproducible files, when available, were shared on the Principal Investigator's GitHub repository dedicated to Computational Optimal Recovery. In addition, the results were presented in multiple conferences, workshops, and seminars. In fine, they should have implications outside of mathematics in any field of science where worst-case guarantees are sought. The ones touched upon during the project were Atmospheric Science (computation of average temperatures), Computational Science (multi-fidelity methods), and Engineering (system identification and graph signal processing).</p>\n<p><br />In terms of broader impact, the project contributed to the training of mathematicians in computational and data-related aspects, at the Principal Investigator's institution and beyond. Indeed, the Principal Investigator designed a graduate course on Data Science (where Optimal Recovery was given a proper place) and this course was the seed of a monograph now published by Cambridge University Press that can be used as a textbook in mathematics departments. More tangibly, the project supported a doctoral student whose dissertation was on the very topic of Optimal Recovery.</p><br>\n<p>\n Last Modified: 07/27/2024<br>\nModified by: Simon&nbsp;Foucart</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe field of Optimal Recovery can be viewed as an analytical learning theory which is trustworthy by design, since it targets certified guarantees valid in a worst-case setting. Its framework is therefore fitted to critical areas such as defense, medicine, and transportation. The objective of this project was to modernize the mathematics of Optimal Recovery by making the field more responsive to novel data-focused questions and by integrating computational solutions into the theory. This objective was achieved on several fronts, three of them to be highlighted below.\n\n\n\nIn a first scenario, where random errors corrupt the observed data, it was shown that linear maps are near-optimal for the estimation of linear functionals of objects belonging to fairly common model sets, so long as the randomness is log-concave. In a second scenario, still involving corrupted data but this time nonrandom ones, it was established that, in the usual confines of Hilbert spaces, linear maps are genuinely optimal for the recovery of the whole object. Furthermore, optimal recovery maps were found to come from regularization. Importantly, the parameter of the regularization can be selected in a principled way by solving a semidefinite optimization program. In a third scenario, the observed data are exact but more involved model sets are introduced. For each of them, again leveraging modern optimization techniques, optimal recovery maps (linear, to boot) were provided through algorithmic constructions.\n\n\n\nThese and other outcomes were disseminated as traditional journal publications which are also publicly available on the arXiv repository. Reproducible files, when available, were shared on the Principal Investigator's GitHub repository dedicated to Computational Optimal Recovery. In addition, the results were presented in multiple conferences, workshops, and seminars. In fine, they should have implications outside of mathematics in any field of science where worst-case guarantees are sought. The ones touched upon during the project were Atmospheric Science (computation of average temperatures), Computational Science (multi-fidelity methods), and Engineering (system identification and graph signal processing).\n\n\n\nIn terms of broader impact, the project contributed to the training of mathematicians in computational and data-related aspects, at the Principal Investigator's institution and beyond. Indeed, the Principal Investigator designed a graduate course on Data Science (where Optimal Recovery was given a proper place) and this course was the seed of a monograph now published by Cambridge University Press that can be used as a textbook in mathematics departments. More tangibly, the project supported a doctoral student whose dissertation was on the very topic of Optimal Recovery.\t\t\t\t\tLast Modified: 07/27/2024\n\n\t\t\t\t\tSubmitted by: SimonFoucart\n"
 }
}