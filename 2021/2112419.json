{
 "awd_id": "2112419",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  High-Resolution Image Segmentation for Natural Resource Management",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922936",
 "po_email": "emirowsk@nsf.gov",
 "po_sign_block_name": "Ela Mirowski",
 "awd_eff_date": "2021-07-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 256000.0,
 "awd_amount": 256000.0,
 "awd_min_amd_letter_date": "2021-06-16",
 "awd_max_amd_letter_date": "2021-06-16",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to produce currently unavailable high-resolution vegetation maps and analyses that enable stakeholders (i.e., government agencies, academic researchers, land managers, non-governmental organizations, and private companies) to rapidly assess the health of ecosystems that are threatened by human development and environmental change. Producing this information will result in better management of natural lands and their associated services and goods, globally valued at $125 trillion, such as buffering current and future infrastructure from natural disasters (i.e., managing wetlands that dampen storm surge) and improving human health and well being outcomes (i.e., disease prevention and livelihood security, respectively). Compared to traditional ground surveying methods, this project will revolutionize the ecosystem health evaluation and management process by reducing work hours by approximately 50-90% and project costs by approximately 40%-70%. \r\n\r\nThis SBIR Phase I project will demonstrate the feasibility to expand the accessibility and scalability of machine learning image segmentation to the fields of natural resource management, environmental conservation, and ecological research. The technical innovation of this project is a replicable machine learning model for vegetation analysis and ecosystem assessment that will expedite the ability to process and classify aerial imagery into individual species layers that can be used to assess vegetation composition and dynamic changes in species populations most influenced by human activity and climate change on a global scale. While there are examples of employing machine learning image segmentation in these fields, they are specific to regions or species and are incapable of scaling across diverse ecosystems and image resolution levels. The goal of the project is to create a machine learning model that can quickly and accurately delineate vegetation types from aerial imagery across diverse sets of data. This goal will be achieved following a development strategy of model exploration, data collection/annotation, model refinement, testing and evaluation, and model deployment.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ross",
   "pi_last_name": "Davison",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Ross H Davison",
   "pi_email_addr": "rhdaviso@gmail.com",
   "nsf_id": "000841136",
   "pi_start_date": "2021-06-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "COMON SOLUTIONS LLC",
  "inst_street_address": "519 CONGRESS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PACIFIC GROVE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507935087",
  "inst_zip_code": "939504111",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "CA19",
  "org_lgl_bus_name": "COMON SOLUTIONS LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "NKKGN3CKTNM4"
 },
 "perf_inst": {
  "perf_inst_name": "COMON SOLUTIONS LLC",
  "perf_str_addr": "1191 BRUCKNER CIR",
  "perf_city_name": "Mountain View",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "940404562",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5187",
   "pgm_ref_txt": "ENVIRONMENT"
  },
  {
   "pgm_ref_code": "8037",
   "pgm_ref_txt": "Advanced Manufacturing"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 256000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong id=\"docs-internal-guid-0398fb24-7fff-b82e-b341-0f62d185f1c4\" style=\"font-weight: normal;\"> </strong></p>\n<p><strong id=\"docs-internal-guid-0398fb24-7fff-b82e-b341-0f62d185f1c4\" style=\"font-weight: normal;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Our goal was to generate accurate high resolution land cover maps, with specific granularity of species-level identification. To accomplish that, we developed a machine learning pipeline that segments aerial (drone) based imagery, focusing on the delineation of species-level vegetation types. The final outputs are geospatial maps that can be used to understand the vegetation composition and diversity of an ecosystem, as well as temporal trends.&nbsp;</span></strong><strong id=\"docs-internal-guid-0398fb24-7fff-b82e-b341-0f62d185f1c4\" style=\"font-weight: normal;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span></strong></p>\n<p><strong id=\"docs-internal-guid-0398fb24-7fff-b82e-b341-0f62d185f1c4\" style=\"font-weight: normal;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The model was tested and iterated on three sites, each representing a different ecosystem with unique challenges (i.e. river watershed, chaparral, and high density native showcase zone). During Phase 1, we defined the parameters for input requirements (i.e., minimum / ideal resolution), created image pre-processing scripts, developed our cloud based ingestion pipeline, completed development of a segmentation model with accuracy greater than 85%, and validated our results via ground truthing with independent consultants. We achieved our Phase I goal of generating an accurate, high-resolution land cover map capable of providing species-level identification. We developed a machine learning (ML) pipeline that segments drone-based (aerial) imagery to delineate species-level vegetation types, yielding geospatial maps that can be used to understand both static and temporal trends of vegetation composition and ecosystem diversity.</span></strong><strong id=\"docs-internal-guid-0398fb24-7fff-b82e-b341-0f62d185f1c4\" style=\"font-weight: normal;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span></strong></p>\n<p><strong id=\"docs-internal-guid-0398fb24-7fff-b82e-b341-0f62d185f1c4\" style=\"font-weight: normal;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Historically, natural resource and conservation organizations have had difficulties mapping their targeted ecosystems, whether due to high costs of manual surveys or poor resolution of imaging technologies. </span><span style=\"font-size: 11pt; font-family: Arial; color: #222222; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">By identifying individual plants down to species level, the model provides insights on ecosystem composition and health indicators to improve land management. </span><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This process of mapping sites over time enables land managers and conservationists to track land changes and assess if programs implemented have the intended impacts on the ecosystem.</span></strong></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/03/2023<br>\n\t\t\t\t\tModified by: Ross&nbsp;H&nbsp;Davison</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/2112419/2112419_10740421_1672779566474_Final_Outputs_Report--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2112419/2112419_10740421_1672779566474_Final_Outputs_Report--rgov-800width.jpg\" title=\"Output Selection\"><img src=\"/por/images/Reports/POR/2023/2112419/2112419_10740421_1672779566474_Final_Outputs_Report--rgov-66x44.jpg\" alt=\"Output Selection\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our approach yielded greater than 85% grid point accuracy at the two sites</div>\n<div class=\"imageCredit\">Comon Solutions</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ross&nbsp;H&nbsp;Davison</div>\n<div class=\"imageTitle\">Output Selection</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \n\nOur goal was to generate accurate high resolution land cover maps, with specific granularity of species-level identification. To accomplish that, we developed a machine learning pipeline that segments aerial (drone) based imagery, focusing on the delineation of species-level vegetation types. The final outputs are geospatial maps that can be used to understand the vegetation composition and diversity of an ecosystem, as well as temporal trends.  \n\nThe model was tested and iterated on three sites, each representing a different ecosystem with unique challenges (i.e. river watershed, chaparral, and high density native showcase zone). During Phase 1, we defined the parameters for input requirements (i.e., minimum / ideal resolution), created image pre-processing scripts, developed our cloud based ingestion pipeline, completed development of a segmentation model with accuracy greater than 85%, and validated our results via ground truthing with independent consultants. We achieved our Phase I goal of generating an accurate, high-resolution land cover map capable of providing species-level identification. We developed a machine learning (ML) pipeline that segments drone-based (aerial) imagery to delineate species-level vegetation types, yielding geospatial maps that can be used to understand both static and temporal trends of vegetation composition and ecosystem diversity. \n\nHistorically, natural resource and conservation organizations have had difficulties mapping their targeted ecosystems, whether due to high costs of manual surveys or poor resolution of imaging technologies. By identifying individual plants down to species level, the model provides insights on ecosystem composition and health indicators to improve land management. This process of mapping sites over time enables land managers and conservationists to track land changes and assess if programs implemented have the intended impacts on the ecosystem.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 01/03/2023\n\n\t\t\t\t\tSubmitted by: Ross H Davison"
 }
}