{
 "awd_id": "2119677",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: PPoSS: Planning: Model-Driven Compiler Optimization and Algorithm-Architecture Co-Design for Scalable Machine Learning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Seung-Jong Park",
 "awd_eff_date": "2021-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 186955.0,
 "awd_amount": 186955.0,
 "awd_min_amd_letter_date": "2021-07-14",
 "awd_max_amd_letter_date": "2021-07-14",
 "awd_abstract_narration": "There is an inexorable need for increased computational performance and improved energy efficiency in the development and use of machine-learning (ML) models. Currently available frameworks for ML have limitations in developing non-traditional models, e.g., using tensor networks, as well as in developing and using models that are too large to fit in the physical memory of processors. The design of efficient hardware accelerators and the mapping of ML algorithms to them is another challenge. This planning project presents a plan of action to address these needs via advances to model-driven compiler optimization. The research conducted in this project is enhancing productivity, performance, and portability in developing software for ML. It is enabling new ML applications to be developed with high productivity, with high achieved performance, and performance-portability over a diverse set of hardware platforms. It is enabling greater \"democratization of ML\", permitting researchers who only have access to low-end hardware platforms to be able to run the largest models -- infeasible today due to limitations of existing ML frameworks. The project involves training activities tailored for K-12 students, undergraduate students, and graduate students. \r\n\r\nIn this planning project, the following primary technical directions are explored: (1) ML Algorithms: flexible new ML models, offering trade-offs between model size, model execution time, model accuracy, and energy efficiency; (2) Optimizing Compilers: advances in polyhedral compiler optimization to enable parametric tilesize optimization and code generation for diverse target platforms, including CPUs, GPUs, and accelerators; (3) ML Accelerators: new ML accelerator designs for sparse and dense operators, optimized for multiple criteria via comprehensive design space exploration. Broader impact aims of the project include the \"Democratization of AI\u201d, to enable state-of-the-art ML models to be used by all, on widely available non-state-of-the-art hardware. To achieve these goals, the project integrates expertise in computer architecture, optimizing compilers, ML algorithms, and high-performance computing.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ponnuswamy",
   "pi_last_name": "Sadayappan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ponnuswamy Sadayappan",
   "pi_email_addr": "saday@cs.utah.edu",
   "nsf_id": "000182536",
   "pi_start_date": "2021-07-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rajeev",
   "pi_last_name": "Balasubramonian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rajeev Balasubramonian",
   "pi_email_addr": "rajeev@cs.utah.edu",
   "nsf_id": "000136755",
   "pi_start_date": "2021-07-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Vivek",
   "pi_last_name": "Srikumar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Vivek Srikumar",
   "pi_email_addr": "svivek@cs.utah.edu",
   "nsf_id": "000676145",
   "pi_start_date": "2021-07-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "50 S. Central Campus Drive",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841128930",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 186955.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;</p>\n<div><span>Machine learning (ML) plays a critical role in a variety of fields, including image processing, natural language processing, data analytics, and scientific computation. A new generation of computer hardware, referred to as hardware accelerators, presents unprecedented opportunities for executing ML software with high speed and low energy usage. To realize these opportunities, many new technical challenges need to be solved.</span></div>\n<div><br /><span>This planning project helped to define the research agenda for a FULL PPOSS propsal for a comprehensive framework for efficient, scalable, and performance-portable computations on tensors, with emphasis on hardware accelerators as targeted platforms. Tensors are core ML data structures and are also heavily used in other areas such as scientific computing. The project assembled a team of 10 researchers spanning expertise in computer architecture, high-performance computing, programming languages and compilers, scientific computing, machine learning, and image analysis.&nbsp;</span></div>\n<div><br /><span>As part of the planning project, the following technical challenges were targeted and partially solved: (a) An automated approach to execute ML analysis of large images on hardware with limited memory. The resulting novel approach allows arbitrarily large images to be processed, irrespective of the hardware memory size. (b) An automated approach to create and solve performance models for algorithm-architecture co-design for a layer in an ML convolutional neural network. This new co-design optimization enables significant improvements over prior accelerator designs for both energy reduction and performance improvements; (c) The development of compact ML models, replacing large parameter matrices by a tensor network with fewer parmeters.</span></div>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/09/2023<br>\n\t\t\t\t\tModified by: Ponnuswamy&nbsp;Sadayappan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nMachine learning (ML) plays a critical role in a variety of fields, including image processing, natural language processing, data analytics, and scientific computation. A new generation of computer hardware, referred to as hardware accelerators, presents unprecedented opportunities for executing ML software with high speed and low energy usage. To realize these opportunities, many new technical challenges need to be solved.\n\nThis planning project helped to define the research agenda for a FULL PPOSS propsal for a comprehensive framework for efficient, scalable, and performance-portable computations on tensors, with emphasis on hardware accelerators as targeted platforms. Tensors are core ML data structures and are also heavily used in other areas such as scientific computing. The project assembled a team of 10 researchers spanning expertise in computer architecture, high-performance computing, programming languages and compilers, scientific computing, machine learning, and image analysis. \n\nAs part of the planning project, the following technical challenges were targeted and partially solved: (a) An automated approach to execute ML analysis of large images on hardware with limited memory. The resulting novel approach allows arbitrarily large images to be processed, irrespective of the hardware memory size. (b) An automated approach to create and solve performance models for algorithm-architecture co-design for a layer in an ML convolutional neural network. This new co-design optimization enables significant improvements over prior accelerator designs for both energy reduction and performance improvements; (c) The development of compact ML models, replacing large parameter matrices by a tensor network with fewer parmeters.\n\n \n\n\t\t\t\t\tLast Modified: 07/09/2023\n\n\t\t\t\t\tSubmitted by: Ponnuswamy Sadayappan"
 }
}