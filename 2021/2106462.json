{
 "awd_id": "2106462",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Stochastic Optimal Control with High Dimensional Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Pedro Embid",
 "awd_eff_date": "2021-06-15",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 285000.0,
 "awd_amount": 285000.0,
 "awd_min_amd_letter_date": "2021-06-03",
 "awd_max_amd_letter_date": "2021-06-03",
 "awd_abstract_narration": "Optimal control has been a central tool in many groundbreaking technological advances starting with the moon-landing problem to recent developments in machine learning. Impressive advances in the training of neural networks now allow for further exciting complex and realistic applications. This project aims to leverage these modern optimization techniques to build an almost data-driven theory and to reduce the potentially catastrophic model risk that was prevalent in the recent financial crisis. Additionally, as machine learning methodology is becoming the dominant paradigm in many industries, education on these topics is vital to the economy of the nation. Towards this goal, students from all levels will be integrated into this research providing them with well-rounded training on these omnipresent computational practices.\r\n \r\nTechnically, several classes of problems will be investigated in-depth to highlight and resolve different difficulties that the general theory faces. The main study will be a general high-level analysis of recent numerical experiments based on the efficient training of deep neural networks. Optimal control of McKean-Vlasov jump-diffusions will be analyzed to provide a concrete setting. These problems are naturally set in the infinite-dimensional Wasserstein-type spaces and pose many interesting questions, including the construction of high-dimensional but tractable approximations. Similar questions also arise in optimal transport problems related to optimization with model uncertainty and risk management problems in quantitative finance with many underlying risk factors, and they have broad applicability.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Halil",
   "pi_last_name": "Soner",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Halil M Soner",
   "pi_email_addr": "soner@princeton.edu",
   "nsf_id": "000086162",
   "pi_start_date": "2021-06-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "225 Sherrerd Hall",
  "perf_city_name": "Princeton",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442020",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126600",
   "pgm_ele_name": "APPLIED MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 285000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Starting from its initial use in the moon landing problem, over the past several decades optimal control developed into a powerful omnibus mathematical theory for uncertain decisions.&nbsp;&nbsp;I found many and exciting applications including its central role in autopilots, the&nbsp;groundbreaking&nbsp;Q-learning of Watson, general reinforcement learning, many robotics models, production planning in operations research, financial economics, utility maximization of Merton, contract theory of Hardt &amp; Holmstrom, and more recently essentially in all learning algorithms.&nbsp;&nbsp;It is one of the&nbsp;indispensable&nbsp;tools of modern engineering and economics. &nbsp;</p>\n<p>Recent exciting developments in optimization and the availability of highly efficient computational packages also introduced many technologically important, mathematically challenging novel questions.&nbsp;&nbsp;Indeed, incredible speed of the mentioned numerical resources allow us to consider realistic complex models that capture all relevant aspects of the applications.&nbsp;&nbsp;As these models require many features to describe the system, they are high dimensional and previously they were out-of-reach of all numerical methods.&nbsp;&nbsp;However, they are now directly solvable with readily available software.</p>\n<p>This leading goal of this project is to leverage these exciting new developments and to analyze the resulting algorithm.&nbsp;&nbsp;As effective as they are, these algorithms need to be understood in term of their data needs and their interactions with the underlying models.</p>\n<p>&nbsp;Initial step was to develop a general approach applicable to essentially all control problems with a clear numeric performance criterion.&nbsp;&nbsp;We utilize deep neural networks as a controller taking the available data as input and providing actions.&nbsp;&nbsp;We then evaluate its performance by simulating many scenarios from the model or if available from the observed data and averaging the outcomes.&nbsp;&nbsp;This Monte-Carlo step attaches a numeric `goodness&rsquo; value to each deep neural network.&nbsp;&nbsp;We then use the modern optimization packages to train the network to construct the optimal one.&nbsp;&nbsp;Although each application requires several additional steps to overcome the difficulties presented by then individual problems, it is very robust, and it performs remarkably well.</p>\n<p>&nbsp;This project applied this methodology to several classical problems to assess it in relevant benchmark problems and the results were communicated through nine research articles published by leading academic journals.&nbsp;&nbsp;Additionally, numerous scientific presentations were given to disseminate the outcomes. &nbsp;</p>\n<p>&nbsp;The problem of optimal stopping is one problem that was analyzed.&nbsp;&nbsp;In this problem the only mechanism is to stop the system and collect a known reward.&nbsp;&nbsp;The dynamics of the system is not known or random and the goal is to maximize the reward.&nbsp;&nbsp;Despite its deceiving simplicity and mathematical elegance, it has many. Real-life applications such as the American options of the financial industry or the convertible bonds.&nbsp;&nbsp;In this project we studied the related algorithm both analytically showing how to avoid overfitting, demonstrated numerical effectiveness on several financial products and proved its convergence as the neural networks get larger and deeper.&nbsp;&nbsp;We also applied same techniques to develop an algorithm for the solidification problems with highly irregular interfaces.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 08/06/2024<br>\nModified by: Halil&nbsp;M&nbsp;Soner</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nStarting from its initial use in the moon landing problem, over the past several decades optimal control developed into a powerful omnibus mathematical theory for uncertain decisions.I found many and exciting applications including its central role in autopilots, thegroundbreakingQ-learning of Watson, general reinforcement learning, many robotics models, production planning in operations research, financial economics, utility maximization of Merton, contract theory of Hardt & Holmstrom, and more recently essentially in all learning algorithms.It is one of theindispensabletools of modern engineering and economics. \n\n\nRecent exciting developments in optimization and the availability of highly efficient computational packages also introduced many technologically important, mathematically challenging novel questions.Indeed, incredible speed of the mentioned numerical resources allow us to consider realistic complex models that capture all relevant aspects of the applications.As these models require many features to describe the system, they are high dimensional and previously they were out-of-reach of all numerical methods.However, they are now directly solvable with readily available software.\n\n\nThis leading goal of this project is to leverage these exciting new developments and to analyze the resulting algorithm.As effective as they are, these algorithms need to be understood in term of their data needs and their interactions with the underlying models.\n\n\nInitial step was to develop a general approach applicable to essentially all control problems with a clear numeric performance criterion.We utilize deep neural networks as a controller taking the available data as input and providing actions.We then evaluate its performance by simulating many scenarios from the model or if available from the observed data and averaging the outcomes.This Monte-Carlo step attaches a numeric `goodness value to each deep neural network.We then use the modern optimization packages to train the network to construct the optimal one.Although each application requires several additional steps to overcome the difficulties presented by then individual problems, it is very robust, and it performs remarkably well.\n\n\nThis project applied this methodology to several classical problems to assess it in relevant benchmark problems and the results were communicated through nine research articles published by leading academic journals.Additionally, numerous scientific presentations were given to disseminate the outcomes. \n\n\nThe problem of optimal stopping is one problem that was analyzed.In this problem the only mechanism is to stop the system and collect a known reward.The dynamics of the system is not known or random and the goal is to maximize the reward.Despite its deceiving simplicity and mathematical elegance, it has many. Real-life applications such as the American options of the financial industry or the convertible bonds.In this project we studied the related algorithm both analytically showing how to avoid overfitting, demonstrated numerical effectiveness on several financial products and proved its convergence as the neural networks get larger and deeper.We also applied same techniques to develop an algorithm for the solidification problems with highly irregular interfaces.\n\n\n\t\t\t\t\tLast Modified: 08/06/2024\n\n\t\t\t\t\tSubmitted by: HalilMSoner\n"
 }
}