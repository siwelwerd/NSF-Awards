{
 "awd_id": "2134108",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Foundations of Deep Learning: Theory, Robustness, and the Brain\u200b",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927212",
 "po_email": "jmead@nsf.gov",
 "po_sign_block_name": "Jodi Mead",
 "awd_eff_date": "2021-12-01",
 "awd_exp_date": "2024-11-30",
 "tot_intn_awd_amt": 600000.0,
 "awd_amount": 600000.0,
 "awd_min_amd_letter_date": "2021-09-15",
 "awd_max_amd_letter_date": "2021-09-15",
 "awd_abstract_narration": "A truly comprehensive theory of machine learning has the potential of informing science and engineering in the same profound way Maxwell\u2019s equations did. It was the development of that theory by Maxwell that truly unleashed the potential of electricity, leading to radio, radars, computers, and the Internet. In an analogy, deep learning (DL) has found over the past decade many applications, so far without a comprehensive theory. An eventual theory of learning that explains why and how deep networks work and what their limitations are may thus enable the development of even more powerful learning approaches \u2013 especially if the goal of reconnecting DL to brain research bears fruit. In the long  term, the ability to develop and build better intelligent machines will be essential to any technology-based economy. After all, even in its current \u2013 still highly imperfect \u2013 state, DL is impacting or about to impact just about every aspect of our society and life. The investigators also plan to complement their theoretical research with the educational goal of training a diverse population of young researchers from mathematics, computer science, statistics, electrical engineering, and computational neuroscience in the field of machine learning and of its theoretical underpinnings.\r\n\r\nThe investigators propose to join forces in a multi-pronged and collaborative assault on the profound mysteries of DL, informed by  the sum of their experience, expertise, ideas, and insight. The research goals are threefold: to develop a sound foundational/mathematical understanding of DL; in doing so to advance the foundational understanding of learning more generally; and to advance the practice of DL by addressing its above-mentioned  weaknesses. Of six foundational thrusts, the first two focus on the standard decomposition of the prediction error in approximation and sample (or estimation) error. Their goal is to extend classical results in  approximation theory and theory of learnability to DL. These two are then supported by a research project that is specific to deep learning: analysis of the dynamics of gradient descent in training a network. The  fourth theme is about robustness against adversaries and shifts, a powerful test for theories which is also important for practical deployment of learning systems. The fifth thrust is about developing the theory of control through DL, as well as exploring dynamical systems aspects of deep reinforcement learning. The final topic connects research on DL to its origins - and possibly its future: networks of neurons in the brain. The proposed research also promises to advance the foundations of learning theory. Success in this project will result in sharper mathematical techniques for machine learning and comprehensive foundations of machine learning robustness, broadly construed. It will also ultimately enable development of learning algorithms that transcend deep learning and guide the way towards creating more intelligent machines, and shed new light on our own intelligence.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tomaso",
   "pi_last_name": "Poggio",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tomaso Poggio",
   "pi_email_addr": "tp@ai.mit.edu",
   "nsf_id": "000099992",
   "pi_start_date": "2021-09-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Constantinos",
   "pi_last_name": "Daskalakis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Constantinos Daskalakis",
   "pi_email_addr": "costis@csail.mit.edu",
   "nsf_id": "000537704",
   "pi_start_date": "2021-09-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Stefanie",
   "pi_last_name": "Jegelka",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Stefanie Jegelka",
   "pi_email_addr": "stefje@mit.edu",
   "nsf_id": "000692422",
   "pi_start_date": "2021-09-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Aleksander",
   "pi_last_name": "Madry",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aleksander Madry",
   "pi_email_addr": "madry@MIT.EDU",
   "nsf_id": "000699850",
   "pi_start_date": "2021-09-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Avenue",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "125300",
   "pgm_ele_name": "OFFICE OF MULTIDISCIPLINARY AC"
  },
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  },
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 600000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;</p>\r\n<div><span>The topic of our collaborative research is the problem of intelligence, probably the greatest problem in science since its full solution would imply the solution of all other great problems of science. During the last ten years there has been an explosion of powerful applications of AI but an understanding of the underlying science has been lacking behind. Our proposal is motivated by the belief that a foundational theory of Machine Learning -- which is at the core of AI and of intelligence itself -- is not only important but also urgent. In other words, the stunning success of deep learning (DL) over the past decade is crying out for a&nbsp; scientific understanding through foundational research.&nbsp;We need a theory a) because we need better systems b) because a theory provides deep explainability + control (for alignment etc.) c) because a theory may help find and understand basic principles of intelligence, including of our own intelligence and d) the theory should be like a theory in physics, spelling out&nbsp;</span><em><span>fundamental principles of intelligence.</span></em></div>\r\n<div><span>In the MIT part of our collaboration we focused on key parts of machine learning: approximation, generalization, optimization and robustness against adversaries&nbsp;and shifts. Our most significant results include potentially foundational findings that bridge ideas of computability with learnability. In particular, functions that are efficiently Turing computable -- that is computable in non-exponential time-- are compositionally sparse and can be represented by&nbsp;</span><em><span>deep and sparse</span></em><span>networks without curse of dimensionality that is with a non-exponential number of weights. This result answers several questions and puzzles around deep networks such as: -why is depth important? -why can deep nets escape the curse of dimensionality? -why are sparse networks (like CNN) much better than fully connected NN?</span></div>\r\n<div><span>The next set of relevant results regards&nbsp;</span><em><span>generalization.&nbsp;</span></em><span>It turns out that&nbsp;</span><em><span>sparsity</span></em><span>&nbsp;of the weight matrices of a deep network (e.g. convolutional layers) reduces the Rademacher complexity -- and thereby bounds on the generalization gap -- by several order of magnitude. Furthermore,&nbsp;</span><em><span>low rank</span></em><span>&nbsp;of the weight matrices can lead to better generalization (bounds). We have also been able to prove that&nbsp;</span><em><span>out of distribution generalization</span></em><span>&nbsp;holds for sparse graphs and not only for dense graphs.</span></div>\r\n<div><span>On the&nbsp;</span><em><span>optimization</span></em><span>&nbsp;side, we have shown that SGD, unlike GD, has a bias &nbsp;towards &nbsp;low-rank weight matrices; such bias depends on small minibatches and the presence of regularization. We have also developed a new framework called&nbsp;meta optimization coupling the emerging theory of online nonstochastic control&nbsp;with an application to optimization.</span><em><span>&nbsp;</span></em><span>This online nonstochastic control framework applies to smooth dynamical&nbsp;systems. However, many reinforcement learning and control settings apply in unknown and&nbsp;discontinuous dynamics that are artificial and have no physical analogue. We provide efficient and practical algorithms for optimizing policies in these situations. We also studied equilibrium learning in&nbsp;</span><em><span>multi-agent&nbsp;reinforcement learning&nbsp;</span></em><span>settings. In our work, we provide intractability results for equilibrium computation in stochastic games, and tractability results for multi-agent reinforcement learning.&nbsp;</span></div>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<div><span>Our research has been disseminated in publications, conferences and teaching, including collaborations and interactions with Google Deep Mind, Microsoft and other companies. It has deeply contributed to the education of skilled workforce in the critical area of AI. It is foundational for the development of more powerful technologies and for their deeper understanding and control.</span></div>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/29/2025<br>\nModified by: Tomaso&nbsp;Poggio</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\r\nThe topic of our collaborative research is the problem of intelligence, probably the greatest problem in science since its full solution would imply the solution of all other great problems of science. During the last ten years there has been an explosion of powerful applications of AI but an understanding of the underlying science has been lacking behind. Our proposal is motivated by the belief that a foundational theory of Machine Learning -- which is at the core of AI and of intelligence itself -- is not only important but also urgent. In other words, the stunning success of deep learning (DL) over the past decade is crying out for a scientific understanding through foundational research.We need a theory a) because we need better systems b) because a theory provides deep explainability + control (for alignment etc.) c) because a theory may help find and understand basic principles of intelligence, including of our own intelligence and d) the theory should be like a theory in physics, spelling outfundamental principles of intelligence.\r\nIn the MIT part of our collaboration we focused on key parts of machine learning: approximation, generalization, optimization and robustness against adversariesand shifts. Our most significant results include potentially foundational findings that bridge ideas of computability with learnability. In particular, functions that are efficiently Turing computable -- that is computable in non-exponential time-- are compositionally sparse and can be represented bydeep and sparsenetworks without curse of dimensionality that is with a non-exponential number of weights. This result answers several questions and puzzles around deep networks such as: -why is depth important? -why can deep nets escape the curse of dimensionality? -why are sparse networks (like CNN) much better than fully connected NN?\r\nThe next set of relevant results regardsgeneralization.It turns out thatsparsityof the weight matrices of a deep network (e.g. convolutional layers) reduces the Rademacher complexity -- and thereby bounds on the generalization gap -- by several order of magnitude. Furthermore,low rankof the weight matrices can lead to better generalization (bounds). We have also been able to prove thatout of distribution generalizationholds for sparse graphs and not only for dense graphs.\r\nOn theoptimizationside, we have shown that SGD, unlike GD, has a bias towards low-rank weight matrices; such bias depends on small minibatches and the presence of regularization. We have also developed a new framework calledmeta optimization coupling the emerging theory of online nonstochastic controlwith an application to optimization.This online nonstochastic control framework applies to smooth dynamicalsystems. However, many reinforcement learning and control settings apply in unknown anddiscontinuous dynamics that are artificial and have no physical analogue. We provide efficient and practical algorithms for optimizing policies in these situations. We also studied equilibrium learning inmulti-agentreinforcement learningsettings. In our work, we provide intractability results for equilibrium computation in stochastic games, and tractability results for multi-agent reinforcement learning.\r\n\n\n\r\n\n\n\r\nOur research has been disseminated in publications, conferences and teaching, including collaborations and interactions with Google Deep Mind, Microsoft and other companies. It has deeply contributed to the education of skilled workforce in the critical area of AI. It is foundational for the development of more powerful technologies and for their deeper understanding and control.\r\n\n\n\t\t\t\t\tLast Modified: 01/29/2025\n\n\t\t\t\t\tSubmitted by: TomasoPoggio\n"
 }
}