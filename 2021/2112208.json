{
 "awd_id": "2112208",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Artificial Intelligence for Competency-Based Medical Training",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032924392",
 "po_email": "amonk@nsf.gov",
 "po_sign_block_name": "Alastair Monk",
 "awd_eff_date": "2021-08-15",
 "awd_exp_date": "2022-11-30",
 "tot_intn_awd_amt": 256000.0,
 "awd_amount": 256000.0,
 "awd_min_amd_letter_date": "2021-08-04",
 "awd_max_amd_letter_date": "2021-08-04",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to train physicians efficiently, assure high-quality patient care, and provide the United States with a robustly competent physician workforce. Current assessment practices require attending physicians and surgeons to review tens-to-hundreds of data points, removing them from clinical activities. Integrating a machine learning model in an existing resident assessment system to predict performance can address trainees\u2019 learning needs and identify excelling, competent, and struggling residents months earlier. This is vital to patient care: earlier identification of trainee performance can benefit patient care faster than the current human-based, semiannual process. Improved tracking and documentation of competence may be of interest to multiple stakeholders including patients, hospitals, third-party payers such as insurance companies or the Centers for Medicare and Medicaid Services, and the residency accreditation entity, the Accreditation Council for Graduate Medical Education. Improved, automated assessment models using existing trainee data help training programs facing increasing documentation burden, as well as hospitals and third-party payers interested in reducing adverse health events for the patients they serve.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project will integrate an artificial intelligence model to support resident physician training programs in customizing training based on individual learners\u2019 needs. Starting with plastic and reconstructive surgery and one of the four training programs in the United States engaged in time-variable training is an efficient way to create, test, and assess the model\u2019s efficacy. The created machine learning model will be assessed for its predictive ability at different points during resident physicians\u2019 training and compared with attending physicians\u2019 assessments of trainees\u2019 skills. Such models make time-variable training feasible enabling adaptive, needs-based scheduling of various educational rotations. This has the added advantages of keeping residents fully engaged in their training and returning faculty physicians to clinical care faster, improving job satisfaction and reducing risk of burnout. Ultimately, time-variable training and use of their associated machine learning models will reduce the direct and indirect costs of graduate medical education; accelerate the entry of new, fully competent physicians into the workforce; and retain valuable physician educators in the workforce.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Carisa",
   "pi_last_name": "Cooney",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Carisa M Cooney",
   "pi_email_addr": "ccooney3@jhmi.edu",
   "nsf_id": "000783313",
   "pi_start_date": "2021-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "EDUMD, LLC",
  "inst_street_address": "1812 ASHLAND AVE",
  "inst_street_address_2": "STE 110",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "2172200467",
  "inst_zip_code": "212051506",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "EDUMD LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "WC19APUV6BK5"
 },
 "perf_inst": {
  "perf_inst_name": "EDUMD, LLC",
  "perf_str_addr": "1812 Ashland Ave, Ste 110",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212051258",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1707",
   "pgm_ref_txt": "ADVANCED LEARNING TECHNOLOGIES"
  },
  {
   "pgm_ref_code": "8031",
   "pgm_ref_txt": "Education Products"
  },
  {
   "pgm_ref_code": "8042",
   "pgm_ref_txt": "Health and Safety"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 256000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Training America&rsquo;s &gt;130,000 resident physicians annually is costly, exceeding $15 billion each year. Physician training uses the apprenticeship model: over a set number of years, resident physicians (trainees) learn their craft on-the-job, on patients, under the supervision of attending physicians (faculty). Increasing restrictions on trainee work-hours and resources, along with increasing documentation requirements, have contributed significantly to educational complexity. Improving training efficiency could help reduce training time as well as costs, medical errors ($17B in 2008), and physician burnout. Specialties have begun considering time-variable training (TVT), an innovative educational advancement aiming to accelerate historically costly, time-consuming training.</p>\n<p>Medical faculty and surgeons invested in surgical education created MileMarker&reg;, a mobile software as a service (SaaS) technology, to support this effort. MileMarker houses two types of resident physician assessments: the Operative Entrustability Assessment (OEA), a point-of-care assessment performed throughout training which can document changes in trainees&rsquo; operative skills over time, and the accrediting body [the Accreditation Council for Graduate Medical Education (ACGME)]-required Next Accreditation System (NAS) Milestones, a global semi-annual assessment of resident physicians&rsquo; skills.</p>\n<p><strong>As of 10/31/2022, over 15,000 OEAs and 15,000 Milestones assessments have been logged in MileMarker</strong>.</p>\n<p>The <strong><span style=\"text-decoration: underline;\">global objective </span></strong>of this project is to create an machine learning model using data housed in MileMarker that can classify overall whether a plastic surgery resident (aka - trainee) struggles, is average, or excels in their operative skills; this has the potential to increase training efficiency and lower training costs.</p>\n<p>Under this NSF SBIR Phase 1 funded award, we successfully identified and refined a retrospective machine learning model to predict with 80% accuracy plastic surgery residents&rsquo; operative performance using OEA and semi-annual assessment data&nbsp;using a publicly available model. Subject Matter Experts (SMEs, or faculty surgeons) labeled resident trainees in terms of their operative abilities. Using these labels, the model demonstrated superior accuracy (80%) compared to uniformly random (33%) or majority-label (61.8%) assignment. When resident ability (i.e., operative skills) labels assigned by SMEs are consolidated into three classes, the fine-tuned classifier is accurate, and holds this accuracy under cross validation.</p>\n<p>After completing this important first step, we successfully created a robust machine learning model capable of predicting whether a resident is &ldquo;Excelling&rdquo; or &ldquo;On Track&rdquo; using cumulative MileMarker metrics. Our analysis demonstrated high accuracy for the first 3 years of plastic surgery residency training (accuracy: ~85%) and higher accuracy by the fourth year (accuracy: ~94%) and fifth and sixth years (accuracy: ~95%). The high level of predictive accuracy in the fourth year of training is a valuable time point, being&nbsp;sufficiently early for training programs to effectively act on the prediction: namely, to decide whether to begin preparations to enable early graduation (prediction of \"Excelling\") and/or future employment plans (e.g., identifying a fellowship for additional specialty training or a job as a private or academic plastic surgeon). It&nbsp;is also earlier in plastic surgery residency training than most (95%) SMEs are comfortable / confident predicting and acting on to result in the educational programming changes necessary to enable earlier graduation.</p>\n<p>Having created this machine learning model, we&nbsp;compared it with ratings from ten SMEs following a recent semi-annual meeting assessing all active plastic surgery residents in the pilot program. This comparison demonstrated 100% agreement for the first three training years, 60% agreement in the fourth year, and 70% agreement in the fifth and sixth years; the rating differences that occurred were through the machine learning model&rsquo;s underestimating some &ldquo;Excelling&rdquo; residents&rsquo; skills. We are pleased by these initial results and will continue working with our data scientists to identify additional engineered features that may improve the model&rsquo;s accuracy in the higher training levels.</p>\n<p><span>The machine learning model developed in this project is likely to impact plastic surgery residency training by providing additional data to resident physicians and the faculty who train them to determine if early graduation (in less than six years) may be possible for certain resident trainees.&nbsp;<span>Because other procedure-based (e.g., surgical) residency training programs use similar data to track their resident trainees' progress, it is likely that this machine learning model may be adapted to enable similar predictions of future performance for other procedure-based medical specialties. Shorter training times for competent surgeons translates into potential cost savings related to this costly training and making fully-trained physicians / surgeons available to serve the public more quickly, a need that was further highlighted during the first 6-18 months of the COVID-19 pandemic.</span></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/14/2022<br>\n\t\t\t\t\tModified by: Carisa&nbsp;M&nbsp;Cooney</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nTraining America\u2019s &gt;130,000 resident physicians annually is costly, exceeding $15 billion each year. Physician training uses the apprenticeship model: over a set number of years, resident physicians (trainees) learn their craft on-the-job, on patients, under the supervision of attending physicians (faculty). Increasing restrictions on trainee work-hours and resources, along with increasing documentation requirements, have contributed significantly to educational complexity. Improving training efficiency could help reduce training time as well as costs, medical errors ($17B in 2008), and physician burnout. Specialties have begun considering time-variable training (TVT), an innovative educational advancement aiming to accelerate historically costly, time-consuming training.\n\nMedical faculty and surgeons invested in surgical education created MileMarker&reg;, a mobile software as a service (SaaS) technology, to support this effort. MileMarker houses two types of resident physician assessments: the Operative Entrustability Assessment (OEA), a point-of-care assessment performed throughout training which can document changes in trainees\u2019 operative skills over time, and the accrediting body [the Accreditation Council for Graduate Medical Education (ACGME)]-required Next Accreditation System (NAS) Milestones, a global semi-annual assessment of resident physicians\u2019 skills.\n\nAs of 10/31/2022, over 15,000 OEAs and 15,000 Milestones assessments have been logged in MileMarker.\n\nThe global objective of this project is to create an machine learning model using data housed in MileMarker that can classify overall whether a plastic surgery resident (aka - trainee) struggles, is average, or excels in their operative skills; this has the potential to increase training efficiency and lower training costs.\n\nUnder this NSF SBIR Phase 1 funded award, we successfully identified and refined a retrospective machine learning model to predict with 80% accuracy plastic surgery residents\u2019 operative performance using OEA and semi-annual assessment data using a publicly available model. Subject Matter Experts (SMEs, or faculty surgeons) labeled resident trainees in terms of their operative abilities. Using these labels, the model demonstrated superior accuracy (80%) compared to uniformly random (33%) or majority-label (61.8%) assignment. When resident ability (i.e., operative skills) labels assigned by SMEs are consolidated into three classes, the fine-tuned classifier is accurate, and holds this accuracy under cross validation.\n\nAfter completing this important first step, we successfully created a robust machine learning model capable of predicting whether a resident is \"Excelling\" or \"On Track\" using cumulative MileMarker metrics. Our analysis demonstrated high accuracy for the first 3 years of plastic surgery residency training (accuracy: ~85%) and higher accuracy by the fourth year (accuracy: ~94%) and fifth and sixth years (accuracy: ~95%). The high level of predictive accuracy in the fourth year of training is a valuable time point, being sufficiently early for training programs to effectively act on the prediction: namely, to decide whether to begin preparations to enable early graduation (prediction of \"Excelling\") and/or future employment plans (e.g., identifying a fellowship for additional specialty training or a job as a private or academic plastic surgeon). It is also earlier in plastic surgery residency training than most (95%) SMEs are comfortable / confident predicting and acting on to result in the educational programming changes necessary to enable earlier graduation.\n\nHaving created this machine learning model, we compared it with ratings from ten SMEs following a recent semi-annual meeting assessing all active plastic surgery residents in the pilot program. This comparison demonstrated 100% agreement for the first three training years, 60% agreement in the fourth year, and 70% agreement in the fifth and sixth years; the rating differences that occurred were through the machine learning model\u2019s underestimating some \"Excelling\" residents\u2019 skills. We are pleased by these initial results and will continue working with our data scientists to identify additional engineered features that may improve the model\u2019s accuracy in the higher training levels.\n\nThe machine learning model developed in this project is likely to impact plastic surgery residency training by providing additional data to resident physicians and the faculty who train them to determine if early graduation (in less than six years) may be possible for certain resident trainees. Because other procedure-based (e.g., surgical) residency training programs use similar data to track their resident trainees' progress, it is likely that this machine learning model may be adapted to enable similar predictions of future performance for other procedure-based medical specialties. Shorter training times for competent surgeons translates into potential cost savings related to this costly training and making fully-trained physicians / surgeons available to serve the public more quickly, a need that was further highlighted during the first 6-18 months of the COVID-19 pandemic.\n\n \n\n\t\t\t\t\tLast Modified: 12/14/2022\n\n\t\t\t\t\tSubmitted by: Carisa M Cooney"
 }
}