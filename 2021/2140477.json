{
 "awd_id": "2140477",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: SaTC: EAGER: Trustworthy and Privacy-preserving Federated Learning",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 60000.0,
 "awd_amount": 60000.0,
 "awd_min_amd_letter_date": "2021-08-13",
 "awd_max_amd_letter_date": "2021-08-13",
 "awd_abstract_narration": "Researchers and the public have been alarmed by a fact that user privacy of training data in machine learning (ML) models has been exploited in many ways, leading to a rapidly expanding field of federated learning(FL). In FL, the learning of ML models is performed directly on user devices, while the aggregated model is composed with a help of a central server. As data never leave user devices, this new paradigm offers a key promise to protect data privacy. It, unfortunately, poses new challenges in both security and privacy. On one hand, malicious users can compromise security by injecting backdoors into the model updates, thus poisoning the aggregated model. On the other hand, there is a risk of privacy leakage as an untrusted server can inverse the model update to expose private data. This project develops a principled and systematic FL framework that simultaneously offers both privacy and security protection against threats from malicious users and servers. As part of this project, novel protocols will be developed to ensure verifiability, execution integrity, model confidentiality, and protection against adversarial attacks. The success of the project holds significant potential in expanding machine learning to new application scenarios, especially, when no trust is assumed among the stakeholders. The findings may also benefit other fields, such as zero-knowledge proof, distributed machine learning, and distributed ledger technology. The project involves students at all levels, with an emphasis on attracting students from underrepresented groups and K-12 students.\r\n\r\nThe focus of the project is to develop a principled and systematic FL framework with three jointly key components: 1) a lightweight secure aggregation and backdoor inspection mechanisms in which each user is responsible for both securely aggregating their values and an attestation of an attack-free model, 2) a succinct non-interactive argument of knowledge (SNARK) attestation that minimizes non-arithmetic operations to maintain both high accuracy and communication-efficiency, and 3) a blockchain-based FL architecture to tight together security measures at various stages in the training process, offering privacy and security protection for the entire training process. By shifting a task of proving that model is free-of-attack to users, coupling of Blockchain for transparency, this project provides a first step towards a secured and privacy protection of distributed learning systems. The success of this novel approach will significantly impact the design of FL for many real-life applications.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "My",
   "pi_last_name": "Thai",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "My T Thai",
   "pi_email_addr": "mythai@cise.ufl.edu",
   "nsf_id": "000391957",
   "pi_start_date": "2021-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1 University of Florida",
  "perf_city_name": "GAINESVILLE, FL",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326112002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 60000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aims to simultaneously address security and privacy issues in Federated Learning (FL) such as privacy leakage as well as adversarial attacks in the collaboratively trained model. The goals are to develop a principled and systematic framework that simultaneously offers both privacy and security protection, in a presence of both malicious users and semi-dishonest servers. Accordingly, we have achieved the following major results: (1) Developed attack-free proofs in the presence of secure aggregation: We first addressed the contradiction goals between verifying the attack-free model while preserving user privacy by shifting the verification task to users, including developing a novel zero-knowledge-proof (ZKP) based on multiparty computation, which is introduced for the first time in the context of federated learning, especially for attesting non-poisoned models while maintaining privacy guarantees. (2) Designed succinct zero-knowledge proofs for attack-free models: We developed a succinct non-interactive argument of knowledge (SNARK) attestation that minimizes non-arithmetic operations to maintain both high accuracy and communication-efficiency, thus advancing the state of the art of ZKP where existing work in the literature model the computations as arithmetic circuits. (3) Developed the first secure blockchain-based FL against semi-dishonest servers with provable guarantees: Based on the results (1) and (2), we designed an FL system to tighten together security measures at various stages in the training process, offering privacy and security protection for the entire training process. Specifically, the designed system prevents a semi-dishonest server from breaking secure aggregation protocol by forcing the server to choose a random pool of users during the user selection stage and provides a consistent global model update to all users. (4)&nbsp;Moreover, as we have identified blockchain as a key component in maintaining a trustworthy FL system, it is necessary to examine the vulnerabilities and scalability of blockchain so as to ensure a highly performant and secure integration between the two technologies. we investigated the security threats of blockchain, effectively capturing the recent attacks, and reviewed the security enhancement solutions for blockchain. We further carried out a study on sharding, which is an auspicious solution in tackling the scalability issue of legacy blockchain systems. Specifically, we identified a new vulnerability of blockchain sharding that makes it susceptible to a low-cost denial-of-service attack and developed a countermeasure accordingly.</p>\n<p>The project has several impacts on the development of secure and privacy-preserving federated learning systems. Indeed, several studies recently have shown that FL as its primitive design offers little to none privacy preserving, especially when the server is dishonest. Therefore, the results of this project will serve as an initial attempt with provable guarantees to simultaneously protect data privacy and security.&nbsp;</p>\n<p>For the broader impact, there were one undergraduate female student (in a total of two undergraduate and two Ph.D. students) and one&nbsp;African-American Ph.D. student&nbsp;involved in this project. We have presented our works in conferences and on a panel on Blockchain &amp; Applications at the DBSec&rsquo;22 conference. The project results have been integrated into two courses: the Blockchain: Optimization and Application at the University of Florida and&nbsp;the CMSC 512: Advanced Social Networks Analysis &amp; Security course at Virginia Commonwealth University.&nbsp;&nbsp;The results have also been integrated into a Capstone Design project on Blockchain system for Medical Data Sharing and Analysis. Students gained an understanding of federated systems and how to train joint models without gathering data in a single place.</p><br>\n<p>\n Last Modified: 12/01/2023<br>\nModified by: My&nbsp;T&nbsp;Thai</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project aims to simultaneously address security and privacy issues in Federated Learning (FL) such as privacy leakage as well as adversarial attacks in the collaboratively trained model. The goals are to develop a principled and systematic framework that simultaneously offers both privacy and security protection, in a presence of both malicious users and semi-dishonest servers. Accordingly, we have achieved the following major results: (1) Developed attack-free proofs in the presence of secure aggregation: We first addressed the contradiction goals between verifying the attack-free model while preserving user privacy by shifting the verification task to users, including developing a novel zero-knowledge-proof (ZKP) based on multiparty computation, which is introduced for the first time in the context of federated learning, especially for attesting non-poisoned models while maintaining privacy guarantees. (2) Designed succinct zero-knowledge proofs for attack-free models: We developed a succinct non-interactive argument of knowledge (SNARK) attestation that minimizes non-arithmetic operations to maintain both high accuracy and communication-efficiency, thus advancing the state of the art of ZKP where existing work in the literature model the computations as arithmetic circuits. (3) Developed the first secure blockchain-based FL against semi-dishonest servers with provable guarantees: Based on the results (1) and (2), we designed an FL system to tighten together security measures at various stages in the training process, offering privacy and security protection for the entire training process. Specifically, the designed system prevents a semi-dishonest server from breaking secure aggregation protocol by forcing the server to choose a random pool of users during the user selection stage and provides a consistent global model update to all users. (4)Moreover, as we have identified blockchain as a key component in maintaining a trustworthy FL system, it is necessary to examine the vulnerabilities and scalability of blockchain so as to ensure a highly performant and secure integration between the two technologies. we investigated the security threats of blockchain, effectively capturing the recent attacks, and reviewed the security enhancement solutions for blockchain. We further carried out a study on sharding, which is an auspicious solution in tackling the scalability issue of legacy blockchain systems. Specifically, we identified a new vulnerability of blockchain sharding that makes it susceptible to a low-cost denial-of-service attack and developed a countermeasure accordingly.\n\n\nThe project has several impacts on the development of secure and privacy-preserving federated learning systems. Indeed, several studies recently have shown that FL as its primitive design offers little to none privacy preserving, especially when the server is dishonest. Therefore, the results of this project will serve as an initial attempt with provable guarantees to simultaneously protect data privacy and security.\n\n\nFor the broader impact, there were one undergraduate female student (in a total of two undergraduate and two Ph.D. students) and oneAfrican-American Ph.D. studentinvolved in this project. We have presented our works in conferences and on a panel on Blockchain & Applications at the DBSec22 conference. The project results have been integrated into two courses: the Blockchain: Optimization and Application at the University of Florida andthe CMSC 512: Advanced Social Networks Analysis & Security course at Virginia Commonwealth University.The results have also been integrated into a Capstone Design project on Blockchain system for Medical Data Sharing and Analysis. Students gained an understanding of federated systems and how to train joint models without gathering data in a single place.\t\t\t\t\tLast Modified: 12/01/2023\n\n\t\t\t\t\tSubmitted by: MyTThai\n"
 }
}