{
 "awd_id": "2140411",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: SaTC: EAGER: Trustworthy and Privacy-preserving Federated Learning",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jeremy Epstein",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 40000.0,
 "awd_amount": 40000.0,
 "awd_min_amd_letter_date": "2021-08-13",
 "awd_max_amd_letter_date": "2021-08-13",
 "awd_abstract_narration": "Researchers and the public have been alarmed by a fact that user privacy of training data in machine learning (ML) models has been exploited in many ways, leading to a rapidly expanding field of federated learning(FL). In FL, the learning of ML models is performed directly on user devices, while the aggregated model is composed with a help of a central server. As data never leave user devices, this new paradigm offers a key promise to protect data privacy. It, unfortunately, poses new challenges in both security and privacy. On one hand, malicious users can compromise security by injecting backdoors into the model updates, thus poisoning the aggregated model. On the other hand, there is a risk of privacy leakage as an untrusted server can inverse the model update to expose private data. This project develops a principled and systematic FL framework that simultaneously offers both privacy and security protection against threats from malicious users and servers. As part of this project, novel protocols will be developed to ensure verifiability, execution integrity, model confidentiality, and protection against adversarial attacks. The success of the project holds significant potential in expanding machine learning to new application scenarios, especially, when no trust is assumed among the stakeholders. The findings may also benefit other fields, such as zero-knowledge proof, distributed machine learning, and distributed ledger technology. The project involves students at all levels, with an emphasis on attracting students from underrepresented groups and K-12 students.\r\n\r\nThe focus of the project is to develop a principled and systematic FL framework with three jointly key components: 1) a lightweight secure aggregation and backdoor inspection mechanisms in which each user is responsible for both securely aggregating their values and an attestation of an attack-free model, 2) a succinct non-interactive argument of knowledge (SNARK) attestation that minimizes non-arithmetic operations to maintain both high accuracy and communication-efficiency, and 3) a blockchain-based FL architecture to tight together security measures at various stages in the training process, offering privacy and security protection for the entire training process. By shifting a task of proving that model is free-of-attack to users, coupling of Blockchain for transparency, this project provides a first step towards a secured and privacy protection of distributed learning systems. The success of this novel approach will significantly impact the design of FL for many real-life applications.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thang",
   "pi_last_name": "Dinh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Thang Dinh",
   "pi_email_addr": "tndinh@vcu.edu",
   "nsf_id": "000662166",
   "pi_start_date": "2021-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Commonwealth University",
  "inst_street_address": "910 WEST FRANKLIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "RICHMOND",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "8048286772",
  "inst_zip_code": "232849005",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "VA04",
  "org_lgl_bus_name": "VIRGINIA COMMONWEALTH UNIVERSITY",
  "org_prnt_uei_num": "WXQLZ1PA6XP3",
  "org_uei_num": "MLQFL4JSSAA9"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Commonwealth University",
  "perf_str_addr": "401 W. Main St",
  "perf_city_name": "Richmond",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "232843068",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "VA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 40000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"whitespace-pre-wrap break-words\">This EAGER project developed new security and privacy protections for federated learning (FL) systems, which allow multiple parties to collaboratively train machine learning models without sharing raw data. The project focused on addressing both privacy leakage and adversarial attacks through a systematic framework that protects against malicious users and semi-dishonest servers.</p>\n<p class=\"whitespace-pre-wrap break-words\">Intellectual Merit: Our research made significant advances in combining privacy protection with security verification in federated learning. We developed a novel zero-knowledge-proof (ZKP) framework that enables verification of non-poisoned models while maintaining privacy guarantees during secure aggregation. This was enhanced by creating succinct non-interactive arguments of knowledge (SNARK) for model attestation that minimize non-arithmetic operations, improving both accuracy and communication efficiency.</p>\n<p class=\"whitespace-pre-wrap break-words\">A key achievement was developing CoSpaN, a secure consensus protocol for blockchain networks that prevents manipulation of client selection by semi-dishonest servers. This protocol guarantees reliable message delivery with minimal connections through a novel core-periphery network topology and implements verifiable random connections to prevent Sybil and eclipse attacks. The protocol's security was formally proven against both static and adaptive adversaries, providing a robust foundation for blockchain-based federated learning systems.</p>\n<p class=\"whitespace-pre-wrap break-words\">Broader Impacts: The project has significantly contributed to both education and diversity in computing through support of graduate student research and engagement of female and minority students in cutting-edge research across both participating institutions. The collaboration between universities has resulted in multiple publications and the integration of research outcomes into graduate courses on blockchain technology and network security.</p>\n<p class=\"whitespace-pre-wrap break-words\">Our framework enables privacy-preserving collaborative machine learning while protecting against malicious behavior, with applications in healthcare, cybersecurity, and other domains where both data sharing and privacy are critical concerns. This work provides a foundation for building trustworthy federated learning systems that can help solve important societal challenges while preserving individual privacy and system security. The theoretical advances and practical solutions developed in this project will continue to influence the development of secure and privacy-preserving distributed learning systems.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/30/2024<br>\nModified by: Thang&nbsp;Dinh</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis EAGER project developed new security and privacy protections for federated learning (FL) systems, which allow multiple parties to collaboratively train machine learning models without sharing raw data. The project focused on addressing both privacy leakage and adversarial attacks through a systematic framework that protects against malicious users and semi-dishonest servers.\n\n\nIntellectual Merit: Our research made significant advances in combining privacy protection with security verification in federated learning. We developed a novel zero-knowledge-proof (ZKP) framework that enables verification of non-poisoned models while maintaining privacy guarantees during secure aggregation. This was enhanced by creating succinct non-interactive arguments of knowledge (SNARK) for model attestation that minimize non-arithmetic operations, improving both accuracy and communication efficiency.\n\n\nA key achievement was developing CoSpaN, a secure consensus protocol for blockchain networks that prevents manipulation of client selection by semi-dishonest servers. This protocol guarantees reliable message delivery with minimal connections through a novel core-periphery network topology and implements verifiable random connections to prevent Sybil and eclipse attacks. The protocol's security was formally proven against both static and adaptive adversaries, providing a robust foundation for blockchain-based federated learning systems.\n\n\nBroader Impacts: The project has significantly contributed to both education and diversity in computing through support of graduate student research and engagement of female and minority students in cutting-edge research across both participating institutions. The collaboration between universities has resulted in multiple publications and the integration of research outcomes into graduate courses on blockchain technology and network security.\n\n\nOur framework enables privacy-preserving collaborative machine learning while protecting against malicious behavior, with applications in healthcare, cybersecurity, and other domains where both data sharing and privacy are critical concerns. This work provides a foundation for building trustworthy federated learning systems that can help solve important societal challenges while preserving individual privacy and system security. The theoretical advances and practical solutions developed in this project will continue to influence the development of secure and privacy-preserving distributed learning systems.\n\n\n\t\t\t\t\tLast Modified: 10/30/2024\n\n\t\t\t\t\tSubmitted by: ThangDinh\n"
 }
}