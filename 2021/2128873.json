{
 "awd_id": "2128873",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FW-HTF-P: Collaborative Research: Artificial Intelligence-Supported Development of Future Organizational Leaders",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032928950",
 "po_email": "soliu@nsf.gov",
 "po_sign_block_name": "Songqi Liu",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2023-09-30",
 "tot_intn_awd_amt": 35904.0,
 "awd_amount": 35904.0,
 "awd_min_amd_letter_date": "2021-09-03",
 "awd_max_amd_letter_date": "2021-09-03",
 "awd_abstract_narration": "The purpose of the proposed effort is to aid future leadership development professionals (LDP) in their work to train a diverse pipeline of leaders. The future of work involves a virtual context for many occupations. Hence, two new challenges for LDP workers are to train leaders to perform effectively in a virtual context and to leverage future technology in their training of leaders. We address these challenges by proposing to create a leadership training platform to be used by LDP workers to train the next generation of diverse leaders to adapt to an online setting. The proposed platform leverages Artificial Intelligence (AI) models to provide real-time feedback to leaders. An interactive dashboard including visualization and storytelling will be developed as the front-end to provide information on leaders\u2019 performance to improve their leadership signals. The proposed work will have practical implications for numerous stakeholders. First, LDP will be able to effectively train current and emerging leaders to work in the virtual setting. Second, future leaders and their followers will benefit from the improved training. Third, the approach aims to substantially reduce discrimination in leadership evaluations by creating objective and diverse training data.\r\n\r\nThe current scope of work within the award is focused on creating partnerships and further developing the proposed work. The award will support on-site and virtual meetings and observations of end users of the proposed AI platform (i.e., LDPs). A leadership and data science workshop will be held to share and develop ideas. LDPs will participate for training and networking purposes and to provide feedback. A consultant will be engaged to develop the project plan. Graduate students will assist in additional analytic model building and the creation of study materials for the project and subsequent data collections (e.g., developing the experimental protocol; creating recruitment and training materials).\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Srijan",
   "pi_last_name": "Kumar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Srijan Kumar",
   "pi_email_addr": "srijan@gatech.edu",
   "nsf_id": "000821085",
   "pi_start_date": "2021-09-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue NW",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "803100",
   "pgm_ele_name": "SoO-Science Of Organizations"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 35904.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p2\">The purpose of the proposed effort is to aid future leadership development professionals (LDP) in their work to train a diverse pipeline of leaders. The future of work involves a virtual context for many occupations. Hence, two new challenges for LDP workers are to train leaders to perform effectively in a virtual context and to leverage future technology in their training of leaders. We address these challenges by proposing to create a leadership training platform to be used by LDP workers to train the next generation of diverse leaders to adapt to an online setting. The proposed platform leverages Artificial Intelligence (AI) models to provide real-time feedback to leaders. An interactive dashboard including visualization and storytelling will be developed as the front-end to provide information on leaders&rsquo; performance to improve their leadership signals. The proposed work will have practical implications for numerous stakeholders. First, LDP will be able to effectively train current and emerging leaders to work in the virtual setting. Second, future leaders and their followers will benefit from the improved training. Third, the approach aims to substantially reduce discrimination in leadership evaluations by creating objective and diverse training data.</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p2\">The current scope of work within the award is focused on creating partnerships and further developing the proposed work. The award will support on-site and virtual meetings and observations of end users of the proposed AI platform (i.e., LDPs). A leadership and data science workshop will be held to share and develop ideas. LDPs will participate for training and networking purposes and to provide feedback. A consultant will be engaged to develop the project plan. Graduate students will assist in additional analytic model building and the creation of study materials for the project and subsequent data collections (e.g., developing the experimental protocol; creating recruitment and training materials).</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p2\">In this period, we focused on creating multimodal models for classification and prediction tasks. A key necessity of these models is to be accurate as well as robust to errors.&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p2\">We benchmarked the accuracy of a late fusion-based multimodal model on a social media-based content classification dataset.</p>\n<p class=\"p2\">The datasets used are:</p>\n<p class=\"p2\">1) Multimodal crisis humanitarian dataset, which comprises 7, 216 Twitter posts (images + text) that are categorized into 5 humanitarian categories. The dataset covers 7 crises that occurred in 2017 all over the globe (3 hurricanes, 2 earthquakes, 1 wildfre and foods). We formulate the task of humanitarian information detection as a multi-class classifcation problem.&nbsp;</p>\n<p class=\"p2\">2)&nbsp;Multimodal emotion dataset: we collect the dataset introduced by Duong, Lebret, and Aberer ( 2017) for the task of multimodal emotion detection. The dataset comprises Reddit posts categorized into 4 emotion-related classes, creepy, gore, happy, and rage, where each post contains an image and text. We crawled the images from Reddit using the URLs provided by the authors.</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p2\">We compared&nbsp;DisilBERT and mBERT for unimodal models and created late fusion-based multimodal models.&nbsp;</p>\n<p class=\"p2\"><br />Experiments showed that using multimodality increased the F1 classification score by 0.01 to 0.06 points on the two datasets, resulting in F1 scores between 0.75 and 0.85. This shows the usefulness of the multimodal models and their universality.&nbsp;</p>\n<p class=\"p1\"><em>&nbsp;</em></p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p2\">The findings from our experiments highlight the applicability and generalizability of multimodal models, which can be used to build multimodal models for leadership assessment, development, and training.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 07/15/2024<br>\nModified by: Srijan&nbsp;Kumar</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe purpose of the proposed effort is to aid future leadership development professionals (LDP) in their work to train a diverse pipeline of leaders. The future of work involves a virtual context for many occupations. Hence, two new challenges for LDP workers are to train leaders to perform effectively in a virtual context and to leverage future technology in their training of leaders. We address these challenges by proposing to create a leadership training platform to be used by LDP workers to train the next generation of diverse leaders to adapt to an online setting. The proposed platform leverages Artificial Intelligence (AI) models to provide real-time feedback to leaders. An interactive dashboard including visualization and storytelling will be developed as the front-end to provide information on leaders performance to improve their leadership signals. The proposed work will have practical implications for numerous stakeholders. First, LDP will be able to effectively train current and emerging leaders to work in the virtual setting. Second, future leaders and their followers will benefit from the improved training. Third, the approach aims to substantially reduce discrimination in leadership evaluations by creating objective and diverse training data.\n\n\n\n\n\nThe current scope of work within the award is focused on creating partnerships and further developing the proposed work. The award will support on-site and virtual meetings and observations of end users of the proposed AI platform (i.e., LDPs). A leadership and data science workshop will be held to share and develop ideas. LDPs will participate for training and networking purposes and to provide feedback. A consultant will be engaged to develop the project plan. Graduate students will assist in additional analytic model building and the creation of study materials for the project and subsequent data collections (e.g., developing the experimental protocol; creating recruitment and training materials).\n\n\n\n\n\n\n\n\n\n\n\nIn this period, we focused on creating multimodal models for classification and prediction tasks. A key necessity of these models is to be accurate as well as robust to errors.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe benchmarked the accuracy of a late fusion-based multimodal model on a social media-based content classification dataset.\n\n\nThe datasets used are:\n\n\n1) Multimodal crisis humanitarian dataset, which comprises 7, 216 Twitter posts (images + text) that are categorized into 5 humanitarian categories. The dataset covers 7 crises that occurred in 2017 all over the globe (3 hurricanes, 2 earthquakes, 1 wildfre and foods). We formulate the task of humanitarian information detection as a multi-class classifcation problem.\n\n\n2)Multimodal emotion dataset: we collect the dataset introduced by Duong, Lebret, and Aberer ( 2017) for the task of multimodal emotion detection. The dataset comprises Reddit posts categorized into 4 emotion-related classes, creepy, gore, happy, and rage, where each post contains an image and text. We crawled the images from Reddit using the URLs provided by the authors.\n\n\n\n\n\nWe comparedDisilBERT and mBERT for unimodal models and created late fusion-based multimodal models.\n\n\n\nExperiments showed that using multimodality increased the F1 classification score by 0.01 to 0.06 points on the two datasets, resulting in F1 scores between 0.75 and 0.85. This shows the usefulness of the multimodal models and their universality.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe findings from our experiments highlight the applicability and generalizability of multimodal models, which can be used to build multimodal models for leadership assessment, development, and training.\n\n\n\t\t\t\t\tLast Modified: 07/15/2024\n\n\t\t\t\t\tSubmitted by: SrijanKumar\n"
 }
}