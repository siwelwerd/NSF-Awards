{
 "awd_id": "2115040",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: EAGER SaTC-EDU:  Artificial Intelligence and Cybersecurity: From Research to the Classroom",
 "cfda_num": "47.076",
 "org_code": "11010000",
 "po_phone": "7032922677",
 "po_email": "liyang@nsf.gov",
 "po_sign_block_name": "Li Yang",
 "awd_eff_date": "2021-05-01",
 "awd_exp_date": "2024-04-30",
 "tot_intn_awd_amt": 80000.0,
 "awd_amount": 80000.0,
 "awd_min_amd_letter_date": "2021-04-16",
 "awd_max_amd_letter_date": "2021-04-16",
 "awd_abstract_narration": "One of the most critical security challenges of the 21st century is protecting the cyber-physical systems that manage and control our infrastructure, vehicles, homes, and personal devices as well as the information that they store, use and exchange.  Artificial intelligence (AI) and machine learning-based tools can help human analysts sort through large volumes of data to determine if an attack on these systems has happened.  Yet, AI components are also vulnerable to attacks, and require development of techniques to make them more robust. This collaborative project between the University of Maryland Baltimore County (UMBC) and the University of Illinois addresses the research and educational aspects of combining AI and cybersecurity. Educational and training materials will be developed for use by college and university instructors and students and by cybersecurity and AI professionals. These materials will address how AI can improve security systems and how cybersecurity analytics can protect AI systems. In addition, the project will recruit students from groups that have been traditionally underrepresented in computing. \r\n\r\nThis project has three interrelated topics. The first focuses on education and extends the project team\u2019s existing cybersecurity concept inventory to include relevant AI-related concepts. Student knowledge and understanding of cybersecurity and AI relatedness will be assessed before and after taking AI or cybersecurity courses.  Educational materials and projects  will also be created to demonstrate  how AI can be applied to cybersecurity problems and how cybersecurity tools can protect AI systems from attack. The second topic explores how the latest AI tools can support cybersecurity tasks. The creation and maintenance of semantic knowledge graphs of cyberthreat information will be studied and used to support reinforcement learning systems that are better at detecting the presence of malware in a host. The third topic focuses on finding new ways that cybersecurity tools can protect AI systems from becoming compromised by attacks such as data poisoning. Cyberthreat knowledge graphs and neural networks will be used to detect and eliminate likely disinformation from data used to train AI-based cybersecurity systems. This aspect of the project has applications beyond cybersecurity, such as countering disinformation. \r\n\r\nThis project is supported by the Secure and Trustworthy Cyberspace (SaTC) program, which funds proposals that address cybersecurity and privacy, and in this case specifically cybersecurity education. The SaTC program aligns with the Federal Cybersecurity Research and Development Strategic Plan and the National Privacy Research Strategy to protect and preserve the growing social and economic benefits of cyber systems while ensuring security and privacy.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DGE",
 "org_div_long_name": "Division Of Graduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Geoffrey",
   "pi_last_name": "Herman",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Geoffrey L Herman",
   "pi_email_addr": "glherman@illinois.edu",
   "nsf_id": "000592249",
   "pi_start_date": "2021-04-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "Board of Trustees of the University of Illinois",
  "perf_str_addr": "506 S. Wright Street",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "093Z",
   "pgm_ref_txt": "AI Education/Workforce Develop"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0421",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002122DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 80000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The problem of providing adequate security for computing systems affects everyone as computing systems are in almost every part of our lives. At the same time, Artificial Intelligence (AI) systems have incrceased the number of ways that these systems can be attacked and the ways that they can be protected. This project povides groundwork to help inform how we will be able to best educate our students as they prepare for this new and increasingly complex field. By creating educational activities and assessments, we can both provide help students prepare for this world and help instructors determine how to well their students are learning the core concepts.</span></p>\n<p>Through a series of surveys and interviews, we identified three critical issues that instructors will need to consider as they design courses and programs to help students deal with new reality.&nbsp;</p>\n<p>Security Applied to AI: Students will need to be trained to think about how AI systems can be vulnerable or must be defended. For example, can someone tamper with the data that is used to train an AI system so that it provides misinformation or recommends outcomes that benefit nefarious actors.</p>\n<p>AI Enhancements in Security: Students will need to be trained on how to use AI systems to enhance security processes. For example, how can AI be leveraged to detect fraudalent transactions or when an actor is trying to impersonate someone else to gain access to data.</p>\n<p>Prerequisite Knowledge: Increasingly, students need training in both AI and cybersecurity to be successful and to achieve the goals above. Institutions should explore ways to encourage students to take basic cybersecurity and basic AI courses as well as courses that explore the intersection of AI and cybersecurity. These courses will need to be continuously updated with the latest research as AI and its effects on cybersecurity continue to rapidly evolve.</p><br>\n<p>\n Last Modified: 08/02/2024<br>\nModified by: Geoffrey&nbsp;L&nbsp;Herman</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe problem of providing adequate security for computing systems affects everyone as computing systems are in almost every part of our lives. At the same time, Artificial Intelligence (AI) systems have incrceased the number of ways that these systems can be attacked and the ways that they can be protected. This project povides groundwork to help inform how we will be able to best educate our students as they prepare for this new and increasingly complex field. By creating educational activities and assessments, we can both provide help students prepare for this world and help instructors determine how to well their students are learning the core concepts.\n\n\nThrough a series of surveys and interviews, we identified three critical issues that instructors will need to consider as they design courses and programs to help students deal with new reality.\n\n\nSecurity Applied to AI: Students will need to be trained to think about how AI systems can be vulnerable or must be defended. For example, can someone tamper with the data that is used to train an AI system so that it provides misinformation or recommends outcomes that benefit nefarious actors.\n\n\nAI Enhancements in Security: Students will need to be trained on how to use AI systems to enhance security processes. For example, how can AI be leveraged to detect fraudalent transactions or when an actor is trying to impersonate someone else to gain access to data.\n\n\nPrerequisite Knowledge: Increasingly, students need training in both AI and cybersecurity to be successful and to achieve the goals above. Institutions should explore ways to encourage students to take basic cybersecurity and basic AI courses as well as courses that explore the intersection of AI and cybersecurity. These courses will need to be continuously updated with the latest research as AI and its effects on cybersecurity continue to rapidly evolve.\t\t\t\t\tLast Modified: 08/02/2024\n\n\t\t\t\t\tSubmitted by: GeoffreyLHerman\n"
 }
}