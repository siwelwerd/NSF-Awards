{
 "awd_id": "2135309",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: SHF: Small: Learning Fault Tolerance at Scale",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2022-01-01",
 "awd_exp_date": "2024-12-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2021-08-31",
 "awd_max_amd_letter_date": "2021-08-31",
 "awd_abstract_narration": "In computer-aided design and analysis of engineered systems such as automobiles or semiconductor chips, computational models are simulated on high-performance computers to characterize and evaluate key attributes. The sheer scale of such high-performance computing systems, e.g., over 20 billion transistors in Summit (one of the world's fastest supercomputers), increases the likelihood of transient hardware faults from events such as cosmic radiation or processor-chip voltage fluctuations. The likelihood of such errors and their negative impacts are further increased as such simulations are typically long running, and the corruption of a single data field or variable may require weeks to months of re-computations before critical decisions can be made. This project will develop automated approaches that bring fault tolerance to hardware faults for such applications which are widely used not only across multiple industrial sectors but to also increase the predictive power of climate or weather models to aid critical decision making. \r\n\r\nTraditional fault-tolerant schemes can be either application-specific, requiring significant programmer effort to redesign or customize large-scale software, or application-agnostic where all or most data are redundantly stored periodically to allow for recovery, thus limiting their scalability due to their significant memory and processing overheads. This project seeks to address these limitations by providing a theoretical foundation for a new class of fault-tolerant schemes that are suitable for the broad array of applications based on iterative numerical simulations that evolve over time on discretized spatial domains. This project is based on the premise that in such physics-based applications, the rate of change of the solution vector components across time steps (iterations) and spatial domains is a key metric to automatically identifying the critical computational variables, monitoring their evolution, and dynamically selecting the type of safeguarding techniques that should be applied. The investigators will pursue three key directions: (i) characterizing the intrinsic resiliency of the application by developing resiliency gradient metrics, (ii) developing and testing fault-tolerance schemes that adapt the level and type of protection to the resiliency gradient with the goal of reducing computational overheads and increasing scalability, and (iii) constructing an automatic online decision-based learning framework for adaptively selecting fault-tolerance methods in relation to the system's ability to use approximate computing and co-scheduling techniques. The investigators will also work closely with application and runtime system developers to seek broader use of this fault tolerance framework, develop specialized undergraduate and graduate curriculum for student training, and offer research experiences to high school students.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Padma",
   "pi_last_name": "Raghavan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Padma Raghavan",
   "pi_email_addr": "padma.raghavan@vanderbilt.edu",
   "nsf_id": "000097691",
   "pi_start_date": "2021-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Hongyang",
   "pi_last_name": "Sun",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hongyang Sun",
   "pi_email_addr": "hongyang.sun@ku.edu",
   "nsf_id": "000759577",
   "pi_start_date": "2021-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Vanderbilt University",
  "inst_street_address": "110 21ST AVE S",
  "inst_street_address_2": "",
  "inst_city_name": "NASHVILLE",
  "inst_state_code": "TN",
  "inst_state_name": "Tennessee",
  "inst_phone_num": "6153222631",
  "inst_zip_code": "372032416",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "TN05",
  "org_lgl_bus_name": "VANDERBILT UNIVERSITY",
  "org_prnt_uei_num": "K9AHBDTKCB55",
  "org_uei_num": "GTNBNWXJ12D5"
 },
 "perf_inst": {
  "perf_inst_name": "Vanderbilt University",
  "perf_str_addr": "Sponsored Programs Administratio",
  "perf_city_name": "Nashville",
  "perf_st_code": "TN",
  "perf_st_name": "Tennessee",
  "perf_zip_code": "372350002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "TN07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-fee11917-7fff-ad40-262f-18947ca5cdf7\"> </span></p>\r\n<p dir=\"ltr\"><span>The major goal of this project is to create large-scale scientific applications on high-performance computers, aka, supercomputers, that are tolerant to hard faults (e.g., hardware malfunctioning, crashes) and silent errors (e.g., undetectable double bit flips). As today&rsquo;s supercomputers reach unprecedented scales, these faults and errors are becoming increasingly common. Ensuring fault tolerance is essential for maintaining the reliability, accuracy, and efficiency of scientific simulations and computations. By developing robust fault-tolerant techniques, we can enable applications to continue running despite failures, minimizing data loss and reducing the need for costly recomputations.</span></p>\r\n<p dir=\"ltr\"><span>Traditional fault tolerance techniques often rely on replicating the entire computation to ensure detection and/or correction of faults, which incur significant overhead. In the project, we seek intelligent solutions that leverage application-specific characteristics to decide what needs to be safeguarded in the presence of faults, thereby substantially reducing the overhead. The research outcome has established a resilience framework by which scientific applications can more efficiently tolerate and recover from hard faults and silent errors. Some of our important findings include the following:</span></p>\r\n<ul>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\"><span>We identified new metrics, particularly for sparse linear solvers &ndash; an important routine in scientific applications &ndash; that can capture the impacts of faults on application performance. Leveraging these metrics while performing </span><span>selective protection for the critical components of iterative solvers</span><span> can significantly reduce the resilience overhead.&nbsp;</span></p>\r\n</li>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\"><span>We provided strong evidence that effective fault tolerance at the system level can be achieved through a combined algorithmic approach and machine learning predictions. This opens new research opportunities in several promising directions for other types of scientific simulations and machine-learning domains.&nbsp;&nbsp;</span></p>\r\n</li>\r\n<li dir=\"ltr\">\r\n<p dir=\"ltr\"><span>Our results related to multi-precision and online resource management demonstrate that we can reduce application runtime using lower-precision calculations for replication or through more effective task scheduling mechanisms to achieve a high level of fault tolerance and competitive runtime performance.&nbsp;</span></p>\r\n</li>\r\n</ul>\r\n<p dir=\"ltr\"><span>Our research findings will significantly influence the design and implementation of future fault tolerance and resource management algorithms. They will also contribute to increasing the energy efficiency of supercomputers, enhancing system resilience, and lowering the costs associated with running large-scale scientific simulations or training large AI models.</span></p>\r\n<p dir=\"ltr\"><span>The project has led to multiple peer-reviewed publications in top venues related to high-performance computing and has provided research opportunities for several graduate and undergraduate students. The results have been disseminated through seminars and conference presentations, as well as integrated into the courses we teach at our institutions.</span></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 04/03/2025<br>\nModified by: Hongyang&nbsp;Sun</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \r\n\n\nThe major goal of this project is to create large-scale scientific applications on high-performance computers, aka, supercomputers, that are tolerant to hard faults (e.g., hardware malfunctioning, crashes) and silent errors (e.g., undetectable double bit flips). As todays supercomputers reach unprecedented scales, these faults and errors are becoming increasingly common. Ensuring fault tolerance is essential for maintaining the reliability, accuracy, and efficiency of scientific simulations and computations. By developing robust fault-tolerant techniques, we can enable applications to continue running despite failures, minimizing data loss and reducing the need for costly recomputations.\r\n\n\nTraditional fault tolerance techniques often rely on replicating the entire computation to ensure detection and/or correction of faults, which incur significant overhead. In the project, we seek intelligent solutions that leverage application-specific characteristics to decide what needs to be safeguarded in the presence of faults, thereby substantially reducing the overhead. The research outcome has established a resilience framework by which scientific applications can more efficiently tolerate and recover from hard faults and silent errors. Some of our important findings include the following:\r\n\r\n\r\n\n\nWe identified new metrics, particularly for sparse linear solvers  an important routine in scientific applications  that can capture the impacts of faults on application performance. Leveraging these metrics while performing selective protection for the critical components of iterative solvers can significantly reduce the resilience overhead.\r\n\r\n\r\n\n\nWe provided strong evidence that effective fault tolerance at the system level can be achieved through a combined algorithmic approach and machine learning predictions. This opens new research opportunities in several promising directions for other types of scientific simulations and machine-learning domains.\r\n\r\n\r\n\n\nOur results related to multi-precision and online resource management demonstrate that we can reduce application runtime using lower-precision calculations for replication or through more effective task scheduling mechanisms to achieve a high level of fault tolerance and competitive runtime performance.\r\n\r\n\r\n\n\nOur research findings will significantly influence the design and implementation of future fault tolerance and resource management algorithms. They will also contribute to increasing the energy efficiency of supercomputers, enhancing system resilience, and lowering the costs associated with running large-scale scientific simulations or training large AI models.\r\n\n\nThe project has led to multiple peer-reviewed publications in top venues related to high-performance computing and has provided research opportunities for several graduate and undergraduate students. The results have been disseminated through seminars and conference presentations, as well as integrated into the courses we teach at our institutions.\r\n\n\n\t\t\t\t\tLast Modified: 04/03/2025\n\n\t\t\t\t\tSubmitted by: HongyangSun\n"
 }
}