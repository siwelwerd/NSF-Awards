{
 "awd_id": "2112926",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Using and Gathering Data for Efficient Batch Reinforcement Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924286",
 "po_email": "yduan@nsf.gov",
 "po_sign_block_name": "Andy Duan",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2021-07-23",
 "awd_max_amd_letter_date": "2021-07-23",
 "awd_abstract_narration": "Imagine if we could provide each child with the right support, at the right time, for helping them learn best, or to ensure a diabetes patient is being given the best interventions to help them manage their chronic condition over time at home. Unfortunately such personalization is expensive. More scalable computerized approaches can lack the real-time information needed to provide effective personalization, or the ability to specialize interventions. However, the huge rise in more user-friendly software tools means that it is now possible to do such targeted personalization in a broad array of settings.  This research will  develop new methods for leveraging existing data, and create algorithms to acquire new data in a way that is compatible with the limitations of common systems. This work could help enable personalized interventions across a much broader array of applications than is currently benefiting from such approaches. The research will be particularly focused on the technical challenges arising from areas like education and healthcare.\r\n\r\nMore specifically, this research will create data efficient algorithms and statistical estimators for leveraging past datasets about decisions made and their outcomes, and for acquiring new batch data that might lead to better results to create decision policies-- mappings from features describing the current context to a particular decision or intervention. In particular, the project will center on developing new algorithms that optimize policies with data efficient, minimal assumption lower statistical bounds on their future performance; bound the benefit of gathering a budget of additional data; and, inspired by insights from optimal experimental design, create algorithms for constructing non-adaptive policies that can be used to gather data that then can be leveraged to identify a near-optimal decision policy. The research will focus on both settings where a single decision is made for a particular context, and where a sequence of decisions are made and the decisions made impact the next context observed (common in sequential decision making under uncertainty processes).\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Emma",
   "pi_last_name": "Brunskill",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Emma Brunskill",
   "pi_email_addr": "ebrun@cs.stanford.edu",
   "nsf_id": "000514969",
   "pi_start_date": "2021-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "353 Jane Stanford Way",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943055008",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Consider an intelligent tutoring system that selects the best teaching activity to support a student&rsquo;s learning, or a fitness mobile application that selects the best nudge or activity to support a user&rsquo;s fitness journey. Building such systems by hand can be brittle and labor-intensive. Fortunately, reinforcement learning is a subfield of machine learning that automatically learns strategies for when and which intervention to provide (e.g., which teaching activity) directly from data. Unfortunately, historically, most reinforcement learning algorithms require massive amounts of data. Our research focused on creating new reinforcement learning methods that require less data to learn effective personalized decision policies. We made a number of contributions, including:</p>\r\n<p>&nbsp;</p>\r\n<ul>\r\n<li>\r\n<p><strong>Algorithms for evaluating potential future policies:</strong> These algorithms take historical data about past interventions (such as providing different activities in educational software) and their outcomes (such as student engagement with the software or student learning outcomes) to evaluate how well various future decision policies might perform (e.g., new strategies for providing educational activities). Our work introduced new algorithms that are more robust and/or more accurate than prior approaches.</p>\r\n</li>\r\n</ul>\r\n<p>&nbsp;</p>\r\n<ul>\r\n<li>\r\n<p><strong>Algorithms for reducing data requirements:</strong> While many existing AI methods try to optimize performance in the course of learning, our work addresses situations where it is important to minimize the amount of data needed to identify a good personalized policy. Our new algorithms strategically gather data and come with formal theoretical results showing when they outperform other methods. We also introduced new algorithms that balance multiple objectives while learning.</p>\r\n</li>\r\n</ul>\r\n<p>&nbsp;</p>\r\n<ul>\r\n<li>\r\n<p><strong>Experimental validations in education and healthcare:</strong> We used our new methodologies to personalize educational software designed to teach children about the concept of volume. An experimental study suggested that our approaches are particularly promising for students who have low initial knowledge of how to compute volume. We also evaluated our method using an existing dataset on sepsis treatment in an intensive care unit.</p>\r\n</li>\r\n</ul>\r\n<p>&nbsp;</p>\r\n<p>Our findings were shared with the broader community through peer-reviewed publications and presentations.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 03/18/2025<br>\nModified by: Emma&nbsp;Brunskill</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nConsider an intelligent tutoring system that selects the best teaching activity to support a students learning, or a fitness mobile application that selects the best nudge or activity to support a users fitness journey. Building such systems by hand can be brittle and labor-intensive. Fortunately, reinforcement learning is a subfield of machine learning that automatically learns strategies for when and which intervention to provide (e.g., which teaching activity) directly from data. Unfortunately, historically, most reinforcement learning algorithms require massive amounts of data. Our research focused on creating new reinforcement learning methods that require less data to learn effective personalized decision policies. We made a number of contributions, including:\r\n\n\n\r\n\r\n\r\n\n\nAlgorithms for evaluating potential future policies: These algorithms take historical data about past interventions (such as providing different activities in educational software) and their outcomes (such as student engagement with the software or student learning outcomes) to evaluate how well various future decision policies might perform (e.g., new strategies for providing educational activities). Our work introduced new algorithms that are more robust and/or more accurate than prior approaches.\r\n\r\n\r\n\n\n\r\n\r\n\r\n\n\nAlgorithms for reducing data requirements: While many existing AI methods try to optimize performance in the course of learning, our work addresses situations where it is important to minimize the amount of data needed to identify a good personalized policy. Our new algorithms strategically gather data and come with formal theoretical results showing when they outperform other methods. We also introduced new algorithms that balance multiple objectives while learning.\r\n\r\n\r\n\n\n\r\n\r\n\r\n\n\nExperimental validations in education and healthcare: We used our new methodologies to personalize educational software designed to teach children about the concept of volume. An experimental study suggested that our approaches are particularly promising for students who have low initial knowledge of how to compute volume. We also evaluated our method using an existing dataset on sepsis treatment in an intensive care unit.\r\n\r\n\r\n\n\n\r\n\n\nOur findings were shared with the broader community through peer-reviewed publications and presentations.\r\n\n\n\t\t\t\t\tLast Modified: 03/18/2025\n\n\t\t\t\t\tSubmitted by: EmmaBrunskill\n"
 }
}