{
 "awd_id": "2040929",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FAI: Fair AI in Public Policy - Achieving Fair Societal Outcomes in ML Applications to Education, Criminal Justice, and Health and Human Services",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2021-04-01",
 "awd_exp_date": "2024-03-31",
 "tot_intn_awd_amt": 375000.0,
 "awd_amount": 391000.0,
 "awd_min_amd_letter_date": "2021-01-25",
 "awd_max_amd_letter_date": "2021-06-29",
 "awd_abstract_narration": "This project advances the potential for Machine Learning (ML) to serve the social good by improving understanding of how to apply ML methods to high-stakes, real-world settings in fair and responsible ways. Government agencies and nonprofits use ML tools to inform consequential decisions. However, a growing number of academics, journalists, and policy-makers have expressed apprehension regarding the prominent (and growing) role that ML technology plays in the allocation of social benefits and burdens across diverse policy areas, including child welfare, health, and criminal justice. Many of these decisions impart long-lasting effects on the lives of their subjects. When applied inappropriately, they can harm already vulnerable and historically-disadvantaged communities. These concerns have given rise to a growing number of research efforts aimed at understanding disparities and developing tools that aim to minimize or mitigate them. To date, these efforts have been limited in their impact on real-world applications by focusing too narrowly on abstract technical concepts and computational methods at the expense of addressing the decisions and societal outcomes these methods affect. Such efforts also commonly fail to situate the work in real-world contexts or to draw input from the communities most affected by ML-assisted decision-making. This project seeks to fill these gaps in current research and practice in close partnership with government agencies and nonprofits.\r\n\r\nThis project draws upon disciplinary perspectives from computer science, statistics, and public policy. Its first aim explores the mapping between policy goals and ML formulations. This aim focuses on what facts must be consulted to make coherent determinations about fairness, and anchors those assessments of fairness to near- and long-term societal outcomes for people subject to decisions. This work offers practical ways to engage with partners, policymakers, and affected communities to translate desired fairness goals into computationally tractable measures. Itssecond aim investigates fairness through the entire ML decision-support pipeline, from policy goals to data to models to interventions. It explores how different approaches to data collection, imputation, model selection, and evaluation impact the fairness of resulting tools. The project\u2019s third aim is concerned with modeling the long-term societal outcomes of ML-assisted decision-making in policy domains, ultimately to guide a grounded approach to designing fairness-promoting methods. The project\u2019s over-arching objective is to bridge the divide between active research in fair ML and applications in policy domains. It does that through innovative teaching and training activities, broadening the participation of under-represented groups in research and technology design, enhancing scientific and technological understanding among the public, practitioners, and legislators, and delivering a direct positive impact with partner agencies.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hoda",
   "pi_last_name": "Heidari",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hoda Heidari",
   "pi_email_addr": "hoda.heidari@gmail.com",
   "nsf_id": "000832089",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rayid",
   "pi_last_name": "Ghani",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rayid Ghani",
   "pi_email_addr": "rayid@cmu.edu",
   "nsf_id": "000663876",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "OLEXANDRA",
   "pi_last_name": "CHOULDECHOVA",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "OLEXANDRA CHOULDECHOVA",
   "pi_email_addr": "achoulde@andrew.cmu.edu",
   "nsf_id": "000692997",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Zachary",
   "pi_last_name": "Lipton",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Zachary C Lipton",
   "pi_email_addr": "zlipton@cmu.edu",
   "nsf_id": "000784704",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Rodolfa",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher T Rodolfa",
   "pi_email_addr": "krodolfa@cmu.edu",
   "nsf_id": "000832335",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "114Y00",
   "pgm_ele_name": "Fairness in Artificial Intelli"
  },
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 391000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-c2745cf9-7fff-6208-65ee-53eea6b927b9\"> </span></p>\r\n<h3 dir=\"ltr\"><span>Bridging AI and Society: Our Mission for Safe and Effective AI</span></h3>\r\n<p dir=\"ltr\"><span>In an era where Artificial Intelligence (AI) is increasingly influencing critical aspects of society, our project set out to ensure that AI can be effectively and responsibly applied to data-rich societal domains&mdash;without amplifying undue harm or disparities. By integrating expertise from computer science, statistics, and public policy, we developed methods, tools, and guidelines that close the gap between AI's potential and its real-world applicability.</span></p>\r\n<h3 dir=\"ltr\"><span>Key Research Areas</span></h3>\r\n<h4 dir=\"ltr\"><span>1. Translating Societal Goals into AI Solutions</span></h4>\r\n<p dir=\"ltr\"><span>How can we align AI decision-making with the diverse societal and policy-level goals of different communities? For example, what fairness means can vary significantly depending on cultural, legal, and ethical perspectives. Our research found that existing methods for capturing these perspectives were inadequate. In response, we designed better ways to engage with policymakers, affected communities, and other AI stakeholders. One of our key contributions was the </span><span>AI Failure Cards</span><span>, a tool designed to help communities understand AI&rsquo;s risks and share their own experiences and preferred strategies for harm mitigation in AI-driven decision-making.</span></p>\r\n<h4 dir=\"ltr\"><span>2. Reducing Harm Throughout the AI Lifecycle</span></h4>\r\n<p dir=\"ltr\"><span>From initial goal-setting to data collection, model design, and deployment, AI systems can introduce unintended harms at every stage. Our research focused on identifying critical intervention points to prevent such issues before they arise. A major outcome of this work was the </span><span>Situate-AI Guidebook</span><span>, developed in collaboration with local and state governments. This guidebook provides a structured framework for evaluating AI projects early on&mdash;helping decision-makers assess their goals, legal and societal constraints, data limitations, and governance requirements before committing to AI-based solutions.</span></p>\r\n<h4 dir=\"ltr\"><span>3. Understanding AI&rsquo;s Real-World Impact</span></h4>\r\n<p dir=\"ltr\"><span>Even the most well-designed AI tools can fail if human decision-makers don&rsquo;t trust or properly integrate them into their workflows. Through our research, we identified key factors that influence AI adoption, including user perceptions, potential liability concerns, and the broader interests of stakeholders. We also studied why some algorithmic tools are ultimately abandoned or decommissioned, providing insights into how to improve accountability and long-term success in AI implementation.</span></p>\r\n<h3 dir=\"ltr\"><span>Advancing AI with a Multidisciplinary Approach</span></h3>\r\n<p dir=\"ltr\"><span>Creating fair and effective AI systems requires more than just technical expertise&mdash;it demands an understanding of public policy, economics, moral philosophy, and human behavior. Our team worked closely with experts across these fields, as well as real-world stakeholders, to ensure AI solutions address genuine societal needs rather than just technical challenges.</span></p>\r\n<h3 dir=\"ltr\"><span>Impact and Future Directions</span></h3>\r\n<p dir=\"ltr\"><span>Our findings offer practical insights for a wide range of AI stakeholders, including policymakers, developers, and the communities affected by AI-driven decisions. By fostering transparency, fairness, and accountability, we aim to empower society to harness AI&rsquo;s benefits while minimizing its risks.</span></p><br>\n<p>\n Last Modified: 01/30/2025<br>\nModified by: Hoda&nbsp;Heidari</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \r\nBridging AI and Society: Our Mission for Safe and Effective AI\r\n\n\nIn an era where Artificial Intelligence (AI) is increasingly influencing critical aspects of society, our project set out to ensure that AI can be effectively and responsibly applied to data-rich societal domainswithout amplifying undue harm or disparities. By integrating expertise from computer science, statistics, and public policy, we developed methods, tools, and guidelines that close the gap between AI's potential and its real-world applicability.\r\nKey Research Areas\r\n1. Translating Societal Goals into AI Solutions\r\n\n\nHow can we align AI decision-making with the diverse societal and policy-level goals of different communities? For example, what fairness means can vary significantly depending on cultural, legal, and ethical perspectives. Our research found that existing methods for capturing these perspectives were inadequate. In response, we designed better ways to engage with policymakers, affected communities, and other AI stakeholders. One of our key contributions was the AI Failure Cards, a tool designed to help communities understand AIs risks and share their own experiences and preferred strategies for harm mitigation in AI-driven decision-making.\r\n2. Reducing Harm Throughout the AI Lifecycle\r\n\n\nFrom initial goal-setting to data collection, model design, and deployment, AI systems can introduce unintended harms at every stage. Our research focused on identifying critical intervention points to prevent such issues before they arise. A major outcome of this work was the Situate-AI Guidebook, developed in collaboration with local and state governments. This guidebook provides a structured framework for evaluating AI projects early onhelping decision-makers assess their goals, legal and societal constraints, data limitations, and governance requirements before committing to AI-based solutions.\r\n3. Understanding AIs Real-World Impact\r\n\n\nEven the most well-designed AI tools can fail if human decision-makers dont trust or properly integrate them into their workflows. Through our research, we identified key factors that influence AI adoption, including user perceptions, potential liability concerns, and the broader interests of stakeholders. We also studied why some algorithmic tools are ultimately abandoned or decommissioned, providing insights into how to improve accountability and long-term success in AI implementation.\r\nAdvancing AI with a Multidisciplinary Approach\r\n\n\nCreating fair and effective AI systems requires more than just technical expertiseit demands an understanding of public policy, economics, moral philosophy, and human behavior. Our team worked closely with experts across these fields, as well as real-world stakeholders, to ensure AI solutions address genuine societal needs rather than just technical challenges.\r\nImpact and Future Directions\r\n\n\nOur findings offer practical insights for a wide range of AI stakeholders, including policymakers, developers, and the communities affected by AI-driven decisions. By fostering transparency, fairness, and accountability, we aim to empower society to harness AIs benefits while minimizing its risks.\t\t\t\t\tLast Modified: 01/30/2025\n\n\t\t\t\t\tSubmitted by: HodaHeidari\n"
 }
}