{
 "awd_id": "2118737",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: PPoSS: Planning: Model-Driven Compiler Optimization and Algorithm-Architecture Co-Design for Scalable Machine Learning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Seung-Jong Park",
 "awd_eff_date": "2021-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 63000.0,
 "awd_amount": 63000.0,
 "awd_min_amd_letter_date": "2021-07-14",
 "awd_max_amd_letter_date": "2021-07-14",
 "awd_abstract_narration": "There is an inexorable need for increased computational performance and improved energy efficiency in the development and use of machine-learning (ML) models. Currently available frameworks for ML have limitations in developing non-traditional models, e.g., using tensor networks, as well as in developing and using models that are too large to fit in the physical memory of processors. The design of efficient hardware accelerators and the mapping of ML algorithms to them is another challenge. This planning project presents a plan of action to address these needs via advances to model-driven compiler optimization. The research conducted in this project is enhancing productivity, performance, and portability in developing software for ML. It is enabling new ML applications to be developed with high productivity, with high achieved performance, and performance-portability over a diverse set of hardware platforms. It is enabling greater \"democratization of ML\", permitting researchers who only have access to low-end hardware platforms to be able to run the largest models -- infeasible today due to limitations of existing ML frameworks. The project involves training activities tailored for K-12 students, undergraduate students, and graduate students. \r\n\r\nIn this planning project, the following primary technical directions are explored: (1) ML Algorithms: flexible new ML models, offering trade-offs between model size, model execution time, model accuracy, and energy efficiency; (2) Optimizing Compilers: advances in polyhedral compiler optimization to enable parametric tilesize optimization and code generation for diverse target platforms, including CPUs, GPUs, and accelerators; (3) ML Accelerators: new ML accelerator designs for sparse and dense operators, optimized for multiple criteria via comprehensive design space exploration. Broader impact aims of the project include the \"Democratization of AI\u201d, to enable state-of-the-art ML models to be used by all, on widely available non-state-of-the-art hardware. To achieve these goals, the project integrates expertise in computer architecture, optimizing compilers, ML algorithms, and high-performance computing.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Atanas",
   "pi_last_name": "Rountev",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Atanas Rountev",
   "pi_email_addr": "rountev@cse.ohio-state.edu",
   "nsf_id": "000191396",
   "pi_start_date": "2021-07-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio State University",
  "inst_street_address": "1960 KENNY RD",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBUS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "6146888735",
  "inst_zip_code": "432101016",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OH03",
  "org_lgl_bus_name": "OHIO STATE UNIVERSITY, THE",
  "org_prnt_uei_num": "MN4MDDMN8529",
  "org_uei_num": "DLWBSLWAJWR1"
 },
 "perf_inst": {
  "perf_inst_name": "Ohio State University",
  "perf_str_addr": "1960 Kenny Road",
  "perf_city_name": "Columbus",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "432101016",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OH03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 63000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Machine learning (ML) plays a critical role in a variety of fields, including image processing, natural language processing, data analytics, and scientific computation. A new generation of computer hardware, referred to as hardware accelerators, presents unprecedented opportunities for executing ML software with high speed and low energy usage. To realize these opportunities, many new technical challenges need to be solved. <br /><br />This 1-year planning project defined an ambitious research agenda for a comprehensive framework for efficient, scalable, and performance-portable computations on tensors, with emphasis on hardware accelerators as targeted hardware. Tensors are core ML data structures and are also heavily used in other areas such as scientific computing. The project also assembled a team of 10 researchers, in computer architecture, high-performance computing, programming languages and compilers, scientific computing, machine learning, and image analysis. These planning efforts led to the creation of a new 5-year research project that aims to pursue this research agenda via synergistic activities by team members.&nbsp;<br /><br />As part of the planning project, the following technical challenges were targeted and partially solved: (a) An automated approach to execute ML analysis of large images on hardware with limited memory. The resulting novel approach allows arbitrarily large images to be processed, irrespective of the hardware memory size. (b) An automated approach to create and solve performance models for algorithm-architecture co-design for a layer in an ML convolutional neural network. This new co-design optimization enables significant improvements over prior accelerator designs for both energy reduction and performance improvements; (c) A study of the popular MLIR compiler infrastructure, with focus on abstractions to represent tensor computations and to perform modeling of execution cost for a variety of target hardware. This is the initial step of translating the results of the research project into a popular software infrastructure where it can be easily accessible to other researchers and software developers.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/13/2023<br>\n\t\t\t\t\tModified by: Atanas&nbsp;Rountev</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMachine learning (ML) plays a critical role in a variety of fields, including image processing, natural language processing, data analytics, and scientific computation. A new generation of computer hardware, referred to as hardware accelerators, presents unprecedented opportunities for executing ML software with high speed and low energy usage. To realize these opportunities, many new technical challenges need to be solved. \n\nThis 1-year planning project defined an ambitious research agenda for a comprehensive framework for efficient, scalable, and performance-portable computations on tensors, with emphasis on hardware accelerators as targeted hardware. Tensors are core ML data structures and are also heavily used in other areas such as scientific computing. The project also assembled a team of 10 researchers, in computer architecture, high-performance computing, programming languages and compilers, scientific computing, machine learning, and image analysis. These planning efforts led to the creation of a new 5-year research project that aims to pursue this research agenda via synergistic activities by team members. \n\nAs part of the planning project, the following technical challenges were targeted and partially solved: (a) An automated approach to execute ML analysis of large images on hardware with limited memory. The resulting novel approach allows arbitrarily large images to be processed, irrespective of the hardware memory size. (b) An automated approach to create and solve performance models for algorithm-architecture co-design for a layer in an ML convolutional neural network. This new co-design optimization enables significant improvements over prior accelerator designs for both energy reduction and performance improvements; (c) A study of the popular MLIR compiler infrastructure, with focus on abstractions to represent tensor computations and to perform modeling of execution cost for a variety of target hardware. This is the initial step of translating the results of the research project into a popular software infrastructure where it can be easily accessible to other researchers and software developers.\n\n\t\t\t\t\tLast Modified: 06/13/2023\n\n\t\t\t\t\tSubmitted by: Atanas Rountev"
 }
}