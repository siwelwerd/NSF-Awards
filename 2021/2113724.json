{
 "awd_id": "2113724",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Learning Algorithms for Inverse Problems from Data: Statistical and Computational Foundations",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yulia Gel",
 "awd_eff_date": "2021-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2021-06-11",
 "awd_max_amd_letter_date": "2021-06-11",
 "awd_abstract_narration": "Methods for the solution of inverse problems arising in domains such as image analysis, the geosciences, computational genomics, and many others are designed based on a detailed understanding by a human analyst of the structure underlying the problem.  This project aims to develop new data-driven approaches to learning solution methods for inverse problems and to develop the associated statistical foundations. Specifically, the project will provide a new approach to data-driven design of learning regularizers, which can be computed or optimized within a specified computational budget, and come with statistical guarantees. The research will engage both graduate and undergraduate students and will be disseminated to a broader audience through the development of new courses.\r\n\r\nRegularization techniques are widely employed in the solution of model selection and statistical inverse problems because of their effectiveness in addressing difficulties due to ill-posedness, access to only a small number of observations, or the high dimensionality of the signal or model to be inferred. In their most common manifestation, these methods take the form of penalty functions added to the objective in optimization-based formulations. The design of the penalty function is based on prior domain-specific expertise about the particular model selection or inverse problem at hand, with a view to promoting a desired structure in the solution. This project will develop a framework for the construction of algorithms for inferential problems so as to address the following questions \u2013 What if we do not know in advance the structure we seek in our solution due to a lack of detailed domain knowledge? Can we identify a suitable regularizer directly from data rather than human-provided expertise? What are the fundamental limitations in terms of sample complexity and the amount of computational resources required in such a framework? Statistically, how do we provide confidence bounds for point estimates that lie in a collection of regularizers?\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Venkat",
   "pi_last_name": "Chandrasekaran",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Venkat Chandrasekaran",
   "pi_email_addr": "venkatc@caltech.edu",
   "nsf_id": "000618011",
   "pi_start_date": "2021-06-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "California Institute of Technology",
  "inst_street_address": "1200 E CALIFORNIA BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "PASADENA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6263956219",
  "inst_zip_code": "911250001",
  "inst_country_name": "United States",
  "cong_dist_code": "28",
  "st_cong_dist_code": "CA28",
  "org_lgl_bus_name": "CALIFORNIA INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "U2JMKHNS5TG4"
 },
 "perf_inst": {
  "perf_inst_name": "California Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "911250001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "28",
  "perf_st_cong_dist": "CA28",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The aim of this project was to develop the statistical and computational foundations of the question of learning regularizers from data.&nbsp; Regularization is a popular method for solving ill-posed inverse problems arising in statistics and signal processing.&nbsp; Regularizers are often derived via human-provided domain expertise in the context of a particular application, and they are useful for promoting a desired structure in the solution of an inverse problem.&nbsp; However, in many settings such prior expertise may not be available and regularizers must be learned from data.&nbsp; This project developed new methods for learning regularizers from data and identified some of the associated fundamental computational and statistical limitations.&nbsp; Some of the papers that were partially supported by this project include:</p>\n<p>--&nbsp;Model selection over partially ordered sets, Proceedings of the National Academy of Sciences, 2024</p>\n<p>-- Kronecker Product Approximation of Operators in Spectral Norm via Alternating SDP, SIAM Journal on Matrix Analysis and Applications, 2023</p>\n<p>--&nbsp;Terracini convexity, Mathematical Programming, 2023</p>\n<p>--&nbsp;Spectrahedral Regression, SIAM Journal on Optimization, 2023</p>\n<p>--&nbsp;Optimal Regularization for a Data Source, preprint</p>\n<p>--&nbsp;Controlling the False Discovery Rate in Subspace Selection, preprint</p>\n<p>--&nbsp;Free Descriptions of Convex Sets, preprint</p>\n<p>--&nbsp;Modeling groundwater levels in California's Central Valley by hierarchical Gaussian process and neural network regression, preprint</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/15/2024<br>\nModified by: Venkat&nbsp;Chandrasekaran</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe aim of this project was to develop the statistical and computational foundations of the question of learning regularizers from data. Regularization is a popular method for solving ill-posed inverse problems arising in statistics and signal processing. Regularizers are often derived via human-provided domain expertise in the context of a particular application, and they are useful for promoting a desired structure in the solution of an inverse problem. However, in many settings such prior expertise may not be available and regularizers must be learned from data. This project developed new methods for learning regularizers from data and identified some of the associated fundamental computational and statistical limitations. Some of the papers that were partially supported by this project include:\n\n\n--Model selection over partially ordered sets, Proceedings of the National Academy of Sciences, 2024\n\n\n-- Kronecker Product Approximation of Operators in Spectral Norm via Alternating SDP, SIAM Journal on Matrix Analysis and Applications, 2023\n\n\n--Terracini convexity, Mathematical Programming, 2023\n\n\n--Spectrahedral Regression, SIAM Journal on Optimization, 2023\n\n\n--Optimal Regularization for a Data Source, preprint\n\n\n--Controlling the False Discovery Rate in Subspace Selection, preprint\n\n\n--Free Descriptions of Convex Sets, preprint\n\n\n--Modeling groundwater levels in California's Central Valley by hierarchical Gaussian process and neural network regression, preprint\n\n\n\t\t\t\t\tLast Modified: 10/15/2024\n\n\t\t\t\t\tSubmitted by: VenkatChandrasekaran\n"
 }
}