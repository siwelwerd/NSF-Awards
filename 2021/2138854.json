{
 "awd_id": "2138854",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AI-based Assessment in STEM Education Conference",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032928447",
 "po_email": "cshen@nsf.gov",
 "po_sign_block_name": "Chia Shen",
 "awd_eff_date": "2021-08-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 49995.0,
 "awd_amount": 59941.0,
 "awd_min_amd_letter_date": "2021-07-06",
 "awd_max_amd_letter_date": "2023-09-20",
 "awd_abstract_narration": "The Framework for K-12 Science Education has set forth an ambitious vision for science learning by integrating disciplinary science ideas, scientific and engineering practices, and crosscutting concepts, so that students could develop competence to meet the STEM challenges of the 21st century. Achieving this vision requires transformation of assessment practices from relying on multiple-choice items to performance-based knowledge-in-use tasks. Such novel assessment tasks serve the purpose of both engaging students in using knowledge to solve problems and tracking students\u2019 learning progression so that teachers could adjust instruction to meet students\u2019 needs. However, these performance-based constructed-response items often prohibit timely feedback, which, in turn, has hindered science teachers from using these assessments. Artificial Intelligence (AI) has demonstrated great potential to meet this assessment challenge. To tackle this challenge, experts in assessment, AI, and science education will gather for a two-day conference at University of Georgia to generate knowledge of integrating AI in science assessment. \r\n\r\nThe conference is organized around four themes: (a) AI and Domain Specific Learning Theory; (b) AI and validity theory and assessment design principles; (c) AI and technology integration theory; and (d) AI and pedagogical theory focusing on assessment practices. It allows participants to share theoretical perspectives, empirical findings, as well as research experiences. It can also help identify challenges and future research directions to increase the broad use of AI-based assessments in science education. The conference will be open to other researchers, postdocs, and students via Zoom. It is expected that conference participants establish a network in this emergent area of science assessment. Another outcome of the conference, Applying AI in STEM Assessment, will be published as an edited volume by Harvard Education Press.    \r\n\r\nThe Discovery Research preK-12 program (DRK-12) seeks to significantly enhance the learning and teaching of science, technology, engineering and mathematics (STEM) by preK-12 students and teachers, through research and development of innovative resources, models and tools. Projects in the DRK-12 program build on fundamental research in STEM education and prior research and development efforts that provide theoretical and empirical justification for proposed projects.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiaoming",
   "pi_last_name": "Zhai",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaoming Zhai",
   "pi_email_addr": "xiaoming.zhai@uga.edu",
   "nsf_id": "000810678",
   "pi_start_date": "2021-07-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Joseph",
   "pi_last_name": "Krajcik",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Joseph S Krajcik",
   "pi_email_addr": "krajcik@msu.edu",
   "nsf_id": "000341539",
   "pi_start_date": "2021-07-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Georgia Research Foundation Inc",
  "inst_street_address": "310 E CAMPUS RD RM 409",
  "inst_street_address_2": "",
  "inst_city_name": "ATHENS",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "7065425939",
  "inst_zip_code": "306021589",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "GA10",
  "org_lgl_bus_name": "UNIVERSITY OF GEORGIA RESEARCH FOUNDATION, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "NMJHD63STRC5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Georgia",
  "perf_str_addr": "310 East Campus Road, Tucker Hal",
  "perf_city_name": "Athens",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "306021589",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "GA10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "764500",
   "pgm_ele_name": "Discovery Research K-12"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "092Z",
   "pgm_ref_txt": "AI-Supported Learning"
  },
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "04002223DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0421",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002122DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 49995.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 9946.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This NSF-funded Conference invited 41 experts in assessment, Artificial Intelligence (AI), and science education to the University of Georgia for a two-day conference to generate knowledge of integrating AI in science assessment. The Framework for K-12 Science Education has set forth an ambitious vision for science learning by integrating disciplinary science ideas, scientific and engineering practices, and crosscutting concepts, so that students could develop competence to meet the STEM challenges of the 21st century. Achieving this vision requires the transformation of assessment practices from relying on multiple-choice items to performance-based knowledge-in-use tasks. Such novel assessment tasks serve the purpose of involving students in using knowledge to solve problems, explaining phenomena, and tracking students&rsquo; learning progression so that teachers can adjust instruction to meet students&rsquo; needs. However, these performance-based constructed-response items often prohibit timely feedback, which, in turn, has hindered science teachers from using these assessments. AI has demonstrated potential to meet this assessment challenge. Therefore, this conference intended to address two goals: (a) communicating the frontier research on AI-based assessments in STEM. (b) identifying the challenges of applying AI in science assessments; (c) mapping the future direction of AI-based assessment research.</p>\r\n<p>&nbsp;</p>\r\n<p>One of the most impactful contributions of our work has been creating a platform that brings together leading scholars from across the globe in this rapidly evolving field. By inviting these experts to present their cutting-edge research, share insights, and engage in collaborative discussions about challenges and future directions, we have fostered a dynamic exchange of ideas that is advancing the frontiers of this emergent area.</p>\r\n<p>&nbsp;</p>\r\n<p>This project is poised to leave a lasting legacy on the field by shaping and broadening the community's understanding of the scope and possibilities for research and application. Specifically, it is helping to define and address critical dimensions of working in this emergent domain, including:</p>\r\n<p><strong>AI-Based Assessment in Domain-Specific Learning:</strong>&nbsp;Exploring how AI-driven assessment tools can be tailored to evaluate learning in specific disciplines, providing nuanced insights that traditional assessments may miss.</p>\r\n<p><strong>Validity Theory and Design Principles for AI-Based Assessment:</strong>&nbsp;Establishing robust theoretical foundations and design guidelines to ensure the validity, reliability, and fairness of AI-powered assessments in educational settings.</p>\r\n<p><strong>Integrating AI-Based Assessments in STEM Education:</strong>&nbsp;Investigating strategies to seamlessly incorporate AI assessments into STEM curricula, enhancing their alignment with instructional goals and real-world applications.</p>\r\n<p><strong>Instruction and Pedagogy with AI-Based Assessments:</strong>&nbsp;Examining how AI assessments can inform and transform teaching practices, enabling educators to personalize learning experiences and support diverse student needs.</p>\r\n<p><strong>AI and Big Data in STEM Education:</strong>&nbsp;Leveraging the power of AI and big data analytics to uncover patterns, predict outcomes, and optimize instructional strategies, driving more effective and equitable STEM learning experiences.</p>\r\n<p>&nbsp;</p>\r\n<p>Through these efforts, our project not only addresses immediate challenges but also lays the groundwork for future innovations, inspiring new lines of inquiry and empowering educators, researchers, and practitioners to harness the transformative potential of AI in education.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/29/2024<br>\nModified by: Xiaoming&nbsp;Zhai</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis NSF-funded Conference invited 41 experts in assessment, Artificial Intelligence (AI), and science education to the University of Georgia for a two-day conference to generate knowledge of integrating AI in science assessment. The Framework for K-12 Science Education has set forth an ambitious vision for science learning by integrating disciplinary science ideas, scientific and engineering practices, and crosscutting concepts, so that students could develop competence to meet the STEM challenges of the 21st century. Achieving this vision requires the transformation of assessment practices from relying on multiple-choice items to performance-based knowledge-in-use tasks. Such novel assessment tasks serve the purpose of involving students in using knowledge to solve problems, explaining phenomena, and tracking students learning progression so that teachers can adjust instruction to meet students needs. However, these performance-based constructed-response items often prohibit timely feedback, which, in turn, has hindered science teachers from using these assessments. AI has demonstrated potential to meet this assessment challenge. Therefore, this conference intended to address two goals: (a) communicating the frontier research on AI-based assessments in STEM. (b) identifying the challenges of applying AI in science assessments; (c) mapping the future direction of AI-based assessment research.\r\n\n\n\r\n\n\nOne of the most impactful contributions of our work has been creating a platform that brings together leading scholars from across the globe in this rapidly evolving field. By inviting these experts to present their cutting-edge research, share insights, and engage in collaborative discussions about challenges and future directions, we have fostered a dynamic exchange of ideas that is advancing the frontiers of this emergent area.\r\n\n\n\r\n\n\nThis project is poised to leave a lasting legacy on the field by shaping and broadening the community's understanding of the scope and possibilities for research and application. Specifically, it is helping to define and address critical dimensions of working in this emergent domain, including:\r\n\n\nAI-Based Assessment in Domain-Specific Learning:Exploring how AI-driven assessment tools can be tailored to evaluate learning in specific disciplines, providing nuanced insights that traditional assessments may miss.\r\n\n\nValidity Theory and Design Principles for AI-Based Assessment:Establishing robust theoretical foundations and design guidelines to ensure the validity, reliability, and fairness of AI-powered assessments in educational settings.\r\n\n\nIntegrating AI-Based Assessments in STEM Education:Investigating strategies to seamlessly incorporate AI assessments into STEM curricula, enhancing their alignment with instructional goals and real-world applications.\r\n\n\nInstruction and Pedagogy with AI-Based Assessments:Examining how AI assessments can inform and transform teaching practices, enabling educators to personalize learning experiences and support diverse student needs.\r\n\n\nAI and Big Data in STEM Education:Leveraging the power of AI and big data analytics to uncover patterns, predict outcomes, and optimize instructional strategies, driving more effective and equitable STEM learning experiences.\r\n\n\n\r\n\n\nThrough these efforts, our project not only addresses immediate challenges but also lays the groundwork for future innovations, inspiring new lines of inquiry and empowering educators, researchers, and practitioners to harness the transformative potential of AI in education.\r\n\n\n\t\t\t\t\tLast Modified: 11/29/2024\n\n\t\t\t\t\tSubmitted by: XiaomingZhai\n"
 }
}