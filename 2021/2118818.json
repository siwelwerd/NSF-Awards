{
 "awd_id": "2118818",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Learning-Aided Integrated Control and Semantic Perception Architecture for Legged Robot Locomotion and Navigation in the Wild",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928950",
 "po_email": "rwachter@nsf.gov",
 "po_sign_block_name": "Ralph Wachter",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 986380.0,
 "awd_amount": 986380.0,
 "awd_min_amd_letter_date": "2021-08-06",
 "awd_max_amd_letter_date": "2021-08-06",
 "awd_abstract_narration": "This project develops an open-source system to allow legged robots to perform autonomous exploration and environmental monitoring in unstructured environments, such as in a forest. A central theme is the design and deployment of a unified and integrated framework that exploits the redundancy of onboard sensory modalities and cross-integrates with feedback control and planning. The project seeks major advances in control theory, computer vision, embedded systems, and planning under uncertainty, areas that are often studied in isolation. By studying these areas as a systems problem,  the researchers expect significant advances for autonomous systems in unstructured environments. The results of the research are demonstrated on a Digit-series 3D biped and a Mini Cheetah quadruped robot. \r\n\r\nThe research elevates the state of the art in deploying autonomous mobile robots \u201cin the wild.\u201d In off-road and unstructured settings, the main technique currently employed by the autonomous vehicle industry, registering into known high-definition maps on the basis of collected sensor measurements, is not possible and adversely affects autonomy. The project develops a real-time multi-layer dense semantic occupancy mapping with an extended set of terrain labels and a \u201cwalk-ability\u201d index combined with an integrated motion planner for an autonomous system. The traversability map enables a walking robot to make dynamic real-time planning and feedback control decisions, adjusting for gait characteristics and for precise foot placement based on the surrounding terrain and environment.\r\n\r\nThe principal investigators are co-developing a freshman college course to inspire students by teaching how practicing engineers employ computational linear algebra to solve large and important problems as arise in the study of autonomous robots. Course projects are selected from contemporary topics in robotics such as, for example, map building from LiDAR point clouds, machine learning for spatial representation of data, and feedback control of mobile platforms. In addition, the project engages in outreach to underrepresented communities through collaborative educational instruction in STEM fields in Detroit public high schools.\r\n\r\nThis project is supported by the cross-directorate Foundational Research in Robotics program, jointly managed and funded by the Directorates for Engineering (ENG) and Computer and Information Science and Engineering (CISE).\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jessy",
   "pi_last_name": "Grizzle",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Jessy W Grizzle",
   "pi_email_addr": "grizzle@umich.edu",
   "nsf_id": "000396941",
   "pi_start_date": "2021-08-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Maani",
   "pi_last_name": "Ghaffari Jadidi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maani Ghaffari Jadidi",
   "pi_email_addr": "maanigj@umich.edu",
   "nsf_id": "000806191",
   "pi_start_date": "2021-08-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "Regents of the University of Michigan - Ann Arbor",
  "perf_str_addr": "1301 Beal Avenue",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092122",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  },
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 986380.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;</p>\r\n<p>Our research focuses on making legged robots, such as Cassie and the MIT Cheetah, more capable of navigating real-world environments. From obstacle avoidance to walking on ice, we are developing advanced systems that improve robot mobility, safety, and decision-making. These efforts combine cutting-edge control algorithms, artificial intelligence, and real-world testing to bring us closer to autonomous robots that can perform practical tasks in dynamic settings.</p>\r\n<p><strong>Intelligent Path Planning and Obstacle Avoidance</strong><br />We developed a planning system that enables Cassie to navigate complex environments without relying on high-definition maps. Using LiDAR sensors and innovative control barrier functions (CBFs), Cassie dynamically avoids obstacles while following planned routes. This system was tested on the University of Michigan's North Campus, where Cassie successfully navigated sidewalks, road crossings, and meandering paths with only low-fidelity maps. By making this technology open-source, we aim to advance robotics research and foster collaboration.</p>\r\n<p><strong>Walking on Challenging Terrains</strong><br />A major milestone was Cassie&rsquo;s ability to walk on moving platforms and uneven terrains. Our team designed a robust control strategy using an Angular Momentum Linear Inverted Pendulum (ALIP) model combined with Model Predictive Control (MPC). This approach allowed Cassie to maintain balance and stability, even on slopes, shifting surfaces, and icy conditions with low friction. These breakthroughs in walking stability are critical for robots operating in environments like disaster zones or urban landscapes.</p>\r\n<p><strong>Predicting and Preventing Falls</strong><br />To improve robot safety, we developed an algorithm that predicts falls during the standing phase. Using a 1D convolutional neural network (CNN), the system anticipates potential falls caused by abrupt or subtle faults and provides enough lead time for corrective action. Tested on the Digit humanoid robot, this approach achieved excellent results with no false positives. These advancements enhance the reliability of bipedal robots in unpredictable environments.</p>\r\n<p><strong>Efficient Trajectory Optimization</strong><br />We tackled the complex problem of trajectory optimization for robotic motion planning, introducing a method based on Lie group mathematics. By reformulating the problem as a Polynomial Optimization Problem (POP), we achieved globally optimal solutions with significantly lower computational costs. This work was recognized as a Best Paper Award finalist at a leading robotics conference, highlighting its potential to revolutionize motion planning for robots with complex dynamics.</p>\r\n<p><strong>Socially Aware Navigation</strong><br />As robots increasingly interact with humans, understanding social behavior becomes essential. We designed a system that incorporates social zones into robot navigation, ensuring that robots behave in a socially compliant manner, such as yielding or adjusting their speed when near people. This technology is particularly relevant for robots in shared spaces, like malls or airports.</p>\r\n<p><strong>Stair Climbing and Whole-Body Control</strong><br />To enable Cassie to climb stairs, we enhanced its control systems to handle the changing dynamics of stair navigation. By allowing variations in the virtual pendulum formed between Cassie&rsquo;s center of mass and its foot, our model predicts and stabilizes stair-climbing gaits. Additionally, our Kinodynamic Fabrics framework ensures robots can execute multiple motion tasks simultaneously while responding to unexpected disturbances. These improvements bring robots closer to operating seamlessly in human-centric environments.</p>\r\n<p><strong>Advancing Perception and Mapping</strong><br />Accurate perception and mapping are crucial for robot navigation. We made strides in real-time terrain mapping using sensors like RGBD cameras and LiDAR. While not yet fully integrated, our mapping system estimates important properties such as slope and friction, enabling better control decisions. We also enhanced Invariant Extended Kalman Filtering (InEKF), which now operates in real-time to detect contact events crucial for maintaining balance.</p>\r\n<p><strong>Impact and Vision</strong><br />The results of our research have significant implications for industries like autonomous vehicles, logistics, and disaster response. By replacing the need for costly high-definition maps with low-fidelity alternatives, we are reducing barriers to robot deployment. Additionally, our findings in motion control and perception pave the way for safer, more agile robots capable of working alongside humans in dynamic environments.</p>\r\n<p>Through open-source contributions and integration into educational programs, we aim to inspire the next generation of roboticists while advancing the state of autonomous systems. Our experiments on Cassie and Digit showcase the practical potential of these innovations, bringing us closer to a future where robots assist us in everyday tasks with confidence and reliability.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/09/2025<br>\nModified by: Jessy&nbsp;W&nbsp;Grizzle</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\r\n\n\nOur research focuses on making legged robots, such as Cassie and the MIT Cheetah, more capable of navigating real-world environments. From obstacle avoidance to walking on ice, we are developing advanced systems that improve robot mobility, safety, and decision-making. These efforts combine cutting-edge control algorithms, artificial intelligence, and real-world testing to bring us closer to autonomous robots that can perform practical tasks in dynamic settings.\r\n\n\nIntelligent Path Planning and Obstacle Avoidance\nWe developed a planning system that enables Cassie to navigate complex environments without relying on high-definition maps. Using LiDAR sensors and innovative control barrier functions (CBFs), Cassie dynamically avoids obstacles while following planned routes. This system was tested on the University of Michigan's North Campus, where Cassie successfully navigated sidewalks, road crossings, and meandering paths with only low-fidelity maps. By making this technology open-source, we aim to advance robotics research and foster collaboration.\r\n\n\nWalking on Challenging Terrains\nA major milestone was Cassies ability to walk on moving platforms and uneven terrains. Our team designed a robust control strategy using an Angular Momentum Linear Inverted Pendulum (ALIP) model combined with Model Predictive Control (MPC). This approach allowed Cassie to maintain balance and stability, even on slopes, shifting surfaces, and icy conditions with low friction. These breakthroughs in walking stability are critical for robots operating in environments like disaster zones or urban landscapes.\r\n\n\nPredicting and Preventing Falls\nTo improve robot safety, we developed an algorithm that predicts falls during the standing phase. Using a 1D convolutional neural network (CNN), the system anticipates potential falls caused by abrupt or subtle faults and provides enough lead time for corrective action. Tested on the Digit humanoid robot, this approach achieved excellent results with no false positives. These advancements enhance the reliability of bipedal robots in unpredictable environments.\r\n\n\nEfficient Trajectory Optimization\nWe tackled the complex problem of trajectory optimization for robotic motion planning, introducing a method based on Lie group mathematics. By reformulating the problem as a Polynomial Optimization Problem (POP), we achieved globally optimal solutions with significantly lower computational costs. This work was recognized as a Best Paper Award finalist at a leading robotics conference, highlighting its potential to revolutionize motion planning for robots with complex dynamics.\r\n\n\nSocially Aware Navigation\nAs robots increasingly interact with humans, understanding social behavior becomes essential. We designed a system that incorporates social zones into robot navigation, ensuring that robots behave in a socially compliant manner, such as yielding or adjusting their speed when near people. This technology is particularly relevant for robots in shared spaces, like malls or airports.\r\n\n\nStair Climbing and Whole-Body Control\nTo enable Cassie to climb stairs, we enhanced its control systems to handle the changing dynamics of stair navigation. By allowing variations in the virtual pendulum formed between Cassies center of mass and its foot, our model predicts and stabilizes stair-climbing gaits. Additionally, our Kinodynamic Fabrics framework ensures robots can execute multiple motion tasks simultaneously while responding to unexpected disturbances. These improvements bring robots closer to operating seamlessly in human-centric environments.\r\n\n\nAdvancing Perception and Mapping\nAccurate perception and mapping are crucial for robot navigation. We made strides in real-time terrain mapping using sensors like RGBD cameras and LiDAR. While not yet fully integrated, our mapping system estimates important properties such as slope and friction, enabling better control decisions. We also enhanced Invariant Extended Kalman Filtering (InEKF), which now operates in real-time to detect contact events crucial for maintaining balance.\r\n\n\nImpact and Vision\nThe results of our research have significant implications for industries like autonomous vehicles, logistics, and disaster response. By replacing the need for costly high-definition maps with low-fidelity alternatives, we are reducing barriers to robot deployment. Additionally, our findings in motion control and perception pave the way for safer, more agile robots capable of working alongside humans in dynamic environments.\r\n\n\nThrough open-source contributions and integration into educational programs, we aim to inspire the next generation of roboticists while advancing the state of autonomous systems. Our experiments on Cassie and Digit showcase the practical potential of these innovations, bringing us closer to a future where robots assist us in everyday tasks with confidence and reliability.\r\n\n\n\t\t\t\t\tLast Modified: 01/09/2025\n\n\t\t\t\t\tSubmitted by: JessyWGrizzle\n"
 }
}