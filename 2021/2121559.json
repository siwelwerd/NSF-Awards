{
 "awd_id": "2121559",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "A Novel AI-Human Teaming Approach to Trust and Cooperation in AI-Cybersecurity Education",
 "cfda_num": "47.076",
 "org_code": "11040000",
 "po_phone": "7032922832",
 "po_email": "ptymann@nsf.gov",
 "po_sign_block_name": "Paul Tymann",
 "awd_eff_date": "2021-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 298620.0,
 "awd_amount": 298620.0,
 "awd_min_amd_letter_date": "2021-06-30",
 "awd_max_amd_letter_date": "2021-06-30",
 "awd_abstract_narration": "This project aims to serve the national interest by improving the state-of-the-art in cybersecurity education. The national cyberinfrastructure is vulnerable to a wide range of cyberthreats and hazards. Cyberthreat intelligence data gives insight into a cyberattack and provides an opportunity to become proactively secure. Proactive cybersecurity has become dependent upon AI, making it essential that cybersecurity practitioners gain an understanding of both cybersecurity and AI. This project will combine research in AI, cybersecurity, education, and behavior science to investigate evidence-based and knowledge-generating approaches to cybersecurity education that emphasizes AI-human teams. The investigators will study trust and cooperation in AI-human teams to generate knowledge that will inform future educational efforts that lie at the intersection of AI and cybersecurity.\r\n\r\nThis project will advance educational knowledge in the fields of AI, cybersecurity, and behavior science through three objectives, resulting in 1) AI-Enabled Defense Simulation Suite (AI-EDSimS), enabling hands-on learning for students and cybersecurity professionals, 2) a new course on AI and Cybersecurity transforming undergraduate education by integrating the two subjects with a focus on AI-human teaming for proactive cybersecurity practice, and 3) new knowledge in AI-Cybersecurity education as it relates to AI-human teaming, leading to improved understanding of the role of trust and cooperation in AI-human teams. The NSF IUSE: EHR Program supports research and development projects to improve the effectiveness of STEM education for all students. Through the Engaged Student Learning track, the program supports the creation, exploration, and implementation of promising practices and tools.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DUE",
 "org_div_long_name": "Division Of Undergraduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Emily",
   "pi_last_name": "Hand",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Emily M Hand",
   "pi_email_addr": "emhand@unr.edu",
   "nsf_id": "000784557",
   "pi_start_date": "2021-06-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sushil",
   "pi_last_name": "Louis",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Sushil J Louis",
   "pi_email_addr": "sushil.louis@gmail.com",
   "nsf_id": "000288984",
   "pi_start_date": "2021-06-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ramona",
   "pi_last_name": "Houmanfar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ramona Houmanfar",
   "pi_email_addr": "ramonah@unr.edu",
   "nsf_id": "000528284",
   "pi_start_date": "2021-06-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Shamik",
   "pi_last_name": "Sengupta",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shamik Sengupta",
   "pi_email_addr": "ssengupta@unr.edu",
   "nsf_id": "000540898",
   "pi_start_date": "2021-06-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Board of Regents, NSHE, obo University of Nevada, Reno",
  "inst_street_address": "1664 N VIRGINIA ST # 285",
  "inst_street_address_2": "",
  "inst_city_name": "RENO",
  "inst_state_code": "NV",
  "inst_state_name": "Nevada",
  "inst_phone_num": "7757844040",
  "inst_zip_code": "895570001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NV02",
  "org_lgl_bus_name": "BOARD OF REGENTS OF THE NEVADA SYSTEM OF HIGHER ED",
  "org_prnt_uei_num": "WLDGTNCFFJZ3",
  "org_uei_num": "WLDGTNCFFJZ3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Nevada, Reno",
  "perf_str_addr": "1664 North Virginia Street",
  "perf_city_name": "Reno",
  "perf_st_code": "NV",
  "perf_st_name": "Nevada",
  "perf_zip_code": "895570001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NV02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "199800",
   "pgm_ele_name": "IUSE"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8209",
   "pgm_ref_txt": "Improv Undergrad STEM Ed(IUSE)"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0421",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002122DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 298620.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project had three main goals:</p>\n<p>1. Introduce a cybersecurity simulation for educational purposes that allows students to team up with AI to identify and mitigate cybersecurity threats.</p>\n<p>2. Introduce a new course at the intersection of AI and Cybersecurity for undergraduates that focuses on applications of AI in cybersecurity.</p>\n<p>3. Study and understand how bias toward or against AI affects cooperation in AI-human teams.</p>\n<p>&nbsp;</p>\n<p>Intellectual Merit:</p>\n<p>Goal 1: We introduce TAISER (and later T2), a cybersecurity simulation that allows students to work with either a human or AI teammate to protect a city from cybersecurity threats. This simulation has been used in the new course developed under this award, and has provided valuable insight into student perspectives on AI. We found, through testing our simulation in the classroom, that students are very comfortable with AI in game settings, but are less comfortable with AI in work (or more serious) settings.&nbsp;This was valuable insight, which helped us in our third goal of studying how bias affects cooperation. We were able to publish a paper on this simulation at the 2024 IEEE Conference on Games.</p>\n<p>&nbsp;</p>\n<p>Goal 2: We introduced a new course, CS 345: CyberAI at the University of Nevada, Reno. This course has been very positively received by students and has been offered three times over the project period, with high enrollments. We have hired a new faculty member, whose research is at the intersection of AI and Cybersecurity. She has taken on teaching this course regularly, and so it has become a regular course offering at UNR. The University of Nevada, Las Vegas is now putting together a course based on our CyberAI course. Additionally, UNR is offering a graduate-level course in CyberAI, building off of our undergraduate curriculum.</p>\n<p>&nbsp;</p>\n<p>Goal 3: We introduced two new tools to measure bias and cooperative tendencies in AI-human teams. We introduced a new Implicit Relational Assessment Procedure (IRAP), which measures implicit bias. This is an established tool in behavior science, and variations exist to measure gender, age and ethnicity biases amongst many others. We developed our own variations, one for measuring bias in AI-human teams in game settings, and one for measuring bias in work settings. Additionally, we introduced a new tool, QSort, for measuring more explicit biases in both of these settings. The QSort is a type of structured survey that highlights an individual&rsquo;s views on a particular topic. We found that the QSort and IRAP were aligned, so if an individual expressed a distrust for AI in the QSort, this same bias was seen in the IRAP measures and vice versa. These tools allow us to measure an individual&rsquo;s likelihood to cooperate with an AI teammate.</p>\n<p>&nbsp;</p>\n<p>Broader Impacts:&nbsp;</p>\n<p>With the advent of ChatGPT and other large language models, it is clear that the future of work directly involves AI. Therefore, it is essential to understand how people work and interact with AI. It is important to educate individuals on how AI works, so they have an understanding of its capabilities, and more importantly its limitations. It is also important that future workers leverage AI capabilities to solve problems more efficiently. This can only be done if there is a sense of trust between the individual and their AI teammate. This work has laid the groundwork for understanding trust in AI-human teams. Additionally, the CyberAI course that has resulted from this project will be a regular course offering in the Nevada System of Higher Education institutions, impacting generations of students to come.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/30/2024<br>\nModified by: Emily&nbsp;M&nbsp;Hand</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project had three main goals:\n\n\n1. Introduce a cybersecurity simulation for educational purposes that allows students to team up with AI to identify and mitigate cybersecurity threats.\n\n\n2. Introduce a new course at the intersection of AI and Cybersecurity for undergraduates that focuses on applications of AI in cybersecurity.\n\n\n3. Study and understand how bias toward or against AI affects cooperation in AI-human teams.\n\n\n\n\n\nIntellectual Merit:\n\n\nGoal 1: We introduce TAISER (and later T2), a cybersecurity simulation that allows students to work with either a human or AI teammate to protect a city from cybersecurity threats. This simulation has been used in the new course developed under this award, and has provided valuable insight into student perspectives on AI. We found, through testing our simulation in the classroom, that students are very comfortable with AI in game settings, but are less comfortable with AI in work (or more serious) settings.This was valuable insight, which helped us in our third goal of studying how bias affects cooperation. We were able to publish a paper on this simulation at the 2024 IEEE Conference on Games.\n\n\n\n\n\nGoal 2: We introduced a new course, CS 345: CyberAI at the University of Nevada, Reno. This course has been very positively received by students and has been offered three times over the project period, with high enrollments. We have hired a new faculty member, whose research is at the intersection of AI and Cybersecurity. She has taken on teaching this course regularly, and so it has become a regular course offering at UNR. The University of Nevada, Las Vegas is now putting together a course based on our CyberAI course. Additionally, UNR is offering a graduate-level course in CyberAI, building off of our undergraduate curriculum.\n\n\n\n\n\nGoal 3: We introduced two new tools to measure bias and cooperative tendencies in AI-human teams. We introduced a new Implicit Relational Assessment Procedure (IRAP), which measures implicit bias. This is an established tool in behavior science, and variations exist to measure gender, age and ethnicity biases amongst many others. We developed our own variations, one for measuring bias in AI-human teams in game settings, and one for measuring bias in work settings. Additionally, we introduced a new tool, QSort, for measuring more explicit biases in both of these settings. The QSort is a type of structured survey that highlights an individuals views on a particular topic. We found that the QSort and IRAP were aligned, so if an individual expressed a distrust for AI in the QSort, this same bias was seen in the IRAP measures and vice versa. These tools allow us to measure an individuals likelihood to cooperate with an AI teammate.\n\n\n\n\n\nBroader Impacts:\n\n\nWith the advent of ChatGPT and other large language models, it is clear that the future of work directly involves AI. Therefore, it is essential to understand how people work and interact with AI. It is important to educate individuals on how AI works, so they have an understanding of its capabilities, and more importantly its limitations. It is also important that future workers leverage AI capabilities to solve problems more efficiently. This can only be done if there is a sense of trust between the individual and their AI teammate. This work has laid the groundwork for understanding trust in AI-human teams. Additionally, the CyberAI course that has resulted from this project will be a regular course offering in the Nevada System of Higher Education institutions, impacting generations of students to come.\n\n\n\t\t\t\t\tLast Modified: 10/30/2024\n\n\t\t\t\t\tSubmitted by: EmilyMHand\n"
 }
}