{
 "awd_id": "2118380",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Bimodal Haptic-Mixed Reality (HMR) Needle Insertion Simulation for Hand-Eye Skills",
 "cfda_num": "47.070, 47.075",
 "org_code": "05020000",
 "po_phone": "7032927878",
 "po_email": "slim@nsf.gov",
 "po_sign_block_name": "Soo-Siang Lim",
 "awd_eff_date": "2021-09-15",
 "awd_exp_date": "2025-08-31",
 "tot_intn_awd_amt": 850000.0,
 "awd_amount": 870000.0,
 "awd_min_amd_letter_date": "2021-09-07",
 "awd_max_amd_letter_date": "2024-06-26",
 "awd_abstract_narration": "Although performing intravenous (IV) insertion is a very common medical procedure, it is technically difficult to master as demonstrated by the 35%-50% failure rate resulting in a negative cycle of re-insertions leading to increased patient harm and costs to the healthcare system. Faulty IV insertions in real-world conditions are related to vein variables (vein rolling or resistant to puncture) and patient variables (touch skin, skin coloring). Experts in nursing education have advocated for self-paced integration of simulation-based technologies to deliberately practice IV skills while receiving immediate feedback for error correction. However, using currently developed simulators or manikin arms fails to capture the actual realism and psychomotor techniques adaptive to variability needed to gain procedural mastery of the skill. To enhance the current learning environment, technological advances are needed to create a realistic learning platform with variability that maximizes the skill transfer and long-term retention. The proposed work is to fill the gap by developing a novel simulation system using haptics and mixed reality (HMR) and investigating the learning impacts. This work is significant because current haptic technologies combined with extended reality do not yet provide sufficient realism and variability to effectively develop the fine motor skills. Further, studies have not been conducted on the educational impact of bimodal HMR simulation with variable conditions that can adaptively create realistic patient environments during training. Upon developing the successful nature of the proposed research, new insight into effective learning technology as well as causes of improved learning in hand-eye skills will be provided, which may be used to improve learning in similar settings or be transformative to other fields such as cyber teaching and learning, hand skill training at work, immersive dexterous interfaces, motor skill development for people with disabilities, STEM learning, robotic surgery, and medical training.\r\n\r\nThis project will develop a bimodal HMR system, using emerging technologies, haptics and MR, to simulate IV needle insertion with variable conditions that will create a realistic learning environment for students to master insertion tactile skills using two hands; and investigate whether variability in practice (disuse theory) improves needle insertion skills. To achieve these goals, the project will be divided into two phases: Phase I and II. Phase I will focus on developing the bimodal haptic simulation using two complimentary haptic devices, a haptic glove and a stylus haptic device, integrated with MR to simulate virtual patients and IV needle insertion with variable training conditions (skin color and stiffness, vein rolled, or resistant to puncture). In Phase II studies, 360 (180 per year) nursing students will be randomly assigned to experience training sessions in one of the three modes (HMR-static, HMR-variable, manikin arm). To measure learners\u2019 IV insertion skills, trained evaluators (faculty members) from the College of Nursing will observe and evaluate participants\u2019 skills based on an established IV insertion skill checklist through exams. Post training surveys will be collected in terms of the realism and the user experience (usability) and those data will be used for continuously improving the HMR system. This research will advance the knowledge related to developing innovative learning and teaching environments using emerging technologies and provide empirical evidence of impactful variables that affect learning performance. The developed platform as an automatic self-practice system will provide free access to this medium for instructors and students alike in healthcare or related communities to extend and use even under a pandemic, for broadening participation for under-represented and financially challenged groups.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kwangtaek",
   "pi_last_name": "Kim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kwangtaek Kim",
   "pi_email_addr": "kkim@cs.kent.edu",
   "nsf_id": "000813482",
   "pi_start_date": "2021-09-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Clements",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Robert Clements",
   "pi_email_addr": "rclement@kent.edu",
   "nsf_id": "000562063",
   "pi_start_date": "2021-09-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jeremy",
   "pi_last_name": "Jarzembak",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jeremy M Jarzembak",
   "pi_email_addr": "jjarzemb@kent.edu",
   "nsf_id": "000817615",
   "pi_start_date": "2021-09-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Kent State University",
  "inst_street_address": "1500 HORNING RD",
  "inst_street_address_2": "",
  "inst_city_name": "KENT",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "3306722070",
  "inst_zip_code": "442420001",
  "inst_country_name": "United States",
  "cong_dist_code": "14",
  "st_cong_dist_code": "OH14",
  "org_lgl_bus_name": "KENT STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "KXNVA7JCC5K6"
 },
 "perf_inst": {
  "perf_inst_name": "Kent State University",
  "perf_str_addr": "800 East Summit Street",
  "perf_city_name": "Kent",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "442420001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "14",
  "perf_st_cong_dist": "OH14",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 517000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 166500.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 176500.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 10000.0
  }
 ],
 "por": null
}