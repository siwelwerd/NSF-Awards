{
 "awd_id": "2128611",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Advancing Fractional Combinatorial Optimization: Computation and Applications",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leland Jameson",
 "awd_eff_date": "2021-02-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 122773.0,
 "awd_min_amd_letter_date": "2021-03-22",
 "awd_max_amd_letter_date": "2021-03-22",
 "awd_abstract_narration": "Single- and multiple-ratio fractional combinatorial optimization problems naturally arise in diverse application contexts when modeling trade-offs such as maximizing return/investment, maximizing profit/time, minimizing cost/time or minimizing wasted/used material.  For example, risk-adverse decision-makers are often interested in solutions that provide a good trade-off between the expected return and risk, which can be modeled naturally as the ratio function. Also, fractional objectives can be used for feature selection and clustering in data mining as well as for solving isoperimetric problems on graphs that can be applied for error-correcting codes and image segmentation. There are no adequate solution approaches for these classes of optimization problems if they involve integrality and/or combinatorial restrictions (constraints). Therefore, if successful, the proposed research will substantially enhance the ability to solve these hard classes of optimization problems and can lead to a more widespread use of single- and multiple-ratio fractional measures in existing and emerging applications.\r\n\r\nThe project's main goal is to develop computational approaches with the solid underlying theoretical foundation, that deliver provably good solutions and can be used to solve realistically sized instances of single- and multiple-ratio fractional combinatorial optimization problems. In order to do so, the investigators propose to systematically exploit the combinatorial structure of the feasible region and structural properties of the ratio functions to construct strong convex relaxations of the fractional combinatorial optimization problems. The investigators will also explore single- and multiple-ratio fractional combinatorial optimization problems under parameter uncertainty. The proposed research, unlike most of previous work in the related literature, does not enforce restrictive simplifying assumptions on either the combinatorial structure induced by the constraint set or the number of ratios. Furthermore, the research does not rely on assuming that the functions in the numerators and denominators of the ratios are affine. The proposed approaches draw ideas and will contribute to the literature of mathematical optimization, particularly conic, fractional and discrete optimization, combinatorics, and algebraic graph theory.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Andres",
   "pi_last_name": "Gomez",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andres Gomez",
   "pi_email_addr": "gomezand@usc.edu",
   "nsf_id": "000755902",
   "pi_start_date": "2021-03-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3720 S. Flower St.",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900890001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 122773.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project studied combinatorial fractional optimization problems, an important class of problems that arise when there are two competing objectives that need to be optimized simultaneously. There are three main contribution that are worth highlighting: <em>(i)</em> we showed that combinatorial fractional optimization arises naturally in modern machine learning problems; <em>(ii)</em> we discovered fundamental properties concerning fractional optimization structures, providing theoretical insights into problems involving fractional optimization; and <em>(iii)</em> we showed how these theoretical insights can be exploited to design new and improved algorithms for such problems.</p>\n<p>In practice, machine learning models need to balance accuracy ? how well the model is able to make predictions?and auxiliary considerations such as interpretability ? which enables to model to be used by human experts and helps prevent overfitting. We showed that classical metrics for statistical models that balance these two competing objectives can be optimized using tools from fractional optimization, ultimately leading to the best algorithms to date to solve these inference problems. Moreover, we showed that fractional optimization substructures implicitly arise in several other interpretable statistical and machine learning problems.</p>\n<p>Discrete and combinatorial are known to be hard to solve, and fractional problems are no exception. Nonetheless, even if fractional problems in general are hard, there may be special classes of problems that can in fact be solved efficiently, but only a few of those problems had been identified prior to this research. We showed many classes of efficiently solvable problems: for example, we provided a complete characterization under which a fractional combinatorial problem is submodular and thus tractable; we also showed that, often, stochastic versions (that is, problem where the data is no longer given but is uncertain instead) of tractable problems remain tractable. Furthermore, we derived both strong/ideal continuous relaxations of the discrete fractional problems, and continuous fractional relaxations of other combinatorial problems. Since most methods for discrete problems revolve around solving a sequence of easier subproblems, these continuous relaxations are instrumental to solving hard combinatorial problems.</p>\n<p>Finally, we generalized classical methods for fractional optimization to more general problems, and we also proposed brand-new methods to solve such problems. In terms of classical approaches, we showed that Dinkelbach?s method (often used for linear fractional optimization) remains a powerful tool for tackling nonlinear combinatorial fractional optimization problems, or fractional problems under uncertainty. We also showed how to exploit and combine recent advances in both conic and fractional optimization to design improved nonlinear branch-and-bound methods for the most challenging combinatorial fractional optimization problems.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/02/2022<br>\n\t\t\t\t\tModified by: Andres&nbsp;Gomez</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project studied combinatorial fractional optimization problems, an important class of problems that arise when there are two competing objectives that need to be optimized simultaneously. There are three main contribution that are worth highlighting: (i) we showed that combinatorial fractional optimization arises naturally in modern machine learning problems; (ii) we discovered fundamental properties concerning fractional optimization structures, providing theoretical insights into problems involving fractional optimization; and (iii) we showed how these theoretical insights can be exploited to design new and improved algorithms for such problems.\n\nIn practice, machine learning models need to balance accuracy ? how well the model is able to make predictions?and auxiliary considerations such as interpretability ? which enables to model to be used by human experts and helps prevent overfitting. We showed that classical metrics for statistical models that balance these two competing objectives can be optimized using tools from fractional optimization, ultimately leading to the best algorithms to date to solve these inference problems. Moreover, we showed that fractional optimization substructures implicitly arise in several other interpretable statistical and machine learning problems.\n\nDiscrete and combinatorial are known to be hard to solve, and fractional problems are no exception. Nonetheless, even if fractional problems in general are hard, there may be special classes of problems that can in fact be solved efficiently, but only a few of those problems had been identified prior to this research. We showed many classes of efficiently solvable problems: for example, we provided a complete characterization under which a fractional combinatorial problem is submodular and thus tractable; we also showed that, often, stochastic versions (that is, problem where the data is no longer given but is uncertain instead) of tractable problems remain tractable. Furthermore, we derived both strong/ideal continuous relaxations of the discrete fractional problems, and continuous fractional relaxations of other combinatorial problems. Since most methods for discrete problems revolve around solving a sequence of easier subproblems, these continuous relaxations are instrumental to solving hard combinatorial problems.\n\nFinally, we generalized classical methods for fractional optimization to more general problems, and we also proposed brand-new methods to solve such problems. In terms of classical approaches, we showed that Dinkelbach?s method (often used for linear fractional optimization) remains a powerful tool for tackling nonlinear combinatorial fractional optimization problems, or fractional problems under uncertainty. We also showed how to exploit and combine recent advances in both conic and fractional optimization to design improved nonlinear branch-and-bound methods for the most challenging combinatorial fractional optimization problems.\n\n \n\n\t\t\t\t\tLast Modified: 03/02/2022\n\n\t\t\t\t\tSubmitted by: Andres Gomez"
 }
}