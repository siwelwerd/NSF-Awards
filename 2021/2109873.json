{
 "awd_id": "2109873",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "NSF Postdoctoral Fellowship in Biology FY 2021: Linking biomechanics to neurobiology: how coordinated bird flight emerges from visual motion processing",
 "cfda_num": "47.074",
 "org_code": "08080000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Barthell",
 "awd_eff_date": "2021-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 138000.0,
 "awd_amount": 138000.0,
 "awd_min_amd_letter_date": "2021-06-24",
 "awd_max_amd_letter_date": "2021-06-24",
 "awd_abstract_narration": "This action funds an NSF Postdoctoral Research Fellowship in Biology for FY 2021, Integrative Research Investigating the Rules of Life Governing Interactions Between Genomes, Environment and Phenotypes. The fellowship supports research and training of the Fellow that will contribute to the area of Rules of Life in innovative ways. How the brain interprets visual information to guide safe movement through the environment is one of the great outstanding questions in biology. Understanding this process will help direct the design of safer self-driving cars. Using bird flight as a model system, this research will uncover fundamental principles for the control of movement around obstacles and in coordination with other individuals. Birds are among the most maneuverable animals and rely on visual information to guide their movement; as do humans and self-driving cars. This research will determine how bird flight emerges through processing in the brain using real-world visual stimuli. Data describing bird flight and coordination will be collected in collaboration with students from the Lummi Nation. Thus, this project will provide Native American students \u2013 the least represented group in STEM \u2013 with hands-on, geographically relevant, exposure to science.\r\n\r\nTypically, visual processing is studied by exposing animal subjects to simple patterns in laboratory settings. Though these methods allow for tight regulation of experimental designs, simple patterns lack many features of visual stimuli provided by natural conditions. This dramatically limits our insight into how animal behaviors emerge through the processing of visual information. With training in visual neuroscience from two renowned experts in the field, the Fellow will build upon their experience in biomechanics to connect animal behavior to visual neurobiology. Research will determine how the natural statistics of visual stimuli experienced by free-flying pigeons differ across flight contexts using a paired, head-mounted camera system. Animals will also be equipped with GPS-trackers and accelerometers, such that context-specific visual stimuli can be linked to instantaneous kinematics and trajectories of pigeons. Finally, exposing pigeons to visual stimuli while using electrophysiology to study brain activity will uncover how features of natural visual stimuli are encoded in the activity patterns of visual-motion neurons. This research will thereby bridge the gaps between the information provided to the sensory system, processing, individual motor responses, and coordinated group movement, while providing the Fellow with advanced training in neuroscience. Data for this project will be collected in collaboration with Native American students to facilitate and encourage them to pursue advanced degrees in STEM.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "BIO",
 "org_dir_long_name": "Directorate for Biological Sciences",
 "div_abbr": "DBI",
 "org_div_long_name": "Division of Biological Infrastructure",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anthony",
   "pi_last_name": "Lapsansky",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Anthony B Lapsansky",
   "pi_email_addr": "",
   "nsf_id": "000843670",
   "pi_start_date": "2021-06-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Lapsansky, Anthony B",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "Missoula",
  "inst_state_code": "MT",
  "inst_state_name": "Montana",
  "inst_phone_num": "",
  "inst_zip_code": "59802",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MT01",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "University of British Columbia",
  "perf_str_addr": null,
  "perf_city_name": "Vancouver",
  "perf_st_code": "",
  "perf_st_name": "RI REQUIRED",
  "perf_zip_code": "",
  "perf_ctry_code": "CA",
  "perf_cong_dist": "",
  "perf_st_cong_dist": "",
  "perf_ctry_name": "Canada",
  "perf_ctry_flag": "0"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "804900",
   "pgm_ele_name": "Biology Postdoctoral Research"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 138000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>As we move about the world, we experience optic flow - the movement of surfaces and objects resulting from self-motion. Studies of human behavior have shown that optic flow is critical for controlling posture, walking, driving, and navigating complex environments. Deficits in optic flow processing are linked to diseases including vertigo, oscillopsia, ataxias, Parkinson&rsquo;s disease, and Alzheimer&rsquo;s disease. Determining how and where the brain processes optic flow is therefore crucial to understanding health and behavior, but major gaps in knowledge remain.</p>\n<p>Typically, optic flow processing is studied by exposing subjects to simple patterns. These methods allow for tight control of experimental designs, but simple patterns lack features provided by the real world &ndash; features we use every day. How and where the brain processes realistic visual motion to control movement is almost entirely unknown. This limits our understanding of how humans and other animals navigate in the real world, and our ability to treat those with optic flow deficits.</p>\n<p>Additionally, the challenges that animals face to safely navigate are closely matched by autonomous vehicles. Both animals and autonomous vehicles must sense self-motion, detect obstacles, and predict the likely trajectories of other moving objects, all while immersed in a complex environment.</p>\n<p>The aim of this project was to use pigeons as a model to understand the fundamental principles behind optic flow processing. Through this work, I developed a system for recording video from free-flying pigeons in the field. Working in the lab, these videos will be used in the coming months to study how the brain can extract relevant information from the complex visual signals that birds see during flight. In addition,&nbsp;this work has led to the discovery that, during flight, pigeons track visual features of their environment with slow eye movements. This was surprising, as past researchers had assumed that eye movements would be insignificant in flying birds. Humans exhibit tracking eye movements as we walk and drive, and a similar behavior was recently documented in insects. This suggests that compensatory eye movements play a key role in controlling movement across animals, and offers a potential avenue for improving autonomous vehicles.</p><br>\n<p>\n Last Modified: 12/22/2023<br>\nModified by: Anthony&nbsp;B&nbsp;Lapsansky</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/2109873/2109873_10844172_1703278101194_Lapsansky_pigeonWithCamera--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2109873/2109873_10844172_1703278101194_Lapsansky_pigeonWithCamera--rgov-800width.jpg\" title=\"Pigeon with head-mounted camera\\\"><img src=\"/por/images/Reports/POR/2023/2109873/2109873_10844172_1703278101194_Lapsansky_pigeonWithCamera--rgov-66x44.jpg\" alt=\"Pigeon with head-mounted camera\\\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A homing pigeon prepares for takeoff, carrying equipment for recording a birds-eye-view of flight.</div>\n<div class=\"imageCredit\">Anthony Lapsansky</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Anthony&nbsp;B&nbsp;Lapsansky\n<div class=\"imageTitle\">Pigeon with head-mounted camera\\</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nAs we move about the world, we experience optic flow - the movement of surfaces and objects resulting from self-motion. Studies of human behavior have shown that optic flow is critical for controlling posture, walking, driving, and navigating complex environments. Deficits in optic flow processing are linked to diseases including vertigo, oscillopsia, ataxias, Parkinsons disease, and Alzheimers disease. Determining how and where the brain processes optic flow is therefore crucial to understanding health and behavior, but major gaps in knowledge remain.\n\n\nTypically, optic flow processing is studied by exposing subjects to simple patterns. These methods allow for tight control of experimental designs, but simple patterns lack features provided by the real world  features we use every day. How and where the brain processes realistic visual motion to control movement is almost entirely unknown. This limits our understanding of how humans and other animals navigate in the real world, and our ability to treat those with optic flow deficits.\n\n\nAdditionally, the challenges that animals face to safely navigate are closely matched by autonomous vehicles. Both animals and autonomous vehicles must sense self-motion, detect obstacles, and predict the likely trajectories of other moving objects, all while immersed in a complex environment.\n\n\nThe aim of this project was to use pigeons as a model to understand the fundamental principles behind optic flow processing. Through this work, I developed a system for recording video from free-flying pigeons in the field. Working in the lab, these videos will be used in the coming months to study how the brain can extract relevant information from the complex visual signals that birds see during flight. In addition,this work has led to the discovery that, during flight, pigeons track visual features of their environment with slow eye movements. This was surprising, as past researchers had assumed that eye movements would be insignificant in flying birds. Humans exhibit tracking eye movements as we walk and drive, and a similar behavior was recently documented in insects. This suggests that compensatory eye movements play a key role in controlling movement across animals, and offers a potential avenue for improving autonomous vehicles.\t\t\t\t\tLast Modified: 12/22/2023\n\n\t\t\t\t\tSubmitted by: AnthonyBLapsansky\n"
 }
}