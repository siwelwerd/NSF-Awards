{
 "awd_id": "2106711",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: SHF: Medium: Heterogeneous Architecture for Collaborative Machine Learning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2021-07-15",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2021-07-09",
 "awd_max_amd_letter_date": "2023-07-18",
 "awd_abstract_narration": "The recent breakthrough of on-device machine learning with specialized artificial-intelligence hardware brings machine intelligence closer to individual devices. To leverage the power of the crowd, collaborative machine learning makes it possible to build up machine-learning models based on datasets that are distributed across multiple devices while preventing data leakage. However, most existing efforts are focused on homogeneous devices; given the widespread yet heterogeneous participants in practice, it is urgently important but challenging to manage immense heterogeneity. The research team develops heterogeneous architectures for collaborative machine learning to achieve three objectives under heterogeneity: efficiency, adaptivity, and privacy. The proposed heterogeneous architecture for collaborative machine learning is bringing tangible benefits for a wide range of disciplines that employ artificial intelligence technologies, such as healthcare, precision medicine, cyber physical systems, and education. The research findings of this project are intended to be integrated with the existing courses and K-12 programs. Furthermore, the research team is actively engaged in activities that encourage students from underrepresented groups to participate in computer science and engineering research.\r\n\r\nThis project provides the theoretical underpinning and empirical evidence for an efficient, adaptive and privacy-preserving design under heterogeneity, which fills a critical void - the existing collaborative machine-learning approach fails to manage the immense heterogeneity in practice. This project centers on three aspects: (1) design of specialized neural architectures for heterogeneous hardware platforms to cope with the limited efficiency of collaborative training due to heterogeneity; (2) design of an efficient and adaptive knowledge-transfer framework to bridge heterogeneous participants based on their underlying proximity benefits; (3) privacy strategies for heterogeneous collaboration by identifying new vulnerabilities and developing privacy-preserving mechanisms. A general-purpose testbed is built to rigorously validate the proposed research and expand the impact of this project. It is expected that this project opens a new research paradigm to unleash the utmost potential of heterogeneous and collaborative machine intelligence.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Song",
   "pi_last_name": "Han",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Song Han",
   "pi_email_addr": "songhan@MIT.EDU",
   "nsf_id": "000762347",
   "pi_start_date": "2021-07-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Avenue",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 200000.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 100000.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 100000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>My research focuses on efficient deep learning and systems. This is a crucial area because deep learning requires immense computational power, limiting the deployment on everyday devices and burdening the cloud infrastructure. Retraining models on-device is even more challenging. As Moore&rsquo;s law is slowing down, full-stack innovation across software and hardware is imperative for efficiency.</p>\n<p><strong>I </strong><strong>pioneered an area </strong><strong>that marries algorithms and systems co-designed to accelerate deep learning. </strong>My work is distinguished by comprehensive optimizations across the full stack, including neural network models, systems, and accelerators. This research enables state-of-the-art neural networks that previously required cloud resources, to run efficiently on low-power mobile devices. It also substantially lowers the cost of cloud AI. My research created an interdisciplinary field of efficient deep learning computing, making AI greener and more economical. I have contributed to:</p>\n<p><strong>[1] Tiny Machine Learning (TinyML)</strong> &ndash; compressing neural networks to fit tiny edge devices.</p>\n<p>I started the field of model compression, pruning, and quantization that can shrink neural networks by &gt;10&times;. With the &ldquo;<a href=\"http://hanlab.mit.edu/projects/ofa\">once-for-all</a>&rdquo; hardware-aware neural architecture search technique, <a href=\"https://hanlab.mit.edu/projects/mcunet\">MCUNet</a> can fit a microcontroller. We further enable <a href=\"https://hanlab.mit.edu/projects/mcunetv3\">on-device training</a> under 256KB memory (1000&times; reduction).</p>\n<p><strong>[2] Accelerating AI with Sparsity</strong> &ndash; exploit sparsity with algorithm and system co-design.</p>\n<p>Sparsity in neural networks arises where not all neurons are connected. I am the first to bring weight sparsity in AI accelerators; I identify new sources of sparsity in modern AI: <a href=\"https://hanlab.mit.edu/projects/spatten\">sparse attention</a>, <a href=\"https://hanlab.mit.edu/projects/sparsevit\">sparse vision transformer</a>, <a href=\"https://hanlab.mit.edu/projects/pvcnn\">3D spatial sparsity</a>, and design efficient <a href=\"https://hanlab.mit.edu/projects/torchsparsepp\">systems</a> &amp; <a href=\"https://hanlab.mit.edu/projects/spatten\">accelerators</a> to exploit sparsity.</p>\n<p><strong>[3] </strong><strong>Efficient </strong><strong>Large Language Model (LLM) </strong>&ndash; quantization and KV cache optimization.</p>\n<p>Large language models are significantly larger (&gt;1000&times;) than TinyML models, presenting new computational challenges. We invented new techniques for <a href=\"https://hanlab.mit.edu/projects/smoothquant\">quantization</a>, <a href=\"https://hanlab.mit.edu/projects/distrifusion\">parallelization</a>, <a href=\"https://hanlab.mit.edu/projects/streamingllm\">KV cache optimization</a>, and new operators to efficiently perform <a href=\"https://hanlab.mit.edu/projects/efficientvit\">high-resolution</a> and <a href=\"https://hanlab.mit.edu/projects/quest\">long-context</a> generation.</p>\n<p><strong>Research Impact.</strong> Model compression, pruning and quantization have become the standard lexicon of our field. It is now the industry&rsquo;s standard practice. My research received the <strong>best paper awards</strong> at ICLR&rsquo;16, FPGA&rsquo;17, MLSys&rsquo;24, <strong>best demo award</strong> at DAC&rsquo;23, and multiple <strong>first places</strong> in the low-power computer vision challenge. I received the NSF CAREER Award for &ldquo;efficient algorithms and hardware for accelerated machine learning,&rdquo; Sloan Research Fellowship, and IEEE &ldquo;AIs 10 to Watch: The Future of AI&rdquo; award.&nbsp;I was named &ldquo;35 Innovators Under 35&rdquo; by MIT Technology Review. My work received over <a href=\"https://scholar.google.com/citations?user=E0iCaa4AAAAJ&amp;hl=en&amp;oi=ao\">58,000 citations</a> on Google Scholar and over <a href=\"https://github.com/mit-han-lab\">34,000 GitHub stars</a>. <a href=\"https://arxiv.org/pdf/1602.01528\">EIE</a> ranks among the <a href=\"https://www.sigarch.org/what-are-the-most-cited-isca-papers/\">top 5 most cited</a> papers in the 50-year history of ISCA (1953-2023). Efficient machine learning has become a field with <a href=\"https://www.emc2-ai.org/\">workshops</a> being held every year. TinyML and MCUNet have been incorporated into lectures at several universities: <a href=\"https://courses.cs.washington.edu/courses/cse599m/23sp/\">UW</a>, <a href=\"https://www.cs.princeton.edu/courses/archive/spr22/cos598D/general.html\">Princeton</a>, <a href=\"https://sites.google.com/g.harvard.edu/cs249-tinyml-2023\">Harvard</a> (<a href=\"https://harvard-edge.github.io/cs249r_book/contents/optimizations/optimizations.html#sec-model-optimizations-resource\">textbook</a>), <a href=\"https://tinyml.seas.upenn.edu/\">UPenn</a>, <a href=\"https://catalyst.cs.cmu.edu/15-884-mlsys-sp21/schedule\">CMU</a>.</p>\n<p>Our research is widely adopted by industry. <a href=\"https://hanlab.mit.edu/projects/smoothquant\">SmoothQuant</a> and <a href=\"https://hanlab.mit.edu/projects/awq\">AWQ</a> for LLM quantization have been adopted by <a href=\"https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/Falcon180B-H200.md\">NVIDIA</a>, <a href=\"https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Effective-Weight-Only-Quantization-for-Large-Language-Models/post/1529552\">Intel</a>, <a href=\"https://blogs.windows.com/windowsdeveloper/2024/05/24/quantization-with-directml-helps-you-scale-further-on-windows/\">Microsoft</a>, <a href=\"https://rocm.blogs.amd.com/software-tools-optimization/ck-int8-gemm-sq/README.html\">AMD</a>,&nbsp;<a href=\"https://huggingface.co/docs/transformers/main_classes/quantization\">HuggingFace</a>, <a href=\"https://github.com/lm-sys/FastChat/blob/main/docs/awq.md\">Berkeley</a> to accelerate LLM inference. AWQ received the best paper award at MLSys&rsquo;24 with more than 6 million downloads on HuggingFace. <a href=\"https://hanlab.mit.edu/projects/streamingllm\">StreamingLLM</a> excited the community with long generation under constant memory, it&rsquo;s adopted by <a href=\"file:///Users/songhan/Dropbox%20(MIT)/tenure/FPR/NVIDIA%20TensorRT-LLM\">NVIDIA</a>, <a href=\"https://github.com/intel/intel-extension-for-transformers\">Intel</a>, <a href=\"https://www.linkedin.com/posts/luis-ceze-50b2314_fantastic-to-see-mlc-llms-impact-and-what-activity-7141568060674457600-sbKd/\">CMU, UW, OctoAI</a>, <a href=\"https://github.com/huggingface/transformers/issues/26553\">HuggingFace</a>. The <a href=\"https://hanlab.mit.edu/projects/ofa\">Once-For-All</a> network for hardware-aware neural architecture search is adopted by <a href=\"https://pytorch.org/hub/pytorch_vision_once_for_all/\">PyTorch</a>, <a href=\"https://blog.nnabla.org/release/fairnas-and-ofa/\">SONY,</a> <a href=\"https://github.com/MaximIntegratedAI/ai8x-training\">ADI</a>, <a href=\"https://arxiv.org/pdf/2406.10260\">NVIDIA</a>, and its sister project <a href=\"https://hanlab.mit.edu/projects/proxylessnas\">ProxylessNAS</a> is adopted by <a href=\"https://pytorch.org/hub/pytorch_vision_proxylessnas/\">PyTorch</a> and <a href=\"https://github.com/Microsoft/nni/blob/v1.6/docs/en_US/NAS/Proxylessnas.md\">Microsoft</a>. Neural network pruning and sparsity has influenced the modern AI chip design by <a href=\"https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/\">NVIDIA</a>, <a href=\"https://apple.github.io/coremltools/docs-guides/source/opt-palettization-overview.html\">Apple</a>, <a href=\"https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html\">AMD</a>. My research led to successful commercialization. I co-founded DeePhi, a startup specializing in efficient AI accelerators, which was acquired by Xilinx before I joined MIT. After I join MIT, based on our open-source project: <a href=\"https://github.com/mit-han-lab/once-for-all\">Once-for-All</a>, I co-founded OmniML focusing on model optimization software, which was acquired by NVIDIA. My research has been featured in over 30 press articles, including IEEE Spectrum, Wired, MIT News, Venture Beat, and has been spotlighted on the MIT homepage four times.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 09/05/2024<br>\nModified by: Song&nbsp;Han</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2106711/2106711_10746863_1725589447571_Picture2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2106711/2106711_10746863_1725589447571_Picture2--rgov-800width.png\" title=\"TinyChat Computer\"><img src=\"/por/images/Reports/POR/2024/2106711/2106711_10746863_1725589447571_Picture2--rgov-66x44.png\" alt=\"TinyChat Computer\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">On-device LLM using AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</div>\n<div class=\"imageCredit\">Quincy Kuang</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Song&nbsp;Han\n<div class=\"imageTitle\">TinyChat Computer</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nMy research focuses on efficient deep learning and systems. This is a crucial area because deep learning requires immense computational power, limiting the deployment on everyday devices and burdening the cloud infrastructure. Retraining models on-device is even more challenging. As Moores law is slowing down, full-stack innovation across software and hardware is imperative for efficiency.\n\n\nI pioneered an area that marries algorithms and systems co-designed to accelerate deep learning. My work is distinguished by comprehensive optimizations across the full stack, including neural network models, systems, and accelerators. This research enables state-of-the-art neural networks that previously required cloud resources, to run efficiently on low-power mobile devices. It also substantially lowers the cost of cloud AI. My research created an interdisciplinary field of efficient deep learning computing, making AI greener and more economical. I have contributed to:\n\n\n[1] Tiny Machine Learning (TinyML)  compressing neural networks to fit tiny edge devices.\n\n\nI started the field of model compression, pruning, and quantization that can shrink neural networks by 10. With the once-for-all hardware-aware neural architecture search technique, MCUNet can fit a microcontroller. We further enable on-device training under 256KB memory (1000 reduction).\n\n\n[2] Accelerating AI with Sparsity  exploit sparsity with algorithm and system co-design.\n\n\nSparsity in neural networks arises where not all neurons are connected. I am the first to bring weight sparsity in AI accelerators; I identify new sources of sparsity in modern AI: sparse attention, sparse vision transformer, 3D spatial sparsity, and design efficient systems & accelerators to exploit sparsity.\n\n\n[3] Efficient Large Language Model (LLM)  quantization and KV cache optimization.\n\n\nLarge language models are significantly larger (1000) than TinyML models, presenting new computational challenges. We invented new techniques for quantization, parallelization, KV cache optimization, and new operators to efficiently perform high-resolution and long-context generation.\n\n\nResearch Impact. Model compression, pruning and quantization have become the standard lexicon of our field. It is now the industrys standard practice. My research received the best paper awards at ICLR16, FPGA17, MLSys24, best demo award at DAC23, and multiple first places in the low-power computer vision challenge. I received the NSF CAREER Award for efficient algorithms and hardware for accelerated machine learning, Sloan Research Fellowship, and IEEE AIs 10 to Watch: The Future of AI award.I was named 35 Innovators Under 35 by MIT Technology Review. My work received over 58,000 citations on Google Scholar and over 34,000 GitHub stars. EIE ranks among the top 5 most cited papers in the 50-year history of ISCA (1953-2023). Efficient machine learning has become a field with workshops being held every year. TinyML and MCUNet have been incorporated into lectures at several universities: UW, Princeton, Harvard (textbook), UPenn, CMU.\n\n\nOur research is widely adopted by industry. SmoothQuant and AWQ for LLM quantization have been adopted by NVIDIA, Intel, Microsoft, AMD,HuggingFace, Berkeley to accelerate LLM inference. AWQ received the best paper award at MLSys24 with more than 6 million downloads on HuggingFace. StreamingLLM excited the community with long generation under constant memory, its adopted by NVIDIA, Intel, CMU, UW, OctoAI, HuggingFace. The Once-For-All network for hardware-aware neural architecture search is adopted by PyTorch, SONY, ADI, NVIDIA, and its sister project ProxylessNAS is adopted by PyTorch and Microsoft. Neural network pruning and sparsity has influenced the modern AI chip design by NVIDIA, Apple, AMD. My research led to successful commercialization. I co-founded DeePhi, a startup specializing in efficient AI accelerators, which was acquired by Xilinx before I joined MIT. After I join MIT, based on our open-source project: Once-for-All, I co-founded OmniML focusing on model optimization software, which was acquired by NVIDIA. My research has been featured in over 30 press articles, including IEEE Spectrum, Wired, MIT News, Venture Beat, and has been spotlighted on the MIT homepage four times.\n\n\n\t\t\t\t\tLast Modified: 09/05/2024\n\n\t\t\t\t\tSubmitted by: SongHan\n"
 }
}