{
 "awd_id": "2123568",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: NCS-FO: Active vision during natural behavior: More than meets the eye?",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 87861.0,
 "awd_amount": 87861.0,
 "awd_min_amd_letter_date": "2021-08-17",
 "awd_max_amd_letter_date": "2021-08-17",
 "awd_abstract_narration": "Vision is a process by which the image falling on the eyes is processed by specialized neurons within visual brain areas. Neurons in the early stages of visual processing convey information about small bits of the visual scene, like pixel-detectors in a camera. For example, a neuron in visual cortex might respond best to a small white bar at a particular location in visual space. Should this example neuron respond differently when the white bar is part of an object that we have seen before, or one that we are moving towards? Psychology might suggest so, but for almost 60 years, most scientists studying the neural basis of visual perception have implicitly assumed that responses of neurons in visual cortex depend only on the visual image falling on the eyes. It is increasingly clear that neurons in the visual cortex do indeed care about behavioral context \u2013 as well as the state of the brain itself. These external, internal, and contextual factors influence how neurons process the visual scene. Exactly how much these \u201cnon-visual\u201d factors influence visual cortical neurons remains a significant open question that this project aims to address.\r\n\r\nThe experiments will record from neurons in the visual cortex of ferrets as they freely explore a naturalistic environment. Using position and eye-tracking cameras, the project will both recreate a movie of what the ferret saw within the environment, and track other observable variables related to behavior. The movie will then be replayed to the ferret while it is anesthetized, thus directly measuring any differences in neuronal responses to the same visual stimulation in these two very different contexts. Analysis will compare the physiological quality and statistical properties of neuronal responses across naturalistic and anesthetized conditions to quantify the contribution of natural context to neuronal responses. Results will relate the differences in the freely moving context to specific sources, like motor actions such as eye and head movements, familiarity with specific visual features, and their behavioral relevance. Experiments will inform models for how these sources influence neuronal activity, setting the stage for understanding the function of non-retinal inputs for sensory perception. The project will provide a foundation for long-term studies of natural vision.\r\nThis project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NCS), a multidisciplinary program jointly supported by the Directorates for Biology (BIO), Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Butts",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel A Butts",
   "pi_email_addr": "dab@umd.edu",
   "nsf_id": "000515420",
   "pi_start_date": "2021-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland, College Park",
  "perf_str_addr": "1207 Biology-Psychology Bldg #14",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207424401",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8551",
   "pgm_ref_txt": "IntgStrat Undst Neurl&Cogn Sys"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 87861.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project established a platform for studying active visual perception in naturalistic conditions within the laboratory, extending the boundaries of what is currently possible in sensory systems neuroscience. Our experimental paradigm leverages simulated visual reality with mobile neurophysiological multi-electrode recordings, coupled with computational approaches&nbsp; that offer a detailed characterization of visual processing, including elements of active vision influence it. Our long-term research agenda is to challenge traditional paradigms performed under head-fixed conditions, and typically using impoverished laboratory paradigms. Our ability to do so is supported by the multidisciplinary approach we developed, which bridged neurophysiological and computational methodologies and advances knowledge and educational opportunities through data sharing.</p>\r\n<p>The first specific objective of the project (Aim 1) was to develop a strategy to synchronously collect 4 data streams (V1 neurons, eye position, head position, and video of animals&rsquo; view). This included establishing an analysis pipeline for generating movie data that integrates eye and head positions as well as ferrets&rsquo; views of the environment. This has been accomplished and preliminary data that can be plugged into the modeling approach has been collected.&nbsp;</p>\r\n<p>The second specific objective (Aim 2) was to model V1 neuronal activity recorded from a freely moving and behaving ferret. Because the general assumption in the field is that elements of freely behaving vision do not influence visual processing, we focused on developing latent variable models that can infer visual processing changes from recorded neural activity. We did this in parallel with Aim 1 using data from other collaborators that were recorded in more controlled circumstances, and used these models to measure the degree that attention, arousal, and running modulate visual signaling.&nbsp;</p>\r\n<p>Key outcomes of this project were: the successful implantation of multi-electrode arrays, recording of neuronal activity in freely moving animals, successful head and eye tracking in freely moving animals, and the development and refinement of latent variable models that can be applied to this data. These accomplishments set the foundation for future work (past this funding period) that integrate them together in order to address how the brain processes fully natural, active vision.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/29/2025<br>\nModified by: Daniel&nbsp;A&nbsp;Butts</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project established a platform for studying active visual perception in naturalistic conditions within the laboratory, extending the boundaries of what is currently possible in sensory systems neuroscience. Our experimental paradigm leverages simulated visual reality with mobile neurophysiological multi-electrode recordings, coupled with computational approaches that offer a detailed characterization of visual processing, including elements of active vision influence it. Our long-term research agenda is to challenge traditional paradigms performed under head-fixed conditions, and typically using impoverished laboratory paradigms. Our ability to do so is supported by the multidisciplinary approach we developed, which bridged neurophysiological and computational methodologies and advances knowledge and educational opportunities through data sharing.\r\n\n\nThe first specific objective of the project (Aim 1) was to develop a strategy to synchronously collect 4 data streams (V1 neurons, eye position, head position, and video of animals view). This included establishing an analysis pipeline for generating movie data that integrates eye and head positions as well as ferrets views of the environment. This has been accomplished and preliminary data that can be plugged into the modeling approach has been collected.\r\n\n\nThe second specific objective (Aim 2) was to model V1 neuronal activity recorded from a freely moving and behaving ferret. Because the general assumption in the field is that elements of freely behaving vision do not influence visual processing, we focused on developing latent variable models that can infer visual processing changes from recorded neural activity. We did this in parallel with Aim 1 using data from other collaborators that were recorded in more controlled circumstances, and used these models to measure the degree that attention, arousal, and running modulate visual signaling.\r\n\n\nKey outcomes of this project were: the successful implantation of multi-electrode arrays, recording of neuronal activity in freely moving animals, successful head and eye tracking in freely moving animals, and the development and refinement of latent variable models that can be applied to this data. These accomplishments set the foundation for future work (past this funding period) that integrate them together in order to address how the brain processes fully natural, active vision.\r\n\n\n\t\t\t\t\tLast Modified: 01/29/2025\n\n\t\t\t\t\tSubmitted by: DanielAButts\n"
 }
}