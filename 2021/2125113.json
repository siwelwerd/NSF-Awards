{
 "awd_id": "2125113",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: CHS: Harnessing Machine Learning to Improve Human Decision Making: A Case Study on Deceptive Detection",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2021-01-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 174977.0,
 "awd_amount": 145886.0,
 "awd_min_amd_letter_date": "2021-04-19",
 "awd_max_amd_letter_date": "2021-04-19",
 "awd_abstract_narration": "Humans are the final decision-makers in a wide variety of critical tasks that involve ethical and legal concerns, ranging from predicting criminal recidivism by the courts, to medical diagnosis, to identifying misleading information. These are challenging tasks for humans and for machines. However, for some closely-constrained tasks where vast amounts of training data are available, machine learning algorithms can outperform humans.  If the knowledge encoded in the machine learning models can be elucidated to humans, these implementations can support human decision making and even tutor humans to achieve better performance. Those are the goals of this project.\r\n\r\nThis project investigates human decision making with assistance from machine learning models for the task of detecting deception. It explores two domains routinely encountered on the Internet, online reviews and news articles. It develops two forms of assistance from machine learning models to improve human decision making while retaining human agency: 1) providing information based on machine learning models for real-time support of human decisions, and 2) automatically generating tutorials to help humans understand the nature of this task from the perspective of machine learning models (offline training).  This project develops novel algorithms that incorporate educational psychology to help teach humans the knowledge encoded in machine learning algorithms. The project evaluates the two forms of assistance by tracking human performance improvement in user studies. The project explores additional indicators, such as trust and time to complete tasks, to further understand collaboration between humans and machine learning algorithms.  The knowledge  gained in the project will inform design principles for effective integration of artificial intelligence into human decision making.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chenhao",
   "pi_last_name": "Tan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chenhao Tan",
   "pi_email_addr": "chenhao@chenhaot.com",
   "nsf_id": "000745868",
   "pi_start_date": "2021-04-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "6054 South Drexel Avenue Suite 300",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606372612",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 145886.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aims to&nbsp;investigate human decision making with assistance from machine learning models. Using deception detection as a testbed, it develops two forms of assistance from machine learning models to improve human decision making while retaining human agency: 1) providing information based on machine learning models for real-time support of human decisions, and 2) automatically generating tutorials to help humans understand the nature of this task from the perspective of machine learning models (offline training).&nbsp;It further extends to two additional tasks: recidivism prediction and profession detection. In addition, it lays the foundation for future projects by exploring novel directions such as out-of-distribution evaluation and conditional delegation.</p>\n<p><br /><strong>Intellectual Merits</strong>. This project constitutes an important step towards building machine-in-the-loop methods to empower humans with machine learning in critical challenging tasks. It brings the human side to the development of machine learning and lies at the intersection of human-computer interaction and machine learning. Specifically, it makes the following contributions: 1) empirically investigating human cognition and human performance in deception detection with assistance from machine learning models; 2) developing novel methods to generate training modules with examples and explanations for humans based on machine learning models; 3) deepening our understanding and advancing design principles regarding how humans interact with assistance from machine learning models in challenging tasks.&nbsp;<br /><br /><strong>Broader Impacts</strong>. The project contributes to the discussion on the role of artificial intelligence in human society and presents a perspective in which machine learning is designed to assist humans while retaining human agency. The PI releases a public website to demonstrate the proposed work and engage the public with human-centered machine learning approaches. The PI has presented demos based on this work at the museum of science and industry. In addition to the training of graduate students, the PI has integrated findings from the proposed work into educational activities at the University of Colorado Boulder and the University of Chicago, and make educational materials publicly available for instructors at other institutions to use. The research findings have been presented at top CS conferences, including a tutorial at Annual Conference of the North American Chapter of the Association for Computational Linguistics with videos available online.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/29/2022<br>\n\t\t\t\t\tModified by: Chenhao&nbsp;Tan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project aims to investigate human decision making with assistance from machine learning models. Using deception detection as a testbed, it develops two forms of assistance from machine learning models to improve human decision making while retaining human agency: 1) providing information based on machine learning models for real-time support of human decisions, and 2) automatically generating tutorials to help humans understand the nature of this task from the perspective of machine learning models (offline training). It further extends to two additional tasks: recidivism prediction and profession detection. In addition, it lays the foundation for future projects by exploring novel directions such as out-of-distribution evaluation and conditional delegation.\n\n\nIntellectual Merits. This project constitutes an important step towards building machine-in-the-loop methods to empower humans with machine learning in critical challenging tasks. It brings the human side to the development of machine learning and lies at the intersection of human-computer interaction and machine learning. Specifically, it makes the following contributions: 1) empirically investigating human cognition and human performance in deception detection with assistance from machine learning models; 2) developing novel methods to generate training modules with examples and explanations for humans based on machine learning models; 3) deepening our understanding and advancing design principles regarding how humans interact with assistance from machine learning models in challenging tasks. \n\nBroader Impacts. The project contributes to the discussion on the role of artificial intelligence in human society and presents a perspective in which machine learning is designed to assist humans while retaining human agency. The PI releases a public website to demonstrate the proposed work and engage the public with human-centered machine learning approaches. The PI has presented demos based on this work at the museum of science and industry. In addition to the training of graduate students, the PI has integrated findings from the proposed work into educational activities at the University of Colorado Boulder and the University of Chicago, and make educational materials publicly available for instructors at other institutions to use. The research findings have been presented at top CS conferences, including a tutorial at Annual Conference of the North American Chapter of the Association for Computational Linguistics with videos available online.\n\n \n\n\t\t\t\t\tLast Modified: 12/29/2022\n\n\t\t\t\t\tSubmitted by: Chenhao Tan"
 }
}