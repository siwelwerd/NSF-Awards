{
 "awd_id": "2106446",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "OAC Core: SMALL: DeepJIMU: Model-Parallelism Infrastructure for Large-scale Deep Learning by Gradient-Free Optimization",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032922625",
 "po_email": "jjli@nsf.gov",
 "po_sign_block_name": "Juan Li",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 498609.0,
 "awd_amount": 498609.0,
 "awd_min_amd_letter_date": "2020-11-19",
 "awd_max_amd_letter_date": "2020-11-19",
 "awd_abstract_narration": "In recent years, the use of deep neural networks (DNNs) has been increasing to obtain useful insights for scientific explorations, business management, security, and healthcare. The constant improvement of DNN model performance has been accompanied by an increase in their complexity and size, which indicate a clear trend toward larger and deeper models. Such a trend is especially the case for numerous important application domains, such as remote sensing where super-high-resolution geospatial image processing is required. Such applications lead to a huge challenge for the training of very large models to fit on a single computing device (e.g., a graphics processing unit, GPU), and hence raises urgent demands for partitioning such models across multiple computing devices and parallelizing the training process (i.e., model parallelism). However, until now model parallelism for DNNs has been poorly explored and is very difficult due to the inherent bottleneck from the backpropagation algorithm, where the training of one layer closely depends on input from all the previous layers. To overcome these challenges, this project aims a radically new pathway toward model parallelism infrastructure for large-scale DNNs based on optimization methods that do not rely on backpropagation for training. This project plans to address the challenges of training very large and very deep neural network models that require huge amounts of high-dimensional data. The project will develop new optimization techniques and distributed DNN training software infrastructure to enable wider applications and deployment of model parallel deep learning training. The project includes educational and engagement activities that will greatly increase the community's understanding of distributed machine learning algorithms and systems. Those activities include teaching and training students and peers, providing graduate and undergraduate students with new courses, and research and internship opportunities, as well as broadening participation of underrepresented groups and students at local high schools.\r\n\r\nThis project brings together researchers in machine learning algorithms, distributed computing systems, remote sensing, and spatial data science, to boost the performance and scalability of deep learning applications enhanced by model parallelism. Specifically, this project focuses on proposing and developing a suite of new model parallelism optimization algorithms and system infrastructure for training large-scale DNNs, especially for image processing of massive datasets for geospatial scientific research. To enable model parallelism in the training, new gradient-free optimization methods are proposed to break down the whole problem of DNN optimization into subproblems, which can then be solved separately in parallel (by many workers) with high efficiency. The products of this project include new theories and algorithms for model parallelism, along with an efficient gradient-free DNN training framework with new scheduling and work balancing techniques. Specifically, this project has the following research thrusts: 1) Develop new gradient-free methods for training various types of DNNs; 2) Designing an algorithmic and theoretical framework of model parallelization based on gradient-free optimization; and 3) Building a scalable and efficient distributed training framework for a broad range of model parallel DNN training applications, such as deep learning for large graphs and very deep convolutional neural networks for image processing. This project also involves both theoretical and experimental comparison between the new techniques and current state-of-the-art methods, including those using gradient-based optimizations and pipeline parallelism.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Liang",
   "pi_last_name": "Zhao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Liang Zhao",
   "pi_email_addr": "liang.zhao@emory.edu",
   "nsf_id": "000754958",
   "pi_start_date": "2020-11-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Emory University",
  "inst_street_address": "201 DOWMAN DR NE",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4047272503",
  "inst_zip_code": "303221061",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "EMORY UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "S352L5PJLMP8"
 },
 "perf_inst": {
  "perf_inst_name": "Emory University",
  "perf_str_addr": "1599 Clifton Rd NE",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303224250",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "090Y00",
   "pgm_ele_name": "OAC-Advanced Cyberinfrast Core"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 498609.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project aims at charting a radically new model parallelism infrastructure for the training of large-scale DNNs based on gradient-free optimization. Our new gradient-free optimization has broken down the composite function of DNN optimization into subproblems, which can then be solved separately in parallel (by many workers) with high ef&#64257;ciency. New theories and algorithms for model parallelism, along with a novel gradient-free DNN training system with decentralized scheduling and work re-partitioning have be debuted. Speci&#64257;cally, this project: 1) developed new gradient-free methods for training of various types of DNNs; 2) designed an algorithmic and theoretical framework of model parallelization based on gradient-free optimization; and 3) built a scalable and ef&#64257;cient distributed training system with novel scheduling and work re-partitioning techniques attuned to a broad range of model parallel DNN training applications such as deep learning for large graphs and very-deep convolutional neural networks for image processing.&nbsp;We have demonstrated the feasibility of gradient-free optimization and the condition of the situation where gradient-free optimization works better and worse than gradient-based methods. We have extended the success of the gradient-free optimization to non-i.i.d. data, such as graph data, and verified using benchmark graph datasets.&nbsp;</span>This project has been advancing the algorithmic and theoretical foundations for distributed gradient-free optimization for deep learning, by innovatively exploring the synergistic convergence of techniques and theories for distributed computing, deep learning, and nonconvex optimization. The techniques and theories we proposed in this project for distributed deep learning have also advanced distributed system research as well as relevant theories on model parallelism. The novel alternating optimization framework for deep learning model training is generic and hence can benefit different deep learning models. The proposed theoretical analysis strategies can benefit other research on deep learning models for different types of data such as images and graphs.&nbsp;The techniques developed in this project have been widening the bridge between deep learning, model parallelism, and various social and natural science domains that require large-scale parallel computing. This project strengthened the PIs' collaborative research on parallelizing multiple deep-learning models for different data types. It has also benefited the research on event prediction and remote sensing, based on collaborating with the PIs' colleagues on relevant domains. The proposed techniques helped fill the gaps among model developers, data scientists, and domain experts, leading to an additional profound understanding of the behaviors of different optimization strategies for complex models such as deep neural networks.</p><br>\n<p>\n Last Modified: 12/18/2024<br>\nModified by: Liang&nbsp;Zhao</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project aims at charting a radically new model parallelism infrastructure for the training of large-scale DNNs based on gradient-free optimization. Our new gradient-free optimization has broken down the composite function of DNN optimization into subproblems, which can then be solved separately in parallel (by many workers) with high ef&#64257;ciency. New theories and algorithms for model parallelism, along with a novel gradient-free DNN training system with decentralized scheduling and work re-partitioning have be debuted. Speci&#64257;cally, this project: 1) developed new gradient-free methods for training of various types of DNNs; 2) designed an algorithmic and theoretical framework of model parallelization based on gradient-free optimization; and 3) built a scalable and ef&#64257;cient distributed training system with novel scheduling and work re-partitioning techniques attuned to a broad range of model parallel DNN training applications such as deep learning for large graphs and very-deep convolutional neural networks for image processing.We have demonstrated the feasibility of gradient-free optimization and the condition of the situation where gradient-free optimization works better and worse than gradient-based methods. We have extended the success of the gradient-free optimization to non-i.i.d. data, such as graph data, and verified using benchmark graph datasets.This project has been advancing the algorithmic and theoretical foundations for distributed gradient-free optimization for deep learning, by innovatively exploring the synergistic convergence of techniques and theories for distributed computing, deep learning, and nonconvex optimization. The techniques and theories we proposed in this project for distributed deep learning have also advanced distributed system research as well as relevant theories on model parallelism. The novel alternating optimization framework for deep learning model training is generic and hence can benefit different deep learning models. The proposed theoretical analysis strategies can benefit other research on deep learning models for different types of data such as images and graphs.The techniques developed in this project have been widening the bridge between deep learning, model parallelism, and various social and natural science domains that require large-scale parallel computing. This project strengthened the PIs' collaborative research on parallelizing multiple deep-learning models for different data types. It has also benefited the research on event prediction and remote sensing, based on collaborating with the PIs' colleagues on relevant domains. The proposed techniques helped fill the gaps among model developers, data scientists, and domain experts, leading to an additional profound understanding of the behaviors of different optimization strategies for complex models such as deep neural networks.\t\t\t\t\tLast Modified: 12/18/2024\n\n\t\t\t\t\tSubmitted by: LiangZhao\n"
 }
}