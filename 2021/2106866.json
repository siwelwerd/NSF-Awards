{
 "awd_id": "2106866",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: HCC: Medium: TouchBots for Surface Haptics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924420",
 "po_email": "cbethel@nsf.gov",
 "po_sign_block_name": "Cindy Bethel",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2025-09-30",
 "tot_intn_awd_amt": 399999.0,
 "awd_amount": 399999.0,
 "awd_min_amd_letter_date": "2021-07-09",
 "awd_max_amd_letter_date": "2021-07-09",
 "awd_abstract_narration": "This project will lead to a new class human-machine interfaces that provide tactile feedback to fingertips. Fingertips are remarkable multimodal sensors capable of detecting pressure and vibration, local defor-mation such as braille cells, hardness/softness, warmth/coolness, and endless types of textures.  There are strong reasons to exploit these sensory capabilities in interfaces: making touch screens more accessi-ble for the vision impaired, making it easier to use touch interfaces in automobiles, providing touch feedback in augmented and virtual reality, and supporting remote touch in social, medical and retail applications.  The wealth of commercially important use cases has led to a fast-growing market for touch feedback (\u201chaptic\u201d) technologies, yet none of the existing approaches engages more than a small fraction of the fingertips\u2019 capabilities.  The new interfaces to be developed \u2013 TouchBots \u2013 will provide a greatly expanded suite of haptic feedback modalities.  A TouchBot is a miniaturized module that is placed be-tween a fingertip and a touch surface, such as a touchscreen or trackpad.  It includes two main subsys-tems, one that guides the finger along a programmable path, and another that provides a sense of the shape and texture of objects along that path.  Together, these subsystems will enable TouchBots to offer many new haptic interactions such as touch-typing interfaces without keyboards, realistic surface tex-tures for virtual reality, and fully programmable braille and tactile graphics anywhere there is a touch surface. These interactions have the potential to make touch screen devices accessible to the vision im-paired. Recognizing that a new generation of technological innovators will be needed to commercialize the fruits of this research, close ties will be forged to graduate-level curricula in innovation, leading to impact-minded individuals who are well-positioned to provide leadership in the growing haptics indus-try.\r\n\r\nThe capabilities of a TouchBot stem from the manner in which it interacts with the underlying surface. The proposed TouchBot design include: (a) kinesthetic subsystem that provides feedback via passively rolling, but actively steered, wheels; (b) a cutaneous module that provides feedback via an array of tiny \"pucks\"; (c) selective brake mechanism for each of these pucks using electroadhesion. This approach, known as \u201ccobotic,\u201d has been thoroughly developed for macro-scale devices, and will be adapted here to the meso-scale by careful integration of steering actuation, wheel design, and intent sensing.  Touch-bot will be extremely compact, with a low-power, and high-performance system for motion guidance. The ability of the TouchBot to provide local shape and texture will be provided by an array of tiny \u201cpucks,\u201d using the selective breaking mechanism. This research will leverage prior efforts in areas as diverse as surface haptics, wall-climbing robots and data storage read-write heads to realize an electro-adhesive device that is high-force and high-bandwidth and that can be used to control a high-density tactile array. By bringing these technologies together into fingertip-scale devices, it will be possible to demonstrate a wide range of surface haptic interactions including buttons, toggles, raised line drawings, braille characters, tactile graphics, and textures. Participatory design methods will be used to identify potential uses of TouchBot in the areas such as automotive and user interaction design. Experience proto-type and rapid iteration will be used to create stimuli that evoke rich feedback.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mary",
   "pi_last_name": "Hipwell",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Mary C Hipwell",
   "pi_email_addr": "cynthia.hipwell@tamu.edu",
   "nsf_id": "000780414",
   "pi_start_date": "2021-07-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M Engineering Experiment Station",
  "perf_str_addr": "600 Discovery Drive",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778430001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 399999.0
  }
 ],
 "por": null
}