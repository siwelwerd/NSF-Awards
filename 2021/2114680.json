{
 "awd_id": "2114680",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: SaTC-EDU: A Life-Cycle Approach for Artificial Intelligence-Based Cybersecurity Education",
 "cfda_num": "47.076",
 "org_code": "11010000",
 "po_phone": "7032928182",
 "po_email": "asiraj@nsf.gov",
 "po_sign_block_name": "Ambareen Siraj",
 "awd_eff_date": "2021-05-01",
 "awd_exp_date": "2023-10-31",
 "tot_intn_awd_amt": 298214.0,
 "awd_amount": 298214.0,
 "awd_min_amd_letter_date": "2021-04-21",
 "awd_max_amd_letter_date": "2021-04-21",
 "awd_abstract_narration": "In order to devise more effective defenses against a rising number of cyber attacks, recent security solutions leverage artificial intelligence (AI) techniques. While there are plenty of publicly available AI approaches to cybersecurity, successful use depends on users\u2019 technical and soft skills. Moreover, AI-based approaches have been intensely scrutinized with respect to their security and ethics, delaying deployment. AI itself can be attacked and there can also be issues with discrimination in AI-based classification.  Thus, for AI to be effectively and quickly adopted for cybersecurity, AI security and ethics need to be assured. Training cybersecurity professionals to understand how to effectively use AI for cybersecurity and to be aware of AI security and ethics issues is critical for effective design and deployment of AI-based cybersecurity solutions. Future cybersecurity professionals must also be able effectively to communicate relevant information related to AI-based security mechanisms and policies to a variety of stakeholders.  This project will design competency-driven educational activities focusing on AI techniques for cybersecurity that will increase the effective and ethical application of AI-enhanced cybersecurity. \r\n\r\nThe project\u2019s educational approach is based on four interrelated pillars. The first pillar focuses on educational activities covering a systematic AI-powered approach to cybersecurity, based on defender and attacker perspectives. The second pillar focuses on educational activities covering a systematic analysis of categories of AI attack and corresponding mitigation techniques. The third and fourth pillars focus on AI ethics and approaches to cybersecurity communications, respectively. A combination of social, philosophical, and technical perspectives will create a unique approach to cybersecurity communication. Together, the pillars provide a systematic perspective of AI-powered cybersecurity. They provide both foundational and technical competencies related to AI ethics and cybersecurity communication that benefit multiple stakeholders, from students and educators to employers and regulators. An important goal of the project is to make sure that students and educators understand that cybersecurity, including AI-based defense techniques, requires deployment of different types of defense approaches.  The project includes design of educational projects, focusing on well-known data breaches and other types of attack and how AI-based security techniques could prevent or mitigate these attacks.\r\n\r\nThis project is supported by a special initiative of the Secure and Trustworthy Cyberspace (SaTC) program to foster new, previously unexplored, collaborations between the fields of cybersecurity, artificial intelligence, and education. The SaTC program aligns with the Federal Cybersecurity Research and Development Strategic Plan and the National Privacy Research Strategy to protect and preserve the growing social and economic benefits of cyber systems while ensuring security and privacy.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DGE",
 "org_div_long_name": "Division Of Graduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Elisa",
   "pi_last_name": "Bertino",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Elisa Bertino",
   "pi_email_addr": "bertino@purdue.edu",
   "nsf_id": "000456326",
   "pi_start_date": "2021-04-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sorin",
   "pi_last_name": "Matei",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Sorin A Matei",
   "pi_email_addr": "smatei@purdue.edu",
   "nsf_id": "000107322",
   "pi_start_date": "2021-04-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "305 N. University Street",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072107",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "093Z",
   "pgm_ref_txt": "AI Education/Workforce Develop"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0421",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04002122DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 298214.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Data ransoms, denial of service, sabotage, and data theft, are on a dramatic increase, creating a cyberattack culture that makes our workplaces, schools, or private residences vulnerable. In order to devise more effective defenses, recent security solutions leverage AI techniques, which are becoming more feasible with significant advances in AI combined with big data collection and analysis capabilities. However, whereas there are plenty of publicly available AI techniques, their successful use depends on the technical and soft skills of their users. Training them demands much care, both in terms of goals and means. Significantly, AI-based approaches have been intensely scrutinized with respect to their security &ndash; as AI itself can be attacked &ndash; and ethics (see for example issues of discrimination in AI-based classification) delaying their deployment. Thus, for AI to be effectively and quickly adopted in cybersecurity, AI security and ethics need to be also assured. Training cybersecurity professionals to understand how to effectively use AI for cybersecurity and also be aware of AI security and ethics issues is thus a critical requirement for effective design and deployment of AI-based cybersecurity solutions. Future cybersecurity professionals must also be able to effectively communicate relevant information related to AI-based security mechanisms and policies to a variety of stakeholders. &nbsp;</p>\n<p>This project has designed an educational approach driven by a cybersecurity lifecycle, consisting of multiple phases (prepare and prevent; monitor and detect; diagnose and understand; react, recovery and fix). Each phase is supported by various security functions (such as detection functions to detect attack activities), organized according to a taxonomy. For each such security functions, the educational approach covers the AI approaches that have been proposed to support/enhance the function. The technical activities are complemented by educational activities covering AI security and ethics as related to the use of AI techniques, and communication approaches allowing students to learn how best to communicate security and privacy policies to end-users. Students are trained in mastering knowledge related to: (a) foundations of AI techniques for specific security tasks in each lifecycle phase &ndash; these foundations are illustrated with cybersecurity examples and scenarios; (b) methods addressing issues when applying AI techniques to cybersecurity tasks &ndash; a notable example is the lack of training dataset that can be addressed using adversarial domain adaptation and generating synthetic data using generative adversarial networks; (c) scenarios showing how to configure specific AI techniques, such as reinforcement learning, and/or how / which features to extract from artifacts of interest (such as software programs) for analyzing these artifacts with AI techniques &ndash; for example to classify a piece of malware. &nbsp;In terms of human interaction core competencies, students are trained about&nbsp;&nbsp; human-AI interaction, systems thinking, focusing on trade-off judgement of human vs. AI efficiency and desirability of outcomes, and empathic/evaluative communication, which uses the most appropriate persuasive techniques to mitigate the undesirable effects of AI under or over efficient use in sorting out cybersecurity crises.</p><br>\n<p>\n Last Modified: 11/10/2023<br>\nModified by: Elisa&nbsp;Bertino</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/2114680/2114680_10729045_1699656929574_figure2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/2114680/2114680_10729045_1699656929574_figure2--rgov-800width.png\" title=\"Taxonomy of security functions\"><img src=\"/por/images/Reports/POR/2023/2114680/2114680_10729045_1699656929574_figure2--rgov-66x44.png\" alt=\"Taxonomy of security functions\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A taxonomy covering the security functions for which AI techniques have been proposed.</div>\n<div class=\"imageCredit\">Elisa Bertino</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Elisa&nbsp;Bertino\n<div class=\"imageTitle\">Taxonomy of security functions</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/2114680/2114680_10729045_1699657103867_figure--rgov-214x142.png\" original=\"/por/images/Reports/POR/2023/2114680/2114680_10729045_1699657103867_figure--rgov-800width.png\" title=\"Security Lifecycle\"><img src=\"/por/images/Reports/POR/2023/2114680/2114680_10729045_1699657103867_figure--rgov-66x44.png\" alt=\"Security Lifecycle\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The phases of a comprehensive approach for protection against cyberattacks and data breaches</div>\n<div class=\"imageCredit\">Elisa Bertino</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Elisa&nbsp;Bertino\n<div class=\"imageTitle\">Security Lifecycle</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nData ransoms, denial of service, sabotage, and data theft, are on a dramatic increase, creating a cyberattack culture that makes our workplaces, schools, or private residences vulnerable. In order to devise more effective defenses, recent security solutions leverage AI techniques, which are becoming more feasible with significant advances in AI combined with big data collection and analysis capabilities. However, whereas there are plenty of publicly available AI techniques, their successful use depends on the technical and soft skills of their users. Training them demands much care, both in terms of goals and means. Significantly, AI-based approaches have been intensely scrutinized with respect to their security  as AI itself can be attacked  and ethics (see for example issues of discrimination in AI-based classification) delaying their deployment. Thus, for AI to be effectively and quickly adopted in cybersecurity, AI security and ethics need to be also assured. Training cybersecurity professionals to understand how to effectively use AI for cybersecurity and also be aware of AI security and ethics issues is thus a critical requirement for effective design and deployment of AI-based cybersecurity solutions. Future cybersecurity professionals must also be able to effectively communicate relevant information related to AI-based security mechanisms and policies to a variety of stakeholders. \n\n\nThis project has designed an educational approach driven by a cybersecurity lifecycle, consisting of multiple phases (prepare and prevent; monitor and detect; diagnose and understand; react, recovery and fix). Each phase is supported by various security functions (such as detection functions to detect attack activities), organized according to a taxonomy. For each such security functions, the educational approach covers the AI approaches that have been proposed to support/enhance the function. The technical activities are complemented by educational activities covering AI security and ethics as related to the use of AI techniques, and communication approaches allowing students to learn how best to communicate security and privacy policies to end-users. Students are trained in mastering knowledge related to: (a) foundations of AI techniques for specific security tasks in each lifecycle phase  these foundations are illustrated with cybersecurity examples and scenarios; (b) methods addressing issues when applying AI techniques to cybersecurity tasks  a notable example is the lack of training dataset that can be addressed using adversarial domain adaptation and generating synthetic data using generative adversarial networks; (c) scenarios showing how to configure specific AI techniques, such as reinforcement learning, and/or how / which features to extract from artifacts of interest (such as software programs) for analyzing these artifacts with AI techniques  for example to classify a piece of malware. In terms of human interaction core competencies, students are trained about human-AI interaction, systems thinking, focusing on trade-off judgement of human vs. AI efficiency and desirability of outcomes, and empathic/evaluative communication, which uses the most appropriate persuasive techniques to mitigate the undesirable effects of AI under or over efficient use in sorting out cybersecurity crises.\t\t\t\t\tLast Modified: 11/10/2023\n\n\t\t\t\t\tSubmitted by: ElisaBertino\n"
 }
}