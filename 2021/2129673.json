{
 "awd_id": "2129673",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Lip Reading by Unobtrusive Multimodal Sensors and Machine Learning Algorithms",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": "7032924568",
 "po_email": "hdai@nsf.gov",
 "po_sign_block_name": "Huaiyu Dai",
 "awd_eff_date": "2021-08-15",
 "awd_exp_date": "2023-01-31",
 "tot_intn_awd_amt": 149878.0,
 "awd_amount": 149878.0,
 "awd_min_amd_letter_date": "2021-07-28",
 "awd_max_amd_letter_date": "2021-07-28",
 "awd_abstract_narration": "The project aims to build an unobtrusive system to enable lip reading for patients with Amyotrophic Lateral Sclerosis (ALS, also known as Lou Gehrig's diseases) and individuals with speech and hearing disorders. Although there is rich literature on lip reading, the bulkiness, obtrusiveness, and/or immobility of these solutions impedes their applications in daily practice, especially for patients with neuromuscular disorders. There is an urgent need to develop novel lip-reading technologies to improve the communication capabilities of ALS patients with loved ones and healthcare providers. The proposed system can considerably improve on existing solutions for tracking and interpreting facial movements and more broadly, body movements, such as finger motions and body gestures. The ability to gather multimodal motion patterns from unobtrusive sensors and apply machine learning (ML) to interpret the acquired data would greatly facilitate diagnosis, treatment, and rehabilitation of motion-related disorders, such as stroke and Parkinson's disease. In addition, this work paves the way for the development of nonverbal communication interfaces enabled by facial/body gestures and opens new avenues for rehabilitation, robotics, and human-machine interfaces. This project presents an excellent opportunity for students to participate in cross-disciplinary research. Part of the research will be integrated into the PI's courses and capstone design projects. The PIs are committed to outreach activities and increasing the diversity through local minority organizations and the Vertically Integrated Program at Stony Brook University. \r\n\r\nThe overarching goal of this project is to build an unobtrusive hardware-software platform for ALS patients that can capture speech-relevant lip gestures and decode lip movements for speech. First, a skin-like multimodal strain and electromyography (EMG) sensing system will be designed to track both skin deformations and muscle activities associated with lip movements. Self-assembled structures will be introduced to render the sensors ultrathin, breathable, and semi-transparent. Second, the feasibility of converting the sensed lip signals to corresponding spoken words will be demonstrated. Modern ML methods, and in particular, ensemble Gaussian processes (GPs) will be exploited for speech recognition. In the proposed scheme, each GP serves as a classifier and the final decision is made by fusing the results of all the GPs by making use of methods within the Bayesian framework. The potential contributions of the proposed work include: 1) Design of skin-like strain and EMG sensors with high sensitivity and good skin compatibility through a scalable self-assembly process. 2) Integration of multimodal sensors for comprehensive in-vivo quantification of lip movements associated with speech. 3) Development of ML algorithms that precisely convert lip movements to speech. 4) Laying the grounds for developing a truly natural and unobtrusive hardware-software system for lip reading. Our proposed work can fill the gaps in the existing solutions by an intuitive and unobtrusive technology for lip reading.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shanshan",
   "pi_last_name": "Yao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shanshan Yao",
   "pi_email_addr": "shanshan.yao@stonybrook.edu",
   "nsf_id": "000830547",
   "pi_start_date": "2021-07-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Petar",
   "pi_last_name": "Djuric",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Petar M Djuric",
   "pi_email_addr": "petar.djuric@stonybrook.edu",
   "nsf_id": "000110452",
   "pi_start_date": "2021-07-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Renee",
   "pi_last_name": "Fabus",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Renee Fabus",
   "pi_email_addr": "renee.fabus@stonybrook.edu",
   "nsf_id": "000771959",
   "pi_start_date": "2021-07-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "WEST 5510 FRK MEL LIB",
  "perf_city_name": "Stony Brook",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117940001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "756400",
   "pgm_ele_name": "CCSS-Comms Circuits & Sens Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "019E",
   "pgm_ref_txt": "SENSORS AND SENSING"
  },
  {
   "pgm_ref_code": "091E",
   "pgm_ref_txt": "Light generation & detection"
  },
  {
   "pgm_ref_code": "153E",
   "pgm_ref_txt": "Wireless comm & sig processing"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 149878.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"Default\">This project investigates an unobtrusive hardware-software platform for tracking and decoding speech-relevant movement patterns for speech recognition. This project develops two types of epidermal sensors for monitoring lip and neck movements. The research generates new methods for the rational design of wearable biopotential electrodes and magnetic skin sensors for movement tracking. The developed machine learning methodologies yield new knowledge on the processing of biopotential signals and magnetic signals for speech recognition. The research provides a speech communication interface for people with voice disorders. In addition, the developed hardware-software system can facilitate the development of nonverbal speech communication interfaces that opens new avenues for healthcare, robotics, and human-machine interactions.</p>\n<p class=\"Default\">More than four journal articles fully or partially supported by this award were published as peer-review journal articles. This project has trained three Ph.D. students, several MS and undergraduate students, and several summer researchers from local high schools. The PIs have incorporated this project into courses and senior design projects. Two undergraduate students are coauthors of two journal publications. Both students received the \"URECA Summer Research\" award and \"MEC Researcher\" Award at Stony Brook University.</p>\n<p class=\"Default\">The PIs are committed to encouraging female and underrepresented students to pursue STEM fields. Note that around 50% of our research team members are female. We have also collaborated with the Women in Science and Engineering (WISE) Honors program and the Asian, Asian American, and Pacific Islander (AAPI) Network at Stony Brook University. Examples of past activities include student mentoring, sharing the career experience as a woman in STEM, research open house, and hosting lab rotations to inspire and mentor female students in research.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/22/2023<br>\n\t\t\t\t\tModified by: Shanshan&nbsp;Yao</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "This project investigates an unobtrusive hardware-software platform for tracking and decoding speech-relevant movement patterns for speech recognition. This project develops two types of epidermal sensors for monitoring lip and neck movements. The research generates new methods for the rational design of wearable biopotential electrodes and magnetic skin sensors for movement tracking. The developed machine learning methodologies yield new knowledge on the processing of biopotential signals and magnetic signals for speech recognition. The research provides a speech communication interface for people with voice disorders. In addition, the developed hardware-software system can facilitate the development of nonverbal speech communication interfaces that opens new avenues for healthcare, robotics, and human-machine interactions.\nMore than four journal articles fully or partially supported by this award were published as peer-review journal articles. This project has trained three Ph.D. students, several MS and undergraduate students, and several summer researchers from local high schools. The PIs have incorporated this project into courses and senior design projects. Two undergraduate students are coauthors of two journal publications. Both students received the \"URECA Summer Research\" award and \"MEC Researcher\" Award at Stony Brook University.\nThe PIs are committed to encouraging female and underrepresented students to pursue STEM fields. Note that around 50% of our research team members are female. We have also collaborated with the Women in Science and Engineering (WISE) Honors program and the Asian, Asian American, and Pacific Islander (AAPI) Network at Stony Brook University. Examples of past activities include student mentoring, sharing the career experience as a woman in STEM, research open house, and hosting lab rotations to inspire and mentor female students in research.\n\n\t\t\t\t\tLast Modified: 05/22/2023\n\n\t\t\t\t\tSubmitted by: Shanshan Yao"
 }
}