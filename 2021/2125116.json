{
 "awd_id": "2125116",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AI-DCL: EAGER: Explanations through Diverse, Feasible, and Interactive Counterfactuals",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Frederick Kronz",
 "awd_eff_date": "2021-01-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 297786.0,
 "awd_amount": 252472.0,
 "awd_min_amd_letter_date": "2021-03-29",
 "awd_max_amd_letter_date": "2021-03-29",
 "awd_abstract_narration": "This award supports a research project that will help people to better understand decision algorithms that are developed using machine learning techniques. The research team will facilitate that understanding by making use of a promising class of explanations that use counterfactual scenarios. Such explanations provide understanding by showing how outcomes change when hypothetical changes are made in factors that together serve to determine the decision outcome. As a concrete example, consider a person who applies for a loan from a financial company but is rejected by the loan distribution algorithm used by the company. To help the person understand why the decision algorithm rejected the application, the explanation algorithm would generate counterfactual scenarios in which the applicant's situation is hypothetically changed in viable ways (such as moving to a nearby city, or changing jobs) to see whether this affects the decision outcome. If this approach is successful, it would be applicable to a variety of societally critical domains where machine learning holds promise for improving decision making including healthcare, criminal justice, finance, and hiring. The project will have other impacts as well. The research team will release a public web site to engage the public with human-centered machine learning approaches. The PI will work with the University of Colorado Boulder's Science Discovery to present demos at events such as \"Family Engineering Day\" and \"Boulder Computer Science Week\". In addition to training graduate students, the PI will host high-school students as summer interns, integrate findings from the proposed work into educational activities at the University of Colorado Boulder, and make educational materials publicly available for use by instructors at other institutions. \r\n\r\nThis research project seeks to explain machine decisions by generating diverse and feasible counterfactuals and developing user-centered interactive processes. The results of this project will constitute an important step towards building machine-in-the-loop methods to empower users in understanding algorithmic decisions. Specific contributions include developing diversity and distance metrics for generating diverse counterfactuals, integrating causal graphs to generate feasible counterfactuals that align with real-world processes, developing novel user-centered designs to examine human interaction with counterfactuals, and advancing design principles for explaining algorithmic decisions. The team will also develop human-centered designs that enable users to interact with counterfactual explanations. This will enable the researchers to conduct large-scale user studies to understand human preferences, which would in turn serve as an effective evaluation of their proposed method. The results of this research project will contribute to the emerging area of interpretable machine learning that emphasizes human-centered designs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chenhao",
   "pi_last_name": "Tan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chenhao Tan",
   "pi_email_addr": "chenhao@chenhaot.com",
   "nsf_id": "000745868",
   "pi_start_date": "2021-03-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "6054 South Drexel Avenue Suite 300",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606372612",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 252472.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aims to explore the potential of counterfactual explanations in human-AI interaction. Counterfactual explanations provide a way for individuals to comprehend how changing an input could lead to a different AI prediction. This project develops algorithms to generate diverse and feasible counterfactuals and designs interactive experiences with counterfactual explanations. Another contribution of this project is to advance the evaluation of counterfactual explanations with both automatic methods of measuring sufficiency and necessity and large-scale human-subject experiments. Additionally, this project lays the groundwork for future endeavors by examining conditional delegation and linking the psychological study of human explanations with the field of explainable AI.</p>\n<p><br /><strong>Intellectual Merits</strong>. This project advances the research of counterfactual explanations in both algorithms and evaluations. Specifically, it makes the following contributions: 1) developing novel algorithms to generate diverse and feasible counterfactual explanations; 2) designing interactive experiences with counterfactual explanations by allowing users to observe how AI predictions change by manipulating the input; 3) advancing evaluation approaches with both automatic methods of measuring sufficiency and necessity and large-scale human-subject experiments.<br /><br /><strong>Broader Impacts</strong>. The project contributes to the broader goal of making AI more understandable and useful for people. This project has enabled a public website to demonstrate the proposed work and engage the public with human-centered machine learning approaches. Demonstrations based on the project have been exhibited at the Museum of Science and Industry in Chicago. The research outcomes have also been incorporated into academic programs at the University of Colorado Boulder and the University of Chicago, with educational materials accessible to instructors at other educational institutions. The results of the research have been presented at major computer science conferences, including a tutorial at the Annual Conference of the North American Chapter of the Association for Computational Linguistics, and videos of these presentations are available online.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/05/2023<br>\n\t\t\t\t\tModified by: Chenhao&nbsp;Tan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project aims to explore the potential of counterfactual explanations in human-AI interaction. Counterfactual explanations provide a way for individuals to comprehend how changing an input could lead to a different AI prediction. This project develops algorithms to generate diverse and feasible counterfactuals and designs interactive experiences with counterfactual explanations. Another contribution of this project is to advance the evaluation of counterfactual explanations with both automatic methods of measuring sufficiency and necessity and large-scale human-subject experiments. Additionally, this project lays the groundwork for future endeavors by examining conditional delegation and linking the psychological study of human explanations with the field of explainable AI.\n\n\nIntellectual Merits. This project advances the research of counterfactual explanations in both algorithms and evaluations. Specifically, it makes the following contributions: 1) developing novel algorithms to generate diverse and feasible counterfactual explanations; 2) designing interactive experiences with counterfactual explanations by allowing users to observe how AI predictions change by manipulating the input; 3) advancing evaluation approaches with both automatic methods of measuring sufficiency and necessity and large-scale human-subject experiments.\n\nBroader Impacts. The project contributes to the broader goal of making AI more understandable and useful for people. This project has enabled a public website to demonstrate the proposed work and engage the public with human-centered machine learning approaches. Demonstrations based on the project have been exhibited at the Museum of Science and Industry in Chicago. The research outcomes have also been incorporated into academic programs at the University of Colorado Boulder and the University of Chicago, with educational materials accessible to instructors at other educational institutions. The results of the research have been presented at major computer science conferences, including a tutorial at the Annual Conference of the North American Chapter of the Association for Computational Linguistics, and videos of these presentations are available online.\n\n \n\n\t\t\t\t\tLast Modified: 02/05/2023\n\n\t\t\t\t\tSubmitted by: Chenhao Tan"
 }
}