{
 "awd_id": "2110123",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Automatic Data Series Extraction from a Text Corpus",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2021-08-01",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 256000.0,
 "awd_amount": 256000.0,
 "awd_min_amd_letter_date": "2021-07-23",
 "awd_max_amd_letter_date": "2023-03-07",
 "awd_abstract_narration": "The broader impact of this Small Business Innovation Research (SBIR) Phase I project will be improved market efficiency and greater competition in financial services and adjacent industries.  Currently, these sectors are dominated by large firms that have the resources to create and exploit asymmetric information advantages over smaller firms.  A key reason for this asymmetry is that company information \u2013 the basis for building high-quality, detailed financial models \u2013 can be prohibitively expensive to surface, not because it is unavailable, but because it is reported in non-standardized ways and therefore difficult to extract and make actionable.  To do so systematically and industry-wide requires thousands of man-hours per year of manually sifting through millions of documents, a cost that only the largest firms in the world can bear.  Automating the extraction of such information and making it both widely available and easily accessible helps to level the playing field for small firms while simultaneously improving the speed and quality of decision-making \u2013 at a lower total cost \u2013 for large firms.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project aims to develop a machine learning platform for automatically extracting data from a collection of financial documents.  The platform will take advantage of recent advances in natural language processing model architectures, but nonetheless faces the challenges of (a) achieving and maintaining a high level of accuracy, even as document text volume, and thus semantic variation, grows; and (b) generating sufficient labeled training data in a cost-effective way.  This project addresses these dual challenges with a novel framework for continuous model training based on recent meta-learning techniques.  Such an approach to supervised learning can substantially accelerate model improvement and simultaneously drive down training costs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "CHIT-KWAN",
   "pi_last_name": "LIN",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "CHIT-KWAN LIN",
   "pi_email_addr": "ck@revelata.com",
   "nsf_id": "000622093",
   "pi_start_date": "2021-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "REVELATA, INC.",
  "inst_street_address": "616 RAMONA ST STE 24",
  "inst_street_address_2": "",
  "inst_city_name": "PALO ALTO",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6504680681",
  "inst_zip_code": "943012541",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "REVELATA, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "HDAMZZLRV5N6"
 },
 "perf_inst": {
  "perf_inst_name": "REVELATA, INC.",
  "perf_str_addr": "2323 EASTRIDGE AVE APT 521",
  "perf_city_name": "MENLO PARK",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "940256742",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6856",
   "pgm_ref_txt": "ARTIFICIAL INTELL & COGNIT SCI"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 256000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In the financial sector, a vast amount of numerical information is still communicated through complex, long-form text documents.&nbsp; This is greatly at odds with financial professionals' critical need for numerical data -- especially, data series -- in structured, electronic formats.&nbsp; Today, surfacing just a single data series can require highly skilled analysts to sift through reams of documents, a grueling, manual process that is slow, inefficient, and bears a high labor cost that only large firms can shoulder.</p>\n<p>The goal of this SBIR Phase I project was to show the feasibility of automatically extracting such data series from a collection of complex, financial text documents using natural language processing (NLP), and to do so with high accuracy and low data acquisition costs. To this end, we developed a general framework based on meta-learning techniques to continuously train and improve neural language models with minimal human-in-the-loop feedback.&nbsp; We achieved our Phase I goal by using this framework to train a collection of neural language models that together perform this data series extraction task with high fidelity, outperforming even the latest in large language models in terms of correctness and cost.</p>\n<p>Such a capability makes critical financial information easily accessible where it previously was not.&nbsp; This has two broad impacts.&nbsp; First, operationalizing such information can both accelerate and deepen the analyses financial professionals perform and, in doing so, provide improved insights that promote better financial decision-making.&nbsp; Second, by automating away the high labor costs associated with extracting this data, we can level the playing field for smaller firms that would not have the resources to surface it themselves, making them more competitive.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/03/2023<br>\n\t\t\t\t\tModified by: Chit-Kwan&nbsp;Lin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn the financial sector, a vast amount of numerical information is still communicated through complex, long-form text documents.  This is greatly at odds with financial professionals' critical need for numerical data -- especially, data series -- in structured, electronic formats.  Today, surfacing just a single data series can require highly skilled analysts to sift through reams of documents, a grueling, manual process that is slow, inefficient, and bears a high labor cost that only large firms can shoulder.\n\nThe goal of this SBIR Phase I project was to show the feasibility of automatically extracting such data series from a collection of complex, financial text documents using natural language processing (NLP), and to do so with high accuracy and low data acquisition costs. To this end, we developed a general framework based on meta-learning techniques to continuously train and improve neural language models with minimal human-in-the-loop feedback.  We achieved our Phase I goal by using this framework to train a collection of neural language models that together perform this data series extraction task with high fidelity, outperforming even the latest in large language models in terms of correctness and cost.\n\nSuch a capability makes critical financial information easily accessible where it previously was not.  This has two broad impacts.  First, operationalizing such information can both accelerate and deepen the analyses financial professionals perform and, in doing so, provide improved insights that promote better financial decision-making.  Second, by automating away the high labor costs associated with extracting this data, we can level the playing field for smaller firms that would not have the resources to surface it themselves, making them more competitive. \n\n \n\n\t\t\t\t\tLast Modified: 07/03/2023\n\n\t\t\t\t\tSubmitted by: Chit-Kwan Lin"
 }
}