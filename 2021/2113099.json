{
 "awd_id": "2113099",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Neural Net Learning for Graph Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yulia Gel",
 "awd_eff_date": "2021-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 240002.0,
 "awd_amount": 240002.0,
 "awd_min_amd_letter_date": "2021-06-23",
 "awd_max_amd_letter_date": "2021-06-23",
 "awd_abstract_narration": "Graph structures are special data types that arise naturally in sociology, economics, public health, computer science, neuroscience, among other areas. In this project, we develop an innovative graph neural network architecture that is theoretically sound, computationally efficient, numerically superior, and versatile for a variety of graph structures. The development will incorporate many recent advances in graph embedding, dependence testing, and convolutional neural network. This project will significantly advance the theoretical foundation of graph neural networks, enable scalable and better graph learning for data scientists, and is uniquely poised to accelerate discoveries in a many graph-based applications. The project also provides research training opportunities for graduate students. \r\n\r\nIn the project, the PIs will start with graph adjacency, and investigate the difference among spectral embedding, standard neural network, and a novel graph convolutional neural network. Then the PIs plan to prove that under certain graph models, the graph convolutional layer can be asymptotically Bayes optimal in supervised learning. When the graph data is further coupled with node attributes, the PIs develop an attributed neural network architecture via a distance correlation screening layer. The project aims to prove its asymptotic optimality in the presence of node attributes, investigate the relationship between graph adjacency and node attributes to enable better machine learning, and demonstrate its superior performance against existing state-of-the-art methods in simulations and real data. Moreover, the project designs the algorithm in linear-time computation complexity, making it efficient and scalable to big data and sparse graphs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cencheng",
   "pi_last_name": "Shen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cencheng Shen",
   "pi_email_addr": "shenc@udel.edu",
   "nsf_id": "000736944",
   "pi_start_date": "2021-06-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Carey",
   "pi_last_name": "Priebe",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Carey E Priebe",
   "pi_email_addr": "cep@jhu.edu",
   "nsf_id": "000391688",
   "pi_start_date": "2021-06-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Joshua",
   "pi_last_name": "Vogelstein",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Joshua Vogelstein",
   "pi_email_addr": "jovo@jhu.edu",
   "nsf_id": "000606511",
   "pi_start_date": "2021-06-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Delaware",
  "inst_street_address": "550 S COLLEGE AVE",
  "inst_street_address_2": "",
  "inst_city_name": "NEWARK",
  "inst_state_code": "DE",
  "inst_state_name": "Delaware",
  "inst_phone_num": "3028312136",
  "inst_zip_code": "197131324",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DE00",
  "org_lgl_bus_name": "UNIVERSITY OF DELAWARE",
  "org_prnt_uei_num": "",
  "org_uei_num": "T72NHKM259N3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Delaware",
  "perf_str_addr": "210 Hullihen Hall",
  "perf_city_name": "Newark",
  "perf_st_code": "DE",
  "perf_st_name": "Delaware",
  "perf_zip_code": "197160099",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DE00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 240002.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Graph embedding, which involves mapping graph data into a lower-dimensional space, and understanding how neural networks process such data, are important topics in statistics and machine learning. As graph data usage expands across fields like biology, finance, and physics, and the size and complexity of datasets continue to grow, advancements in methods, theory, and applications are becoming increasingly important.</p>\n<p>In this project, we addressed several key aspects of graph embedding, with the most notable achievement being the development of a new approach called the one-hot graph encoder embedding. This method combines essential elements of neural networks with the core principles of traditional spectral embedding.</p>\n<p>Our approach sets a new benchmark for speed and scalability, capable of processing billions of edges within an hour, making it suitable for real-time analysis of massive datasets. It also significantly broadens the theoretical understanding of graph embedding, encompassing traditional properties like asymptotic convergence and normality, while introducing new insights such as conditional density preservation and sufficient dimension reduction in finite-sample, synergistic behavior in multi-graph settings, and consistent outlier detection in time-series graph.</p>\n<p>Methodologically, the designed graph embedding facilitates numerous inference tasks with strong theoretical guarantees and exceptional numerical performance. These applications range from vertex classification and community detection to graph fusion and temporal dynamics, as well as unique use cases like latent community discovery, fast multi-kernel classification, and testing independence between graph data.</p>\n<p>Overall, the theoretical foundations we established provide a rigorous framework for future research in mathematics and statistics, while the methodological advancements offer a versatile and effective tool for a wide range of graph-based analyses. The scalability of the algorithm positions it as a invaluable tool for large-scale graph analysis, unlocking new opportunities and driving innovation across multiple disciplines.</p>\n<p>During the course of the project, we submitted and published over 10 papers in various journals and conferences, including leading machine learning venues such as IEEE TPAMI, IEEE TNSE, and Information Sciences. All manuscripts are accessible on arXiv, and the working code is publicly available on GitHub.</p><br>\n<p>\n Last Modified: 10/16/2024<br>\nModified by: Cencheng&nbsp;Shen</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nGraph embedding, which involves mapping graph data into a lower-dimensional space, and understanding how neural networks process such data, are important topics in statistics and machine learning. As graph data usage expands across fields like biology, finance, and physics, and the size and complexity of datasets continue to grow, advancements in methods, theory, and applications are becoming increasingly important.\n\n\nIn this project, we addressed several key aspects of graph embedding, with the most notable achievement being the development of a new approach called the one-hot graph encoder embedding. This method combines essential elements of neural networks with the core principles of traditional spectral embedding.\n\n\nOur approach sets a new benchmark for speed and scalability, capable of processing billions of edges within an hour, making it suitable for real-time analysis of massive datasets. It also significantly broadens the theoretical understanding of graph embedding, encompassing traditional properties like asymptotic convergence and normality, while introducing new insights such as conditional density preservation and sufficient dimension reduction in finite-sample, synergistic behavior in multi-graph settings, and consistent outlier detection in time-series graph.\n\n\nMethodologically, the designed graph embedding facilitates numerous inference tasks with strong theoretical guarantees and exceptional numerical performance. These applications range from vertex classification and community detection to graph fusion and temporal dynamics, as well as unique use cases like latent community discovery, fast multi-kernel classification, and testing independence between graph data.\n\n\nOverall, the theoretical foundations we established provide a rigorous framework for future research in mathematics and statistics, while the methodological advancements offer a versatile and effective tool for a wide range of graph-based analyses. The scalability of the algorithm positions it as a invaluable tool for large-scale graph analysis, unlocking new opportunities and driving innovation across multiple disciplines.\n\n\nDuring the course of the project, we submitted and published over 10 papers in various journals and conferences, including leading machine learning venues such as IEEE TPAMI, IEEE TNSE, and Information Sciences. All manuscripts are accessible on arXiv, and the working code is publicly available on GitHub.\t\t\t\t\tLast Modified: 10/16/2024\n\n\t\t\t\t\tSubmitted by: CenchengShen\n"
 }
}