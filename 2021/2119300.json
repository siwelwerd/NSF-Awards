{
 "awd_id": "2119300",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: PPoSS: Planning: Efficient Address Translation with Formal Guarantees for Data-Center-Scale Applications",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 62500.0,
 "awd_amount": 62500.0,
 "awd_min_amd_letter_date": "2021-07-09",
 "awd_max_amd_letter_date": "2021-07-09",
 "awd_abstract_narration": "The investigators propose a bottom-up redesign of address translation, a critical bottleneck in the way computers organize where data is stored---whether the computer is a laptop or a massively parallel supercomputer.  Address translation gives computer systems flexibility in placing and migrating data between RAM and disk, but it incurs an additional computational cost. The project\u2019s novelty is to employ advanced techniques in data structures to accelerate address translation.  The project\u2019s impact will be to dramatically accelerate a component of all computational tasks, on all computers, from laptops to parallel supercomputers, and for computations ranging from weather simulations to machine learning.\r\n\r\nThe investigators propose a redesign of TLBs, based on the investigators\u2019 recent advances in stable, low-address-complexity hashing. This redesign includes improvements across the hardware/software stack, from the CPU, to hardware accelerators, to RDMA.  The goal of this planning project is to establish the viability of the team\u2019s approach in preparation for a full proposal to be submitted in the next phase.  The investigators are empirically evaluating tacit assumptions behind address-translation design, providing a principled theoretical foundation for end-to-end analysis and design of naming, placement, load balancing, and translation in data-center-scale applications.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Donald",
   "pi_last_name": "Porter",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Donald E Porter",
   "pi_email_addr": "porter@cs.unc.edu",
   "nsf_id": "000569931",
   "pi_start_date": "2021-07-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "104 Airport Dr Ste 2200",
  "perf_city_name": "Chapel Hill",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275991350",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 62500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project did a preliminary investigation into the potential for a recent advancement in hashing, called Iceberg hashing, to reduce virtual address translation overheads.&nbsp; Virtual address translation has become a significant&nbsp; overhead for data-intensive workloads, such as graph analytics.&nbsp; One key reason for these overheads is that virtual address translations are cached in a very small hardware cache, called a translation lookaside buffer (TLB).&nbsp; The size of a TLB is highly constrained by performance and power concerns, and TLB sizes have grown very slowly.</p>\n<p>The key idea of this project is to compress individual translations and pack multiple, discrete translations into one TLB entry.&nbsp; Translations are compressed by limiting the number of physical addresses where a given virtual address is mapped. Initial results from simulation indicate that the TLB miss rate can be reduced by as much as 81% for representative workloads.</p>\n<p><strong>Intellectual Merit: </strong>A conventional wisdom in OS and hardware design is that it is necessary for the OS to have complete flexibility to map any page of virtual memory to any physical page frame.&nbsp; The natural concern about restricting mappings is that these restrictions may cause a conflict, where a new mapping cannot be created without removing a more important mapping, such as swapping a frequently used page to disk that would not be swapped in an unconstrained system.&nbsp; Our initial results indicate that, with the Iceberg hashing scheme, the amount of swapping is comparable to Linux's unconstrained virtual memory implementation.&nbsp; This derives from Iceberg hashing's unique constellation of properties: it is stable, has low associativity, and high utilization.</p>\n<p>The primary practical technique to improve the number of virtual addresses that can be cached in a TLB (also called \"TLB reach\") is to increase the page size, say from 4 KiB to 2 MiB or 1 GiB.&nbsp; Huge pages have the downside of requiring physical contiguity; defragmenting memory to retain huge physical pages can be so expensive as to offset the gains from increased TLB reach.&nbsp; We note that our technique does not require expensive defragmentation, and, in future work, could profitably combined huge pages.</p>\n<p><strong>Broader Impacts: </strong>The ability to derive insights from large data sets has driven rapid advancement in areas ranging from healthcare to education.&nbsp; For these applications, current CPUs must consume a proverbial ocean of data through a narrow straw; this project demonstrated the viability of a new technique to increase the speed of data movement to and from the CPU, thereby unlocking future advances in large-scale data-intensive workloads.&nbsp; This project trained several graduate and undergraduate students in cutting-edge research ideas and techniques in several areas of computer science: theory, operating systems, and architecture.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/28/2022<br>\n\t\t\t\t\tModified by: Donald&nbsp;E&nbsp;Porter</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project did a preliminary investigation into the potential for a recent advancement in hashing, called Iceberg hashing, to reduce virtual address translation overheads.  Virtual address translation has become a significant  overhead for data-intensive workloads, such as graph analytics.  One key reason for these overheads is that virtual address translations are cached in a very small hardware cache, called a translation lookaside buffer (TLB).  The size of a TLB is highly constrained by performance and power concerns, and TLB sizes have grown very slowly.\n\nThe key idea of this project is to compress individual translations and pack multiple, discrete translations into one TLB entry.  Translations are compressed by limiting the number of physical addresses where a given virtual address is mapped. Initial results from simulation indicate that the TLB miss rate can be reduced by as much as 81% for representative workloads.\n\nIntellectual Merit: A conventional wisdom in OS and hardware design is that it is necessary for the OS to have complete flexibility to map any page of virtual memory to any physical page frame.  The natural concern about restricting mappings is that these restrictions may cause a conflict, where a new mapping cannot be created without removing a more important mapping, such as swapping a frequently used page to disk that would not be swapped in an unconstrained system.  Our initial results indicate that, with the Iceberg hashing scheme, the amount of swapping is comparable to Linux's unconstrained virtual memory implementation.  This derives from Iceberg hashing's unique constellation of properties: it is stable, has low associativity, and high utilization.\n\nThe primary practical technique to improve the number of virtual addresses that can be cached in a TLB (also called \"TLB reach\") is to increase the page size, say from 4 KiB to 2 MiB or 1 GiB.  Huge pages have the downside of requiring physical contiguity; defragmenting memory to retain huge physical pages can be so expensive as to offset the gains from increased TLB reach.  We note that our technique does not require expensive defragmentation, and, in future work, could profitably combined huge pages.\n\nBroader Impacts: The ability to derive insights from large data sets has driven rapid advancement in areas ranging from healthcare to education.  For these applications, current CPUs must consume a proverbial ocean of data through a narrow straw; this project demonstrated the viability of a new technique to increase the speed of data movement to and from the CPU, thereby unlocking future advances in large-scale data-intensive workloads.  This project trained several graduate and undergraduate students in cutting-edge research ideas and techniques in several areas of computer science: theory, operating systems, and architecture. \n\n\t\t\t\t\tLast Modified: 11/28/2022\n\n\t\t\t\t\tSubmitted by: Donald E Porter"
 }
}