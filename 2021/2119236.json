{
 "awd_id": "2119236",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: PPoSS: Planning: Extreme-scale Sparse Data Analytics",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Damian Dechev",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 75000.0,
 "awd_amount": 75000.0,
 "awd_min_amd_letter_date": "2021-08-30",
 "awd_max_amd_letter_date": "2021-08-30",
 "awd_abstract_narration": "The graph data structure is used for storing and manipulating relational data. Tensors are a higher-order generalization of the two-dimensional matrix representation. Both graphs and tensors are used in exploratory and automated data analysis. Applications areas include cybersecurity, complex system analysis, and personalized healthcare. There exist a myriad of known algorithms for typical data analysis tasks in these areas. For instance, the problem of community identification in graphs, referring to automatically identifying well-connected groups of vertices in graphs, has dozens of algorithms. Analogous to the singular value decomposition in matrices, several tensor factorizations exist with diverse use-cases. Both graph algorithms and tensor factorizations use computer storage formats inspired by matrix computations. This project focuses on data analysis use-cases that result in large-scale graphs and tensors, necessitating parallel and distributed processing. The project's novelties are in identifying and developing unifying parallel algorithm design principles that span multiple graph computations and tensor factorizations. In the planning stage, several focused research tasks will explore eight unifying themes.\r\n\r\nThe project aims to develop the foundations for an end-to-end streaming data analytics system with performance comparable to highly tuned static graph analysis benchmarks on current high-end workstations and supercomputers. The investigators' multi-disciplinary expertise span high-performance computing, theory and algorithms, computer architecture, and programming languages and compilers. The cross-cutting research aims include generalizable principles to orchestrate intra- and inter-node communication, multiple approaches for exploiting hierarchical parallelism, locality-enhancing strategies, and automatic performance tuning. The software artifacts from the planning stage could form the basis for new data analytic benchmarks. The investigators will incorporate research findings into the courses they teach. Engaging experts from the national laboratories and the industry in the planning stage will help solidify future large-scale efforts. The investigators will leverage and contribute to existing institutional programs that broaden participation in computing research.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kamesh",
   "pi_last_name": "Madduri",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kamesh Madduri",
   "pi_email_addr": "madduri@cse.psu.edu",
   "nsf_id": "000598267",
   "pi_start_date": "2021-08-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mahmut",
   "pi_last_name": "Kandemir",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Mahmut T Kandemir",
   "pi_email_addr": "mtk2@psu.edu",
   "nsf_id": "000163936",
   "pi_start_date": "2021-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "The Pennsylvania State University",
  "perf_str_addr": "W312 Westgate Building",
  "perf_city_name": "University Park",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168021503",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "PA15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "042Y00",
   "pgm_ele_name": "PPoSS-PP of Scalable Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 75000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The Penn State team on this collaborative grant has two main research contributions. The first contribution is related to node property prediction for heterogeneous graphs on CPU-GPU systems. In semi-supervised graph learning problems, a typical challenge is to predict node properties or labels for a large set of vertices, given features and labels for a smaller subset. Prior work has used the label propagation technique on simple graphs to improve the performance of baseline predictors that do not exploit graph structure. We are extending label propagation to heterogeneous graphs and consider its efficient parallelization for GPUs and multicore systems. We also study combining label propagation with feature engineering, and identify several algorithmic building blocks when training models that use heterogeneous graphs. Our experiments indicate that label propagation significantly improves performance with simple models even for heterogeneous graphs. Further, we profile state-of-the-art heterogeneous graph neural networks and identify bottleneck subroutines. The parallelization strategies we develop for GPUs consider a collection of large heterogeneous graphs and target improving performance of these algorithmic building blocks.</span></p>\n<div>The second contribution is related to distributed-memory synthetic graph generation. In the recent past, several new low-communication distributed-memory undirected graph generation techniques have been proposed. These techniques primarily use parallel pseudorandom number generators with algorithmic workarounds to frequent inter-process communication. We are adapting these graph generation techniques to also capture higher-order properties of streaming data (e.g., multipartite structure, distributions of edge timestamps, categorical attributes, graph update rates, etc.). To simplify the initial design, we have a multi-pass approach where vertex-related attributes are generated in initial passes, and edges in subsequent passes. Since many real-world graphs have highly skewed degree distributions, we are specializing the algorithms for this setting, using GPUs for edges associated with high-degree vertices and the CPU cores for handling edges connecting low-degree vertices.</div>\n<div></div>\n<div>\n<p>The research outcomes are incorporated into undergraduate and graduate classes. The team has also disseminated research findings through presentations, released source code, and submitted work to peer-reviewed conferences.</p>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/07/2023<br>\n\t\t\t\t\tModified by: Kamesh&nbsp;Madduri</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe Penn State team on this collaborative grant has two main research contributions. The first contribution is related to node property prediction for heterogeneous graphs on CPU-GPU systems. In semi-supervised graph learning problems, a typical challenge is to predict node properties or labels for a large set of vertices, given features and labels for a smaller subset. Prior work has used the label propagation technique on simple graphs to improve the performance of baseline predictors that do not exploit graph structure. We are extending label propagation to heterogeneous graphs and consider its efficient parallelization for GPUs and multicore systems. We also study combining label propagation with feature engineering, and identify several algorithmic building blocks when training models that use heterogeneous graphs. Our experiments indicate that label propagation significantly improves performance with simple models even for heterogeneous graphs. Further, we profile state-of-the-art heterogeneous graph neural networks and identify bottleneck subroutines. The parallelization strategies we develop for GPUs consider a collection of large heterogeneous graphs and target improving performance of these algorithmic building blocks.\nThe second contribution is related to distributed-memory synthetic graph generation. In the recent past, several new low-communication distributed-memory undirected graph generation techniques have been proposed. These techniques primarily use parallel pseudorandom number generators with algorithmic workarounds to frequent inter-process communication. We are adapting these graph generation techniques to also capture higher-order properties of streaming data (e.g., multipartite structure, distributions of edge timestamps, categorical attributes, graph update rates, etc.). To simplify the initial design, we have a multi-pass approach where vertex-related attributes are generated in initial passes, and edges in subsequent passes. Since many real-world graphs have highly skewed degree distributions, we are specializing the algorithms for this setting, using GPUs for edges associated with high-degree vertices and the CPU cores for handling edges connecting low-degree vertices.\n\n\n\nThe research outcomes are incorporated into undergraduate and graduate classes. The team has also disseminated research findings through presentations, released source code, and submitted work to peer-reviewed conferences.\n\n\n\t\t\t\t\tLast Modified: 05/07/2023\n\n\t\t\t\t\tSubmitted by: Kamesh Madduri"
 }
}