{
 "awd_id": "2116918",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Doctoral Dissertation Research: Developing a scalable theory of alternatives in pragmatics",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927920",
 "po_email": "jvaldesk@nsf.gov",
 "po_sign_block_name": "Jorge Valdes Kroff",
 "awd_eff_date": "2021-08-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 18244.0,
 "awd_amount": 18244.0,
 "awd_min_amd_letter_date": "2021-07-08",
 "awd_max_amd_letter_date": "2021-07-08",
 "awd_abstract_narration": "This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2).\r\n\r\nHumans interpret language in remarkably flexible ways. In particular, our interpretations involve not only what a speaker actually says, but also what the speaker could have said but didn't. For example, if someone says \"some students passed the exam,\" listeners probably take this to mean that not all students passed, because the speaker could have used the more informative alternative \"all students passed the exam\" if that had been the case. Reasoning about these linguistic alternatives appears to play a key role in language comprehension, but it remains unclear how exactly the alternatives themselves are determined. When a speaker says something, what makes one sentence a better or worse alternative than another? How do alternatives depend on prior experience with different grammatical structures? And how might children learn the ability to reason about alternatives? This research project investigates these questions by combining linguistic theory, behavioral experiments, probabilistic modeling, and machine learning to test competing theories of alternatives. In doing so, this work has the potential to advance our understanding of language in the human mind, as well as artificial models that use language in human-like ways. The project also establishes opportunities for undergraduate researchers, and produce new code and datasets that will be publicly released to the broader scientific community.\r\n\r\nIn contrast to existing theories which suggest that alternatives are generated through operations on syntactic structures, this research evaluates the idea that alternatives capture experience-based accessibility relationships between the lexicon, grammar, and context. A planned series of behavioral experiments assess how the accessibility of alternatives affects the interpretation of event causation in English periphrastic causative constructions. In addition, model simulations investigate how knowledge of alternatives may emerge over the course of language learning, simultaneously establishing a framework for testing theories of alternatives in more ecologically valid domains.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Roger",
   "pi_last_name": "Levy",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Roger P Levy",
   "pi_email_addr": "rplevy@mit.edu",
   "nsf_id": "000508659",
   "pi_start_date": "2021-07-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jennifer",
   "pi_last_name": "Hu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jennifer Hu",
   "pi_email_addr": "jennhu@mit.edu",
   "nsf_id": "000846815",
   "pi_start_date": "2021-07-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Ave",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "837400",
   "pgm_ele_name": "DDRI Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "102Z",
   "pgm_ref_txt": "COVID-Disproportionate Impcts Inst-Indiv"
  },
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "1V21",
   "app_name": "R&RA ARP Act DEFC V",
   "app_symb_id": "040100",
   "fund_code": "010V2122DB",
   "fund_name": "R&RA ARP Act DEFC V",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 18244.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-99142593-7fff-df91-3c53-5a0308b7b892\" style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Humans interpret language in remarkably flexible ways. Our interpretations involve not only what a speaker actually says, but also what the speaker could have said but didn&rsquo;t. For example, if someone says &ldquo;some students passed the exam,&rdquo; you probably take this to mean that not all students passed, because the speaker could have used the more informative alternative &ldquo;all students passed the exam&rdquo; if that had been the case. Reasoning about these linguistic alternatives appears to play a key role in language comprehension, but it remains unclear how exactly the alternatives themselves are determined. The goal of this project was to investigate how listeners determine unspoken alternatives, using a combination of linguistic theory, behavioral experiments, and machine learning. Developing a theory of alternatives has the potential to advance our understanding of language in the human mind, as well as artificial models that use language in human-like ways.&nbsp;</span></p>\n<p style=\"line-height: 1.38; margin-top: 12pt; margin-bottom: 12pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">In particular, this project focused on scalar implicature (SI). SI, like the inference involving &ldquo;some&rdquo; and &ldquo;all&rdquo; described above, is a classic example of how humans interpret language based on unspoken alternatives. Prior work has shown that the strengths of these inferences (&ldquo;SI rates&rdquo;) are highly variable, both within instances of a single scale (like &lt;some, all&gt;), and across scales formed by different words (like &lt;warm, hot&gt; and &lt;ugly, hideous&gt;). However, there have been few proposals that quantitatively explain variation both within and across scales. Furthermore, while it is generally assumed that SIs arise through reasoning about unspoken alternatives, it remains debated whether humans reason about alternatives as linguistic forms, or at the level of concepts.&nbsp;</span></p>\n<p style=\"line-height: 1.38; margin-top: 12pt; margin-bottom: 12pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">In our work, we investigated whether an expectation-based theory of alternatives could explain both within- and cross-scale variation in SI rates. Using neural network language models to approximate human linguistic predictions, we found that SI rates are captured by the expectedness of the strong scalemate (e.g., &ldquo;all&rdquo;) as an alternative. Crucially, however, expectedness robustly predicts cross-scale variation only under a meaning-based view of alternatives. Our results suggest that pragmatic inferences arise from context-driven expectations over alternatives, and these expectations operate at the level of concepts. We published these results in a top computational linguistics journal and presented various stages of the work at top conferences and workshops.</span></p><br>\n<p>\n Last Modified: 01/29/2024<br>\nModified by: Roger&nbsp;P&nbsp;Levy</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nHumans interpret language in remarkably flexible ways. Our interpretations involve not only what a speaker actually says, but also what the speaker could have said but didnt. For example, if someone says some students passed the exam, you probably take this to mean that not all students passed, because the speaker could have used the more informative alternative all students passed the exam if that had been the case. Reasoning about these linguistic alternatives appears to play a key role in language comprehension, but it remains unclear how exactly the alternatives themselves are determined. The goal of this project was to investigate how listeners determine unspoken alternatives, using a combination of linguistic theory, behavioral experiments, and machine learning. Developing a theory of alternatives has the potential to advance our understanding of language in the human mind, as well as artificial models that use language in human-like ways.\n\n\nIn particular, this project focused on scalar implicature (SI). SI, like the inference involving some and all described above, is a classic example of how humans interpret language based on unspoken alternatives. Prior work has shown that the strengths of these inferences (SI rates) are highly variable, both within instances of a single scale (like \n\n\nIn our work, we investigated whether an expectation-based theory of alternatives could explain both within- and cross-scale variation in SI rates. Using neural network language models to approximate human linguistic predictions, we found that SI rates are captured by the expectedness of the strong scalemate (e.g., all) as an alternative. Crucially, however, expectedness robustly predicts cross-scale variation only under a meaning-based view of alternatives. Our results suggest that pragmatic inferences arise from context-driven expectations over alternatives, and these expectations operate at the level of concepts. We published these results in a top computational linguistics journal and presented various stages of the work at top conferences and workshops.\t\t\t\t\tLast Modified: 01/29/2024\n\n\t\t\t\t\tSubmitted by: RogerPLevy\n"
 }
}