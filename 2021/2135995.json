{
 "awd_id": "2135995",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Communication Architecture Designs for Future Heterogeneous Systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2021-11-01",
 "awd_exp_date": "2023-12-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2021-08-31",
 "awd_max_amd_letter_date": "2021-08-31",
 "awd_abstract_narration": "Big data have emerged in various data-centric applications including deep learning and graph processing. These applications show characteristics such as stream processing or irregular data access patterns. However, modern CPU-based architectures with general-purpose instruction-set architectures and memory incur large performance overheads. To remedy this problem, adopting application-specific components and heterogeneous processing units, like GPUs and accelerators, is gaining popularity. As data size increases, more efficient data processing is required, which demands high-density computation and larger bandwidth for data movements, which motivates the need for large-scale heterogeneous systems. Unlike CPU-based systems, the communication in heterogeneous systems may have dynamic and flexible requirements for both latency and throughput depending on applications and involved processors. In addition, since designing a large monolithic chip is impractical due to high cost and low yield rate, cost-effective and design-efficient chiplet-based modular designs are preferred. \r\n\r\nThis project studies the design of communication architectures for heterogeneous systems to accelerate data-centric applications.  It includes research in the fundamentals of interconnects such as deadlock-freedom, routing, flow control, and topology designs, to provide correct functionalities and fulfill heterogeneous communication requirements. To reduce data movements inside the architectures, in-network computing and communication-acceleration solutions through specialization will be investigated to improve performance and energy efficiency of the heterogeneous systems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eun Jung",
   "pi_last_name": "Kim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eun Jung Kim",
   "pi_email_addr": "ejkim@cs.tamu.edu",
   "nsf_id": "000209891",
   "pi_start_date": "2021-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ki Hwan",
   "pi_last_name": "Yum",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ki Hwan Yum",
   "pi_email_addr": "yum@cse.tamu.edu",
   "nsf_id": "000227317",
   "pi_start_date": "2021-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M Engineering Experiment Station",
  "perf_str_addr": "435 Nagle St",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433112",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In [1], we co-design an all-reduce communication algorithm and an&nbsp; interconnection architecture to support efficient and scalable&nbsp;all-reduce operations. We propose MULTITREE, a scalable topology-aware all-reduce algorithm that is applicable to various topologies. MULTITREE couples tree construction and message scheduling with&nbsp;topology and global link utilization awareness to build trees&nbsp;from roots in top-down fashion. MULTITREE moves more communication&nbsp;closer to the roots to make communication closer to the leaves&nbsp;sparse so that communications are balanced in all levels of the&nbsp;trees. Moreover, we co-design the network interface according to the proposed communication algorithm and to facilitate the&nbsp;all-reduce schedule management to achieve contention-free&nbsp;all-reduce. We also simplify the flow control and arbitration&nbsp;to exploit the characteristics of large gradients in all-reduce operations.</p>\n<p>In [2], we propose WHISTLE, a set of CPU abstractions for memory&nbsp;safety violation detection inside the microarchitecture. It is&nbsp;capable of handling both software and hardware violations and&nbsp;allows program-specific policies to check synchronous or&nbsp;asynchronously. WHISTLE provides schemes to detect violations in stacks, heaps, and global objects of a program, and can prevent spatial attacks as well as temporal attacks. WHISTLE is based on program-specific invariants stemming from a common pattern that most of the memory locations of a program are accessed by only a handful of instructions during normal executions. These&nbsp;instructions can be formulated for the corresponding memory&nbsp;locations as invariants of the program. By allowing only memory accesses within the invariants, WHISTLE can defend against future, unknown software or hardware vulnerabilities as exploiting these vulnerabilities will trigger the alarms by accessing disallowed&nbsp;memory locations.</p>\n<p>In [3], we demonstrate a new distance-based side-channel attack on the Non-Uniform Cache Access (NUCA) architecture on Intel Knights Landing CPU against a vulnerable Advanced Encryption Standard (AES) implementation. We also identify and address two technical&nbsp;challenges to performing a robust NUCA distance-based side-channel attack. We develop several techniques including the use of a machine learning model to classify latency that consists of multiple cache accesses, use of a separate timing thread for fine-grained timing of the victim operations, and use of a remote thread to force L1 D misses but last-level cache (LLC) hits for the target cachelines.</p>\n<p>In [4], we identify inefficiencies in the existing state-of-the-art AllReduce algorithms in multi-chip-module (MCM)-based systems. We propose RingBiOdd, a Bidirectional Ring AllReduce algorithm for odd-sized meshes, which ensures that Bidirectional Ring AllReduce can be applied to any mesh topology, effectively doubling the bandwidth usage and performance compared to widely used Unidirectional Ring AllReduce. To further improve the performance, we propose a Tree-based algorithm, Three Tree Overlap (TTO), which constructs three&nbsp;topology-aware disjoint trees by running the training in N-1 chiplets in an N-chiplet system.</p>\n<p><br />[1] J. Huang, P. Majumder, S. Kim, A. Muzahid, K. H. Yum, and&nbsp;E. J. Kim, \"Communication Algorithm-Architecture Co-Design for&nbsp;Distributed Deep Learning,\" in Proceedings of 2021 ACM/IEEE 48th&nbsp;Annual International Sympoisium on Computer Architecure (ISCA), 2021.</p>\n<p>[2] S. Kim, F. Mahmud, J. Huang, P. Majumder, C.-C. Tsai, A.&nbsp;Muzahid, and E. J. Kim, \"WHISTLE: CPU Abstractions for Hardware&nbsp;and Software Memory Safety Invariants,\" IEEE Transactions on&nbsp;Computers, Vol. 72, No. 3, March 2023.</p>\n<p>[3] F. Mahmud, S. Kim, H. S. Chawla, E. J. Kim, C.-C. Tsai, andA. Muzahid, \"Attack of the Knights: A Non Uniform Cache Side-Channel Attack,\" in Proceedings of the 39th Annual Computer Security&nbsp;Applications Conference, December 2023.</p>\n<p>[4] S. Laskar, P. Majhi, S. Kim, F. Mahmud, A. Muzahid, and E. J. Kim, \"Enhancing Collective Communication in MCM Accelerators for Deep Leaning Training,\" to appear in 2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA), March 2024.</p><br>\n<p>\n Last Modified: 03/04/2024<br>\nModified by: Ki Hwan&nbsp;Yum</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn [1], we co-design an all-reduce communication algorithm and an interconnection architecture to support efficient and scalableall-reduce operations. We propose MULTITREE, a scalable topology-aware all-reduce algorithm that is applicable to various topologies. MULTITREE couples tree construction and message scheduling withtopology and global link utilization awareness to build treesfrom roots in top-down fashion. MULTITREE moves more communicationcloser to the roots to make communication closer to the leavessparse so that communications are balanced in all levels of thetrees. Moreover, we co-design the network interface according to the proposed communication algorithm and to facilitate theall-reduce schedule management to achieve contention-freeall-reduce. We also simplify the flow control and arbitrationto exploit the characteristics of large gradients in all-reduce operations.\n\n\nIn [2], we propose WHISTLE, a set of CPU abstractions for memorysafety violation detection inside the microarchitecture. It iscapable of handling both software and hardware violations andallows program-specific policies to check synchronous orasynchronously. WHISTLE provides schemes to detect violations in stacks, heaps, and global objects of a program, and can prevent spatial attacks as well as temporal attacks. WHISTLE is based on program-specific invariants stemming from a common pattern that most of the memory locations of a program are accessed by only a handful of instructions during normal executions. Theseinstructions can be formulated for the corresponding memorylocations as invariants of the program. By allowing only memory accesses within the invariants, WHISTLE can defend against future, unknown software or hardware vulnerabilities as exploiting these vulnerabilities will trigger the alarms by accessing disallowedmemory locations.\n\n\nIn [3], we demonstrate a new distance-based side-channel attack on the Non-Uniform Cache Access (NUCA) architecture on Intel Knights Landing CPU against a vulnerable Advanced Encryption Standard (AES) implementation. We also identify and address two technicalchallenges to performing a robust NUCA distance-based side-channel attack. We develop several techniques including the use of a machine learning model to classify latency that consists of multiple cache accesses, use of a separate timing thread for fine-grained timing of the victim operations, and use of a remote thread to force L1 D misses but last-level cache (LLC) hits for the target cachelines.\n\n\nIn [4], we identify inefficiencies in the existing state-of-the-art AllReduce algorithms in multi-chip-module (MCM)-based systems. We propose RingBiOdd, a Bidirectional Ring AllReduce algorithm for odd-sized meshes, which ensures that Bidirectional Ring AllReduce can be applied to any mesh topology, effectively doubling the bandwidth usage and performance compared to widely used Unidirectional Ring AllReduce. To further improve the performance, we propose a Tree-based algorithm, Three Tree Overlap (TTO), which constructs threetopology-aware disjoint trees by running the training in N-1 chiplets in an N-chiplet system.\n\n\n\n[1] J. Huang, P. Majumder, S. Kim, A. Muzahid, K. H. Yum, andE. J. Kim, \"Communication Algorithm-Architecture Co-Design forDistributed Deep Learning,\" in Proceedings of 2021 ACM/IEEE 48thAnnual International Sympoisium on Computer Architecure (ISCA), 2021.\n\n\n[2] S. Kim, F. Mahmud, J. Huang, P. Majumder, C.-C. Tsai, A.Muzahid, and E. J. Kim, \"WHISTLE: CPU Abstractions for Hardwareand Software Memory Safety Invariants,\" IEEE Transactions onComputers, Vol. 72, No. 3, March 2023.\n\n\n[3] F. Mahmud, S. Kim, H. S. Chawla, E. J. Kim, C.-C. Tsai, andA. Muzahid, \"Attack of the Knights: A Non Uniform Cache Side-Channel Attack,\" in Proceedings of the 39th Annual Computer SecurityApplications Conference, December 2023.\n\n\n[4] S. Laskar, P. Majhi, S. Kim, F. Mahmud, A. Muzahid, and E. J. Kim, \"Enhancing Collective Communication in MCM Accelerators for Deep Leaning Training,\" to appear in 2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA), March 2024.\t\t\t\t\tLast Modified: 03/04/2024\n\n\t\t\t\t\tSubmitted by: Ki HwanYum\n"
 }
}