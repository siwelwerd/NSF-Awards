{
 "awd_id": "2147546",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Fine-Grained Statistical Inference in High Dimension: Actionable Information, Bias Reduction, and Optimality",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2022-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 101829.0,
 "awd_min_amd_letter_date": "2021-08-17",
 "awd_max_amd_letter_date": "2022-06-27",
 "awd_abstract_narration": "Emerging data science applications require efficient extraction of actionable insights from large and messy datasets. The number of relevant features often overwhelms the volume of data that is available, which dramatically complicates the statistical inference tasks and subsequent decision making. In the existing statistical literature, most of theory aims at understanding the average or global behavior of a statistical estimator in high dimensions. In many applications, however, it is often the case that the goal is not to explore the global behavior of a parameter estimator, but rather to perform inference and reasoning on its local, yet important, operational properties.  The techniques and methods developed in the project will further advance the interplay between a broad range of areas including high-dimensional statistics, harmonic analysis, statistical physics, optimization, complex analysis, and statistical machine learning. The project provides research training opportunities for graduate students.\r\n\r\n\r\nThis project pursues fine-grained inferential procedures and theory, aimed at enlarging the uncertainty assessment toolbox for various low-complexity models in high dimensions. Focusing on a few stylized problems, this research program consists of four major thrusts: (1) construct optimal confidence intervals for linear functionals of eigenvectors in low-rank matrix estimation; (2) design fine-grained hypothesis testing procedures for sparse regression under general designs; (3) develop entry-wise inference schemes for principal component analysis with missing data; and (4) conduct reliable and adaptive statistical eigen-analysis under minimal eigen-gaps. Emphasis is placed on algorithms that are model-agnostic and fully adaptive to data heteroscedasticity. Addressing these issues calls for the development of new statistical theory that enables reliable inference for a broad class of local properties underlying the unknown parameters.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yuting",
   "pi_last_name": "Wei",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yuting Wei",
   "pi_email_addr": "ytwei@wharton.upenn.edu",
   "nsf_id": "000800345",
   "pi_start_date": "2021-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 19500.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 40499.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 41830.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this research project, we have developed novel statistical methods and theory to improve the design of statistical procedures and uncertainty quantification methods in high-dimensional statistical data science applications, with a particular emphasis on fine-grained inference. The research tasks we have conducted have spanned several directions of fundamental importance: constructing optimal confidence intervals for functions of eigenvectors in low-rank matrix estimation, designing fine-grained hypothesis tests for sparse regression, understanding the efficacy of approximate message passing from random initialization,&nbsp; developing a non-asymptotic analysis framework for approximate message passing for high-dimensional statistics, and fine-grained spectral methods under minimal eigen-gaps. Many statistical procedures we have developed are provably adaptive to unknown data heteroscedasticity, are able to tackle the most data hungry regime, and are applicable to diverse domains such as genomics, economics, finance, and signal processing. Through this research project, we have also developed new mathematical tools for high-dimensional statistics, mathematical optimization, and statistical machine learning, which might shed light on the design and analysis of a broader array of problems beyond the specific tasks conducted herein. In addition, this NSF project has provided research training for graduate students, undergraduate students, and postdoc researchers, helping them launch their careers in the STEM field.</p><br>\n<p>\n Last Modified: 11/23/2024<br>\nModified by: Yuting&nbsp;Wei</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn this research project, we have developed novel statistical methods and theory to improve the design of statistical procedures and uncertainty quantification methods in high-dimensional statistical data science applications, with a particular emphasis on fine-grained inference. The research tasks we have conducted have spanned several directions of fundamental importance: constructing optimal confidence intervals for functions of eigenvectors in low-rank matrix estimation, designing fine-grained hypothesis tests for sparse regression, understanding the efficacy of approximate message passing from random initialization, developing a non-asymptotic analysis framework for approximate message passing for high-dimensional statistics, and fine-grained spectral methods under minimal eigen-gaps. Many statistical procedures we have developed are provably adaptive to unknown data heteroscedasticity, are able to tackle the most data hungry regime, and are applicable to diverse domains such as genomics, economics, finance, and signal processing. Through this research project, we have also developed new mathematical tools for high-dimensional statistics, mathematical optimization, and statistical machine learning, which might shed light on the design and analysis of a broader array of problems beyond the specific tasks conducted herein. In addition, this NSF project has provided research training for graduate students, undergraduate students, and postdoc researchers, helping them launch their careers in the STEM field.\t\t\t\t\tLast Modified: 11/23/2024\n\n\t\t\t\t\tSubmitted by: YutingWei\n"
 }
}