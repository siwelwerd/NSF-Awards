{
 "awd_id": "2118904",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Common Error Diagnostics and Support in Short-answer Math Questions",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 235693.0,
 "awd_amount": 235693.0,
 "awd_min_amd_letter_date": "2021-08-09",
 "awd_max_amd_letter_date": "2021-08-09",
 "awd_abstract_narration": "One important way to help struggling students improve in math is to deliver personalized support that addresses their specific weaknesses. Many math questions have common wrong answers (CWAs) that correspond to specific errors students make during their answering process, caused by misconceptions or a general lack of knowledge on certain math skills. To date, CWA identification and support remains a labor-intensive process at a limited scale because it requires significant effort by teachers and/or domain experts. In this project, the investigators will develop artificial intelligence (AI)-based mechanisms that can automatically identify CWAs from students\u2019 answers to short-answer math questions and diagnose errors. Once these errors are identified, the investigators will enlist the help of teachers to design feedback and support mechanisms in various formats such as textual feedback messages and short videos. In turn, the investigators will integrate these diagnosis and effective support mechanisms into a teacher interface to support them in either classrooms or online learning environments. Overall, this project has the potential to lead to i) better understanding of CWAs in math questions and the underlying errors and ii) effective CWA support mechanisms for each error type. The project will be grounded in ASSISTments, a free web-based learning platform, therefore directly benefiting the 500,000 US students and 20,000 teachers using it and potentially an even larger number of students and teachers through the dissemination of research findings.\r\n \r\nThis project consists of four main research activities. First, the investigators will leverage math expression embedding methods to learn the representations of student errors by clustering CWAs across multiple questions in the latent math expression embedding vector space. These learned representations will enable the automated diagnosis of student errors in real time. Second, the investigators will develop new knowledge tracing algorithms that go beyond typical correctness analysis and analyze the full answer each student submits to each question. These algorithms will enable the automated tracking of students\u2019 progress in correcting their errors. Third, the investigators will crowdsource multiple types of student support from teachers and integrate both student error diagnostics and support mechanisms into the existing ASSISTments teacher interface. This interface will provide feedback to teachers on which students are struggling in real time and recommend a support, which the teacher can either adopt and customize or reject and create their own support instead. Fourth, the investigators will conduct a randomized controlled trial to evaluate the effectiveness of each support mechanism in helping students correct their errors. This experiment will identify which support mechanisms are most effective at helping students correct each error type and improving learning outcomes.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cristina",
   "pi_last_name": "Heffernan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cristina Heffernan",
   "pi_email_addr": "cristina.heffernan@assistments.org",
   "nsf_id": "000666701",
   "pi_start_date": "2021-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "ASSISTMENTS FOUNDATION, INC.",
  "inst_street_address": "20 HAPGOOD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "SHREWSBURY",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "7742396826",
  "inst_zip_code": "015452820",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "ASSISTMENTS FOUNDATION INC",
  "org_prnt_uei_num": "",
  "org_uei_num": "UW6BD45WNK99"
 },
 "perf_inst": {
  "perf_inst_name": "ASSISTments Foundation, Inc.",
  "perf_str_addr": "482 Southbridge Street, #398",
  "perf_city_name": "Auburn",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "015012468",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "722700",
   "pgm_ele_name": "ITEST-Inov Tech Exp Stu & Teac"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  }
 ],
 "app_fund": [
  {
   "app_code": "13XX",
   "app_name": "H-1B FUND, EHR, NSF",
   "app_symb_id": "045176",
   "fund_code": "1300XXXXDB",
   "fund_name": "H-1B FUND, EDU, NSF",
   "fund_symb_id": "045176"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 235693.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-5b1fa2a0-7fff-e3dd-fd26-cdf9692903a0\">\r\n<p dir=\"ltr\"><span>This year WPI has been building on the work we talked reported last year and described in these two publications: </span><a href=\"https://doi.org/10.1145/3573051.3593390\"><span>https://doi.org/10.1145/3573051.3593390</span></a><span> and </span><a href=\"https://doi.org/10.1145/3576050.3576109\"><span>https://doi.org/10.1145/3576050.3576109</span></a><span>). In these works we reported that students are helped by common wrong answer messages written by teachers. More recently, we have started an experiment in which we look to see if LLMs can author good common wrong answer feedback messages. While it&rsquo;s the case that GPT does a good job of explaining mathematics, anecdotally we have seen that GPT does </span><span>not</span><span> do that well with understanding Common Wrong Answers (meaning, they do not generate good feedback messages). Here is a draft of our work-in-progress: </span><a href=\"https://drive.google.com/file/d/1MDu4Zodv9iRkJseKsIK1Oy6MFOPyyAXs/view?usp=drive_link\"><span>https://drive.google.com/file/d/1MDu4Zodv9iRkJseKsIK1Oy6MFOPyyAXs/view?usp=drive_link</span></a><span>. This is not yet published, so I am not putting it onto the NSF PAR system.&nbsp;&nbsp;</span></p>\r\n<p dir=\"ltr\"><span>We have also started looking at a different type of common wrong answers&mdash;when they are expressed in open-ended-text. We looked at different LLMs to capture the scoring of these open-ended text&nbsp; questions: </span><a href=\"https://educationaldatamining.org/edm2024/proceedings/2024.EDM-posters.80/2024.EDM-posters.80.pdf\"><span>https://educationaldatamining.org/edm2024/proceedings/2024.EDM-posters.80/2024.EDM-posters.80.pdf</span></a><span>).&nbsp; </span><span>&#8203;&#8203;</span></p>\r\n<p dir=\"ltr\"><span>We are proud to report a lot of papers were published. We list them in two sections: Andrew Lan's paper and then those driven by Neil Heffernan. We are excited to continue this work with other projects that involve the ASSISTments Plattform.&nbsp;</span></p>\r\n</span></p><br>\n<p>\n Last Modified: 01/15/2025<br>\nModified by: Cristina&nbsp;Heffernan</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\r\n\n\nThis year WPI has been building on the work we talked reported last year and described in these two publications: https://doi.org/10.1145/3573051.3593390 and https://doi.org/10.1145/3576050.3576109). In these works we reported that students are helped by common wrong answer messages written by teachers. More recently, we have started an experiment in which we look to see if LLMs can author good common wrong answer feedback messages. While its the case that GPT does a good job of explaining mathematics, anecdotally we have seen that GPT does not do that well with understanding Common Wrong Answers (meaning, they do not generate good feedback messages). Here is a draft of our work-in-progress: https://drive.google.com/file/d/1MDu4Zodv9iRkJseKsIK1Oy6MFOPyyAXs/view?usp=drive_link. This is not yet published, so I am not putting it onto the NSF PAR system.\r\n\n\nWe have also started looking at a different type of common wrong answerswhen they are expressed in open-ended-text. We looked at different LLMs to capture the scoring of these open-ended text questions: https://educationaldatamining.org/edm2024/proceedings/2024.EDM-posters.80/2024.EDM-posters.80.pdf). &#8203;&#8203;\r\n\n\nWe are proud to report a lot of papers were published. We list them in two sections: Andrew Lan's paper and then those driven by Neil Heffernan. We are excited to continue this work with other projects that involve the ASSISTments Plattform.\r\n\t\t\t\t\tLast Modified: 01/15/2025\n\n\t\t\t\t\tSubmitted by: CristinaHeffernan\n"
 }
}