{
 "awd_id": "2126534",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER International Type II: Synchronized cloud-based collaborative platform",
 "cfda_num": "47.079",
 "org_code": "01090000",
 "po_phone": "7032928905",
 "po_email": "aykenned@nsf.gov",
 "po_sign_block_name": "Allyson Kennedy",
 "awd_eff_date": "2021-05-01",
 "awd_exp_date": "2024-04-30",
 "tot_intn_awd_amt": 299957.0,
 "awd_amount": 299957.0,
 "awd_min_amd_letter_date": "2021-04-05",
 "awd_max_amd_letter_date": "2021-05-21",
 "awd_abstract_narration": "Part 1. Nontechnical description\r\nThe COVID-19 pandemic has forced international collaborations, as part of science and engineering research and education, to move to remote communication using Zoom and other platforms. The ultimate goal of this EAGER proposal is to design, implement, and test a novel, immersive, cloud-based platform that will facilitate international collaborations of researchers and allow them to interactively perform remote experiments. The platform will immerse remote participants into a holistic virtual environment imitating an actual facility where they can interactively perform authentic experiments using digital equipment. Real-time teamwork is facilitated by synchronizing digital equipment and processes on participants\u2019 devices. Incorporated augmented reality (AR) through wearable Smart Glasses enables partners to combine synchronous group work with asynchronous individual exploration. The project involves foreign partners from Mexico, Australia, United Kingdom, Russia and Africa.\r\nU.S. scientists and students of diverse cultural, ethnical, educational and language backgrounds will work as teams with their foreign counterparts exploring the efficiency, applicability and scalability of the pilot platform. The collaboration will initially cover education and research on applications of X-Ray diffraction methods for studying nanostructures and dynamics of macromolecules. This materials research area is of interest for many other science and engineering disciplines and domains. \r\nThe envisioned idea represents high risk/high pay-off exploratory work in its early stages on untested concepts as such a platform currently does not exist. Should it succeed it will be a real game-changer in distant international collaboration by essentially lifting the difference between an in-person and remote online collaboration. The platform combines the most advanced features of videoconferencing, group computer games, flight and race simulators, and augmented and mixed reality into a single system.  This way, international collaboration will become global and fast, relevant and meaningful, efficient and scalable.\r\n\r\nPart 2. Technical description\r\nThe project will innovatively integrate current and emerging telecommunication and computer technologies into a futuristic collaborative platform that incorporates numerous innovations.  The most significant of them are: (i) orchestrating an interactive teamwork of the partners from different countries by synchronizing simulated virtual processes and digital equipment operations on their devices; (ii) connecting digital equipment with science/engineering modeling software; (iii) combining synchronized performance of experiment as a group member with individual exploration and skills training using augmented reality objects; (iv) connecting and synchronizing interactive augmented reality (AR) objects, provided through Smart Glasses, with relevant virtual processes simulated by cloud-based software objects and presented on a computer or smartphone screen; (v) connecting and synchronizing digital and physical equipment; (vi) integrating automated project and collaboration tools/features with video conferencing; and (vii) real-time voice translation. \r\nThe efficiency, applicability, and scalability of the proposed system is instrumental for connecting scientists and students of different cultural and educational backgrounds, and for facilitating their work as a team. The project platform technology has a great potential to dramatically change the way scientists and engineers collaborate internationally as well as student participate in educational and exchange programs. Being developed and tested for the specific area of studying crystal structures, the technology and approach can be easily generalized and expanded and applied to virtually all science and engineering domains.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "O/D",
 "org_dir_long_name": "Office Of The Director",
 "div_abbr": "OISE",
 "org_div_long_name": "Office of International Science and Engineering",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yakov",
   "pi_last_name": "Cherner",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Yakov E Cherner",
   "pi_email_addr": "ycherner@ATeLearning.com",
   "nsf_id": "000104043",
   "pi_start_date": "2021-04-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "ATEL, LLC",
  "inst_street_address": "87 STANLEY RD",
  "inst_street_address_2": "",
  "inst_city_name": "SWAMPSCOTT",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "7818423300",
  "inst_zip_code": "019071454",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MA06",
  "org_lgl_bus_name": "ATEL, LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "DNEDGUWC7MJ9"
 },
 "perf_inst": {
  "perf_inst_name": "ATeL \u2013 Advanced Tools for  e-Learning",
  "perf_str_addr": "87 Stanley Rd.",
  "perf_city_name": "Swampscott",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "019071454",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MA06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "772700",
   "pgm_ele_name": "IRES Track I: IRES Sites (IS)"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7298",
   "pgm_ref_txt": "COLLABORATIVE RESEARCH"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 299957.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has developed and tested a novel, cloud-based Synchronized Collaborative Online Platform (<strong><em>SCOP</em></strong>) that facilitates international partnerships of researchers and students allowing them to interact in real time while remotely performing laboratory or workplace tasks together.</p>\n<p>To showcase the platform's versatility beyond the XRDS area, it was expanded to include virtual laboratories, along with augmented reality (AR) and other educational and training resources centered around Energy Efficient Houses, Solar Energy, and Biomanufacturing (see Fig.1).</p>\n<p>SCOP is an interactive videoconferencing application which supplement or substitute the currently available communication services such as Zoom, Skype, etc. In contrast with these applications, which keep all participants, except for a presenter, mostly passive and alienated, SCOP integrates and synchronizes multiple relevant applications running on various participants&rsquo; computers and gadgets providing geographically dispersed partners with a common environment where they con jointly conduct authentic online experiments. The participants feel and behave as if they perform an experiment in the same laboratory and use the same set of physical equipment and supplies.</p>\n<p>User can select a list of available simulations, self-guided online activities, and virtual labs.</p>\n<p>SCOP allows real-time connection of up to four different cameras and multiple streaming sources, showcasing activities in research labs or production facilities and visualizing relevant processes.</p>\n<p>Documents such as data forms, experiment protocols, operation manuals, meeting minutes, draft of a paper, calendar, etc. can be opened in a separate panel for discussion and real-time joint editing.&nbsp;</p>\n<p>The collaborative workspace can any time be switched from multi-panel mode to multi-tab mode to substantially enlarge images, animations and videos and enhance resolution.</p>\n<p>Augmented reality (<strong><em>AR</em></strong>) objects can be integrated with real and digital equipment (see Fig. 2) and processes to bridge real and digital worlds and provide learners with more engaging experience.</p>\n<p>Students can use self-guided online activities to explore processes (e.g., heat flow through a building wall). Virtual labs can synchronize with data simulated by software.</p>\n<p>The control and operation information presented on a smartphone home assistant dashboard can be streamed to another panel.</p>\n<p>SCOP provides a platform for integrating&nbsp;digital equipment and processes with analytical and modeling software in order to help the participants significantly enhance strategic planning and joint management of actual experiments and make discussions of expected results more relevant and constructive regardless of their physical location.</p>\n<p>To help U.S. students&nbsp;acquire&nbsp;communication skills needed to work in&nbsp;multicultural and multilingual teams the&nbsp;project develops collaborative online activities for joint teams of U.S. and foreign students.</p>\n<p>To enhance productivity of the international collaboration, the platform provides participants with the opportunity to automate supplemental tasks, such as creating, viewing and editing, in real time, technical documents, meeting minutes, experiment protocols, discussion records, etc. The complementary tools for planning, scheduling and managing remote collaboration is also available.</p>\n<p>For eliminating the linguistic barrier and improve efficient international collaboration, especially for students, SCOP incorporates an instant multilingual interpreter that allows users to speak and text chat with their foreign partners in native languages.</p>\n<p>To assess the feasibility and efficiency of SCOP testing it with international partners an instant interpreter to foreign languages has been embedded in the platform. It converts in real time participant&rsquo;s speech in his/her native language into the native language of foreign participants.</p>\n<p>Key outcomes and other achievements:</p>\n<p>The Project has created the fully functional interactive collaborative online platform&nbsp;<em>SCOP</em> that enables remote users to integrate, synchronizes and manipulate a wide range of diverse resources that include but&nbsp;not limited to videoconferencing, virtual labs and digital equipment, shared documents, streaming videos, etc.</p>\n<p><em>SCOP</em> facilitates real time multilingual communication and supports simultaneous broadcast from multiple webcams located in geographically distant locations. A synchronized access to interactive virtual facilities and digital equipment for multiple remote participants is useful for preparing young researchers and students for hands-on experimentation and collaborative practical works at actual physical XRD analytical and research labs as well as other STEM domains.</p>\n<p>The platform has been tested with faculty of the City University of New York who are using the virtual X-Ray labs, as well as with ATeL&rsquo;s international partners in Mexico, UK, Australia and Singapore.</p>\n<p>Project results have been presented at five nationaland international conferences.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/03/2024<br>\nModified by: Yakov&nbsp;E&nbsp;Cherner</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730666061200_Fig_4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730666061200_Fig_4--rgov-800width.jpg\" title=\"Fig. 4\"><img src=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730666061200_Fig_4--rgov-66x44.jpg\" alt=\"Fig. 4\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 4.\tThe screenshot of virtual and physical (bottom left) labs, associated with SCOP. Parameters presented in the virtual dashboard and generated by the science model of virtual labs are synchronized with process parameters measured by real sensors.</div>\n<div class=\"imageCredit\">Yakov Cherner</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yakov&nbsp;E&nbsp;Cherner\n<div class=\"imageTitle\">Fig. 4</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730663294620_Fig_3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730663294620_Fig_3--rgov-800width.jpg\" title=\"Fig. 3\"><img src=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730663294620_Fig_3--rgov-66x44.jpg\" alt=\"Fig. 3\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 3.\tThe screenshot showcases a virtual lab along with two different cameras providing     real-time views of activities in two research labs. Additionally, session minutes can be edited by each participant.</div>\n<div class=\"imageCredit\">Yakov Cherner</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yakov&nbsp;E&nbsp;Cherner\n<div class=\"imageTitle\">Fig. 3</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730663000347_Fig_2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730663000347_Fig_2--rgov-800width.jpg\" title=\"Fig. 2\"><img src=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730663000347_Fig_2--rgov-66x44.jpg\" alt=\"Fig. 2\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 2.\tThe screenshot showcases the \"Perfusion\" biomanufacturing laboratory. The first panel displays the virtual lab, while the second panel live-streams the physical lab/workplace via a smartphone camera that also runs AR Bioreactor.</div>\n<div class=\"imageCredit\">Yakov Cherner</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yakov&nbsp;E&nbsp;Cherner\n<div class=\"imageTitle\">Fig. 2</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730668319381_Fig_6--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730668319381_Fig_6--rgov-800width.jpg\" title=\"Fig. 6\"><img src=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730668319381_Fig_6--rgov-66x44.jpg\" alt=\"Fig. 6\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 6 The multilingual translator opens in a separate panel allowing participants to manage translation stages. Speech is instantly converted to editable text (left panel) and then translated into a selected foreign language. The translated text can be converted to voice.</div>\n<div class=\"imageCredit\">Yakov Cherner</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yakov&nbsp;E&nbsp;Cherner\n<div class=\"imageTitle\">Fig. 6</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730662645963_SCOP_HomePG_640--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730662645963_SCOP_HomePG_640--rgov-800width.jpg\" title=\"Fig. 1\"><img src=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730662645963_SCOP_HomePG_640--rgov-66x44.jpg\" alt=\"Fig. 1\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 1.\tHome page of the project and Synchronized Collaborative Online Platform (SCOP) platform (https://atelearning.com/ICOP/). Initially developed for the field of X-Ray Powder Diffraction and Spectroscopy,</div>\n<div class=\"imageCredit\">Yakov Cherner</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yakov&nbsp;E&nbsp;Cherner\n<div class=\"imageTitle\">Fig. 1</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730667812686_Fig_5--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730667812686_Fig_5--rgov-800width.jpg\" title=\"Fig. 5\"><img src=\"/por/images/Reports/POR/2024/2126534/2126534_10725995_1730667812686_Fig_5--rgov-66x44.jpg\" alt=\"Fig. 5\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 5.\tThe screenshot shows an instructor using a head-mounted GoPro (top right) to broadcast an on-campus XRD experiment, while a similar experiment is conducted online with a digital diffractometer (top left). AR X-Ray beam optics enhance understanding of the XRD method.</div>\n<div class=\"imageCredit\">Yakov Cherner</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yakov&nbsp;E&nbsp;Cherner\n<div class=\"imageTitle\">Fig. 5</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project has developed and tested a novel, cloud-based Synchronized Collaborative Online Platform (SCOP) that facilitates international partnerships of researchers and students allowing them to interact in real time while remotely performing laboratory or workplace tasks together.\n\n\nTo showcase the platform's versatility beyond the XRDS area, it was expanded to include virtual laboratories, along with augmented reality (AR) and other educational and training resources centered around Energy Efficient Houses, Solar Energy, and Biomanufacturing (see Fig.1).\n\n\nSCOP is an interactive videoconferencing application which supplement or substitute the currently available communication services such as Zoom, Skype, etc. In contrast with these applications, which keep all participants, except for a presenter, mostly passive and alienated, SCOP integrates and synchronizes multiple relevant applications running on various participants computers and gadgets providing geographically dispersed partners with a common environment where they con jointly conduct authentic online experiments. The participants feel and behave as if they perform an experiment in the same laboratory and use the same set of physical equipment and supplies.\n\n\nUser can select a list of available simulations, self-guided online activities, and virtual labs.\n\n\nSCOP allows real-time connection of up to four different cameras and multiple streaming sources, showcasing activities in research labs or production facilities and visualizing relevant processes.\n\n\nDocuments such as data forms, experiment protocols, operation manuals, meeting minutes, draft of a paper, calendar, etc. can be opened in a separate panel for discussion and real-time joint editing.\n\n\nThe collaborative workspace can any time be switched from multi-panel mode to multi-tab mode to substantially enlarge images, animations and videos and enhance resolution.\n\n\nAugmented reality (AR) objects can be integrated with real and digital equipment (see Fig. 2) and processes to bridge real and digital worlds and provide learners with more engaging experience.\n\n\nStudents can use self-guided online activities to explore processes (e.g., heat flow through a building wall). Virtual labs can synchronize with data simulated by software.\n\n\nThe control and operation information presented on a smartphone home assistant dashboard can be streamed to another panel.\n\n\nSCOP provides a platform for integratingdigital equipment and processes with analytical and modeling software in order to help the participants significantly enhance strategic planning and joint management of actual experiments and make discussions of expected results more relevant and constructive regardless of their physical location.\n\n\nTo help U.S. studentsacquirecommunication skills needed to work inmulticultural and multilingual teams theproject develops collaborative online activities for joint teams of U.S. and foreign students.\n\n\nTo enhance productivity of the international collaboration, the platform provides participants with the opportunity to automate supplemental tasks, such as creating, viewing and editing, in real time, technical documents, meeting minutes, experiment protocols, discussion records, etc. The complementary tools for planning, scheduling and managing remote collaboration is also available.\n\n\nFor eliminating the linguistic barrier and improve efficient international collaboration, especially for students, SCOP incorporates an instant multilingual interpreter that allows users to speak and text chat with their foreign partners in native languages.\n\n\nTo assess the feasibility and efficiency of SCOP testing it with international partners an instant interpreter to foreign languages has been embedded in the platform. It converts in real time participants speech in his/her native language into the native language of foreign participants.\n\n\nKey outcomes and other achievements:\n\n\nThe Project has created the fully functional interactive collaborative online platformSCOP that enables remote users to integrate, synchronizes and manipulate a wide range of diverse resources that include butnot limited to videoconferencing, virtual labs and digital equipment, shared documents, streaming videos, etc.\n\n\nSCOP facilitates real time multilingual communication and supports simultaneous broadcast from multiple webcams located in geographically distant locations. A synchronized access to interactive virtual facilities and digital equipment for multiple remote participants is useful for preparing young researchers and students for hands-on experimentation and collaborative practical works at actual physical XRD analytical and research labs as well as other STEM domains.\n\n\nThe platform has been tested with faculty of the City University of New York who are using the virtual X-Ray labs, as well as with ATeLs international partners in Mexico, UK, Australia and Singapore.\n\n\nProject results have been presented at five nationaland international conferences.\n\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 11/03/2024\n\n\t\t\t\t\tSubmitted by: YakovECherner\n"
 }
}