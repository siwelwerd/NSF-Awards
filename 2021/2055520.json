{
 "awd_id": "2055520",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CNS Core: Medium: Collaborative: Reality-Aware Networks",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927855",
 "po_email": "aabouzei@nsf.gov",
 "po_sign_block_name": "Alhussein Abouzeid",
 "awd_eff_date": "2020-10-01",
 "awd_exp_date": "2024-09-30",
 "tot_intn_awd_amt": 199942.0,
 "awd_amount": 191598.0,
 "awd_min_amd_letter_date": "2021-02-05",
 "awd_max_amd_letter_date": "2022-08-27",
 "awd_abstract_narration": "This project seeks to improve the robustness of wireless sensing and networking technologies through a reality-aware wireless architecture that blends networking and sensing. Robust perception and high-bandwidth networking benefit innovations across a diverse spectrum of high-impact areas including mixed-reality, robotics, and automated vehicles. For example, the use of such techniques to enhance driver assistance systems or automated vehicles has the potential to save numerous lives. In addition to disseminating results through scholarly publication, the project will engage the wireless and automotive industry to facilitate the technology transfer. The project also includes a set of integrated education and broadening participation activities to engage and retain students from underrepresented groups through internship programs, educational and outreach activities at each participating institution.\r\n\r\nAs wireless sensing and networking technologies make significant strides in today's world, applications such as automated driving or augmented reality are increasingly involving rich sensing of the environment with unprecedented network requirements. Existing approaches that strictly separate the network stack and the perception component face challenges in providing robust perception and high-bandwidth networking. To address this, this project develops and studies a reality-aware wireless architecture that blends networking and sensing components, rather than isolating them. This approach exploits sensor information and scene geometry to provide improved and more predictable wireless network performance. It also uses information received over the network to aid perception functions such as object recognition and point correspondence. The team first explores the design space of network architectures for blending perception and communications by designing low-energy tags and visual signaling strategies. The team then develops simultaneous localization and mapping algorithms that blend conventional strategies with network information to enhance robustness. It also designs geometric matching techniques to enhance object association in images with network information. At the network and link layers, the system will exploit knowledge about physical obstacles and the surrounding geometry obtained from camera views and other sensors to provide more predictable and seamless high-bandwidth coverage. The outcomes from the thrusts are integrated into a reality-aware network architecture that exploits information about the environment gathered via sensors. The architecture is implemented and evaluated in indoor and outdoor experiments, culminating in a validation on the Platform for Advanced Wireless Research (PAWR) COSMOS testbed.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shubham",
   "pi_last_name": "Jain",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shubham Jain",
   "pi_email_addr": "jain@cs.stonybrook.edu",
   "nsf_id": "000757699",
   "pi_start_date": "2021-02-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "West 5510 FRK Mel Lib",
  "perf_city_name": "Stony Brook",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117940001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0122",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 42547.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 49510.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 49682.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 49859.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project designs a novel 'reality-aware network' architecture that blends networking and sensing components to improve the robustness of the wireless networking and sensing processes. To achieve this goal, this project brings together a team across Rutgers University, Stony Brook University, and Georgia State University, to execute research and broadening impact plans that integrate research, training and outreach activities.&nbsp;</span></p>\r\n<p><span>The major research objectives were to (1)&nbsp;<span>Design and study a network architecture that can blend visual perception and wireless communication to increase overall wireless system performance; (2)&nbsp;</span></span>Design low-energy, visual signaling strategies, hardware markers or 'tags' and communication protocols to improve wireless device lifetime; (3) Develop improved Simultaneous Localization and Mapping (SLAM) algorithms that blend conventional computer vision strategies with tag recognition and decoding; (4) Implement a reality-aware network architecture prototype that integrates the results from objectives 1-3 and lets applications address and communicate with perceived nodes; and (5)&nbsp;<span>Experimentally evaluate the reality-aware network architecture.</span></p>\r\n<p><span>We designed algorithms for multimodal data streams into realizing a holistic system that was reality-aware. Multimodal datasets are quite limited and there weren't any on the data we planned to study, so we collected our own data for this study. These datasets are first of their kind, wherein we have streams from camera, Wi-Fi, and inertial sensing. The data was collected for both mobile and static scenarios in indoor and outdoor environments. One example where this study could be useful is in city environments with self driving vehicles. These vehicles have an array of sensors that communicate with infrastructure devices. Our datasets have been instrumental in our study. We have developed several novel algorithms that map data across modalities. We have also studied how to facilitate visual navigation. Additionally, we have looked at ways to make the computations of these algorithms more efficient.&nbsp;</span></p>\r\n<p>Our findings have been published in top venues in the field, including but not limited to ICLR, IEEE SECON, ACM/IEEE SECON, IEEE ICPR, ACM SEC and various workshops. These works are already being cited by others in the research community showing their impact and potential to support research in the future.</p>\r\n<p>Moreover, during the course of the project, we have trained several graduate and undergraduate students. Two of these graduate students were female. Components of this project were incorporated in the PI's course, thereby exposing many students to our findings and outcomes. Students also adapted some of these ideas for course projects, that also helped them think creatively about this space.</p>\r\n<p><span><br /></span></p><br>\n<p>\n Last Modified: 01/29/2025<br>\nModified by: Shubham&nbsp;Jain</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project designs a novel 'reality-aware network' architecture that blends networking and sensing components to improve the robustness of the wireless networking and sensing processes. To achieve this goal, this project brings together a team across Rutgers University, Stony Brook University, and Georgia State University, to execute research and broadening impact plans that integrate research, training and outreach activities.\r\n\n\nThe major research objectives were to (1)Design and study a network architecture that can blend visual perception and wireless communication to increase overall wireless system performance; (2)Design low-energy, visual signaling strategies, hardware markers or 'tags' and communication protocols to improve wireless device lifetime; (3) Develop improved Simultaneous Localization and Mapping (SLAM) algorithms that blend conventional computer vision strategies with tag recognition and decoding; (4) Implement a reality-aware network architecture prototype that integrates the results from objectives 1-3 and lets applications address and communicate with perceived nodes; and (5)Experimentally evaluate the reality-aware network architecture.\r\n\n\nWe designed algorithms for multimodal data streams into realizing a holistic system that was reality-aware. Multimodal datasets are quite limited and there weren't any on the data we planned to study, so we collected our own data for this study. These datasets are first of their kind, wherein we have streams from camera, Wi-Fi, and inertial sensing. The data was collected for both mobile and static scenarios in indoor and outdoor environments. One example where this study could be useful is in city environments with self driving vehicles. These vehicles have an array of sensors that communicate with infrastructure devices. Our datasets have been instrumental in our study. We have developed several novel algorithms that map data across modalities. We have also studied how to facilitate visual navigation. Additionally, we have looked at ways to make the computations of these algorithms more efficient.\r\n\n\nOur findings have been published in top venues in the field, including but not limited to ICLR, IEEE SECON, ACM/IEEE SECON, IEEE ICPR, ACM SEC and various workshops. These works are already being cited by others in the research community showing their impact and potential to support research in the future.\r\n\n\nMoreover, during the course of the project, we have trained several graduate and undergraduate students. Two of these graduate students were female. Components of this project were incorporated in the PI's course, thereby exposing many students to our findings and outcomes. Students also adapted some of these ideas for course projects, that also helped them think creatively about this space.\r\n\n\n\n\t\t\t\t\tLast Modified: 01/29/2025\n\n\t\t\t\t\tSubmitted by: ShubhamJain\n"
 }
}