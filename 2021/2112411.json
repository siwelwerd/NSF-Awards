{
 "awd_id": "2112411",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Estimation of Detailed Plant Geometry for Robotic Farm Work",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2021-08-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 253723.0,
 "awd_amount": 253723.0,
 "awd_min_amd_letter_date": "2021-07-20",
 "awd_max_amd_letter_date": "2021-07-20",
 "awd_abstract_narration": "The broader impact of this Small Business Innovation Research (SBIR) Phase I project will improve the economics of farming. Machines with good computer perception of plant geometry can implement farming practices that reduce the use of pesticides, fertilizer, water, and fuel. This will increase farm efficiency and provide long-term benefits to the environment.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project will develop new algorithms for estimation of plant structure from images. This is challenging because agricultural fields are often densely packed with plants, such that portions of each plant are hidden from view. Existing methods can estimate missing geometry of man-made objects from obstructed views, but plants are considerably more difficult, due to the complexity, variability, and visual ambiguity of their geometry. The project will aim to achieve levels of detail and accuracy not previously attained in plant imaging. To reach this goal, the project will use rapid iterations of field data collection, algorithm development, and field testing.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Sand",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Peter Sand",
   "pi_email_addr": "peter@modularscience.com",
   "nsf_id": "000712796",
   "pi_start_date": "2021-07-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Modular Science, Inc.",
  "inst_street_address": "777 14TH ST",
  "inst_street_address_2": "",
  "inst_city_name": "SAN FRANCISCO",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "4158817886",
  "inst_zip_code": "941141322",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "CA11",
  "org_lgl_bus_name": "MODULAR SCIENCE, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "PKHPW66NB7T3"
 },
 "perf_inst": {
  "perf_inst_name": "Modular Science, Inc.",
  "perf_str_addr": "771 Capp St",
  "perf_city_name": "San Francisco",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "941103223",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "CA11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6856",
   "pgm_ref_txt": "ARTIFICIAL INTELL & COGNIT SCI"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 253723.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In our NSF SBIR Phase I research project, Modular Science developed and tested software tools for understanding the geometry of plants in farm fields. This is challenging because crops and weeds can be densely packed and overlapping, such that much of the plant structures are hidden from view.</p>\n<p>Understanding plant geometry is useful for applications like mechanical weeding. A robotic system with cameras could identify a weed and plan the best path for a tool that removes the weed without damaging nearby crop plants. This could support sustainable practices, potentially reducing tiling and the use of herbicides. Smarter tools could make it easier for farms to adopt practices that support biodiversity, reduce use of water, and perform carbon sequestration.</p>\n<p>Our research explored using object detection methods and 3D reconstruction algorithms. We tested the algorithms using real-world farm imagery along with rendered images from virtual farms.</p>\n<p>We found that recent object detection methods were able to locate plant stems even within dense weeds. Locating plant stems is useful in many cases, but full 3D reconstruction may be necessary for handling complex cases of weeds growing very close to crop plants. For this we explored recent neural-network-based 3D reconstruction methods, finding that they were able to handle the overlapping geometry and fine structures of plants. We also investigated related challenges such as handling complex lighting conditions, efficiently capturing and processing data, and obtaining good ground-truth data.</p>\n<p>To support the research we developed new control systems for our field robots and performed a number of field tests. We talked with a variety of small-scale and large-scale vegetable farmers to learn about their concerns and what tools might be most useful for their operations.</p>\n<p>This is the initial stage of a longer research process in which we will explore how computer vision and machine learning systems can more fully understand the complex structures and complex conditions in farm fields. This research will support our long-term goals of building tools for farmers that can help improve soil health and reduce the use of pesticides, fertilizer, water, and fuel.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/17/2022<br>\n\t\t\t\t\tModified by: Peter&nbsp;Sand</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn our NSF SBIR Phase I research project, Modular Science developed and tested software tools for understanding the geometry of plants in farm fields. This is challenging because crops and weeds can be densely packed and overlapping, such that much of the plant structures are hidden from view.\n\nUnderstanding plant geometry is useful for applications like mechanical weeding. A robotic system with cameras could identify a weed and plan the best path for a tool that removes the weed without damaging nearby crop plants. This could support sustainable practices, potentially reducing tiling and the use of herbicides. Smarter tools could make it easier for farms to adopt practices that support biodiversity, reduce use of water, and perform carbon sequestration.\n\nOur research explored using object detection methods and 3D reconstruction algorithms. We tested the algorithms using real-world farm imagery along with rendered images from virtual farms.\n\nWe found that recent object detection methods were able to locate plant stems even within dense weeds. Locating plant stems is useful in many cases, but full 3D reconstruction may be necessary for handling complex cases of weeds growing very close to crop plants. For this we explored recent neural-network-based 3D reconstruction methods, finding that they were able to handle the overlapping geometry and fine structures of plants. We also investigated related challenges such as handling complex lighting conditions, efficiently capturing and processing data, and obtaining good ground-truth data.\n\nTo support the research we developed new control systems for our field robots and performed a number of field tests. We talked with a variety of small-scale and large-scale vegetable farmers to learn about their concerns and what tools might be most useful for their operations.\n\nThis is the initial stage of a longer research process in which we will explore how computer vision and machine learning systems can more fully understand the complex structures and complex conditions in farm fields. This research will support our long-term goals of building tools for farmers that can help improve soil health and reduce the use of pesticides, fertilizer, water, and fuel.\n\n\t\t\t\t\tLast Modified: 10/17/2022\n\n\t\t\t\t\tSubmitted by: Peter Sand"
 }
}