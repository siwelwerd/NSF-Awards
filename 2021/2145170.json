{
 "awd_id": "2145170",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "The Future of Thermodynamics of Computation",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2021-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 49991.0,
 "awd_amount": 49991.0,
 "awd_min_amd_letter_date": "2021-09-01",
 "awd_max_amd_letter_date": "2021-09-01",
 "awd_abstract_narration": "This proposal is for an invited NSF workshop for studying the interplay between computing hardware and the newly emerging field of nonequilibrium (stochastic) Thermodynamics. This workshop will identify open challenges, opportunities and research priorities to develop understanding of the stochastic thermodynamics of computational systems that are distributed, with multiple spatially separated subsystems, are not at thermodynamic equilibrium (and in general, not even in a stationary state), and have both substantial thermodynamic costs of communication among the subsystems and thermodynamic costs of the information processing within the subsystems. This connection between energy efficiency in information processing and thermodynamic limits could have far reaching consequences in the design of computing systems at large. The topic also has a broad appeal to natural scientists, engineers, computer scientists and has been of much recent interest in multiple disciplines. The inclusion of participants from diverse backgrounds will facilitate the scientific and professional development of early career researchers and increase the STEM workforce pipeline in these areas, as well as help to ensure inclusion of scientists from traditionally underrepresented groups. Close to half of the invitees to the workshop will be students or postdocs from different communities. The PI has had extensive recent experience in mentoring students and postdocs in the general field of the stochastic thermodynamics of computation. \r\n\r\nThis workshop will assemble a set of leading researchers working to examine issues common to nonequilibrium theormodynamics and the design of computers, to describe the reasons that they should be studied from an interdisciplinary point of view, to enumerate the major challenges that lays ahead, and to create a strategy for a way forward.  A diverse group of physical theorists, electrical and computer engineers, and electronic device researchers with strong understanding of thermodynamics will participate in the workshop.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Wolpert",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Wolpert",
   "pi_email_addr": "dhw@santafe.edu",
   "nsf_id": "000711099",
   "pi_start_date": "2021-09-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Santa Fe Institute",
  "inst_street_address": "1399 HYDE PARK RD",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA FE",
  "inst_state_code": "NM",
  "inst_state_name": "New Mexico",
  "inst_phone_num": "5059462727",
  "inst_zip_code": "875018943",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "NM03",
  "org_lgl_bus_name": "SANTA FE INSTITUTE OF SCIENCE",
  "org_prnt_uei_num": "",
  "org_uei_num": "M8SBQ7NVNAH4"
 },
 "perf_inst": {
  "perf_inst_name": "Santa Fe Institute",
  "perf_str_addr": "1399 Hyde Park Road",
  "perf_city_name": "Santa FE",
  "perf_st_code": "NM",
  "perf_st_name": "New Mexico",
  "perf_zip_code": "875018943",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "NM03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 49991.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This NSF Conference Award funded two Working Groups whose goals were to bring together leading experts from around the world in the topics of stochastic thermodynamics and theoretical computer science in order to identify challenges, opportunities and research priorities to develop our understanding of the thermodynamics of computational systems. Participants came up with suggestions for potential methodologies involving theory, simulation, and experiment, for attempting to address these research investigations. These ideas and suggestions were compiled into a White Paper, and a soon-to-be-released perspective article in a scientific journal. A summary follows:</p>\n<p>Nearly all computational systems of interest, whether natural or engineered, are distributed. That is, they consist of sets of components that interact with each other and whose (perhaps stochastic) co-evolution transforms a set of inputs into a set of outputs on a continual basis. Distributed computers operate under (often severe) constraints, many of which arise from inviolable physics. Such physical constraints often stem from the properties of the computer, including but not limited to</p>\n<ul>\n<li>material substrates used to build the computer,</li>\n<li>modes of signal propagation between computational components,</li>\n<li>timescales of component dynamics,</li>\n<li>algorithms (from high-level code, to operating system and scheduling routines, all the way down to compiled and optimized register instructions), and </li>\n<li>organization of the network of interactions between its components.</li>\n</ul>\n<p>At the same time, there are constraints in terms of important performance metrics one wants the computer to optimize, such as the time or memory requirements to complete a computation, accuracy / precision, robustness against external physical perturbation or component failure, and energy consumption. Unfortunately, energetic resource constraints are often overlooked.</p>\n<p>Prior research efforts regarding energy usage in distributed computational systems have focused on either the discovery of macro-scale phenomena such as scaling of energetic costs with total wiring length, or the biophysics of micro-scale components such as transistors or neurons. However, this ignores the fact that the exchange of information among the individual components of a computer and its many levels of abstraction ultimately governs its energetic requirements (e.g., for digital computation, the levels may be: electrons moving across electrically-biased substrates&nbsp;&rarr; gates&nbsp;&rarr; transistors&nbsp;&rarr; logical components &rarr; Boolean circuits). Therefore, it is clear that we need theoretical frameworks that can rigorously treat all intermediate scales involved in implementing computation. In particular, how does computer architecture, implementation and algorithmic design determine the minimum amount of physical resources (within desired performance levels) that must be expended in order to solve a given problem?</p>\n<p>Despite the fact that reducing energy requirements has become one of the most challenging issues for the actual implementation and deployment of distributed computers, the main threads of theoretical computer science research have historically ignored this issue, focusing instead on time and memory usage, circuit size and depth, use of randomness, <em>etc</em>.</p>\n<p>The shortage of research in this direction until now was likely due to the lack of a common scientific framework capable of mathematically formalizing the relationships between the diverse set of design features, resources, and performance metrics involved in this problem.</p>\n<p>Thermodynamics and statistical physics present an alluring option for overcoming this shortfall.</p>\n<p>Until the past two decades, however, efforts to use thermodynamics to study computation considered extremely basic scenarios (such as the erasure of a single bit), and almost always in the quasi-static limit. Those investigations were therefore constrained to the equilibrium or near-equilibrium realm, making them all but useless for understanding real computers, which operate far from equilibrium.</p>\n<p>However, recent advances in nonequilibrium thermodynamics have made it a strong candidate for the universal language required to investigate physically-embedded computational systems across scales, across design features, and across resource costs.</p>\n<p>In light of these considerations, here we present the need for a unified research program that:</p>\n<ul>\n<li>Uses nonequilibrium thermodynamics to develop our understanding of how the properties of a physical computational system affect its performance metrics.</li>\n<li>Uses this understanding to expand the scope of computer science theory to include this constrained optimization problem of building more robust and more (time-, memory-, and energy-) efficient computers subject to real-world constraints.</li>\n</ul>\n<p>In particular, the most important research challenges to address will be:</p>\n<ul>\n<li>Tabulating all the different sources of energetic costs (e.g., entropy production) in computational systems, including, e.g., non-intuitive costs such as those that may arise due to the mismatch between the actual distribution of inputs to a system and the expected distribution of inputs that the system was designed to handle</li>\n<li>Developing designs or principles of design for alternative forms of computation, including neuromorphic computing, stochastic computing, and molecular computing</li>\n<li>Unifying stochastic thermodynamics with computational complexity theory, circuit theory, <em>etc</em>.</li>\n</ul>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/12/2022<br>\n\t\t\t\t\tModified by: David&nbsp;Wolpert</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis NSF Conference Award funded two Working Groups whose goals were to bring together leading experts from around the world in the topics of stochastic thermodynamics and theoretical computer science in order to identify challenges, opportunities and research priorities to develop our understanding of the thermodynamics of computational systems. Participants came up with suggestions for potential methodologies involving theory, simulation, and experiment, for attempting to address these research investigations. These ideas and suggestions were compiled into a White Paper, and a soon-to-be-released perspective article in a scientific journal. A summary follows:\n\nNearly all computational systems of interest, whether natural or engineered, are distributed. That is, they consist of sets of components that interact with each other and whose (perhaps stochastic) co-evolution transforms a set of inputs into a set of outputs on a continual basis. Distributed computers operate under (often severe) constraints, many of which arise from inviolable physics. Such physical constraints often stem from the properties of the computer, including but not limited to\n\nmaterial substrates used to build the computer,\nmodes of signal propagation between computational components,\ntimescales of component dynamics,\nalgorithms (from high-level code, to operating system and scheduling routines, all the way down to compiled and optimized register instructions), and \norganization of the network of interactions between its components.\n\n\nAt the same time, there are constraints in terms of important performance metrics one wants the computer to optimize, such as the time or memory requirements to complete a computation, accuracy / precision, robustness against external physical perturbation or component failure, and energy consumption. Unfortunately, energetic resource constraints are often overlooked.\n\nPrior research efforts regarding energy usage in distributed computational systems have focused on either the discovery of macro-scale phenomena such as scaling of energetic costs with total wiring length, or the biophysics of micro-scale components such as transistors or neurons. However, this ignores the fact that the exchange of information among the individual components of a computer and its many levels of abstraction ultimately governs its energetic requirements (e.g., for digital computation, the levels may be: electrons moving across electrically-biased substrates &rarr; gates &rarr; transistors &rarr; logical components &rarr; Boolean circuits). Therefore, it is clear that we need theoretical frameworks that can rigorously treat all intermediate scales involved in implementing computation. In particular, how does computer architecture, implementation and algorithmic design determine the minimum amount of physical resources (within desired performance levels) that must be expended in order to solve a given problem?\n\nDespite the fact that reducing energy requirements has become one of the most challenging issues for the actual implementation and deployment of distributed computers, the main threads of theoretical computer science research have historically ignored this issue, focusing instead on time and memory usage, circuit size and depth, use of randomness, etc.\n\nThe shortage of research in this direction until now was likely due to the lack of a common scientific framework capable of mathematically formalizing the relationships between the diverse set of design features, resources, and performance metrics involved in this problem.\n\nThermodynamics and statistical physics present an alluring option for overcoming this shortfall.\n\nUntil the past two decades, however, efforts to use thermodynamics to study computation considered extremely basic scenarios (such as the erasure of a single bit), and almost always in the quasi-static limit. Those investigations were therefore constrained to the equilibrium or near-equilibrium realm, making them all but useless for understanding real computers, which operate far from equilibrium.\n\nHowever, recent advances in nonequilibrium thermodynamics have made it a strong candidate for the universal language required to investigate physically-embedded computational systems across scales, across design features, and across resource costs.\n\nIn light of these considerations, here we present the need for a unified research program that:\n\nUses nonequilibrium thermodynamics to develop our understanding of how the properties of a physical computational system affect its performance metrics.\nUses this understanding to expand the scope of computer science theory to include this constrained optimization problem of building more robust and more (time-, memory-, and energy-) efficient computers subject to real-world constraints.\n\n\nIn particular, the most important research challenges to address will be:\n\nTabulating all the different sources of energetic costs (e.g., entropy production) in computational systems, including, e.g., non-intuitive costs such as those that may arise due to the mismatch between the actual distribution of inputs to a system and the expected distribution of inputs that the system was designed to handle\nDeveloping designs or principles of design for alternative forms of computation, including neuromorphic computing, stochastic computing, and molecular computing\nUnifying stochastic thermodynamics with computational complexity theory, circuit theory, etc.\n\n\n \n\n\t\t\t\t\tLast Modified: 12/12/2022\n\n\t\t\t\t\tSubmitted by: David Wolpert"
 }
}