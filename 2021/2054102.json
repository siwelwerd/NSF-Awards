{
 "awd_id": "2054102",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: All-Optical Information Processing Device for Seeing Through Diffusers at the Speed of Light",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Vikram Dalal",
 "awd_eff_date": "2020-11-15",
 "awd_exp_date": "2021-10-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2020-11-12",
 "awd_max_amd_letter_date": "2021-05-21",
 "awd_abstract_narration": "Proposal Number: 2054102\r\nPrincipal Investigator: Aydogan Ozcan (PI) and Mona Jarrahi (co-PI)\r\nInstitution: University of California, Los Angeles\r\nTitle: EAGER: All-Optical Information Processing Device for Seeing Through Diffusers at the Speed of Light\r\nProgram Description: EAGER: Electronics, Photonics, and Magnetic Devices\r\n\r\nNon-Technical Abstract:\r\n\r\nImaging through scattering and diffusive media such as fog, clouds or human tissue has been an important problem for many decades. Without an exception, all the previous methods are based on, at their core, digital computers, such that the signals are first detected by a device and then processed using digital computers to reconstruct the diffuser-distorted images. There is an important and pressing need for a new generation of optical devices that can see, detect and quantify target objects through for example human tissues, walls, packages, clouds, fogs, etc., at the speed of light and without using any power-hungry digital computation. This unique capability, once fully demonstrated and developed, might open various new applications in autonomous systems, biomedical imaging, astronomy, astrophysics, atmospheric sciences, security, robotics, and many other fields.\r\n\r\nTechnical Abstract:\r\n\r\nIn this proposal, a computer-free, all-optical device that will see through unknown diffusers at the speed of light, without the need for any digital computation device will be developed. Unlike previous digital approaches that utilized computers to reconstruct an image of the input object behind unknown diffusers, a passive device will be created using a set of diffractive surfaces/layers to all-optically reconstruct the image of an unknown object as the diffuser-distorted input signals diffract through successive trained diffractive layers, i.e., the image reconstruction will be processed at the speed of light through this device. Each diffractive surface of a given device designed will have thousands of diffractive features (termed as neurons), where the individual phase values of these neurons will be adjusted in the training phase through error back-propagation, by minimizing a customized loss function between the ground truth image and the diffracted pattern at the output field-of-view. After this deep learning-based design of these diffractive layers, the resulting passive device will be fabricated to form a physical diffractive optical network that is positioned between an unknown diffuser and the output/image plane. As the input object light passes through an unknown diffuser, the scattered light will be collected by the trained diffractive device to passively reconstruct the distorted image. The success of this diffractive device will be demonstrated in 0.1-3 THz frequency band. Unlike other devices, the proposed diffractive image reconstruction device operates at the speed of light and does not require any power except for the illumination light. This all-optical image reconstruction that will be achieved by passive diffractive layers will enable to see objects through unknown diffusers and present an extremely low power device compared with existing deep learning-based or iterative image reconstruction methods implemented in computers.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aydogan",
   "pi_last_name": "Ozcan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aydogan Ozcan",
   "pi_email_addr": "ozcan@ee.ucla.edu",
   "nsf_id": "000488625",
   "pi_start_date": "2020-11-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mona",
   "pi_last_name": "Jarrahi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mona Jarrahi",
   "pi_email_addr": "mjarrahi@ee.ucla.edu",
   "nsf_id": "000668554",
   "pi_start_date": "2020-11-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles",
  "perf_str_addr": "420 Westwood Plz",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900951406",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "151700",
   "pgm_ele_name": "EPMD-ElectrnPhoton&MagnDevices"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Imaging through scattering and diffusive media such as fog, clouds or human tissue has been an important problem for many decades, with numerous solutions reported so far. Without an exception, all of the previous methods and devices are based on, at their core, digital computers, such that the signals are first detected by a device and then processed using digital computers to see through diffusers. There is an important and pressing need for a new generation of optical devices that can see, detect and quantify target objects through for example, human tissue, walls, packages, clouds, fog, etc. at the speed of light and without the need for any digital computation. Once fully demonstrated and developed, this unique capability might open up various new applications in biomedical imaging, astronomy, astrophysics, atmospheric sciences, security, robotics, and many other fields.</p>\n<p>In this proposal, a computer-free, all-optical device that can see through unknown diffusers at the speed of light, without the need for any digital computation device was developed. Unlike previous digital approaches that utilized computers to reconstruct an image of the input object behind a diffuser, here a passive device was created using a set of diffractive surfaces/layers to all-optically reconstruct the image of an unknown object as the diffuser-distorted input optical field diffracts through successive trained diffractive layers, i.e., the image reconstruction is processed at the speed of light through this device. Each diffractive surface of a given device design has thousands of diffractive features (termed as neurons), where the individual phase values of these neurons are adjusted in the training phase through error back-propagation, by minimizing a customized loss function between the ground truth image and the diffracted pattern at the output field-of-view. After this deep learning-based design of these diffractive layers (which is a one-time effort), the resulting passive device was fabricated to form a physical diffractive optical network that is positioned between an unknown, new diffuser and the output/image plane. As the input object light passes through an unknown diffuser, the scattered light is collected by the trained diffractive device to all-optically reconstruct an image of the object at its output field-of-view, without the need for an optoelectronic device or computer or any digital computation. The success of this diffractive device was demonstrated using THz illumination, providing unique capabilities owing to the distinct properties of THz radiation. Unlike other devices, the developed diffractive image reconstruction device operates at the speed of light and does not require any power except for the illumination light. This all-optical image reconstruction achieved by passive diffractive layers enables to see objects through unknown diffusers and presents an extremely low power device compared with existing deep learning-based or iterative image reconstruction methods implemented in computers, only requiring power for the illumination source.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/06/2022<br>\n\t\t\t\t\tModified by: Aydogan&nbsp;Ozcan</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/2054102/2054102_10708935_1644137565662_TOCImage--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/2054102/2054102_10708935_1644137565662_TOCImage--rgov-800width.jpg\" title=\"Computational Imaging Without a Computer\"><img src=\"/por/images/Reports/POR/2022/2054102/2054102_10708935_1644137565662_TOCImage--rgov-66x44.jpg\" alt=\"Computational Imaging Without a Computer\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Computational Imaging Without a Computer: Seeing Through Random Diffusers at the Speed of Light</div>\n<div class=\"imageCredit\">Ozcan Lab @UCLA</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Aydogan&nbsp;Ozcan</div>\n<div class=\"imageTitle\">Computational Imaging Without a Computer</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nImaging through scattering and diffusive media such as fog, clouds or human tissue has been an important problem for many decades, with numerous solutions reported so far. Without an exception, all of the previous methods and devices are based on, at their core, digital computers, such that the signals are first detected by a device and then processed using digital computers to see through diffusers. There is an important and pressing need for a new generation of optical devices that can see, detect and quantify target objects through for example, human tissue, walls, packages, clouds, fog, etc. at the speed of light and without the need for any digital computation. Once fully demonstrated and developed, this unique capability might open up various new applications in biomedical imaging, astronomy, astrophysics, atmospheric sciences, security, robotics, and many other fields.\n\nIn this proposal, a computer-free, all-optical device that can see through unknown diffusers at the speed of light, without the need for any digital computation device was developed. Unlike previous digital approaches that utilized computers to reconstruct an image of the input object behind a diffuser, here a passive device was created using a set of diffractive surfaces/layers to all-optically reconstruct the image of an unknown object as the diffuser-distorted input optical field diffracts through successive trained diffractive layers, i.e., the image reconstruction is processed at the speed of light through this device. Each diffractive surface of a given device design has thousands of diffractive features (termed as neurons), where the individual phase values of these neurons are adjusted in the training phase through error back-propagation, by minimizing a customized loss function between the ground truth image and the diffracted pattern at the output field-of-view. After this deep learning-based design of these diffractive layers (which is a one-time effort), the resulting passive device was fabricated to form a physical diffractive optical network that is positioned between an unknown, new diffuser and the output/image plane. As the input object light passes through an unknown diffuser, the scattered light is collected by the trained diffractive device to all-optically reconstruct an image of the object at its output field-of-view, without the need for an optoelectronic device or computer or any digital computation. The success of this diffractive device was demonstrated using THz illumination, providing unique capabilities owing to the distinct properties of THz radiation. Unlike other devices, the developed diffractive image reconstruction device operates at the speed of light and does not require any power except for the illumination light. This all-optical image reconstruction achieved by passive diffractive layers enables to see objects through unknown diffusers and presents an extremely low power device compared with existing deep learning-based or iterative image reconstruction methods implemented in computers, only requiring power for the illumination source.\n\n\t\t\t\t\tLast Modified: 02/06/2022\n\n\t\t\t\t\tSubmitted by: Aydogan Ozcan"
 }
}