{
 "awd_id": "2040880",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FAI: Foundations of Fair AI in Medicine: Ensuring the Fair Use of Patient Attributes",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2021-07-01",
 "awd_exp_date": "2025-06-30",
 "tot_intn_awd_amt": 625000.0,
 "awd_amount": 625000.0,
 "awd_min_amd_letter_date": "2021-01-25",
 "awd_max_amd_letter_date": "2021-05-20",
 "awd_abstract_narration": "Machine learning models support decisions that affect millions of patients in the U.S. healthcare system in diagnosing illnesses, facilitating triage in emergency rooms, and informing supervision at intensive care units. In such applications, models will often include group attributes such as age, weight, and employment status to capture differences between patient subgroups. Standard techniques to build models with group attributes typically improve aggregate performance across the entire patient population. As a result, however, such models may lead to worse performance for specific groups. In such cases, the model may assign these groups preventable inaccurate predictions that undermine medical care and health outcomes. This project aims to prevent this harm by developing tools to ensure the fair use of group attributes in predictive models. The goal is to ensure that a model uses group attributes in a way that yields a tailored performance benefit for every group. \r\n\r\nCurrently deployed machine learning models in medicine may exhibit fair use violations that undermine health outcomes. This project mitigates fair use violations at key stages in the deployment of machine learning in medicine: verification, model development, and communication. First, it develops tools to check if a model ensures fair use. These tools include theoretical guarantees that characterize when common approaches to model development produce fair use violations, and statistical tests to verify if a model violates fair use before and during deployment. Second, it develops algorithms for learning models with fair use guarantees. Algorithms will be tailored for salient use cases in medicine, paired with open-source software, and applied to build decision support tools for real-world medical applications. Third, it creates tools to inform key stakeholders (regulators, physicians, and patients) about a model's fair use guarantees. The project draws on machine learning, information theory, optimization, human-centered design, as well as expertise in deploying models in clinical settings. The resulting toolkit for ensuring fair use of group attributes in medicine will be embedded in real-world systems through collaborations with medical researchers and industry.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Flavio",
   "pi_last_name": "Calmon",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Flavio Calmon",
   "pi_email_addr": "flavio@seas.harvard.edu",
   "nsf_id": "000733796",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Elena",
   "pi_last_name": "Glassman",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Elena L Glassman",
   "pi_email_addr": "glassman@seas.harvard.edu",
   "nsf_id": "000788229",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Berk",
   "pi_last_name": "Ustun",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Berk Ustun",
   "pi_email_addr": "berk@ucsd.edu",
   "nsf_id": "000831823",
   "pi_start_date": "2021-01-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University SEAS",
  "perf_str_addr": "33 Oxford Street, MD 347",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021382933",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "114Y00",
   "pgm_ele_name": "Fairness in Artificial Intelli"
  },
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 625000.0
  }
 ],
 "por": null
}