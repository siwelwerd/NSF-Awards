{
 "awd_id": "2100237",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CCRI: ABR: Cognitive Hardware and Software Ecosystem Community Infrastructure (CHASE-CI)",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2021-06-15",
 "awd_exp_date": "2023-05-31",
 "tot_intn_awd_amt": 999971.0,
 "awd_amount": 1015971.0,
 "awd_min_amd_letter_date": "2021-07-07",
 "awd_max_amd_letter_date": "2021-12-14",
 "awd_abstract_narration": "This project, called the Cognitive Hardware And Software Ecosystem Community Infrastructure (CHASE-CI), is to continue and expand a cloud of hundreds of affordable Graphics Processing Units (GPUs), networked together with a variety of neural network machines to facilitate development of next generation cognitive computing. This cloud will be accessible by 30 researchers assembled from 10 universities via the NSF-funded Pacific Research Platform. These researchers will investigate a range of problems from image and video recognition, computer vision, contextual robotics to cognitive neurosciences using the cloud to be purpose-built in this project.\r\n\r\nTraining of neural network with large data-sets is best performed on GPUs. Lack of availability of affordable GPUs and lack of easy access to the new generation of Non-von Neumann (NvN) machines with embedded neural networks impede research in cognitive computing. The purpose-built cloud will be available over the network to address this bottleneck. PIs will study various Deep Neural Network, Recurrent Neural Network, and Reinforcement Learning Algorithms on this platform.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Larry",
   "pi_last_name": "Smarr",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Larry L Smarr",
   "pi_email_addr": "lsmarr@ucsd.edu",
   "nsf_id": "000396797",
   "pi_start_date": "2021-07-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Tajana",
   "pi_last_name": "Rosing",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Tajana S Rosing",
   "pi_email_addr": "tajana@ucsd.edu",
   "nsf_id": "000485892",
   "pi_start_date": "2021-07-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ilkay",
   "pi_last_name": "Altintas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ilkay Altintas",
   "pi_email_addr": "altintas@sdsc.edu",
   "nsf_id": "000487407",
   "pi_start_date": "2021-07-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Thomas",
   "pi_last_name": "DeFanti",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas A DeFanti",
   "pi_email_addr": "tdefanti@ucsd.edu",
   "nsf_id": "000072525",
   "pi_start_date": "2021-07-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Qi",
   "pi_last_name": "Yu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Qi Yu",
   "pi_email_addr": "roseyu@eng.ucsd.edu",
   "nsf_id": "000767945",
   "pi_start_date": "2021-07-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "The Regents of the Univ. of Calif., U.C. San Diego",
  "perf_str_addr": "9500 Gilman Drive #0934",
  "perf_city_name": "La Jolla",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930934",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  },
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 999971.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Machine learning (ML), commonly referred to as AI, is a fast-growing scientific field in which computer neural nets are trained on data for many hours, and then the trained nets are delivered (as a chatbot or other tool) onto real-time computing platforms, smartphones, robots, drones, self-driving vehicles, and other devices throughout the Internet of Things. As ML research goals advance, better access to compute accelerators, such as Graphics Processing Units (GPUs) and Field Programmable Gate Arrays (FPGAs) is required, as are new learning resources to meet the increased student demand for courses and practical AI training.</p>\n<p>The goal of the CHASE-CI Accomplishment Based Renewal (ABR) project was to meet these demands by building a research community around a 29-campus GPU cluster: a community cyberinfrastructure (CI) called<em> Nautilus </em>developed as part of this and several complementary NSF-CISE and other federal agency awards.</p>\n<p>The CHASE-CI ABR project had seven major goals that focused on researchers, CI professionals, hardware, software, and measuring and monitoring. The primary goal (goal #1) was to double the number of CISE researchers using Nautilus and use the expansion to increase diversity in the field. New Nautilus users were shown how to containerize their applications (bundling the application's code with all the files and libraries needed to run on any infrastructure, goal #2), so they could efficiently share community CPU and GPU resources for ML and computational media applications. In addition, CI professionals were trained to manage GPU clusters (goal #3) and encouraged to create similar clusters for student use and other scientific domains. Researchers using Nautilus were then able to better exploit cloud resources from Amazon, Google, and Microsoft through high-speed research networks (goal #4). To address the challenges of limited availability and affordability of GPUs and the large storage needed for offline ML computations (goal #5), state-of-the-art hardware (Nvidia Ampere series FP32 GPUs and FPGAs) was purchased and installed within the Nautilus cluster. Programming access to new hardware architectures was provided (goal #6) to support diverse users.&nbsp; The project also monitored and measured the usage of Nautilus resources (goal #7) to evaluate CHASE-CI as a sustainable resource for research and education.</p>\n<p>Over the project's two-year period, achievement of these CHASE-CI ABR goals often exceeded expectations. Nearly 3,000 faculty, researchers, and students on more than 135 campuses across the U.S. now use Nautilus, triple the number of users from the first year of the award, and ML researchers using Nautilus get their research results much faster by graduating from just one computer under their desks to many computers -- up to 100s at a time -- being used in parallel. As part of the Nautilus expansion, minority-serving institutions (MSIs) and campuses in participating EPSCoR (Established Program for Stimulating Competitive Research) states were invited to join the CHASE-CI community to broaden access and participation in computer science. To date, the CHASE-CI community has been expanded to 135 campuses, including campuses located in 21 of the 28 EPSCoR states and territories, with 24 of the 135 campuses being MSIs. JupyterLab notebooks, which have gained popularity for their integrated environment for data exploration, and Matrix chat rooms were created to onboard, train, and support users. Matrix allows users to get support from cluster admins and engage with other users in a secure messaging system. The Nautilus Matrix community has grown to over 800 users, including channels dedicated to specific projects where Nautilus users interact with developers. This collaborative approach has enabled the entire community to provide user support rather than relying solely on one institution's technical staff, which has been particularly helpful for campuses that do not have strong CI support teams.</p>\n<p>Some NSF supercomputers and Google, Microsoft, and Amazon Web Services now allow Kubernetes orchestration for CHASE-CI users' containerized code, making it a straightforward process to move CHASE-CI jobs to commercially provided GPUs at cloud service providers when needed. The CHASE-CI/Nautilus Kubernetes-based infrastructure is operated as a coherent entity that offers both administrative and research support and is managed in a way that allows existing and new researchers to bring their own hardware. Automation (e.g., Ansible scripts) allows hardware scale-out with relatively fixed extra administrative effort, and social media techniques are used to scale-out researcher support. To sustain the success and usability of the CHASE-CI infrastructure, university CI professionals have been trained to care for and instruct usage of the Nautilus GPU clusters and to encourage building of similar clusters of GPUs for student use in classes and labs. As a result, 10,000 students a year in UCSD courses now use a tuition-funded 128-GPU Nautilus-cloned cluster. In addition, tools for measuring and monitoring scientific use of CHASE-CI resources were created that allow developers to tabulate and visualize quantitative information so that CHASE-CI resources can be continually compared to commercial cloud offerings and updated as needed to remain state-of-the-art.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/24/2023<br>\n\t\t\t\t\tModified by: Larry&nbsp;L&nbsp;Smarr</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMachine learning (ML), commonly referred to as AI, is a fast-growing scientific field in which computer neural nets are trained on data for many hours, and then the trained nets are delivered (as a chatbot or other tool) onto real-time computing platforms, smartphones, robots, drones, self-driving vehicles, and other devices throughout the Internet of Things. As ML research goals advance, better access to compute accelerators, such as Graphics Processing Units (GPUs) and Field Programmable Gate Arrays (FPGAs) is required, as are new learning resources to meet the increased student demand for courses and practical AI training.\n\nThe goal of the CHASE-CI Accomplishment Based Renewal (ABR) project was to meet these demands by building a research community around a 29-campus GPU cluster: a community cyberinfrastructure (CI) called Nautilus developed as part of this and several complementary NSF-CISE and other federal agency awards.\n\nThe CHASE-CI ABR project had seven major goals that focused on researchers, CI professionals, hardware, software, and measuring and monitoring. The primary goal (goal #1) was to double the number of CISE researchers using Nautilus and use the expansion to increase diversity in the field. New Nautilus users were shown how to containerize their applications (bundling the application's code with all the files and libraries needed to run on any infrastructure, goal #2), so they could efficiently share community CPU and GPU resources for ML and computational media applications. In addition, CI professionals were trained to manage GPU clusters (goal #3) and encouraged to create similar clusters for student use and other scientific domains. Researchers using Nautilus were then able to better exploit cloud resources from Amazon, Google, and Microsoft through high-speed research networks (goal #4). To address the challenges of limited availability and affordability of GPUs and the large storage needed for offline ML computations (goal #5), state-of-the-art hardware (Nvidia Ampere series FP32 GPUs and FPGAs) was purchased and installed within the Nautilus cluster. Programming access to new hardware architectures was provided (goal #6) to support diverse users.  The project also monitored and measured the usage of Nautilus resources (goal #7) to evaluate CHASE-CI as a sustainable resource for research and education.\n\nOver the project's two-year period, achievement of these CHASE-CI ABR goals often exceeded expectations. Nearly 3,000 faculty, researchers, and students on more than 135 campuses across the U.S. now use Nautilus, triple the number of users from the first year of the award, and ML researchers using Nautilus get their research results much faster by graduating from just one computer under their desks to many computers -- up to 100s at a time -- being used in parallel. As part of the Nautilus expansion, minority-serving institutions (MSIs) and campuses in participating EPSCoR (Established Program for Stimulating Competitive Research) states were invited to join the CHASE-CI community to broaden access and participation in computer science. To date, the CHASE-CI community has been expanded to 135 campuses, including campuses located in 21 of the 28 EPSCoR states and territories, with 24 of the 135 campuses being MSIs. JupyterLab notebooks, which have gained popularity for their integrated environment for data exploration, and Matrix chat rooms were created to onboard, train, and support users. Matrix allows users to get support from cluster admins and engage with other users in a secure messaging system. The Nautilus Matrix community has grown to over 800 users, including channels dedicated to specific projects where Nautilus users interact with developers. This collaborative approach has enabled the entire community to provide user support rather than relying solely on one institution's technical staff, which has been particularly helpful for campuses that do not have strong CI support teams.\n\nSome NSF supercomputers and Google, Microsoft, and Amazon Web Services now allow Kubernetes orchestration for CHASE-CI users' containerized code, making it a straightforward process to move CHASE-CI jobs to commercially provided GPUs at cloud service providers when needed. The CHASE-CI/Nautilus Kubernetes-based infrastructure is operated as a coherent entity that offers both administrative and research support and is managed in a way that allows existing and new researchers to bring their own hardware. Automation (e.g., Ansible scripts) allows hardware scale-out with relatively fixed extra administrative effort, and social media techniques are used to scale-out researcher support. To sustain the success and usability of the CHASE-CI infrastructure, university CI professionals have been trained to care for and instruct usage of the Nautilus GPU clusters and to encourage building of similar clusters of GPUs for student use in classes and labs. As a result, 10,000 students a year in UCSD courses now use a tuition-funded 128-GPU Nautilus-cloned cluster. In addition, tools for measuring and monitoring scientific use of CHASE-CI resources were created that allow developers to tabulate and visualize quantitative information so that CHASE-CI resources can be continually compared to commercial cloud offerings and updated as needed to remain state-of-the-art.\n\n \n\n\t\t\t\t\tLast Modified: 07/24/2023\n\n\t\t\t\t\tSubmitted by: Larry L Smarr"
 }
}