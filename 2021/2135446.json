{
 "awd_id": "2135446",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Computer-Assisted Redaction and Anonymization of Scholarly Communications and Products (CARASCAP)",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924278",
 "po_email": "plsmith@nsf.gov",
 "po_sign_block_name": "Plato Smith",
 "awd_eff_date": "2021-07-15",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 299858.0,
 "awd_amount": 299858.0,
 "awd_min_amd_letter_date": "2021-07-09",
 "awd_max_amd_letter_date": "2021-07-09",
 "awd_abstract_narration": "The Computer-Assisted Redaction and Anonymization of Scholarly Communications and Products (CARASCAP) project will produce a proof-of-concept open-source application stack to assist research teams and individual scholars in identifying, documenting, and redacting sensitive and personally identifying information within their research products.  The potential presence of personally identifying information (PII) and other sensitive information is a significant inhibitor to public access to datasets and other products of publicly funded research.  Without reliable and cost-effective processes for identifying such information, the default response is most often to indefinitely prevent the public from accessing entire collections of research products.  By developing new components and tools for iterative redaction functions incorporated into workflows to prepare datasets for public dissemination, this project will foster a stronger ecosystem of research data publishing efforts.  \r\n\r\nThe software will be developed primarily in Python, MIT Licensed, and packaged for distribution on the Python Package Index (PyPI).  Independent modules will interpret and modify the source material data structures. For this prototype phase, the project will focus on formats likely to be of interest to a broad range of collections, including open text scraped from web pages at specific URLs, text formats, and modern office formats (e.g., PDF,.odt, .docx, .pst, .ost).\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Lee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher Lee",
   "pi_email_addr": "callee@ils.unc.edu",
   "nsf_id": "000592776",
   "pi_start_date": "2021-07-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "Manning Hall",
  "perf_city_name": "Chapel Hill",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275993360",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "741400",
   "pgm_ele_name": "NSF Public Access Initiative"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 299858.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Computer-Assisted Redaction and Anonymization of Scholarly Communications and Products (CARASCAP) developed and tested new software for identification and redaction/filtering of sensitive information within scholarly communications and products (SCAP). Most modern redaction software is built using the same set of core technologies. This is typically some combination of document parser, optical character recognition, natural language processing (NLP) to identify entities of interest, pattern libraries to match common private and individually identifying information (PII) and custom string matching. Improving performance of these products is generally iterative, e.g., increasing document format coverage, expanding pattern libraries, or using improved NLP models. While performance and coverage are important factors for institutional workflows, they do not fundamentally answer new questions about how and why certain redaction actions are performed. CARASCAP introduced a new approach to add explainability to the redaction process, recording metadata that links redaction actions to specific rules and model behaviors. One can then use this information to validate software behaviors, compare those behaviors to actions performed by humans redacting manually, and train models tuned to specific redaction behaviors for collections of similar documents.&nbsp;</p>\n<p>Products of the project (available at https://github.com/carascap) include software to support text analysis, reporting, and redaction workflows.&nbsp; We have also developed Jupyter notebooks and sample data to demonstrate how the software can be implemented into various workflows.&nbsp; Aplication of NLP often requires switching between models, which was challenging with existing software.&nbsp; We also produced a command-line tool view, install, and upgrade models for those using the powerful tool called SpaCy for named-entity recognization.</p><br>\n<p>\n Last Modified: 01/22/2024<br>\nModified by: Christopher&nbsp;Lee</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nComputer-Assisted Redaction and Anonymization of Scholarly Communications and Products (CARASCAP) developed and tested new software for identification and redaction/filtering of sensitive information within scholarly communications and products (SCAP). Most modern redaction software is built using the same set of core technologies. This is typically some combination of document parser, optical character recognition, natural language processing (NLP) to identify entities of interest, pattern libraries to match common private and individually identifying information (PII) and custom string matching. Improving performance of these products is generally iterative, e.g., increasing document format coverage, expanding pattern libraries, or using improved NLP models. While performance and coverage are important factors for institutional workflows, they do not fundamentally answer new questions about how and why certain redaction actions are performed. CARASCAP introduced a new approach to add explainability to the redaction process, recording metadata that links redaction actions to specific rules and model behaviors. One can then use this information to validate software behaviors, compare those behaviors to actions performed by humans redacting manually, and train models tuned to specific redaction behaviors for collections of similar documents.\n\n\nProducts of the project (available at https://github.com/carascap) include software to support text analysis, reporting, and redaction workflows. We have also developed Jupyter notebooks and sample data to demonstrate how the software can be implemented into various workflows. Aplication of NLP often requires switching between models, which was challenging with existing software. We also produced a command-line tool view, install, and upgrade models for those using the powerful tool called SpaCy for named-entity recognization.\t\t\t\t\tLast Modified: 01/22/2024\n\n\t\t\t\t\tSubmitted by: ChristopherLee\n"
 }
}