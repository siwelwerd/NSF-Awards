{
 "awd_id": "2218226",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: CHS: RUI: Computational models of humans for studying and improving Human-AI interaction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2022-01-15",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 174148.0,
 "awd_amount": 42756.0,
 "awd_min_amd_letter_date": "2022-02-28",
 "awd_max_amd_letter_date": "2022-02-28",
 "awd_abstract_narration": "Understanding the interactions between humans and systems utilizing artificial intelligence (AI) requires an understanding of how human physiological changes impact memory and other mental processes. To realize the beneficial societal outcomes on, for example, interactions between humans and intelligent robots, it is important to develop simulations to test a variety of situations where memory under arousal states will function. In this project, the investigator articulates a research plan to use a simulation of the human mind and body to understand effects of physiological arousal on human memory and cognition and the consequences for human interaction with AI agents. Human-subject studies will be used to introduce stimuli to induce human arousal by using selected stressors and collect physiological and behavioral data during tasks that require cooperation between humans and AI agents. Societal benefits include an architecture to simulate a variety of human-AI interactions under various levels of arousal and stress. This architecture can be used to explore new ways to co-team humans with AI agents and set expectations for positive and/or negative behaviors that might occur in such collaborations. Undergraduate students at Bucknell University will be heavily involved as research assistants on this project. \r\n\r\nThe investigator plans to develop simulations and elicit arousal states in human operators performing collaborative tasks with agents enabled by artificial intelligence (AI) to understand human-AI interaction. The goal is to better understand, through simulation, how algorithms for intelligent agents can be advanced and expanded to respond to human variations in behavior and memory processes under different levels of arousal, including levels that mimic stress.  The objectives include developing simulations to examine contexts and tasks; understanding how environmental stimuli affect interactions between humans and intelligent agents; and determining how to advance algorithms to optimize human-AI cooperation and avoid maladaptive interactions. The investigator has already extended Adaptive Control of Thought-Rational (ACT-R) architecture to account for physiological influences on declarative and procedural memory. Physio-cognitive agents will be developed based on Bayesian and reinforcement learning to acquire knowledge of their environment. Human-AI task simulations will be implemented in a virtual environment to understand how arousal mediates intelligent behavior and how interaction with external environments that include AI agents may change performance, including through maladaptive behavior. The project seeks to discover computationally-enabled processes and contexts to amplify human capabilities. The resulting revised models and open-source code will be made available to the public for further explorations in human-AI interaction. The university is an undergraduate institution allowing significant participation of undergraduates in research.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Dancy",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher L Dancy",
   "pi_email_addr": "cld5070@psu.edu",
   "nsf_id": "000711315",
   "pi_start_date": "2022-02-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "201 Old Main",
  "perf_city_name": "University Park",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168021503",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "PA15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 34826.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 7930.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project set out to explore the ways people may interact with AI systems and how these interactions may be affected by how they feel and think. Furthermore, we sought to develop an early understand how social and cultural structures (e.g., racial structures founded on white supremacy) may implicitly impact how people interact with AI systems through the structures of their memory. This is important to understand as the things people have learned impact how they interact with AI systems even if what is impacting behavior isn't always apparent. That is, sometimes the effects are unconscious (though not always).</p>\n<p>Through the work supported by this project we found that how one identifies within a racial system and how they believe the AI agent learned (e.g., that it learned from behavioral data from African-American people) effects how people may cooperate and interact with that AI agent. The PI for this grant was able to publish the results from this work and present them (along with co-authors supported by this grant) in the conference on Social Computing, Behavioral-Cultural  Modeling &amp; Prediction and Behavior Representation in Modeling and  Simulation (SBP-BRiMS) in 2021. In addition, reviewing relevant research for this grant led to an understanding of the current AI ethics landscape, including places where current work in the understanding and development of ethical AI systems falls short; the results from that literature review were published in the Fairness, Accountability, and Transparency (FaaCT) conference proceedings in 2022 (a paper co-authored by the PI, a research assistant supported by the grant, and other collaborators). The insights from this work have led to follow-up work supported by new funding.</p>\n<p>Beyond the implications and outcomes in research, this funding has had positive effects in undergraduate education. The grant supported 8 undergraduate students including several Black students, thus having a positive impact on racially minoritized students. Insights from this work have been intergrated into coursework, including Artificial Intelligence courses taught at the institutions at which the PI has had appointments. These results have also been discussed in guest lectures in course not directly taught by the PI, including at other Universities.</p>\n<p>Overall, this project highlighted the very important role racial systems may play in the way people interact with AI systems, even if they don't explicitly realize it. They highlight the care we need to take when thinking about how we develop AI systems that are going to be interacting with people, something important given the current ubiquity of AI (and AI-related) systems.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/29/2023<br>\n\t\t\t\t\tModified by: Christopher&nbsp;L&nbsp;Dancy</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project set out to explore the ways people may interact with AI systems and how these interactions may be affected by how they feel and think. Furthermore, we sought to develop an early understand how social and cultural structures (e.g., racial structures founded on white supremacy) may implicitly impact how people interact with AI systems through the structures of their memory. This is important to understand as the things people have learned impact how they interact with AI systems even if what is impacting behavior isn't always apparent. That is, sometimes the effects are unconscious (though not always).\n\nThrough the work supported by this project we found that how one identifies within a racial system and how they believe the AI agent learned (e.g., that it learned from behavioral data from African-American people) effects how people may cooperate and interact with that AI agent. The PI for this grant was able to publish the results from this work and present them (along with co-authors supported by this grant) in the conference on Social Computing, Behavioral-Cultural  Modeling &amp; Prediction and Behavior Representation in Modeling and  Simulation (SBP-BRiMS) in 2021. In addition, reviewing relevant research for this grant led to an understanding of the current AI ethics landscape, including places where current work in the understanding and development of ethical AI systems falls short; the results from that literature review were published in the Fairness, Accountability, and Transparency (FaaCT) conference proceedings in 2022 (a paper co-authored by the PI, a research assistant supported by the grant, and other collaborators). The insights from this work have led to follow-up work supported by new funding.\n\nBeyond the implications and outcomes in research, this funding has had positive effects in undergraduate education. The grant supported 8 undergraduate students including several Black students, thus having a positive impact on racially minoritized students. Insights from this work have been intergrated into coursework, including Artificial Intelligence courses taught at the institutions at which the PI has had appointments. These results have also been discussed in guest lectures in course not directly taught by the PI, including at other Universities.\n\nOverall, this project highlighted the very important role racial systems may play in the way people interact with AI systems, even if they don't explicitly realize it. They highlight the care we need to take when thinking about how we develop AI systems that are going to be interacting with people, something important given the current ubiquity of AI (and AI-related) systems.\n\n\t\t\t\t\tLast Modified: 10/29/2023\n\n\t\t\t\t\tSubmitted by: Christopher L Dancy"
 }
}