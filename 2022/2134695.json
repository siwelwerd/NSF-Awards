{
 "awd_id": "2134695",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Image-based Readouts of Cellular State using Universal Morphology Embeddings",
 "cfda_num": "47.074",
 "org_code": "08080000",
 "po_phone": "7032922224",
 "po_email": "jweller@nsf.gov",
 "po_sign_block_name": "Jennifer Weller",
 "awd_eff_date": "2022-05-01",
 "awd_exp_date": "2023-11-30",
 "tot_intn_awd_amt": 512731.0,
 "awd_amount": 512731.0,
 "awd_min_amd_letter_date": "2022-01-25",
 "awd_max_amd_letter_date": "2022-01-25",
 "awd_abstract_narration": "Observing cells under the microscope reveals an incredible amount of information about cellular processes. For example, images of cells can reveal cell types, and whether the cells are healthy or sick, among others. This research aims to develop advanced computational models to measure cellular traits in microscopy images. Cellular measurements taken from images are useful to conduct biological research such as understanding how diseases work, diagnosing patients, and searching for effective cures. All of these applications are fundamental to advance and promote national health. An important aspect of this project is that the computational models for measuring cellular traits will be of general purpose and reusable across many biological applications where microscopy images are acquired, with minimal or no manual configuration. This research will design, develop and make publicly available the models and automated tools to facilitate rapid image-based cellular analysis in basic biological research and other biotechnology systems. This project will involve diverse researchers working in an inclusive environment at the intersection of cutting-edge machine learning technologies and image analysis for cell biology. Diverse graduate students and postdocs will be trained in an inclusive environment at the intersection of cutting-edge deep learning technologies and\r\nimage analysis for cell biology.\r\n\r\nExtracting cell morphological features from images is a complex, ad-hoc process without well established standards. Typically, imaging projects develop custom approaches from scratch and measure only a few cellular features given the complexity and diversity of imaging techniques and experimental goals. This lack of a common methodology to define and measure the morphological state of single cells prevents researchers from realizing the full potential of imaging for advancing cell biology. This project aims to create a universal deep-learning model for collecting single-cell morphological data. It will readily quantify cell morphology in any microscopy image, requiring little to no training. The specific goals of this research are: 1) develop methods for learning and extracting multidimensional representations of cell morphology from diverse imaging experiments, 2) formulate strategies for correcting batch effects and removing technical variation, and 3) develop strategies for analyzing and interpreting the biological significance of morphological features. For learning representations, neural networks that can adaptively process multi-channel microscopy images will be developed and trained using self-supervised learning. Domain adaptation techniques will be extended for correcting batch effects. Importantly, learned features will be used to map relations between populations of cells and explainable methods will be designed to facilitate their interpretation. This research will prepare imaging datasets from various public sources for training and evaluation, including the Broad Bioimage Benchmark Collections (BBBC), the Image Data Resource (IDR), and the Human Protein Atlas (HPA). The models created in this project will be applicable to most microscopy imaging protocols to transform images of single cells into quantitative data for biological research. All the results, software tools and models will be publicly available at http://broad.io/morphem\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "BIO",
 "org_dir_long_name": "Directorate for Biological Sciences",
 "div_abbr": "DBI",
 "org_div_long_name": "Division of Biological Infrastructure",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Juan",
   "pi_last_name": "Caicedo",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Juan C Caicedo",
   "pi_email_addr": "jcaicedo@broad.mit.edu",
   "nsf_id": "000856295",
   "pi_start_date": "2022-01-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Broad Institute, Inc.",
  "inst_street_address": "415 MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6177147000",
  "inst_zip_code": "021421027",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "THE BROAD INSTITUTE, INC",
  "org_prnt_uei_num": "H5G9NWEFHXN4",
  "org_uei_num": "H5G9NWEFHXN4"
 },
 "perf_inst": {
  "perf_inst_name": "Broad Institute, Inc.",
  "perf_str_addr": "415 Main Street",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021421027",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164Y00",
   "pgm_ele_name": "Innovation: Bioinformatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1165",
   "pgm_ref_txt": "ADVANCES IN BIO INFORMATICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 256064.0
  }
 ],
 "por": null
}