{
 "awd_id": "2213187",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Low-Density Logical Qubit Parity Coding",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2022-09-15",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 255414.0,
 "awd_amount": 255414.0,
 "awd_min_amd_letter_date": "2022-09-09",
 "awd_max_amd_letter_date": "2024-01-23",
 "awd_abstract_narration": "The broader impact of this Small Business Innovation Research (SBIR) Phase I project will be to accelerate the adoption of error correction technologies in the quantum computing industry.  It is widely held that quantum error correction will be critical to realize the potential of universal quantum computing.  An error-corrected quantum computer holds promise for making transformational discoveries in science and engineering that will have broad impact across traditional technology sectors. By developing resource-efficient quantum error correction design and decoding software tools, this Phase I project aims to hasten the era of error-corrected quantum computing.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project will advance a new method for error syndrome extraction from a register of data qubits during the execution of an error-corrected quantum algorithm. In contrast to the standard approach to syndrome extraction, where each quantum codeword is treated independently, this new approach extracts error information from the entire quantum computer collectively.  The algorithmic and cost advantage of the proposed approach is a reduction in the number of extra qubits required for error syndrome extraction. This project will focus on reducing the density of the quantum circuits used for syndrome extraction according to the new approach. Low-density quantum circuits are critical for robust quantum error correction since syndrome extraction is mediated by two-qubit entangling gates, which often have error rates higher than idling or memory errors occurring in the data qubits. Another objective of this Phase I project is to design low-density error correcting codes that promote locality in syndrome extraction. Local syndrome extraction is important for error correction in quantum processors that support limited connectivity between qubits. A final objective is to benchmark the proposed constructions and algorithms on simulated data and perform proof-of-concept experimental validation on cloud-based quantum computers.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dennis",
   "pi_last_name": "Lucarelli",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dennis Lucarelli",
   "pi_email_addr": "dennis@error-corp.com",
   "nsf_id": "000861521",
   "pi_start_date": "2022-09-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "ERROR CORP.",
  "inst_street_address": "4405 E WEST HWY",
  "inst_street_address_2": "STE 410",
  "inst_city_name": "BETHESDA",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "2409889655",
  "inst_zip_code": "208144535",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "MD08",
  "org_lgl_bus_name": "ERROR CORP.",
  "org_prnt_uei_num": "",
  "org_uei_num": "UAQADPJ23Q97"
 },
 "perf_inst": {
  "perf_inst_name": "ERROR CORP.",
  "perf_str_addr": "4405 East West Highway",
  "perf_city_name": "Bethesda",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "208144522",
  "perf_ctry_code": "US",
  "perf_cong_dist": "08",
  "perf_st_cong_dist": "MD08",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7203",
   "pgm_ref_txt": "QUANTUM INFORMATION SCIENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 255414.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong id=\"docs-internal-guid-5ff20a8e-7fff-189d-64d4-8a81ec3a7c94\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"> </strong></p>\n<p>A growing ecosystem of quantum hardware and software companies has emerged in the last several years around the notion that quantum computers can be leveraged to demonstrate quantum advantage over conventional computing <em>and</em> create real business value across the spectrum of traditional technology sectors.&nbsp; Analogous to the widespread use of conventional computers for scientific discovery and engineering, a quantum computer will create value throughout industry by increasing the accuracy and lowering the cost of simulating complex quantum processes and solving large-scale optimization problems.</p>\n<p>Noise currently limits the utility of quantum computers. To combat the accumulation of errors during the execution of a quantum algorithm, quantum error correction will be essential. &nbsp;Error correction achieves robustness through redundancy and current approaches to quantum error correction incur significant overhead, presenting a significant obstacle to realizing useful quantum computing.</p>\n<p>This SBIR project advanced a new approach to quantum error correction that lowers the quantum resources required for error correction while maintaining performance guarantees. In contrast to the standard approach to error syndrome extraction, where a separate set of syndrome qubits is devoted to each logical qubit, Error Corp has developed a new approach&minus;called <em>Logical Qubit Parity Coding</em>&minus;that extracts error information from the entire computer collectively by prescribing additional parity measurements across the logical qubits. This global view is consistent with the laws of quantum mechanics, does not destroy the quantum data, and, importantly, leads to significant savings in the number of syndrome qubits required for large-scale quantum error correction.</p>\n<p>The principal research and development goals of the Phase I project were to extend and benchmark Error Corp.'s technique for large-scale quantum error correction, with a particular emphasis on addressing the challenges associated with commercialization and product development. &nbsp;We identified two main issues preventing adoption of our approach: (1) circuit noise and (2) limited connectivity between qubits.&nbsp;&nbsp; <em>Circuit noise</em> refers to errors that can be added back into the data qubits while performing error correction or during a faulty measurement.&nbsp; In this Phase I SBIR project, we developed and benchmarked our Logical Parity Coding approach when paired with a classical low-density parity check code.&nbsp; This results in a quantum low-density parity check code that limits the number of entangling operations required to extract error information from the data qubits.&nbsp; To benchmark our method, we developed the belief propagation (BP) decoding algorithm tailored to quantum low-density Logical Parity-check codes couple with the ordered statistics decoding post-processing (OSD).&nbsp; We applied this two-stage decoder to examples of Low-density Logical Parity Coding to simulate the detection and correction performance of our approach and found excellent performance approaching the code capacity when assuming perfect measurements.&nbsp; In addition to the BP+OSD decoder, we implemented a neural network-based decoder based on BP that includes learnable weights in the BP iterations.&nbsp; Simulations with the neural network decoder demonstrates that a machine learning approach can improve detection and correction performance when training data is available.</p>\n<p>Limited connectivity between qubits implies that long-range interactions between qubits require costly and error-prone routing of information through the connectivity graph of the quantum processor. &nbsp;Since leading qubit architectures, such as superconducting and silicon-based quantum processors exhibit limited connectivity, imposing locality constraints in Low-Density Logical Parity Coding was a commercialization priority.&nbsp; To address limited connectivity, in Phase I we developed a new architecture that supports a 2-layer architecture with limited connectivity in each layer and between the two layers.&nbsp; This new architecture shares the same benefits of Logical Parity Coding, but supports multiple-shot syndrome extraction and preserves locality of the base quantum code.&nbsp; This new method developed in Phase I, called <em>Logical Qubit Syndrome Compression</em>, applies to other post-selection tasks require for fault-tolerant quantum computing. To demonstrate novel applications of our method, we applied the Logical Qubit Syndrome Compression to magic state distillation and found significant speed-ups to the process in simulation.&nbsp;</p>\n<p><strong id=\"docs-internal-guid-5ff20a8e-7fff-189d-64d4-8a81ec3a7c94\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"> </strong></p>\n<p style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><strong id=\"docs-internal-guid-5ff20a8e-7fff-189d-64d4-8a81ec3a7c94\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"><span style=\"font-size: 11pt; font-family: Arial, sans-serif; color: #000000; background-color: transparent; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span></strong></p>\n<p><strong id=\"docs-internal-guid-5ff20a8e-7fff-189d-64d4-8a81ec3a7c94\" style=\"caret-color: #000000; color: #000000; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none; font-weight: normal;\"> </strong></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/01/2024<br>\nModified by: Dennis&nbsp;Lucarelli</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nA growing ecosystem of quantum hardware and software companies has emerged in the last several years around the notion that quantum computers can be leveraged to demonstrate quantum advantage over conventional computing and create real business value across the spectrum of traditional technology sectors. Analogous to the widespread use of conventional computers for scientific discovery and engineering, a quantum computer will create value throughout industry by increasing the accuracy and lowering the cost of simulating complex quantum processes and solving large-scale optimization problems.\n\n\nNoise currently limits the utility of quantum computers. To combat the accumulation of errors during the execution of a quantum algorithm, quantum error correction will be essential. Error correction achieves robustness through redundancy and current approaches to quantum error correction incur significant overhead, presenting a significant obstacle to realizing useful quantum computing.\n\n\nThis SBIR project advanced a new approach to quantum error correction that lowers the quantum resources required for error correction while maintaining performance guarantees. In contrast to the standard approach to error syndrome extraction, where a separate set of syndrome qubits is devoted to each logical qubit, Error Corp has developed a new approachcalled Logical Qubit Parity Codingthat extracts error information from the entire computer collectively by prescribing additional parity measurements across the logical qubits. This global view is consistent with the laws of quantum mechanics, does not destroy the quantum data, and, importantly, leads to significant savings in the number of syndrome qubits required for large-scale quantum error correction.\n\n\nThe principal research and development goals of the Phase I project were to extend and benchmark Error Corp.'s technique for large-scale quantum error correction, with a particular emphasis on addressing the challenges associated with commercialization and product development. We identified two main issues preventing adoption of our approach: (1) circuit noise and (2) limited connectivity between qubits. Circuit noise refers to errors that can be added back into the data qubits while performing error correction or during a faulty measurement. In this Phase I SBIR project, we developed and benchmarked our Logical Parity Coding approach when paired with a classical low-density parity check code. This results in a quantum low-density parity check code that limits the number of entangling operations required to extract error information from the data qubits. To benchmark our method, we developed the belief propagation (BP) decoding algorithm tailored to quantum low-density Logical Parity-check codes couple with the ordered statistics decoding post-processing (OSD). We applied this two-stage decoder to examples of Low-density Logical Parity Coding to simulate the detection and correction performance of our approach and found excellent performance approaching the code capacity when assuming perfect measurements. In addition to the BP+OSD decoder, we implemented a neural network-based decoder based on BP that includes learnable weights in the BP iterations. Simulations with the neural network decoder demonstrates that a machine learning approach can improve detection and correction performance when training data is available.\n\n\nLimited connectivity between qubits implies that long-range interactions between qubits require costly and error-prone routing of information through the connectivity graph of the quantum processor. Since leading qubit architectures, such as superconducting and silicon-based quantum processors exhibit limited connectivity, imposing locality constraints in Low-Density Logical Parity Coding was a commercialization priority. To address limited connectivity, in Phase I we developed a new architecture that supports a 2-layer architecture with limited connectivity in each layer and between the two layers. This new architecture shares the same benefits of Logical Parity Coding, but supports multiple-shot syndrome extraction and preserves locality of the base quantum code. This new method developed in Phase I, called Logical Qubit Syndrome Compression, applies to other post-selection tasks require for fault-tolerant quantum computing. To demonstrate novel applications of our method, we applied the Logical Qubit Syndrome Compression to magic state distillation and found significant speed-ups to the process in simulation.\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 10/01/2024\n\n\t\t\t\t\tSubmitted by: DennisLucarelli\n"
 }
}