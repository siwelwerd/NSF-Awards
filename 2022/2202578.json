{
 "awd_id": "2202578",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Seeing Science: Using Computer Vision to Explore the Scientific Principles Behind Everyday Objects",
 "cfda_num": "47.070, 47.076",
 "org_code": "05020000",
 "po_phone": "7032922190",
 "po_email": "ltakeuch@nsf.gov",
 "po_sign_block_name": "Lori Takeuchi",
 "awd_eff_date": "2022-07-01",
 "awd_exp_date": "2026-06-30",
 "tot_intn_awd_amt": 425000.0,
 "awd_amount": 425000.0,
 "awd_min_amd_letter_date": "2022-06-14",
 "awd_max_amd_letter_date": "2022-06-14",
 "awd_abstract_narration": "Understanding science is critical for preparing students to make sense of the world around them, make informed decisions, and participate in civic society and in the workforce. However, for many youth, science is a mysterious body of knowledge that feels disconnected from their lives. This project aims to bring science into middle school students\u2019 homes, allowing them to see the science behind everyday objects and transforming lived environments into engaging learning spaces. Students will work on inquiry-based learning units on mobile phones that explore STEM phenomena topics like diffusion, electricity, and simple machines that are present in their kitchens, bedrooms, and local parks. They will be able to take photos and videos of their home and neighborhood, and computer vision algorithms will augment these images with diagrams, models, and simulations that illustrate the principles and mechanisms that explain the STEM phenomena. These overlays will allow students to observe, experiment with, and make predictions for phenomena such as tea diffusing in hot water or heat traveling through walls. The project will capitalize on existing technological devices, such as camera phones, to create \u201clenses\u201d which enable students to see the science that is all around them.\r\n \r\nBy committing to such low-cost solutions, the project aims to make science education accessible to more students, and enable at-home learning while avoiding undue pressures on family resources. Operating in diverse, low-resource environments motivates fundamental advances in computer vision: First, algorithms must automatically build up a 3D and temporal representation of a scene of a given physical phenomenon. Second, the system must expose hooks for educators to decide which graphics should be overlaid at which time and in which place atop this scene. Further, the project will engage in human-centered design to bring cutting-edge technologies to youth in ways that are accessible, easy to use, and achieve educational goals. Investigators will conduct extensive interviews with parents, students, and teachers about the aspects of students\u2019 out-of-school lives that they would be willing to share with researchers, peers, and teachers. These data will enable the team to realize the benefits of equitable science education that builds on students\u2019 lives and cultures. This research will help foster the development of a more agentic, inclusive way of engaging in science inquiry at home, encouraging students to have a personal connection with science from a young age. This is particularly important for students most at risk to perceive science as disconnected from their lives, and whom can benefit most from seeing science at work in their lives and community.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lydia",
   "pi_last_name": "Chilton",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Lydia B Chilton",
   "pi_email_addr": "chilton@cs.columbia.edu",
   "nsf_id": "000776634",
   "pi_start_date": "2022-06-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Carl",
   "pi_last_name": "Vondrick",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Carl M Vondrick",
   "pi_email_addr": "cv2428@columbia.edu",
   "nsf_id": "000755733",
   "pi_start_date": "2022-06-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "2960 Broadway",
  "perf_city_name": "NEW YORK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100276902",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "722700",
   "pgm_ele_name": "ITEST-Inov Tech Exp Stu & Teac"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "093Z",
   "pgm_ref_txt": "AI Education/Workforce Develop"
  },
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "1300PYXXDB",
   "fund_name": "H-1B FUND, EDU, NSF",
   "fund_symb_id": "045176"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 425000.0
  }
 ],
 "por": null
}