{
 "awd_id": "2202898",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "PostDoctoral Research Fellowship",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922113",
 "po_email": "ygorb@nsf.gov",
 "po_sign_block_name": "Yuliya Gorb",
 "awd_eff_date": "2022-09-01",
 "awd_exp_date": "2026-08-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2022-03-17",
 "awd_max_amd_letter_date": "2022-03-17",
 "awd_abstract_narration": "This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2). This award is made as part of the FY 2022 Mathematical Sciences Postdoctoral Research Fellowships Program. Each of the fellowships supports a research and training project at a host institution in the mathematical sciences, including applications to other disciplines, under the mentorship of a sponsoring scientist.\r\n\r\nThe title of the project for this fellowship to Jessica Finocchiaro is \"Analyzing the design and impact of loss functions in prediction.\" The host institution for the fellowship is Harvard University, and the sponsoring scientist is Yiling Chen.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jessica",
   "pi_last_name": "Finocchiaro",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Jessica J Finocchiaro",
   "pi_email_addr": "",
   "nsf_id": "000866472",
   "pi_start_date": "2022-03-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Finocchiaro, Jessica J",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "Boulder",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "",
  "inst_zip_code": "80309",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "Finocchiaro, Jessica J",
  "perf_str_addr": null,
  "perf_city_name": "Boulder",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "803090422",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "060Y00",
   "pgm_ele_name": "Workforce (MSPRF) MathSciPDFel"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "102Z",
   "pgm_ref_txt": "COVID-Disproportionate Impcts Inst-Indiv"
  },
  {
   "pgm_ref_code": "9219",
   "pgm_ref_txt": "POSTDOCTORAL FELLOWSHIPS IN MATH SCIENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "010V2122DB",
   "fund_name": "R&RA ARP Act DEFC V",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project studied two main questions across algorithmic game theory and machine learining:</p>\n<p>1. <strong>How do we understand algorithms that interact with fairness-concerned people?</strong> Historically, we've decided these algorithms are good if they produce good results for people who \"play well.\" This thread re-evaluates what it means to \"play well.\" Often, we assume players are self-interested and have full knowledge of what they want. Instead, this thread evlauates how some standard algorithms interact with people who are (a) inequality-averse, and (b) affected by information about others' preferences.</p>\n<p>Related publications: [1, 2]</p>\n<p>&nbsp;</p>\n<p>2. <strong>What are the consequences of the objectives we optimize in algorithm design? </strong>While algorithmic recommendations show much promise, perfect prediction is generally impossible. In the face of this impossibility, the way we design our algorithms (namely, what we teach them to predict) is incredibly consequential for our decision-making with these algorithmic recommendations. &nbsp;This thread examines (a) when and how constraints on acceptable solutions (e.g., fairness concerns) affect algorithmic recommendations, (b) how to design efficient algorithms while only minimally sacrificing performance guarantees when the strongest guarantees are too expensive, (c) how robust certain algorithms for algorithmic decision-making are in a worst-case approach, and (d) how codifications of fairness constraints are minimally viable in a stylized model of information-sharing.</p>\n<p>&nbsp;</p>\n<p>Related publications: [3, 4, 5, 6, 7]</p>\n<p>&nbsp;</p>\n<p>In addition, this project reflected on general lessons to be learned when designing algorithms that interact with marginalized people via a collaborative autoethnography following a series of interviews with practitioners across a variety of domains seeking to use data-driven decision-making in their work [8].</p>\n<p>&nbsp;</p>\n<p><strong>References</strong></p>\n<p>&nbsp;</p>\n<p>[1]&nbsp;Ali Shirali, Jessie Finocchiaro, and Rediet Abebe. 2024. Participatory Objective Design via Preference Elicitation. In Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT '24). Association for Computing Machinery, New York, NY, USA, 1637&ndash;1662. https://doi.org/10.1145/3630106.3658994</p>\n<p>&nbsp;</p>\n<p>[2]&nbsp;<span>Yiling Chen and Jessie Finocchiaro. \"Robustness of voting mechanisms to external information in expectation.\"&nbsp;</span><em>arXiv preprint arXiv:2404.07818</em><span>&nbsp;(2024).</span></p>\n<p>&nbsp;</p>\n<p><span>[3]&nbsp;<span>Jessie Finocchiaro. \"Using Property Elicitation to Understand the Impacts of Fairness Regularizers.\"&nbsp;</span><em>The 2024 ACM Conference on Fairness, Accountability, and Transparency</em><span>. 2024.</span></span></p>\n<p>&nbsp;</p>\n<p><span><span>[4]&nbsp;<span>Enrique Nueve IV, et al. \"Trading off Consistency and Dimensionality of Convex Surrogates for the Mode.\"&nbsp;</span><em>arXiv preprint arXiv:2402.10818</em><span>&nbsp;(2024).</span></span></span></p>\n<p>&nbsp;</p>\n<p><span><span><span>[5] Sonja&nbsp;<span>Johnson-Yu et al. \"Characterizing and Improving the Robustness of Predict-Then-Optimize Frameworks.\"&nbsp;</span><em>International Conference on Decision and Game Theory for Security</em><span>. Cham: Springer Nature Switzerland, 2023.</span></span></span></span></p>\n<p>&nbsp;</p>\n<p><span><span><span><span>[6] Jessie&nbsp;<span>Finocchiaro, Rafael M. Frongillo, and Bo Waggoner. \"An embedding framework for the design and analysis of consistent polyhedral surrogates.\"&nbsp;</span><em>Journal of Machine Learning Research</em><span>&nbsp;25.63 (2024): 1-60.</span></span></span></span></span></p>\n<p>&nbsp;</p>\n<p><span><span><span><span><span>[7] Jakob&nbsp;<span>Schoeffer et al. \"Online platforms and the fair exposure problem under Homophily.\"&nbsp;</span><em>Proceedings of the AAAI Conference on Artificial Intelligence</em><span>. Vol. 37. No. 10. 2023.</span></span></span></span></span></span></p>\n<p>&nbsp;</p>\n<p><span><span><span><span><span><span>[8]&nbsp;<span>Mayra Russo et al. \"Bridging Research and Practice through Conversations with Practitioners.\"&nbsp;</span><em>Proceedings of the ACM Conference on Equity and Access to Algorithms, Mechanisms, and Optimization</em><span>. Forthcoming, 2024.</span></span></span></span></span></span></span></p><br>\n<p>\n Last Modified: 08/02/2024<br>\nModified by: Jessica&nbsp;J&nbsp;Finocchiaro</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project studied two main questions across algorithmic game theory and machine learining:\n\n\n1. How do we understand algorithms that interact with fairness-concerned people? Historically, we've decided these algorithms are good if they produce good results for people who \"play well.\" This thread re-evaluates what it means to \"play well.\" Often, we assume players are self-interested and have full knowledge of what they want. Instead, this thread evlauates how some standard algorithms interact with people who are (a) inequality-averse, and (b) affected by information about others' preferences.\n\n\nRelated publications: [1, 2]\n\n\n\n\n\n2. What are the consequences of the objectives we optimize in algorithm design? While algorithmic recommendations show much promise, perfect prediction is generally impossible. In the face of this impossibility, the way we design our algorithms (namely, what we teach them to predict) is incredibly consequential for our decision-making with these algorithmic recommendations. This thread examines (a) when and how constraints on acceptable solutions (e.g., fairness concerns) affect algorithmic recommendations, (b) how to design efficient algorithms while only minimally sacrificing performance guarantees when the strongest guarantees are too expensive, (c) how robust certain algorithms for algorithmic decision-making are in a worst-case approach, and (d) how codifications of fairness constraints are minimally viable in a stylized model of information-sharing.\n\n\n\n\n\nRelated publications: [3, 4, 5, 6, 7]\n\n\n\n\n\nIn addition, this project reflected on general lessons to be learned when designing algorithms that interact with marginalized people via a collaborative autoethnography following a series of interviews with practitioners across a variety of domains seeking to use data-driven decision-making in their work [8].\n\n\n\n\n\nReferences\n\n\n\n\n\n[1]Ali Shirali, Jessie Finocchiaro, and Rediet Abebe. 2024. Participatory Objective Design via Preference Elicitation. In Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT '24). Association for Computing Machinery, New York, NY, USA, 16371662. https://doi.org/10.1145/3630106.3658994\n\n\n\n\n\n[2]Yiling Chen and Jessie Finocchiaro. \"Robustness of voting mechanisms to external information in expectation.\"arXiv preprint arXiv:2404.07818(2024).\n\n\n\n\n\n[3]Jessie Finocchiaro. \"Using Property Elicitation to Understand the Impacts of Fairness Regularizers.\"The 2024 ACM Conference on Fairness, Accountability, and Transparency. 2024.\n\n\n\n\n\n[4]Enrique Nueve IV, et al. \"Trading off Consistency and Dimensionality of Convex Surrogates for the Mode.\"arXiv preprint arXiv:2402.10818(2024).\n\n\n\n\n\n[5] SonjaJohnson-Yu et al. \"Characterizing and Improving the Robustness of Predict-Then-Optimize Frameworks.\"International Conference on Decision and Game Theory for Security. Cham: Springer Nature Switzerland, 2023.\n\n\n\n\n\n[6] JessieFinocchiaro, Rafael M. Frongillo, and Bo Waggoner. \"An embedding framework for the design and analysis of consistent polyhedral surrogates.\"Journal of Machine Learning Research25.63 (2024): 1-60.\n\n\n\n\n\n[7] JakobSchoeffer et al. \"Online platforms and the fair exposure problem under Homophily.\"Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 10. 2023.\n\n\n\n\n\n[8]Mayra Russo et al. \"Bridging Research and Practice through Conversations with Practitioners.\"Proceedings of the ACM Conference on Equity and Access to Algorithms, Mechanisms, and Optimization. Forthcoming, 2024.\t\t\t\t\tLast Modified: 08/02/2024\n\n\t\t\t\t\tSubmitted by: JessicaJFinocchiaro\n"
 }
}