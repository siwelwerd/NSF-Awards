{
 "awd_id": "2218220",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Visual Control of Steering, Obstacle Avoidance, and Path Following",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2022-08-15",
 "awd_exp_date": "2025-07-31",
 "tot_intn_awd_amt": 418127.0,
 "awd_amount": 418127.0,
 "awd_min_amd_letter_date": "2022-07-24",
 "awd_max_amd_letter_date": "2022-07-24",
 "awd_abstract_narration": "The ability to guide one\u2019s movement through the world on the basis of vision plays an essential role in many daily activities, from routine behaviors such as walking through crowded spaces to skilled tasks such as steering a tractor-trailer along a mountain road.  Oftentimes, humans and other animals must move at high speeds through densely cluttered environments, avoiding obstacles, squeezing through narrow openings, and following winding paths to reach their goals.  To perform such tasks safely and efficiently, it is not enough to focus entirely on the most nearby objects.  Skillful navigation also relies on the ability to look farther ahead and anticipate the need to reach goals that lie beyond the immediate future.  This project will investigate how people visually guide their movement to satisfy goals over multiple time horizons.  It is novel in its focus on tasks that push the limits of human visual-motor performance to the extreme and that could inform the development of semiautonomous driver- and pilot-assist technologies.  The research will benefit society by revealing new visual control strategies that could be adapted for use on robots to produce more skillful and human-like behavior.  \r\n\r\nThe ability to adapt behavior in anticipation of future goals is often assumed to reflect elaborate cognitive processes such as path planning that rely on internal models.  However, there are very few empirical studies of anticipatory steering behavior and the possibility that such behavior could be captured without invoking internal models has not yet been seriously considered.  This project combines experiments on steering and gaze behavior in humans with mathematical modeling to explore how humans guide their movements to satisfy both immediate and future constraints on their trajectory.  Using a custom-designed, virtual reality drone piloting simulator, the researchers will study the steering and gaze strategies that humans use to navigate through a series of waypoints and will conduct experiments to reveal how and in what conditions humans adapt their movements in anticipation of future goals.  They will also use modeling and simulation to determine whether anticipatory steering behavior can emerge without model-based path planning.  Lastly, a suite of research tools for conducting experiments in virtual reality and for processing, analyzing, and visualizing gaze data will be developed and made available to the scientific community.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Brett",
   "pi_last_name": "Fajen",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Brett R Fajen",
   "pi_email_addr": "fajenb@rpi.edu",
   "nsf_id": "000124857",
   "pi_start_date": "2022-07-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rensselaer Polytechnic Institute",
  "inst_street_address": "110 8TH ST",
  "inst_street_address_2": "",
  "inst_city_name": "TROY",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5182766000",
  "inst_zip_code": "121803590",
  "inst_country_name": "United States",
  "cong_dist_code": "20",
  "st_cong_dist_code": "NY20",
  "org_lgl_bus_name": "RENSSELAER POLYTECHNIC INSTITUTE",
  "org_prnt_uei_num": "",
  "org_uei_num": "U5WBFKEBLMX3"
 },
 "perf_inst": {
  "perf_inst_name": "Rensselaer Polytechnic Institute",
  "perf_str_addr": "Cognitive Science Department, 11",
  "perf_city_name": "Troy",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "121803522",
  "perf_ctry_code": "US",
  "perf_cong_dist": "20",
  "perf_st_cong_dist": "NY20",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 418127.0
  }
 ],
 "por": null
}