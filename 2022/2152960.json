{
 "awd_id": "2152960",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Algorithms for Learning Regularizations of Inverse Problems with High Data Heterogeneity",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2022-04-15",
 "awd_exp_date": "2025-03-31",
 "tot_intn_awd_amt": 170000.0,
 "awd_amount": 170000.0,
 "awd_min_amd_letter_date": "2022-03-11",
 "awd_max_amd_letter_date": "2024-05-09",
 "awd_abstract_narration": "In today's era of big data, massive amount of data are being collected in various acquisition settings and different formats from diverse sources. Such high heterogeneity has posed serious challenges in many aspects of analysis, inference, and computation involving big data. This project aims at developing novel modeling and computational methods, including highly structured deep neural networks and novel training algorithms, to effectively address this challenging issue. Results of this project will provide powerful computational tools to a broad range of important fields involving large heterogenous data sets, such as signal processing, medical imaging, computer vision, and bioinformatics.\r\n\r\nThe research in this project includes three major components: (1) Development of learnable optimization algorithms (LOAs) which induce highly efficient schemes for solving nonconvex and nonsmooth inverse problems. These LOAs effectively integrate residual learning architectures into exact and inexact descent-type algorithms, which not only have outstanding efficiency compared to the state-of-the-art methods in practice but are also supported by rigorous convergence guarantees in theory; (2) Novel training strategies based on bi-level optimization to learn the parameters of the LOAs, which can explore the underlying common features across a variety of tasks in heterogeneous data sets as well as the task-specific features; and (3) Efficient methods to solve the bi-level optimization problems of parameter training with comprehensive computation and sampling complexity analysis.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiaojing",
   "pi_last_name": "Ye",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaojing Ye",
   "pi_email_addr": "xye@gsu.edu",
   "nsf_id": "000636991",
   "pi_start_date": "2022-03-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia State University Research Foundation, Inc.",
  "inst_street_address": "58 EDGEWOOD AVE NE",
  "inst_street_address_2": "FL 3",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4044133570",
  "inst_zip_code": "303032921",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA STATE UNIVERSITY RESEARCH FOUNDATION INC",
  "org_prnt_uei_num": "",
  "org_uei_num": "MNS7B9CVKDN7"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia State University",
  "perf_str_addr": "25 Park Place",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303032921",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806900",
   "pgm_ele_name": "CDS&E-MSS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 32818.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 68593.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 68589.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aims at constructing a comprehensive framework of computational methods to handle problems with large amount of data sets collected in various acquisition settings, different formats, and diverse sources in real-world applications. The issue of high data heterogeneity has posed serious challenges in many aspects of analysis, inference, and computation involving big data. In this project, the PI and his collaborators developed a series of novel modeling and computational methods, including highly structured deep neural networks and novel training algorithms, to effectively resolve these challenges. Results of this project provide powerful computational tools to solve problems in a broad range of important fields involving large heterogenous data sets, such as signal/image processing, computer vision, and machine learning.</p>\r\n<p>&nbsp;</p>\r\n<p>The research in this project made several major contributions: (1) Development of learnable optimization algorithms (LOAs). LOAs induce highly efficient schemes for solving non-convex and non-smooth inverse problems which are prevalent in modern computational science and data-driven applications. By effectively integrating residual learning architectures into descent-type algorithms, LOAs not only have outstanding efficiency compared to the existing methods in numerous empirical tests, but are also proved to have convergence guarantee using rigorous mathematical analysis; (2) Development of novel training strategies based on bi-level optimization to learn the parameters of LOAs, which can explore the underlying common features across a variety of tasks in heterogeneous data sets as well as the task-specific features; (3) Development of efficient methods to solve bi-level optimization problems of parameter training with comprehensive computation and sampling complexity analysis. These methods are also applicable to similar parameter learning problems that are prevalent in other application domains; and (4) Discovery of novel nonlinear reduced-order model (ROM) approach to tackle computational problems defined on infinite-dimensional function spaces. The new approach establishes deep connections between the finite-dimensional parameters of ROMs and the corresponding functions and provide insights and new computational techniques to solve relevant problems such as Wasserstein gradient and Hamiltonian flows in high dimension. The idea has been revolutionized to address more challenging operator learning problems, for example, to directly approximate mappings from initial values to the corresponding solutions of high-dimensional evolution PDEs with self-generated and adaptive data sampling strategies.</p>\r\n<p>&nbsp;</p>\r\n<p>In summary, the algorithms developed in this project effectively integrate deep neural network architectures into customized numerical schemes with comprehensive mathematical theory. The new methods can be used to solve a broad range of inverse problems which are prevalent in signal/image processing, machine learning, computer vision, optimal control, among many others. The results benefit both research and industry communities. The research findings have been integrated into the education program at the PI&rsquo;s institution via new course entitled Mathematical Foundations of Deep Learning for graduate students. The developments are published through a set of peer-reviewed journal and conference papers in top venues. The project also provided supports to a graduate student to obtain a PhD degree of mathematics with focus on the aforementioned fields.</p><br>\n<p>\n Last Modified: 04/11/2025<br>\nModified by: Xiaojing&nbsp;Ye</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project aims at constructing a comprehensive framework of computational methods to handle problems with large amount of data sets collected in various acquisition settings, different formats, and diverse sources in real-world applications. The issue of high data heterogeneity has posed serious challenges in many aspects of analysis, inference, and computation involving big data. In this project, the PI and his collaborators developed a series of novel modeling and computational methods, including highly structured deep neural networks and novel training algorithms, to effectively resolve these challenges. Results of this project provide powerful computational tools to solve problems in a broad range of important fields involving large heterogenous data sets, such as signal/image processing, computer vision, and machine learning.\r\n\n\n\r\n\n\nThe research in this project made several major contributions: (1) Development of learnable optimization algorithms (LOAs). LOAs induce highly efficient schemes for solving non-convex and non-smooth inverse problems which are prevalent in modern computational science and data-driven applications. By effectively integrating residual learning architectures into descent-type algorithms, LOAs not only have outstanding efficiency compared to the existing methods in numerous empirical tests, but are also proved to have convergence guarantee using rigorous mathematical analysis; (2) Development of novel training strategies based on bi-level optimization to learn the parameters of LOAs, which can explore the underlying common features across a variety of tasks in heterogeneous data sets as well as the task-specific features; (3) Development of efficient methods to solve bi-level optimization problems of parameter training with comprehensive computation and sampling complexity analysis. These methods are also applicable to similar parameter learning problems that are prevalent in other application domains; and (4) Discovery of novel nonlinear reduced-order model (ROM) approach to tackle computational problems defined on infinite-dimensional function spaces. The new approach establishes deep connections between the finite-dimensional parameters of ROMs and the corresponding functions and provide insights and new computational techniques to solve relevant problems such as Wasserstein gradient and Hamiltonian flows in high dimension. The idea has been revolutionized to address more challenging operator learning problems, for example, to directly approximate mappings from initial values to the corresponding solutions of high-dimensional evolution PDEs with self-generated and adaptive data sampling strategies.\r\n\n\n\r\n\n\nIn summary, the algorithms developed in this project effectively integrate deep neural network architectures into customized numerical schemes with comprehensive mathematical theory. The new methods can be used to solve a broad range of inverse problems which are prevalent in signal/image processing, machine learning, computer vision, optimal control, among many others. The results benefit both research and industry communities. The research findings have been integrated into the education program at the PIs institution via new course entitled Mathematical Foundations of Deep Learning for graduate students. The developments are published through a set of peer-reviewed journal and conference papers in top venues. The project also provided supports to a graduate student to obtain a PhD degree of mathematics with focus on the aforementioned fields.\t\t\t\t\tLast Modified: 04/11/2025\n\n\t\t\t\t\tSubmitted by: XiaojingYe\n"
 }
}