{
 "awd_id": "2153546",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: III: Robust and Explainable AI Agents with Common Sense",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2022-05-01",
 "awd_exp_date": "2024-04-30",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2022-03-15",
 "awd_max_amd_letter_date": "2022-03-15",
 "awd_abstract_narration": "This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2). \r\n\r\nThis project will gain an understanding of how to create Artificial Intelligence (AI) agents that provide commonsense explanations about real-world narratives. Current AI agents lack commonsense mechanisms to explain their judgment of everyday stories and they cannot be applied to novel scenarios. This award will enable AI agents to reason in novel situations and to explain their decisions. The project will focus on two key aspects of stories: understanding situations and judging the adequacy of actions in context. The project will test the ability of AI agents to complete narratives and to provide commonsense explanations on the task of explainable natural language inference. The explainability of AI agents can be expected to improve public trust in AI technologies. Robust and explainable AI with common sense is also critically missing in social AI assistants that aim to increase the participation of children with Autism Spectrum Disorder and the elderly with Alzheimer's dementia. The investigator will design a new set of lectures and a full course on the topic of \u201cAI assistants with common sense\u201d, which will be taught both at USC as well as internationally. Interdisciplinary research will be facilitated via summer internships, and participation in the existing University of Southern California (USC) Center for Knowledge-Powered Interdisciplinary Data Science and NSF Research Experiences for Undergraduates programs. The investigator will partner with USC's Center for Engineering Diversity and Women in Science and Engineering, in order to recruit members of historically underrepresented groups for research on this project. The investigator will partner with USC's K-12 STEM Center to engage K-12 students from historically underrepresented groups.\r\n\r\n\r\nThis award will create a paradigm shift in the development of AI agents, by combining advances in neural language modeling with high-level explanations based on logical axioms and commonsense knowledge. State-of-the-art technology is not adequate for this goal: neural methods cannot infer causal links between events and the motivations and goals of the agents directly from narratives, whereas commonsense axioms and knowledge resources alone cannot handle the contextual variations in human language. The team of researchers will build AI agents that use common sense to explain their reasoning. To do so, the researchers will leverage commonsense knowledge and axioms about agent psychology and event causality in order to enrich story corpora. The enriched data will be used to pre-train neuro-symbolic agents to complete open-world narratives and justify their completion with commonsense explanations. The researchers will measure the impact of representative techniques, axiomatic theories, and knowledge dimensions on understanding narratives about situations and actions.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Filip",
   "pi_last_name": "Ilievski",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Filip Ilievski",
   "pi_email_addr": "ilievski@isi.edu",
   "nsf_id": "000863822",
   "pi_start_date": "2022-03-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "4676 Admiralty Way Suite 1001",
  "perf_city_name": "Marina del Rey",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "902926611",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "102Z",
   "pgm_ref_txt": "COVID-Disproportionate Impcts Inst-Indiv"
  },
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "010V2122DB",
   "fund_name": "R&RA ARP Act DEFC V",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of the project was to&nbsp;gain an understanding of how to create robust and explainable AI agents that provide commonsense explanations about open-world narratives. Humans are perpetual storytellers, so narratives are found in many places and in multiple modalities. The premise of this project was that models struggle with understanding narratives from the perspective of commonsense reasoning and abstraction, and have limitations in terms of robustness and explainability.</p>\n<p>To address these concerns, this project developed two benchmarks: ARN for analogical reasoning in narratives, and MARVEL for abstract visual reasoning. We developed novel methods with focus on robustness and explainability, using techniques like case-based reasoning, prototype-based networks, and data augmentation with knowledge graphs and language models. We, finally, performed systematic studies to measure the fundamental strenghts and weaknesses of models. The work on this project was inspired by theories in cognitive science, linguistics, and philosophy, thus providing a natural bridge to other disciplines.&nbsp;</p>\n<p>The results from this project were published in prestigious journals and presented at top-tier conferences. We organized two workshops on analogical reasoning and neuro-symbolic AI (at ESWC and IJCAI), one tutorial on generalizable commonsense reasoning (at AAAI), and led a seminar at Dagstuhl on generalization by humans and machines. These activities led to additional publications, above all, an invited book for Springer Nature on human-centric AI with common sense. The PI and the graduate students supported by this project gave invited talks and guest lectures on the topics of commonsense reasoning, analogical abstraction, and narrative understanding. The results were also incorporated into educational materials for courses taught by the PI, such as Building Knowledge Graphs and Conversational AI.</p>\n<p>The project contributed to the human resource development of the PI and three graduate students. Each of the papers published or submitted with support by this project was led by one of these students, and most of the papers involved intensive collaboration between them, in some cases also with other groups in Germany, the Netherlands, and Switzerland.</p><br>\n<p>\n Last Modified: 07/30/2024<br>\nModified by: Filip&nbsp;Ilievski</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2153546/2153546_10789558_1722346082516_leap--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2153546/2153546_10789558_1722346082516_leap--rgov-800width.png\" title=\"LEAP\"><img src=\"/por/images/Reports/POR/2024/2153546/2153546_10789558_1722346082516_leap--rgov-66x44.png\" alt=\"LEAP\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The LEAP framework for transferring of procedural knowledge from a source task  through zero-shot evaluation on unseen tasks.</div>\n<div class=\"imageCredit\">Jiang et al. (2023)</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Filip&nbsp;Ilievski\n<div class=\"imageTitle\">LEAP</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2024/2153546/2153546_10789558_1722346217105_analogical_reasoning.drawio_2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2153546/2153546_10789558_1722346217105_analogical_reasoning.drawio_2--rgov-800width.png\" title=\"ARN\"><img src=\"/por/images/Reports/POR/2024/2153546/2153546_10789558_1722346217105_analogical_reasoning.drawio_2--rgov-66x44.png\" alt=\"ARN\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Example entry from the ARN benchmark, showing a query story (Q), an analogical match (A), and a distractor story (N).</div>\n<div class=\"imageCredit\">Sourati et al., (2024)</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Filip&nbsp;Ilievski\n<div class=\"imageTitle\">ARN</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe goal of the project was togain an understanding of how to create robust and explainable AI agents that provide commonsense explanations about open-world narratives. Humans are perpetual storytellers, so narratives are found in many places and in multiple modalities. The premise of this project was that models struggle with understanding narratives from the perspective of commonsense reasoning and abstraction, and have limitations in terms of robustness and explainability.\n\n\nTo address these concerns, this project developed two benchmarks: ARN for analogical reasoning in narratives, and MARVEL for abstract visual reasoning. We developed novel methods with focus on robustness and explainability, using techniques like case-based reasoning, prototype-based networks, and data augmentation with knowledge graphs and language models. We, finally, performed systematic studies to measure the fundamental strenghts and weaknesses of models. The work on this project was inspired by theories in cognitive science, linguistics, and philosophy, thus providing a natural bridge to other disciplines.\n\n\nThe results from this project were published in prestigious journals and presented at top-tier conferences. We organized two workshops on analogical reasoning and neuro-symbolic AI (at ESWC and IJCAI), one tutorial on generalizable commonsense reasoning (at AAAI), and led a seminar at Dagstuhl on generalization by humans and machines. These activities led to additional publications, above all, an invited book for Springer Nature on human-centric AI with common sense. The PI and the graduate students supported by this project gave invited talks and guest lectures on the topics of commonsense reasoning, analogical abstraction, and narrative understanding. The results were also incorporated into educational materials for courses taught by the PI, such as Building Knowledge Graphs and Conversational AI.\n\n\nThe project contributed to the human resource development of the PI and three graduate students. Each of the papers published or submitted with support by this project was led by one of these students, and most of the papers involved intensive collaboration between them, in some cases also with other groups in Germany, the Netherlands, and Switzerland.\t\t\t\t\tLast Modified: 07/30/2024\n\n\t\t\t\t\tSubmitted by: FilipIlievski\n"
 }
}