{
 "awd_id": "2143730",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Visual Manipulation Learning for Challenging Object Grasping",
 "cfda_num": "47.041, 47.070",
 "org_code": "05020000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2022-06-01",
 "awd_exp_date": "2027-05-31",
 "tot_intn_awd_amt": 538863.0,
 "awd_amount": 538863.0,
 "awd_min_amd_letter_date": "2022-03-16",
 "awd_max_amd_letter_date": "2023-03-27",
 "awd_abstract_narration": "This Faculty Early Career Development (CAREER) project seeks to significantly enhance the capabilities of robotic systems to grasp objects. Object grasping is an important prerequisite for various manipulation tasks. Humans are capable of grasping diverse objects dexterously even if their workspaces are cluttered. When an object is in a constrained space, such as a cardboard box or a shelf, humans often take advantage of the constraint by pushing the object toward a wall or a corner to grasp it. Even if a targeted object is hidden in a pile of objects, humans actively search for it by removing the clutter objects. While object grasping in such challenging scenarios seems effortless and natural for humans, current robots are still grasping objects in moderately cluttered tabletop environments. This project will develop computational algorithms to allow robots to perform such challenging object grasping. This project has the potential to broaden the application domains of robotic manipulation, such as flexible manufacturing (e.g., supporting human worker by providing right parts), agriculture (e.g., automated fruit and vegetable harvesting), warehouse fulfillment centers or grocery shopping (e.g., pick-and-place ordered items in shelves or bins), and eldercare (e.g., fetching a remote controller or pills), which have not been feasible with current robotic labor.\r\n\r\nThe objective of this project is to develop novel computational algorithms that enable robots to visually understand scenes, learn to perform a proper manipulation action sequence, and adapt to different environmental settings. This project will address three fundamental challenges in robotic object grasping: (1) context-aware object grasping -- considering spatial contexts related to grasping, such as clutteredness, reachability, and collision, (2) object grasping via leveraging fixtures -- making use of environmental fixtures to grasp challenging objects by learning pixel-level or object-level affordances, and (3) object searching and grasping -- searching and grasping a hidden target object queried by either a reference image or a human natural language. All the algorithms and systems are designed to be self-supervised, meaning that they can learn and adapt to novel objects, environments, and tasks with minimal human interventions or guidance. This project will lay a solid foundation for the affordable and reliable robotic labor beneficial to the broad areas of our society, such as homes, factories, farms, warehouses, and eldercare facilities.\r\n\r\nThis project is supported by the cross-directorate Foundational Research in Robotics program, jointly managed and funded by the Directorates for Engineering (ENG) and Computer and Information Science and Engineering (CISE).\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Changhyun",
   "pi_last_name": "Choi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Changhyun Choi",
   "pi_email_addr": "cchoi@umn.edu",
   "nsf_id": "000785161",
   "pi_start_date": "2022-03-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "University of Minnesota-Twin Cities",
  "perf_str_addr": "200 Union St. SE, Keller Hall",
  "perf_city_name": "Minneapolis",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "554550170",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MN05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 413863.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 125000.0
  }
 ],
 "por": null
}