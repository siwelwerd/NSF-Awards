{
 "awd_id": "2204528",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Human-centered Robot Manipulation Planning for Solving Object Handover Tasks in the Real-World",
 "cfda_num": "47.041, 47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2022-09-01",
 "awd_exp_date": "2025-08-31",
 "tot_intn_awd_amt": 389468.0,
 "awd_amount": 389468.0,
 "awd_min_amd_letter_date": "2022-08-16",
 "awd_max_amd_letter_date": "2022-08-16",
 "awd_abstract_narration": "Robots aiming to assist people in their daily lives need to have robust skills in handing over arbitrary, unknown objects to and from their interacting partners in various environments. Older people, especially those with a disability, often have difficulty maneuvering and need assistance even for minor chores such as handing over the TV remote, fetching water bottles, and other items such as medicines. This need for assistance has become even clearer from the COVID-19 outbreak, requiring collaborative robots with object handover skills to keep the affected person and their caretakers at a safe distance. Similarly, such robot abilities in factories can significantly improve work efficiency by handing over various tools to and from their collaborating workers. However, despite the significance of having robots with object handover skills, such a fundamental task remains unsolved. This proposal presents a framework to solve the human-robot handover tasks with arbitrary daily-life objects in uncontrolled environments and explicitly considers the most-used items by patients with motor impairments such as Amyotrophic Lateral Sclerosis.\r\n\r\nThe technical contributions of this proposal are divided into three research thrusts. First, a novel task-aware, 3D pose forecasting approach will be introduced to predict future poses of the full human body and their handheld objects from raw sensory information. During inference, various human body parts that are crucial for robot decision-making and control in solving human-robot object handover tasks will also be highlighted through learning-based attention models. Second, the proposal will formalize, represent, and learn the task-specific physical human-object and object-object interactions to predict socially feasible target object poses for handovers concerning the expected human behaviors and robot\u2019s kinematic reachability during manipulation. Third, the predicted human behaviors and desired object handover poses will be used to determine human-friendly robot grasp and generate informed human-aware robot motion sequences. Finally, the proposed research thrusts will be integrated into a unified framework to solve human-to-robot and robot-to-human handover tasks with arbitrarily unknown objects from raw visual observations. The proposal\u2019s outcomes will also exhibit new, proof-of-concept, human-robot handover demonstrations in the real-world using various most-used items by people with motor impairments.\r\n\r\nThis project is supported by the cross-directorate Foundational Research in Robotics program, jointly managed and funded by the Directorates for Engineering (ENG) and Computer and Information Science and Engineering (CISE).\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ahmed",
   "pi_last_name": "Qureshi",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Ahmed H Qureshi",
   "pi_email_addr": "qureshi7@purdue.edu",
   "nsf_id": "000864599",
   "pi_start_date": "2022-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "305 N. University Street",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072107",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 389468.0
  }
 ],
 "por": null
}