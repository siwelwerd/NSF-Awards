{
 "awd_id": "2223292",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI:Small:Exploring Efficient Bayesian Model-Augmentation Techniques for Decomposible Contrastive Representation Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2022-09-01",
 "awd_exp_date": "2025-08-31",
 "tot_intn_awd_amt": 415709.0,
 "awd_amount": 415709.0,
 "awd_min_amd_letter_date": "2022-08-23",
 "awd_max_amd_letter_date": "2022-08-23",
 "awd_abstract_narration": "Modern deep learning models that trains large on web-scale data with a heavy computational load are achieving state-of-the-art performance on many real-world problems. The ability to learning good representations from the large-scale unlabeled data is the key to the success. Although many methods have been developed, their underlying properties and limitations are still not well understood. Contrastive Representation Learning (CRL) is a method of learning to represent the data such that similar data are close to each other while dissimilar data are far apart. This project investigates the limitations of CRL in order to make it more scalable to big data and be appropriately applied to real-world problems such as computer vision. The project will also support the continued development of machine-learning related courses for undergraduate and graduate students at University at Buffalo as well as various outreach activities to expose K-12 students to the field of computer science.\r\n\r\nThis research develops a scalable conditional decomposable contrastive learning framework from the Bayesian principle and extend it to the federated learning and multi-model learning. First, an augmentation technique will be applied to decouple the entanglement of positive-negative samples, leading to a conditional decomposable loss that can be optimized with unbiased stochastic gradients. Second, the technique will be further refined to develop a communication-efficient distributed training framework for CRL, where clients no longer need to explicitly communicate with other clients to fetch other negative samples. Third, the improved CRL technique will be further applied to the emerging field of foundation models for vision-and-language modeling. The project will also result in the dissemination of shared data and benchmarks to the broader AI community, for example through Github, presentation and workshop organization.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Changyou",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Changyou Chen",
   "pi_email_addr": "changyou@buffalo.edu",
   "nsf_id": "000764296",
   "pi_start_date": "2022-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Buffalo",
  "inst_street_address": "520 LEE ENTRANCE STE 211",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "7166452634",
  "inst_zip_code": "142282577",
  "inst_country_name": "United States",
  "cong_dist_code": "26",
  "st_cong_dist_code": "NY26",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "GMZUKXFDJMA9",
  "org_uei_num": "LMCJKRFW5R81"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Buffalo",
  "perf_str_addr": "520 LEE ENTRANCE STE 211",
  "perf_city_name": "AMHERST",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "142282577",
  "perf_ctry_code": "US",
  "perf_cong_dist": "26",
  "perf_st_cong_dist": "NY26",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 415709.0
  }
 ],
 "por": null
}