{
 "awd_id": "2217878",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAPA: Collaborative Research: ARION: Taming Heterogeneity with DSLs, Approximation, and Synthesis",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2023-11-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 129614.0,
 "awd_min_amd_letter_date": "2022-03-31",
 "awd_max_amd_letter_date": "2022-03-31",
 "awd_abstract_narration": "Specialization and the arrival of new technologies are key forces motivating heterogeneous systems. Heterogeneity is already in use widely, with public clouds offering instances that are heterogeneous in both compute capabilities and storage. This project identifies the following forces that will make systems heterogeneous beyond just compute and storage, complicating programming and compilation beyond the challenges that we face today. This project develops Arion, a system for compiling programs onto heterogeneous platforms based on several unifying ideas. The Arion system will be evaluated on practically relevant workloads ranging from computer vision and virtual reality, to graph computations, machine learning and stream processing. The investigators will work with partners in industry to transfer research results to products, and the tools and software developed by this project will be released as open source.\r\n\r\nThe research in this project relies on four unifying ideas. The first thrust explores schedules and type systems separate a program's specification from its implementation strategy, enabling performance portability because one can select, without changing the program, its parallelism, locality, and hardware mapping. The second thrust uses domain-specific languages to describe not only programs but also artifacts used during compilation, such as schedules, resource-, and memory consistency models. This allows automatic synthesis of these artifacts. The third thrust uses resource models to bring scheduling and synthesis to large programs because the target program need not be scheduled or synthesized all at once. Instead, the compiler makes high-level decisions by estimating performance using a model before committing to low-level decisions. Finally, the investigators will use formal methods to lift programs into, and verify and synthesize programs in our DSLs, providing a high degree of automation. The verifiers and synthesizers are automatically generated from descriptions of DSLs.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jonathan",
   "pi_last_name": "Ragan-Kelley",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jonathan M Ragan-Kelley",
   "pi_email_addr": "jrk@mit.edu",
   "nsf_id": "000738655",
   "pi_start_date": "2022-03-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Ave",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "021Z",
   "pgm_ref_txt": "Industry Partnerships"
  },
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "2878",
   "pgm_ref_txt": "SPECIAL PROJECTS - CCF"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "8206",
   "pgm_ref_txt": "Formal Methods and Verification"
  },
  {
   "pgm_ref_code": "8585",
   "pgm_ref_txt": "NSF/Intel Partnership Projects"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 69615.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 59999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In the twilight of Moore's Law, computer hardware has diverged from the programming models we use to control it. From CPUs to GPUs to specialized accelerators, the fundamental physics of modern devices has led to a proliferation of complex, specialized hardware. Traditional programming languages can be adapted to target this new hardware, but they require programs be restructured to map to specific hardware. As a result, when performance matters, traditional programming models no longer provide a useful abstraction of the hardware -- key to productive programming, automatic compiler optimization, and portability across hardware. Without this, we are doomed to a future where improvements in computation no longer serve all people and applications, but instead are only accessible to the handful of programs which can be painstakingly hand-optimized to specific hardware.</p>\n<p>This project has developed an array of new programming tools and techniques to address this problem. It builds first on the concept of domain-specific languages (DSLs), which capture higher-level application structure than traditional programming languages, and so are far better able to target specialized hardware. Second, it develops and applies techniques of program synthesis, which automatically search for programs to solve a given task. Third, it exploits machine learning both to guide synthesis by predicting what choices will be effective, and to automatically tune the parameters of programs.</p>\n<p>Focusing on performance-critical applications in visual computing and machine learning, key developments include:</p>\n<ul>\n<li><span style=\"font-size: 12px;\">\"Automatic differentiation\" techniques to enable machine learning to automatically tune the parameters of traditional programs, providing faster, higher quality image processing, 3D rendering, and physics simulation</span><span style=\"font-size: 12px;\">;</span></li>\n<li><span style=\"font-size: 12px;\">New AI algorithms to automatically optimize image processing and machine learning programs for CPUs and GPUs, delivering higher performance than any prior techniques;</span></li>\n<li><span style=\"font-size: 12px;\">A new DSL for fast computation on sparse data that naturally emerges in many physics simulations and machine learning models;</span></li>\n<li><span style=\"font-size: 12px;\">A new program synthesizer, which automatically translated decades-old image processing code in Adobe Photoshop to high-level DSL code that is faster and portable to new architectures like ARM processors and GPUs.</span></li>\n</ul>\n<p>All of the resulting work has been released as open source, many of them are now in use for major commercial products in industry (like Adobe Photoshop), and one has spawned a new startup.</p><br>\n<p>\n Last Modified: 04/09/2024<br>\nModified by: Jonathan&nbsp;M&nbsp;Ragan-Kelley</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn the twilight of Moore's Law, computer hardware has diverged from the programming models we use to control it. From CPUs to GPUs to specialized accelerators, the fundamental physics of modern devices has led to a proliferation of complex, specialized hardware. Traditional programming languages can be adapted to target this new hardware, but they require programs be restructured to map to specific hardware. As a result, when performance matters, traditional programming models no longer provide a useful abstraction of the hardware -- key to productive programming, automatic compiler optimization, and portability across hardware. Without this, we are doomed to a future where improvements in computation no longer serve all people and applications, but instead are only accessible to the handful of programs which can be painstakingly hand-optimized to specific hardware.\n\n\nThis project has developed an array of new programming tools and techniques to address this problem. It builds first on the concept of domain-specific languages (DSLs), which capture higher-level application structure than traditional programming languages, and so are far better able to target specialized hardware. Second, it develops and applies techniques of program synthesis, which automatically search for programs to solve a given task. Third, it exploits machine learning both to guide synthesis by predicting what choices will be effective, and to automatically tune the parameters of programs.\n\n\nFocusing on performance-critical applications in visual computing and machine learning, key developments include:\n\n\"Automatic differentiation\" techniques to enable machine learning to automatically tune the parameters of traditional programs, providing faster, higher quality image processing, 3D rendering, and physics simulation;\nNew AI algorithms to automatically optimize image processing and machine learning programs for CPUs and GPUs, delivering higher performance than any prior techniques;\nA new DSL for fast computation on sparse data that naturally emerges in many physics simulations and machine learning models;\nA new program synthesizer, which automatically translated decades-old image processing code in Adobe Photoshop to high-level DSL code that is faster and portable to new architectures like ARM processors and GPUs.\n\n\n\nAll of the resulting work has been released as open source, many of them are now in use for major commercial products in industry (like Adobe Photoshop), and one has spawned a new startup.\t\t\t\t\tLast Modified: 04/09/2024\n\n\t\t\t\t\tSubmitted by: JonathanMRagan-Kelley\n"
 }
}