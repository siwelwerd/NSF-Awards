{
 "awd_id": "2220876",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: Integrating Perception and Manipulation of Deformable Objects by Learning Implicit Representations",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2022-09-01",
 "awd_exp_date": "2026-08-31",
 "tot_intn_awd_amt": 749653.0,
 "awd_amount": 749653.0,
 "awd_min_amd_letter_date": "2022-08-25",
 "awd_max_amd_letter_date": "2022-08-25",
 "awd_abstract_narration": "The goal of this National Robotics Initiative 3.0 project is to develop models and algorithms that enable autonomous robotic manipulation of deformable objects by integrating sight and touch for contact-rich interactions. Manipulation of deformable objects is essential in many day-to-day tasks ranging from cooking (e.g., using a compliant spatula to scrape a wok) to manufacturing (e.g., assembly tasks involving flexible parts and materials such as composites and cables). These tasks require the robot to perform complex maneuvers to bring deformable objects into contact and apply forces to bend and shape them to achieve tasks. Recent advances in collaborative robots (e.g., the Franka Emika Panda and Kuka LBR iiwa robots) have made robotic manipulation of deformable objects physically possible but robots still lack the models and algorithms necessary to perform practical tasks such as cooking, cleaning, and flexible manufacturing. This project will have broad societal impact through its applications in in-home assistive and manufacturing robotics. The ability to robustly manipulate deformable structures is an important precursor technology towards realizing intelligent robotic assistants. Robotics and their assistive applications have the potential to inspire children to pursue careers in STEM fields and meet the needs of America's growing assistive and manufacturing robotics industry. Integration of the research activities with education will emphasize actively involving undergraduates in research activities and introducing new lecture material and projects into undergraduate and graduate courses. Also, special emphasis will be given to recruit qualified students from under-represented groups.\r\n\r\nThis project will develop integrated methods for perception and manipulation of elastically deformable objects via novel implicit function representations. Elastic objects are ubiquitous in people's lives, from spatulas and sponges in the kitchens to elastic rods on manufacturing floors to surgical tools and tissue. Their manipulation is an essential skill for practical robotic systems. The proposed integrative approach brings together methods from computer vision and robotics to address the need for seamless visio-tactile reasoning and acting that is essential for robotics applications. Specifically, this approach integrates and extends recent theoretical and computational advances in implicit function learning to model, perceive, and intelligently manipulate elastic objects. Implicit representations of 3D geometries have recently gained traction in computer vision owing to their compactness and computational efficiency; however, they have yet to be deployed successfully for robotics. Towards their successful integration, the outcomes of this project are: 1) A generalization of implicit function theory and algorithms for 3D visio-tactile deformable object representations. This addresses the need for dynamic and multi-modal deformable object representations particularly suited for robotics; specially to streamline the sense-reason-act pipeline. 2) Algorithmic tools for implicit state-estimation. These algorithms will bridge inherently uncertain robotic sensing modalities with implicit representations. 3) Theoretic and algorithmic foundations for implicit control and planning. The resulting tools from this project will enable real-time closed-loop control of deformable objects for practical robotic systems. For evaluation, this project will explore the integration of these algorithms for assistive robotics (food preparation) and warehouse logistics (dense packing). The research outcomes contribute to several related fields including continuum mechanics, computer vision, and learning theory where object deformations subject to boundary conditions and/or implicit function theory are studied. In particular, this approach will offer a flexible, generalizable, and computationally efficient alternative to the current state-of-the-art methods using finite element analysis or particle models.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nima",
   "pi_last_name": "Fazeli",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nima Fazeli",
   "pi_email_addr": "nfz@umich.edu",
   "nsf_id": "000821989",
   "pi_start_date": "2022-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Dmitry",
   "pi_last_name": "Berenson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dmitry Berenson",
   "pi_email_addr": "berenson@eecs.umich.edu",
   "nsf_id": "000231987",
   "pi_start_date": "2022-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "Regents of the University of Michigan - Ann Arbor",
  "perf_str_addr": "3003 South State St. Room 1062",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091274",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 749653.0
  }
 ],
 "por": null
}