{
 "awd_id": "2136669",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  AI-assisted software for fast labeling of medical tomographic images",
 "cfda_num": "47.041, 47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2022-02-15",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 255807.0,
 "awd_amount": 255807.0,
 "awd_min_amd_letter_date": "2022-02-09",
 "awd_max_amd_letter_date": "2022-02-09",
 "awd_abstract_narration": "The broader impact of this Small Business Innovation Research (SBIR) Phase I project is to extract new valuable information from medical images, accelerate image interpretation by radiologists, and improve patient outcomes. The process of identifying key features in images, known as ``labeling'', is the key to improved diagnosis and management of certain conditions.  The innovations proposed here will substantially lower the cost of labeled datasets, enabling access for developers of artificial intelligence (AI) algorithms and improving the use of AI in health care. \r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project will apply machine learning algorithms to develop a system for assisting in manual labeling of medical tomographic images. The proposed research will result in an adaptive system architecture that evolves to accelerate labeling and increase the volume of labeled data. Moreover, the research will increase labeling accuracy at the edges of anatomical structures. For instance, surgical resections for cancer treatment requires accurate labeling of the edges of abnormal tissue to ensure clean margins and minimal recurrence. Similarly, radiation therapy planning requires accurate labeling of the edges of organs at risk for safety and favorable outcomes. Due to its clinical importance, accurate manual labeling of ambiguities and sophisticated shapes is highly time-consuming. The proposed approach is differentiated from current methods by the inclusion of an additional subsystem for increasing the accuracy of edge labeling.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sergey",
   "pi_last_name": "Anishchenko",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sergey Anishchenko",
   "pi_email_addr": "as@alienbyte.us",
   "nsf_id": "000856773",
   "pi_start_date": "2022-02-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "ALIENBYTE SCIENTIFIC SOFTWARE INC",
  "inst_street_address": "12156 PARKLAWN DR",
  "inst_street_address_2": "STE A",
  "inst_city_name": "ROCKVILLE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "2404266021",
  "inst_zip_code": "208521708",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "MD08",
  "org_lgl_bus_name": "ALIENBYTE SCIENTIFIC SOFTWARE INC",
  "org_prnt_uei_num": "",
  "org_uei_num": "MQ2SS1Z33878"
 },
 "perf_inst": {
  "perf_inst_name": "ALIENBYTE SCIENTIFIC SOFTWARE INC",
  "perf_str_addr": "12156 Parklawn Drive",
  "perf_city_name": "Rockville",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "208521708",
  "perf_ctry_code": "US",
  "perf_cong_dist": "08",
  "perf_st_cong_dist": "MD08",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 255807.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-20656707-7fff-842e-e755-ef8358627b41\" style=\"line-height: 1.295; text-indent: 18pt; margin-top: 0pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Calibri,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Manual labeling of medical images is essential for data analysis or training Artificial Intelligence (AI). Labeling of 3D tomographic images is extremely time consuming and expensive.</span></p>\n<p style=\"line-height: 1.295; text-indent: 18pt; margin-top: 0pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Calibri,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">In this project we have developed Bru(TM), a web application for assisting manual labeling of medical tomographic images. Bru<span style=\"font-size: 11pt; font-family: Calibri,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(TM)</span> utilizes AI and other algorithms to speed up labeling, thus </span><span style=\"font-size: 11pt; font-family: Calibri,sans-serif; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">lowering the cost of labeled datasets</span><span style=\"font-size: 11pt; font-family: Calibri,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span></p>\n<p style=\"line-height: 1.295; text-indent: 18pt; margin-top: 0pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Calibri,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">We developed AI models and training/retraining strategies to enable and constantly improve automatic assistance in labeling regardless of region of interest (ROI) and imaging modalities.</span></p>\n<p style=\"line-height: 1.295; text-indent: 18pt; margin-top: 0pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Calibri,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">When a user starts labeling, only a small data set is available for training AI. We have demonstrated that AI models may be reliably trained on carefully preprocessed small datasets. Due to this innovation Bru? can offer assistance starting at the earliest stages of labeling.</span></p>\n<p style=\"line-height: 1.295; text-indent: 18pt; margin-top: 0pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Calibri,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">For constant improvement of assistance quality during labeling, we developed a system for the automatic orchestration of AI training/retraining. Hence, users are not required to have technical skills or experience in AI to use Bru<span style=\"font-size: 11pt; font-family: Calibri,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(TM)</span>.</span></p>\n<p style=\"line-height: 1.295; text-indent: 18pt; margin-top: 0pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Calibri,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">We also developed diverse AI models for reliable assistance in labeling, despite the variety in appearance of ROIs.</span></p>\n<p style=\"line-height: 1.295; text-indent: 18pt; margin-top: 0pt; margin-bottom: 8pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Calibri,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Finally, we developed an approach for coarse to fine labeling. It allows for precise automatic labeling of&nbsp; ROI edges where manual labeling is very challenging due to ambiguity and necessity for fine movement of the mouse cursor.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/14/2022<br>\n\t\t\t\t\tModified by: Sergey&nbsp;Anishchenko</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/2136669/2136669_10784461_1665778604659_user-interface-dei--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/2136669/2136669_10784461_1665778604659_user-interface-dei--rgov-800width.jpg\" title=\"Bru(TM) web user interface\"><img src=\"/por/images/Reports/POR/2022/2136669/2136669_10784461_1665778604659_user-interface-dei--rgov-66x44.jpg\" alt=\"Bru(TM) web user interface\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Web user interface showing labeled bones in a CT of an equine hock joint</div>\n<div class=\"imageCredit\">Alienbyte Inc.</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Sergey&nbsp;Anishchenko</div>\n<div class=\"imageTitle\">Bru(TM) web user interface</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/2136669/2136669_10784461_1665779178815_50-p--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/2136669/2136669_10784461_1665779178815_50-p--rgov-800width.jpg\" title=\"Labels predicted by AI\"><img src=\"/por/images/Reports/POR/2022/2136669/2136669_10784461_1665779178815_50-p--rgov-66x44.jpg\" alt=\"Labels predicted by AI\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Labels of medial sesamoid bone predicted by AI trained on 500 samples</div>\n<div class=\"imageCredit\">Alienbyte Inc.</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Sergey&nbsp;Anishchenko</div>\n<div class=\"imageTitle\">Labels predicted by AI</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "Manual labeling of medical images is essential for data analysis or training Artificial Intelligence (AI). Labeling of 3D tomographic images is extremely time consuming and expensive.\nIn this project we have developed Bru(TM), a web application for assisting manual labeling of medical tomographic images. Bru(TM) utilizes AI and other algorithms to speed up labeling, thus lowering the cost of labeled datasets.\nWe developed AI models and training/retraining strategies to enable and constantly improve automatic assistance in labeling regardless of region of interest (ROI) and imaging modalities.\nWhen a user starts labeling, only a small data set is available for training AI. We have demonstrated that AI models may be reliably trained on carefully preprocessed small datasets. Due to this innovation Bru? can offer assistance starting at the earliest stages of labeling.\nFor constant improvement of assistance quality during labeling, we developed a system for the automatic orchestration of AI training/retraining. Hence, users are not required to have technical skills or experience in AI to use Bru(TM).\nWe also developed diverse AI models for reliable assistance in labeling, despite the variety in appearance of ROIs.\nFinally, we developed an approach for coarse to fine labeling. It allows for precise automatic labeling of  ROI edges where manual labeling is very challenging due to ambiguity and necessity for fine movement of the mouse cursor.\n\n\t\t\t\t\tLast Modified: 10/14/2022\n\n\t\t\t\t\tSubmitted by: Sergey Anishchenko"
 }
}