{
 "awd_id": "2224246",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Building a rich and rigorous theory of decision tree learning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922095",
 "po_email": "kwimmer@nsf.gov",
 "po_sign_block_name": "Karl Wimmer",
 "awd_eff_date": "2022-10-01",
 "awd_exp_date": "2025-09-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2022-07-21",
 "awd_max_amd_letter_date": "2022-07-21",
 "awd_abstract_narration": "Decision trees are logical flowcharts that specify how responses to a sequence of questions can be amalgamated into a single global decision.  Decision trees are one of the most natural ways of representing decision-making processes and they pervade everyday life.  For example, a loan approval decision can reasonably be modeled as a decision tree that amalgamates various information about the applicant --- for example, \"What is their annual income?\";  \"Have they defaulted on a loan in the past 5 years?\"; etc. --- into a single global decision, whether the loan is approved or denied.  Decision trees are also very basic objects of study throughout computer science and they play an increasingly important role in machine learning (ML).  A central problem here, well studied since the 1970s, is that of decision tree learning: the algorithmic task of efficiently building a decision tree that represents a dataset.  For example, given a dataset of applicants who had approved or denied loans, the task would be to build a decision tree that explains these decisions.  In this project, the investigator will develop new algorithms for decision tree learning, as well as establish rigorous mathematical guarantees for existing decision tree learning algorithms that are widely used in practice.  An important educational goal of this project is to train undergraduates and graduate students through the process of research collaboration and mentorship, with a particular goal of building expertise in decision tree learning and the theory of machine learning more generally.  The investigator will also develop new curricular materials and maintain a tight feedback loop with experimental work and with ML practitioners. \r\n \r\nThe popularity and effectiveness of decision trees in machine learning, and throughout computer science more generally, stem from their simplicity.  They are extremely fast to evaluate, with evaluation time scaling with their depth, a quantity that is often exponentially smaller than their overall representation size.  Alongside other classics such as linear regression, k-means, k-nearest neighbors, and support vector machines, heuristics for learning decision trees are an essential topic in any introductory ML course, and they are part of the standard toolkit of every ML practitioner.  The logical and hierarchical structure of decision trees makes them easy to understand, and they are the most canonical example of an explainable model.  A recent survey lists decision tree learning as the very first of \"10 grand challenges\" for the emerging field of explainable ML.  Despite its empirical importance and success, many of the most basic theoretical questions regarding decision tree learning remain wide open.  The investigator and his students have been working on addressing this for the past couple of years, and this project is structured around two overarching goals that have emerged from their research: (i) Develop new decision tree learning algorithms that advance our fundamental understanding of the problem. (ii) Establish performance guarantees for standard decision tree learning heuristics used in practice and place their empirical success on a firm theoretical footing.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Li-Yang",
   "pi_last_name": "Tan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Li-Yang Tan",
   "pi_email_addr": "liyang@cs.stanford.edu",
   "nsf_id": "000703196",
   "pi_start_date": "2022-07-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "450 Jane Stanford Way",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943052004",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": null
}