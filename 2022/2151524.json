{
 "awd_id": "2151524",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "STTR Phase I: Virtual Interfaces using Multi-Protocol, Augmented-Reality Activation-Based Control Transfer",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922174",
 "po_email": "rmehta@nsf.gov",
 "po_sign_block_name": "Rajesh Mehta",
 "awd_eff_date": "2022-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 256000.0,
 "awd_amount": 256000.0,
 "awd_min_amd_letter_date": "2022-08-24",
 "awd_max_amd_letter_date": "2022-08-24",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Technology Transfer (STTR) Phase I project provides virtual interfaces that can be dynamically customized to address the challenge of user adoption in augmented reality (AR) products. This project overcomes previous limitations for AR such as the lack of interoperability, user-acceptance, scalability, and application-aware user intent recognition. While the AR market is projected to grow, wearable collaboration has unexplored potential. Users empowered by this project may be able to easily collaborate alongside skilled experts as well as robotic interfaces in the same medium. Through contextually-aware dynamic controls, manufacturing businesses can lower the risk of human-error while increasing fulfillment capabilities, as employees working from home can stay physically connected and remain engaged with minimal compromise. The AR innovation proposed in this project has application across multiple industries, including manufacturing, training, and emergency simulations.\r\n\r\nThis Small Business Technology Transfer (STTR) Phase I project aims to create a framework for scalable experimentation of virtual interfaces that empower users to search, tag, and store meaningful data using gesture interactions in a secure and private manner. This project seeks to provide context-based, hands-free interaction with wireless devices while minimizing the need to set up sensors (such as optical components or microphones) in controlled environments and providing visual feedback and accessibility to the end user. A wrist-worn wearable captures pre-trained gesture data, and a pair of augmented reality (AR) glasses identifies and analyzes an object within the context of said gestures to control a mechatronic device, such as a robot, to perform occupational tasks. This dynamic process uses factors such as the user\u2019s gaze area, physical location, and computer application.  The improvement upon gesture control may allow a separate visual unit, such as the AR glasses, to wirelessly receive and display the gesture intents and perform contextually-aware, meaningful interactions with a clear distinction across a plurality of devices or digitally tagged objects associated with a specific use-case.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dominick",
   "pi_last_name": "Lee",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Dominick S Lee",
   "pi_email_addr": "dlee@gyropalm.com",
   "nsf_id": "000825450",
   "pi_start_date": "2022-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Frederick",
   "pi_last_name": "Berry",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Frederick C Berry",
   "pi_email_addr": "berryf@purdue.edu",
   "nsf_id": "000744435",
   "pi_start_date": "2022-08-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "GYROPALM, LLC",
  "inst_street_address": "8000 EDGEWATER DR # 200",
  "inst_street_address_2": "",
  "inst_city_name": "OAKLAND",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5103203128",
  "inst_zip_code": "946212042",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "GYROPALM, LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "G96ZP9DPBB44"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "610 Purdue Mall",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "150500",
   "pgm_ele_name": "STTR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1654",
   "pgm_ref_txt": "HUMAN COMPUTER INTERFACE"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 256000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our NSF project titled Virtual Interfaces using Multi-Protocol Augmented-Reality Activation-based Control Transfer (VIMPAACT) has a primary objective to create a novel hands-free framework that expands the potential of augmented reality (AR) devices along with GyroPalm's gesture control to bolster safer and more efficient human collaboration with machines/robots in a remote environment. To achieve the ideal commercial and strategic offerings in human-robot collaboration, GyroPalm has seamlessly paired the Vuzix Blade 2 AR glasses with our own GyroPalm Encore wearable. This hybrid-architecture integration forms 'GyroPalm Spectrum', a complete industrial package featuring our groundbreaking VIMPAACT firmware. Spectrum allows professionals and enterprises to connect wirelessly to ROS-based robots from anywhere in the world, offering an adaptable and versatile system for more secure and optimized robotic operations.</p>\n<p>The Spectrum firmware comprises of an intelligent Android-compatible application and GyroPalm OS binary which is used to communicate with the VIMPAACT framework through JSON, secure websockets (WSS), WebRTC, and REST API. Our R&amp;D in Phase I was very successful! The proposed wireless protocol was established, which enables multiple Spectrum devices to control one or more robots, making them more contextually-aware of facility environments for dynamic control. With Spectrum, custom user-based interactions can be performed on the GyroPalm Encore while the AR glasses display relevant visuals from Intel Realsense cameras in proximity with robot(s).</p>\n<p>Computer vision algorithms were deployed that leveraged the Intel RealSense to not only obtain point clouds, but to locate both rounded and square objects, such as test tubes, packages, and blocks, and command a robotic arm running on ROS MoveIt to use inverse kinematics to locate and pick up the distinctly recognized object. Essentially, deliberate navigation gestures such as a combination of an activation snap and double-wave left or right, combined with a dynamic rules engine, would command the robot to either strategically sort or dispose of the selected object, all without requiring the operator's physical presence near the machine.</p>\n<p>While fiducial markers were used to calibrate and coordinate multiple 6-DOF industrial robot arms, the AI vision algorithms developed for the VIMPAACT project were instrumental in recognizing objects that do not have any QR or Aruco tag attached. VIMPAACT also encompasses a full networking pipeline that not only connects Spectrum wearables to Cloud, but also enables local ROS industrial machines to be securely accessible virtually anywhere in the world. By creating repeatable Performance, Measurement, and Inventory (PMI) tasks that can be triggered through our wearable devices, this implementation helps to create a safer, more intuitive, and more efficient manufacturing workplace for both remote and in-person operators especially for materials handling, monitoring, robotic telepresence, and industrial automation use-cases.</p>\n<p>Because of the big success in Phase I R&amp;D, GyroPalm Spectrum won the 2023 Best Innovation - Wearables from Sensors Expo in Silicon Valley, which is North America's largest design engineers' event, beating advanced products of reputable large publicly held corporations such as TDK Robotics and Synaptics.This substantiates the superiority, novelty, and versatility of Spectrum. Our unprecedented technology always made us the center of attraction in tech expos.</p>\n<p>We completed the initial version of Spectrum which entered the market in the 3rd qtr. of 2023.&nbsp; We have already sold considerable number of Spectrum units even with limited marketing/sales efforts.The I-Corps Boot Camp enabled us to know the needs and preferences of potential customers and gain considerable insights. Large corporations tend to buy multiple units. It is anticipated that a small number of customers will want us to create customized setup or system for them and that about two-thirds of our customers will rely on us for the dedicated Cloud services. Thus, revenue from consulting or after-sale services will be considerable.</p>\n<p>Our Phase I results have already attracted 3 large corporations to engage in R&amp;D projects with us so that Spectrum will be specially tailored to their companies' needs, reflecting their strong desire to buy from us! To start with, Subaru is one of the leading automotive manufacturers in the world; they want to use Spectrum for factory automation. Endress+Hauser is a leading international corporation on factory automation and would like to integrate their products with ours. Finally,Fino Advisors is a North American infrastructure and energy company, they are interested in using Spectrum for their water purification system. These use-cases, to be further integrated in Phase II R&amp;D, are really promising and captivating.</p>\n<p>In Phase II, we plan to finish our R&amp;D objective of adding the vital voice-command feature to Spectrum next year or sooner, and we will finish our R&amp;D later successfully inventing more momentous product features particularly the AI ones and will file for another patent. We believe that if we have adequate resources and employ appropriate strategies and tactics on marketing/sales, Spectrum has huge potentials and sky is the limit especially with our continuous R&amp;D efforts!&nbsp;&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/18/2023<br>\n\t\t\t\t\tModified by: Dominick&nbsp;S&nbsp;Lee</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697618860972_GyroPalmwinsAwardatSensorsExpo--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697618860972_GyroPalmwinsAwardatSensorsExpo--rgov-800width.jpg\" title=\"GyroPalm wins Award at Sensors Converge Expo\"><img src=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697618860972_GyroPalmwinsAwardatSensorsExpo--rgov-66x44.jpg\" alt=\"GyroPalm wins Award at Sensors Converge Expo\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">GyroPalm Spectrum, a product of the VIMPAACT project, wins \"2023 Best Innovative Product of the Year - Wearables\" award at Sensors Converge Expo, one of North America's largest electronics design engineering event.</div>\n<div class=\"imageCredit\">Dominick Lee</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Dominick&nbsp;S&nbsp;Lee</div>\n<div class=\"imageTitle\">GyroPalm wins Award at Sensors Converge Expo</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697618974757_GyroPalmSpectrum-AwardShowcase--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697618974757_GyroPalmSpectrum-AwardShowcase--rgov-800width.jpg\" title=\"GyroPalm Spectrum - Award Showcase\"><img src=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697618974757_GyroPalmSpectrum-AwardShowcase--rgov-66x44.jpg\" alt=\"GyroPalm Spectrum - Award Showcase\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The award-winning GyroPalm Spectrum package displayed at the Sensors Converge Expo showcase.</div>\n<div class=\"imageCredit\">Dominick Lee</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Dominick&nbsp;S&nbsp;Lee</div>\n<div class=\"imageTitle\">GyroPalm Spectrum - Award Showcase</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697619245099_GyroPalmSpectrumSpot--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697619245099_GyroPalmSpectrumSpot--rgov-800width.jpg\" title=\"GyroPalm Spectrum controlling Boston Dynamics robot\"><img src=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697619245099_GyroPalmSpectrumSpot--rgov-66x44.jpg\" alt=\"GyroPalm Spectrum controlling Boston Dynamics robot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">User wears the GyroPalm Spectrum controlling Boston Dynamics robot hands-free with remote teleoperated visualization.</div>\n<div class=\"imageCredit\">Dominick Lee</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Dominick&nbsp;S&nbsp;Lee</div>\n<div class=\"imageTitle\">GyroPalm Spectrum controlling Boston Dynamics robot</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697619331407_GyroPalmSpectrumview--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697619331407_GyroPalmSpectrumview--rgov-800width.jpg\" title=\"GyroPalm Spectrum - User View\"><img src=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697619331407_GyroPalmSpectrumview--rgov-66x44.jpg\" alt=\"GyroPalm Spectrum - User View\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A user's perspective on using the Spectrum framework inside a manufacturing facility.</div>\n<div class=\"imageCredit\">Dominick Lee</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Dominick&nbsp;S&nbsp;Lee</div>\n<div class=\"imageTitle\">GyroPalm Spectrum - User View</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697619685009_GyroPalm-Spectrum-Driving--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697619685009_GyroPalm-Spectrum-Driving--rgov-800width.jpg\" title=\"GyroPalm Spectrum - Gesture Interface\"><img src=\"/por/images/Reports/POR/2023/2151524/2151524_10830776_1697619685009_GyroPalm-Spectrum-Driving--rgov-66x44.jpg\" alt=\"GyroPalm Spectrum - Gesture Interface\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Users can perform hands-free robotic control using customizable gestures and receive insights through paired AR glasses.</div>\n<div class=\"imageCredit\">Dominick Lee</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Dominick&nbsp;S&nbsp;Lee</div>\n<div class=\"imageTitle\">GyroPalm Spectrum - Gesture Interface</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nOur NSF project titled Virtual Interfaces using Multi-Protocol Augmented-Reality Activation-based Control Transfer (VIMPAACT) has a primary objective to create a novel hands-free framework that expands the potential of augmented reality (AR) devices along with GyroPalm's gesture control to bolster safer and more efficient human collaboration with machines/robots in a remote environment. To achieve the ideal commercial and strategic offerings in human-robot collaboration, GyroPalm has seamlessly paired the Vuzix Blade 2 AR glasses with our own GyroPalm Encore wearable. This hybrid-architecture integration forms 'GyroPalm Spectrum', a complete industrial package featuring our groundbreaking VIMPAACT firmware. Spectrum allows professionals and enterprises to connect wirelessly to ROS-based robots from anywhere in the world, offering an adaptable and versatile system for more secure and optimized robotic operations.\n\nThe Spectrum firmware comprises of an intelligent Android-compatible application and GyroPalm OS binary which is used to communicate with the VIMPAACT framework through JSON, secure websockets (WSS), WebRTC, and REST API. Our R&amp;D in Phase I was very successful! The proposed wireless protocol was established, which enables multiple Spectrum devices to control one or more robots, making them more contextually-aware of facility environments for dynamic control. With Spectrum, custom user-based interactions can be performed on the GyroPalm Encore while the AR glasses display relevant visuals from Intel Realsense cameras in proximity with robot(s).\n\nComputer vision algorithms were deployed that leveraged the Intel RealSense to not only obtain point clouds, but to locate both rounded and square objects, such as test tubes, packages, and blocks, and command a robotic arm running on ROS MoveIt to use inverse kinematics to locate and pick up the distinctly recognized object. Essentially, deliberate navigation gestures such as a combination of an activation snap and double-wave left or right, combined with a dynamic rules engine, would command the robot to either strategically sort or dispose of the selected object, all without requiring the operator's physical presence near the machine.\n\nWhile fiducial markers were used to calibrate and coordinate multiple 6-DOF industrial robot arms, the AI vision algorithms developed for the VIMPAACT project were instrumental in recognizing objects that do not have any QR or Aruco tag attached. VIMPAACT also encompasses a full networking pipeline that not only connects Spectrum wearables to Cloud, but also enables local ROS industrial machines to be securely accessible virtually anywhere in the world. By creating repeatable Performance, Measurement, and Inventory (PMI) tasks that can be triggered through our wearable devices, this implementation helps to create a safer, more intuitive, and more efficient manufacturing workplace for both remote and in-person operators especially for materials handling, monitoring, robotic telepresence, and industrial automation use-cases.\n\nBecause of the big success in Phase I R&amp;D, GyroPalm Spectrum won the 2023 Best Innovation - Wearables from Sensors Expo in Silicon Valley, which is North America's largest design engineers' event, beating advanced products of reputable large publicly held corporations such as TDK Robotics and Synaptics.This substantiates the superiority, novelty, and versatility of Spectrum. Our unprecedented technology always made us the center of attraction in tech expos.\n\nWe completed the initial version of Spectrum which entered the market in the 3rd qtr. of 2023.  We have already sold considerable number of Spectrum units even with limited marketing/sales efforts.The I-Corps Boot Camp enabled us to know the needs and preferences of potential customers and gain considerable insights. Large corporations tend to buy multiple units. It is anticipated that a small number of customers will want us to create customized setup or system for them and that about two-thirds of our customers will rely on us for the dedicated Cloud services. Thus, revenue from consulting or after-sale services will be considerable.\n\nOur Phase I results have already attracted 3 large corporations to engage in R&amp;D projects with us so that Spectrum will be specially tailored to their companies' needs, reflecting their strong desire to buy from us! To start with, Subaru is one of the leading automotive manufacturers in the world; they want to use Spectrum for factory automation. Endress+Hauser is a leading international corporation on factory automation and would like to integrate their products with ours. Finally,Fino Advisors is a North American infrastructure and energy company, they are interested in using Spectrum for their water purification system. These use-cases, to be further integrated in Phase II R&amp;D, are really promising and captivating.\n\nIn Phase II, we plan to finish our R&amp;D objective of adding the vital voice-command feature to Spectrum next year or sooner, and we will finish our R&amp;D later successfully inventing more momentous product features particularly the AI ones and will file for another patent. We believe that if we have adequate resources and employ appropriate strategies and tactics on marketing/sales, Spectrum has huge potentials and sky is the limit especially with our continuous R&amp;D efforts!  \n\n\t\t\t\t\tLast Modified: 10/18/2023\n\n\t\t\t\t\tSubmitted by: Dominick S Lee"
 }
}