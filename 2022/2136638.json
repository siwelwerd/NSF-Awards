{
 "awd_id": "2136638",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I: Programmable Three-Dimensional (3D) Light Curtains for Enhanced Human-Robot Collaboration",
 "cfda_num": "47.041, 47.084",
 "org_code": "15030000",
 "po_phone": "7032922936",
 "po_email": "emirowsk@nsf.gov",
 "po_sign_block_name": "Ela Mirowski",
 "awd_eff_date": "2022-03-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 255806.0,
 "awd_amount": 255806.0,
 "awd_min_amd_letter_date": "2022-02-24",
 "awd_max_amd_letter_date": "2022-02-24",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project seeks to improve the efficiency and safety of human-robot collaboration with a new type of three-dimensional (3D) sensor. As labor shortages stress supply chains, companies are rapidly adopting robotic solutions to try and reduce time delays in obtaining materials. Whereas robots of the past typically operated by themselves, the proposed robots work collaboratively with humans to perform complicated tasks. Human workers can then transition to higher-skill positions where they can assist in the more intricate aspects of a task, while robots perform the dull and monotonous operations. The new applications are enabled by close interactions between robots and humans. Where physical barriers were once used to guarantee separation and safety, sensors now detect people and ensure human-robot interactions are safe. Despite the broad use of 3D sensors in many other areas of robotics, low-resolution and processing requirements force most safety applications to use the same fundamental 2D sensor technology that have been employed for decades. Since 2D technology cannot provide 3D protection, safety buffers are added, and human-robot collaboration is limited. New safety-sensors that provide 3D coverage will enable improved collaboration and efficiency in robotic applications throughout global supply chains.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project seeks to commercialize 3D light curtain safety sensors that have potential for use in autonomous systems and human-robot interactions. The core technology is a software-defined 3D sensor that senses specific 3D surfaces upon request. Instead of sensing an entire 3D volume like most sensors on the market today, these sensors monitor a single requested 3D surface within the specified volume. For 3D safety sensing, this approach allows users to adaptively program specific 3D safety boundaries around robots and humans. This removes the complex 3D processing required by other sensors and replaces it with a simple detection task similar to how existing 2D safety-sensors work. The proposed research may advance the applicability of the 3D light curtain technology to tasks in agile manufacturing and co-bots, potentially improving safety and efficiency in factories. The objectives of this work are to improve detection capabilities, increase field-of-view, and advance product readiness with customer-guided testing. Research will include iterative simulation, prototyping, and characterization of potential optical and photonic configurations to achieve these goals.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Joseph",
   "pi_last_name": "Bartels",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Joseph Bartels",
   "pi_email_addr": "joe@phlux.io",
   "nsf_id": "000850670",
   "pi_start_date": "2022-02-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "PHLUX TECHNOLOGIES, INC.",
  "inst_street_address": "113 KINGS DALE RD",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4123948824",
  "inst_zip_code": "152213909",
  "inst_country_name": "United States",
  "cong_dist_code": "17",
  "st_cong_dist_code": "PA17",
  "org_lgl_bus_name": "PHLUX TECHNOLOGIES, INC",
  "org_prnt_uei_num": "C91LVZJEU1K8",
  "org_uei_num": "C91LVZJEU1K8"
 },
 "perf_inst": {
  "perf_inst_name": "PHLUX TECHNOLOGIES, INC.",
  "perf_str_addr": "6024 Broad Street",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152063010",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7632",
   "pgm_ref_txt": "HUMAN-ROBOT INTERACTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 255806.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This Small Business Innovation Research (SBIR) Phase I project made key developments to commercialize an innovative 3D sensor for safety applications in robotics and industrial automation. As manufacturing companies look to cut costs and improve efficiency they are turning to flexible and collaborative systems where humans work with robots to accomplish tasks. Up until recently, industrial robots had minimal interaction with workers, but small collaborative robots have changed that. Unlike large industrial robots which typically require safety fences, these robots function without such physical barriers. This flexibility facilitates easy reconfiguration and adaptation to new tasks. However, the safety limitations of these small robots compromise their performance. In contrast, industrial robots are faster and more powerful, but their operation necessitates strict safety measures like physical barriers. To bridge this gap, this project develops a pioneering 3D sensing technology, called programmable 3D light curtains, that aims to eliminate the need for fences around robots and make all robots collaborative.&nbsp; These sensors monitor virtual fences around robots and other equipment by triangulating a projected plane of light with a sensing plane from a 2D detector to form a line of detection that is then steered through the volume and fused together to form surfaces, called 3D light curtains. These light curtains can be programmed to create dynamic virtual fences around robots that when intruded upon either slow down or stop the robot to maintain safety. This Phase I research advanced the technical readiness of the sensors, focusing on how to increase the versatility and reliability of the technology for industrial safety applications.</p>\n<p>One objective of the research was to improve the versatility of these sensors by expanding their field of view and operational angle. To achieve this, a geometric ray-tracing simulator was developed, allowing for the simulation of 3D light curtain sensors under a variety of optical parameters. This simulator was then used to perform a comprehensive evaluation of available camera lenses and image sensors which provided insights into balancing the system&rsquo;s field of view with optical distortion. This led to the identification of optical configurations suitable for creating wide-angled light curtain imaging systems. Additionally, the project explored the complexities of generating light curtains from elevated positions, identifying challenges, and proposing potential solutions.</p>\n<p>The second objective was to enhance detection reliability. The goal was to optimize the sensors to identify low-reflectance objects without an increase in false detections or potential interferences from other sensors. An in-depth analysis of the image formation model tailored for the light curtain system highlighted key parameters influencing the signal-to-noise ratio and detection range. Based on simulation findings, several systems were prototyped and then tested. Their performance was evaluated for detection range at several calibrated surface reflectance values. In tandem, strategies were devised to eliminate the occurrence of false positives, with emphasis on spatial-temporal filtering and its impact on essential safety parameters. To counter multi-device interferences, the project also examined alternative imaging sensing technologies such as time-of-flight imaging and multi-modal sensor fusion.</p>\n<p>The final objective of the project was to improve overall product readiness and produce a minimally viable product ready for customer testing. By integrating the research results and supplemental technical developments, a new hardware prototype was produced that provides the expected form, fit, and function of a safety device. A 3D graphical user interface was then developed that provides a platform for intuitive configuration and real-time monitoring of the 3D light curtains.</p>\n<p>In conclusion, this research advanced the commercialization readiness of a unique 3D sensing technology for applications in robot safety. These programmable safety sensors allow for new and improved ways for humans to work safely with robots, improving efficiency, resilience, and sustainability of factories around the world. Resulting advancements in robotics and automation will help reshore domestic manufacturing and improve the well-being of factory workers by removing them from dangerous low-skill jobs and promoting them to higher-value skilled positions.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/18/2023<br>\n\t\t\t\t\tModified by: Joseph&nbsp;Bartels</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis Small Business Innovation Research (SBIR) Phase I project made key developments to commercialize an innovative 3D sensor for safety applications in robotics and industrial automation. As manufacturing companies look to cut costs and improve efficiency they are turning to flexible and collaborative systems where humans work with robots to accomplish tasks. Up until recently, industrial robots had minimal interaction with workers, but small collaborative robots have changed that. Unlike large industrial robots which typically require safety fences, these robots function without such physical barriers. This flexibility facilitates easy reconfiguration and adaptation to new tasks. However, the safety limitations of these small robots compromise their performance. In contrast, industrial robots are faster and more powerful, but their operation necessitates strict safety measures like physical barriers. To bridge this gap, this project develops a pioneering 3D sensing technology, called programmable 3D light curtains, that aims to eliminate the need for fences around robots and make all robots collaborative.  These sensors monitor virtual fences around robots and other equipment by triangulating a projected plane of light with a sensing plane from a 2D detector to form a line of detection that is then steered through the volume and fused together to form surfaces, called 3D light curtains. These light curtains can be programmed to create dynamic virtual fences around robots that when intruded upon either slow down or stop the robot to maintain safety. This Phase I research advanced the technical readiness of the sensors, focusing on how to increase the versatility and reliability of the technology for industrial safety applications.\n\nOne objective of the research was to improve the versatility of these sensors by expanding their field of view and operational angle. To achieve this, a geometric ray-tracing simulator was developed, allowing for the simulation of 3D light curtain sensors under a variety of optical parameters. This simulator was then used to perform a comprehensive evaluation of available camera lenses and image sensors which provided insights into balancing the system\u2019s field of view with optical distortion. This led to the identification of optical configurations suitable for creating wide-angled light curtain imaging systems. Additionally, the project explored the complexities of generating light curtains from elevated positions, identifying challenges, and proposing potential solutions.\n\nThe second objective was to enhance detection reliability. The goal was to optimize the sensors to identify low-reflectance objects without an increase in false detections or potential interferences from other sensors. An in-depth analysis of the image formation model tailored for the light curtain system highlighted key parameters influencing the signal-to-noise ratio and detection range. Based on simulation findings, several systems were prototyped and then tested. Their performance was evaluated for detection range at several calibrated surface reflectance values. In tandem, strategies were devised to eliminate the occurrence of false positives, with emphasis on spatial-temporal filtering and its impact on essential safety parameters. To counter multi-device interferences, the project also examined alternative imaging sensing technologies such as time-of-flight imaging and multi-modal sensor fusion.\n\nThe final objective of the project was to improve overall product readiness and produce a minimally viable product ready for customer testing. By integrating the research results and supplemental technical developments, a new hardware prototype was produced that provides the expected form, fit, and function of a safety device. A 3D graphical user interface was then developed that provides a platform for intuitive configuration and real-time monitoring of the 3D light curtains.\n\nIn conclusion, this research advanced the commercialization readiness of a unique 3D sensing technology for applications in robot safety. These programmable safety sensors allow for new and improved ways for humans to work safely with robots, improving efficiency, resilience, and sustainability of factories around the world. Resulting advancements in robotics and automation will help reshore domestic manufacturing and improve the well-being of factory workers by removing them from dangerous low-skill jobs and promoting them to higher-value skilled positions.\n\n \n\n\t\t\t\t\tLast Modified: 09/18/2023\n\n\t\t\t\t\tSubmitted by: Joseph Bartels"
 }
}