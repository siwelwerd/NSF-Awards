{
 "awd_id": "2240733",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: Medium: Collaborative Research: Srch3D: Efficient 3D Model Search via Online Manufacturing-specific Object Recognition and Automated Deep Learning-Based Design Classification",
 "cfda_num": "47.041, 47.070",
 "org_code": "07030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Bruce Kramer",
 "awd_eff_date": "2022-06-15",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 594996.0,
 "awd_amount": 341958.0,
 "awd_min_amd_letter_date": "2022-09-15",
 "awd_max_amd_letter_date": "2022-09-15",
 "awd_abstract_narration": "Rapid growth in additive manufacturing (AM) has improved the accessibility, customizability and affordability of making products using personal printers.  Designs can be developed by consumers, if they have enough knowledge of mechanical design and 3D modeling, or they can be obtained from third parties. However, the process of translating a design to a program that can successfully executed by a 3D printer often requires specialized domain knowledge that many end-users currently lack. In the meantime, lots of objects, which may be very similar or identical to what the non-technical user aims to design and print, have been produced by experts in industry and, hence, millions of proven part designs already exist. This research aims to fill the above-mentioned gap by developing a theoretically sound and practically deployable, domain-specific online search engine, called Srch3D, for 3D models. Srch3D will provide the non-technical end-users with a user-friendly solution to efficiently search for their components in a large repository of existing proven part designs. \r\n\r\nThe outcomes of this project will include algorithms for advanced 3D model analysis, indexing and search algorithms that can identify designs of interest within a large number of proven design files accurately in runtime. The research will involve development of algorithms for automated design search via 3D object detection with adaptive resolutions. They will build on top of state-of-the-art computer vision techniques, namely histogram of gradients (HOG), and extend them to three-dimensional spaces for the manufacturing design files. Additionally, the project will research algorithms for runtime 3D object classification and labeling via data-driven modeling. The solutions will use deep neural networks to search and identify objects of interest from a large design repository. The use of relatively high-level data-driven models, along with the detailed HOG-based solutions, will enable our online 3D model search engine to accept a different variety of input object formats from the users, such as sketches or photos of the objects of interest, their (partial) G-Code, computer-aided design design files, or English descriptions and keywords. The framework will be accessible via a public cloud-based 3D model search service. In the vein of google.com and virustotal.com for document and malware search, respectively, the framework will realize the aforementioned modules as a cloud-based search engine service that allows anyone to search for their design of interest using different input formats.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Saman",
   "pi_last_name": "Zonouz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Saman Zonouz",
   "pi_email_addr": "szonouz6@gatech.edu",
   "nsf_id": "000602787",
   "pi_start_date": "2022-09-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Tech Research Corporation",
  "perf_str_addr": "926 DALNEY ST NW",
  "perf_city_name": "ATLANTA",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "30332",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "791800",
   "pgm_ele_name": "CPS-Cyber-Physical Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "016Z",
   "pgm_ref_txt": "Cybermanufacturing Systems"
  },
  {
   "pgm_ref_code": "082E",
   "pgm_ref_txt": "MFG MACHINES & METROLOGY"
  },
  {
   "pgm_ref_code": "152E",
   "pgm_ref_txt": "Cyber-Physical Systems"
  },
  {
   "pgm_ref_code": "7371",
   "pgm_ref_txt": "CYBER TRUST"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "8027",
   "pgm_ref_txt": "Cyber Secur - Cyberinfrastruc"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 341958.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research aims to develop a theoretically sound and practically deployable domain-specific online search engine, called Srch3D, for 3D models. Srch3D will provide the non-technical end-users with a user-friendly solution to search for their components on a large repository of existing proven part designs efficiently.</p>\n<p>AI-enabled search capabilities for geometrically similar 3D design files in large databases. With the proliferation of 3D printing technology, manufacturing 3D design content is becoming increasingly ubiquitous. Inevitably, this epoch-making technology has brought with it a considerable increase in intellectual property (IP) theft of 3D object file designs. Adversarial parties and infringers use 3D design files to replicate objects, causing hundreds of billions of dollars of IP financial losses. Aside from preventive measures to preserve the confidentiality of 3D design files, novel detection algorithms are also needed to identify inevitable IP thefts. In this project, we propose 3DMON, a domain-specific attack detection technique in manufacturing to identify IP theft attempts and similarities in 3D design files. 3DMON leverages a data-driven approach to partition a given manufacturing design file into parts, and calculates similarity scores using a deep neural network model. The proposed network architecture constructs a unique mathematical signature for each 3D manufacturing design, which is leveraged to discover similarities between two or more 3D objects. 3DMON&rsquo;s support for whole and partial design similarity discovery enables accurate detection of complicated IP theft attacks. We perform extensive experiments with more than 600,000 manufacturing 3D design parts and demonstrate 3DMON&rsquo;s practicality and effectiveness (up to 96.51% whole design search and 93.01% partial design search accuracy) in manufacturing IP theft detection problems.</p>\n<p>Systemization of Knowledge: Security Landscape of Additive Manufacturing. Additive Manufacturing (AM), commonly known as 3D printing, has grown into a multi-billion-dollar industry and is increasingly getting adopted by several industries such as aerospace, automotive, medical, military, etc. Despite the increasing usage of AM in many critical infrastructures, research on AM security &mdash; theft of private intellectual properties and manufacturing of unauthorized 3D-printed objects with/without stealthy defects that cause the objects to fail during operation &mdash; has received little attention from the security community. In this project, we critique the last 10 years of prior works on AM security, identify critical weaknesses, fix them, and identify open problems that need to be solved to harden the various insecure processes in the AM supply chain. In our literature survey of AM security over the last 10 years, we found 14 papers on IP theft, 18 papers on counterfeit detection, and just six papers on AM trojans. Only 5 out of the 38 papers were published in the top 4 security venues which indicates that the security of AM has not received much attention from the security community. Note that while shortlisting papers on IP theft, counterfeiting, and trojans in AM, we scraped all papers in the top-4 security venues that were accepted between 2014 &minus; 2024 and selected all papers on 3D printing/additive manufacturing.&nbsp;</p>\n<p>AI-enabled digital twin creation of printing processes. 3D printers are often accompanied by internet-connected cameras that monitor the printing process for quality assurance. Exploiting known vulnerabilities in these cameras allows an adversary to observe and record the 3D printing of high-valued objects. Now, having the video recording of the 3D-print process, the adversary can target to reverse-engineer the print instructions that are encoded in a G-code file and produce counterfeit versions of the high-valued 3D-printed objects. This makes the G-code the target intellectual property (IP) of the adversary. Recent prior work showed that using a ResNet-50 machine learning model, an adversary can map individual frames in the video to points in the 3D plane of the printer. However, this effectively gives the adversary the path that the extruder of the 3D printer takes while printing the object. This is not sufficient for an adversary to 3D print counterfeit versions of the object because a full G-code IP encodes a lot more information (e.g., movement type, extrusion rate, feed rate) apart from the extrusion path that fully describes the dimension as well as the mechanical properties of the object. In this work, we develop three solutions to overcome several limitations of prior work.&nbsp;</p>\n<p>For outreach, we hosted and worked with a female faculty and underrepresented undergrad student from a Minority/Hispanic Serving Institution (HSI) - the University of Texas at San Antonio (UTSA) over the summer. Furthermore, we participation in Georgia Tech SURE Program: we hosted and trained an African-American undergraduate student from Kennesaw State University for a summer internship on this project and manufacturing cybersecurity. Additionally, we stated a research collaboration with Historically black colleges and universities (HBCU): Clark Atlanta University (CAU), the first HBCU in Southern United States. Finally, throughout this project, we trained 3 research scientists and postDocs along with more than 5 graduate students in addition to undergrads.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/03/2024<br>\nModified by: Saman&nbsp;Zonouz</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2240733/2240733_10634914_1730681030918_Screenshot_2024_11_03_at_7.42.44__8239_PM--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/2240733/2240733_10634914_1730681030918_Screenshot_2024_11_03_at_7.42.44__8239_PM--rgov-800width.png\" title=\"Srch3D\"><img src=\"/por/images/Reports/POR/2024/2240733/2240733_10634914_1730681030918_Screenshot_2024_11_03_at_7.42.44__8239_PM--rgov-66x44.png\" alt=\"Srch3D\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">searching for geometrically similar 3D design files.</div>\n<div class=\"imageCredit\">Georgia Tech</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Saman&nbsp;Zonouz\n<div class=\"imageTitle\">Srch3D</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis research aims to develop a theoretically sound and practically deployable domain-specific online search engine, called Srch3D, for 3D models. Srch3D will provide the non-technical end-users with a user-friendly solution to search for their components on a large repository of existing proven part designs efficiently.\n\n\nAI-enabled search capabilities for geometrically similar 3D design files in large databases. With the proliferation of 3D printing technology, manufacturing 3D design content is becoming increasingly ubiquitous. Inevitably, this epoch-making technology has brought with it a considerable increase in intellectual property (IP) theft of 3D object file designs. Adversarial parties and infringers use 3D design files to replicate objects, causing hundreds of billions of dollars of IP financial losses. Aside from preventive measures to preserve the confidentiality of 3D design files, novel detection algorithms are also needed to identify inevitable IP thefts. In this project, we propose 3DMON, a domain-specific attack detection technique in manufacturing to identify IP theft attempts and similarities in 3D design files. 3DMON leverages a data-driven approach to partition a given manufacturing design file into parts, and calculates similarity scores using a deep neural network model. The proposed network architecture constructs a unique mathematical signature for each 3D manufacturing design, which is leveraged to discover similarities between two or more 3D objects. 3DMONs support for whole and partial design similarity discovery enables accurate detection of complicated IP theft attacks. We perform extensive experiments with more than 600,000 manufacturing 3D design parts and demonstrate 3DMONs practicality and effectiveness (up to 96.51% whole design search and 93.01% partial design search accuracy) in manufacturing IP theft detection problems.\n\n\nSystemization of Knowledge: Security Landscape of Additive Manufacturing. Additive Manufacturing (AM), commonly known as 3D printing, has grown into a multi-billion-dollar industry and is increasingly getting adopted by several industries such as aerospace, automotive, medical, military, etc. Despite the increasing usage of AM in many critical infrastructures, research on AM security  theft of private intellectual properties and manufacturing of unauthorized 3D-printed objects with/without stealthy defects that cause the objects to fail during operation  has received little attention from the security community. In this project, we critique the last 10 years of prior works on AM security, identify critical weaknesses, fix them, and identify open problems that need to be solved to harden the various insecure processes in the AM supply chain. In our literature survey of AM security over the last 10 years, we found 14 papers on IP theft, 18 papers on counterfeit detection, and just six papers on AM trojans. Only 5 out of the 38 papers were published in the top 4 security venues which indicates that the security of AM has not received much attention from the security community. Note that while shortlisting papers on IP theft, counterfeiting, and trojans in AM, we scraped all papers in the top-4 security venues that were accepted between 2014  2024 and selected all papers on 3D printing/additive manufacturing.\n\n\nAI-enabled digital twin creation of printing processes. 3D printers are often accompanied by internet-connected cameras that monitor the printing process for quality assurance. Exploiting known vulnerabilities in these cameras allows an adversary to observe and record the 3D printing of high-valued objects. Now, having the video recording of the 3D-print process, the adversary can target to reverse-engineer the print instructions that are encoded in a G-code file and produce counterfeit versions of the high-valued 3D-printed objects. This makes the G-code the target intellectual property (IP) of the adversary. Recent prior work showed that using a ResNet-50 machine learning model, an adversary can map individual frames in the video to points in the 3D plane of the printer. However, this effectively gives the adversary the path that the extruder of the 3D printer takes while printing the object. This is not sufficient for an adversary to 3D print counterfeit versions of the object because a full G-code IP encodes a lot more information (e.g., movement type, extrusion rate, feed rate) apart from the extrusion path that fully describes the dimension as well as the mechanical properties of the object. In this work, we develop three solutions to overcome several limitations of prior work.\n\n\nFor outreach, we hosted and worked with a female faculty and underrepresented undergrad student from a Minority/Hispanic Serving Institution (HSI) - the University of Texas at San Antonio (UTSA) over the summer. Furthermore, we participation in Georgia Tech SURE Program: we hosted and trained an African-American undergraduate student from Kennesaw State University for a summer internship on this project and manufacturing cybersecurity. Additionally, we stated a research collaboration with Historically black colleges and universities (HBCU): Clark Atlanta University (CAU), the first HBCU in Southern United States. Finally, throughout this project, we trained 3 research scientists and postDocs along with more than 5 graduate students in addition to undergrads.\n\n\n\t\t\t\t\tLast Modified: 11/03/2024\n\n\t\t\t\t\tSubmitted by: SamanZonouz\n"
 }
}