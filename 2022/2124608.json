{
 "awd_id": "2124608",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Bidirectional Body-Brain-Machine Interface (B3MI) for Control of Complex Dynamics",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032927557",
 "po_email": "amedinab@nsf.gov",
 "po_sign_block_name": "Alexandra Medina-Borja",
 "awd_eff_date": "2022-01-01",
 "awd_exp_date": "2024-12-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 316000.0,
 "awd_min_amd_letter_date": "2021-11-02",
 "awd_max_amd_letter_date": "2022-06-30",
 "awd_abstract_narration": "This Mind, Machine, and Motor Nexus (M3X) EArly-concept Grant for Exploratory Research (EAGER) project advances a novel vision for implantable bidirectional brain-machine interfaces. Bidirectional brain-machine interfaces read and write information from and to the brain. These technologies have potential to help restore function after neuromotor injury by supplementing intrinsic sensory and motor pathways with engineered pathways that can be used to control assistive devices. However, successful application of the technology requires users to undergo substantial training to learn how to use the interface to control the assistive device. This project will promote the progress of science and advance the national health by advancing the project's overarching goal, which is to understand and shape how the brain can use a bidirectional brain-machine interface to control physical machines with complex dynamics. The specific objectives of the project are: 1) to characterize how the brain learns to combine intrinsic sensory inputs (vision and somatosensation), along with engineered sensory inputs and motor outputs, to control novel devices with complex dynamics; and 2) to test new ways to build high-performance bidirectional interfaces that can co-adapt to enhance user-in-the-loop control. The project team will test bidirectional body and brain interfaces with foundational research using a clinically relevant model that allows the scientifically rigorous study of complex learning dynamics. The research promises to be impactful in the future development of assistive devices and rehabilitation therapies, where methods to design and optimize user-in-the-loop systems will enable improved performance and customization of devices to users' evolving needs and capabilities. The project also supports graduate education through research mentorship.\r\n\r\nThe long-term goal of this work is to develop new knowledge and engineering tools that can be used to optimize user-in-the-loop assistive devices. When a user receives feedback from a device and uses that feedback to alter the device's performance in real-time, the user becomes part of the device control loop. Current brain-machine interfaces are designed using methods from statistics and machine learning that are ill-suited to the closed-loop, co-adaptive, dynamic environments created when the user is in the loop. As a first step towards optimizing multi-pathway sensorimotor interfaces, the research seeks: (1) to discover how sensory-and-motor pathways are integrated as a user learns to control complex dynamics in a bidirectional body-and-brain-machine interface (B3MI); and (2) to apply this knowledge to synthesize and test a bidirectional interface that optimizes user-in-the-loop control of a machine with complex dynamics. The project uses using a clinically relevant non-human primate (NHP) model that facilitates the rigorous study of complex learning dynamics in a way that is impracticable through human subject experimentation. The research has two aims. The first seeks to empirically measure sensorimotor transforms corresponding to different pathways obtained by pairing visual or neural sensory input with manual or neural motor output as a NHP controls interfaces with different machine dynamics (1st and 2nd order). The second seeks to synthesize B3MIs to optimize closed-loop system performance, and to test performance while controlling physical machine dynamics. The research uses high spatiotemporal resolution, invasive neural recording and stimulation techniques in a NHP to create novel closed-loop bidirectional B3MIs. The study will use a novel trajectory-tracking task wherein spectral analysis of measured input and output signals are used to directly quantify sensorimotor transforms. Interfaces will be synthesized using established techniques from robust control theory. Interface performance will be assessed using performance metrics on established assay tasks, and sensorimotor transformations will be quantified using established metrics from human motor control. This work promises scientific and engineering advances that will improve the robustness and utility of bidirectional neural interfaces for assistive device and rehabilitation applications.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sam",
   "pi_last_name": "Burden",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sam Burden",
   "pi_email_addr": "sburden@uw.edu",
   "nsf_id": "000704018",
   "pi_start_date": "2021-11-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Amy",
   "pi_last_name": "Orsborn",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Amy L Orsborn",
   "pi_email_addr": "aorsborn@uw.edu",
   "nsf_id": "000850468",
   "pi_start_date": "2021-11-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "4333 Brooklyn Ave. NE.",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981952500",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "058Y00",
   "pgm_ele_name": "M3X - Mind, Machine, and Motor"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "116E",
   "pgm_ref_txt": "RESEARCH EXP FOR UNDERGRADS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "060Z",
   "pgm_ref_txt": "Convergent Research"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "9231",
   "pgm_ref_txt": "SUPPL FOR UNDERGRAD RES ASSIST"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 316000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-2bdc7157-7fff-ba9d-aeb3-b7745e79149f\">\r\n<p dir=\"ltr\"><span>This Mind, Machine, and Motor Nexus (M3X) EArly-concept Grant for Exploratory Research (EAGER) project advanced new methods to enable a novel vision for bidirectional brain-machine interfaces. Bidirectional brain-machine interfaces read and write information from and to the brain. These technologies have potential to help restore function after neuromotor injury by supplementing intrinsic sensory and motor pathways with engineered pathways that can be used to control assistive devices. However, successful application of the technology requires users to undergo substantial training to learn how to use the interface to control the assistive device. This project promoted the progress of science and advanced national health by advancing the project's overarching goal, which is to understand and shape how the brain can use a bidirectional brain-machine interface to control devices. The specific objectives of the project were: 1) to characterize how the brain learns to transform sensory inputs, whether intrinsic (vision and somatosensation) or engineered, into motor outputs to control novel devices, and 2) test new ways to build high-performance interfaces that can co-adapt to enhance user-in the-loop control.</span></p>\r\n<p dir=\"ltr\"><span>The outcomes of this project significantly advanced our two specific objectives. Towards our first objective, we developed methods to model and quantify how a user transforms sensory inputs into motor outputs and applied it to characterize how users learn to control new visual &ndash; motor and visual &ndash; muscle devices. Our new approach revealed that user learning involves significant contributions from feedback control (related to sensory inputs). This finding expands our understanding of how users learn to control new devices and further emphasizes the importance of bi-directional interface design. Towards our second objective, we developed and evaluated new adaptive interface algorithms in a visual &ndash; muscle device. We used the methods developed for the first objective to analyze how users learned and how this was influenced by different parameters within the algorithm. We found that changing the interface algorithm could influence user behavior and overall interface performance in predictable ways. This provides the first demonstration of methods for intelligent co-adaptive interfaces that may be able to shape and enhance user-in-the-loop interface control.</span></p>\r\n<p dir=\"ltr\"><span>The outcomes of this project will significantly inform future studies on control of assistive devices or rehabilitative therapies. The new co-adaptive algorithms we developed will enable improved performance and customization of devices to users' evolving needs and capabilities. More broadly, the tools we developed have potential applications in studying how the brain controls movement and improving human-computer interaction technologies.&nbsp; This project also supported undergraduate and graduate education through research mentorship opportunities for multiple trainees.&nbsp;</span></p>\r\n</span></p><br>\n<p>\n Last Modified: 04/08/2025<br>\nModified by: Amy&nbsp;L&nbsp;Orsborn</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\r\n\n\nThis Mind, Machine, and Motor Nexus (M3X) EArly-concept Grant for Exploratory Research (EAGER) project advanced new methods to enable a novel vision for bidirectional brain-machine interfaces. Bidirectional brain-machine interfaces read and write information from and to the brain. These technologies have potential to help restore function after neuromotor injury by supplementing intrinsic sensory and motor pathways with engineered pathways that can be used to control assistive devices. However, successful application of the technology requires users to undergo substantial training to learn how to use the interface to control the assistive device. This project promoted the progress of science and advanced national health by advancing the project's overarching goal, which is to understand and shape how the brain can use a bidirectional brain-machine interface to control devices. The specific objectives of the project were: 1) to characterize how the brain learns to transform sensory inputs, whether intrinsic (vision and somatosensation) or engineered, into motor outputs to control novel devices, and 2) test new ways to build high-performance interfaces that can co-adapt to enhance user-in the-loop control.\r\n\n\nThe outcomes of this project significantly advanced our two specific objectives. Towards our first objective, we developed methods to model and quantify how a user transforms sensory inputs into motor outputs and applied it to characterize how users learn to control new visual  motor and visual  muscle devices. Our new approach revealed that user learning involves significant contributions from feedback control (related to sensory inputs). This finding expands our understanding of how users learn to control new devices and further emphasizes the importance of bi-directional interface design. Towards our second objective, we developed and evaluated new adaptive interface algorithms in a visual  muscle device. We used the methods developed for the first objective to analyze how users learned and how this was influenced by different parameters within the algorithm. We found that changing the interface algorithm could influence user behavior and overall interface performance in predictable ways. This provides the first demonstration of methods for intelligent co-adaptive interfaces that may be able to shape and enhance user-in-the-loop interface control.\r\n\n\nThe outcomes of this project will significantly inform future studies on control of assistive devices or rehabilitative therapies. The new co-adaptive algorithms we developed will enable improved performance and customization of devices to users' evolving needs and capabilities. More broadly, the tools we developed have potential applications in studying how the brain controls movement and improving human-computer interaction technologies. This project also supported undergraduate and graduate education through research mentorship opportunities for multiple trainees.\r\n\t\t\t\t\tLast Modified: 04/08/2025\n\n\t\t\t\t\tSubmitted by: AmyLOrsborn\n"
 }
}