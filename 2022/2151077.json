{
 "awd_id": "2151077",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Modular structures in the brain and artificial learningsystems: emergence and function",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2022-07-01",
 "awd_exp_date": "2025-06-30",
 "tot_intn_awd_amt": 464288.0,
 "awd_amount": 464288.0,
 "awd_min_amd_letter_date": "2022-06-21",
 "awd_max_amd_letter_date": "2022-06-21",
 "awd_abstract_narration": "Deep learning has made great strides, with artificial neural networks outperforming humans after training exhaustively on specialized tasks. However, rapid learning and flexible intelligence, hallmarks of biological brains, remain out of reach. In this proposal, we seek to understand an important feature of biological brains that will be critical for better and more interpretable artificial intelligence: the existence of modular architectures that are combined in rich ways to solve multiple problems with some shared sub-structure. We will study three aspects of modular architecture: 1) How observed modular structures in the brain might arise with minimal training, through simple and local constraints on how far a neuron can extend and how many synapses it can make; 2) What is the utility of a modular organization in neural circuits in solving tasks, in terms of robustness and the speed of learning, in the context of known neural circuits and function; 3) How the modular architectures and principles that lead to rapid modularization we learn about in 1)-2) can be imported into artificial neural networks to improve the learning speed and flexibility of machine intelligence. Thus, we seek to better understand brains, build a stronger dialogue between neuroscience and artificial intelligence, and use the resulting insights to improve machine intelligence. The grant will provide training opportunities to students and postdoctoral fellows in cutting-edge areas of strong interest for industry, government, and science, and we will focus on training a highly skilled and diverse workforce in these areas.\r\n\r\nCompositionality, i.e., the ability to learn and perform complex cognitive function by re-combining simpler sub-functions, is fundamental to the capabilities of the mind and is the basis for general intelligence. Underlying this ability is the presence of modular structures in the brain. Modular structures confer inherent advantages, such as increased stability to perturbations and faster learning. We will investigate mechanisms for the emergence of modularity in natural and artificial systems. Existing models for modularity are based primarily on top-down supervised learning, which requires large amounts of learning time and data. Our central hypothesis is that local constraints on connectivity in the brain provide strong prior biases towards modularization, and these lead to the rapid emergence of modular structure and improved function. First, we will use theoretical and computational tools to model low-level constraints to probe how they may drive modularization in neural circuits observed in the brain, including grid cells in the entorhinal cortex. Second, we will analyze the advantages conferred by modular organization in biological systems by studying the properties of high-capacity memory architectures directly inspired by the entorhinal-hippocampal circuit, with mEC-like modular subnetworks. Third, we will combine our developed modularization mechanisms and understanding of biological architectural circuitry to import similar advantages into artificial learning systems, creating artificial neural networks that achieve robust modular solutions to complex real-world tasks. Thus, our work will help to characterize how biological and artificial networks may spontaneously modularize to support robust and efficient inference and learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ila",
   "pi_last_name": "Fiete",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ila Fiete",
   "pi_email_addr": "fiete@mit.edu",
   "nsf_id": "000536962",
   "pi_start_date": "2022-06-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Ave",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 464288.0
  }
 ],
 "por": null
}