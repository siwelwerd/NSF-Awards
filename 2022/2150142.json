{
 "awd_id": "2150142",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: The role of trust when learning from robots",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927878",
 "po_email": "slim@nsf.gov",
 "po_sign_block_name": "Soo-Siang Lim",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2024-11-30",
 "tot_intn_awd_amt": 367918.0,
 "awd_amount": 353138.0,
 "awd_min_amd_letter_date": "2021-12-09",
 "awd_max_amd_letter_date": "2022-04-11",
 "awd_abstract_narration": "A decade ago, robots typically played the role of \u201ctool\u201d or \u201cteammate\u201d. Today, although there are some clear cases where the \u201ctool\u201d or \u201cteammate\u201d model is appropriate, most collaborative robots in long-term deployments in homes, workplaces, or schools readily switch back and forth between being an agentic \u201cteammate\u201d to an inanimate \u201ctool\u201d. While people tolerate this shift in perceived agency, it is unknown how this shift impacts interpersonal properties that are typically attributed only to agentic \u201cteammate\u201d robots. This project will evaluate factors that affect how people trust robots, recognizing that the way humans \u201ctrust\u201d non-agentic automation is fundamentally different from the way that we \u201ctrust\u201d agents and agentic robots. What happens to the trust formed while a robot is an agent when it becomes an inanimate tool? What happens when the inanimate tool returns to being an agentic teammate? The proposed research will fill a significant gap in our understanding of how young humans develop trust in robots. While trust in non-agentic robots is well understood, there has been little systematic study of trust in robots that function as collaborative tools. This work has broad applications to future deployment of robots as systems that vary over time between agentic (human-like) and non-agentic (object-like) behavior. \r\n\r\nThe investigators will concentrate on the role of agency in establishing trust in human-robot interactions in an important application domain: children\u2019s learning. Educational robots designed specifically for children are increasingly common, often replacing human channels of social information. However, these robots cannot be successful without trust; because children are inherently social and collaborative learners, trust is a prerequisite for successful learning. Integrating insights from interactive robot design into experiments with preschool and early school age children, the project will determine how shifts in perceived agency impact the formation, maintenance, and repair of trust: Study 1 investigates how variations of low-level perceptual cues over a single interaction influence trust and subsequent learning. Study 2 examines how variations of high-level social cues lead to differential trust and subsequent learning. For these experiments, a set of age-appropriate collaborative learning games were designed. The investigators also created a coding scheme for child behavior as well as a post-interaction child interview to assess children\u2019s perceptions of the robots and to measure effectiveness of learning. Findings and activities of this project could have broad impacts in multiple arenas including: (1) design guidelines that will influence a broad range of application areas including healthcare, manufacturing, and education; (2) enhancement/augmentation of learning, education and training, including research offerings for graduate and undergraduate investigators; (3) broadening of participation in one area of computing, and (4) dissemination of science to the general public and to the research community.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tamar",
   "pi_last_name": "Kushnir",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tamar Kushnir",
   "pi_email_addr": "tamar.kushnir@duke.edu",
   "nsf_id": "000555643",
   "pi_start_date": "2021-12-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke university",
  "perf_str_addr": "2200 W. Main St",
  "perf_city_name": "Durham",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277054010",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127Y00",
   "pgm_ele_name": "Sci of Lrng & Augmented Intel"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "059Z",
   "pgm_ref_txt": "Science of Learning"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  }
 ],
 "app_fund": [
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 353138.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project investigated the role of trust in children&rsquo;s learning from robots. Our main goal was accomplished through two studies in which children agest 4 to 9 collaborate with robots who sometimes make errors - either intentional or accidental - that effect the outcomes of the collaboration. We measured children's trust in the robots, their perceptions of the robots mental, emotional, and moral qualities.&nbsp;</p>\r\n<p><span>With the increase in technology use by children at younger and younger ages, it is vital that we better understand its impact on their learning and development. In particular, our work can be used to inform the increasing trend towards social, intelligent, and interactive AIs that are&nbsp;designed to be fully collaborative with children as they learn and interact with the world.&nbsp;</span></p>\r\n<div class=\"accomplishments bottomBorder\">\r\n<div class=\"tinyMCEContent\">\r\n<p>Below is summary of some of our main findings:</p>\r\n<p>1) Young children (4- to 5) are more trusting than older children, especially after mistakes. Interestingly, adult learners were the most trusting group, continuing to engage arobot even when they were intentionally inaccurate for several trials before losing trust. The least trusting group wereschool age children &ndash; 6- to 7-years of age &ndash; who required&nbsp;<em>apologies&nbsp;</em>in order to maintain trust, but who eventually disengaged from the robot and worked independently. Adults, interestingly, were most trusting of technologies, even when they were inaccurate. These findings provide insight into designing informational technologies that account forthe differences in user engagement across ages.</p>\r\n<p>2) Children played a collaborative game with a robot who was either apologetic or uncooperative. We measured children's reactions to the robot and persistence in the game. Results show that children are more likely to stop collaborating if a robot is uncooperative than if the robot apologizes. Furthermore, children are more likely to persist in playing with the apologetic robot than the uncooperative robot. Behavioral coding supports the idea that children felt more positively towards the apologetic robot: children engaged in more cooperative behaviors with the apologetic robot, such as forgiveness, soothing, and teaching or helping. Together, these findings suggest that children are willing to maintain a collaborative partnership with robots that signal prosocial qualities.</p>\r\n<p>Below are some of the broader impacts of the work:</p>\r\n<p>1) This project has provided training for graduate and undergraduate researchers in cognitive developmental science. Several of these students have gone on to prestigious fellowships, graduate programs, and won honors and awards for their work.&nbsp;</p>\r\n<p>2) This project has resulted in multiple peer-reviewed journal publications, conference proceedings publications, and conference presentations, all of which involve student authors.</p>\r\n<p>3)&nbsp;<span>Our findings are a first step to designing robots that can engage with children in collaborative learning. Our work further suggests that educational technology design cannot be one size fits all but rather must account for developmental changes in children&rsquo;s learning goals.</span></p>\r\n</div>\r\n</div>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 01/03/2025<br>\nModified by: Tamar&nbsp;Kushnir</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project investigated the role of trust in childrens learning from robots. Our main goal was accomplished through two studies in which children agest 4 to 9 collaborate with robots who sometimes make errors - either intentional or accidental - that effect the outcomes of the collaboration. We measured children's trust in the robots, their perceptions of the robots mental, emotional, and moral qualities.\r\n\n\nWith the increase in technology use by children at younger and younger ages, it is vital that we better understand its impact on their learning and development. In particular, our work can be used to inform the increasing trend towards social, intelligent, and interactive AIs that aredesigned to be fully collaborative with children as they learn and interact with the world.\r\n\r\n\r\n\n\nBelow is summary of some of our main findings:\r\n\n\n1) Young children (4- to 5) are more trusting than older children, especially after mistakes. Interestingly, adult learners were the most trusting group, continuing to engage arobot even when they were intentionally inaccurate for several trials before losing trust. The least trusting group wereschool age children  6- to 7-years of age  who requiredapologiesin order to maintain trust, but who eventually disengaged from the robot and worked independently. Adults, interestingly, were most trusting of technologies, even when they were inaccurate. These findings provide insight into designing informational technologies that account forthe differences in user engagement across ages.\r\n\n\n2) Children played a collaborative game with a robot who was either apologetic or uncooperative. We measured children's reactions to the robot and persistence in the game. Results show that children are more likely to stop collaborating if a robot is uncooperative than if the robot apologizes. Furthermore, children are more likely to persist in playing with the apologetic robot than the uncooperative robot. Behavioral coding supports the idea that children felt more positively towards the apologetic robot: children engaged in more cooperative behaviors with the apologetic robot, such as forgiveness, soothing, and teaching or helping. Together, these findings suggest that children are willing to maintain a collaborative partnership with robots that signal prosocial qualities.\r\n\n\nBelow are some of the broader impacts of the work:\r\n\n\n1) This project has provided training for graduate and undergraduate researchers in cognitive developmental science. Several of these students have gone on to prestigious fellowships, graduate programs, and won honors and awards for their work.\r\n\n\n2) This project has resulted in multiple peer-reviewed journal publications, conference proceedings publications, and conference presentations, all of which involve student authors.\r\n\n\n3)Our findings are a first step to designing robots that can engage with children in collaborative learning. Our work further suggests that educational technology design cannot be one size fits all but rather must account for developmental changes in childrens learning goals.\r\n\r\n\r\n\n\n\t\t\t\t\tLast Modified: 01/03/2025\n\n\t\t\t\t\tSubmitted by: TamarKushnir\n"
 }
}