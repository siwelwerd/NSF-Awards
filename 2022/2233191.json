{
 "awd_id": "2233191",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Planning: Toward OpenHMI, A Community-Designed Infrastructure for Human-Machine Interaction Research",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Juan Wachs",
 "awd_eff_date": "2022-08-01",
 "awd_exp_date": "2023-07-31",
 "tot_intn_awd_amt": 100000.0,
 "awd_amount": 100000.0,
 "awd_min_amd_letter_date": "2022-07-30",
 "awd_max_amd_letter_date": "2022-07-30",
 "awd_abstract_narration": "Human-machine interaction is an area of research where scientist study how users work together with robots and other devices. It is a broad, cross-cutting area of computing with great potential for supporting wellness, education, and training of people from various backgrounds and with diverse needs.  The technology in this field is expanding rapidly, and leverages major areas of development, including computer vision and computer intelligence.  However, this area of research is stifled by the lack of tools and software platforms that are accessible, affordable, and appropriate for use with real-world users in replicable real-world research studies.  This planning project aims to spend a year understanding this field of research community needs toward designing, what is called \u201cOpenHMI:, an open-source, affordable and modular platform for enabling scalable and accessible research and outreach in human-machine interaction (HMI)\u201d. OpenHMI aims to broaden participation in research by enabling affordable and inclusive real-world studies and data collections. By creating an accessible low-cost and a community accessible platform, this infrastructure will broaden participation of researchers from a range of institutions and levels of research support, in particular opening doors to under-resourced researchers and groups.  By involving researchers in the community in the design process, this work establishes an ecosystem that aims to remove barriers to entry for researchers from traditionally under-represented, under-resourced, and/or minority-serving groups and institutions, thereby expanding computing research ideas and projects.   The low cost of OpenHMI hardware can also make it an affordable platform for demonstrating introductory computing, computer coding, robotics, and design topics to K-12 and enabling safe hands-on learning.\r\n\r\nThis one-year planning project uses surveys, interviews, and workshops to collect information about the computing community needs toward developing OpenHMI. Specifically, three nation-wide surveys assess detailed needs of the community, including hardware and software infrastructure needed and specific prioritized features of each.  Using that input, mockups, early prototypes, and simulations of hardware and software are developed and used in two nation-wide virtual workshops designed to be broadly accessible and inclusive. The workshops serve to train the participants with hands-on experiential activities  while collecting information about usability, priorities, and preferences. The large corpus of collected community data informs the design of OpenHMI so that it can be community-informed and designed to ensure its ability to significantly advance research in human machine interaction research by being open-source, accessible, modular and scalable and to facilitate inclusive, safe, privacy-centered and effective integration of this field of research into everyday lives of users to better support ethical data-driven research. The community design process also establishes an open and collaborative ecosystem to accelerate the transition from research studies in small-scale short-term laboratory settings to large-scale long-term deployments in real-world environments.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maja",
   "pi_last_name": "Matari\u0107",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Maja J Matari\u0107",
   "pi_email_addr": "mataric@usc.edu",
   "nsf_id": "000410606",
   "pi_start_date": "2022-07-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mohammad",
   "pi_last_name": "Soleymani",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mohammad Soleymani",
   "pi_email_addr": "soleymani@ict.usc.edu",
   "nsf_id": "000792581",
   "pi_start_date": "2022-07-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3710 McClintock Avenue",
  "perf_city_name": "LOS ANGELES",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900891044",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 100000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This one-year planning grant supported a project that prepared for a proposal for developing <em>OpenHMI: an open-source, affordable and modular platform for</em><em> enabling scalable and accessible research and outreach in human-machine interaction (HMI)</em>. Human-machine interaction is a broad, cross-cutting area of computing that has shown great potential for supporting health, education, and training of people with diverse needs, along with other applications. HMI is expanding rapidly, and leverages many areas of computing research, including machine vision, machine learning, human activity understanding, affective computing, and others. Such a wide-ranging computing research field depends on significant infrastructure, including software for automatically analyzing human behavior and emotion, hardware for interactions with robots, and data management systems and workflows.&nbsp;</p>\n<p>Research into human-machine interaction is currently stifled by the lack of open-source,&nbsp; compatible software and hardware platforms that are accessible, affordable, and appropriate for use with various real-world user populations and replicable real-world studies and data collections. The major goal of this planning grant was to put together a collaborative multi-university team and project that brings together technical experts and community partners who will use co-design and evaluation through community engagement to develop <strong><em>OpenHMI </em></strong>to enable inclusive, accessible and affordable HMI research that includes the development of an experiment planning, pre-registration, and data-sharing component. This infrastructure project would engage community partner leaders with deep connections with traditionally less represented and served research communities, including minority-serving institutions.&nbsp;</p>\n<p>&nbsp;The specific outcomes of the project include:</p>\n<p>&nbsp;1) We designed and conducted on-line computing community surveys, and found that our proposed <strong><em>OpenHMI</em></strong> platform has the potential to make human-machine interaction research more accessible, affordable and customizable.&nbsp;</p>\n<p>&nbsp;2) We developed the prototype of the messaging architecture between the <strong><em>OpenHMI</em></strong> software and hardware for user demonstration purposes. For software, we developed the messaging architecture to enabled the robot to communicate with the. For hardware, we simplified the robot's open-source hardware design for ease of assembly, reducing the number of fabricated components from 63 to 20 and switching to only laser-cut 3D-printed components. These improvements shorten the robot assembly time and make the robot more affordable and accessible.</p>\n<p>&nbsp;3) We conducted two community workshops: a) a broadly inclusive community workshop (via Zoom) focusing on HMI researchers with around 30 participants; and b) an in-person community workshop with 15 participants at a minority-serving institution focusing on enabling more accessible HMI research for college students. We found that our openHMI robot is perceived by our workshop participants to be effective, easy-to-follow, engaging, and helpful in supporting them for future HMI research and education.</p>\n<p>&nbsp;4) We reported the major findings from this project in a full conference paper and submitted it for review to the 14th Symposium on Educational Advances in Artificial Intelligence at t<a href=\"https://www.google.com/search?client=safari&amp;rls=en&amp;q=The+38th+Annual+AAAI+Conference+on+Artificial+Intelligence&amp;ie=UTF-8&amp;oe=UTF-8\">he 38th Annual AAAI Conference on Artificial Intelligence</a>.</p>\n<p>5) We used all the findings and insights from the one-year planning grant to shape and refine our full project plan and proposal for the CRIC grant, submitted in September 2023.</p>\n<p>In summary, the intellectual merit of the planning grant includes the technical developments on the OpenHMI software and hardware that have been open-sourced, and the broader impacts include the collected insights from the research community obtained over the two workshops and submitted for publication.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 11/10/2023<br>\nModified by: Maja&nbsp;J&nbsp;Matari\u0107</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/2233191/2233191_10820229_1699634365482_Outcome_Images_1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2233191/2233191_10820229_1699634365482_Outcome_Images_1--rgov-800width.jpg\" title=\"OpenHMI System for Facilitating Human-Robot Interaction Research\"><img src=\"/por/images/Reports/POR/2023/2233191/2233191_10820229_1699634365482_Outcome_Images_1--rgov-66x44.jpg\" alt=\"OpenHMI System for Facilitating Human-Robot Interaction Research\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">OpenHMI system architecture showing the example program where the robot recognizes the user\ufffds head pose and imitates the user\ufffds head movements.</div>\n<div class=\"imageCredit\">USC Interaction Lab</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Matari\u0107\n<div class=\"imageTitle\">OpenHMI System for Facilitating Human-Robot Interaction Research</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/2233191/2233191_10820229_1699634402050_Outcome_Images_2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2233191/2233191_10820229_1699634402050_Outcome_Images_2--rgov-800width.jpg\" title=\"Structural Components of the 3D-Printed Blossom Robot\"><img src=\"/por/images/Reports/POR/2023/2233191/2233191_10820229_1699634402050_Outcome_Images_2--rgov-66x44.jpg\" alt=\"Structural Components of the 3D-Printed Blossom Robot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The internal components of the improved Blossom robot. The original design was simplified for ease of assembly (reducing the number of fabricated components from 63 to 20) and for reduced cost (using only laser-cut 3D-printed components).</div>\n<div class=\"imageCredit\">USC Interaction Lab</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Matari\u0107\n<div class=\"imageTitle\">Structural Components of the 3D-Printed Blossom Robot</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2023/2233191/2233191_10820229_1699634445259_Outcome_Images_3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2233191/2233191_10820229_1699634445259_Outcome_Images_3--rgov-800width.jpg\" title=\"Various Exterior Designs of the Blossom Robot\"><img src=\"/por/images/Reports/POR/2023/2233191/2233191_10820229_1699634445259_Outcome_Images_3--rgov-66x44.jpg\" alt=\"Various Exterior Designs of the Blossom Robot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Various hand-crafted Blossom robot designs: detailed documentation and video tutorials were created with the updated open-source software and hardware materials for the OpenHMI platform, enabling researchers to build and customize their robots to meet their various research needs.</div>\n<div class=\"imageCredit\">USC Interaction Lab</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Matari\u0107\n<div class=\"imageTitle\">Various Exterior Designs of the Blossom Robot</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis one-year planning grant supported a project that prepared for a proposal for developing OpenHMI: an open-source, affordable and modular platform for enabling scalable and accessible research and outreach in human-machine interaction (HMI). Human-machine interaction is a broad, cross-cutting area of computing that has shown great potential for supporting health, education, and training of people with diverse needs, along with other applications. HMI is expanding rapidly, and leverages many areas of computing research, including machine vision, machine learning, human activity understanding, affective computing, and others. Such a wide-ranging computing research field depends on significant infrastructure, including software for automatically analyzing human behavior and emotion, hardware for interactions with robots, and data management systems and workflows.\n\n\nResearch into human-machine interaction is currently stifled by the lack of open-source, compatible software and hardware platforms that are accessible, affordable, and appropriate for use with various real-world user populations and replicable real-world studies and data collections. The major goal of this planning grant was to put together a collaborative multi-university team and project that brings together technical experts and community partners who will use co-design and evaluation through community engagement to develop OpenHMI to enable inclusive, accessible and affordable HMI research that includes the development of an experiment planning, pre-registration, and data-sharing component. This infrastructure project would engage community partner leaders with deep connections with traditionally less represented and served research communities, including minority-serving institutions.\n\n\nThe specific outcomes of the project include:\n\n\n1) We designed and conducted on-line computing community surveys, and found that our proposed OpenHMI platform has the potential to make human-machine interaction research more accessible, affordable and customizable.\n\n\n2) We developed the prototype of the messaging architecture between the OpenHMI software and hardware for user demonstration purposes. For software, we developed the messaging architecture to enabled the robot to communicate with the. For hardware, we simplified the robot's open-source hardware design for ease of assembly, reducing the number of fabricated components from 63 to 20 and switching to only laser-cut 3D-printed components. These improvements shorten the robot assembly time and make the robot more affordable and accessible.\n\n\n3) We conducted two community workshops: a) a broadly inclusive community workshop (via Zoom) focusing on HMI researchers with around 30 participants; and b) an in-person community workshop with 15 participants at a minority-serving institution focusing on enabling more accessible HMI research for college students. We found that our openHMI robot is perceived by our workshop participants to be effective, easy-to-follow, engaging, and helpful in supporting them for future HMI research and education.\n\n\n4) We reported the major findings from this project in a full conference paper and submitted it for review to the 14th Symposium on Educational Advances in Artificial Intelligence at the 38th Annual AAAI Conference on Artificial Intelligence.\n\n\n5) We used all the findings and insights from the one-year planning grant to shape and refine our full project plan and proposal for the CRIC grant, submitted in September 2023.\n\n\nIn summary, the intellectual merit of the planning grant includes the technical developments on the OpenHMI software and hardware that have been open-sourced, and the broader impacts include the collected insights from the research community obtained over the two workshops and submitted for publication.\n\n\n\t\t\t\t\tLast Modified: 11/10/2023\n\n\t\t\t\t\tSubmitted by: MajaJMatari\u0107\n"
 }
}