{
 "awd_id": "2231797",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: EAGER: RI: Causal Decision-Making",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2022-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 75000.0,
 "awd_amount": 75000.0,
 "awd_min_amd_letter_date": "2022-08-01",
 "awd_max_amd_letter_date": "2022-08-01",
 "awd_abstract_narration": "Artificial intelligence (AI) plays an increasingly prominent role in society since decisions that were once made by humans are now being delegated to automated systems. These systems are expected to be efficient, robust, explainable, generalizable, and lead to outcomes agreed upon by society. There is a growing understanding that robust decision-making relies on some knowledge of the causal mechanisms underlying the environment. For instance, an intelligent robot has to know the cause and effect relationships in its environment to plan its course of action more robustly; a physician needs to understand the effects of available drugs to design an effective strategy for her patients. The current generation of AI systems responsible for decision-making does not explicitly represent the underlying causal model. This project will build the foundations toward a general framework \u2014 i.e., a set of principles, algorithms, and tools \u2014 for decision-making systems by enriching the traditional AI formalism with causal ingredients for more efficient, robust, and explainable decision-making. The research will plant the seed for a transformation in the decision-making field and have consequences for developing the next generation of AI systems. The research results are expected to have significant impacts on AI foundations and may potentially have broad implications for society as more and more decisions are being delegated to AI systems. The researchers will develop new educational materials and course curricula in causal inference. The researchers will provide research training for graduate students and are committed to continuing to recruit from underrepresented groups. The research team will continue supporting the \u201cCausality in Statistics Education Award\u201d to improve the teaching and learning of modern causal inference tools in statistics and the data sciences.\r\n\r\nThis project is the first step toward the integration of causal inference (CI) and reinforcement learning (RL) into the discipline of causal reinforcement learning (CRL). The idea is to endow an RL agent with an explicit causal model of the environment and new capabilities for interventional and counterfactual reasoning. CRL will open a new family of learning opportunities and challenges that were neither acknowledged nor understood before.  The tasks included in this research include integrating offline and online methods when the agents have different perceptual and actuation capabilities and developing general machinery for counterfactual decision-making, which is more powerful than its standard, interventional counterpart.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jin",
   "pi_last_name": "Tian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jin Tian",
   "pi_email_addr": "jtian@iastate.edu",
   "nsf_id": "000487934",
   "pi_start_date": "2022-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Iowa State University",
  "inst_street_address": "1350 BEARDSHEAR HALL",
  "inst_street_address_2": "515 MORRILL ROAD",
  "inst_city_name": "AMES",
  "inst_state_code": "IA",
  "inst_state_name": "Iowa",
  "inst_phone_num": "5152945225",
  "inst_zip_code": "500112103",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IA04",
  "org_lgl_bus_name": "IOWA STATE UNIVERSITY OF SCIENCE AND TECHNOLOGY",
  "org_prnt_uei_num": "DQDBM7FGJPC5",
  "org_uei_num": "DQDBM7FGJPC5"
 },
 "perf_inst": {
  "perf_inst_name": "Iowa State University",
  "perf_str_addr": "515 MORRILL RD, 1350 BEARDSHEAR HALL",
  "perf_city_name": "AMES",
  "perf_st_code": "IA",
  "perf_st_name": "Iowa",
  "perf_zip_code": "500112105",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7484",
   "pgm_ref_txt": "IIS SPECIAL PROJECTS"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 75000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Artificial intelligence (AI) plays an increasingly prominent role in society since decisions that were once made by humans are now being delegated to automated systems. The current generation of AI systems are almost invariably driven by data, often combined with probabilistic or statistical machinery. However, there is a growing understanding that robust decision-making requires knowledge of the causal mechanisms underlying the environment. For instance, an intelligent robot has to know the cause-and-effect relationships in its environment to plan its course of actions more robustly; and a physician needs to understand the effects of available drugs to design an effective strategy for patients. In this project, we have developed new methods and tools for causal inference.</p>\n<ul>\n<li>Standard causal inference tools in the AI literature require the articulation of causal assumptions in the form of causal diagrams. However, there are many practical settings where the knowledge necessary to specify a causal diagram over all variables is not available, particularly in complex, high-dimensional domains. We have developed a new causal modeling tool called cluster DAGs that allows for the partial specification of relationships among variables based on limited prior knowledge, alleviating the stringent requirement of specifying a full causal diagram. The new tool will allow scientists to represent complex systems in a simplified way, allowing for more relaxed causal inferences when substantive knowledge is largely unavailable and coarse.</li>\n<li>We have developed new methods for estimating the causal effects of a continuous treatment, while the majority of the existing work has focused on binary or categorical treatment variables.</li>\n<li>We have developed new machinery for estimating joint treatment effects by combining data from multiple experimental datasets. Estimating joint treatment effects is critical in many data-intensive domains, including genetics and drug evaluation, but its analysis remains underrepresented compared to the vast literature on single-treatment experiments due to two major challenges: the need for large sample sizes to investigate all possible treatment combinations and the possibility of unsafe or unethical treatment interaction. The work will help data scientists estimate joint treatment effects from multiple experiments in a more principled and efficient manner.</li>\n</ul>\n<p>The results developed in this project will impact a broad range of data-driven disciplines that concern with estimating causal effects from observational data, including artificial intelligence, statistics, economics, and the health and social sciences, providing new tools for scientists to be able to estimate causal effects reliably in practical settings.</p>\n<p>The project has provided research training and opportunities for Ph.D. students, including a student from an underrepresented group. The results of the project have been disseminated through talks and publications in the major AI and machine learning conferences. New educational materials have been developed for teaching a graduate causal inference course.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/30/2023<br>\nModified by: Jin&nbsp;Tian</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nArtificial intelligence (AI) plays an increasingly prominent role in society since decisions that were once made by humans are now being delegated to automated systems. The current generation of AI systems are almost invariably driven by data, often combined with probabilistic or statistical machinery. However, there is a growing understanding that robust decision-making requires knowledge of the causal mechanisms underlying the environment. For instance, an intelligent robot has to know the cause-and-effect relationships in its environment to plan its course of actions more robustly; and a physician needs to understand the effects of available drugs to design an effective strategy for patients. In this project, we have developed new methods and tools for causal inference.\n\nStandard causal inference tools in the AI literature require the articulation of causal assumptions in the form of causal diagrams. However, there are many practical settings where the knowledge necessary to specify a causal diagram over all variables is not available, particularly in complex, high-dimensional domains. We have developed a new causal modeling tool called cluster DAGs that allows for the partial specification of relationships among variables based on limited prior knowledge, alleviating the stringent requirement of specifying a full causal diagram. The new tool will allow scientists to represent complex systems in a simplified way, allowing for more relaxed causal inferences when substantive knowledge is largely unavailable and coarse.\nWe have developed new methods for estimating the causal effects of a continuous treatment, while the majority of the existing work has focused on binary or categorical treatment variables.\nWe have developed new machinery for estimating joint treatment effects by combining data from multiple experimental datasets. Estimating joint treatment effects is critical in many data-intensive domains, including genetics and drug evaluation, but its analysis remains underrepresented compared to the vast literature on single-treatment experiments due to two major challenges: the need for large sample sizes to investigate all possible treatment combinations and the possibility of unsafe or unethical treatment interaction. The work will help data scientists estimate joint treatment effects from multiple experiments in a more principled and efficient manner.\n\n\n\nThe results developed in this project will impact a broad range of data-driven disciplines that concern with estimating causal effects from observational data, including artificial intelligence, statistics, economics, and the health and social sciences, providing new tools for scientists to be able to estimate causal effects reliably in practical settings.\n\n\nThe project has provided research training and opportunities for Ph.D. students, including a student from an underrepresented group. The results of the project have been disseminated through talks and publications in the major AI and machine learning conferences. New educational materials have been developed for teaching a graduate causal inference course.\n\n\n\t\t\t\t\tLast Modified: 12/30/2023\n\n\t\t\t\t\tSubmitted by: JinTian\n"
 }
}