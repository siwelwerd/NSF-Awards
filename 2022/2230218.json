{
 "awd_id": "2230218",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Structural Dynamics Identification Using Motion Estimation and Video Magnification",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032925365",
 "po_email": "jberg@nsf.gov",
 "po_sign_block_name": "Jordan Berg",
 "awd_eff_date": "2022-02-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 376410.0,
 "awd_amount": 184849.0,
 "awd_min_amd_letter_date": "2022-06-13",
 "awd_max_amd_letter_date": "2022-06-13",
 "awd_abstract_narration": "This project aims to explore the use of a non-contact, video camera-based method to identify small motions and dynamic behavior of structures.  This has the potential to help engineers understand complex dynamic behavior of 3D structures, including, for example, wind turbines, bridges, aircraft, ships, and automobiles.  This will help in structural health monitoring, as well as in testing numerical model predictions of deformations of large, complex structures.  Videos can be recorded, and deformations and dynamic behavior distilled using a portable electronic device application (app) developed for a cell phone.  This will permit simplified use of the technology by researchers, design engineers and field inspectors.  The research team will work with high school students to integrate the video sensing technology into their curriculum. The project will also involve female and minority students.\r\n\r\nThe primary research objective of this project is to understand and quantify the relationship between the structural dynamics extracted via camera video motion magnification and the true dynamic motion. The project has the potential to transform the way large-scale experimental modal analysis and three-dimensional (3D) structural dynamics identification is currently performed. The successful completion of the work will lead to a better understanding of vision-based structural dynamic parameter extraction and how the processed data is affected by environmental and operational variabilities.  This work will integrate the phase-based motion estimation technique with 3D digital image correlation and point tracking to achieve an understanding of how two-dimensional camera measurements can be used to extract quantitative 3D motion. The successful outcomes of this project will address the existing knowledge gap between the factors that contaminate the related algorithms and the processed results, while quantifying uncertainty for video-based structural dynamics identification.  The research will generate a systematic understanding of how extracted optical flows are associated with dynamic motions. Achieving a quantitative understanding of how different parameters influence the results for phase-based motion extraction and video magnification will lead to a transformative new approach for non-contact measurement that can impact system identification, validation, and structural health monitoring of various infrastructure systems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zhu",
   "pi_last_name": "Mao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zhu Mao",
   "pi_email_addr": "zmao2@wpi.edu",
   "nsf_id": "000731223",
   "pi_start_date": "2022-06-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Worcester Polytechnic Institute",
  "inst_street_address": "100 INSTITUTE RD",
  "inst_street_address_2": "",
  "inst_city_name": "WORCESTER",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "5088315000",
  "inst_zip_code": "016092280",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "WORCESTER POLYTECHNIC INSTITUTE",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJNQME41NBU4"
 },
 "perf_inst": {
  "perf_inst_name": "Worcester Polytechnic Institute",
  "perf_str_addr": "100 Institute Rd",
  "perf_city_name": "Worcester",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "016092247",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164200",
   "pgm_ele_name": "Special Initiatives"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "030E",
   "pgm_ref_txt": "CONTROL SYSTEMS"
  },
  {
   "pgm_ref_code": "034E",
   "pgm_ref_txt": "Dynamical systems"
  },
  {
   "pgm_ref_code": "8024",
   "pgm_ref_txt": "Complex Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 184849.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"Default\">In addressing the non-contact and full-field aspects of optical sensing and photogrammetry, our investigation delved into the application of phase-based motion magnification for system identification and the extraction of structural dynamics characteristics from videos. The key outcomes of the project encompass:</p>\n<p class=\"Default\">(i) <strong>Quantification of Motion:</strong> We successfully modeled and quantified the magnified pixel displacements in comparison to true motions, as well as the uncertainty.</p>\n<p class=\"Default\">(ii) <strong>Image Enhancement:</strong> Employing two-dimensional Wiener filter, Total Variation Denoising, and advanced edge detection algorithms, such as Holistically Nested Edge Detection, to obtain an enhanced image quality which ensures a more robust performance in serving the dynamics extraction process.</p>\n<p class=\"Default\">(iii) <strong>Automated Processing:</strong> Our project includes the development of a point tracking algorithm by hybridizing adaptive filtering and clustering. This algorithm facilitates the automation of the entire computer-vision-based procedure for extracting the operating deflection shape and conducting experimental modal analysis.</p>\n<p class=\"Default\">(iv) <strong>4-D Volumetric Dynamics:</strong> We extended the state-of-the-art phase-based motion magnification to address 4-D volumetric dynamics, showcasing the extendibility and advancement of non-contact sensing and dynamics extraction.</p>\n<p class=\"Default\">Beyond theoretical outcomes, we collaborated with the Wind Technology Testing Center at the Massachusetts Clean Energy Center. The application of the non-contact dynamics extraction algorithms on utility-scale wind turbine blades allowed us to estimate vibrational modes. The extracted vibrational modes played a pivotal role in guiding sensor placement in conditions where more precise point measurements are required. As part of the broader impact, we developed a web app that implements phase-based motion magnification for general interest. This accessible tool further contributes to the dissemination and practical application of our research outcomes.</p><br>\n<p>\n Last Modified: 01/15/2024<br>\nModified by: Zhu&nbsp;Mao</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn addressing the non-contact and full-field aspects of optical sensing and photogrammetry, our investigation delved into the application of phase-based motion magnification for system identification and the extraction of structural dynamics characteristics from videos. The key outcomes of the project encompass:\n\n\n(i) Quantification of Motion: We successfully modeled and quantified the magnified pixel displacements in comparison to true motions, as well as the uncertainty.\n\n\n(ii) Image Enhancement: Employing two-dimensional Wiener filter, Total Variation Denoising, and advanced edge detection algorithms, such as Holistically Nested Edge Detection, to obtain an enhanced image quality which ensures a more robust performance in serving the dynamics extraction process.\n\n\n(iii) Automated Processing: Our project includes the development of a point tracking algorithm by hybridizing adaptive filtering and clustering. This algorithm facilitates the automation of the entire computer-vision-based procedure for extracting the operating deflection shape and conducting experimental modal analysis.\n\n\n(iv) 4-D Volumetric Dynamics: We extended the state-of-the-art phase-based motion magnification to address 4-D volumetric dynamics, showcasing the extendibility and advancement of non-contact sensing and dynamics extraction.\n\n\nBeyond theoretical outcomes, we collaborated with the Wind Technology Testing Center at the Massachusetts Clean Energy Center. The application of the non-contact dynamics extraction algorithms on utility-scale wind turbine blades allowed us to estimate vibrational modes. The extracted vibrational modes played a pivotal role in guiding sensor placement in conditions where more precise point measurements are required. As part of the broader impact, we developed a web app that implements phase-based motion magnification for general interest. This accessible tool further contributes to the dissemination and practical application of our research outcomes.\t\t\t\t\tLast Modified: 01/15/2024\n\n\t\t\t\t\tSubmitted by: ZhuMao\n"
 }
}