{
 "awd_id": "2151286",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Low latency and ultra high quality video streaming platform for highly immersive virtual reality (VR) experiences",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922174",
 "po_email": "rmehta@nsf.gov",
 "po_sign_block_name": "Rajesh Mehta",
 "awd_eff_date": "2022-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 255511.0,
 "awd_amount": 255511.0,
 "awd_min_amd_letter_date": "2022-08-17",
 "awd_max_amd_letter_date": "2022-11-14",
 "awd_abstract_narration": "The broader impact of this Small Business Innovation Research (SBIR) Phase I project is  to address the technological challenges that limit the wide adoption of virtual and augmented reality in the United States. The proposed solution may enable or improve telemedicine applications, mental health and wellness social support programs, realistic training simulations for defense personnel, workforce development training and science, technology, engineering and mathematics (STEM) teaching solutions, and other applications which benefit from real-time immersive experiences. Current virtual reality (VR) technology uses low-quality video in order to deliver real-time interactions or uses realistic high-quality video that cannot simulate real-time interactions due to high-latency issues. High quality video delivered with low latency (less than 1 second) is the goal of this project. \r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project seeks to develop a virtual reality, image rendering, streaming solution that can manage 360-degree video with ultra-high quality at low latencies. The technical challenges are to overcome the trade-off between video quality and streaming latency. High-quality VR video, such as 360-degree crisp video, would have high latency, rendering the images very slowly. In contrast, low-quality video has low-latency (below 1 second), which means that the images can be rendered much faster. Both cases limit the immersive nature and feel of virtual reality technology because the video quality is insufficient and/or the latency makes it impossible for live virtual interaction. This SBIR project will include architecture design, low latency product developmental research, and prototype testing and validation. The commercialized product may enable companies to offer a fully immersive VR experience leading to more realistic training simulations, educational demonstrations, and real-time, social interactions for health and mental well-being.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Sebasti\u00e1n",
   "pi_last_name": "Amengual",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sebasti\u00e1n Amengual",
   "pi_email_addr": "grants_SA@ybvr.com",
   "nsf_id": "000861708",
   "pi_start_date": "2022-08-17",
   "pi_end_date": "2022-11-14"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Echeita",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Richard Echeita",
   "pi_email_addr": "grants_re@ybvr.com",
   "nsf_id": "000903894",
   "pi_start_date": "2022-11-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "YERBA BUENA VR, INC.",
  "inst_street_address": "810 FALLS POINT CIR",
  "inst_street_address_2": "",
  "inst_city_name": "JOHNS CREEK",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "7702988817",
  "inst_zip_code": "300228481",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "GA07",
  "org_lgl_bus_name": "YERBA BUENA VR, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "YLDSMNLQMR19"
 },
 "perf_inst": {
  "perf_inst_name": "YERBA BUENA VR, INC.",
  "perf_str_addr": "4444 YERBA BUENA AVE",
  "perf_city_name": "SAN JOSE",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "951211052",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "CA19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079E",
   "pgm_ref_txt": "VISUALIZATION & VIRTUAL DESIGN"
  },
  {
   "pgm_ref_code": "8031",
   "pgm_ref_txt": "Education Products"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 255511.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In our pursuit of an immersive 8K experience with under 2 seconds of latency, we faced several challenges: processing high resolution videos (8K 360-videos at 60 frames per second), optimizing latency, and enhancing video quality. Our primary objective was to create a seamless and captivating viewing experience for users, ensuring they could fully immerse themselves in the content without any noticeable delays.</p>\n<p>To efficiently process large video files, we sought formats and protocols that allowed us to manage large 360-degree videos, specifically 8K resolution at 60 frames per second. Our first step involved converting the camera-provided feeds into a single equirectangular video format. This conversion was achieved using SDI inputs to feed Voysys, the software we selected for the stitching process.</p>\n<p>In order to preserve video quality during the processing of the 8K equirectangular video, we implemented a technique called FOV (Field of View) optimization. This technique involved preserving the maximum quality of the video in the direction the user was looking while optimizing the rest of the video. By reducing the total frame size, we saved bandwidth and processing power. To achieve FOV optimization, we utilized the format Adaptive Pixel Perfect Progressive (AP3) (image 2), a proprietary format developed by YBVR. Since the AP3 format does not cover the entire original video surface, we needed to create four AP3-formatted videos to cover a full 360-degree video.</p>\n<p>The second challenge was to find a distribution protocol that could optimize latency while preserving video quality, and also support a potentially large number of users. After careful consideration, we selected RTMP (Real-Time Messaging Protocol) as the distribution protocol. RTMP is widely supported and enables high-resolution video streaming. However, this was only part of the challenge.</p>\n<p>&nbsp;The third challenge involved the playback of the content on mobile devices. Our goal was not only to support high-quality 360-degree video playback using the AP3 format but also to apply FOV optimization based on the user's behavior seamlessly. To achieve this, we developed a gaze prediction mechanism capable of anticipating the user's direction of focus and triggering a viewport change accordingly. Furthermore, we implemented the play2 mechanism defined by Adobe's RTMP, which facilitated a seamless transition between multiple RTMP streams using the timestamps of each stream.</p>\n<p>Despite making significant progress in achieving our goals, we encountered limitations related to the current capacities of GPUs. These limitations restricted the number of processes that could be simultaneously performed on a single machine for generating the AP3 streams. To overcome these limitations, we explored alternative approaches such as distributed processing and alternative hardware configurations.</p>\n<p>In conclusion, our focus on processing large videos, optimizing latency, and enhancing video quality has yielded impressive results in our pursuit of an immersive 8K experience with minimal latency. By leveraging cutting-edge technologies, meticulous optimization, and a deep understanding of video processing, we have paved the way for consuming immersive content with low latency and opened new opportunities in fields such as education. While challenges and limitations persist, we remain committed to pushing the boundaries of technology and exploring innovative solutions to further improve latency and deliver an unparalleled immersive experience for all viewers.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/14/2023<br>\n\t\t\t\t\tModified by: Richard&nbsp;Echeita</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/2151286/2151286_10827271_1689324508693_1_nsf_outcomes_quality_comparison--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2151286/2151286_10827271_1689324508693_1_nsf_outcomes_quality_comparison--rgov-800width.jpg\" title=\"Quality Comparison\"><img src=\"/por/images/Reports/POR/2023/2151286/2151286_10827271_1689324508693_1_nsf_outcomes_quality_comparison--rgov-66x44.jpg\" alt=\"Quality Comparison\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Comparison between viewport not optimized to the FOV (left) and optimized (right).</div>\n<div class=\"imageCredit\">YBVR</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Richard&nbsp;Echeita</div>\n<div class=\"imageTitle\">Quality Comparison</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/2151286/2151286_10827271_1689324556721_2_nsf_outcomes_ap3_format--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2151286/2151286_10827271_1689324556721_2_nsf_outcomes_ap3_format--rgov-800width.jpg\" title=\"Format\"><img src=\"/por/images/Reports/POR/2023/2151286/2151286_10827271_1689324556721_2_nsf_outcomes_ap3_format--rgov-66x44.jpg\" alt=\"Format\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Guidelines of the AP3 format</div>\n<div class=\"imageCredit\">YBVR</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Richard&nbsp;Echeita</div>\n<div class=\"imageTitle\">Format</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/2151286/2151286_10827271_1689324609524_3_nsf_outcomes_ap3_example--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/2151286/2151286_10827271_1689324609524_3_nsf_outcomes_ap3_example--rgov-800width.jpg\" title=\"Example\"><img src=\"/por/images/Reports/POR/2023/2151286/2151286_10827271_1689324609524_3_nsf_outcomes_ap3_example--rgov-66x44.jpg\" alt=\"Example\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Example of a video frame processed with the AP3 format.</div>\n<div class=\"imageCredit\">YBVR</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Richard&nbsp;Echeita</div>\n<div class=\"imageTitle\">Example</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nIn our pursuit of an immersive 8K experience with under 2 seconds of latency, we faced several challenges: processing high resolution videos (8K 360-videos at 60 frames per second), optimizing latency, and enhancing video quality. Our primary objective was to create a seamless and captivating viewing experience for users, ensuring they could fully immerse themselves in the content without any noticeable delays.\n\nTo efficiently process large video files, we sought formats and protocols that allowed us to manage large 360-degree videos, specifically 8K resolution at 60 frames per second. Our first step involved converting the camera-provided feeds into a single equirectangular video format. This conversion was achieved using SDI inputs to feed Voysys, the software we selected for the stitching process.\n\nIn order to preserve video quality during the processing of the 8K equirectangular video, we implemented a technique called FOV (Field of View) optimization. This technique involved preserving the maximum quality of the video in the direction the user was looking while optimizing the rest of the video. By reducing the total frame size, we saved bandwidth and processing power. To achieve FOV optimization, we utilized the format Adaptive Pixel Perfect Progressive (AP3) (image 2), a proprietary format developed by YBVR. Since the AP3 format does not cover the entire original video surface, we needed to create four AP3-formatted videos to cover a full 360-degree video.\n\nThe second challenge was to find a distribution protocol that could optimize latency while preserving video quality, and also support a potentially large number of users. After careful consideration, we selected RTMP (Real-Time Messaging Protocol) as the distribution protocol. RTMP is widely supported and enables high-resolution video streaming. However, this was only part of the challenge.\n\n The third challenge involved the playback of the content on mobile devices. Our goal was not only to support high-quality 360-degree video playback using the AP3 format but also to apply FOV optimization based on the user's behavior seamlessly. To achieve this, we developed a gaze prediction mechanism capable of anticipating the user's direction of focus and triggering a viewport change accordingly. Furthermore, we implemented the play2 mechanism defined by Adobe's RTMP, which facilitated a seamless transition between multiple RTMP streams using the timestamps of each stream.\n\nDespite making significant progress in achieving our goals, we encountered limitations related to the current capacities of GPUs. These limitations restricted the number of processes that could be simultaneously performed on a single machine for generating the AP3 streams. To overcome these limitations, we explored alternative approaches such as distributed processing and alternative hardware configurations.\n\nIn conclusion, our focus on processing large videos, optimizing latency, and enhancing video quality has yielded impressive results in our pursuit of an immersive 8K experience with minimal latency. By leveraging cutting-edge technologies, meticulous optimization, and a deep understanding of video processing, we have paved the way for consuming immersive content with low latency and opened new opportunities in fields such as education. While challenges and limitations persist, we remain committed to pushing the boundaries of technology and exploring innovative solutions to further improve latency and deliver an unparalleled immersive experience for all viewers.\n\n\t\t\t\t\tLast Modified: 07/14/2023\n\n\t\t\t\t\tSubmitted by: Richard Echeita"
 }
}