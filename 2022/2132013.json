{
 "awd_id": "2132013",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RII Track-4:NSF: Relational Algebra on Heterogeneous Extreme-scale Systems",
 "cfda_num": "47.083",
 "org_code": "01060100",
 "po_phone": "7032928246",
 "po_email": "pbentzvi@nsf.gov",
 "po_sign_block_name": "Pinhas Ben-Tzvi",
 "awd_eff_date": "2022-02-01",
 "awd_exp_date": "2024-01-31",
 "tot_intn_awd_amt": 264755.0,
 "awd_amount": 226540.0,
 "awd_min_amd_letter_date": "2022-01-27",
 "awd_max_amd_letter_date": "2024-02-28",
 "awd_abstract_narration": "Relational algebra (RA) forms a basis of primitive operations such as join, projection, aggregation, and selection that transform one or more input relations (i.e., database tables) into an output relation. It can be used to implement algorithms in graph analytics, deductive databases, program analysis, satisfiability, constraint solving, and machine learning. High-performance RA has the potential to extract vast untapped parallelism from critical applications. Despite this great expressive power, investigation of RA within the HPC community has been limited and significant advances are needed to scale RA on next-generation HPC systems. This work will advance the state of art by developing novel algorithms for massively parallel relational algebra on exascale HPC systems such as the Aurora supercomputer at Argonne National Laboratory (ANL). In the context of heterogeneous systems (i.e., those using multiple distinct compute paradigms in concert, like Aurora), this work will address key scaling concerns including workload decomposition, load balancing, communication, and I/O. This work will establish foundations for long-term collaboration with ANL towards the development of foundational theory, practical implementations, and rigorous evaluations of parallel RA. The project will support a graduate student from an underrepresented minority and lay groundwork for a high-impact dissertation.\r\n\r\nOwing to increasing inter-network data-movement costs and power constraints, exascale systems are increasingly shifting toward heterogeneous computing environments, with CPUs being coupled with coprocessors such as GPUs. Aurora Supercomputer at Argonne national lab is an example of a leadership-class heterogeneous system; every Aurora node is equipped with multiple GPU co-processors. This work will lead to the development of parallel algorithms for RA, in the context of Aurora specifically and heterogeneous systems more broadly, over three key phases: (1) development of core RA algorithms for multi-GPU nodes; (2) extending these algorithms to supercomputers with many nodes, like Aurora; (3) extending the whole compute process to include scalable parallel IO. First, phase (1) will require investigating three technical approaches for the RA itself, extending them to multi-GPU nodes: (i) radix-hash, (ii) sort-merge, and (iii) nested-loop. Second, in phase (2) the work will investigate inter-node balancing of RA primitives and techniques to minimize data movement across multi-node systems. Finally, in phase (3) a customized parallel IO system and storage model will be developed that will take into account the deepening memory hierarchy available on modern supercomputers. These innovations across three phases will be evaluated using the ALCF supercomputer Aurora, using three application domains: graph mining, static program analysis, and deductive databases for scientific simulations. With exascale insight, this research is poised to create a new generation of applications based on relational algebra.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "O/D",
 "org_dir_long_name": "Office Of The Director",
 "div_abbr": "OIA",
 "org_div_long_name": "OIA-Office of Integrative Activities",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sidharth",
   "pi_last_name": "kumar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sidharth kumar",
   "pi_email_addr": "sidharth@uic.edu",
   "nsf_id": "000807599",
   "pi_start_date": "2022-01-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Alabama at Birmingham",
  "inst_street_address": "701 S 20TH STREET",
  "inst_street_address_2": "",
  "inst_city_name": "BIRMINGHAM",
  "inst_state_code": "AL",
  "inst_state_name": "Alabama",
  "inst_phone_num": "2059345266",
  "inst_zip_code": "352940001",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "AL07",
  "org_lgl_bus_name": "UNIVERSITY OF ALABAMA AT BIRMINGHAM",
  "org_prnt_uei_num": "",
  "org_uei_num": "YND4PLMC9AN7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Alabama at Birmingham",
  "perf_str_addr": "AB 1170",
  "perf_city_name": "Birmingham",
  "perf_st_code": "AL",
  "perf_st_name": "Alabama",
  "perf_zip_code": "352940001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "AL07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "196Y00",
   "pgm_ele_name": "EPSCoR RII: EPSCoR Research Fe"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 226539.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"font-claude-message  pr-4  md:pr-9  relative  overflow-x-auto  leading-[1.65rem]  [&amp;_pre&gt;div]:bg-bg-300  [&amp;_pre]:-mr-4  md:[&amp;_pre]:-mr-9\">\n<div class=\"grid grid-col-1 gap-2.5 [&amp;_&gt;_*]:min-w-0\">\n<p class=\"whitespace-pre-wrap break-words\">This project had two primary objectives: (1) cultivate collaborations with Argonne National Laboratory, providing the PI and students with opportunities to utilize state-of-the-art high-performance supercomputers, and (2) develop innovative algorithms for efficient implementation of iterative relational algebra (RA) on graphics processing units (GPUs). The project successfully achieved both of these goals.</p>\n<p class=\"whitespace-pre-wrap break-words\"><br />The collaboration with Argonne National Lab yielded valuable near-term and long-term partnerships. The PI and a group of three students gained hands-on experience working in a cutting-edge laboratory environment. This research led to multiple peer-reviewed publications, showcasing the project's scientific value and impact. Moreover, it fostered new collaborations and relationships that are expected to continue producing fruitful results in the future.</p>\n<p class=\"whitespace-pre-wrap break-words\"><br />The research conducted under this grant has laid the groundwork for a high-performance implementation of iterative RA on GPUs, which is essential for accelerating analytics in declarative logic programming languages like Datalog. Such languages are particularly useful for relational data analytics across various domains, including graph mining, program analysis, and social media analytics. Key outcomes and findings include: (1) The development of an optimized GPU-based hash table for relational data, enabling efficient hash joins between relations on the GPU. (2) The fusion of RA operations, such as joins and projections, to enhance memory access and computational efficiency, reducing time and memory consumption for iterated joins by up to 5%. (3) Performance evaluations demonstrating speedups of up to 10.8x compared to cuDF (a GPU dataframe library) and 3.9x compared to Souffl&eacute; (a state-of-the-art CPU-based Datalog engine) for transitive closure computation. These innovations constitute significant steps towards developing a comprehensive GPU-based Datalog engine capable of extracting massive data parallelism for relational analytics applications. The techniques developed can be generalized to other finite-domain Datalog programs beyond the transitive closure use case demonstrated in this project.</p>\n<p class=\"whitespace-pre-wrap break-words\"><br />The project also resulted in the development of novel algorithms for non-uniform all-to-all data exchanges, a crucial component in implementing parallel multi-node iterative relational algebra. Non-uniform all-to-all plays a vital role in materializing the new tuples generated at each iteration. The research team introduced two innovative algorithms: padded Bruck and two-layer Bruck. These novel approaches significantly enhanced the performance of all-to-all algorithms, surpassing the efficiency of vendor-optimized implementations. This technological advancement paves the way for the implementation of parallel iterative relational algebra on multi-GPU systems. By enabling faster and more efficient data exchanges across multiple nodes, these algorithms contribute to the scalability and performance of relational algebra operations on large-scale datasets.</p>\n<p class=\"whitespace-pre-wrap break-words\"><br />The broader impacts of this project include advancing the use of modern GPU architectures for high-performance declarative programming and data analytics, enabling more scalable implementations of relational algorithms on larger datasets. By making these powerful programming paradigms more accessible and efficient, this research can accelerate data-driven discoveries and applications across various scientific domains. In conclusion, this work made substantial progress on core components necessary for leveraging GPUs in iterative relational algebra for logic programming languages. The promising results obtained encourage further research on unified GPU-based declarative engines to democratize high-performance relational analytics.</p>\n</div>\n</div><br>\n<p>\n Last Modified: 05/23/2024<br>\nModified by: Sidharth&nbsp;Kumar</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\nThis project had two primary objectives: (1) cultivate collaborations with Argonne National Laboratory, providing the PI and students with opportunities to utilize state-of-the-art high-performance supercomputers, and (2) develop innovative algorithms for efficient implementation of iterative relational algebra (RA) on graphics processing units (GPUs). The project successfully achieved both of these goals.\n\n\n\nThe collaboration with Argonne National Lab yielded valuable near-term and long-term partnerships. The PI and a group of three students gained hands-on experience working in a cutting-edge laboratory environment. This research led to multiple peer-reviewed publications, showcasing the project's scientific value and impact. Moreover, it fostered new collaborations and relationships that are expected to continue producing fruitful results in the future.\n\n\n\nThe research conducted under this grant has laid the groundwork for a high-performance implementation of iterative RA on GPUs, which is essential for accelerating analytics in declarative logic programming languages like Datalog. Such languages are particularly useful for relational data analytics across various domains, including graph mining, program analysis, and social media analytics. Key outcomes and findings include: (1) The development of an optimized GPU-based hash table for relational data, enabling efficient hash joins between relations on the GPU. (2) The fusion of RA operations, such as joins and projections, to enhance memory access and computational efficiency, reducing time and memory consumption for iterated joins by up to 5%. (3) Performance evaluations demonstrating speedups of up to 10.8x compared to cuDF (a GPU dataframe library) and 3.9x compared to Souffl (a state-of-the-art CPU-based Datalog engine) for transitive closure computation. These innovations constitute significant steps towards developing a comprehensive GPU-based Datalog engine capable of extracting massive data parallelism for relational analytics applications. The techniques developed can be generalized to other finite-domain Datalog programs beyond the transitive closure use case demonstrated in this project.\n\n\n\nThe project also resulted in the development of novel algorithms for non-uniform all-to-all data exchanges, a crucial component in implementing parallel multi-node iterative relational algebra. Non-uniform all-to-all plays a vital role in materializing the new tuples generated at each iteration. The research team introduced two innovative algorithms: padded Bruck and two-layer Bruck. These novel approaches significantly enhanced the performance of all-to-all algorithms, surpassing the efficiency of vendor-optimized implementations. This technological advancement paves the way for the implementation of parallel iterative relational algebra on multi-GPU systems. By enabling faster and more efficient data exchanges across multiple nodes, these algorithms contribute to the scalability and performance of relational algebra operations on large-scale datasets.\n\n\n\nThe broader impacts of this project include advancing the use of modern GPU architectures for high-performance declarative programming and data analytics, enabling more scalable implementations of relational algorithms on larger datasets. By making these powerful programming paradigms more accessible and efficient, this research can accelerate data-driven discoveries and applications across various scientific domains. In conclusion, this work made substantial progress on core components necessary for leveraging GPUs in iterative relational algebra for logic programming languages. The promising results obtained encourage further research on unified GPU-based declarative engines to democratize high-performance relational analytics.\n\n\t\t\t\t\tLast Modified: 05/23/2024\n\n\t\t\t\t\tSubmitted by: SidharthKumar\n"
 }
}