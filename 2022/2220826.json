{
 "awd_id": "2220826",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF21 DIBBs: EI: Virtual Data Collaboratory: A Regional Cyberinfrastructure for Collaborative Data Intensive Science",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032927092",
 "po_email": "alsuarez@nsf.gov",
 "po_sign_block_name": "Alejandro Suarez",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 4000000.0,
 "awd_amount": 1540483.0,
 "awd_min_amd_letter_date": "2022-02-24",
 "awd_max_amd_letter_date": "2022-03-31",
 "awd_abstract_narration": "This project develops a virtual data collaboratory that can be accessed by researchers, educators, and entrepreneurs across institutional and geographic boundaries, fostering community engagement and accelerating interdisciplinary research.  A federated data system is created, using existing components and building upon existing cyberinfrastructure and resources in New Jersey and Pennsylvania.  Seven universities are directly involved (the three Rutgers University campuses, Pennsylvania State University, the University of Pennsylvania, the University of Pittsburgh, Drexel University, Temple University, and the City University of New York); indirectly, other regional schools served by the New Jersey and Pennsylvania high-speed networks also participate.  The system has applicability to a several science and engineering domains, such as protein-DNA interaction and smart cities, and is likely to be extensible to other domains.  The cyberinfrastructure is to be integrated into both graduate and undergraduate programs across several institutions.   \r\n\r\nThe end product is a fully-developed system for collaborative use by the research and education community.   A data management and sharing system is constructed, based largely on commercial off-the-shelf technology.  The storage system is based on the Hadoop Distributed File System (HDFS), a Java-based file system providing scalable and reliable data storage, designed to span large clusters of commodity servers.  The Fedora and VIVO object-based storage systems are used, enabling linked data approaches.  The system will be integrated with existing research data repositories, such as the Ocean Observatories Initiative and Protein Data Bank repositories.  Regional high-performance computing and network infrastructure is leveraged, including New Jersey's Regional Education and Research Network (NJEdge), Pennsylvania's Keystone Initiative for Network Based Education and Research (KINBER), the Extreme Science and Engineering Discovery Environment (XSEDE) computing capabilities, Open Science Grid, and other NSF Campus Cyberinfrastructure investments.  The project also develops a custom site federation and data services layer; the data services layer provides services for data linking, search, and sharing; coupling to computation, analytics, and visualization; mechanisms to attach unique Digital Object Identifiers (DOIs), archive data, and broadly publish to internal and wider audiences; and manage the long-term data lifecycle, ensuring immutable and authentic data and reproducible research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ivan",
   "pi_last_name": "Rodero",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ivan Rodero",
   "pi_email_addr": "ivan.rodero@utah.edu",
   "nsf_id": "000631333",
   "pi_start_date": "2022-02-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841128930",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8048",
   "pgm_ref_txt": "Data Infrstr Bldg Blocks-DIBBs"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 1540483.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Virtual Data Collaboratory (VDC) is a federated data cyberinfrastructure that drives data-intensive, interdisciplinary, and collaborative research and enables data-driven science and engineering discoveries. VDC accomplishes this goal by providing seamless access to data and data services and tools to researchers, educators, and entrepreneurs across a broad range of disciplines, scientific domains, and institutional and geographic boundaries. In addition to enabling researchers to advance research frontiers across multiple disciplines, VDC also focuses on (1) training the next generation of scientists with deep disciplinary expertise and a high degree of competence in leveraging data, cyberinfrastructure, and tools to address research problems, and (2) helping data scientists and engineers develop and apply advanced federated data management and analysis tools to high impact scientific applications.</p>\n<p>The VDC architecture design is based on a loosely coupled core comprising hubs that enable operators to maintain the VDC with reduced overhead without sacrificing features. It lets researchers provision frameworks (e.g., Jupyter-based notebooks) for big data and machine learning services that can run either locally at a specific hub or in a distributed fashion across the data collaboratory. Scaling out the core by adding more sites, connecting them with existing cyber-infrastructure such as Open Science Grid and Open Storage Network, and leveraging commercial cloud providers (e.g., CloudBank) is part of the design. Multiple VDC sites have completed the deployment of the computational, storage, and network infrastructure.</p>\n<p>The VDC data services provide a repository for storing, discovering, and accessing (meta)data objects. VDC also provides a user portal that enables users to create projects, register data repositories, and upload, store, and access data in the repository. Specifically, the user portal allows users (any researcher, anywhere) to search for and access data. In addition, the VDC data services enhance the reusability of data and support collaboration and interdisciplinary data use across traditionally siloed data repositories to improve cooperation and advance FAIR principles using data repository standards, such as linked data and persistent identifiers.</p>\n<p>The VDC advanced federated data management and analysis tools leverage existing cyberinfrastructure resources and services, such as those provided by PATh/OSG, OSDF, ACCESS, and commercial cloud services, enabling researchers to seamlessly run workflows on and accelerate scientific discovery by reducing data movement overhead and streamlining computing and data resources. Specifically, VDC delivers core data services and an integrated middleware with a programmatic software stack that includes a RESTful API, Python library, and command-line and graphical interfaces, as well as other support modules such as an authentication and authorization infrastructure and an application catalog.</p>\n<p>In addition to several research publications and services, VDC has supported impactful scientific use cases using data facilities, including:&nbsp;</p>\n<p>(1)&nbsp;&nbsp;&nbsp;Geosciences: While major scientific facilities provide instrumentations and reliable and pervasive access to the data and products, users typically have to download the data of interest and process them, usually employing local resources. Consequently, transforming these data and products into insights requires local access to powerful computing, storage, and networking resources, which significantly limits the impact of the data, especially for researchers, educators, and students without access to such capabilities. This use case enables data-driven end-to-end workflows that combine data from geoscience facilities and can leverage computing and networking resources that are part of the national cyberinfrastructure. In addition, VDC is used for automated data sharing, processing, and delivery based on data subscription and data-driven workflows from facilities such as the EarthScope Consortium; and&nbsp;</p>\n<p>(2)&nbsp;&nbsp;&nbsp;Bioinformatics: Collaborative assembly, integration, and analyses of multiple data sets of protein-nucleic acid complexes derived from the Protein Data Bank - an archival data resource for all experimentally derived biological macromolecules and their complexes, the Protein Nucleic Acid Database - a specialized data resource containing information about nucleic acid containing structures, and related sources. This use case establishes, uses, and evaluates shared data and computational infrastructure, complete with computational workflows for documenting, comparing, and reproducing computational analyses and predicting protein nucleic acid complexes and interfaces.</p>\n<p>The VDC project has resulted in a functional system that has been tested at the pre-production level with various configurations and different scientifically important (and societally impactful) workflows. VDC has also provided resources for educators and students beyond the participating institutions. The unique VDC education programs have focused on data and have included workshops for high school students. The latter have exposed high-school students to cloud-based analytics platforms and Machine Learning methods and technologies. Interactive instructional materials were provided using widely adopted tools such as Jupyter Notebooks supported by the VDC software stack and use cases. The online educational modules developed by the project are available for all workshops, including those targeting high school, undergraduate, and graduate students, educators, and early career researchers. VDC also led awareness campaigns of research computing and data management best practices, tools, and resources for early career researchers, faculty, postdocs, and graduate students. More information is available at datacollaboratory.org.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/10/2023<br>\n\t\t\t\t\tModified by: Ivan&nbsp;Rodero</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe Virtual Data Collaboratory (VDC) is a federated data cyberinfrastructure that drives data-intensive, interdisciplinary, and collaborative research and enables data-driven science and engineering discoveries. VDC accomplishes this goal by providing seamless access to data and data services and tools to researchers, educators, and entrepreneurs across a broad range of disciplines, scientific domains, and institutional and geographic boundaries. In addition to enabling researchers to advance research frontiers across multiple disciplines, VDC also focuses on (1) training the next generation of scientists with deep disciplinary expertise and a high degree of competence in leveraging data, cyberinfrastructure, and tools to address research problems, and (2) helping data scientists and engineers develop and apply advanced federated data management and analysis tools to high impact scientific applications.\n\nThe VDC architecture design is based on a loosely coupled core comprising hubs that enable operators to maintain the VDC with reduced overhead without sacrificing features. It lets researchers provision frameworks (e.g., Jupyter-based notebooks) for big data and machine learning services that can run either locally at a specific hub or in a distributed fashion across the data collaboratory. Scaling out the core by adding more sites, connecting them with existing cyber-infrastructure such as Open Science Grid and Open Storage Network, and leveraging commercial cloud providers (e.g., CloudBank) is part of the design. Multiple VDC sites have completed the deployment of the computational, storage, and network infrastructure.\n\nThe VDC data services provide a repository for storing, discovering, and accessing (meta)data objects. VDC also provides a user portal that enables users to create projects, register data repositories, and upload, store, and access data in the repository. Specifically, the user portal allows users (any researcher, anywhere) to search for and access data. In addition, the VDC data services enhance the reusability of data and support collaboration and interdisciplinary data use across traditionally siloed data repositories to improve cooperation and advance FAIR principles using data repository standards, such as linked data and persistent identifiers.\n\nThe VDC advanced federated data management and analysis tools leverage existing cyberinfrastructure resources and services, such as those provided by PATh/OSG, OSDF, ACCESS, and commercial cloud services, enabling researchers to seamlessly run workflows on and accelerate scientific discovery by reducing data movement overhead and streamlining computing and data resources. Specifically, VDC delivers core data services and an integrated middleware with a programmatic software stack that includes a RESTful API, Python library, and command-line and graphical interfaces, as well as other support modules such as an authentication and authorization infrastructure and an application catalog.\n\nIn addition to several research publications and services, VDC has supported impactful scientific use cases using data facilities, including: \n\n(1)   Geosciences: While major scientific facilities provide instrumentations and reliable and pervasive access to the data and products, users typically have to download the data of interest and process them, usually employing local resources. Consequently, transforming these data and products into insights requires local access to powerful computing, storage, and networking resources, which significantly limits the impact of the data, especially for researchers, educators, and students without access to such capabilities. This use case enables data-driven end-to-end workflows that combine data from geoscience facilities and can leverage computing and networking resources that are part of the national cyberinfrastructure. In addition, VDC is used for automated data sharing, processing, and delivery based on data subscription and data-driven workflows from facilities such as the EarthScope Consortium; and \n\n(2)   Bioinformatics: Collaborative assembly, integration, and analyses of multiple data sets of protein-nucleic acid complexes derived from the Protein Data Bank - an archival data resource for all experimentally derived biological macromolecules and their complexes, the Protein Nucleic Acid Database - a specialized data resource containing information about nucleic acid containing structures, and related sources. This use case establishes, uses, and evaluates shared data and computational infrastructure, complete with computational workflows for documenting, comparing, and reproducing computational analyses and predicting protein nucleic acid complexes and interfaces.\n\nThe VDC project has resulted in a functional system that has been tested at the pre-production level with various configurations and different scientifically important (and societally impactful) workflows. VDC has also provided resources for educators and students beyond the participating institutions. The unique VDC education programs have focused on data and have included workshops for high school students. The latter have exposed high-school students to cloud-based analytics platforms and Machine Learning methods and technologies. Interactive instructional materials were provided using widely adopted tools such as Jupyter Notebooks supported by the VDC software stack and use cases. The online educational modules developed by the project are available for all workshops, including those targeting high school, undergraduate, and graduate students, educators, and early career researchers. VDC also led awareness campaigns of research computing and data management best practices, tools, and resources for early career researchers, faculty, postdocs, and graduate students. More information is available at datacollaboratory.org.\n\n \n\n\t\t\t\t\tLast Modified: 04/10/2023\n\n\t\t\t\t\tSubmitted by: Ivan Rodero"
 }
}