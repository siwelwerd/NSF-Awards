{
 "awd_id": "2210689",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Theoretical and Algorithmic Foundations of Variational Bayesian Inference",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2022-07-01",
 "awd_exp_date": "2025-09-30",
 "tot_intn_awd_amt": 199338.0,
 "awd_amount": 199338.0,
 "awd_min_amd_letter_date": "2022-06-14",
 "awd_max_amd_letter_date": "2025-01-14",
 "awd_abstract_narration": "Spectacular advances in data acquisition, processing and storage techniques offer modern-day statisticians a unique opportunity to analyze large and complex datasets of unprecedented richness which arise in many scientific investigations and in studies in the social and economic fields.  Bayesian inference, which combines prior knowledge and data information into a posterior distribution, provides a popular paradigm for probabilistic modeling of complex multi-level datasets and for performing associated inferential or predictive tasks in a principled fashion. For most practical problems, computing the posterior probabilities require numerical approximations; to that end, sampling-based approaches such as Markov chain Monte Carlo and deterministic approximations have both received widespread attention. Among deterministic approaches based on optimization, variational approximations, also commonly referred to as variational inference, is highly popular due to its scalability to large datasets. Through this project, the investigators will explore statistical and algorithmic properties of popular variational procedures and develop new methodology and computational tools grounded on a strong theoretical foundation. The results are targeted to empower practitioners with a better understanding of situations where variational inference is likely to be successful and where potential pitfalls exist. The research will be disseminated through articles and talks at prominent outlets. Additionally, software packages for the methods developed will be made available publicly. The investigators are committed to enhancing the pedagogical component of the proposal through advising students and developing graduate and undergraduate topic courses at their respective institutions.\r\n\r\nMotivated by the increasing need to mitigate scalability issues in Bayesian computation, variational inference has tremendously grown in popularity over the last two decades as an approximate Bayesian computational technique. Despite the proven empirical successes of variational inference in large complex data domains, systematic investigations into its statistical properties have commenced only recently. Through this project, the investigators will pose a number of foundational questions to address theoretical challenges in understanding and explaining the great empirical success of variational approximations in parameter estimation, statistical inference, and model selection, coupled with applications in novel domains. The investigators will also develop general purpose sufficient conditions to certify convergence of popularly used variational algorithms. The theoretical development will employ tools from dynamical systems, functional optimization, and optimal transport, leading to a unified treatment of statistical and algorithmic aspects of variational inference. In light of this new theory, the investigators will propose modifications to existing algorithms with certifiably better convergence behaviors.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anirban",
   "pi_last_name": "Bhattacharya",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anirban Bhattacharya",
   "pi_email_addr": "anirbanb@stat.tamu.edu",
   "nsf_id": "000655820",
   "pi_start_date": "2022-06-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Debdeep",
   "pi_last_name": "Pati",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Debdeep Pati",
   "pi_email_addr": "dpati2@wisc.edu",
   "nsf_id": "000653196",
   "pi_start_date": "2022-06-14",
   "pi_end_date": "2025-01-14"
  }
 ],
 "inst": {
  "inst_name": "Texas A&M University",
  "inst_street_address": "400 HARVEY MITCHELL PKY S STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778454375",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A & M UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JF6XLNB4CDJ5"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M University",
  "perf_str_addr": "3143 TAMU",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433143",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 199338.0
  }
 ],
 "por": null
}