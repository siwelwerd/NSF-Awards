{
 "awd_id": "2245674",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Scalable Computational Methods for Large-Scale Stochastic Optimization under High-Dimensional Uncertainty",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922113",
 "po_email": "ygorb@nsf.gov",
 "po_sign_block_name": "Yuliya Gorb",
 "awd_eff_date": "2022-09-01",
 "awd_exp_date": "2024-08-31",
 "tot_intn_awd_amt": 310000.0,
 "awd_amount": 235622.0,
 "awd_min_amd_letter_date": "2022-09-22",
 "awd_max_amd_letter_date": "2023-02-10",
 "awd_abstract_narration": "Large-scale simulation in computational science and engineering is often carried out not only to obtain insight about a system, but also as a basis for decision-making. When the decision variables represent the design or control of an engineered or natural system, and the system is governed by partial differential equations (PDEs) with uncertain input due to lack of knowledge or intrinsic variability, the task of determining the optimal design or control leads to a PDE-constrained stochastic optimization problem. Such problems abound across all areas of science and engineering. Examples include optimal control of subsurface flows, plasma fusion reactors, and chemical and materials processes; optimal structural design of aerospace, automotive, and civil infrastructure systems; and shape, layout, or topology optimization of biomedical, electronic, and nano-structured devices. There are several critical challenges in solving such problems including high dimensionality stemming from uncertainty and/or optimization variable spaces, and the need to solve large-scale PDEs with numerous  samples of the uncertain parameters. This project will develop, analyze, and implement scalable computational methods to make tractable the solution of large-scale PDE-constrained stochastic optimization problems under high-dimensional uncertainty. These methods will be applied to subsurface flow problems with societal impact; software will be developed and disseminated widely in open source form. Graduate students will be involved and will receive interdisciplinary training. \r\n\r\nThis project exploits the intrinsic structure of the stochastic optimization problems--in particular the intrinsic low dimensionality, smoothness, and geometry of the random parameter-to-objective map. Specifically, the components of the research include: (1) Analysis of the rank or spectrum decay of the Hessian of this map to prove intrinsic low-dimensionality for several classical stochastic PDE-constrained optimization problems. (2) Extension of local quadratic approximation-based stochastic optimization to that based on approximation of the Hessian as a translation invariant operator, higher order Taylor approximation, and multi-point Taylor approximation with mixture models. (3) Application to a specific large-scale and challenging problem of optimal flow control in a subsurface porous medium with a random permeability field. The methods developed in this project will apply to a wide class of PDE-constrained stochastic optimization problems. To make the methods accessible to broader communities and allow stochastic optimization specialists to prototype new algorithms and quickly run experiments, a Python library, SOUPy (Stochastic Optimization under high-dimensional Uncertainty in Python), will be implemented and released. Users will be able to rapidly prototype new PDE models and objective functions, as well as quickly implement new algorithms, conduct numerical experiments, and solve challenging problems in new domains in SOUPy.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peng",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Peng Chen",
   "pi_email_addr": "pchen402@gatech.edu",
   "nsf_id": "000766762",
   "pi_start_date": "2022-09-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Tech Research Corporation",
  "perf_str_addr": "926 DALNEY ST NW",
  "perf_city_name": "ATLANTA",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "30332",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 27637.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 103327.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 104658.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-756c5597-7fff-bd50-5343-e543424107be\"> </span></p>\r\n<p dir=\"ltr\"><span>Large&#8209;scale stochastic optimization under high&#8209;dimensional uncertainty is central to the control, inversion, design, and experimental design of complex physical systems across many fields of computational science and engineering. Such problems present significant challenges&mdash;notably the curse of dimensionality and prohibitive computational cost. <strong>In this project, we developed, analyzed, implemented, and applied a suite of novel, scalable computational methods for solving large&#8209;scale stochastic optimization problems under high&#8209;dimensional uncertainty.</strong></span></p>\r\n<p dir=\"ltr\"><strong>Methodological Advances: </strong><span>We tackled the inherent challenges by introducing two complementary classes of scalable computational methods: (1) </span><strong>Functional Taylor Approximations: </strong><span>We developed high&#8209;order Taylor approximation techniques that leverage randomized algorithms for derivative tensor decomposition, as well as Gaussian mixture Taylor approximations. These methods reduce the computational burden by over 100X compared to traditional Monte Carlo approaches when approximating various risk measures. (2) </span><strong>Parsimonious Deep Neural Networks: </strong><span>We designed neural network architectures that exploit the intrinsic low&#8209;dimensional structure of the mapping from random parameters to the objective function. A key innovation is our training procedure, which not only approximates the parameter-to-objective map but also its Jacobian with respect to the optimization variables. We have demonstrated high accuracy and scalability&mdash;achieving roughly a 100X speedup in solving large&#8209;scale PDE&#8209;constrained problems&mdash;by applying these networks within contexts such as optimal control, optimal design, and optimal experimental design.</span></p>\r\n<p dir=\"ltr\"><strong>Theoretical Contributions: </strong><span>On the theoretical front, we derived general performance bounds for PDE&#8209;constrained optimization under uncertainty. Recognizing that practical computational approaches introduce various inaccuracies&mdash;through finite&#8209;dimensional approximations of control and state spaces, sample average approximations of risk measures, smoothing of nonsmooth functions, and penalty approximations of constraints&mdash;we analyzed the performance of controls obtained by our approximation&#8209;based algorithm. Our analysis establishes estimates for optimality gaps in general optimization problems defined on metric spaces. Under mild assumptions, we proved that as the inaccuracies in the approximations vanish, the limiting controls attain arbitrarily small optimality gaps. This analysis covers a broad class of problems incorporating multiple expectation, risk, and reliability functions that depend on PDE solutions and appear in both the objective and constraints.</span></p>\r\n<p dir=\"ltr\"><strong>Software and Implementation: </strong><span>We have released an open&#8209;source software package, </span><span><strong>SOUPy</strong> (Stochastic Optimization under high&#8209;dimensional Uncertainty in Python)</span><span>, which implements our scalable and parallel approximation and optimization algorithms. The library features various risk measures (such as mean, variance, and superquantile, condition-value-at-risk), probability/chance constraints, and optimization/state constraints. SOUPy has been applied successfully to diverse applications, including optimal control of turbulent flows, optimal design of acoustic metamaterials and self&#8209;assembly nanomaterials, optimal management of groundwater extraction, and optimal experimental design for MRI monitoring of brain tumor growth.</span></p>\r\n<p><strong>Broader Impacts: </strong><span>The project has yielded substantial academic and practical outcomes: Two PhD theses have been completed under partial support of this project. Ten publications in high&#8209;impact journals and conferences have been produced. Our work has been disseminated through eighteen presentations at seminars, workshops, and conferences. We have developed and released one open&#8209;source software package (SOUPy). A new graduate course on these topics has been taught at Georgia Tech with about 50 students. Through these achievements, our project has significantly advanced computational methods for stochastic optimization and uncertainty quantification. The dissemination of our methods and software has enabled researchers and practitioners in many scientific and engineering fields to tackle high&#8209;dimensional, stochastic optimization challenges more efficiently and reliably.</span></p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 02/04/2025<br>\nModified by: Peng&nbsp;Chen</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \r\n\n\nLarge&#8209;scale stochastic optimization under high&#8209;dimensional uncertainty is central to the control, inversion, design, and experimental design of complex physical systems across many fields of computational science and engineering. Such problems present significant challengesnotably the curse of dimensionality and prohibitive computational cost. In this project, we developed, analyzed, implemented, and applied a suite of novel, scalable computational methods for solving large&#8209;scale stochastic optimization problems under high&#8209;dimensional uncertainty.\r\n\n\nMethodological Advances: We tackled the inherent challenges by introducing two complementary classes of scalable computational methods: (1) Functional Taylor Approximations: We developed high&#8209;order Taylor approximation techniques that leverage randomized algorithms for derivative tensor decomposition, as well as Gaussian mixture Taylor approximations. These methods reduce the computational burden by over 100X compared to traditional Monte Carlo approaches when approximating various risk measures. (2) Parsimonious Deep Neural Networks: We designed neural network architectures that exploit the intrinsic low&#8209;dimensional structure of the mapping from random parameters to the objective function. A key innovation is our training procedure, which not only approximates the parameter-to-objective map but also its Jacobian with respect to the optimization variables. We have demonstrated high accuracy and scalabilityachieving roughly a 100X speedup in solving large&#8209;scale PDE&#8209;constrained problemsby applying these networks within contexts such as optimal control, optimal design, and optimal experimental design.\r\n\n\nTheoretical Contributions: On the theoretical front, we derived general performance bounds for PDE&#8209;constrained optimization under uncertainty. Recognizing that practical computational approaches introduce various inaccuraciesthrough finite&#8209;dimensional approximations of control and state spaces, sample average approximations of risk measures, smoothing of nonsmooth functions, and penalty approximations of constraintswe analyzed the performance of controls obtained by our approximation&#8209;based algorithm. Our analysis establishes estimates for optimality gaps in general optimization problems defined on metric spaces. Under mild assumptions, we proved that as the inaccuracies in the approximations vanish, the limiting controls attain arbitrarily small optimality gaps. This analysis covers a broad class of problems incorporating multiple expectation, risk, and reliability functions that depend on PDE solutions and appear in both the objective and constraints.\r\n\n\nSoftware and Implementation: We have released an open&#8209;source software package, SOUPy (Stochastic Optimization under high&#8209;dimensional Uncertainty in Python), which implements our scalable and parallel approximation and optimization algorithms. The library features various risk measures (such as mean, variance, and superquantile, condition-value-at-risk), probability/chance constraints, and optimization/state constraints. SOUPy has been applied successfully to diverse applications, including optimal control of turbulent flows, optimal design of acoustic metamaterials and self&#8209;assembly nanomaterials, optimal management of groundwater extraction, and optimal experimental design for MRI monitoring of brain tumor growth.\r\n\n\nBroader Impacts: The project has yielded substantial academic and practical outcomes: Two PhD theses have been completed under partial support of this project. Ten publications in high&#8209;impact journals and conferences have been produced. Our work has been disseminated through eighteen presentations at seminars, workshops, and conferences. We have developed and released one open&#8209;source software package (SOUPy). A new graduate course on these topics has been taught at Georgia Tech with about 50 students. Through these achievements, our project has significantly advanced computational methods for stochastic optimization and uncertainty quantification. The dissemination of our methods and software has enabled researchers and practitioners in many scientific and engineering fields to tackle high&#8209;dimensional, stochastic optimization challenges more efficiently and reliably.\r\n\n\n\t\t\t\t\tLast Modified: 02/04/2025\n\n\t\t\t\t\tSubmitted by: PengChen\n"
 }
}