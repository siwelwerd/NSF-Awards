{
 "awd_id": "2230996",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Conference: Inaugural Workshop on Provably Safe and Beneficial AI (PSBAI)",
 "cfda_num": "47.084",
 "org_code": "15020000",
 "po_phone": "7032922251",
 "po_email": "jgeorge@nsf.gov",
 "po_sign_block_name": "Jemin George",
 "awd_eff_date": "2022-09-01",
 "awd_exp_date": "2023-02-28",
 "tot_intn_awd_amt": 93856.0,
 "awd_amount": 93856.0,
 "awd_min_amd_letter_date": "2022-08-18",
 "awd_max_amd_letter_date": "2022-08-18",
 "awd_abstract_narration": "This workshop proposal aims to bring together a wide range of researchers on a very relevant and ambitious topic. It will start a timely discussion on how Artificial Intelligence (AI) can be made safe for public good, and how current advances in the field can become a supporting backbone for that usage. The proposal addresses a topic that has a lot of potential for research but has been very sparsely visited so far in both engineering and computing research communities. Overall, this is a strong workshop proposal which will lead to novel research conversations on two major topics of importance for today\u2019s society \u2013 AI and digital ecosystem. \r\n\r\nThe workshop is to be conducted over 2 days at the University of California Berkeley campus, both in-person and via videoconference, with 50 attendees, including stakeholders across industry, non-profits, academia, government and supra-national institutions, building on years of collaboration and consultation with the EU Commission, World Economic Forum, OECD, UNESCO, and GPAI; and with major foundations including Schmidt Futures, Kavli, Open Philanthropy; and several national governments. The PI has done a good job in putting together an impressive agenda, featuring academia, industry, and government organizations. The proposed workshop has five suggested topic areas including: 1) fundamental topics for safe and beneficial AI systems; 2) Considerations for provably safe and beneficial algorithmic media; 3) Considerations for provably safe and beneficial human-robot interaction; 4) Relevant technical considerations to enable a regulatory framework governing the deployment of powerful AI systems within a secure digital ecosystem; and 5) Considerations regarding fair access.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "ITE",
 "org_div_long_name": "Innovation and Technology Ecosystems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Stuart",
   "pi_last_name": "Russell",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Stuart J Russell",
   "pi_email_addr": "russell@cs.berkeley.edu",
   "nsf_id": "000443080",
   "pi_start_date": "2022-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "1608 4TH ST STE 201",
  "perf_city_name": "BERKELEY",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947101749",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131Y00",
   "pgm_ele_name": "Convergence Accelerator Resrch"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 93856.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-cf52b5ac-7fff-a73b-c005-8d101ab11a04\">&nbsp;</span></p>\n<p dir=\"ltr\"><span>The Inaugural Workshop on Provably Safe and Beneficial AI (PSBAI) was held in person in Berkeley, California on the weekend of October 7-9, 2022, with 51 primary attendees from a range of disciplines, including stakeholders across industry, non-profits, academia, and government.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>Making AI safe, like making nuclear power safe, is in everyone?s interest. </span><span>This is a particularly imminent challenge because current AI technologies are not founded on safe principles.</span><span> Because a trained deep neural network performs its task according to unknown principles, it is very hard to ensure safety in all situations. More traditional system designs are subject to another kind of failure: </span><span>mis-specification of objectives</span><span>. The optimization of clickthrough or engagement metrics by social media algorithms, with potentially disastrous consequences for human society, serves as an early warning.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>The aim of the workshop was to chart a research program to develop the means to build systems that are well-founded, interpretable, and provably safe and beneficial, including deployment through a secure digital ecosystem. The resulting program requires a concerted effort from multiple disciplines, ranging from mathematically rigorous branches of computer science, engineering, and statistics to conceptually challenging areas of moral philosophy and behavioral economics. It includes paths to develop well-founded and well-understood components and analytical tools for AI systems, rather than black-box methods. The initial program includes five research tracks.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>1. </span><span>Approaches to beneficial AI</span><span>: focused on ways to ensure that AI systems? behavior is actually beneficial, particularly when exact specifications of what is ?beneficial? are not available.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>2. </span><span>Well-founded AI system designs</span><span>: Safety and other related properties are easier to assure when AI systems are designed from well-understood components?particularly components with well-defined, transparent semantics?connected in well-understood ways. This track seeks to create foundational methods for building AI components (such as inference engines and learned models) that are safe by design.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>3. </span><span>Formal methods for AI system assurance</span><span>: This research track aims to develop methods for proving that an AI system satisfies desired safety properties. It focuses on the problem of specifying an AI system formally, then proving that the system meets those specifications ? and that it will do something reasonable even when those specifications are incomplete.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>4. </span><span>Provably safe and beneficial AI system prototypes</span><span>: Research in this area will integrate ideas from the first three areas to develop and demonstrate fully verified prototypes of provably safe and beneficial AI systems, beginning with simulated systems in a lab setting, moving to larger online environments.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>5. </span><span>Policy, regulation and mechanisms for a secure digital ecosystem</span><span>: As provably safe and beneficial AI systems become possible and eventually widely useful, while the underlying AI technologies become more powerful, public policy and regulation will need to remain in step.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>The societal benefits of powerful AI systems are potentially enormous and have been enunciated by many authors; they include greatly increased economic output as well as advances in science, medicine, education, and the creative arts. Existing systems, e.g. recommenders, and more recently large language models such as ChatGPT, have already integrated AI into nearly every human activity, and are a major component of the world economy today, despite our limited understanding of their impact.&nbsp; The proposed research program, if successful, will lead to the emergence of a new class of AI systems that are provably safe and beneficial, as well as a regulatory framework governing the deployment of powerful AI systems within a secure digital ecosystem. It makes possible the realization of these benefits without the accompanying risk of losing control over increasingly capable AI systems, or having them deployed in forms that are deliberately harmful to humans.&nbsp; </span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/10/2023<br>\n\t\t\t\t\tModified by: Stuart&nbsp;J&nbsp;Russell</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThe Inaugural Workshop on Provably Safe and Beneficial AI (PSBAI) was held in person in Berkeley, California on the weekend of October 7-9, 2022, with 51 primary attendees from a range of disciplines, including stakeholders across industry, non-profits, academia, and government. \n\n \nMaking AI safe, like making nuclear power safe, is in everyone?s interest. This is a particularly imminent challenge because current AI technologies are not founded on safe principles. Because a trained deep neural network performs its task according to unknown principles, it is very hard to ensure safety in all situations. More traditional system designs are subject to another kind of failure: mis-specification of objectives. The optimization of clickthrough or engagement metrics by social media algorithms, with potentially disastrous consequences for human society, serves as an early warning.\n\n \nThe aim of the workshop was to chart a research program to develop the means to build systems that are well-founded, interpretable, and provably safe and beneficial, including deployment through a secure digital ecosystem. The resulting program requires a concerted effort from multiple disciplines, ranging from mathematically rigorous branches of computer science, engineering, and statistics to conceptually challenging areas of moral philosophy and behavioral economics. It includes paths to develop well-founded and well-understood components and analytical tools for AI systems, rather than black-box methods. The initial program includes five research tracks.\n\n \n1. Approaches to beneficial AI: focused on ways to ensure that AI systems? behavior is actually beneficial, particularly when exact specifications of what is ?beneficial? are not available. \n\n \n2. Well-founded AI system designs: Safety and other related properties are easier to assure when AI systems are designed from well-understood components?particularly components with well-defined, transparent semantics?connected in well-understood ways. This track seeks to create foundational methods for building AI components (such as inference engines and learned models) that are safe by design.\n\n \n3. Formal methods for AI system assurance: This research track aims to develop methods for proving that an AI system satisfies desired safety properties. It focuses on the problem of specifying an AI system formally, then proving that the system meets those specifications ? and that it will do something reasonable even when those specifications are incomplete.\n\n \n4. Provably safe and beneficial AI system prototypes: Research in this area will integrate ideas from the first three areas to develop and demonstrate fully verified prototypes of provably safe and beneficial AI systems, beginning with simulated systems in a lab setting, moving to larger online environments.\n\n \n5. Policy, regulation and mechanisms for a secure digital ecosystem: As provably safe and beneficial AI systems become possible and eventually widely useful, while the underlying AI technologies become more powerful, public policy and regulation will need to remain in step.\n\n \nThe societal benefits of powerful AI systems are potentially enormous and have been enunciated by many authors; they include greatly increased economic output as well as advances in science, medicine, education, and the creative arts. Existing systems, e.g. recommenders, and more recently large language models such as ChatGPT, have already integrated AI into nearly every human activity, and are a major component of the world economy today, despite our limited understanding of their impact.  The proposed research program, if successful, will lead to the emergence of a new class of AI systems that are provably safe and beneficial, as well as a regulatory framework governing the deployment of powerful AI systems within a secure digital ecosystem. It makes possible the realization of these benefits without the accompanying risk of losing control over increasingly capable AI systems, or having them deployed in forms that are deliberately harmful to humans.  \n\n \n\n \n\n\t\t\t\t\tLast Modified: 08/10/2023\n\n\t\t\t\t\tSubmitted by: Stuart J Russell"
 }
}