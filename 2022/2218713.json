{
 "awd_id": "2218713",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Medium: Collaborative Research:Algorithmic High-Dimensional Statistics: Optimality, Computtional Barriers, and High-Dimensional Corrections",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2022-01-01",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 385000.0,
 "awd_amount": 287594.0,
 "awd_min_amd_letter_date": "2022-04-11",
 "awd_max_amd_letter_date": "2022-04-11",
 "awd_abstract_narration": "This research aims to address the pressing challenges on learning and inference from large-dimensional data. Contemporary sensing and data acquisition technologies produce data at an unprecedented rate. A ubiquitous challenge in modern data applications is thus to efficiently and reliably extract relevant information and associated insights from a deluge of data. In the meantime, this challenge is exacerbated by the unprecedented growth of relevant features one needs to reason about, which oftentimes even outpaces the growth of data samples. Classical statistical inference paradigms, which either only work in the presence of an enormous number of data samples, or ignore the computational cost of the estimators at all, become highly insufficient, or even unreliable, for many emerging applications of machine learning and big-data analytics. \r\n\r\nTo address the above pressing issues in high dimensions, novel theoretical tools need to be brought in the picture in order to provide a comprehensive understanding of the performance limits of various algorithms and tasks. The goal of this project is four-fold: First, to develop a modern theory to characterize precise performance of classical statistical algorithms in high dimensions. Second, to suggest proper corrections of classical statistical inference procedures to accommodate the sample-starved regime. Third, to develop computationally efficient algorithms that can provably attain the fundamental statistical limits, if possible. Finally, forth, to identify potential computational barriers if the fundamental statistical limits cannot be met. The transformative potential of the proposed research program is in the development of foundational statistical data analytics theory through a novel combination of statistics, approximation theory, statistical physics, mathematical optimization, and information theory, offering scalable statistical inference and learning algorithms.  The theory and algorithms developed within this project will have direct impact on various engineering and science applications such as large-scale machine learning, DNA sequencing, genetic disease analysis, and natural language processing. This collaborative program provides cross-university opportunities for students training, and we are committed to engaging and helping underrepresented and women students in STEM through long-term mentorships and outreach activities.This research aims to address the pressing challenges on learning and inference from large-dimensional data. Contemporary sensing and data acquisition technologies produce data at an unprecedented rate. A ubiquitous challenge in modern data applications is thus to efficiently and reliably extract relevant information and associated insights from a deluge of data. In the meantime, this challenge is exacerbated by the unprecedented growth of relevant features one needs to reason about, which oftentimes even outpaces the growth of data samples. Classical statistical inference paradigms, which either only work in the presence of an enormous number of data samples, or ignore the computational cost of the estimators at all, become highly insufficient, or even unreliable, for many emerging applications of machine learning and big-data analytics. \r\n\r\nTo address the above pressing issues in high dimensions, novel theoretical tools need to be brought in the picture in order to provide a comprehensive understanding of the performance limits of various algorithms and tasks. The goal of this project is four-fold: First, to develop a modern theory to characterize precise performance of classical statistical algorithms in high dimensions. Second, to suggest proper corrections of classical statistical inference procedures to accommodate the sample-starved regime. Third, to develop computationally efficient algorithms that can provably attain the fundamental statistical limits, if possible. Finally, forth, to identify potential computational barriers if the fundamental statistical limits cannot be met. The transformative potential of the proposed research program is in the development of foundational statistical data analytics theory through a novel combination of statistics, approximation theory, statistical physics, mathematical optimization, and information theory, offering scalable statistical inference and learning algorithms.  The theory and algorithms developed within this project will have direct impact on various engineering and science applications such as large-scale machine learning, DNA sequencing, genetic disease analysis, and natural language processing. This collaborative program provides cross-university opportunities for students training, and we are committed to engaging and helping underrepresented and women students in STEM through long-term mentorships and outreach activities.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yuxin",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yuxin Chen",
   "pi_email_addr": "yuxinc@wharton.upenn.edu",
   "nsf_id": "000745304",
   "pi_start_date": "2022-04-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 287594.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-d1323d6c-7fff-3b19-74b9-684ec4d56dae\"> </span></p>\n<p dir=\"ltr\"><span>This project aims to address the challenges arising in high-dimensional learning and inference tasks, which become prevalent due to the rapid growth of data acquisition technologies. For these tasks, classical statistical algorithms, which focused primarily upon the asymptotic regime with infinitely many samples and fixed dimension, become highly inadequate and might sometimes break completely. In light of this, our investigation seeks to develop a suite of modern statistical theory and algorithms that lend them well to sample-hungry high-dimensional problems, and propose computationally fast solutions that can outperform classical approaches.&nbsp;</span></p>\n<p dir=\"ltr\"><span>More specific findings of this project include: (1) identifying the bias of spectral methods in high dimension, and proposing bias-correction solutions that lead to improved statistical performance; (2) identifying the computational barriers in problems like tensor completion, tensor clustering and tensor PCA, and proposing computationally efficient solutions that achieve optimal statistical performance among all tractable algorithms; (3) developing nonconvex optimization algorithms that are suitable to high-dimensional problems, and deriving uncertainty quantification schemes to construct trustworthy confidence intervals for nonconvex algorithms. Our project has resulted in publications in top journals in statistics and optimization, as well as leading conferences in machine learning. Several tutorials and short courses have been presented in high-profile conferences based on the research findings of this project, which have further been organized into an overview article and a research monograph. Additionally, the project has enabled valuable training opportunities for students and postdocs within the PI&rsquo;s group. Three students and six postdocs who have worked on related tasks of this project have joined top universities as tenure-track faculty.</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/28/2024<br>\nModified by: Yuxin&nbsp;Chen</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThis project aims to address the challenges arising in high-dimensional learning and inference tasks, which become prevalent due to the rapid growth of data acquisition technologies. For these tasks, classical statistical algorithms, which focused primarily upon the asymptotic regime with infinitely many samples and fixed dimension, become highly inadequate and might sometimes break completely. In light of this, our investigation seeks to develop a suite of modern statistical theory and algorithms that lend them well to sample-hungry high-dimensional problems, and propose computationally fast solutions that can outperform classical approaches.\n\n\nMore specific findings of this project include: (1) identifying the bias of spectral methods in high dimension, and proposing bias-correction solutions that lead to improved statistical performance; (2) identifying the computational barriers in problems like tensor completion, tensor clustering and tensor PCA, and proposing computationally efficient solutions that achieve optimal statistical performance among all tractable algorithms; (3) developing nonconvex optimization algorithms that are suitable to high-dimensional problems, and deriving uncertainty quantification schemes to construct trustworthy confidence intervals for nonconvex algorithms. Our project has resulted in publications in top journals in statistics and optimization, as well as leading conferences in machine learning. Several tutorials and short courses have been presented in high-profile conferences based on the research findings of this project, which have further been organized into an overview article and a research monograph. Additionally, the project has enabled valuable training opportunities for students and postdocs within the PIs group. Three students and six postdocs who have worked on related tasks of this project have joined top universities as tenure-track faculty.\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 10/28/2024\n\n\t\t\t\t\tSubmitted by: YuxinChen\n"
 }
}