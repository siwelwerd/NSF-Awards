{
 "awd_id": "2217889",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Decision Processes in Human Navigation",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2022-08-15",
 "awd_exp_date": "2026-07-31",
 "tot_intn_awd_amt": 348668.0,
 "awd_amount": 360668.0,
 "awd_min_amd_letter_date": "2022-08-22",
 "awd_max_amd_letter_date": "2024-07-09",
 "awd_abstract_narration": "Navigating successfully from one place to another can require difficult decisions.  We often need to consider the costs and the benefits of possible routes.  For example, the best walking path between downtown buildings may be a short outdoor path when the weather is pleasant or a longer path through indoor passageways during overly hot or cold months.  We also use our knowledge to make decisions about where to search for something that we need.  Experienced drivers know, for example, that a strip mall is a better place to find a gas station than is a residential neighborhood.  We also may need to decide whether we know an environment well enough to rely on our memories and sense of direction or should use the mapping app on our cell phones.  To make good choices and to keep from getting lost, we need to rely on several sources of information. One important source is what we see, such as roads, trails, and familiar places.  Another important source is from our bodies:  As we walk and turn, even with our eyes closed, we have a sense of how far we have traveled and which directions we are facing.  These sources of information tell us where we are, where we are headed, and how hard it will be to get there (e.g., climbing a steep hill vs. walking around it).  This research investigates how people make these sorts of decisions, deal with conflicting sources of information (e.g., our sense of direction indicates that we should turn left but a familiar landmark indicates that we should turn right), and use navigation aids (e.g., an overhead map of the environment).  The investigators will use mathematical models of people\u2019s choices and actions to understand how the human brain stores and uses spatial knowledge for navigation.  The results can inform the use of technology, ranging from movement interfaces for video games to GPS-enabled maps. \r\n\r\nThe investigators explore the ways in which navigational decisions and actions are affected by (a) spatial cues about the navigator\u2019s location and the goal location (e.g., landmarks in the environment, body-based cues from walking and turning), (b) costs associated with possible choices (e.g., effort, time), and (c) individual characteristics of the navigator (e.g., spatial ability, risk tolerance). Experiments use immersive virtual reality to maintain tight control over the visual scene while allowing for full physical movement during navigation; this technology allows navigators to walk and turn in virtual environments just as they do in the real world. The experiments examine 1) how navigators use information from multiple spatial cues to find a goal when those cues are inconsistent with one another; 2)  how navigators account for navigational costs, as when choosing between a short path through deep sand or a longer path on firm ground; 3) how navigators use prior knowledge to make navigational decisions, as when selecting the most likely place to search for a restaurant within an unfamiliar city, knowing that a restaurant is more likely to be located in a business district than a residential neighborhood; and 4) how navigators combine spatial information from technology, such as that provided by a GPS-enabled map, with natural cues provided by vision and bodily movement.  Computational models of the cognitive processes involved in human navigation will be used to expand explanatory theories of human decisions and actions.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "McNamara",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy P McNamara",
   "pi_email_addr": "t.mcnamara@vanderbilt.edu",
   "nsf_id": "000409771",
   "pi_start_date": "2022-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Vanderbilt University",
  "inst_street_address": "110 21ST AVE S",
  "inst_street_address_2": "",
  "inst_city_name": "NASHVILLE",
  "inst_state_code": "TN",
  "inst_state_name": "Tennessee",
  "inst_phone_num": "6153222631",
  "inst_zip_code": "372032416",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "TN05",
  "org_lgl_bus_name": "VANDERBILT UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "GTNBNWXJ12D5"
 },
 "perf_inst": {
  "perf_inst_name": "Vanderbilt University",
  "perf_str_addr": "Sponsored Programs Administration",
  "perf_city_name": "Nashville",
  "perf_st_code": "TN",
  "perf_st_name": "Tennessee",
  "perf_zip_code": "372350002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "TN07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132100",
   "pgm_ele_name": "Decision, Risk & Mgmt Sci"
  },
  {
   "pgm_ele_code": "141Y00",
   "pgm_ele_name": "Human-Envi & Geographical Scis"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "105Z",
   "pgm_ref_txt": "HEGS: Human-Envirnmnt and Geogrphcl Sci"
  },
  {
   "pgm_ref_code": "1321",
   "pgm_ref_txt": "DECISION RISK & MANAGEMENT SCI"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "7298",
   "pgm_ref_txt": "COLLABORATIVE RESEARCH"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 113544.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 119117.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 128007.0
  }
 ],
 "por": null
}