{
 "awd_id": "2141246",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Estimating Articulatory Constriction Place and Timing from Speech Acoustics",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032924770",
 "po_email": "rtheodor@nsf.gov",
 "po_sign_block_name": "Rachel M. Theodore",
 "awd_eff_date": "2022-06-15",
 "awd_exp_date": "2025-11-30",
 "tot_intn_awd_amt": 100602.0,
 "awd_amount": 100602.0,
 "awd_min_amd_letter_date": "2022-05-31",
 "awd_max_amd_letter_date": "2022-05-31",
 "awd_abstract_narration": "This collaborative project focuses on a new approach for using speech recordings to study speaker pronunciation habits--that is, the way speakers systematically coordinate the articulatory movements of their lips, jaw, tongue, glottis and soft palate to produce words and sentences.   These articulatory habits differ between individuals, and across languages and dialects of the same language, accounting for many aspects of foreign accent, speech disorders and speaking style.  Whereas previous studies of these habits have required specialized equipment for the immediate observation of articulator movements, the aim of this project is to develop and improve a tool for \"speech inversion\"--that is, a tool that can accurately recover articulatory movements directly from the acoustic speech signal using machine learning methods.  To date, the tool developed by the project team has successfully recovered movements of the tongue and lips; the current project extends the tool\u2019s functionality to encompass nasality (soft palate) and voicing (glottis).  Training and validation of the extended system will proceed using a newly collected corpus of acoustic and articulatory data drawn from speakers of American English.  This corpus, comprising co-collected audio, nasal, voicing, and articulatory movement, will serve as 'ground truth' for training and assessing the capabilities of the fully trained speech inversion system.  As a further test, we will test it against ground truth data from speakers of languages with patterns of articulatory habits known to differ from English.\r\n\r\nThe goal of this project is to develop and refine a Speech Inversion Tool that 'reads' acoustic recordings of speech and 'recovers' details of the magnitude and timing of articulatory movements.  The project aims to accomplish this goal by training specialized Neural Network models to relate features of the acoustic signal to separately acquired ground-truth nasal vs. oral outflow signals and concurrent electroglottography. Training data derives from native speakers of English; validation and tests for generalization include productions of speakers of Canadian French and Russian. When successfully validated, the resulting speech inversion tool will be useful for identifying medical issues that affect speech movement organization, such as the well-known disruption of oral/laryngeal timing in speakers with dysarthria. In addition, incorporating estimates of articulation may also aid in the tracking of changes resulting from medical conditions such as depression and schizophrenia.  More generally, the ability to rapidly and easily analyze articulatory movements obtained from audio recordings alone has the potential substantially improve Automated Speech Recognition (ASR) systems, and to assist scholars, forensic scientists, and clinical professionals studying the speech of communities under field conditions in rural or under-resourced areas, and to help in the documentation of endangered languages.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Suzanne",
   "pi_last_name": "Boyce",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Suzanne E Boyce",
   "pi_email_addr": "suzanne.boyce@uc.edu",
   "nsf_id": "000089943",
   "pi_start_date": "2022-05-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Cincinnati Main Campus",
  "inst_street_address": "2600 CLIFTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CINCINNATI",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "5135564358",
  "inst_zip_code": "452202872",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "OH01",
  "org_lgl_bus_name": "CINCINNATI UNIV OF",
  "org_prnt_uei_num": "DZ4YCZ3QSPR5",
  "org_uei_num": "DZ4YCZ3QSPR5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Cincinnati",
  "perf_str_addr": "3225 Eden Ave",
  "perf_city_name": "Cincinnati",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "452670379",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "OH01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "107Z",
   "pgm_ref_txt": "Human Networks & Data Sci Infrastructure"
  },
  {
   "pgm_ref_code": "7298",
   "pgm_ref_txt": "COLLABORATIVE RESEARCH"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 100602.0
  }
 ],
 "por": null
}