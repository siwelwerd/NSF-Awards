{
 "awd_id": "2146691",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Embodiment of Human Values Profiles in the Control of Autonomous Vehicles",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032922633",
 "po_email": "aleoness@nsf.gov",
 "po_sign_block_name": "Alex Leonessa",
 "awd_eff_date": "2022-01-01",
 "awd_exp_date": "2024-03-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2021-11-02",
 "awd_max_amd_letter_date": "2021-11-02",
 "awd_abstract_narration": "This Mind, Machine, and Motor Nexus (M3X) EArly-concept Grant for Exploratory Research (EAGER) project advances a novel vision for trustworthy interaction between autonomous vehicles and their human drivers and passengers.  Although autonomous vehicles are being developed to increase human safety, failures with such vehicles are inevitable, especially when timely handover of control to a human driver is infeasible due to human fatigue, distraction, or slow reaction times relative to the computational speed of the autonomous vehicle.  This project seeks to design autonomous vehicle controllers that mimic the crash behaviors of responsible human drivers in a way that ensures \"ethically graceful\" failures - failure modes that are likely to meet human standards of ethical scrutiny. This project will promote the progress of science and advance the national health by developing trustworthy controllers for autonomous vehicles that mimic the real-time driving and crash behaviors of responsible human drivers. By doing so, the project will advance the state of the art in autonomous vehicle control while also developing a framework for vehicle controller design that promises to increase human trust in the autonomous vehicles of the future.  The project also will develop resources to inspire involvement of underrepresented groups in STEM fields.\r\n\r\nThe long-term goal of this work is to develop a new framework for autonomous vehicle controller design that will mimic the crash behaviors and decisions of responsible human drivers and thus exhibit \"ethically graceful\" failure modes. Two studies are researched. The first seeks to predict human driving behavior using surveys capable to identify psychological measures of \"benevolent\" and \"power\" Value Profiles in a large cohort of human subjects. Subjects will also engage in both virtual and physical simulations of crash scenarios. The goal of Study 1 is to characterize differences in crash behavior of people expressing benevolent and power Value Profiles. The second study researches a novel approach to translating the different Value Profiles into real-time controllers for the autonomous vehicles. The research l takes a novel approach that is quite different from existing deontological and consequentialist approaches to the design of ethical AI systems for AV control. By fitting the parameters of a low-level, real-time control model to data collected from drivers responding to crash scenarios in both virtual and physical simulations, the PI team will capture the moment-by-moment variations in human sensorimotor control that are more likely to dominate responses during crash scenarios than are high-level conscious decisions. If successful, this work may endow future autonomous vehicles with trustworthy controllers with failure modes that are likely to meet human standards of ethical scrutiny.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kathryn",
   "pi_last_name": "Johnson",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Kathryn A Johnson",
   "pi_email_addr": "kathryn.a.johnson@asu.edu",
   "nsf_id": "000809810",
   "pi_start_date": "2021-11-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Spring",
   "pi_last_name": "Berman",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Spring M Berman",
   "pi_email_addr": "Spring.Berman@asu.edu",
   "nsf_id": "000617982",
   "pi_start_date": "2021-11-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Theodore",
   "pi_last_name": "Pavlic",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Theodore P Pavlic",
   "pi_email_addr": "tpavlic@asu.edu",
   "nsf_id": "000655674",
   "pi_start_date": "2021-11-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "ORSPA",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852816011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "058Y00",
   "pgm_ele_name": "M3X - Mind, Machine, and Motor"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "070E",
   "pgm_ref_txt": "INTEG OF HUMAN & COGNITIVE"
  },
  {
   "pgm_ref_code": "060Z",
   "pgm_ref_txt": "Convergent Research"
  },
  {
   "pgm_ref_code": "070Z",
   "pgm_ref_txt": "MB-Mechanobiology"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "7632",
   "pgm_ref_txt": "HUMAN-ROBOT INTERACTION"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Self-driving cars and other autonomous vehicles (AVs) can substantially benefit society. Although the competency of AVs is increasing, AVs can become separated from meaningful human control (e.g., via operator inattention or incapacity). Additionally, AV decisions must sometimes be made quickly in dynamic&nbsp;environments. Therefore, accidents are inevitable, and humans must be able to trust AVs to respond appropriately. Notably, humans bring a variety of moral priorities and values (&ldquo;Values Profiles&rdquo;) to crash situations. Assuming the mechanical competency of AVs, our goal was to demonstrate the ability to design AV controllers that mimic humans&rsquo; driving and crash behaviors with specific Values Profiles.</p>\n<p>&nbsp;We collected survey data from a nationally representative sample of motor vehicle drivers in the U.S., investigating associations between Values Profiles and driving styles as predictors of decision-making in hypothetical crash scenarios. Consistent with prior studies, individuals with a <em>benevolent</em> Values Profile were more likely to have a prosocial driving style and choose self-sacrifice, whereas individuals with a <em>power</em> Values Profile were more likely to choose self-preservation.</p>\n<p>&nbsp;We replicated these survey results in a sample of over 1,700 undergraduate students. A subset of 320 respondents then completed driving trials in a virtual driving environment, concluding with an unexpected crash scenario. The simulation data included each vehicle&rsquo;s position and velocity along the simulated roadway. Additionally, the crash results allowed us to analyze self-sacrificing vs. self-preserving behaviors during the event. Again, prioritizing benevolence and power predicted prosocial and competitive driving styles, respectively. In turn, prosocial driving was associated with fewer pedestrian injuries in the crash scenario.</p>\n<p>&nbsp;Driving simulation data enables us to develop concrete mappings between behavior motivated by high-level Values Profiles and low-level sensorimotor actuation dynamics for the first time. We have used off-the-shelf optimization program tools to discover AV control parameters that can generate simulated vehicle trajectories matching those of human drivers and enable the study of the relationships between the objective driving behaviors and Values Profile of each human driver. Harkening back to behaviorism, we are mapping different kinds of implementable AV controllers onto different psychological profiles of humans&mdash;thus translating subjective characterizations of human personality into objective physical characteristics as salient as how quickly one walks or how often one talks.</p>\n<p>&nbsp;Our approach is innovative and critical because much of the existing research characterizes human driving by focusing on higher-order deliberative thinking. Instead, our approach captures lower-level variation in human sensorimotor behavior that is more likely to dominate responses during crash scenarios at very short timescales in uncertain environments. Accepting that AVs will inevitably fail, our approach helps to ensure that accidental failures will be more consistent with the normative failure modes of human driving. We also expect the resulting AV controllers to have a higher degree of explainability than <em>de novo</em> models based on higher-order cognition.</p>\n<p>&nbsp;In future work, we will program AVs with what we refer to as psychomimetic controllers in both virtual and physical environments. We have developed a small-scale traffic testbed (CHARTOPOLIS) that will allow us to empirically assess observers&rsquo; acceptance of these diverse (e.g., benevolent vs. power) control-parameter syndromes and objectively assess their effects on AVs&rsquo; safety margins.</p>\n<p>&nbsp;Through this research, we expect to help mitigate distrust of AVs and to catalyze further collaborative research aimed at incorporating ethical, psychological, and cultural factors into the design of controllers for many other types of autonomous robots (e.g., search-and-rescue robots, delivery AVs). For example, controllers set to mimic particular Values Profiles can be tuned to the moral priorities and values of the programmer, operator, passenger, or observers as needed.</p>\n<p>&nbsp;To date, our research results have been disseminated through refereed conference publications and presentations, a manuscript draft posted on PsyArXiv, and invited talks.&nbsp;In the future, we plan to give demonstrations in the community of small-scale AVs in our testbed programmed with diverse Values Profiles, whereby we may also inspire the involvement of underrepresented groups in STEM fields.</p>\n<p>&nbsp;This project provided funding for two Ph.D.&nbsp;students and volunteer learning opportunities for three engineering and computer science graduate students. The project also provided STEM research opportunities for 23 undergraduates (18 psychology majors and 5 computer science majors) as research assistants. All of them completed human subjects research training and were familiarized with the challenges of developing ethical AI.</p>\n<p>&nbsp;In sum, we have taken initial steps toward developing autonomous machines of all types that fail in &ldquo;ethically graceful&rdquo; ways that are consistent with human expectations and behavior in uncertain, complex, dynamic environments.</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/04/2024<br>\nModified by: Kathryn&nbsp;A&nbsp;Johnson</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nSelf-driving cars and other autonomous vehicles (AVs) can substantially benefit society. Although the competency of AVs is increasing, AVs can become separated from meaningful human control (e.g., via operator inattention or incapacity). Additionally, AV decisions must sometimes be made quickly in dynamicenvironments. Therefore, accidents are inevitable, and humans must be able to trust AVs to respond appropriately. Notably, humans bring a variety of moral priorities and values (Values Profiles) to crash situations. Assuming the mechanical competency of AVs, our goal was to demonstrate the ability to design AV controllers that mimic humans driving and crash behaviors with specific Values Profiles.\n\n\nWe collected survey data from a nationally representative sample of motor vehicle drivers in the U.S., investigating associations between Values Profiles and driving styles as predictors of decision-making in hypothetical crash scenarios. Consistent with prior studies, individuals with a benevolent Values Profile were more likely to have a prosocial driving style and choose self-sacrifice, whereas individuals with a power Values Profile were more likely to choose self-preservation.\n\n\nWe replicated these survey results in a sample of over 1,700 undergraduate students. A subset of 320 respondents then completed driving trials in a virtual driving environment, concluding with an unexpected crash scenario. The simulation data included each vehicles position and velocity along the simulated roadway. Additionally, the crash results allowed us to analyze self-sacrificing vs. self-preserving behaviors during the event. Again, prioritizing benevolence and power predicted prosocial and competitive driving styles, respectively. In turn, prosocial driving was associated with fewer pedestrian injuries in the crash scenario.\n\n\nDriving simulation data enables us to develop concrete mappings between behavior motivated by high-level Values Profiles and low-level sensorimotor actuation dynamics for the first time. We have used off-the-shelf optimization program tools to discover AV control parameters that can generate simulated vehicle trajectories matching those of human drivers and enable the study of the relationships between the objective driving behaviors and Values Profile of each human driver. Harkening back to behaviorism, we are mapping different kinds of implementable AV controllers onto different psychological profiles of humansthus translating subjective characterizations of human personality into objective physical characteristics as salient as how quickly one walks or how often one talks.\n\n\nOur approach is innovative and critical because much of the existing research characterizes human driving by focusing on higher-order deliberative thinking. Instead, our approach captures lower-level variation in human sensorimotor behavior that is more likely to dominate responses during crash scenarios at very short timescales in uncertain environments. Accepting that AVs will inevitably fail, our approach helps to ensure that accidental failures will be more consistent with the normative failure modes of human driving. We also expect the resulting AV controllers to have a higher degree of explainability than de novo models based on higher-order cognition.\n\n\nIn future work, we will program AVs with what we refer to as psychomimetic controllers in both virtual and physical environments. We have developed a small-scale traffic testbed (CHARTOPOLIS) that will allow us to empirically assess observers acceptance of these diverse (e.g., benevolent vs. power) control-parameter syndromes and objectively assess their effects on AVs safety margins.\n\n\nThrough this research, we expect to help mitigate distrust of AVs and to catalyze further collaborative research aimed at incorporating ethical, psychological, and cultural factors into the design of controllers for many other types of autonomous robots (e.g., search-and-rescue robots, delivery AVs). For example, controllers set to mimic particular Values Profiles can be tuned to the moral priorities and values of the programmer, operator, passenger, or observers as needed.\n\n\nTo date, our research results have been disseminated through refereed conference publications and presentations, a manuscript draft posted on PsyArXiv, and invited talks.In the future, we plan to give demonstrations in the community of small-scale AVs in our testbed programmed with diverse Values Profiles, whereby we may also inspire the involvement of underrepresented groups in STEM fields.\n\n\nThis project provided funding for two Ph.D.students and volunteer learning opportunities for three engineering and computer science graduate students. The project also provided STEM research opportunities for 23 undergraduates (18 psychology majors and 5 computer science majors) as research assistants. All of them completed human subjects research training and were familiarized with the challenges of developing ethical AI.\n\n\nIn sum, we have taken initial steps toward developing autonomous machines of all types that fail in ethically graceful ways that are consistent with human expectations and behavior in uncertain, complex, dynamic environments.\n\n\n\t\t\t\t\tLast Modified: 10/04/2024\n\n\t\t\t\t\tSubmitted by: KathrynAJohnson\n"
 }
}