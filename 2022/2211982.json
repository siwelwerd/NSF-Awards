{
 "awd_id": "2211982",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: SHF: MEDIUM: Smart Integrated Tuning of Parallel Code for Multicore and Manycore Systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2022-10-01",
 "awd_exp_date": "2025-09-30",
 "tot_intn_awd_amt": 502318.0,
 "awd_amount": 502318.0,
 "awd_min_amd_letter_date": "2022-06-15",
 "awd_max_amd_letter_date": "2023-09-13",
 "awd_abstract_narration": "High Performance Computing (HPC) entails executing code on multicore and manycore architectures. To better utilize multicore/manycore architectures, parallel programming models have emerged. But often using these parallel models naively will not be able to scratch the surface of the potential performance gains such systems can provide. A common technique for improving performance is to add more hardware resources. However, this is expensive and system integration is usually an onerous task. To this end, the investigators propose a framework of improving performance by better utilization of the available resource and identifying near-optimal configuration. These configurations can take the form of code optimizations, as well as intelligent resource mapping and utilization. Specifically, this project is concerned with identifying code optimizations and runtime configurations that can potentially speed up executions manifold. Faster executions can also implicitly lead to reduced power consumption. Additionally, for situations where existing execution performance is acceptable, the proposed approach can also be extended to optimize for other performance metrics such as power. Power consumption is usually a huge bottleneck for HPC systems, and is a source of concern for organizations that deploy such systems; these concerns are both fiscal and environmental. The investigators posit that the framework outlined in this project can also be extended to optimize for power consumption without compromising execution performance.\r\n\r\n\r\nThe investigators\u2019 aim is to provide such an AI-assisted framework that can automatically configure parallel code considering the underlying hardware architecture. The steps necessary to build such a framework lie at the convergence of compiler technologies, performance analysis and modeling, and deep learning. A primary driver of this project will be developing a program representation technique targeted towards parallel code. Existing representations target mostly serial code and cannot fully encapsulate the interactions and complexities of parallel code. Such a code representation technique is highly suited to analyses using deep learning. A means of representing parallel code in a machine learning friendly format will be very beneficial to the overall program analysis community. The proposed code representation will take the form of a graph, in order to correctly typify the inherent structure present in code. The investigators propose modeling this code representation using state-of-the-art Graph Neural Network (GNN) techniques. The modeled embeddings will be used in conjunction with task specific features in order to identify near optimum configurations for improved performance. The overall scale of this project will span the entire \u201csource code to execution\u201d pipeline that most HPC workloads follow. The aim of this project is to optimize each optimizable step in the pipeline. A sample optimization pipeline can take the following form: given a parallel code, our GNN-based code optimization model will predict the best optimizations for the given code, followed by identifying the best device (CPU, GPU, and others) for executing the optimized code. Further downstream, our framework will identify the optimum runtime configurations appropriate for the device under consideration. The ideas presented in this project can have the potential effect of increased hardware utilization and reduced future hardware commissioning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ali",
   "pi_last_name": "Jannesari",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ali Jannesari",
   "pi_email_addr": "jannesar@iastate.edu",
   "nsf_id": "000796985",
   "pi_start_date": "2022-06-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Iowa State University",
  "inst_street_address": "1350 BEARDSHEAR HALL",
  "inst_street_address_2": "515 MORRILL ROAD",
  "inst_city_name": "AMES",
  "inst_state_code": "IA",
  "inst_state_name": "Iowa",
  "inst_phone_num": "5152945225",
  "inst_zip_code": "500112103",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IA04",
  "org_lgl_bus_name": "IOWA STATE UNIVERSITY OF SCIENCE AND TECHNOLOGY",
  "org_prnt_uei_num": "DQDBM7FGJPC5",
  "org_uei_num": "DQDBM7FGJPC5"
 },
 "perf_inst": {
  "perf_inst_name": "Iowa State University",
  "perf_str_addr": "1138 Pearson",
  "perf_city_name": "AMES",
  "perf_st_code": "IA",
  "perf_st_name": "Iowa",
  "perf_zip_code": "500112042",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 332189.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 170129.0
  }
 ],
 "por": null
}