{
 "awd_id": "2147256",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FAI: Using Explainable AI to Increase Equity and Transparency in the Juvenile Justice System\u2019s Use of Risk Scores",
 "cfda_num": "47.070, 47.075",
 "org_code": "05020000",
 "po_phone": "7032927215",
 "po_email": "tleen@nsf.gov",
 "po_sign_block_name": "Todd Leen",
 "awd_eff_date": "2022-05-01",
 "awd_exp_date": "2025-04-30",
 "tot_intn_awd_amt": 392993.0,
 "awd_amount": 392993.0,
 "awd_min_amd_letter_date": "2022-02-11",
 "awd_max_amd_letter_date": "2022-02-11",
 "awd_abstract_narration": "Throughout the United States, juvenile justice systems use juvenile risk and need-assessment (JRNA) scores to identify the likelihood a youth will commit another offense in the future.  This risk assessment score is then used by juvenile justice practitioners to inform how to intervene with a youth to prevent reoffending (e.g., referring youth to a community-based program vs. placing a youth in a juvenile correctional center). Unfortunately, most risk assessment systems lack transparency and often the reasons why a youth received a particular score are unclear. Moreover, how these scores are used in the decision making process is sometimes not well understood by families and youth affected by such decisions.  This possibility is problematic because it can hinder individuals\u2019 buy-in to the intervention recommended by the risk assessment as well as mask potential bias in those scores (e.g., if youth of a particular race or gender have risk scores driven by a particular item on the assessment). To address this issue, project researchers will develop automated, computer-generated explanations for these risk scores aimed at explaining how these scores were produced.  Investigators will then test whether these better-explained risk scores help youth and juvenile justice decision makers understand the risk score a youth is given. In addition, the team of researchers will investigate whether these risk scores are working equally well for different groups of youth (for example, equally well for boys and for girls) and identify any potential biases in how they are being used in an effort to understand how equitable the decision making process is for demographic groups based on race and gender.   The project is embedded within the juvenile justice system and aims to evaluate how real stakeholders understand how the risk scores are generated and used within that system based on actual juvenile justice system data.  \r\n\r\nMore specifically, this project aims to understand how risk assessment scores are currently being used in the juvenile justice system and how interpretable machine learning methods can be used to make black-box risk assessment algorithms more transparent (without reverse engineering them given that most assessments are proprietary).  The team of researchers endeavor to understand the way that juvenile justice risk scores are being used through the analysis of quantitative data from the juvenile justice system (which details the risk scores and justice system decisions) and through qualitative data collected via key informant interviews. In the second phase of the work, the team of researchers will train various interpretable machine learning algorithms to predict youth\u2019s risk scores (which are currently generated by a proprietary, black-box algorithm).  The team will also predict the sentencing dispositions for youth based on these risk scores and other pertinent data collected by the juvenile justice system.   The project team will then test and measure how understandable a series of the automated explanations derived from these machine learning methods are to youth, families, judges and probation officers.   The goal of this step will be to identify algorithms that are highly predictive of the risk score and dispositions, respectively and then to identify methods that provide clear, human-interpretable explanations of the risk and dispositions to key stakeholders throughout the process.  This step will also allow researchers to optimize methods for explaining outcomes by possibly identifying one method that is more understandable for explaining risk scores to youth compared to another method that is more understandable for their families or probation officers, for example.    Finally, the project team will also explore the potential for bias throughout the process (from risk scoring to the use of the scores) and ways in which these interpretable algorithms can be used to help identify, quantify and mitigate biases.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kelly",
   "pi_last_name": "Murphy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kelly Murphy",
   "pi_email_addr": "kmurphy@childtrends.org",
   "nsf_id": "000792963",
   "pi_start_date": "2022-02-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Trent",
   "pi_last_name": "Buskirk",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Trent D Buskirk",
   "pi_email_addr": "tbuskirk@odu.edu",
   "nsf_id": "000861342",
   "pi_start_date": "2022-02-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Bowling Green State University",
  "inst_street_address": "1851 N RESEARCH DR",
  "inst_street_address_2": "",
  "inst_city_name": "BOWLING GREEN",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "4193722481",
  "inst_zip_code": "434034401",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "OH05",
  "org_lgl_bus_name": "BOWLING GREEN STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "SLT3EB6G3FA9"
 },
 "perf_inst": {
  "perf_inst_name": "Bowling Green State University",
  "perf_str_addr": "302 Hayes Hall",
  "perf_city_name": "Bowling Green",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "434030230",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "OH05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "114y00",
   "pgm_ele_name": "Fairness in Artificial Intelli"
  },
  {
   "pgm_ele_code": "114Y00",
   "pgm_ele_name": "Fairness in Artificial Intelli"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 392993.0
  }
 ],
 "por": null
}