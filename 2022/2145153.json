{
 "awd_id": "2145153",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Structured High-Agency Interactive Narratives for Virtual Environments",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2022-06-15",
 "awd_exp_date": "2027-05-31",
 "tot_intn_awd_amt": 530369.0,
 "awd_amount": 326283.0,
 "awd_min_amd_letter_date": "2022-04-11",
 "awd_max_amd_letter_date": "2024-07-19",
 "awd_abstract_narration": "This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2).\r\n\r\nNarratives are fundamental to the way we think, communicate, and learn. Virtual environments such as training simulations invite the user to play the role of one character in a narrative, while the system controls all the other non-player characters and the environment. Interactive narratives are effective tools for teaching people how to perform a task and educating people about important topics, but writing interactive narratives is challenging. Most are manually written, ensuring a nice structure but limiting their scope because every choice must be imagined in advance. Some environments are realistic simulations that give users freedom to do a wide variety of actions, but then it is hard for the designer to guarantee the narratives have the necessary content. This project will use artificial intelligence planning algorithms to create narratives at run time in games and training simulations. Planned narratives can have the structure of a hand-written story and the freedom of a simulation. This project will explore fast algorithms for generating narratives as well as models of what users remember and expect. Over the project duration, the research team will develop virtual environments (such as a virtual reality de-escalation training simulation for police officers) that evolves from a role-playing exercise between two people to a fully automated virtual environment where the artificial intelligence personalizes the interactive narrative for each player.\r\n\r\nThis project frames interactive narratives as an improvisational exercise between a player who controls one character and an experience manager who controls all the other elements of a virtual environment. These partners communicate their beliefs, intentions, memories, and expectations via the actions they choose to take, which is a noisy channel that requires inference for understanding. This project operationalizes the interactive narrative creation as a Mutual Implicit Question Answering (MIQA) process. Each action taken by one participant causes their partner to implicitly ask questions about why they took that action and/or implicitly answers questions that were raised earlier. The better one partner can answer questions raised by the other, the closer they are to mutual understanding. MIQA combines research on multi-agent artificial intelligence planning, cognitive models of memory and expectations, and procedures from automated question answering to represent both partners and how well they understand one another. Participants in an interactive virtual environment will do paired exercises where one will act as player and the other as experience manager. During this exercise, both partners will answer questions about their actions and about their perceptions of their partner\u2019s actions. They will also report on their perceptions of the structure of the narrative and the player agency. These exercises will begin as person-to-person exercises but will evolve into person-to-intelligent-agent exercises through data gathering and model refinement. The research hypothesis is that the intelligent agent will be able to provide high-agency, structured interactive narratives that approach the quality of those created with a human partner. This hypothesis will be evaluated using a Turing test: can the player identify whether the interactive narration is controlled by a human or an intelligent agent. These exercises will take place in a virtual environment called Camelot, but the research team will simultaneously implement the same procedures into an ongoing virtual reality training simulation that is being built in consultation with police officer training experts to teach best practices for de-escalating potentially dangerous situations.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Stephen",
   "pi_last_name": "Ware",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Stephen G Ware",
   "pi_email_addr": "sgware@cs.uky.edu",
   "nsf_id": "000678546",
   "pi_start_date": "2022-04-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Kentucky Research Foundation",
  "inst_street_address": "500 S LIMESTONE",
  "inst_street_address_2": "109 KINKEAD HALL",
  "inst_city_name": "LEXINGTON",
  "inst_state_code": "KY",
  "inst_state_name": "Kentucky",
  "inst_phone_num": "8592579420",
  "inst_zip_code": "405260001",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "KY06",
  "org_lgl_bus_name": "UNIVERSITY OF KENTUCKY RESEARCH FOUNDATION, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "H1HYA8Z1NTM5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Kentucky Research Foundation",
  "perf_str_addr": "500 South Limestone",
  "perf_city_name": "Lexington",
  "perf_st_code": "KY",
  "perf_st_name": "Kentucky",
  "perf_zip_code": "405260001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "KY06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "102Z",
   "pgm_ref_txt": "COVID-Disproportionate Impcts Inst-Indiv"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "010V2122DB",
   "fund_name": "R&RA ARP Act DEFC V",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 119434.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 105126.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 101723.0
  }
 ],
 "por": null
}