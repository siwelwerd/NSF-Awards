{
 "awd_id": "2212841",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "AF: Medium: Collaborative Research: Estimation, Learning, and Memory: The Quest for Statistically Optimal Algorithms",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922182",
 "po_email": "pbrass@nsf.gov",
 "po_sign_block_name": "Peter Brass",
 "awd_eff_date": "2021-12-01",
 "awd_exp_date": "2023-06-30",
 "tot_intn_awd_amt": 550000.0,
 "awd_amount": 109388.0,
 "awd_min_amd_letter_date": "2022-01-11",
 "awd_max_amd_letter_date": "2022-01-11",
 "awd_abstract_narration": "The goal of this project is to develop new, efficient algorithms that extract as much information as is possible from a given quantity of data.  In particular, this research aims to develop an understanding of how to leverage structure that is present in natural language settings, medical and genomic settings, and network- or graph-based settings. Many fundamental types of structure are encountered repeatedly in widely varying scientific and technological settings; our goal is to build on a recent body of work that focused on the simplest unstructured settings, and develop broadly applicable tools and insights to these diverse settings.   A central component of this project is a close interaction and transfer of ideas, problems, and techniques, between the theory community, the machine learning community, and the broader set of data-centric researchers and practitioners.\r\n\r\nFrom a technical perspective, this research focuses on three fundamental types of structure: geometric structure, algebraic or low-rank structure, and the structure that is present in sequential\r\ndata (such as natural language).   For the first two types of structure, the research focus is on understanding the possibilities and limitations in the sparse data regime where the amount of data is comparable to, or sublinear in, the dimensionality of the data.  In the third setting, the focus is on understanding the role of memory for learning and prediction tasks.\r\n\r\nBeyond the direct research goals of the project, the PIs are extensively involved in teaching and outreach, including designing UW?s new data sciences curriculum, and developing new courses on algorithms and foundational aspects of data sciences at Stanford.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sham",
   "pi_last_name": "Kakade",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sham Kakade",
   "pi_email_addr": "sham@seas.harvard.edu",
   "nsf_id": "000553028",
   "pi_start_date": "2022-01-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard University",
  "perf_str_addr": "1033 MASSACHUSETTS AVE",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021385369",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 8588.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 100800.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-123427b6-7fff-1d95-ebba-ab0a0cf446ed\"> </span></p>\n<p dir=\"ltr\"><span>Our work sought to decipher the underlying structure of data using statistical and computational tools. The primary objective was to reveal intricate connections and structures that emerge when working with structured probability distributions. These could range from geometric or algebraic structures to intricate sequences arising from models of sequential data.</span></p>\n<p dir=\"ltr\"><span>One pivotal achievement was the characterization of the optimal statistical rate of SGD in infinite dimensions, an aspect at the core of our proposal. This research showed that unregularized SGD, even in infinite dimensions, offers robustness against overfitting by its inherent streaming nature. We furthered this study to compare the implicit regularization provided by SGD to other explicit regularization methods. The revelations from this research present a fresh perspective on the phenomenon of benign overfitting.</span></p>\n<p dir=\"ltr\"><span>Furthermore, in the domain of reinforcement learning, our research has demystified some old open questions. Offline policy evaluation, a crucial statistical conundrum in this field, was explored in-depth. We were able to offer a complete and statistically optimal insight into this longstanding question, revealing the underlying complexities and challenges.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Also, a timely area of progress has been in the realm of deep learning, specifically exploring memory in these models. Our efforts led us to discern that self-attention mechanisms in deep learning models are notably adept at capturing sparse representations. Another aspect of this work was on understanding the computational challenges faced by deep learning models. Notably, we established that SGD effectively matches known optimal statistical query lower bounds, especially when trained on problems presenting theoretical computational challenges.</span></p>\n<p dir=\"ltr\"><span>Beyond the research realm, PI Kakade has made strides in the academic landscape by laying down the groundwork for a new book on reinforcement learning.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Also, due to the COVID-19 situation, part of our work quickly shifted focus. We redirected our efforts to assist with both manual and digital contact tracing. Concurrently, we aimed to furnish policymakers with tools to gauge prevalence levels and determine the necessary resources to manage outbreaks. This transition entailed vast interdisciplinary collaboration.</span></p>\n<p dir=\"ltr\"><span>Not only has our work made significant strides in understanding complex data structures and their implications but we've also managed to bridge the gap between computation and estimation. We hope the insights and outcomes generated will help for future research and innovations in the fields of deep learning, reinforcement learning, and optimization.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/27/2023<br>\n\t\t\t\t\tModified by: Sham&nbsp;Kakade</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nOur work sought to decipher the underlying structure of data using statistical and computational tools. The primary objective was to reveal intricate connections and structures that emerge when working with structured probability distributions. These could range from geometric or algebraic structures to intricate sequences arising from models of sequential data.\nOne pivotal achievement was the characterization of the optimal statistical rate of SGD in infinite dimensions, an aspect at the core of our proposal. This research showed that unregularized SGD, even in infinite dimensions, offers robustness against overfitting by its inherent streaming nature. We furthered this study to compare the implicit regularization provided by SGD to other explicit regularization methods. The revelations from this research present a fresh perspective on the phenomenon of benign overfitting.\nFurthermore, in the domain of reinforcement learning, our research has demystified some old open questions. Offline policy evaluation, a crucial statistical conundrum in this field, was explored in-depth. We were able to offer a complete and statistically optimal insight into this longstanding question, revealing the underlying complexities and challenges. \nAlso, a timely area of progress has been in the realm of deep learning, specifically exploring memory in these models. Our efforts led us to discern that self-attention mechanisms in deep learning models are notably adept at capturing sparse representations. Another aspect of this work was on understanding the computational challenges faced by deep learning models. Notably, we established that SGD effectively matches known optimal statistical query lower bounds, especially when trained on problems presenting theoretical computational challenges.\nBeyond the research realm, PI Kakade has made strides in the academic landscape by laying down the groundwork for a new book on reinforcement learning. \nAlso, due to the COVID-19 situation, part of our work quickly shifted focus. We redirected our efforts to assist with both manual and digital contact tracing. Concurrently, we aimed to furnish policymakers with tools to gauge prevalence levels and determine the necessary resources to manage outbreaks. This transition entailed vast interdisciplinary collaboration.\nNot only has our work made significant strides in understanding complex data structures and their implications but we've also managed to bridge the gap between computation and estimation. We hope the insights and outcomes generated will help for future research and innovations in the fields of deep learning, reinforcement learning, and optimization.\n\n\t\t\t\t\tLast Modified: 10/27/2023\n\n\t\t\t\t\tSubmitted by: Sham Kakade"
 }
}