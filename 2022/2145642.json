{
 "awd_id": "2145642",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER: Robots, Speech, and Learning in Inclusive Human Spaces",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922972",
 "po_email": "emiltsak@nsf.gov",
 "po_sign_block_name": "Eleni Miltsakaki",
 "awd_eff_date": "2022-06-01",
 "awd_exp_date": "2027-05-31",
 "tot_intn_awd_amt": 548928.0,
 "awd_amount": 548928.0,
 "awd_min_amd_letter_date": "2022-03-11",
 "awd_max_amd_letter_date": "2022-03-11",
 "awd_abstract_narration": "As robots become more capable and ubiquitous, they are increasingly moving into traditionally human-centric environments such as as health care, education, and elder care. As robots engage in tasks as diverse as helping with household work, deploying medication, and tutoring students, it becomes increasingly critical for them to interact naturally with the people around them. Key to this progress is the development of robots that acquire an understanding of goals and objects from natural communications with a diverse set of end users. One way to address this is using language to build systems that learn from people they are interacting with. Algorithms and systems developed in this project will allow robots to learn about the world around them from linguistic interactions. This research will focus on understanding spoken language about the physical world from diverse groups of people, resulting in systems that are more able to robustly handle a wide variety of real-world interactions. Ultimately, the project will increase the usability and fairness of robots deployed in human spaces.\r\n\r\nThis CAREER project will study how robots can learn about noisy, unpredictable human environments from spoken language combined with perception, using context derived from sensors to constrain the learning problem. Grounded language refers to language that occurs in and refers to the physical world in which robots operate. Human interactions are fundamentally contextual: when learning about the world, we focus learning by considering not only direct communication but also the context of that interaction. For much existing work on learning to understand physically situated language, text is the primary interlingua, and context is considered relatively narrowly. Additionally, reliance on pre-existing large datasets has begun to raise questions about bias and inclusivity in learning-driven technologies. To address these limitations, this work will focus on learning semantics directly from perceptual inputs combined with speech from diverse sources. The goal is to develop learning infrastructure, algorithms, and approaches to enable robots to learn to understand task instructions and object descriptions from spoken communication with end users. The project will develop new methods of efficiently learning from multi-modal data inputs, with the ultimate goal of enabling robots to efficiently and naturally learn about their world and the tasks they should perform.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cynthia",
   "pi_last_name": "Matuszek",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cynthia Matuszek",
   "pi_email_addr": "cmat@umbc.edu",
   "nsf_id": "000690099",
   "pi_start_date": "2022-03-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland Baltimore County",
  "inst_street_address": "1000 HILLTOP CIR",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4104553140",
  "inst_zip_code": "212500001",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND BALTIMORE COUNTY",
  "org_prnt_uei_num": "",
  "org_uei_num": "RNKYWXURFRL5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland Baltimore County",
  "perf_str_addr": "1000 Hilltop Circle ITE 325",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212500001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 548928.0
  }
 ],
 "por": null
}