{
 "awd_id": "2210266",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Framework: Software: CINES: A Scalable Cyberinfrastructure for Sustained Innovation in Network Engineering and Science",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032925147",
 "po_email": "dmassey@nsf.gov",
 "po_sign_block_name": "Daniel F. Massey",
 "awd_eff_date": "2021-10-01",
 "awd_exp_date": "2024-05-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 405881.0,
 "awd_min_amd_letter_date": "2022-01-07",
 "awd_max_amd_letter_date": "2022-01-07",
 "awd_abstract_narration": "Networks are ubiquitous and are a part of our common vocabulary. Network science and engineering has emerged as a formal field over the last twenty years and has seen explosive growth.  Ideas from network science are central to companies such as Akamai, Twitter, Google, Facebook, and LinkedIn.  The concepts have also been used to address fundamental problems in diverse fields (e.g., biology, economics, social sciences, psychology, power systems, telecommunications, public health and marketing), and are now part of most university curricula. Ideas and techniques from network science are widely used in making scientific progress in the disciplines mentioned above.  Networks are now part of the public vocabulary, with news articles and magazines frequently using the term \"networks\" to refer to interconnected entities.  Yet, resources for effective use of techniques from network science are largely dispersed and stand-alone, of small scale, home-grown for personal use, and/or do not cover the broad range of operations that need to be performed on networks.  Compositions of these diverse capabilities are rare.  Furthermore, many researchers who study networks are not computer scientists.  As a result, they do not have easy access to computing and data resources; this creates a barrier for researchers. This project will develop a sophisticated cyberinfrastructure that brings together various resources to provide a unifying ecosystem for network science that is greater than the sum of its parts. The resulting cyberinfrastructure will benefit researchers and students from various disciplines by facilitating access to various tools for synthesizing and analyzing large networks, and by providing access points for contributors of new software and data. An important benefit of the system is that it can be readily used even by researchers who have no formal training in computer programming.  The cyberinfrastructure resulting from this work will foster multi-disciplinary and multi-university research and teaching collaborations. As part of this project, comprehensive education and outreach programs will be launched by the participating institutions, spanning educators and K-12 students. These programs will include network science courses with students from minority and under-represented groups, and students at smaller institutions who do not have easy access to high performance computing resources.\r\n\r\n\r\nResources for doing network science are largely dispersed and stand-alone (in silos of isolated tools), of small scale, or home-grown for personal use.  What is needed is a cyberinfrastructure to bring together various resources, to provide a unifying ecosystem for network science that is greater than the sum of its parts. The primary goal of this proposal is to build self-sustaining cyberinfrastructure (CI) named CINES (Cyberinfrastructure for Sustained Innovation in Network Engineering and Science) that will be a community resource for network science.  CINES will be an extensible and sustainable platform for producers and consumers of network science data, information, and software.  CINES will have: (1) a layered architecture that systematically modularizes and isolates messaging, infrastructure services, common services, a digital library, and APIs for change-out  and updates; (2) a robust and reliable infrastructure that---for applications (apps)---is designed to accommodate technological advances in methods, programming languages, and computing models; (3) a resource manager to enable jobs to run on target machines for which they are best suited; (4) an engine to enable users to create new workflows by composing available components and to distribute the resulting workload across computing resources; (5) orchestration among system components to provide CI-as-a-service (CIaaS) that scales under high system load to networks with a billion or more vertices; (6) a digital library with 100,000+ networks of various kinds that allows rich services for storing, searching, annotating, and browsing; (7) structural methods (e.g., centrality, paths, cuts, etc.) and dynamical models of various contagion processes; (8) new methods to acquire data, build networks, and augment them using machine learning techniques; (9) a suite of industry- recognized tools such as SNAP, NetworkX, and R-studio that make it easier for researchers, educators, and analysts to do network science and engineering; (10) a suite of APIs that allows developers to add new web-apps and services, based on an app-store model, and allows access to CINES from third party software; and (11) metrics and a Stack Overflow model, among other features, for producers and consumers to interact (in real-time) and guide the evolution of CINES. CINES will enable fundamental changes in the way researchers study and teach complex networks.  The use of state-of-the-art high-performance computing (HPC) resources to synthesize, analyze, and reason about large networks will enable researchers and educators to study networks in novel ways. CINES will allow scientists to address fundamental scientific questions---e.g., biologists can use network methods to reason about genomics data that is now available in large quantities due to fast and effective sequencing and the NIH Microbiome Program.  It will enable educators to harness HPC technologies to teach Network Science to students spanning various academic levels, disciplines, and institutions.  CINES, which will be useful to researchers supported by many NSF directorates and divisions, will be designed for scalability, usability, extensibility, and sustainability. This project will also advance the fields of digital libraries and cloud computing by stretching them to address challenges related to Network Science.  Given the multidisciplinary nature of the field, CINES will provide a collaborative space for scientists from different disciplines, leading to important cross fertilization of ideas.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Geoffrey",
   "pi_last_name": "Fox",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Geoffrey C Fox",
   "pi_email_addr": "vxj6mb@virginia.edu",
   "nsf_id": "000231257",
   "pi_start_date": "2022-01-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Virginia Main Campus",
  "inst_street_address": "1001 EMMET ST N",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTESVILLE",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "4349244270",
  "inst_zip_code": "229034833",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "VA05",
  "org_lgl_bus_name": "RECTOR & VISITORS OF THE UNIVERSITY OF VIRGINIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJG6HU8PA4S5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Virginia Main Campus",
  "perf_str_addr": "P.O. BOX 400195",
  "perf_city_name": "CHARLOTTESVILLE",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "229044195",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "VA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "800400",
   "pgm_ele_name": "Software Institutes"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "026Z",
   "pgm_ref_txt": "NSCI: National Strategic Computing Initi"
  },
  {
   "pgm_ref_code": "077Z",
   "pgm_ref_txt": "CSSI-1: Cyberinfr for Sustained Scientif"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "8004",
   "pgm_ref_txt": "Software Institutes"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 405881.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-e3546347-7fff-5ce9-f37c-9a88b97c8e24\"> </span></p>\n<p dir=\"ltr\"><span>This project is part of the CINES (Cyberinfrastructure for Network Science) collaboration, and its research falls into two areas: firstly, high-performance cyberinfrastructure and secondly, tools that support deep learning-based time series for Network science and, more generally, AI for Science. The CINES project consists of the following universities: University of Virginia, Virginia Tech, Stanford University, University of North Carolina A&amp;T, Jackson State University, and Indiana University was involved but that work was transferred to the University of Virginia.&nbsp;</span></p>\n<p dir=\"ltr\"><span>In the area of data engineering, we focussed on two areas. First, we improved the parallel performance of the core operations such as sort, shuffle, union, and join for the open-source Cylon project. Cylon is the C++/Python high-performance kernel building on the system Twister2 built before CINES started. This project improved Cylon&rsquo;s performance advantages over Spark, Modin, and Dask. The project linked Cylon to the popular workflow engine Radical Pilot in collaboration with the design team of this workflow. This illustrated our architectural approach, where we use existing capabilities where possible and do not build a new workflow environment but rather reuse state-of-the-art existing systems. Our contribution is the much improved parallel and vector (due to Apache Arrow) performance of Cylon. In a new paper on shuffling, we used the Apache Arrow vector format (heart of Cylon) and Apace Parquet (disk form of Arrow) plus parallel I/O to improve the two major PyTorch shuffling systems. This is a step towards integrating Cylon with deep learning systems. It was tested first on large language model training and will be extended to other data modalities.</span></p>\n<p dir=\"ltr\"><span>For Time Series, we developed a common pattern approach to extend our time series deep learning library to many other domains: Covid, Flu, earthquakes, and Hydrology.&nbsp; We published several papers, including one that will be presented at the SC24 conference. We distinguish patterns where a common architecture/library is developed and trained separately on each application and Foundation models, which are pre-trained on a large dataset and fine-tuned on each separate application. This project reported on important computer science findings from these time series results. We looked at twenty different proposed Foundation and pattern models for Time Series and found they underperformed custom-trained pattern models as fine-tuning was not as effective as training from scratch. Further, we showed that using exogenous (known) data improved fits up to a factor of 2 for mean square error in the hydrology case with extensive exogenous information. Finally, we introduced a new style of foundation model, MultiFoundationPattern, which gave the best performance in our study.</span></p>\n<p dir=\"ltr\"><span>The project worked with the major consortium MLCommons, which is a non-profit consortium comprised of over 125 corporations, Universities, and Government entities. It promotes non-proprietary activities based on three pillars: Machine Learning (ML) benchmarks and models, ML datasets, and ML best practices. We focus on the Science Data working group, where we have released a Science benchmark using our time series technology. The project also interacts with the AI Alliance and Trillion Parameter Consortia, each with over 80 institutional members. The AI Alliance is setting up a Time Series activity.</span></p>\n<div><span><br /></span></div>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 10/27/2024<br>\nModified by: Geoffrey&nbsp;C&nbsp;Fox</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/2210266/2210266_10577216_1730056268868_Foundation_Models__for_Science_Time_Series_AI_Alliance_Oct_3_2024--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2024/2210266/2210266_10577216_1730056268868_Foundation_Models__for_Science_Time_Series_AI_Alliance_Oct_3_2024--rgov-800width.jpg\" title=\"Looking at lots of Models for Earthquake Nowcasting: Patterns outperform Foundation Models\"><img src=\"/por/images/Reports/POR/2024/2210266/2210266_10577216_1730056268868_Foundation_Models__for_Science_Time_Series_AI_Alliance_Oct_3_2024--rgov-66x44.jpg\" alt=\"Looking at lots of Models for Earthquake Nowcasting: Patterns outperform Foundation Models\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">22 Time series models for Earthquakes listed in order of decreasing Mean Square Error MSE. F are Foundation and P Pattern models. Chronos and TimeLLM are LLM based. MultiFoundationQuake is our simple FM gotten by enhancing one pattern by other FMs or patterns</div>\n<div class=\"imageCredit\">Geoffrey Fox, Alireza Jafari, John Rundle, Andrea Donnellan, Lisa Grant</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Geoffrey&nbsp;C&nbsp;Fox\n<div class=\"imageTitle\">Looking at lots of Models for Earthquake Nowcasting: Patterns outperform Foundation Models</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\n \n\n\nThis project is part of the CINES (Cyberinfrastructure for Network Science) collaboration, and its research falls into two areas: firstly, high-performance cyberinfrastructure and secondly, tools that support deep learning-based time series for Network science and, more generally, AI for Science. The CINES project consists of the following universities: University of Virginia, Virginia Tech, Stanford University, University of North Carolina A&T, Jackson State University, and Indiana University was involved but that work was transferred to the University of Virginia.\n\n\nIn the area of data engineering, we focussed on two areas. First, we improved the parallel performance of the core operations such as sort, shuffle, union, and join for the open-source Cylon project. Cylon is the C++/Python high-performance kernel building on the system Twister2 built before CINES started. This project improved Cylons performance advantages over Spark, Modin, and Dask. The project linked Cylon to the popular workflow engine Radical Pilot in collaboration with the design team of this workflow. This illustrated our architectural approach, where we use existing capabilities where possible and do not build a new workflow environment but rather reuse state-of-the-art existing systems. Our contribution is the much improved parallel and vector (due to Apache Arrow) performance of Cylon. In a new paper on shuffling, we used the Apache Arrow vector format (heart of Cylon) and Apace Parquet (disk form of Arrow) plus parallel I/O to improve the two major PyTorch shuffling systems. This is a step towards integrating Cylon with deep learning systems. It was tested first on large language model training and will be extended to other data modalities.\n\n\nFor Time Series, we developed a common pattern approach to extend our time series deep learning library to many other domains: Covid, Flu, earthquakes, and Hydrology. We published several papers, including one that will be presented at the SC24 conference. We distinguish patterns where a common architecture/library is developed and trained separately on each application and Foundation models, which are pre-trained on a large dataset and fine-tuned on each separate application. This project reported on important computer science findings from these time series results. We looked at twenty different proposed Foundation and pattern models for Time Series and found they underperformed custom-trained pattern models as fine-tuning was not as effective as training from scratch. Further, we showed that using exogenous (known) data improved fits up to a factor of 2 for mean square error in the hydrology case with extensive exogenous information. Finally, we introduced a new style of foundation model, MultiFoundationPattern, which gave the best performance in our study.\n\n\nThe project worked with the major consortium MLCommons, which is a non-profit consortium comprised of over 125 corporations, Universities, and Government entities. It promotes non-proprietary activities based on three pillars: Machine Learning (ML) benchmarks and models, ML datasets, and ML best practices. We focus on the Science Data working group, where we have released a Science benchmark using our time series technology. The project also interacts with the AI Alliance and Trillion Parameter Consortia, each with over 80 institutional members. The AI Alliance is setting up a Time Series activity.\n\n\n\n\n\t\t\t\t\tLast Modified: 10/27/2024\n\n\t\t\t\t\tSubmitted by: GeoffreyCFox\n"
 }
}