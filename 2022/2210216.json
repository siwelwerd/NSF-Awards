{
 "awd_id": "2210216",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Numerical Construction of Optimal Estimators Using Machine Learning Tools",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2022-09-15",
 "awd_exp_date": "2025-08-31",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2022-06-16",
 "awd_max_amd_letter_date": "2022-06-16",
 "awd_abstract_narration": "Optimal statistical procedures make maximal use of available data, making it possible to answer pressing scientific questions more precisely and cost-effectively. These procedures are traditionally derived via analytic calculations that require expert knowledge achieved over many years of training. In this project, the investigators will study two novel strategies for deriving optimal procedures. Compared to existing approaches, these strategies require more expertise in computational methods and less expertise in statistical theory. As a result, this project will broaden the pool of researchers who can develop optimal statistical procedures. If preliminary results support the strong performance of the new methods, the investigators will incorporate them into vaccine clinical trial data analyses. Through this project, the investigators will engage undergraduates in statistical research and advance the understanding of mentored graduate students.\r\n\r\nThe investigators will consider both local and global notions of optimality. The first strategy will use novel representations of the efficient influence function (EIF). The EIF is a critical ingredient for constructing asymptotically efficient estimators, particularly in nonparametric and semiparametric models. It also provides a principled approach to debias machine learning-based estimators to recover valid statistical inference. Unfortunately, the conventional approach for deriving the EIF involves advanced theory that is often not taught in statistical curricula. Additionally, in some problems, the EIF does not have a closed form, rendering its use difficult even for experts. The investigators will derive a novel representation of the EIF that lends itself to computerization and study how it can be used to derive novel asymptotically efficient estimators. The second strategy will use ideas from deep reinforcement learning, as used recently to build self-learning game playing algorithms with super-human performance, to adversarially learn (globally and locally) minimax optimal statistical procedures with computational tools. Except in simple cases, analytic calculations have thus far only been successfully used to derive estimators that are asymptotically minimax optimal. However, asymptotic optimality does not generally guarantee optimality in small samples. Existing works on numerically learning minimax optimal estimators use a Bayesian formulation of the minimax problem. This formulation results in learning schemes that are too computationally prohibitive to be applicable to most problems. This project will develop and study an alternative means to construct these estimators that can readily leverage massively parallel computing.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alex",
   "pi_last_name": "Luedtke",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alex Luedtke",
   "pi_email_addr": "aluedtke@uw.edu",
   "nsf_id": "000793258",
   "pi_start_date": "2022-06-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Marco",
   "pi_last_name": "Carone",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Marco Carone",
   "pi_email_addr": "mcarone@uw.edu",
   "nsf_id": "000732429",
   "pi_start_date": "2022-06-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "4333 Brooklyn AVE NE",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981950001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": null
}