{
 "awd_id": "2208771",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: FET: Medium:  Energy-Efficient Persistent Learning-in-Memory with Quantum Tunneling Dynamic Synapses",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2022-10-01",
 "awd_exp_date": "2025-09-30",
 "tot_intn_awd_amt": 525000.0,
 "awd_amount": 525000.0,
 "awd_min_amd_letter_date": "2022-08-25",
 "awd_max_amd_letter_date": "2022-08-25",
 "awd_abstract_narration": "This research project investigates a framework that can significantly improve the energy-efficiency of training artificial intelligence (AI) systems using circuits and system architectures that are based on quantum-tunneling dynamic-analog-memory (DAM) devices. In 2019, the energy required to train a top-of-the-line AI system was more than the energy required to operate five US cars over their entire lifetime. The energy requirements for training large-scale AI systems have only gotten worse since to the point of being unsustainable. The proposed research aims to develop novel learning hardware that will make the training of ML and AI systems more energy sustainable. The project is also developing software tools for training AI systems that can be disseminated and adopted by the research community. The novel online learning and memory consolidation algorithms that are being developed in this project will be integrated with an openly shared, general-purpose neuromorphic cognitive computing platform available through the Neuroscience Gateway (NSG) Portal at the San Diego Supercomputer Center. In collaboration with Efabless Inc. the project is supporting open-source development of mixed-signal integrated circuits (IC) design tools that is being evaluated through in class-room instruction and projects.\r\n\r\nThe technical activities of this research project are based on an ultra-energy-efficient synaptic element called Fowler-Nordheim Dynamic Analog Memory (FN-DAM) that can be easily fabricated on a standard integrated circuits process. The memory retention property of the synaptic element has been previously shown to be adaptive and can be traded-off with the energy required for synaptic updates. These FN-DAM properties are being explored within the context of the following research objectives: 1) Investigation into novel FN-DAM based neural network training and learning algorithms and architecture: Mechanisms are being explored that can connect the dynamics of FN-DAM array with the training formulations of standard convolutional neural network. Efficient one-shot continual online learning techniques are being investigated that exploit the dynamics of FN-DAM to improve the speed and robustness of learning. The framework is being used to explore connections between the FN-DAM based architectures with neuromorphic memory architectures that combines episodic-memories with incremental learning paradigms; 2) Investigation into novel FN-DAM based compute-in-memory and on-chip learning architectures: Analog compute-in-memory learning architectures are being investigated that integrate FN-DAM arrays with CMOS computing circuits and on-chip adaptation and learning strategies; 3) Validation of the FN-DAM based hardware-software co-design framework: The project is validating the co-design framework for achieving high energy-efficiency in neural network training using the NSF CISE Community Research Infrastructure (CRI) for large-scale neuromorphic cognitive computing developed and maintained at University of California at San Diego (UCSD). The project is also validating the energy-efficiency improvements that can be achieved using prototypes that will be fabricated in a standard integrated circuits process.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gert",
   "pi_last_name": "Cauwenberghs",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gert Cauwenberghs",
   "pi_email_addr": "gert@ucsd.edu",
   "nsf_id": "000486695",
   "pi_start_date": "2022-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "Office of Contract & Grant Admin",
  "perf_city_name": "La Jolla",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930934",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "089Y00",
   "pgm_ele_name": "FET-Fndtns of Emerging Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "086Z",
   "pgm_ref_txt": "Neuromorphic Computing"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 525000.0
  }
 ],
 "por": null
}