{
 "awd_id": "2210891",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Testing and Deep Learning for Functional Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032927299",
 "po_email": "yzeng@nsf.gov",
 "po_sign_block_name": "Yong Zeng",
 "awd_eff_date": "2022-07-01",
 "awd_exp_date": "2025-06-30",
 "tot_intn_awd_amt": 299997.0,
 "awd_amount": 299997.0,
 "awd_min_amd_letter_date": "2022-05-20",
 "awd_max_amd_letter_date": "2022-05-20",
 "awd_abstract_narration": "The proposed research involves two distinctive fields, functional data analysis (FDA) and deep learning. Functional data are random functions, which have become increasingly common due to technological advances to handle massive data.  Examples include climate or air pollution data collected over a period of time. The field has emerged as a mainstream research area, but the literature is mainly focused on estimation problems and has not yet leveraged the advantages of deep learning methods. This project aims to fill these gaps. It includes several new tests for functional data and employs deep learning, instead of the conventional nonparametric smoothing methods, to handle functional data. The proposed approaches will be applied to various functional data, including evaluating the effect of pollutants on lung cancer mortality and explaining the effects of physical activity on health.  A major emphasis is the development of new theory and algorithms. Computer code associated with the research will be publicly disseminated as R- or Python packages. The research findings will be incorporated in graduate curricula, undergraduate research projects, and short courses at workshops.  They will also be presented at professional meetings. Student researchers will receive training in research, computing and communication skills.\r\n\r\n\r\n\r\nAlthough functional data are intrinsically infinite dimensional, measurements are only available at discrete locations, which may vary from subject to subject. The number of measurement locations per subject can be small (sparse functional data) or grow with the sample size (intensely sampled functional data). The proposed research covers all types of sampling plans and employs, whenever feasible, a single platform that is universally applicable. Such an approach is important as it is not trivial to judge whether the sampling plan for a particular dataset is intense or sparse. It also has the merit that the theory is unified and automatically reveals the phase transitions of the convergence rates of the corresponding estimators. Project 1 (Hypothesis Testing for Functional Linear Models) aims at developing a general framework for hypothesis testing under the setting of functional linear models.  Existing methods focus on testing a specific null hypothesis using a tailored test and are not well suited for testing the temporal duration of the effect of a functional covariate, such as the impact of PM2.5 on lung cancer. None of them has been shown to be optimal for a composite null hypothesis. We propose a single platform to test the null hypothesis that the regression coefficient of a functional covariate resides in a closed subspace of all possible coefficient functions.  The proposed test, which resembles the classical F-test, is simple and includes tests for global nullity, partial nullity and domain of the coefficient function as special cases. Project 2 (Testing Homogeneity and Independence for Functional Data) addresses the challenges of two fundamental tasks, testing the homogeneity (equal distributions) and independence of functional data. Such tests are infeasible when the functional process can only be sampled at a few discrete locations, a situation that is ubiquitous in longitudinal studies. For each task, we propose a customized version, marginal homogeneity or marginal independence, that has practical implications and is feasible for theory and implementation. Project 3 (Deep learning for Functional Data) aims at bringing the success of deep learning to bear with functional data. Surprisingly, the application of deep neural networks to functional data has been scarce and remains an open problem. A recent approach, developed by a team led by the PI, uses neural networks to search for the optimal basis functions to represent a functional input that automatically adapts to the prediction task in hand. We propose to expand the reach and theoretical understanding of this adaptive basis approach. Another objective is to design new methodology to impute partially observed functional data that uses Transformers, a deep neural network that transforms a given sequence of elements, such as the sequence of words in a sentence, into another sequence. The project will offer a broad range of new opportunities for interdisciplinary training of a future generation of statisticians and will contribute to enhancing a more inclusive atmosphere in statistical sciences.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jane-Ling",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jane-Ling Wang",
   "pi_email_addr": "janelwang@ucdavis.edu",
   "nsf_id": "000452165",
   "pi_start_date": "2022-05-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Davis",
  "perf_str_addr": "1 Shields Ave",
  "perf_city_name": "Davis",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956165270",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  },
  {
   "pgm_ele_code": "745400",
   "pgm_ele_name": "MSPA-INTERDISCIPLINARY"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "068Z",
   "pgm_ref_txt": "URoL-Understanding Rules of Life"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "1269",
   "pgm_ref_txt": "STATISTICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 299997.0
  }
 ],
 "por": null
}