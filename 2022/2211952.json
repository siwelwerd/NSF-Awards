{
 "awd_id": "2211952",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: RI: Medium: From Acoustic Signal to Morphosyntactic Analysis in One End-to-End Neural System",
 "cfda_num": "47.070, 47.075",
 "org_code": "05020000",
 "po_phone": "7032922972",
 "po_email": "emiltsak@nsf.gov",
 "po_sign_block_name": "Eleni Miltsakaki",
 "awd_eff_date": "2022-08-01",
 "awd_exp_date": "2026-07-31",
 "tot_intn_awd_amt": 301916.0,
 "awd_amount": 317489.0,
 "awd_min_amd_letter_date": "2022-07-27",
 "awd_max_amd_letter_date": "2024-01-16",
 "awd_abstract_narration": "There are approximately 7,000 languages in the world today, but this number is declining precipitously.\r\nEven many languages that currently have thousands upon thousands of speakers are likely to fall out\r\nof use within a generation. For the speakers of these languages, this represents a tragic loss of cultural\r\nand linguistic heritage, which are important anchors of their social identity. Each language also carries\r\nirreplaceable data about language as a phenomenon of human behavior\u2014the limits of its variation and\r\nthe patterns in its structure and development. Linguists and language activists are currently working to\r\nquickly and comprehensively document as many languages as possible. In the unfortunate event that a\r\nlanguage fades from use, documentation ensures that its data will remain available for future cultural or\r\nscientific analysis. This project partially automates the process of language documentation using tools\r\nfrom Natural Language Processing and Machine Learning. It differs from similar projects in using one\r\nintegrated system to process the sounds of speech and the structure of words, instead of using two or\r\nmore separate components. With the collaboration of native speaker scholars, the researchers are applying\r\ntheir methodology to four languages: Highland Puebla Nahuatl, Yolox\u00f3chitl Mixtec, San Pedro Amuzgos\r\nAmuzgo, and North Slope I\u00f1upiaq.\r\n\r\nThe proposed research will dramatically transform the landscape of automatic morphosyntactic and\r\nmorphophonological analysis by introducing an end-to-end system that consumes speech as an input and\r\nproduces interlinear annotations as an output. The research team proposes to build an end-to-end system,\r\na single neural net that, with small amounts of labeled data produced by native speaker linguists, can\r\ndirectly convert recorded speech to analyzed text, producing four outputs: (1) surface transcription, (2)\r\nmorphological segmentation of surface forms, (3) an underlying or canonical form for each morpheme,\r\nand (4) a gloss or standardized label for each morpheme. The proposed single end-to-end neural network\r\nrepresents the first attempt to integrate the four aforementioned tasks into a single neural network, avoiding\r\nthe error-propagation problems that have plagued earlier attempts at creating a pipeline and mitigating the\r\ncomplexity of the technology for end-users. The researchers also propose innovative ways to incorporate linguistic\r\nknowledge into neural networks, including the use of differentiable weighted finite-state transducers,\r\nwhich are independently motivated by an iterative self-training architecture. This approach to iterative self training,\r\nin its own right, will represent an advance in machine learning \u2014 a new algorithm for upweighting\r\nwords and morphemes. The research also makes significant contributions to computational morphology.\r\nIt includes a simple but expressive modification to existing schemes for segmentation and glossing, specifically\r\nfor the representation of discontinuous morphemes. Furthermore, the proposal extends popular\r\napproaches to morphological analysis (e.g., UniMorph) by systematically addressing derivation as well as\r\ninflection. This proposal addresses glossing of reduplication and noun-incorporation, which earlier work\r\nhas not.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jonathan",
   "pi_last_name": "Amith",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Jonathan D Amith",
   "pi_email_addr": "jamith@gettysburg.edu",
   "nsf_id": "000197819",
   "pi_start_date": "2022-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Gettysburg College",
  "inst_street_address": "300 N WASHINGTON ST",
  "inst_street_address_2": "",
  "inst_city_name": "GETTYSBURG",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "7173376505",
  "inst_zip_code": "173251483",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "PA13",
  "org_lgl_bus_name": "GETTYSBURG COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LM61PK5X7HK9"
 },
 "perf_inst": {
  "perf_inst_name": "Gettysburg College",
  "perf_str_addr": "North Washington Street",
  "perf_city_name": "Gettysburg",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "173251483",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "PA13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "122Y00",
   "pgm_ele_name": "DLI-Dyn Language Infrastructur"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7719",
   "pgm_ref_txt": "DEL"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 301916.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 15573.0
  }
 ],
 "por": null
}