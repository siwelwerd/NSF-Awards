{
 "awd_id": "2218819",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Conference: US-UK Workshop on Developing a Roadmap for Collaborative AI R&D",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Juan Wachs",
 "awd_eff_date": "2022-03-15",
 "awd_exp_date": "2023-02-28",
 "tot_intn_awd_amt": 38417.0,
 "awd_amount": 38417.0,
 "awd_min_amd_letter_date": "2022-03-15",
 "awd_max_amd_letter_date": "2022-03-15",
 "awd_abstract_narration": "The objective of this award is to support the logistics portion of a virtual workshop that will bring together researchers from the United States and the United Kingdom in the field of artificial Intelligence (AI).  The goal of the workshop is to identify priorities for collaborative research in AI, develop an agenda to develop new research areas, build upon existing collaborations and establish practices for continuous engagement around sharing of new research and development breakthroughs.\r\n\r\nThe workshop will take place virtually over two days in May 2022. The workshop will bring together about 20 researchers from the United States and about 20 researchers from the United Kingdom. Each session in the workshop will include presentations from the researchers, as well as roundtable discussions to identify key areas of research and set the framework for a collaborative agenda in AI.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeannette",
   "pi_last_name": "Wing",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jeannette M Wing",
   "pi_email_addr": "WING@COLUMBIA.EDU",
   "nsf_id": "000142080",
   "pi_start_date": "2022-03-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "2960 Broadway",
  "perf_city_name": "NEW YORK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100276902",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 38417.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This May 2022 workshop brought together some 50 leading researchers and practitioners in AI from both the US and the UK, with the goals of sharing knowledge and experience, and identifying and prioritizing possible areas for US-UK cooperation going forward. This report summarizes the findings and recommendations of that workshop.While the prior expectation was that participants would focus largely on specific research areas,</p>\n<p>In terms of specific research topics, participants were vocal in their view that the now well-known issues of trustworthy AI and explainable AI remain very prominent, and deserving of further research. Trustworthiness touches on issues from human-AI interaction to the formal verification of AI systems, while explainability relates to the issue that contemporary machine learning techniques result in &ldquo;black box&rdquo; systems, from which it is difficult or impossible to distill any human-comprehensible rationale for a system&rsquo;s behavior. Both of these issues represent substantial impediments to the wider take up of AI, particularly in safety-critical applications. Participants noted that many prominent recent AI systems (such as OpenAI&rsquo;s GPT-3) appear to have impressive capabilities in some problem domains, and yet we have difficulty in understanding exactly what the limits of these capabilities are. Work is therefore required on systematically benchmarking the capabilities of such systems. Much discussion in the workshop focused on the issue of computational resources and data used for machine learning systems, and in particular, the fact that state-of-the-art machine learning systems require extraordinarily large data sets to train models on large computational infrastructure; research is thus required to enable machine learning with small data sets. While machine learning approaches are currently predominant in AI research, participants noted that combining such approaches with other AI technologies (e.g., probabilistic reasoning, symbolic reasoning) is a natural direction for investigation. Finally, new hardware paradigms such as quantum computing offer the potential to transform the capabilities of AI systems.</p>\n<p>Turning to the societal impacts of AI, participants strongly voiced their desire to pursue beneficial applications of AI research, and to support this aim, advocated the dissemination of benchmark problems and data sets in areas such as climate, health, transport, agriculture, food production, and the urban environment. Participants also identified the importance of the human-centered AI paradigm, which explicitly considers the role that humans play in all aspects of the AI ecosystem. Education was also seen as a key issue: both the need to educate the public about AI, as well as the need to disseminate technical information about AI to researchers.</p>\n<p>In terms of specific application areas, finance, public health, the natural sciences, climate change/sustainability, and assistive living were all identified as natural targets for application-oriented research.</p>\n<p>Finally, participants strongly signaled the desire to see more done around the issue of diversity in AI. This aim meant not just addressing the well-documented lack of diversity within the AI research community, but tackling such issues as ensuring diversity in data sets and considering diversity in the design of AI systems. There was considerable discussion on the topic of diversity in the AI talent pipeline, and a range of measures were proposed to support this goal.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/31/2023<br>\n\t\t\t\t\tModified by: Jeannette&nbsp;Wing</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis May 2022 workshop brought together some 50 leading researchers and practitioners in AI from both the US and the UK, with the goals of sharing knowledge and experience, and identifying and prioritizing possible areas for US-UK cooperation going forward. This report summarizes the findings and recommendations of that workshop.While the prior expectation was that participants would focus largely on specific research areas,\n\nIn terms of specific research topics, participants were vocal in their view that the now well-known issues of trustworthy AI and explainable AI remain very prominent, and deserving of further research. Trustworthiness touches on issues from human-AI interaction to the formal verification of AI systems, while explainability relates to the issue that contemporary machine learning techniques result in \"black box\" systems, from which it is difficult or impossible to distill any human-comprehensible rationale for a system\u2019s behavior. Both of these issues represent substantial impediments to the wider take up of AI, particularly in safety-critical applications. Participants noted that many prominent recent AI systems (such as OpenAI\u2019s GPT-3) appear to have impressive capabilities in some problem domains, and yet we have difficulty in understanding exactly what the limits of these capabilities are. Work is therefore required on systematically benchmarking the capabilities of such systems. Much discussion in the workshop focused on the issue of computational resources and data used for machine learning systems, and in particular, the fact that state-of-the-art machine learning systems require extraordinarily large data sets to train models on large computational infrastructure; research is thus required to enable machine learning with small data sets. While machine learning approaches are currently predominant in AI research, participants noted that combining such approaches with other AI technologies (e.g., probabilistic reasoning, symbolic reasoning) is a natural direction for investigation. Finally, new hardware paradigms such as quantum computing offer the potential to transform the capabilities of AI systems.\n\nTurning to the societal impacts of AI, participants strongly voiced their desire to pursue beneficial applications of AI research, and to support this aim, advocated the dissemination of benchmark problems and data sets in areas such as climate, health, transport, agriculture, food production, and the urban environment. Participants also identified the importance of the human-centered AI paradigm, which explicitly considers the role that humans play in all aspects of the AI ecosystem. Education was also seen as a key issue: both the need to educate the public about AI, as well as the need to disseminate technical information about AI to researchers.\n\nIn terms of specific application areas, finance, public health, the natural sciences, climate change/sustainability, and assistive living were all identified as natural targets for application-oriented research.\n\nFinally, participants strongly signaled the desire to see more done around the issue of diversity in AI. This aim meant not just addressing the well-documented lack of diversity within the AI research community, but tackling such issues as ensuring diversity in data sets and considering diversity in the design of AI systems. There was considerable discussion on the topic of diversity in the AI talent pipeline, and a range of measures were proposed to support this goal.\n\n\t\t\t\t\tLast Modified: 03/31/2023\n\n\t\t\t\t\tSubmitted by: Jeannette Wing"
 }
}