{
 "awd_id": "2213839",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CCRI: Planning-C: A Framework for Development of Robots and IoT for Precision Agriculture",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032924702",
 "po_email": "cye@nsf.gov",
 "po_sign_block_name": "Cang Ye",
 "awd_eff_date": "2022-08-15",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 100000.0,
 "awd_amount": 116000.0,
 "awd_min_amd_letter_date": "2022-07-12",
 "awd_max_amd_letter_date": "2023-09-22",
 "awd_abstract_narration": "Agriculture is one of the least digitized industries. The US can gain a drastic advantage in this field by adopting automation for agriculture. Precision agriculture consists of using robotics and automation to increase economic benefits.  Automation using robots and Internet of Things is a key enabling factor for precision agriculture and can cut down greenhouse gas emissions and minimize impact on soil, water, and air. Robotic technologies can save tens of billions of dollars every year in herbicide, pesticide, fertilizer, and irrigation costs. They can eliminate the use of billions of pounds of chemicals that are harmful to the ecosystem. In this project, a team of researchers from California, North Dakota, Texas, and New Hampshire, will plan and design a computer modeling software for robots and Internet of Things for precision agriculture. This software will enable scientists and engineers to deploy and test new robots and devices virtually in a computer without physically building them. Using this award, the project team will collect a large amount of data (e.g., videos and images) from real-world farms and use this data to plan the aforementioned software. This data and open-source pedagogical tools will be made available to the public on the internet.\r\n\r\nThe fourth industrial revolution - characterized by smart automation and inter-connectivity - is about to change farm management practices forever. To hasten this positive change, the project team envisions an infrastructure that enables rapid development of robotic hardware, sensing technologies, software tools, and machine learning algorithms. While computer scientists and roboticists are developing novel software and hardware every day with great potential for precision agriculture, these tools typically fall short of real-world application. The envisioned simulation environment for testing such tools will bridge the gap between fundamental research and real-world deployment. These tools can enable autonomous farm management, including precision weed/pest management, precision irrigation, autonomous crop health monitoring, and precision crop protection. This can dramatically cut down labor costs, reduce chemical usage, lower the impact on water resources, conserve the fertility of soil, and increase the yield of crops. Computer scientists and roboticists will be able to get familiar with real-world challenges of precision agriculture, e.g., dramatic effects of precipitation on agriculture. The project team will collect preliminary data to prototype the infrastructure, organize workshops with interested researchers to plan the infrastructure, and connect with farmers and agronomists to gather feedback.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mohammad",
   "pi_last_name": "Khalid Jawed",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mohammad Khalid Jawed",
   "pi_email_addr": "khalidjm@seas.ucla.edu",
   "nsf_id": "000761752",
   "pi_start_date": "2022-07-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Wei",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wei Wang",
   "pi_email_addr": "weiwang@cs.ucla.edu",
   "nsf_id": "000153994",
   "pi_start_date": "2022-07-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jungseock",
   "pi_last_name": "Joo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jungseock Joo",
   "pi_email_addr": "jjoo@comm.ucla.edu",
   "nsf_id": "000746219",
   "pi_start_date": "2022-07-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sriram",
   "pi_last_name": "Narasimhan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sriram Narasimhan",
   "pi_email_addr": "snarasim@ucla.edu",
   "nsf_id": "000839353",
   "pi_start_date": "2022-07-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles",
  "perf_str_addr": "420 Westwood Plaza",
  "perf_city_name": "LOS ANGELES",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900958357",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  },
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 100000.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project focused on advancing robotics and IoT technologies for precision agriculture by addressing the lack of comprehensive simulation frameworks for agricultural robots and sensors. Current robotic simulators, such as Gazebo, are widely used in other domains but are insufficient for the unique requirements of agricultural environments. Our primary goals were to collect preliminary data from real-world agricultural fields and engage with the broader research and farming community to lay the foundation for a future CCRI (Cyberinfrastructure for Sustained Scientific Innovation) proposal.</p>\r\n<p>&nbsp;</p>\r\n<p>A major accomplishment of this project was the development of the &ldquo;AgroScapes&rdquo; dataset, which includes pixel-level annotated images of six diverse crops &mdash; canola, flax, strawberry, bean, corn, and cucumber. This dataset was collected from farms in California and North Dakota, demonstrating our capacity to gather high-quality visual data under varying field conditions. This data will support future research in precision agriculture by enabling the development and testing of machine learning models tailored to diverse crops, growth stages, and environmental factors.</p>\r\n<p>&nbsp;</p>\r\n<p>Another key outcome is &ldquo;Agronav,&rdquo; a vision-driven autonomous navigation framework designed for agricultural robots and vehicles. Agronav processes visual input through semantic segmentation and line detection models to generate a central guiding trajectory for robotic navigation. This framework serves as a proof of concept, illustrating the practical applications of the data collected and its potential to improve the efficiency and accuracy of farm management tasks.</p>\r\n<p>&nbsp;</p>\r\n<p>Throughout the project, we actively engaged with the research and farming communities by attending conferences, such as the 4th International Workshop on Agriculture-Vision at CVPR, and forging collaborations with universities and industrial stakeholders. These partnerships will help broaden the scope of our dataset and support the development of a comprehensive simulation framework for agricultural robotics.</p>\r\n<p>&nbsp;</p>\r\n<p>The broader impacts of this project extend beyond advancing robotics and computer vision in agriculture. By automating tasks like weed control, crop health monitoring, and yield estimation, our work addresses critical challenges in global food security and resource conservation, particularly in the face of climate change. Furthermore, the low-cost robotic platform developed through this project offers significant educational value, providing undergraduate students with hands-on experience in designing and building robotic systems.</p><br>\n<p>\n Last Modified: 01/06/2025<br>\nModified by: Mohammad&nbsp;Khalid Jawed</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/2213839/2213839_10813147_1736216563924_AgroNav_Project_Outcomes--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2213839/2213839_10813147_1736216563924_AgroNav_Project_Outcomes--rgov-800width.png\" title=\"Agronav\"><img src=\"/por/images/Reports/POR/2025/2213839/2213839_10813147_1736216563924_AgroNav_Project_Outcomes--rgov-66x44.png\" alt=\"Agronav\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Agronav: Autonomous Navigation Framework for Agricultural Robots and Vehicles using Semantic Segmentation and Semantic Line Detection</div>\n<div class=\"imageCredit\">S. Panda, Y. Lee, M. K. Jawed</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Mohammad&nbsp;Khalid Jawed\n<div class=\"imageTitle\">Agronav</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nThis project focused on advancing robotics and IoT technologies for precision agriculture by addressing the lack of comprehensive simulation frameworks for agricultural robots and sensors. Current robotic simulators, such as Gazebo, are widely used in other domains but are insufficient for the unique requirements of agricultural environments. Our primary goals were to collect preliminary data from real-world agricultural fields and engage with the broader research and farming community to lay the foundation for a future CCRI (Cyberinfrastructure for Sustained Scientific Innovation) proposal.\r\n\n\n\r\n\n\nA major accomplishment of this project was the development of the AgroScapes dataset, which includes pixel-level annotated images of six diverse crops  canola, flax, strawberry, bean, corn, and cucumber. This dataset was collected from farms in California and North Dakota, demonstrating our capacity to gather high-quality visual data under varying field conditions. This data will support future research in precision agriculture by enabling the development and testing of machine learning models tailored to diverse crops, growth stages, and environmental factors.\r\n\n\n\r\n\n\nAnother key outcome is Agronav, a vision-driven autonomous navigation framework designed for agricultural robots and vehicles. Agronav processes visual input through semantic segmentation and line detection models to generate a central guiding trajectory for robotic navigation. This framework serves as a proof of concept, illustrating the practical applications of the data collected and its potential to improve the efficiency and accuracy of farm management tasks.\r\n\n\n\r\n\n\nThroughout the project, we actively engaged with the research and farming communities by attending conferences, such as the 4th International Workshop on Agriculture-Vision at CVPR, and forging collaborations with universities and industrial stakeholders. These partnerships will help broaden the scope of our dataset and support the development of a comprehensive simulation framework for agricultural robotics.\r\n\n\n\r\n\n\nThe broader impacts of this project extend beyond advancing robotics and computer vision in agriculture. By automating tasks like weed control, crop health monitoring, and yield estimation, our work addresses critical challenges in global food security and resource conservation, particularly in the face of climate change. Furthermore, the low-cost robotic platform developed through this project offers significant educational value, providing undergraduate students with hands-on experience in designing and building robotic systems.\t\t\t\t\tLast Modified: 01/06/2025\n\n\t\t\t\t\tSubmitted by: MohammadKhalid Jawed\n"
 }
}