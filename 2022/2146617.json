{
 "awd_id": "2146617",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBE-UKRI: \"Looked but failed to see\" errors in human vision.",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2022-04-15",
 "awd_exp_date": "2025-03-31",
 "tot_intn_awd_amt": 534995.0,
 "awd_amount": 561919.0,
 "awd_min_amd_letter_date": "2022-04-06",
 "awd_max_amd_letter_date": "2024-05-22",
 "awd_abstract_narration": "It often happens that we fail to notice something that is in plain view. Sometimes this can even be something that we are actively looking for, like typos in our writing. These \u201clooked but failed to see\u201d (LBFTS) errors can be potentially dangerous, as when a radiologist fails to see signs of cancer in a lung x-ray or a driver fails to see someone crossing the road. The aim of this project is to understand the source of these  LBFTS errors and to investigate possible ways to reduce them.\r\n\r\nThere are a variety of different causes that might lead someone to fail to report something that is clearly visible when pointed out. For example, some LBFTS errors can be thought of as a version of bad luck: You can't process everything, so only some  stimuli get processed adequately. The experiments in Aim 1 investigate whether LBFTS errors in some tasks are random or whether there are attributes of the missed stimuli that make them less likely to be found. A second possibility, explored in Aim 2, is that there are perceptual biases within the functional visual field or useful field of view, defined as the region around the point where you are looking, within which you could find your target (even if you don\u2019t). For example, if you are reading English, while you are looking at one word, you are biased to the next words to the right rather than to the words directly above or below where you are fixating. When reading Arabic or Hebrew, you would be biased to words on the left of your fixation point. The two principal investigators on this project have different ideas about where the biases in the functional visual field  might come from and they exploit an \"adversarial collaboration\" in order to resolve these differences. Finally, Aim 3 is devoted to LBFTS errors that occur when doing one task but still \"keeping an eye out\" for other stimuli (e.g. when a doctor is examining a chest x-ray, it may show more than just the fractured rib about which the patient is complaining, such as a suspicious sign of cancer). The investigators will try to develop ways to help observers do their primary task while staying attuned to the possible occurrence of important but non-related events. If the sources of LBFTS errors can be identified and reduced, it could have a major impact on important societal arenas, such as medical image perception and traffic accidents.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeremy",
   "pi_last_name": "Wolfe",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jeremy M Wolfe",
   "pi_email_addr": "jwolfe@bwh.harvard.edu",
   "nsf_id": "000202279",
   "pi_start_date": "2022-04-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brigham & Women's Hospital Inc",
  "inst_street_address": "75 FRANCIS ST",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "8572821670",
  "inst_zip_code": "021156110",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "BRIGHAM & WOMENS HOSPITAL INC",
  "org_prnt_uei_num": "KH2QJR76KMZ6",
  "org_uei_num": "QN6MS4VN7BD1"
 },
 "perf_inst": {
  "perf_inst_name": "Brigham & Women's Hospital Inc",
  "perf_str_addr": "900 Commonwealth Avenue",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021156110",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "003Z",
   "pgm_ref_txt": "SBE-RCUK MOU"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 534995.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 13330.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 13594.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Can you find Loki, the cat, in Figure 1? (You might need to enlarge the figure.) If you didn&rsquo;t find Loki, look just above and to the right of the red leaf. You should see a clearly identifiable cat. Because that red leaf is so salient, it is very likely that you looked there, so, if you missed the cat, this would be an example of a &ldquo;Look but Fail to See&rdquo; (LBFTS) error. Missing Loki is trivial, but LBFTS errors become much more serious if the missed item is something like a pedestrian in a crosswalk or a tumor in an x-ray. We want to know how someone who knows what they are looking for can, in some cases, look right at that target but still fail to &ldquo;see&rdquo; it.</p>\r\n<p>In one set of experiments, we asked if LBFTS errors were either random or determined by the search stimuli. For this, we had observers search for the letter T among Ls.&nbsp; We showed observers hundreds of images like Figure 2. Even though the T is obvious, once you find it, people will miss 5-10% of them during an experiment. The trick in this experiment is that we showed each image twice. If errors were strictly determined, then, if the observer missed the T on one trial, they should miss it again when the same display reappeared. If, on the other hand, the observer had a random 10% chance of missing a target, then, if they missed it the first time, they would have just a 10% chance of missing it the second time. For images like Figure 2, we find that, by this definition, errors were quite random. Of course, some images (like Figure 1) make it more likely that you will miss the target, but if you have a stack of images of similar difficulty, your errors will be random. The cause might lie in the searcher. Maybe your mind drifted to dinner plans and the result was an LBFTS error. In ongoing work, we are looking for evidence of such error-prone states.</p>\r\n<p>But, how can you not &ldquo;see&rdquo; what you look at? When you look around the world, your eyes rest at each location for about a quarter of a second. In that time, you can typically attend to ~4-6 things, usually near your current point of fixation. Suppose you move your eyes to the star in Figure 3a. If you move your eyes away after a quarter of a second, you will not have been able to attend to all eight items and you might fail to &ldquo;see&rdquo; the &ldquo;T&rdquo;. We had observers look at rings of letters like these and we adjusted the duration of the display so that observers missed the T about 25% of the time. In Figure 3b-c, the distance of the curve away from the middle of the graph shows the magnitude of errors in each of the eight possible locations of the T. The thick, red curve shows the average error over many observers. On average, observers make more errors for the targets above and below than for targets to the left and right. The black curves on each figure each show results for one observer. The first observer misses targets that are down and to the right (Fig 3b). The second misses more items up and to the left (Fig 3c). These idiosyncratic patterns of errors are quite stable over time and may help explain the source of some LBFTS errors.</p>\r\n<p>Interestingly, people may know something about the targets that they fail to see. Figure 4 shows the targets for a task where we asked observers to look for three specific targets (the drink, ball, and shoe) and three categories of targets (any animal, fruit, or game). When observers searched through displays like Figure 5, they were more likely to find the specific shoe than the lemon (a member of the &ldquo;fruit&rdquo; category). When observers missed a target in this experiment, we later asked them tell us what they missed (e.g. &ldquo;Is it more likely that you missed a lemon or a mango?&rdquo;). The data show that they were not guessing. They made an LBFTS error, but we could show that some traces of the missed targets were present in their minds.</p>\r\n<p>To summarize: LBFTS errors are an interesting and important aspect of our visual search behavior. From our work on this project, we have learned about three aspects of these errors. 1) They have a substantial random component, 2) Individuals can have consistent idiosyncratic patterns of errors, and 3) Even when someone misses a target, that target may leave some detectable traces in the searcher&rsquo;s mind. Of course, beyond understanding LBFTS errors, we want to reduce them&ndash;especially on those important real-world tasks. We are working on that!</p><br>\n<p>\n Last Modified: 04/03/2025<br>\nModified by: Jeremy&nbsp;M&nbsp;Wolfe</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711375269_Slide1--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711375269_Slide1--rgov-800width.png\" title=\"Fig 01\"><img src=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711375269_Slide1--rgov-66x44.png\" alt=\"Fig 01\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 1: Find \ufffdLoki\ufffd the cat</div>\n<div class=\"imageCredit\">Wanyi Liu</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Jeremy&nbsp;M&nbsp;Wolfe\n<div class=\"imageTitle\">Fig 01</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711438756_Slide2--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711438756_Slide2--rgov-800width.png\" title=\"Fig 02\"><img src=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711438756_Slide2--rgov-66x44.png\" alt=\"Fig 02\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 2: Find the T</div>\n<div class=\"imageCredit\">J Wolfe</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Jeremy&nbsp;M&nbsp;Wolfe\n<div class=\"imageTitle\">Fig 02</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711863528_Slide5--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711863528_Slide5--rgov-800width.png\" title=\"Fig 05\"><img src=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711863528_Slide5--rgov-66x44.png\" alt=\"Fig 05\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 5: Find examples of any of those 6 target types</div>\n<div class=\"imageCredit\">J Wolfe</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Jeremy&nbsp;M&nbsp;Wolfe\n<div class=\"imageTitle\">Fig 05</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711509505_Slide3--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711509505_Slide3--rgov-800width.png\" title=\"Fig 03\"><img src=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711509505_Slide3--rgov-66x44.png\" alt=\"Fig 03\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 3: A) Observers would be asked to find the \ufffdT\ufffd in a brief flash. B & C) Each observer would have their own pattern of errors, missing more Ts in some spots than others.</div>\n<div class=\"imageCredit\">J Wolfe</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Jeremy&nbsp;M&nbsp;Wolfe\n<div class=\"imageTitle\">Fig 03</div>\n</div>\n</li><li>\n<a href=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711827850_Slide4--rgov-214x142.png\" original=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711827850_Slide4--rgov-800width.png\" title=\"Fig 04\"><img src=\"/por/images/Reports/POR/2025/2146617/2146617_10793110_1743711827850_Slide4--rgov-66x44.png\" alt=\"Fig 04\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 4: Six different types of search targets</div>\n<div class=\"imageCredit\">J Wolfe</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Jeremy&nbsp;M&nbsp;Wolfe\n<div class=\"imageTitle\">Fig 04</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nCan you find Loki, the cat, in Figure 1? (You might need to enlarge the figure.) If you didnt find Loki, look just above and to the right of the red leaf. You should see a clearly identifiable cat. Because that red leaf is so salient, it is very likely that you looked there, so, if you missed the cat, this would be an example of a Look but Fail to See (LBFTS) error. Missing Loki is trivial, but LBFTS errors become much more serious if the missed item is something like a pedestrian in a crosswalk or a tumor in an x-ray. We want to know how someone who knows what they are looking for can, in some cases, look right at that target but still fail to see it.\r\n\n\nIn one set of experiments, we asked if LBFTS errors were either random or determined by the search stimuli. For this, we had observers search for the letter T among Ls. We showed observers hundreds of images like Figure 2. Even though the T is obvious, once you find it, people will miss 5-10% of them during an experiment. The trick in this experiment is that we showed each image twice. If errors were strictly determined, then, if the observer missed the T on one trial, they should miss it again when the same display reappeared. If, on the other hand, the observer had a random 10% chance of missing a target, then, if they missed it the first time, they would have just a 10% chance of missing it the second time. For images like Figure 2, we find that, by this definition, errors were quite random. Of course, some images (like Figure 1) make it more likely that you will miss the target, but if you have a stack of images of similar difficulty, your errors will be random. The cause might lie in the searcher. Maybe your mind drifted to dinner plans and the result was an LBFTS error. In ongoing work, we are looking for evidence of such error-prone states.\r\n\n\nBut, how can you not see what you look at? When you look around the world, your eyes rest at each location for about a quarter of a second. In that time, you can typically attend to ~4-6 things, usually near your current point of fixation. Suppose you move your eyes to the star in Figure 3a. If you move your eyes away after a quarter of a second, you will not have been able to attend to all eight items and you might fail to see the T. We had observers look at rings of letters like these and we adjusted the duration of the display so that observers missed the T about 25% of the time. In Figure 3b-c, the distance of the curve away from the middle of the graph shows the magnitude of errors in each of the eight possible locations of the T. The thick, red curve shows the average error over many observers. On average, observers make more errors for the targets above and below than for targets to the left and right. The black curves on each figure each show results for one observer. The first observer misses targets that are down and to the right (Fig 3b). The second misses more items up and to the left (Fig 3c). These idiosyncratic patterns of errors are quite stable over time and may help explain the source of some LBFTS errors.\r\n\n\nInterestingly, people may know something about the targets that they fail to see. Figure 4 shows the targets for a task where we asked observers to look for three specific targets (the drink, ball, and shoe) and three categories of targets (any animal, fruit, or game). When observers searched through displays like Figure 5, they were more likely to find the specific shoe than the lemon (a member of the fruit category). When observers missed a target in this experiment, we later asked them tell us what they missed (e.g. Is it more likely that you missed a lemon or a mango?). The data show that they were not guessing. They made an LBFTS error, but we could show that some traces of the missed targets were present in their minds.\r\n\n\nTo summarize: LBFTS errors are an interesting and important aspect of our visual search behavior. From our work on this project, we have learned about three aspects of these errors. 1) They have a substantial random component, 2) Individuals can have consistent idiosyncratic patterns of errors, and 3) Even when someone misses a target, that target may leave some detectable traces in the searchers mind. Of course, beyond understanding LBFTS errors, we want to reduce themespecially on those important real-world tasks. We are working on that!\t\t\t\t\tLast Modified: 04/03/2025\n\n\t\t\t\t\tSubmitted by: JeremyMWolfe\n"
 }
}