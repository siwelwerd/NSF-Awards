{
 "awd_id": "2144822",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: RUI: CasualVR: Casual Capture of Dynamic Virtual Reality Environments",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922533",
 "po_email": "hshen@nsf.gov",
 "po_sign_block_name": "Han-Wei Shen",
 "awd_eff_date": "2022-07-01",
 "awd_exp_date": "2027-06-30",
 "tot_intn_awd_amt": 425786.0,
 "awd_amount": 252790.0,
 "awd_min_amd_letter_date": "2022-03-15",
 "awd_max_amd_letter_date": "2024-07-03",
 "awd_abstract_narration": "This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2).\r\n\r\nThe need for compelling new ways to connect, learn, and share remotely has never been more immediate and vital for society.  While most digital media today consist of flat, two-dimensional images and video, virtual reality technology will allow for sharing a complete three-dimensional representation of a scene, for a truly collaborative experience.  With virtual reality technology, schoolchildren could virtually stand at the entrance of an ancient pyramid, look at paintings in a renowned museum, or explore a rainforest.  Towards this high-level objective, the aim of this project is to enable anyone with a smartphone to easily capture and share a highly immersive virtual reality experience of their surroundings.  The development of widespread and consumer-accessible technology for sharing high-quality virtual reality experiences would enable the creation of more impactful and lasting learning experiences, support the development of empathy by enabling people to experience the lives of others more convincingly, and allow for more faithfully recordings of important experiences that might otherwise be lost.  The research objectives of this project will be integrated with several education and outreach activities. The investigator will work with an interdisciplinary team of students and faculty in biology and geography to develop immersive educational content about biodiversity in California and will implement an outreach workshop for California students to introduce them to the concepts behind three-dimensional reconstruction and view synthesis and have them create their own virtual reality experiences using the tools developed. Datasets generated as part of the research activities will be made public, serving as a great resource for other researchers and application developers.\r\n\r\nDespite a groundswell of recent developments, critical issues remain in terms of reconstructing virtual reality experiences from casually captured video, handling dynamic scenes, and rendering speed.  This project aims to close these gaps by exploring novel techniques for capture and reconstruction of dynamic physical environments. To address challenges in content capture and reconstruction, the project will explore new methods for automatic self-calibration and dynamic scene reconstruction from casually captured video using a neural implicit scene representation. This becomes a challenging task for more complex and dynamic scenes, where it might be tough to find a single transition (from scene to scene) which appears seamless across the entire volume. For faster capture and better handling of dynamic scenes, the project will develop deep learning techniques to automatically convert consumer panoramic video into a dynamic and immersive multi-layer representation.  Addressing storage efficiency and fast rendering, the project will investigate image-based capture and reconstruction of neural light fields.  The project will also produce new datasets for training and evaluating immersive view synthesis methods in dynamic scenes and develop new measures/metrics for the evaluation of the generated immersive content.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jonathan",
   "pi_last_name": "Ventura",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jonathan Ventura",
   "pi_email_addr": "jventu09@calpoly.edu",
   "nsf_id": "000677310",
   "pi_start_date": "2022-03-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "California Polytechnic State University Foundation",
  "inst_street_address": "1 GRAND AVE BLDG 15",
  "inst_street_address_2": "",
  "inst_city_name": "SAN LUIS OBISPO",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8057562982",
  "inst_zip_code": "934079000",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "CAL POLY CORPORATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "MC4RJJM9XLT5"
 },
 "perf_inst": {
  "perf_inst_name": "California Polytechnic State University",
  "perf_str_addr": "1 Grand Ave",
  "perf_city_name": "San Luis Obispo",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "934070001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "102Z",
   "pgm_ref_txt": "COVID-Disproportionate Impcts Inst-Indiv"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002324DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002425DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "010V2122DB",
   "fund_name": "R&RA ARP Act DEFC V",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 83421.0
  },
  {
   "fund_oblg_fiscal_yr": 2023,
   "fund_oblg_amt": 84250.0
  },
  {
   "fund_oblg_fiscal_yr": 2024,
   "fund_oblg_amt": 85119.0
  }
 ],
 "por": null
}