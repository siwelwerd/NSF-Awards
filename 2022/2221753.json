{
 "awd_id": "2221753",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "An Energy-Efficient, CMOS-based, and Scalable Mixed-Signal DNN System with Reconfigurable Crossbars",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": "7032922303",
 "po_email": "eabed@nsf.gov",
 "po_sign_block_name": "Eyad Abed",
 "awd_eff_date": "2022-09-01",
 "awd_exp_date": "2025-08-31",
 "tot_intn_awd_amt": 418907.0,
 "awd_amount": 418907.0,
 "awd_min_amd_letter_date": "2022-08-23",
 "awd_max_amd_letter_date": "2022-08-23",
 "awd_abstract_narration": "Deep neural networks have demonstrated high accuracy in a broad spectrum of applications, which are typically implemented on the cloud. However, it has become necessary to bring computation close to the data sources to address the data privacy, system latency, and energy consumption concerns, which are critical in applications such as healthcare, autonomous vehicles, and Internet-of-Things. Another arising issue relates to the typical use of digital systems to perform the necessary computations, but digital systems are fundamentally limited in handling big data efficiently. Although analog computation emerged as a promising alternative, which can outperform its digital counterpart by several orders of magnitudes in energy efficiency and computational speed, this alternative faces many challenges. First, emerging analog memories are unreliable, immature, and incompatible with standard CMOS technologies. Second, designing customizable and scalable analog deep neural networks that can support a broad range of deep neural networks is harder than the digital counterpart, leading to longer design cycles and higher costs. The broad goal of this project is to address these challenges by using innovative research directions in both analog and digital designs at the memory technology, circuit, architecture, and system levels, thereby enabling high scalability and great flexibility for various applications. This project will first develop a specialized electronic chip with a novel reconfigurable architecture and a new memory technology, utilizing a software-hardware co-design approach to achieve the necessary optimizations. Subsequently, this project will build a scalable system utilizing multiple such chips to adapt to the needs of even larger neural networks. This project will likely impact the design of future hardware accelerators because it improves energy efficiency, enhances computational speed, and enriches the functionality of deep neural networks while unlocking new capabilities of analog computations and allowing a massive deployment of edge devices. The educational aspects include filling the gap in the electrical and computer engineering curriculum related to deep neural network hardware implementation and providing various skills to participating students. The extensive outreach activities include developing and teaching two summer project-oriented courses in machine learning and circuit design for K-12 students in metro Detroit.  \r\n\r\nThis project proposes multiple innovations at the technology, circuit, architecture, and system levels. At the memory technology level, we propose a new, CMOS-based, analog multi-stable memory circuit that offers compatibility with crossbar systems, provides an analog solution to store the weights, and performs local computations in a highly parallel and energy-efficient manner. At the circuit level, we propose a local storage and processing unit, which employs the proposed analog memory to perform multiply-and-accumulate operations, utilizing only one memory unit to support both positive and negative weights. At the architecture level, we propose a novel reconfigurable architecture to construct a scalable and highly customizable inference engine. In this architecture, crossbar cells can be expanded horizontally and/or vertically using switch matrix circuits, thereby improving the utilization and reducing the power consumption compared to the fixed-size and separate crossbar arrays. Moreover, we propose the usage of a pool of reconfigurable digital-to-analog converters and analog-to-digital converters, which are well suited for the reconfigurable architecture, and will optimize their bit resolutions for each deep neural network layer. Furthermore, the proposed inference engine employs a low-power open-source processor (specifically RISC-V) to enable high flexibility and provide various functions, including the management of the data flow between layers, configuration, and calibration. To minimize the fetch/decode energy consumption, custom digital circuits will be developed to support non-linear and pooling functions. To account for process variations, we will exploit built-in-self-test and built-in-self-calibration techniques to test and calibrate all the analog circuits, utilizing on-chip circuits and configuration registers. Finally, at the system level, multiple chips will be interconnected through PCI Express to support larger models.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mohammad",
   "pi_last_name": "Alhawari",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mohammad Alhawari",
   "pi_email_addr": "alhawari@wayne.edu",
   "nsf_id": "000790171",
   "pi_start_date": "2022-08-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Nabil",
   "pi_last_name": "Sarhan",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Nabil J Sarhan",
   "pi_email_addr": "nabil@ece.eng.wayne.edu",
   "nsf_id": "000226447",
   "pi_start_date": "2022-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Wayne State University",
  "inst_street_address": "5700 CASS AVE STE 4900",
  "inst_street_address_2": "",
  "inst_city_name": "DETROIT",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "3135772424",
  "inst_zip_code": "482023692",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "MI13",
  "org_lgl_bus_name": "WAYNE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M6K6NTJ2MNE5"
 },
 "perf_inst": {
  "perf_inst_name": "Wayne State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "482023622",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "MI13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760700",
   "pgm_ele_name": "EPCN-Energy-Power-Ctrl-Netwrks"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7607",
   "pgm_ref_txt": "POWER, CONTROLS & ADAPTIVE NET"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 418907.0
  }
 ],
 "por": null
}