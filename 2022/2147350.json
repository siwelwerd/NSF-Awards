{
 "awd_id": "2147350",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "FAI: A New Paradigm for the Evaluation and Training of Inclusive Automatic Speech Recognition",
 "cfda_num": "47.070, 47.075",
 "org_code": "05020000",
 "po_phone": "7032922972",
 "po_email": "emiltsak@nsf.gov",
 "po_sign_block_name": "Eleni Miltsakaki",
 "awd_eff_date": "2022-02-15",
 "awd_exp_date": "2026-01-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2022-02-11",
 "awd_max_amd_letter_date": "2022-02-11",
 "awd_abstract_narration": "Automatic speech recognition can improve your productivity in small ways: rather than searching for a song, a product, or an address using a graphical user interface, it is often faster to accomplish these tasks using automatic speech recognition.  For many groups of people, however, speech recognition works less well, possibly because of regional accents, or because of second-language accent, or because of a disability.  This Fairness in AI project defines a new way of thinking about speech technology.  In this new way of thinking, an automatic speech recognizer is not considered to work well unless it works well for all users, including users with regional accents, second-language accents, and severe disabilities.  There are three sub-projects.  The first sub-project will create black-box testing standards that speech technology researchers can use to test their speech recognizers, in order to test how useful their speech recognizer will be for different groups of people.  For example, if a researcher discovers that their product works well for some people, but not others, then the researcher will have the opportunity to gather more training data, and to perform more development, in order to make sure that the under-served community is better-served.  The second sub-project will create glass-box testing standards that researchers can use to debug inclusivity problems.  For example, if a speech recognizer has trouble with a particular dialect, then glass-box methods will identify particular speech sounds in that dialect that are confusing the recognizer, so that researchers can more effectively solve the problem.  The third sub-project will create new methods for training a speech recognizer in order to guarantee that it works equally well for all of the different groups represented in available data.  Data will come from podcasts and the Internet.  Speakers will be identified as members of a particular group if and only if they declare themselves to be members of that group.  All of the developed software will be distributed open-source.\r\n\r\nAutomatic speech recognition has the potential to democratize the flow of information: artificially intelligent dialog agents can provide information to people who would otherwise not know where to look. The speech developer community's relentless focus on minimum error rate over the past fifty years has resulted in a productivity tool that works extremely well for those of whose speech patterns match its training data: typically, college-educated first-language speakers of a standardized dialect, with little or no speech disability.  For many groups of people, however, speech recognition works less well, possibly because their speech patterns differ significantly from the standard dialect (e.g., because of regional accent), because of intra-group heterogeneity (e.g., regional African American dialects), or because the speech pattern of each individual in the group exhibits variability (e.g., people with severe disabilities, or second-language learners).  The aim of this proposal is to create a new paradigm for the evaluation and training of inclusive automatic speech recognizers.  The proposed new evaluation and training paradigm consists of three components: (1) A \"black-box evaluation\" is an evaluation that can measure the degree of inclusivity of a speech recognizer by observing its outputs, without access to source code or trained parameters.  With appropriately balanced test data, a statistical test can determine whether or not a system provides all groups of users with the same error rates, and if different groups get different error rates, then the size of the difference can be read as a measurement of the size of the problem.  (2) A \"glass-box evaluation\" is an evaluation that identifies error patterns that consistently differentiate between groups, and searches for the causes of those errors in the acoustic signal and in the trained parameters of the network. (3) Inclusive optimization is a family of end-to-end neural network training criteria, and training dataset design and augmentation criteria, that explicitly balance the need for low average error rate against the need for low inter-group and inter-speaker variance.  In order to develop these new evaluation and training paradigms, the researchers propose to develop and distribute open-source data and tools.  Data will be drawn from large public data sources including the 100,000-podcast corpus; researchers will search the corpus for dialog acts in which speakers identify themselves with a particular group, then distribute discovered group identities and manual transcriptions as open-source metadata.  Tools will be implemented using open source toolkits including K2, and those tools will be distributed as open-source system recipes.  Speech technology developers are a competitive bunch: if there is a single number that describes the inclusivity of a speech recognizer, and if there is reason to believe that number to be scientifically well-founded and desirable, then researchers all over the world will compete to make their systems more inclusive.  Proposed research will develop such metrics, and associated data, and will deploy them open-source.  This research will be held up as a model of the social impact of artificial intelligence in the ongoing outreach programs of the investigators.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Hasegawa-Johnson",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Mark A Hasegawa-Johnson",
   "pi_email_addr": "jhasegaw@illinois.edu",
   "nsf_id": "000431210",
   "pi_start_date": "2022-02-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Zsuzsanna",
   "pi_last_name": "Fagyal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zsuzsanna Fagyal",
   "pi_email_addr": "zsfagyal@illinois.edu",
   "nsf_id": "000584401",
   "pi_start_date": "2022-02-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Najim",
   "pi_last_name": "Dehak",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Najim Dehak",
   "pi_email_addr": "ndehak3@jhu.edu",
   "nsf_id": "000724141",
   "pi_start_date": "2022-02-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Piotr",
   "pi_last_name": "Zelasko",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Piotr A Zelasko",
   "pi_email_addr": "pzelasko@jhu.edu",
   "nsf_id": "000849617",
   "pi_start_date": "2022-02-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Laureano",
   "pi_last_name": "Moro-Velazquez",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Laureano Moro-Velazquez",
   "pi_email_addr": "lmorove1@jhu.edu",
   "nsf_id": "000861604",
   "pi_start_date": "2022-02-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "506 S. Wright Street",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "114Y00",
   "pgm_ele_name": "Fairness in Artificial Intelli"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": null
}