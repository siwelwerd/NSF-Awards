{
 "awd_id": "2230762",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SCH:INT: Collaborative Research: Semi-Automated Rehabilitation in the Home",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "vsharma@nsf.gov",
 "po_sign_block_name": "Vishal Sharma",
 "awd_eff_date": "2022-01-15",
 "awd_exp_date": "2024-07-31",
 "tot_intn_awd_amt": 1100000.0,
 "awd_amount": 736120.0,
 "awd_min_amd_letter_date": "2022-06-23",
 "awd_max_amd_letter_date": "2022-06-23",
 "awd_abstract_narration": "With the aging of the US population, there is an increasing need for effective and accessible rehabilitation services for debilitating illnesses and injuries such as stroke and arthritis. Intensive long-term rehabilitation is challenging to administer in an accessible and affordable way as it requires frequent trips to the clinic (usually supported by a caregiver), and significant one-on-one time with rehabilitation experts. Telemedicine and telehealth are gaining prominence as cost effective ways to deliver home-based health and wellness to wider populations. However, automated tele-rehabilitation is not currently feasible as the expert functions of the therapist cannot yet be fully automated and replicated in the home. In addition, there are significant technical, behavioral, and clinical challenges to scaling technology assisted home-based rehabilitation. This project aims to address these challenges through the development of a system for Semi-Automated Rehabilitation At Home (SARAH). The system is defined as semi-automated because it relies on the remote participation of the therapist for developing and adapting the therapy program. The SARAH system uses the remote therapists\u2019 instructions to guide the patient through daily intensive therapy sessions at the home. Using inexpensive sensing technologies that are non-intrusive and mindful of the patient\u2019s privacy, the system records and analyzes the daily therapy sessions as well as the general activities of the patient in the home. The SARAH system then provides feedback to the patient based on their therapy activities and general movements around the home. The system also provides summaries of patient progress to the remote therapist so that they can adapt the program for subsequent therapy sessions. The first version of the SARAH system focuses on upper extremity stroke rehabilitation at the home as the team of researchers has significant experience in this space. Additional outputs from this project, including the development of a generalized system and relevant methodology, are designed to support a wide variety of home-based rehabilitation contexts.   \r\n\r\nThe technical goals of the project are the development of movement assessment algorithms fusing knowledge based and data driven approaches. This fused approach produces automated patient assessment feedback during home-based therapy, and summaries of patient therapy and daily activities to assist the therapist with remote decision making. The project utilizes a Hierarchical Bayesian Model (HBM) approximating the therapist decision process as a common framework for the development of integrative cyber-human movement assessment algorithms. Therapy sessions are captured using two video cameras and four wearable Inertial Measurement Units (IMUs), while daily activity is only be tracked through the IMUs to estimate the wearer's 3D kinematics. The project fuses clinician\u2019s expert knowledge of therapy tasks and segments with video and IMU data to implement automated segmentation and rating of therapy at the home. The fused cyber-human assessment of therapy data is used to inform the translation of low-level IMU feature tracking during daily life activities into daily movement summaries assisting remote therapy assessment and customization. The automated summaries include: therapy adherence, quality of therapy performance, quantity of patient daily activity and movement in the house, use of impaired limb, tasks detected during daily activity, and confidence of identification. The fusion of knowledge based and data driven approaches for computational movement analysis, as well as the cyber-human design process itself, will yield higher-level generalizable insights extending to many more applications of machine learning and deep learning in data-constrained scenarios. The low-cost sensor networks and wearable sensor solutions produced by the project will provide practical ways to monitor kinematics in real-world environments such as improved control systems for prosthetics and exoskeletons, prevention of workplace injuries through biofeedback, and enhancements in human-robot collaboration.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thanassis",
   "pi_last_name": "Rikakis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Thanassis Rikakis",
   "pi_email_addr": "rikakis@usc.edu",
   "nsf_id": "000119865",
   "pi_start_date": "2022-06-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900890001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  },
  {
   "pgm_ref_code": "8062",
   "pgm_ref_txt": "SCH Type II: INT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 736120.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project developed a low cost and user-friendly system for the automated assessment of movement in rehabilitation. The system was developed and tested across three rehabilitation clinics in the US with the active participation of 15 expert clinicians and 110 patients. The system focused on the upper extremity rehabilitation of stroke survivors. However, the system techniques are generalizable.&nbsp;&nbsp;With appropriate alterations, the system can be used to assist automation in many other movement rehabilitation contexts (i.e. lower extremity training for neurological accidents or orthopedic surgery).&nbsp;</p>\r\n<p>We use three low-cost video cameras (with semi-automated calibration) to achieve unobtrusive capture of the therapy sessions. We captured 1860 upper extremity tasks performed by 110 patients. We develop techniques that merged data from the three 2D video streams to create 3D kinematics and allowed us to reliably extract the 20 kinematic features that are key to the assessment of upper extremity performance. To capture the insights of the expert clinicians, the project developed a rating rubric and interface that allowed expert therapists to rate the videos of patient movement in a standardized manner that addresses functionality and movement quality. The captured videos and rating labels were used to train the computational engine for the automated assessment of therapy.&nbsp;</p>\r\n<p>The computational engine provides automated assessments that address both functionality and movement quality so as to assist the efficiency and efficacy of therapy. The system assesses movement, in an integrated manner, at the level of the task, segment, composite movement features and kinematics of each performed task.&nbsp;&nbsp;To achieve this goal, we developed three interrelated computational processes: i) an automated segmentation process ii) an automated assessment of functionality (segment and task completion) and iii) an automated assessment of the relation of movement quality elements (composite movement features and kinematics) to functionality (task and segment completion).&nbsp;</p>\r\n<p>The project developed a four-layer Hierarchical Bayesian Model (HBM) for computing the statistical relation of movement quality changes to functionality. We first calculate the conditional layer probabilities using clinician ratings of task, segment, and movement features. We increase the granularity of observation of the HBM by formulating a correlation graph between the 20 key kinematic features and different pairs of task/segment scores. The HBM also generates a correlation graph that relates the 16 composite movement features observed and rated by the therapists to the 20 kinematic features. We then use k-means clustering to arrange the 20 kinematics into three clusters for each statistically meaningful task/segment difference: (i.e. Task 3&amp;Segment 3 - Task 2&amp;Segment 2). The top kinematics cluster resulting from this process is the one with the highest probability of influencing the given difference in the score, the second cluster has a small probability and the bottom cluster has little impact. We also create kinematics clusters for the composite movement features.</p>\r\n<p>The automated segmentation and task completion results, along with established clusters of kinematics and the relative weights of the kinematics in each cluster, can be fed into a transformer algorithm that uses kinematics for the automated generation of a task/segment score for every task. The automated assessments can be presented to the therapist along with an explanation that addresses: the completion of the task, the completion of each segment, the kinematics that influenced the rating of each task and segment, the relation of these kinematics to the 16 composite movement features that are observable by the therapist, additional features of movement quality that may be influencing functionality but cannot be consistently assessed by therapists in real time. Thus the automated assessments can a) limit time that clinicians spend on assessment and increase time clinicians spend on therapy, b) strengthen evidence based adaptation of therapy, c) be used for training of novice clinicians, d) provide quantitative evidence for further research on the relations of movement quality and functionality&nbsp;</p>\r\n<p>The project also started the development of an unobtrusive wearable system for tracking and analyzing Activities of Daily Living (ADL). The goal is to correlate automated assessment of therapy sessions with automated assessment of functionality at the home. We can thus assist the clinicians in adapting therapy sessions and advancing the patients&rsquo; daily functionality. The wearable system consists of four inertial measurement units (IMUs) positioned on the index finger of the impaired hand, the two wrists and waist to infer upper body kinematics, and a sensor used in conjunction with Bluetooth beacons around the house for positioning the wearer around the house. The wearable system integrates novel algorithms that utilize the data from the wearables for the extraction of upper body kinematics and person location and the integrated use of kinematics and location for the assessment of Activities of Daily Living.&nbsp;&nbsp;We use wireless transfer of wearables/ADL data to the clinic thus making the system usable in homes that may not have internet connectivity and relying instead on cellular or emerging non-terrestrial networks.&nbsp;</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/08/2024<br>\nModified by: Thanassis&nbsp;Rikakis</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nThe project developed a low cost and user-friendly system for the automated assessment of movement in rehabilitation. The system was developed and tested across three rehabilitation clinics in the US with the active participation of 15 expert clinicians and 110 patients. The system focused on the upper extremity rehabilitation of stroke survivors. However, the system techniques are generalizable.With appropriate alterations, the system can be used to assist automation in many other movement rehabilitation contexts (i.e. lower extremity training for neurological accidents or orthopedic surgery).\r\n\n\nWe use three low-cost video cameras (with semi-automated calibration) to achieve unobtrusive capture of the therapy sessions. We captured 1860 upper extremity tasks performed by 110 patients. We develop techniques that merged data from the three 2D video streams to create 3D kinematics and allowed us to reliably extract the 20 kinematic features that are key to the assessment of upper extremity performance. To capture the insights of the expert clinicians, the project developed a rating rubric and interface that allowed expert therapists to rate the videos of patient movement in a standardized manner that addresses functionality and movement quality. The captured videos and rating labels were used to train the computational engine for the automated assessment of therapy.\r\n\n\nThe computational engine provides automated assessments that address both functionality and movement quality so as to assist the efficiency and efficacy of therapy. The system assesses movement, in an integrated manner, at the level of the task, segment, composite movement features and kinematics of each performed task.To achieve this goal, we developed three interrelated computational processes: i) an automated segmentation process ii) an automated assessment of functionality (segment and task completion) and iii) an automated assessment of the relation of movement quality elements (composite movement features and kinematics) to functionality (task and segment completion).\r\n\n\nThe project developed a four-layer Hierarchical Bayesian Model (HBM) for computing the statistical relation of movement quality changes to functionality. We first calculate the conditional layer probabilities using clinician ratings of task, segment, and movement features. We increase the granularity of observation of the HBM by formulating a correlation graph between the 20 key kinematic features and different pairs of task/segment scores. The HBM also generates a correlation graph that relates the 16 composite movement features observed and rated by the therapists to the 20 kinematic features. We then use k-means clustering to arrange the 20 kinematics into three clusters for each statistically meaningful task/segment difference: (i.e. Task 3&Segment 3 - Task 2&Segment 2). The top kinematics cluster resulting from this process is the one with the highest probability of influencing the given difference in the score, the second cluster has a small probability and the bottom cluster has little impact. We also create kinematics clusters for the composite movement features.\r\n\n\nThe automated segmentation and task completion results, along with established clusters of kinematics and the relative weights of the kinematics in each cluster, can be fed into a transformer algorithm that uses kinematics for the automated generation of a task/segment score for every task. The automated assessments can be presented to the therapist along with an explanation that addresses: the completion of the task, the completion of each segment, the kinematics that influenced the rating of each task and segment, the relation of these kinematics to the 16 composite movement features that are observable by the therapist, additional features of movement quality that may be influencing functionality but cannot be consistently assessed by therapists in real time. Thus the automated assessments can a) limit time that clinicians spend on assessment and increase time clinicians spend on therapy, b) strengthen evidence based adaptation of therapy, c) be used for training of novice clinicians, d) provide quantitative evidence for further research on the relations of movement quality and functionality\r\n\n\nThe project also started the development of an unobtrusive wearable system for tracking and analyzing Activities of Daily Living (ADL). The goal is to correlate automated assessment of therapy sessions with automated assessment of functionality at the home. We can thus assist the clinicians in adapting therapy sessions and advancing the patients daily functionality. The wearable system consists of four inertial measurement units (IMUs) positioned on the index finger of the impaired hand, the two wrists and waist to infer upper body kinematics, and a sensor used in conjunction with Bluetooth beacons around the house for positioning the wearer around the house. The wearable system integrates novel algorithms that utilize the data from the wearables for the extraction of upper body kinematics and person location and the integrated use of kinematics and location for the assessment of Activities of Daily Living.We use wireless transfer of wearables/ADL data to the clinic thus making the system usable in homes that may not have internet connectivity and relying instead on cellular or emerging non-terrestrial networks.\r\n\n\n\t\t\t\t\tLast Modified: 12/08/2024\n\n\t\t\t\t\tSubmitted by: ThanassisRikakis\n"
 }
}