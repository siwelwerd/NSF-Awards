{
 "awd_id": "1552228",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Collaborative Research: Exploring Models for Conveying Imminent Robot Failures to Allow for Human Intervention",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 184656.0,
 "awd_amount": 200656.0,
 "awd_min_amd_letter_date": "2015-08-25",
 "awd_max_amd_letter_date": "2016-06-20",
 "awd_abstract_narration": "In this exploratory research, the PIs will seek to advance the state of the science on how best to convey a robot's imminent failure to a human (whether an operator, supervisor, or bystander), in a manner that could allow the human to intervene as effectively as possible to prevent the failure. This project has the potential to dramatically increase the safety of humans in and around autonomous robots and vehicles.  Specific goals are to discover design principles for robot systems with respect to conveying failure, and to identify methods for expressing failure so that humans react appropriately.  The research will focus on three use cases: remote operation, co-located operation, and bystander interaction.  To these ends, the team will utilize a variety of robots in order to support different applications and movement scales.  Robots available to the team include small and mid-size unmanned ground vehicles, human-scale torso robots, a robot wheelchair, a telepresence robot, and an autonomous Jeep.  Project outcomes will impact the field of human-robot interaction and the future use of robots in many application domains, particularly those of mobile and manipulation robots, including autonomous vehicles, factory robots, and assistive technology, by enhancing productivity and task performance, increasing personal safety for those who work in hazardous occupations, and improving the lives of persons with disabilities.\r\n\r\nThe PIs' core research questions are informed by their substantial prior work with task-oriented robots.  Based on that experience and other studies, they argue that the following three main factors strongly influence user actions during robot failure: perceived risk (e.g., a robot that crashes frequently is generally perceived as a high risk robot), perceived severity (e.g., the failure of a small robot made of soft materials is generally perceived as less severe than that of a full body humanoid robot), and role (e.g., is the user an operators or a bystander).  Unexplored research questions about the manner in which these factors impact failure include.  How do these factors, both independently and in combination, influence HRI during robot failures?  How do humans utilize these factors during robot failure, and does this utilization have high variability or are humans very consistent?  These factors will be used as independent variables during studies which will advance knowledge in three core areas: formulation and validation of generalizable quantitative and qualitative metrics for measuring a person's response to an imminent failure in a robot system; discovery of appropriate ways to communicate failure states to humans; and initial development of common design guidelines for handling failures.  The primary goal is to make it easier for humans to rapidly understand failure events and to act or assist appropriately in a timely manner.  The PIs are specifically focused on the human-robot interaction aspect of robot failures.  As such, they will track literature and research on diagnosing failures, but will not develop new systems or concepts for this step.  Instead, the team will seek appropriate and effective ways to convey failures to humans, appropriate human responses during failures, and appropriate failure states when human action is not possible or is insufficient.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Holly",
   "pi_last_name": "Yanco",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Holly A Yanco",
   "pi_email_addr": "holly@cs.uml.edu",
   "nsf_id": "000278965",
   "pi_start_date": "2015-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Momotaz",
   "pi_last_name": "Begum",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Momotaz Begum",
   "pi_email_addr": "mbegum@cs.unh.edu",
   "nsf_id": "000673054",
   "pi_start_date": "2015-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Lowell",
  "inst_street_address": "220 PAWTUCKET ST STE 400",
  "inst_street_address_2": "",
  "inst_city_name": "LOWELL",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "9789344170",
  "inst_zip_code": "018543573",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "MA03",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS LOWELL",
  "org_prnt_uei_num": "",
  "org_uei_num": "LTNVSTJ3R6D5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Lowell",
  "perf_str_addr": "",
  "perf_city_name": "Lowell",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "018542927",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "MA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 184656.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 1\">\n<div class=\"section\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p>When autonomous robot systems experience failures, communication about the failure to both the people responsible for the robot and to people who happen to be nearby is critically important. New robot users as well as bystanders might not be familiar enough with a system to tell whether a robot is working properly and experienced robot operators might not notice signs of trouble due to being out-of-the-loop. Thus, an important feature for robots will be the ability to communicate failure to humans when failures occur, as this communication will allow for people to remain safe and intervene, if possible, to correct the robot's failure.</p>\n<p>We conducted two primary reseach activities in this grant. In the first, we discovered a set of icons that could be placed on robot systems, regardless of the type of robot, to indicate the robot's status to people unfamiliar with the robots and the icons. Such feedback will be useful to people who find themselves to be bystanders to increasing numbers of robot systems.</p>\n<p>In the second, we conducted a study with a smartphone-based feedback system that we designed, in order to explore push and pull forms of communication against no communication at all. We found the communication methods improved participants&rsquo; understanding of robots&rsquo; state, increased their confidence in interacting with the robots, and allowed them to remotely monitor and control the robots.</p>\n<p>Our findings suggest that it is possible to develop feedback methods for robot systems that will allow people who are not robot experts to understand the current state of a robot system (e.g., Is the robot working? Is it about to move? Is it safe for me to be near the robot?) and to potentially assist a robot that is experiencing failures (e.g., by hitting a reset button).</p>\n</div>\n</div>\n</div>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/09/2018<br>\n\t\t\t\t\tModified by: Holly&nbsp;A&nbsp;Yanco</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\n\n\nWhen autonomous robot systems experience failures, communication about the failure to both the people responsible for the robot and to people who happen to be nearby is critically important. New robot users as well as bystanders might not be familiar enough with a system to tell whether a robot is working properly and experienced robot operators might not notice signs of trouble due to being out-of-the-loop. Thus, an important feature for robots will be the ability to communicate failure to humans when failures occur, as this communication will allow for people to remain safe and intervene, if possible, to correct the robot's failure.\n\nWe conducted two primary reseach activities in this grant. In the first, we discovered a set of icons that could be placed on robot systems, regardless of the type of robot, to indicate the robot's status to people unfamiliar with the robots and the icons. Such feedback will be useful to people who find themselves to be bystanders to increasing numbers of robot systems.\n\nIn the second, we conducted a study with a smartphone-based feedback system that we designed, in order to explore push and pull forms of communication against no communication at all. We found the communication methods improved participants? understanding of robots? state, increased their confidence in interacting with the robots, and allowed them to remotely monitor and control the robots.\n\nOur findings suggest that it is possible to develop feedback methods for robot systems that will allow people who are not robot experts to understand the current state of a robot system (e.g., Is the robot working? Is it about to move? Is it safe for me to be near the robot?) and to potentially assist a robot that is experiencing failures (e.g., by hitting a reset button).\n\n\n\n\n\n\t\t\t\t\tLast Modified: 07/09/2018\n\n\t\t\t\t\tSubmitted by: Holly A Yanco"
 }
}