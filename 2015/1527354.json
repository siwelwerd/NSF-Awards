{
 "awd_id": "1527354",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Secure and Private Function Computation by Interactive Communication",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 499998.0,
 "awd_amount": 499998.0,
 "awd_min_amd_letter_date": "2015-08-07",
 "awd_max_amd_letter_date": "2020-08-26",
 "awd_abstract_narration": "This research takes an information theoretic approach to develop principles that govern secure or private function computation by multiple terminals that host user data. The goal of the terminals is to compute locally and reliably, a given function of all the possibly correlated user data, using an interactive communication protocol. The protocol is required to satisfy separate security and privacy conditions. The former stipulates for each terminal that a coalition of the remaining terminals should glean no more information about the data at the terminal from their own data and the communication -- than can be obtained from the function value. The latter protects each individual user's data at a terminal from a similar coalition. A common framework is developed for analyzing the distinct concepts of security and privacy, and new information theoretic formulations and approaches are proposed with the objective of understanding basic underlying principles. Potential applications arise, for instance, in: hospital databases that store clinical drug trial results or university databases with student performance records; private information retrieval from user data stored in private clouds; and security and privacy certifications for the identities/locations of communities and individuals participating in crowd-sourced traffic and navigation services. \r\n\r\nThe investigators' technical approach involves the development of a theory with three main distinguishing features. It (i) establishes a key role for interactive communication in reducing communication complexity, and in enhancing security and privacy; and formulates computable measures of security and privacy in terms of conditional Renyi entropy; (ii) provides a common framework for formulating and analyzing problems of secure and private function computation with prominent roles for classical Shannon theory as well as zero-error combinatorial information theory; and introduces the concept of a multiuser privacy region for quantifying privacy tradeoffs among users; and (iii) develops a new method for obtaining converse bounds for communication complexity, upon analyzing the common randomness or shared information generated in function computation with an interactive communication protocol. Rooted in information theory, estimation theory and theoretical computer science, a central objective of the research is to elucidate tradeoffs among computation accuracy, terminal security and user privacy; key to these tradeoffs is the essential role of interactive communication. Furthermore, it aims at creating advances in information theory through the introduction of new models and concepts. Expected outcomes are precise characterizations of the mentioned fundamental tradeoffs, and associated algorithms for secure and private computing.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Prakash",
   "pi_last_name": "Narayan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Prakash Narayan",
   "pi_email_addr": "prakash@eng.umd.edu",
   "nsf_id": "000399822",
   "pi_start_date": "2015-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "2353 A.V. Williams Bldg.",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207423370",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 499998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research project has been motivated by existing as well as potential futuristic applications that entail function recoverability with accompanying data privacy. In such an application, a user must furnish attributes of the data in public (function recoverability) while protecting the data itself or the data-generating mechanism (privacy). For instance, when aggregate statistics of student grades are released from a university database, privacy of each individual student&rsquo;s data must be ensured. When success rates of a clinical drug trial are given out from a hospital database, the privacy of all the patients&rsquo; medical records has to be protected. Many social media platforms allow third party applications to request user profiles for targeted advertising; in providing such information, individual user data must not be compromised. In this vein, potential futuristic applications include: an AI-driven financial trader who reveals trading preferences through daily actions (function recoverability) but seeks to guard the workings of an underlying probabilistic algorithm (privacy); and IoT sensors that must recover user commands for execution (recoverability) but without the details of user habits being compromised (privacy). An instance of the latter would arise when a user&rsquo;s predilections for Smart TV programs must not be compromised when program requests are made to a service provider.</p>\n<p><br />Upon theoretically abstracting the salient features of the mentioned applications, we have investigated three new problem formulations of function computation with privacy. These entail computation of the value of a given function of user data while maximizing privacy of user data or user data-generating mechanism. Our key objectives throughout are two-fold: to understand and characterize precisely the optimal tradeoffs between utility viz. computation accuracy on the one hand and privacy on the other; and to develop implementable algorithms that yield the best utility versus privacy performance tradeoffs.</p>\n<p><br />Our work enables data utility in the form of enabling computation of a given function or attribute of the data while simultaneously maximizing three newly-formulated and stringent forms of privacy that are dictated by the application at hand. These are: (i) ``predicate privacy\" which requires that a separate and sensitive attribute of the data be protected; (ii) ``list privacy\" which guarantees that a protected data value defies even being guessed to lie among a larger group of values; and (iii) ``distribution privacy\" in which the workings of an underlying data-generating algorithm remain under wraps. In all these settings, implementable randomized algorithms are presented that enable function computation with desired accuracy while maximizing the privacy guarantees above.</p>\n<p>Along the way, this project has led to the development of new mathematical techniques that are potentially of independent interest in information theory and statistical learning.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/28/2021<br>\n\t\t\t\t\tModified by: Prakash&nbsp;Narayan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis research project has been motivated by existing as well as potential futuristic applications that entail function recoverability with accompanying data privacy. In such an application, a user must furnish attributes of the data in public (function recoverability) while protecting the data itself or the data-generating mechanism (privacy). For instance, when aggregate statistics of student grades are released from a university database, privacy of each individual student\u2019s data must be ensured. When success rates of a clinical drug trial are given out from a hospital database, the privacy of all the patients\u2019 medical records has to be protected. Many social media platforms allow third party applications to request user profiles for targeted advertising; in providing such information, individual user data must not be compromised. In this vein, potential futuristic applications include: an AI-driven financial trader who reveals trading preferences through daily actions (function recoverability) but seeks to guard the workings of an underlying probabilistic algorithm (privacy); and IoT sensors that must recover user commands for execution (recoverability) but without the details of user habits being compromised (privacy). An instance of the latter would arise when a user\u2019s predilections for Smart TV programs must not be compromised when program requests are made to a service provider.\n\n\nUpon theoretically abstracting the salient features of the mentioned applications, we have investigated three new problem formulations of function computation with privacy. These entail computation of the value of a given function of user data while maximizing privacy of user data or user data-generating mechanism. Our key objectives throughout are two-fold: to understand and characterize precisely the optimal tradeoffs between utility viz. computation accuracy on the one hand and privacy on the other; and to develop implementable algorithms that yield the best utility versus privacy performance tradeoffs.\n\n\nOur work enables data utility in the form of enabling computation of a given function or attribute of the data while simultaneously maximizing three newly-formulated and stringent forms of privacy that are dictated by the application at hand. These are: (i) ``predicate privacy\" which requires that a separate and sensitive attribute of the data be protected; (ii) ``list privacy\" which guarantees that a protected data value defies even being guessed to lie among a larger group of values; and (iii) ``distribution privacy\" in which the workings of an underlying data-generating algorithm remain under wraps. In all these settings, implementable randomized algorithms are presented that enable function computation with desired accuracy while maximizing the privacy guarantees above.\n\nAlong the way, this project has led to the development of new mathematical techniques that are potentially of independent interest in information theory and statistical learning.\n\n \n\n\t\t\t\t\tLast Modified: 11/28/2021\n\n\t\t\t\t\tSubmitted by: Prakash Narayan"
 }
}