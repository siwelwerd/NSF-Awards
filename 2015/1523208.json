{
 "awd_id": "1523208",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "The BrainstormHPCD-1 Workshop",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rudolf Eigenmann",
 "awd_eff_date": "2015-03-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2015-02-26",
 "awd_max_amd_letter_date": "2015-02-26",
 "awd_abstract_narration": "The Brainstorm HPCD-1 workshop is part of a community-driven effort to gather comprehensive information about the needs of the National Science Foundation-sponsored science and engineering research community for advanced capacity through capability computing, including data-intensive and compute-intensive resources. The workshop focuses on the research community needs at the high end of the spectrum and will attempt to articulate the value, contributions and impacts of at-scale computing for the advancement of science, engineering, and other research. In addition to direct input to NSF/ACI, the workshop provides valuable input to the National Research Council Committee on Future Directions for NSF Advanced Computing Infrastructure to Support U.S. Science in 2017-2020. Along with application leaders confronting diverse computing and analysis challenges, attendees include members from industry and government with expertise in algorithms, computer system architecture, and applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Kramer",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "William T Kramer",
   "pi_email_addr": "wtkramer@illinois.edu",
   "nsf_id": "000179975",
   "pi_start_date": "2015-02-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "506 S. Wright Street",
  "perf_city_name": "Urbana",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618013620",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "778100",
   "pgm_ele_name": "Leadership-Class Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The consensus view of the workshop attendees is <strong>Because NSF has the broader, national mission of advancing science and engineering and ensuring the scientific and economic competitiveness of the nation, it is vitally important NSF provide a series of High Performance Computing and Data (HPCD) Track 1 and Track 2 systems and services over time to meet the increasing demands of high spectrum digital science with increased funding and coherence.</strong>&nbsp;</p>\n<p>&nbsp;</p>\n<p>The reasons for this conclusion include the following workshop findings.</p>\n<ol>\n<li>Past sustained funding for HPCD has led to tremendous advances in many fields and NSF cannot let that progress and momentum stop. </li>\n<li>The success and pervasiveness of NSF&rsquo;s HPCD investments created an environment in which access to such HPCD resources are now assumed by the entire research enterprise. </li>\n<li>There is compelling evidence that computational and data intensive computing is now implicitly intertwined with all areas of discovery and competitiveness. </li>\n<li>The demand for high performance computing and data science resources is growing and will continue to grow over the next decades to enable productive and timely science and research progress. </li>\n<li>NSF and other agencies have succeeded in increasing the use and demand for HPCD resources by expanding the impact of traditional communities and broadening the engagements with new communities.&nbsp; Further, workforce and research development efforts have enabled more researchers to make efficient use of high performance resources.&nbsp; </li>\n<li>Scientific needs increasingly require high performance capability for both modeling and simulation and for data science and science, engineering and other types of research.&nbsp; There is an increasing symbiotic relationship between high performance modeling and simulation and high performance experimental/observational data science.&nbsp; Today, the most challenging experiments and instruments cannot fully understand their data without modeling and simulation guidance and verification.&nbsp; Likewise, modeling and simulation projects have intimate engagements with experimental and observed data. </li>\n<li>The NSF National Cyber Infrastructure must include systems of the scale and capability that match the best systems the major national laboratories are deploying. </li>\n<li>NSF should evaluate and develop funding methods and/or programs for advanced HPCD that recognizes the need for coherence and continuity for suppliers, providers and consumers of these capabilities in order to enhance the productivity of the scientific and engineering research endeavors. </li>\n<li>There is a need for a variety of platforms and service models to be efficiently addressing the breadth and depth of the national open-science research endeavors. While diversity is important, there is a point where dropping below a minimum size/capability of deployed national resources is counter productive and inefficient for the national science communities, the funders and the stakeholders.&nbsp;</li>\n<li>While there are, and will be, cases for &ldquo;cloud&rdquo; based resources for pursuing research, the workshop conclusion, which included commercial cloud architects, is that cloud computing methods are limited and cannot address the breadth nor the depth of the national open research portfolio.&nbsp; Even if there was a sufficient business case for commercial cloud HPC providers, there was consensus that those services would be limited to applications that use, at best, no more than a few thousand to a few tens of thousands standard cores of computing for the foreseeable future.&nbsp;</li>\n<li>Many frontier science applications fundamentally need much more scale &ndash; to the order 100,000&rsquo;s to 1,000,000&rsquo;s of cores &ndash; to make frontier and best of breed problem solutions feasible.&nbsp; Add...",
  "por_txt_cntn": "\nThe consensus view of the workshop attendees is Because NSF has the broader, national mission of advancing science and engineering and ensuring the scientific and economic competitiveness of the nation, it is vitally important NSF provide a series of High Performance Computing and Data (HPCD) Track 1 and Track 2 systems and services over time to meet the increasing demands of high spectrum digital science with increased funding and coherence. \n\n \n\nThe reasons for this conclusion include the following workshop findings.\n\nPast sustained funding for HPCD has led to tremendous advances in many fields and NSF cannot let that progress and momentum stop. \nThe success and pervasiveness of NSF\u00c6s HPCD investments created an environment in which access to such HPCD resources are now assumed by the entire research enterprise. \nThere is compelling evidence that computational and data intensive computing is now implicitly intertwined with all areas of discovery and competitiveness. \nThe demand for high performance computing and data science resources is growing and will continue to grow over the next decades to enable productive and timely science and research progress. \nNSF and other agencies have succeeded in increasing the use and demand for HPCD resources by expanding the impact of traditional communities and broadening the engagements with new communities.  Further, workforce and research development efforts have enabled more researchers to make efficient use of high performance resources.  \nScientific needs increasingly require high performance capability for both modeling and simulation and for data science and science, engineering and other types of research.  There is an increasing symbiotic relationship between high performance modeling and simulation and high performance experimental/observational data science.  Today, the most challenging experiments and instruments cannot fully understand their data without modeling and simulation guidance and verification.  Likewise, modeling and simulation projects have intimate engagements with experimental and observed data. \nThe NSF National Cyber Infrastructure must include systems of the scale and capability that match the best systems the major national laboratories are deploying. \nNSF should evaluate and develop funding methods and/or programs for advanced HPCD that recognizes the need for coherence and continuity for suppliers, providers and consumers of these capabilities in order to enhance the productivity of the scientific and engineering research endeavors. \nThere is a need for a variety of platforms and service models to be efficiently addressing the breadth and depth of the national open-science research endeavors. While diversity is important, there is a point where dropping below a minimum size/capability of deployed national resources is counter productive and inefficient for the national science communities, the funders and the stakeholders. \nWhile there are, and will be, cases for \"cloud\" based resources for pursuing research, the workshop conclusion, which included commercial cloud architects, is that cloud computing methods are limited and cannot address the breadth nor the depth of the national open research portfolio.  Even if there was a sufficient business case for commercial cloud HPC providers, there was consensus that those services would be limited to applications that use, at best, no more than a few thousand to a few tens of thousands standard cores of computing for the foreseeable future. \nMany frontier science applications fundamentally need much more scale &ndash; to the order 100,000\u00c6s to 1,000,000\u00c6s of cores &ndash; to make frontier and best of breed problem solutions feasible.  Additionally, these problems require systems with robust and performant interconnects, storage, I/O services, and large amounts of memory in balanced architecture.\nThere are emerging, curated petabyte scale data repositories with thousands of people accessing them for both observa..."
 }
}