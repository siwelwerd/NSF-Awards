{
 "awd_id": "1533768",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS: FULL: DSD: A Parallel Tensor Infrastructure (ParTI!) for Data Analysis",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Wei Ding",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 750000.0,
 "awd_amount": 750000.0,
 "awd_min_amd_letter_date": "2015-08-28",
 "awd_max_amd_letter_date": "2020-06-23",
 "awd_abstract_narration": "This project concerns efficient parallel algorithms and software for\r\nemerging and future data analysis and mining applications, based on an\r\nemerging class of techniques known as tensor networks. Tensors, which\r\nare higher-dimensional generalizations of matrices, are finding\r\napplications in signal and image processing, computer vision,\r\nhealthcare analytics, and neuroscience, to name just a few. Yet\r\ndespite this demand, there is no comprehensive, high-performance\r\nsoftware infrastructure targeting server systems that may have many\r\nparallel processors. Thus, the overarching research goal of this\r\nproject is to design the first such infrastructure. The resulting\r\nprototype will be an open-source package, called the Parallel Tensor\r\nInfrastructure, or ParTI! The broader impact of the ParTI! project is\r\nto make the use of tensors, in a variety of data processing domains,\r\nmuch easier to do and more widespread.\r\n\r\nThe ParTI! project will focus specifically on algorithmic and software\r\nsupport for sparse tensors on single-node multi- and many-core\r\naccelerated platforms. The technical approach relies on a specific way\r\nof representing tensors, referred to as tensor networks.  A tensor\r\nnetwork is an efficient approach for representing the structure of a\r\nhigh-order tensor or tensor factorization. It can used by the data\r\nanalyst as a simple, high-level way to express the specific structure\r\nor relationships he or she seeks in the data that the tensor\r\nrepresents. However, a tensor network is not just a tool for the\r\nanalyst; it is also an abstract intermediate form, from which it is\r\npossible to derive algorithms, express and manage parallelism, and\r\nsemi-automatically generate tensor processing software. This insight,\r\ncombined with well-known data layout and communication-avoiding\r\nparallelization techniques from high-performance sparse linear\r\nalgebra, is what will enable a ParTI! for tensor-based data\r\nanalysis. The project will show the utility of this approach by\r\nevaluating the ParTI! prototype on real data sets and systems, through\r\ncollaborations with government research laboratory and industry\r\npartners.\r\n\r\nFor further information see the project web site at: parti-project.org",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Vuduc",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Richard W Vuduc",
   "pi_email_addr": "richie@cc.gatech.edu",
   "nsf_id": "000080331",
   "pi_start_date": "2015-08-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Jimeng",
   "pi_last_name": "Sun",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jimeng Sun",
   "pi_email_addr": "jimeng@illinois.edu",
   "nsf_id": "000653017",
   "pi_start_date": "2015-08-28",
   "pi_end_date": "2020-06-23"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Chao",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Chao Zhang",
   "pi_email_addr": "chaozhang@gatech.edu",
   "nsf_id": "000814844",
   "pi_start_date": "2020-06-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 750000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project concerned the discovery of efficient algorithms and design of high-performance software for emerging and future data analysis and mining applications. It focused specifically on data that can be represented in the form of a tensor, which is finding applications in signal and image processing, computer vision, healthcare analytics, and neuroscience, to name just a few. At the start of the project, there were no comprehensive, high-performance software infrastructures for targeting server systems that may have many parallel processors. Thus, the overarching research goal of was to lay the foundations for just such an infrastructure.<br /><br />The intellectual merit of this project was the discovery of numerous new algorithms for tensor computations in data mining and analysis, as well as the release of the infrastructure as an open-source software library called ParTI! (Parallel Tensor Infrastructure). ParTI! includes high-performance implementations of many tensor operations for sparse input tensors. These implementations run on multicore CPU and GPU platforms, and have served as a basis for comparison in research studies by others. One key research paper related to ParTI!, which developed a new sparse tensor data structure called \"HiCOO\" (read: \"haiku,\" short for hierarchical coordinate format), received a Best Student Paper award at the top conference in high-performance computing. In terms of its broader impacts, the ParTI! project has led to several \"spin-off\" projects, including one called Hierarchical ParTI! (HiParTI!), which is a US Department of Energy national laboratory effort. Thus, the ParTI! goes on, as it were.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/16/2022<br>\n\t\t\t\t\tModified by: Richard&nbsp;W&nbsp;Vuduc</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project concerned the discovery of efficient algorithms and design of high-performance software for emerging and future data analysis and mining applications. It focused specifically on data that can be represented in the form of a tensor, which is finding applications in signal and image processing, computer vision, healthcare analytics, and neuroscience, to name just a few. At the start of the project, there were no comprehensive, high-performance software infrastructures for targeting server systems that may have many parallel processors. Thus, the overarching research goal of was to lay the foundations for just such an infrastructure.\n\nThe intellectual merit of this project was the discovery of numerous new algorithms for tensor computations in data mining and analysis, as well as the release of the infrastructure as an open-source software library called ParTI! (Parallel Tensor Infrastructure). ParTI! includes high-performance implementations of many tensor operations for sparse input tensors. These implementations run on multicore CPU and GPU platforms, and have served as a basis for comparison in research studies by others. One key research paper related to ParTI!, which developed a new sparse tensor data structure called \"HiCOO\" (read: \"haiku,\" short for hierarchical coordinate format), received a Best Student Paper award at the top conference in high-performance computing. In terms of its broader impacts, the ParTI! project has led to several \"spin-off\" projects, including one called Hierarchical ParTI! (HiParTI!), which is a US Department of Energy national laboratory effort. Thus, the ParTI! goes on, as it were.\n\n\t\t\t\t\tLast Modified: 01/16/2022\n\n\t\t\t\t\tSubmitted by: Richard W Vuduc"
 }
}