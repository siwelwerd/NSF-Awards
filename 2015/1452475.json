{
 "awd_id": "1452475",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Structured Indoor Modeling",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2015-02-01",
 "awd_exp_date": "2018-01-31",
 "tot_intn_awd_amt": 487821.0,
 "awd_amount": 239030.0,
 "awd_min_amd_letter_date": "2015-02-04",
 "awd_max_amd_letter_date": "2018-03-26",
 "awd_abstract_narration": "Many objects around us are associated with certain functions. We use a switch to turn on a light, push a button to call an elevator, and open a door to enter a room. While 3D digital mapping is getting increasingly more attentions due to the rapid advancements in the 3D reconstruction techniques and the 3D sensing hardware, current methods are merely optimized for geometric fidelity and lack such functional information. This project discovers rules governing indoor scenes from a database of indoor 3D models, and then develops an algorithm to reconstruct functional indoor 3D models. High fidelity 3D models, if equipped with functional information, would facilitate fundamentally new applications that influence our lives at a much deeper level. The developed technologies have many different applications, from helping indoor navigation to assessing compliance with building codes, accessibility codes, and energy efficiency levels. The broader impacts of the project include architecture, civil engineering, urban geography and sociology, real estate, and transportation. The research of this project is well integrated with the education. The education plan includes an interdisciplinary course with Sam Fox School of Design & Visual Arts at Washington University, and co-developing a K-12 teaching module with a local high school teacher, which is estimated to impact 2,500 high school students.\r\n\r\nThe central idea of this research is to discover structural elements constituting an indoor scene, together with their hierarchical and functional relationships. For example, a building consists of stories, each of which contains rooms, each of which contains windows. Doors connect rooms, and an elevator door is a passage connecting different floors. First, the project defines a novel structured scene representation together with its rigorous structure grammar. Second, the project derives a principled new structured reconstruction algorithm that follows the rules in the structure grammar. Third, the structured model representation and reconstruction algorithm open up new opportunities to enable a highly tunable reconstruction system. This project develops a system that is capable of enforcing richer classes of geometric constraints far beyond existing methods, and controlling the properties of an output model effectively to meet the demands of specific applications directly. The developed technologies can be transformed to other geometry reconstruction and shape extraction problems, such as 2D shape segmentation, 3D outdoor architectural modeling, and 4D dynamic scene reconstruction.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yasutaka",
   "pi_last_name": "Furukawa",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yasutaka Furukawa",
   "pi_email_addr": "furukawa@wustl.edu",
   "nsf_id": "000674066",
   "pi_start_date": "2015-02-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Washington University",
  "inst_street_address": "1 BROOKINGS DR",
  "inst_street_address_2": "",
  "inst_city_name": "SAINT LOUIS",
  "inst_state_code": "MO",
  "inst_state_name": "Missouri",
  "inst_phone_num": "3147474134",
  "inst_zip_code": "631304862",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MO01",
  "org_lgl_bus_name": "WASHINGTON UNIVERSITY, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "L6NFUM28LQM5"
 },
 "perf_inst": {
  "perf_inst_name": "Washington University",
  "perf_str_addr": "1 Brookings Dr",
  "perf_city_name": "St. Louis",
  "perf_st_code": "MO",
  "perf_st_name": "Missouri",
  "perf_zip_code": "631304899",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "MO01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 239029.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 0.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The funded research project has brought impacts to the two domains: 1) A house scale scene reconstruction from large-scale sensor data; and 2) A singleimage scene understanding and reconstruction.</p>\n<p>1) A house scale scene reconstruction:</p>\n<p>We have developed two algorithms that produce vector-graphics floorplan models. The first algorithm turns scanned floorplan image (e.g., JPG format) into vector-graphics representation, which knows the number of bedrooms, the locations of doors or windows, the connectivity of rooms, and etc.. The floorplan is the important visual media for customers to understand the house structure and also an important building information to predict a proper sales price, for instance. Japan is a countery where most residentail units have floorplans stored in an image but not as vector-graphics format. The precision and recall of our system are both above 90% and the system will have immediate impact on the practice of Japanese real estate market.</p>\n<p>In the rest of the world, most houses do not even have floorplan images, where our second algorithm allows one to walk through a house with a smartphone and generate a vector-graphics floorplan. More specifically, we have utilized a smartphone equipped with a depth camera, where the input to the system is a sequence of a video and depth frames.</p>\n<p>2) Piecewise planar surface reconstruction:</p>\n<p>A single image scene understaing is an important problem for many VR/AR applications. We have trained a neural networks that can segment planar sements and reconstruct their plane coefficients. In most AR applications on iOS or android devices, users are allowed to place only the floor surface. Our research could enable users to interact with planar surfaces in the wild.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/31/2019<br>\n\t\t\t\t\tModified by: Yasutaka&nbsp;Furukawa</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1452475/1452475_10349716_1548923286376_ScreenShot2019-01-30at11.26.31PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1452475/1452475_10349716_1548923286376_ScreenShot2019-01-30at11.26.31PM--rgov-800width.jpg\" title=\"Floorplan reconstruction\"><img src=\"/por/images/Reports/POR/2019/1452475/1452475_10349716_1548923286376_ScreenShot2019-01-30at11.26.31PM--rgov-66x44.jpg\" alt=\"Floorplan reconstruction\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Reconstruction results of our floorplan reconstruction system.</div>\n<div class=\"imageCredit\">Yasutaka Furukawa</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Yasutaka&nbsp;Furukawa</div>\n<div class=\"imageTitle\">Floorplan reconstruction</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1452475/1452475_10349716_1548923348049_ScreenShot2019-01-30at11.31.39PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1452475/1452475_10349716_1548923348049_ScreenShot2019-01-30at11.31.39PM--rgov-800width.jpg\" title=\"Raster to vector.\"><img src=\"/por/images/Reports/POR/2019/1452475/1452475_10349716_1548923348049_ScreenShot2019-01-30at11.31.39PM--rgov-66x44.jpg\" alt=\"Raster to vector.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Turning a raster (jpg) floorplan image into its vector graphics representation.</div>\n<div class=\"imageCredit\">Yasutaka Furukawa</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Yasutaka&nbsp;Furukawa</div>\n<div class=\"imageTitle\">Raster to vector.</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1452475/1452475_10349716_1548923419435_ScreenShot2019-01-31at12.25.36AM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1452475/1452475_10349716_1548923419435_ScreenShot2019-01-31at12.25.36AM--rgov-800width.jpg\" title=\"Piecewise planar 3D reconstruction\"><img src=\"/por/images/Reports/POR/2019/1452475/1452475_10349716_1548923419435_ScreenShot2019-01-31at12.25.36AM--rgov-66x44.jpg\" alt=\"Piecewise planar 3D reconstruction\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our system can produce piecewise planar reconstruction from a single RGB image.</div>\n<div class=\"imageCredit\">Yasutaka Furukawa</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Yasutaka&nbsp;Furukawa</div>\n<div class=\"imageTitle\">Piecewise planar 3D reconstruction</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe funded research project has brought impacts to the two domains: 1) A house scale scene reconstruction from large-scale sensor data; and 2) A singleimage scene understanding and reconstruction.\n\n1) A house scale scene reconstruction:\n\nWe have developed two algorithms that produce vector-graphics floorplan models. The first algorithm turns scanned floorplan image (e.g., JPG format) into vector-graphics representation, which knows the number of bedrooms, the locations of doors or windows, the connectivity of rooms, and etc.. The floorplan is the important visual media for customers to understand the house structure and also an important building information to predict a proper sales price, for instance. Japan is a countery where most residentail units have floorplans stored in an image but not as vector-graphics format. The precision and recall of our system are both above 90% and the system will have immediate impact on the practice of Japanese real estate market.\n\nIn the rest of the world, most houses do not even have floorplan images, where our second algorithm allows one to walk through a house with a smartphone and generate a vector-graphics floorplan. More specifically, we have utilized a smartphone equipped with a depth camera, where the input to the system is a sequence of a video and depth frames.\n\n2) Piecewise planar surface reconstruction:\n\nA single image scene understaing is an important problem for many VR/AR applications. We have trained a neural networks that can segment planar sements and reconstruct their plane coefficients. In most AR applications on iOS or android devices, users are allowed to place only the floor surface. Our research could enable users to interact with planar surfaces in the wild.\n\n \n\n\t\t\t\t\tLast Modified: 01/31/2019\n\n\t\t\t\t\tSubmitted by: Yasutaka Furukawa"
 }
}