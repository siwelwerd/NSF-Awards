{
 "awd_id": "1512964",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "AF: Medium: Behavioral design for online environments",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2015-06-01",
 "awd_exp_date": "2021-05-31",
 "tot_intn_awd_amt": 1199939.0,
 "awd_amount": 1199939.0,
 "awd_min_amd_letter_date": "2015-05-07",
 "awd_max_amd_letter_date": "2019-07-08",
 "awd_abstract_narration": "Online systems are, to a growing degree, economic systems designed for a large population of users, each with their own motivations. Economic design is more likely to be effective when it is based on accurate models of the agent population toward which it is targeted. A growing literature, however, suggests that people do not quite behave like standard economic agents in a variety of settings, both online and offline. What consequences might such differences in behavior have for the optimal design of these environments?\r\n\r\nThis project will lay the groundwork for a theory of behavioral mechanism design, with the aim of both introducing new theoretical problems and impacting the design of online systems in practice. The diversity of the literature that this research draws upon, and can potentially impact, makes it particularly suitable for bringing awareness of theoretical research to communities that are otherwise largely dissociated from mathematical methods. The PIs hope to achieve this via new courses for graduate students with little or no exposure to mathematics, as well as hands-on learning experiences for middle-school students.\r\n\r\nThis research will address questions based on three families of behavioral phenomena well-documented in experimental work, and will investigate how they impact the design of a range of online systems, such as social computing and crowdsourcing platforms, matching markets, and ranking and recommendation systems. The project will consider mechanism design for \"simple\" agents who strategize about their participation decision but not about their input (conditional on participating) to a system; pricing and menu design for agents whose decisions may suffer from \"choice overload;\" and designing learning algorithms whose input comes from behaviorally-biased agents rather than from stationary random sampling processes.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Kleinberg",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Robert Kleinberg",
   "pi_email_addr": "rdk@cs.cornell.edu",
   "nsf_id": "000098359",
   "pi_start_date": "2019-07-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Arpita",
   "pi_last_name": "Ghosh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Arpita Ghosh",
   "pi_email_addr": "arpitaghosh@cornell.edu",
   "nsf_id": "000635263",
   "pi_start_date": "2015-05-07",
   "pi_end_date": "2019-07-08"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jon",
   "pi_last_name": "Kleinberg",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jon M Kleinberg",
   "pi_email_addr": "kleinberg@cs.cornell.edu",
   "nsf_id": "000096706",
   "pi_start_date": "2019-07-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Kleinberg",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Robert Kleinberg",
   "pi_email_addr": "rdk@cs.cornell.edu",
   "nsf_id": "000098359",
   "pi_start_date": "2015-05-07",
   "pi_end_date": "2019-07-08"
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "107 Hoy Road Gates Hall",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148535169",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7932",
   "pgm_ref_txt": "COMPUT GAME THEORY & ECON"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 398613.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 317115.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 484211.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Over the past twenty years, research linking computer science and economics has flourished as researchers seek to predict the performance of online systems with self-interested users, such as Google's ad auctions or Amazon's product recommendations, and to discover principled methods for improving those systems. The standard model of user behavior assumes perfect rationality, but this assumption is often questionable. Users may deviate from traditional notions of \"rationality\" because they lack information, because they lack the resources to solve difficult optimization problems in order to act optimally, or because of psychological biases that are known to influence human behavior. This project revisited important problems in mechanism design, optimization, and machine learning, asking how their solutions change when one modifies the standard perfect-rationality assumption to more realistic behavioral assumptions.<br /><br />One of the project's main thrusts incorporated novel behavioral assumptions into some of the standard models of sequential decision-making. These behavioral assumptions include loss aversion, the tendency to devalue the final outcome of a decision if one knows a different choice could have led to a better outcome, and sunk-cost bias, the tendency to persist in pursuing a goal after having invested in it, even when abandoning the goal would be better, on average, from a cost-benefit standpoint. We quantified how these behavioral biases affect the expected value of the outcome of a planning process, in the worst case. We also showed that procrastination, i.e. the tendency to prioritize easy and quick tasks over more difficult or time-consuming ones, can actually guide the design of near-optimal procedures for algorithm configuration, the automated process of parameter tuning to make an algorithm, on average, run as fast as possible. We enhanced the multi-armed bandit problem, a standard model used in automated recommendation systems, to account for satiation effects whereby a user becomes tired of options (e.g. songs on a playlist) that were recommended in the recent past.<br /><br />Another thrust of the project concerned mechanism design, the research area that studies how to design systems so that users' self-interested behavior will align with the system designer's goals. For example, an auction is a system for allocating one or more items to a set of bidders so that items are matched with the bidders who value them most. When one modifies the standard assumption that users know the value of each item to incorporate a cost for acquiring information about one's value, we showed that different auction formats --- ascending-price, descending-price, and sealed bid auctions --- which were thought to yield the same outcome in equilibrium, can actually yield quite different outcomes, and that the descending-price auction is the only one among these that is guaranteed to approximate the optimal outcome. We also discovered a procedure that can be applied to any algorithm for making a decision based on information supplied by users, to transform the algorithm into an \"incentive compatible mechanism\", i.e. a system in which misreporting a user's private information never yields a decision more favorable for that user than if they had reported truthfully. Our procedure requires the system operator to know the probability distribution from which each user's information is sampled, and it requires the samples to be independently random. Resolving an eight-year-old open question, we devised such a procedure whose complexity grows only moderately as the number of bidders grows.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/10/2022<br>\n\t\t\t\t\tModified by: Robert&nbsp;Kleinberg</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOver the past twenty years, research linking computer science and economics has flourished as researchers seek to predict the performance of online systems with self-interested users, such as Google's ad auctions or Amazon's product recommendations, and to discover principled methods for improving those systems. The standard model of user behavior assumes perfect rationality, but this assumption is often questionable. Users may deviate from traditional notions of \"rationality\" because they lack information, because they lack the resources to solve difficult optimization problems in order to act optimally, or because of psychological biases that are known to influence human behavior. This project revisited important problems in mechanism design, optimization, and machine learning, asking how their solutions change when one modifies the standard perfect-rationality assumption to more realistic behavioral assumptions.\n\nOne of the project's main thrusts incorporated novel behavioral assumptions into some of the standard models of sequential decision-making. These behavioral assumptions include loss aversion, the tendency to devalue the final outcome of a decision if one knows a different choice could have led to a better outcome, and sunk-cost bias, the tendency to persist in pursuing a goal after having invested in it, even when abandoning the goal would be better, on average, from a cost-benefit standpoint. We quantified how these behavioral biases affect the expected value of the outcome of a planning process, in the worst case. We also showed that procrastination, i.e. the tendency to prioritize easy and quick tasks over more difficult or time-consuming ones, can actually guide the design of near-optimal procedures for algorithm configuration, the automated process of parameter tuning to make an algorithm, on average, run as fast as possible. We enhanced the multi-armed bandit problem, a standard model used in automated recommendation systems, to account for satiation effects whereby a user becomes tired of options (e.g. songs on a playlist) that were recommended in the recent past.\n\nAnother thrust of the project concerned mechanism design, the research area that studies how to design systems so that users' self-interested behavior will align with the system designer's goals. For example, an auction is a system for allocating one or more items to a set of bidders so that items are matched with the bidders who value them most. When one modifies the standard assumption that users know the value of each item to incorporate a cost for acquiring information about one's value, we showed that different auction formats --- ascending-price, descending-price, and sealed bid auctions --- which were thought to yield the same outcome in equilibrium, can actually yield quite different outcomes, and that the descending-price auction is the only one among these that is guaranteed to approximate the optimal outcome. We also discovered a procedure that can be applied to any algorithm for making a decision based on information supplied by users, to transform the algorithm into an \"incentive compatible mechanism\", i.e. a system in which misreporting a user's private information never yields a decision more favorable for that user than if they had reported truthfully. Our procedure requires the system operator to know the probability distribution from which each user's information is sampled, and it requires the samples to be independently random. Resolving an eight-year-old open question, we devised such a procedure whose complexity grows only moderately as the number of bidders grows.\n\n\t\t\t\t\tLast Modified: 06/10/2022\n\n\t\t\t\t\tSubmitted by: Robert Kleinberg"
 }
}