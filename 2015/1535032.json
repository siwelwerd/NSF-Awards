{
 "awd_id": "1535032",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SI2-SSE: Scalable Multifaceted Graphical Processing Unit (GPU) Program Debugging",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032928235",
 "po_email": "bmihaila@nsf.gov",
 "po_sign_block_name": "Bogdan Mihaila",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-03-31",
 "tot_intn_awd_amt": 417482.0,
 "awd_amount": 435482.0,
 "awd_min_amd_letter_date": "2015-06-15",
 "awd_max_amd_letter_date": "2016-09-14",
 "awd_abstract_narration": "Modern scientific research crucially depends on software simulations that help model scientific phenomena, and accelerate the process of discoveries, and communal result sharing. With the availability of affordable computational accelerators known as GPUs, the scientific community has begun migrating their existing CPU codes as well as creating new codes targeting GPUs. Unfortunately, this has resulted in a situation where the generated scientific results do not often agree across CPUs and GPUs. This exacerbates the danger of drawing wrong conclusions in crucial areas such as physics, weather simulations, drug discovery, and engineering computations. This project offers a combination of existing and new techniques in dissecting scientific experiments conducted through simulations, obtaining believable results, finding the root causes of varying results, and developing best practices to ensure higher result fidelity. Its techniques have special emphasis on GPUs, given their often poorly specified and evolving nature.\r\n\r\nResult variability has many causes, including evolving, incorrect, or ambiguous specifications of computer hardware and software, racing data accesses, varying floating point precision standards, and incorrect result association within compound computational steps. This project develops methods that help a scientist systematically search through and eliminate these causes, thus accelerating the process of debugging result variability. The produced tools and exemplars of known erroneous behaviors allow a scientist to avoid the use of incorrect specifications, isolate and eliminate data races, and isolate and eliminate unreliable numerical steps. It also develops methods that help a scientist maintain focus on their basic scientific pursuits while still keeping up with technology evolution. It trains students in critical software engineering techniques that help the nation build the talent pool necessary for the extreme scale computing era.\r\n\r\nThe project will combine six research thrusts (GPU concurrency; challenge problems and develop user interfaces; pedagogy for domain scientists; improved GPU concurrency debugging tool support; more reproducible simulation results; and evolving and scaling tools with standards) to build and deliver open source software that incorporates proven stress-testing methods into tools; builds challenge problems, supports formalization support, and designs the user interface; delivers demos, books, and tutorials that help illustrate concurrency nuances; exploits symbolic analysis for input generation in mixed formal and GPU runs; develops stress testing inputs for round-off errors and separable verification to root-cause roundoff; and componentizes the symbolic verifier to enable parallelism, targeting from new APIs.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ganesh",
   "pi_last_name": "Gopalakrishnan",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Ganesh L Gopalakrishnan",
   "pi_email_addr": "ganesh@cs.utah.edu",
   "nsf_id": "000160895",
   "pi_start_date": "2015-06-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841129205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "800400",
   "pgm_ele_name": "Software Institutes"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "019Z",
   "pgm_ref_txt": "Grad Prep APG:Enhan. Experience"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8004",
   "pgm_ref_txt": "Software Institutes"
  },
  {
   "pgm_ref_code": "8005",
   "pgm_ref_txt": "Scientific Software Elements"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 417482.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 18000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>High performance computing applications are designed to model natural phenomena and simulate the characteristics of these models in response to selected inputs and problem parameters.&nbsp; Given their computational demands, these simulations are carried out on the most advanced machines available, and require the use of a software tool chain that translates user intentions to runnable codes.&nbsp; As these machines become more advanced thanks to the developments in semiconductor technology, the tool chain supporting these simulations must also correspondingly adapt to the needs of the newer machines. A typical long-lived scientific simulation application spans multiple generations of such machines and tool chains, thus requiring multiple adaptation steps in its lifetime.</p>\n<p><br />Prominent among the tools assisting in this process are compilers that translate user's higher level problem expressions into runnable sequential and parallel codes. Unfortunately, with each advance in the design of compilers, the computed answers even for the same problem specification and input differ from previously obtained answers. Computational scientists are constantly engaged in reconciling these result changes, and through their expertise, are able to classify the result changes as either acceptable or as needing further investigation. Unfortunately, lacking support tools, their current methods are heavily manual, hence labor intensive, error-prone, and non-scalable. This project addresses this serious and growing concern by providing tool support that automates the investigation.</p>\n<p><br />Specifically, this project provides a suite of tools to conduct the necessary investigations that help pinpoint the sources of result variability when simulation applications are ported across machines and their compilers.&nbsp; The project has contributed a tool suite called FLiT that can be employed when a particular compilation leads to an unacceptable result change. FLiT automates the examination of the simulation application under varying mixes of compiler optimizations and library bindings. This helps the developer narrow down the scope of the problems to either a file containing function definitions or even a single function defined within a source code file.</p>\n<p><br />Provided as part of FLiT is also a facility to study the speedups obtained through various compilation options, and the degree of result variability. Such plots help the developer obtain higher performance in those cases where the application is tolerant to result variations. FLiT's user-provided test acceptance function can be parameterized with information pertaining to allowed result variability.</p>\n<p><br />Key intellectual contributions underlying FLiT include its ability to create a search space of compilation optimizations that are applied to specific files and individual functions within these files.&nbsp; Thanks to key assumptions pertaining to error cancellations that are often justified in practice, FLiT is able to subdivide a typical search space of thousands of options across a logarithmically sized number of steps. In practice, this has resulted in a successful root-causing search even within large projects.</p>\n<p><br />Key broader impacts of FLiT include its demonstrated success in the context of leading HPC applications where the scientists faced the impossible situation of making headway in root-causing result-changing compiler optimizations. Other broad and tangible outcomes include well-documented and released versions of the codebase of FLiT.&nbsp; The long-lasting impact of this project is in the form of students andstaff who are now part of our nation's intellectual capital and expert pool, as evidenced by them being invited to give high visibilitytutorials in some of the most visible of international settings.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/06/2019<br>\n\t\t\t\t\tModified by: Ganesh&nbsp;L&nbsp;Gopalakrishnan</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562463026950_workflow--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562463026950_workflow--rgov-800width.jpg\" title=\"Workflow of FLiT tool\"><img src=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562463026950_workflow--rgov-66x44.jpg\" alt=\"Workflow of FLiT tool\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Workflow of FLiT tool showing how a developer can submit their result-changing compilation and obtain root-causing help</div>\n<div class=\"imageCredit\">Michael Bentley</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Ganesh&nbsp;L&nbsp;Gopalakrishnan</div>\n<div class=\"imageTitle\">Workflow of FLiT tool</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562463123220_ex05_Test-d--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562463123220_ex05_Test-d--rgov-800width.jpg\" title=\"Speedup vs. reproducibility: test 5\"><img src=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562463123220_ex05_Test-d--rgov-66x44.jpg\" alt=\"Speedup vs. reproducibility: test 5\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">MFEM's test 5 exhibits many reproducible and faster compilation combinations</div>\n<div class=\"imageCredit\">Michael Bentley</div>\n<div class=\"imageSubmitted\">Ganesh&nbsp;L&nbsp;Gopalakrishnan</div>\n<div class=\"imageTitle\">Speedup vs. reproducibility: test 5</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562463538380_mfem-variability-boxplot--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562463538380_mfem-variability-boxplot--rgov-800width.jpg\" title=\"Result variability isolated\"><img src=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562463538380_mfem-variability-boxplot--rgov-66x44.jpg\" alt=\"Result variability isolated\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The extent of result variability across various tests provided with the MFEM application</div>\n<div class=\"imageCredit\">Michael Bentley</div>\n<div class=\"imageSubmitted\">Ganesh&nbsp;L&nbsp;Gopalakrishnan</div>\n<div class=\"imageTitle\">Result variability isolated</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562464094574_bisect-search--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562464094574_bisect-search--rgov-800width.jpg\" title=\"FLiT's bisect search\"><img src=\"/por/images/Reports/POR/2019/1535032/1535032_10369696_1562464094574_bisect-search--rgov-66x44.jpg\" alt=\"FLiT's bisect search\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The logarithmic bisect search performed by FLiT</div>\n<div class=\"imageCredit\">Michael Bentley</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Ganesh&nbsp;L&nbsp;Gopalakrishnan</div>\n<div class=\"imageTitle\">FLiT's bisect search</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nHigh performance computing applications are designed to model natural phenomena and simulate the characteristics of these models in response to selected inputs and problem parameters.  Given their computational demands, these simulations are carried out on the most advanced machines available, and require the use of a software tool chain that translates user intentions to runnable codes.  As these machines become more advanced thanks to the developments in semiconductor technology, the tool chain supporting these simulations must also correspondingly adapt to the needs of the newer machines. A typical long-lived scientific simulation application spans multiple generations of such machines and tool chains, thus requiring multiple adaptation steps in its lifetime.\n\n\nProminent among the tools assisting in this process are compilers that translate user's higher level problem expressions into runnable sequential and parallel codes. Unfortunately, with each advance in the design of compilers, the computed answers even for the same problem specification and input differ from previously obtained answers. Computational scientists are constantly engaged in reconciling these result changes, and through their expertise, are able to classify the result changes as either acceptable or as needing further investigation. Unfortunately, lacking support tools, their current methods are heavily manual, hence labor intensive, error-prone, and non-scalable. This project addresses this serious and growing concern by providing tool support that automates the investigation.\n\n\nSpecifically, this project provides a suite of tools to conduct the necessary investigations that help pinpoint the sources of result variability when simulation applications are ported across machines and their compilers.  The project has contributed a tool suite called FLiT that can be employed when a particular compilation leads to an unacceptable result change. FLiT automates the examination of the simulation application under varying mixes of compiler optimizations and library bindings. This helps the developer narrow down the scope of the problems to either a file containing function definitions or even a single function defined within a source code file.\n\n\nProvided as part of FLiT is also a facility to study the speedups obtained through various compilation options, and the degree of result variability. Such plots help the developer obtain higher performance in those cases where the application is tolerant to result variations. FLiT's user-provided test acceptance function can be parameterized with information pertaining to allowed result variability.\n\n\nKey intellectual contributions underlying FLiT include its ability to create a search space of compilation optimizations that are applied to specific files and individual functions within these files.  Thanks to key assumptions pertaining to error cancellations that are often justified in practice, FLiT is able to subdivide a typical search space of thousands of options across a logarithmically sized number of steps. In practice, this has resulted in a successful root-causing search even within large projects.\n\n\nKey broader impacts of FLiT include its demonstrated success in the context of leading HPC applications where the scientists faced the impossible situation of making headway in root-causing result-changing compiler optimizations. Other broad and tangible outcomes include well-documented and released versions of the codebase of FLiT.  The long-lasting impact of this project is in the form of students andstaff who are now part of our nation's intellectual capital and expert pool, as evidenced by them being invited to give high visibilitytutorials in some of the most visible of international settings.\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 07/06/2019\n\n\t\t\t\t\tSubmitted by: Ganesh L Gopalakrishnan"
 }
}