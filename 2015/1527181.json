{
 "awd_id": "1527181",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Small: Time Resolved Imaging: New Methods for Capture, Analysis and Applications",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 460000.0,
 "awd_amount": 460000.0,
 "awd_min_amd_letter_date": "2015-08-18",
 "awd_max_amd_letter_date": "2019-12-13",
 "awd_abstract_narration": "This project fundamentally combines the emerging time of flight imaging techniques with computational methods to redefine a camera and also go beyond the conventional barriers in scientific imaging.  Imaging has transformed science and technology in many fields.  Time-aware ultrafast imaging can bring further radical new innovations in coming years.  Recently, there has been a significant commercial interest in converting time-aware sensors into low cost consumer solutions.  Going forward, solving time-based forward and inverse transport problems can impact new fundamental research in biology, physics, optics, computer science, engineering, and mathematics, with broad applications in health, robotics, defense, and mobility. They have high potential to stimulate economic investment and entrepreneurship using modern imaging solutions. \r\n\r\nEmerging image sensors with picosecond (ps) time resolution provide new ways to capture and understand the world. For scene analysis, typical computational imaging techniques exploit sensor parameters such as spatial resolution, wavelength, and polarization.  However, they are far slower than light speed and are consequently limited in their ability to model the complex dynamics of light propagation.  Time-resolved (or transient) sensors overcome this limitation, but their integration with computational methods has not been realized yet.  Therefore, with the recent spurt in commercial time-of-flight (ToF) systems, new research in transient computational imaging is well-timed. Beyond ToF depth information, this research explores the capture and analysis of per-pixel time profiles at ps scales. This leads to joint re-examination of fundamental inverse problems and solutions in scientific, industrial and consumer applications. Specifically the project builds computer vision algorithms for seeing objects beyond the line of sight, behind diffusive layers and inside turbid media. This provides novel applications in medical imaging. With the development of the theoretical foundation and enabling tools, the project accelerates research and commercialization of this new field.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ramesh",
   "pi_last_name": "Raskar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ramesh Raskar",
   "pi_email_addr": "raskar@media.mit.edu",
   "nsf_id": "000502041",
   "pi_start_date": "2015-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Ave.",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394307",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 460000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-765e9c98-7fff-5758-7379-11b49e6a9433\">&nbsp;</span></p>\n<p dir=\"ltr\"><span>The project seeks to build a foundation for time aware imaging, including theory and algorithms, sensing mechanisms, analysis tools, and applications. To that end we develop time of flight (ToF) sensing techniques for imaging through scattering media and more general novel imaging frameworks with impulse-based and continuous-wave ToF sensing.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><strong><span style=\"text-decoration: underline;\">Imaging through scattering media with ToF sensing</span></strong></p>\n<p dir=\"ltr\"><span>Imaging through scattering media is a challenging problem with applications in medical imaging and imaging in degraded weather conditions that is essential for autonomous navigation. The challenge arises from the need to invert the scattering process. ToF sensing can assist in this task. The ToF information encodes additional information that is helpful in inverting the scatting process. We have developed several modalities with this approach:</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>1- Imaging through thick tissue with All Photon Imaging. We demonstrated recovery of a target hidden behind a 1.5 thick tissue phantom. This was achieved with a probabilistic model of photon arrival times in both time and space. This helped to use all of the optical signal to invert the scattering. Figure 1 shows the optical setup and a recovery result.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>2- Imaging through dense, dynamic, and heterogeneous fog. We show that photons that are back reflected from the fog and photons that are reflected from the occluded target follow different statistics in time. We estimate these statistics and reject photons that are back reflected from the fog. We demonstrate recovery of reflectance and depth through extremely dense fog. Figure 2 shows the results from our work. </span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>3- Classifying hidden objects behind a diffuser with convolutional neural networks. Typically, solving inverse scattering problems require parameter tuning of physical models. In this work, we used a data driven approach to learn a model that is invariant to variations in calibration parameters. We demonstrated robust identification and classification of objects behind a diffuser without a calibration procedure. Figure 3 illustrates this technique.</span></p>\n<p><br /><br /><br /></p>\n<p dir=\"ltr\"><span style=\"text-decoration: underline;\"><strong>Novel Imaging Frameworks based on ToF Sensing</strong></span></p>\n<p dir=\"ltr\"><span>We propose novel imaging techniques that leverage time-resolved measurement. Our goal is to develop new sensing modalities that enable e.g. imaging in challenging environments and outside the visible spectrum like ThZ and IR. We explored ToF sensing that are either impulse based or continuous-wave ToF (CW-ToF).</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><strong>Imaging Frameworks with impulse-based ToF Sensing</strong></p>\n<p dir=\"ltr\"><span>1- Efficient Lensless Imaging with a femto-pixel. We developed a novel compressive sensing architecture with a lensless single pixel. As compared to existing methods, our method uses ToF information to recover an image with substantially shorter acquisition time.</span></p>\n<p dir=\"ltr\"><span>2- Optical Brush. We prototyped a novel imaging device consists of flexible optical fibers that can freely move in complex geometry such as inside human body. ToF information enables full localization of each fiber to reconstruct images. </span></p>\n<p dir=\"ltr\"><span>3- Time-folded Optics. We introduced a cavity into the imaging system along with a time resolved sensor. This configuration leverages the space-time coupling and simplifies traditional imaging system. We demonstrated lens compression, multi-focus, multi-zoom and multi-spectrum imaging. Figure 4 shows the concept of time-folded imaging and demonstrates it in the case of compressing a lens in time.</span></p>\n<p dir=\"ltr\">4- Autocalibration for Non Line of Sight Imaging: We have developed a novel optimization based architecture to automatically correct the calibration errors made during the NLOS experimental setup. This algorithm utilizes the latest developemnts in autodifferentiation by building a differentiable framework to model the physics of the NLOS setup.</p>\n<p><br /><br /></p>\n<p dir=\"ltr\"><strong>Imaging Frameworks with CW-ToF Sensing</strong></p>\n<p dir=\"ltr\"><span>CW-ToF imaging is more affordable than impulse based ToF sensing, but has limitations such as multipath interference. CW-ToF measures phase of modulated light intensity instead of directly measuring time-of-flight information. In this work, we developed techniques and theoretical frameworks to overcome such limitations. </span></p>\n<p dir=\"ltr\"><span>1- &nbsp;Frequency Domain Time of Flight (FD-ToF) imaging for multipath interference. While traditional CW-ToF cameras take multiple measurement at fixed modulation frequency with different reference phase, FD-ToF sweeps modulation frequencies over multiple measurements. This provides robustness to phase wrapping. Figure 5 shows the overview of FD-ToF technique. </span></p>\n<p dir=\"ltr\"><span>2- CW-ToF imaging to look around corners. We demonstrated NLOS imaging around the corner with commercial off-the-shelf CW-ToF cameras. When a wall has a small specular BRDF component, the resolution of NLOS with CW-ToF cameras drastically improves. We showed that NLOS imaging is practically possible for various common materials with affordable cameras. Figure 6 shows results of NLOS imaging using CW-ToF sensor.</span></p>\n<p dir=\"ltr\"><span>3- Dynamic heterodyne interferometry for robust sensing in the scale of optical wavelength. We combined time-resolved measurement scheme similar to CW-ToF sensing with polarization. This approach allows interferometry that is robust to noises such as mechanical vibrations and ambient light. </span></p>\n<p><br /><br /></p>\n<p dir=\"ltr\"><span>In summary, our work utilizes ToF measurements and allows imaging in challenging scenarios. We demonstrated: ToF sensing techniques that can image through scattering media such as dense tissue and fog, and novel imaging frameworks based on impulse continuous-wave time resolved sensing.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/01/2021<br>\n\t\t\t\t\tModified by: Ramesh&nbsp;Raskar</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542731674224_Figure1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542731674224_Figure1--rgov-800width.jpg\" title=\"All Photon Imaging\"><img src=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542731674224_Figure1--rgov-66x44.jpg\" alt=\"All Photon Imaging\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Overview of All Photon Imaging</div>\n<div class=\"imageCredit\">Guy Satat, Barmak Heshmat, Dan Raviv, Ramesh Raskar</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ramesh&nbsp;Raskar</div>\n<div class=\"imageTitle\">All Photon Imaging</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542731788412_figure2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542731788412_figure2--rgov-800width.jpg\" title=\"Seeing through Extremely Dense Fog\"><img src=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542731788412_figure2--rgov-66x44.jpg\" alt=\"Seeing through Extremely Dense Fog\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Experimental setup and result</div>\n<div class=\"imageCredit\">Guy Satat, Matthew Tancik, Ramesh Raskar</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ramesh&nbsp;Raskar</div>\n<div class=\"imageTitle\">Seeing through Extremely Dense Fog</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542731909226_Figure3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542731909226_Figure3--rgov-800width.jpg\" title=\"Calibration Invariant Imaging\"><img src=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542731909226_Figure3--rgov-66x44.jpg\" alt=\"Calibration Invariant Imaging\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Calibration invariant imaging through scattering using deep learning</div>\n<div class=\"imageCredit\">Guy Satat, Matthew Tancik, Otkrist Gupta, Barmak Heshmat Ramesh Raskar</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ramesh&nbsp;Raskar</div>\n<div class=\"imageTitle\">Calibration Invariant Imaging</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542732052695_Figure4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542732052695_Figure4--rgov-800width.jpg\" title=\"Time-Folded Optics\"><img src=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542732052695_Figure4--rgov-66x44.jpg\" alt=\"Time-Folded Optics\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Lens Compression Example</div>\n<div class=\"imageCredit\">Barmak Heshmat, Matthew Tancik, Guy Satat, Ramesh Raskar</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ramesh&nbsp;Raskar</div>\n<div class=\"imageTitle\">Time-Folded Optics</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542732187375_Figure5--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542732187375_Figure5--rgov-800width.jpg\" title=\"Macroscopic Interferometry (Frequency Domain Time-of-Flight Camera)\"><img src=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542732187375_Figure5--rgov-66x44.jpg\" alt=\"Macroscopic Interferometry (Frequency Domain Time-of-Flight Camera)\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Overview of frequency domain time-of-flight imaging system</div>\n<div class=\"imageCredit\">Achuta Kadambi, Jamie Schiel, Ramesh Raskar</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ramesh&nbsp;Raskar</div>\n<div class=\"imageTitle\">Macroscopic Interferometry (Frequency Domain Time-of-Flight Camera)</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542732414505_Figure6--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542732414505_Figure6--rgov-800width.jpg\" title=\"Non-Line of Sight Imaging with Continuous-Wave Based ToF Camera\"><img src=\"/por/images/Reports/POR/2018/1527181/1527181_10388959_1542732414505_Figure6--rgov-66x44.jpg\" alt=\"Non-Line of Sight Imaging with Continuous-Wave Based ToF Camera\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Experimental result of non-line of sight imaging with off-the-shelf continuous-wave based ToF camera.</div>\n<div class=\"imageCredit\">Achuta Kadambi, Hang Zhao, Boxin Shi, Ramesh Raskar</div>\n<div class=\"imageSubmitted\">Ramesh&nbsp;Raskar</div>\n<div class=\"imageTitle\">Non-Line of Sight Imaging with Continuous-Wave Based ToF Camera</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nThe project seeks to build a foundation for time aware imaging, including theory and algorithms, sensing mechanisms, analysis tools, and applications. To that end we develop time of flight (ToF) sensing techniques for imaging through scattering media and more general novel imaging frameworks with impulse-based and continuous-wave ToF sensing.\n\n \nImaging through scattering media with ToF sensing\nImaging through scattering media is a challenging problem with applications in medical imaging and imaging in degraded weather conditions that is essential for autonomous navigation. The challenge arises from the need to invert the scattering process. ToF sensing can assist in this task. The ToF information encodes additional information that is helpful in inverting the scatting process. We have developed several modalities with this approach:\n\n \n1- Imaging through thick tissue with All Photon Imaging. We demonstrated recovery of a target hidden behind a 1.5 thick tissue phantom. This was achieved with a probabilistic model of photon arrival times in both time and space. This helped to use all of the optical signal to invert the scattering. Figure 1 shows the optical setup and a recovery result.\n\n \n2- Imaging through dense, dynamic, and heterogeneous fog. We show that photons that are back reflected from the fog and photons that are reflected from the occluded target follow different statistics in time. We estimate these statistics and reject photons that are back reflected from the fog. We demonstrate recovery of reflectance and depth through extremely dense fog. Figure 2 shows the results from our work. \n\n \n3- Classifying hidden objects behind a diffuser with convolutional neural networks. Typically, solving inverse scattering problems require parameter tuning of physical models. In this work, we used a data driven approach to learn a model that is invariant to variations in calibration parameters. We demonstrated robust identification and classification of objects behind a diffuser without a calibration procedure. Figure 3 illustrates this technique.\n\n\n\n\n\nNovel Imaging Frameworks based on ToF Sensing\nWe propose novel imaging techniques that leverage time-resolved measurement. Our goal is to develop new sensing modalities that enable e.g. imaging in challenging environments and outside the visible spectrum like ThZ and IR. We explored ToF sensing that are either impulse based or continuous-wave ToF (CW-ToF).\n\n \nImaging Frameworks with impulse-based ToF Sensing\n1- Efficient Lensless Imaging with a femto-pixel. We developed a novel compressive sensing architecture with a lensless single pixel. As compared to existing methods, our method uses ToF information to recover an image with substantially shorter acquisition time.\n2- Optical Brush. We prototyped a novel imaging device consists of flexible optical fibers that can freely move in complex geometry such as inside human body. ToF information enables full localization of each fiber to reconstruct images. \n3- Time-folded Optics. We introduced a cavity into the imaging system along with a time resolved sensor. This configuration leverages the space-time coupling and simplifies traditional imaging system. We demonstrated lens compression, multi-focus, multi-zoom and multi-spectrum imaging. Figure 4 shows the concept of time-folded imaging and demonstrates it in the case of compressing a lens in time.\n4- Autocalibration for Non Line of Sight Imaging: We have developed a novel optimization based architecture to automatically correct the calibration errors made during the NLOS experimental setup. This algorithm utilizes the latest developemnts in autodifferentiation by building a differentiable framework to model the physics of the NLOS setup.\n\n\n\n\nImaging Frameworks with CW-ToF Sensing\nCW-ToF imaging is more affordable than impulse based ToF sensing, but has limitations such as multipath interference. CW-ToF measures phase of modulated light intensity instead of directly measuring time-of-flight information. In this work, we developed techniques and theoretical frameworks to overcome such limitations. \n1-  Frequency Domain Time of Flight (FD-ToF) imaging for multipath interference. While traditional CW-ToF cameras take multiple measurement at fixed modulation frequency with different reference phase, FD-ToF sweeps modulation frequencies over multiple measurements. This provides robustness to phase wrapping. Figure 5 shows the overview of FD-ToF technique. \n2- CW-ToF imaging to look around corners. We demonstrated NLOS imaging around the corner with commercial off-the-shelf CW-ToF cameras. When a wall has a small specular BRDF component, the resolution of NLOS with CW-ToF cameras drastically improves. We showed that NLOS imaging is practically possible for various common materials with affordable cameras. Figure 6 shows results of NLOS imaging using CW-ToF sensor.\n3- Dynamic heterodyne interferometry for robust sensing in the scale of optical wavelength. We combined time-resolved measurement scheme similar to CW-ToF sensing with polarization. This approach allows interferometry that is robust to noises such as mechanical vibrations and ambient light. \n\n\n\n\nIn summary, our work utilizes ToF measurements and allows imaging in challenging scenarios. We demonstrated: ToF sensing techniques that can image through scattering media such as dense tissue and fog, and novel imaging frameworks based on impulse continuous-wave time resolved sensing.\n\n \n\n\t\t\t\t\tLast Modified: 03/01/2021\n\n\t\t\t\t\tSubmitted by: Ramesh Raskar"
 }
}