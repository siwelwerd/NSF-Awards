{
 "awd_id": "1525902",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Deep Learning Software Repositories",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2015-07-20",
 "awd_max_amd_letter_date": "2015-07-20",
 "awd_abstract_narration": "Improvements in both computational power and the amount of memory in modern computer architectures, have enabled new approaches to canonical machine learning tasks. Specifically, these architectural advances have enabled machines, which are capable of learning deep compositional representations of massive data repositories. The rise of deep learning has ushered tremendous advances in several fields, and, given the complexity of software repositories, our hypothesis is that deep learning has the potential to usher new analytical frameworks and methodologies for Software Engineering research as well practice.\r\n\r\nThe research program addresses three main goals by applying deep learning where conventional machine learning has been used before. First is the design of new models based on deep architectures for Software Engineering tasks. The project will develop deep software language models for sequence analysis tasks and deep information retrieval models for document analysis tasks. Second, the project will apply the internal representations to practical problems in Software Engineering by instantiating deep learning to support tasks such as code suggestion, improving software lexicons, model-based testing, code search and clone detection. Third, the project will conduct empirical evaluations designed to demonstrate ways of modeling software artifacts that will inform entirely novel suites of learned features that can be used from task to task. The move from traditional machine learning to deep learning will improve results in many software analysis tasks and in empirical Software Engineering research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Denys",
   "pi_last_name": "Poshyvanyk",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Denys Poshyvanyk",
   "pi_email_addr": "dposhyvanyk@wm.edu",
   "nsf_id": "000516306",
   "pi_start_date": "2015-07-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "College of William and Mary",
  "inst_street_address": "1314 S MOUNT VERNON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "WILLIAMSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "7572213965",
  "inst_zip_code": "23185",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "VA08",
  "org_lgl_bus_name": "COLLEGE OF WILLIAM AND MARY",
  "org_prnt_uei_num": "EVWJPCY6AD97",
  "org_uei_num": "EVWJPCY6AD97"
 },
 "perf_inst": {
  "perf_inst_name": "College of William and Mary",
  "perf_str_addr": "McGlothlin-Street Hall 006",
  "perf_city_name": "Williamsburg",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "231887921",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "VA01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research project posits a new research paradigm for SE where low-level representations automatically acquire domain knowledge from unlabeled input, and this knowledge automatically informs a hierarchy of features. Additionally, in this new paradigm, the knowledge we learn in one domain (e.g., software engineering problem) can be transferred to another domain under certain conditions. The project lies at the nexus of this rich new class of models and SE. Notwithstanding the complexity of the problem, we used two principal abstractions, sequences (e.g., execution traces) and documents (e.g., source code files), to couple deep compositional representations to critical SE tasks. The minimal amount of structure imposed on sequences and documents yields generic abstractions that pervade solutions in SE research. In other words, with documents and sequences, we are modeling objects and simple arrangements of objects, respectively. Hence, we used Deep Learning (DL), a nascent field in machine learning (ML), to provide the SE community with new ways to conduct sequence analysis and document analysis in different SE contexts. The near-term goal of our research program was in providing a new framework for SE research and methodologies for designing, applying and evaluating unprecedented conceptualizations of massive software repositories. These conceptualizations in turn measurably affected many critical SE tasks (see our publications at http://www.cs.wm.edu/~denys/publications.html). The long-term goal of our research program will be on the tools in commercial software development. Specifically, the proposed research program has addressed the following three main goals amplified by key objectives:&nbsp;</p>\n<p><strong>Designed new models based on deep architectures for critical SE tasks</strong>. We designed and published models based on deep architectures for SE research. We focused on models for conducting sequence analysis (e.g., software language modeling (SLM)) and document analysis (e.g., information retrieval (IR)). We defined deep software language models for sequence analysis tasks and deep IR models for document analysis tasks. This work admitted completely new learning and inference procedures for SE researchers. The novelty in this work lies in how we use these learning and inference procedures to solve SE problems such as quickly inferring relevant code snippets or controlling evolutionary aspects of software application development. The proposed work is poised to impact and improve all SE solutions relying on SLM and IR techniques.&nbsp;</p>\n<p><strong>Applied internal representations to practical problems in SE</strong>. DL is a growing field in ML, and several different types of deep architectures have been already applied in fields such as computer vision and natural language processing. We instantiated DL to support practical problems in SE, e.g., code suggestion, improving software lexicon, model-based testing, language migration, code search, clone detection and automated program repair. In our experiments, DL significantly outperformed state-of-the-art results measuring the quality of a language model. These high-quality language models demonstrate the risk of our proposed work on SLM is low, yet the opportunity is high since we showed language models are an underlying abstraction for many critical SE tasks.</p>\n<p><strong>Evaluated new approaches based on DL to practical problems in SE</strong>. Our empirical evaluations were designed to ensure the paradigm shift in representations impacts practical problems in SE. There are several nontrivial dimensions to these evaluations. We validated the proposed approaches using empirical techniques such as case studies and controlled experiments. One of the challenging aspects of these experiments was the model selection problem: Deep architectures typically comprise a number of hyper-parameters spanning expansive design spaces. These are new search problems for SE research and SE datasets. To support evaluations over massive repositories, we engineered new data sets and benchmarks for SE community (e.g., https://github.com/micheletufano/AutoenCODE). We also designed and implemented new DL-based application programming interfaces (APIs) tailored to SE research concerns on top of existing DL libraries, and we built tools based on our research for critical SE tasks.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/12/2019<br>\n\t\t\t\t\tModified by: Denys&nbsp;Poshyvanyk</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis research project posits a new research paradigm for SE where low-level representations automatically acquire domain knowledge from unlabeled input, and this knowledge automatically informs a hierarchy of features. Additionally, in this new paradigm, the knowledge we learn in one domain (e.g., software engineering problem) can be transferred to another domain under certain conditions. The project lies at the nexus of this rich new class of models and SE. Notwithstanding the complexity of the problem, we used two principal abstractions, sequences (e.g., execution traces) and documents (e.g., source code files), to couple deep compositional representations to critical SE tasks. The minimal amount of structure imposed on sequences and documents yields generic abstractions that pervade solutions in SE research. In other words, with documents and sequences, we are modeling objects and simple arrangements of objects, respectively. Hence, we used Deep Learning (DL), a nascent field in machine learning (ML), to provide the SE community with new ways to conduct sequence analysis and document analysis in different SE contexts. The near-term goal of our research program was in providing a new framework for SE research and methodologies for designing, applying and evaluating unprecedented conceptualizations of massive software repositories. These conceptualizations in turn measurably affected many critical SE tasks (see our publications at http://www.cs.wm.edu/~denys/publications.html). The long-term goal of our research program will be on the tools in commercial software development. Specifically, the proposed research program has addressed the following three main goals amplified by key objectives: \n\nDesigned new models based on deep architectures for critical SE tasks. We designed and published models based on deep architectures for SE research. We focused on models for conducting sequence analysis (e.g., software language modeling (SLM)) and document analysis (e.g., information retrieval (IR)). We defined deep software language models for sequence analysis tasks and deep IR models for document analysis tasks. This work admitted completely new learning and inference procedures for SE researchers. The novelty in this work lies in how we use these learning and inference procedures to solve SE problems such as quickly inferring relevant code snippets or controlling evolutionary aspects of software application development. The proposed work is poised to impact and improve all SE solutions relying on SLM and IR techniques. \n\nApplied internal representations to practical problems in SE. DL is a growing field in ML, and several different types of deep architectures have been already applied in fields such as computer vision and natural language processing. We instantiated DL to support practical problems in SE, e.g., code suggestion, improving software lexicon, model-based testing, language migration, code search, clone detection and automated program repair. In our experiments, DL significantly outperformed state-of-the-art results measuring the quality of a language model. These high-quality language models demonstrate the risk of our proposed work on SLM is low, yet the opportunity is high since we showed language models are an underlying abstraction for many critical SE tasks.\n\nEvaluated new approaches based on DL to practical problems in SE. Our empirical evaluations were designed to ensure the paradigm shift in representations impacts practical problems in SE. There are several nontrivial dimensions to these evaluations. We validated the proposed approaches using empirical techniques such as case studies and controlled experiments. One of the challenging aspects of these experiments was the model selection problem: Deep architectures typically comprise a number of hyper-parameters spanning expansive design spaces. These are new search problems for SE research and SE datasets. To support evaluations over massive repositories, we engineered new data sets and benchmarks for SE community (e.g., https://github.com/micheletufano/AutoenCODE). We also designed and implemented new DL-based application programming interfaces (APIs) tailored to SE research concerns on top of existing DL libraries, and we built tools based on our research for critical SE tasks. \n\n\t\t\t\t\tLast Modified: 11/12/2019\n\n\t\t\t\t\tSubmitted by: Denys Poshyvanyk"
 }
}