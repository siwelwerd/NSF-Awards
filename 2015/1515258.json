{
 "awd_id": "1515258",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "EAPSI: Identifying Relations between Computer-Generated and Manually Annotated Interpretations of Activities for Planning and Plan Recognition Tasks",
 "cfda_num": "47.079",
 "org_code": "01090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Anne Emig",
 "awd_eff_date": "2015-06-01",
 "awd_exp_date": "2016-05-31",
 "tot_intn_awd_amt": 5070.0,
 "awd_amount": 5070.0,
 "awd_min_amd_letter_date": "2015-06-03",
 "awd_max_amd_letter_date": "2015-06-03",
 "awd_abstract_narration": "While humans perceive activities using words and cluster similar activities by some properties, computers using unsupervised learning algorithms do not necessarily identify them the same way and thus generate different interpretations. The goal of this research is to develop an analogy between human and machine definitions of activities so that artificial intelligence planning and plan recognition methods do not need to be adjusted for each set of definitions. Usually, either humans define the activities in a way which is too vague for machines to make accurate computations or computers define activities such that people cannot understand the underlying reasoning. Developing an interpreter for each entity will not only smooth the interaction between users and devices when solving problems together, but also contribute to bridging the human-computer gap. This project will use techniques in the research areas of interest to Dr. Alex Fukunaga at the University of Tokyo who studies many facets of artificial intelligence, especially those regarding autonomous planning, search, and optimization.\r\n\r\nExtending prior research on unsupervised activity recognition using topic models, this work proposes a two-step approach consisting of constraint optimization and heuristic search. The first phase uses constraint optimization to align a computer's recognized activity sequence with a given human's annotation of the same sequence. Then the second phase similarly aligns a computer's recognized activity sequence with an annotation of the sequence derived by heuristic search over a human-defined hierarchical task network. To develop these methods, the project will include formalizing the constraint and search problems, coding their formulations, and testing results of the identified mappings between the two definition sets. This test will be performed by combining an unsupervised activity recognition method previously developed by the PI for machine-interpreted actions with a commonly used plan recognition method that uses human-perceived action representations. This NSF EAPSI award is funded in collaboration with the Japan Society for the Promotion of Science.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "O/D",
 "org_dir_long_name": "Office Of The Director",
 "div_abbr": "OISE",
 "org_div_long_name": "Office of International Science and Engineering",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Freedman",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Richard G Freedman",
   "pi_email_addr": "",
   "nsf_id": "000685325",
   "pi_start_date": "2015-06-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Freedman                Richard        G",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "Amherst",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "",
  "inst_zip_code": "010021372",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "University of Tokyo",
  "perf_str_addr": null,
  "perf_city_name": "",
  "perf_st_code": "",
  "perf_st_name": "RI REQUIRED",
  "perf_zip_code": "",
  "perf_ctry_code": "JA",
  "perf_cong_dist": "",
  "perf_st_cong_dist": "",
  "perf_ctry_name": "Japan",
  "perf_ctry_flag": "0"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "731600",
   "pgm_ele_name": "EAPSI"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5921",
   "pgm_ref_txt": "JAPAN"
  },
  {
   "pgm_ref_code": "5978",
   "pgm_ref_txt": "EAST ASIA AND PACIFIC PROGRAM"
  },
  {
   "pgm_ref_code": "7316",
   "pgm_ref_txt": "EAPSI"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 5070.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>While humans perceive activities using words and cluster similar activities by some properties, computers using unsupervised learning algorithms do not necessarily identify them the same way and thus generate different interpretations. The goal of this research was to develop an analogy between human and machine definitions of activities so that artificial intelligence planning and plan recognition methods do not need to be adjusted for each set of definitions. This would create a translator between the two perspectives of activities so that artificial intelligence methods could be better integrated to facilitate interaction between humans and machines. In order to gain a better understanding of how to prepare the proposed research, we began working on the follow-up future work of integrating artificial intelligence planning methods with plan recognition. In particular, the proposed methods required defining constraints to align activity sequences labeled by both human annotations and a computer's recognition algorithm that the PI previously developed. Without a deeper understanding of how the human-labeled sequences are formed, our defined constraints may have been incorrect or yielded a less optimal matching.<br /><br />To study the human-defined actions, we reviewed and extended current research on reinterpreting the plan recognition task as a planning task with respect to how easy it is to solve problems using the observed human-defined actions. The initial method was not developed with real-time interaction in mind and did not make accurate predictions until it is too late to repsond before the task is solved without assistance. Our extensions made more accurate evaluations of 'easiness' and added a foresight factor to bias the recognition process in favor of tasks that are further from completion. With these extensions, we could identify the necessity of completing subtasks for which a computer could decide how to join in. We plan to return to the proposed research upon completing enough of this follow-up work to have the necessary information for the problem formulation and constraint development. This better understanding is expected to improve the results of the proposed research, which will also improve the later continuation of this work to develop a smoother interaction between users and devices when solving problems together.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/12/2016<br>\n\t\t\t\t\tModified by: Richard&nbsp;G&nbsp;Freedman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhile humans perceive activities using words and cluster similar activities by some properties, computers using unsupervised learning algorithms do not necessarily identify them the same way and thus generate different interpretations. The goal of this research was to develop an analogy between human and machine definitions of activities so that artificial intelligence planning and plan recognition methods do not need to be adjusted for each set of definitions. This would create a translator between the two perspectives of activities so that artificial intelligence methods could be better integrated to facilitate interaction between humans and machines. In order to gain a better understanding of how to prepare the proposed research, we began working on the follow-up future work of integrating artificial intelligence planning methods with plan recognition. In particular, the proposed methods required defining constraints to align activity sequences labeled by both human annotations and a computer's recognition algorithm that the PI previously developed. Without a deeper understanding of how the human-labeled sequences are formed, our defined constraints may have been incorrect or yielded a less optimal matching.\n\nTo study the human-defined actions, we reviewed and extended current research on reinterpreting the plan recognition task as a planning task with respect to how easy it is to solve problems using the observed human-defined actions. The initial method was not developed with real-time interaction in mind and did not make accurate predictions until it is too late to repsond before the task is solved without assistance. Our extensions made more accurate evaluations of 'easiness' and added a foresight factor to bias the recognition process in favor of tasks that are further from completion. With these extensions, we could identify the necessity of completing subtasks for which a computer could decide how to join in. We plan to return to the proposed research upon completing enough of this follow-up work to have the necessary information for the problem formulation and constraint development. This better understanding is expected to improve the results of the proposed research, which will also improve the later continuation of this work to develop a smoother interaction between users and devices when solving problems together.\n\n\t\t\t\t\tLast Modified: 03/12/2016\n\n\t\t\t\t\tSubmitted by: Richard G Freedman"
 }
}