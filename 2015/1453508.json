{
 "awd_id": "1453508",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Towards Practical Deterministic Parallel Languages",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2015-02-15",
 "awd_exp_date": "2020-01-31",
 "tot_intn_awd_amt": 535043.0,
 "awd_amount": 535043.0,
 "awd_min_amd_letter_date": "2015-02-02",
 "awd_max_amd_letter_date": "2019-05-10",
 "awd_abstract_narration": "Title: CAREER: Towards Practical Deterministic Parallel Languages\r\n\r\nParallel, multicore processors have become ubiquitous, but parallel programming has not. This gap implies that many everyday programs do not fully use the hardware on which they run. The problem persists because traditional parallel programming approaches are high-risk: a parallel program can yield inconsistent answers, or even crash, due to unpredictable interactions between simultaneous tasks.  Certain classes of programs, however, admit strong mathematical guarantees that they will behave the same in spite of parallel execution. That is, they enable deterministic parallel programming. Functional programming, extended with \"LVars\" --shared-state data structures that support commutating operations-- is one such model. While this theoretical model has been proven deterministic, significant questions remain regarding practical aspects such as efficiency and scalability. This research addresses those questions by developing new LVar data structures and scaling them to larger distributed memory machines. The intellectual merits are in the development of novel algorithms that support parallel programming. Further, the LVar model provides a new lens through which to view problems in parallel programming, which can lead to downstream discoveries. The project's broader significance and importance are (1) its potential to lower the cost and risk of parallel programming and (2) its educational goal: to employ deterministic parallel programming in the introductory programming course at both a university level, and in K-12 education. Changing how programming is taught may be necessary for leveraging hardware parallelism to become a normal and unexceptional part of writing software.\r\n\r\nThree specific technical challenges are addressed in this research. First, LVars traditionally require more storage space over time, because \"delete\" operations do not commute with others. Semantically, the state-space of each LVar forms a join semi-lattice and all modifications must move the state \"upwards\" monotonically. Nevertheless, this project investigates new ways that LVars can free memory, using a concept of Saturating LVars. Second, this research seeks to formalize the relationship of LVar-based parallel programs to their purely functional counterparts, characterizing asymptotic performance advantages. Finally, this project explores the scalability of LVar-based programming abstractions in a distributed memory setting, where they share similarities with recent distributed programming constructs such as concurrent replicated data structures.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ryan",
   "pi_last_name": "Newton",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Ryan R Newton",
   "pi_email_addr": "rrnewton@purdue.edu",
   "nsf_id": "000596232",
   "pi_start_date": "2015-02-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Indiana University",
  "inst_street_address": "107 S INDIANA AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BLOOMINGTON",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "3172783473",
  "inst_zip_code": "474057000",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IN09",
  "org_lgl_bus_name": "TRUSTEES OF INDIANA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "YH86RTW2YVJ4"
 },
 "perf_inst": {
  "perf_inst_name": "Indiana University, School of Computing and Informatics",
  "perf_str_addr": "150 S Woodlawn",
  "perf_city_name": "Bloomington",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "474057104",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IN09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 199057.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 243624.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 92362.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Parallelism allows software to run faster, especially on future hardware. This project sought to make parallel programming more widespread by making it safer.&nbsp; If parallelism is time consuming and risks introducing bugs, then we will continue to see it only applied in select circumstances, rather than all software. This project refined and explored a particular form of safe parallel programming, based on lattice-variables (LVars).&nbsp; These store information, shared between different threads of control in the program, but in a manner that is nondestructive.&nbsp; Different parts of the program collaboratively <em>add information</em>, but do not destroy it.&nbsp; LVars are specially constrained so that all the interactions through them, while unpredictably ordered, come out the same in the end, yielding reproducible, deterministic program results.<br /><br />In a series of publications, we explored the limits of the LVars model, for example extending them to release memory in an unintuitive contrast to the \"adding information\" description above (PPoPP'16).&nbsp; We improved the implementation of LVars and tested their scalability limits.&nbsp; For example, we explored <em>adaptive</em> versions of LVar implementations (ICFP'15), which conform their implementation to the workload they observe at runtime.&nbsp; We performed research further enhancing the safety of LVar implementations by formally verifying mathematical properties of these datatypes (POPL'18, Haskell'19).<br /><br />This research then forked off in three directions, leading to follow-on work.&nbsp; First, the verification effort became a broader approach for combining formal methods and parallelism (NSF award #1909862). Second, the effort to derive a practical, system-level implementation of LVars turned into a broader effort to build an efficient compiler and runtime for functional programs (i.e. the Gibbon compiler, and NSF award #1725679).&nbsp; Third, the effort to accomplish deterministic parallelism with LVars turned into a broader effort to dynamically enforce deterministic parallelism (OOPSLA'17, ASPLOS'20, and a successful startup company).</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/22/2020<br>\n\t\t\t\t\tModified by: Ryan&nbsp;R&nbsp;Newton</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nParallelism allows software to run faster, especially on future hardware. This project sought to make parallel programming more widespread by making it safer.  If parallelism is time consuming and risks introducing bugs, then we will continue to see it only applied in select circumstances, rather than all software. This project refined and explored a particular form of safe parallel programming, based on lattice-variables (LVars).  These store information, shared between different threads of control in the program, but in a manner that is nondestructive.  Different parts of the program collaboratively add information, but do not destroy it.  LVars are specially constrained so that all the interactions through them, while unpredictably ordered, come out the same in the end, yielding reproducible, deterministic program results.\n\nIn a series of publications, we explored the limits of the LVars model, for example extending them to release memory in an unintuitive contrast to the \"adding information\" description above (PPoPP'16).  We improved the implementation of LVars and tested their scalability limits.  For example, we explored adaptive versions of LVar implementations (ICFP'15), which conform their implementation to the workload they observe at runtime.  We performed research further enhancing the safety of LVar implementations by formally verifying mathematical properties of these datatypes (POPL'18, Haskell'19).\n\nThis research then forked off in three directions, leading to follow-on work.  First, the verification effort became a broader approach for combining formal methods and parallelism (NSF award #1909862). Second, the effort to derive a practical, system-level implementation of LVars turned into a broader effort to build an efficient compiler and runtime for functional programs (i.e. the Gibbon compiler, and NSF award #1725679).  Third, the effort to accomplish deterministic parallelism with LVars turned into a broader effort to dynamically enforce deterministic parallelism (OOPSLA'17, ASPLOS'20, and a successful startup company).\n\n\t\t\t\t\tLast Modified: 11/22/2020\n\n\t\t\t\t\tSubmitted by: Ryan R Newton"
 }
}