{
 "awd_id": "1550397",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Volition Based Anticipatory Control for Time-Critical Brain-Prosthetic Interaction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2015-08-15",
 "awd_exp_date": "2017-07-31",
 "tot_intn_awd_amt": 178761.0,
 "awd_amount": 178761.0,
 "awd_min_amd_letter_date": "2015-08-05",
 "awd_max_amd_letter_date": "2015-08-05",
 "awd_abstract_narration": "This exploratory project focuses on developing algorithms that will allow the PI's previously implemented prototype drumming prosthesis, which was developed in an effort to help an injured teen, to anticipate human physical actions based on an analysis of EEG signals so that it can respond mechanically in a timely manner.  The goal is to enable the enhanced prosthesis to detect volition, the cognitive process by which an individual decides on and commits to a particular course of action hundreds of milliseconds before the action actually takes place, in order to foresee the drummer's actions and achieve sub-second synchronization between artificial and biological limbs, thereby leading to improved performance in a time-sensitive domain where asynchronous operations of more than a few milliseconds are noticeable by listeners.  Project outcomes will include cognitive models and technical approaches that will be of great value for improving efficiency and fluency in a wide range of human-robot and human-prosthesis interaction scenarios, from construction tasks where humans and robots collaborate to achieve common goals, to time-critical tasks such as in hospital operating rooms or space stations where humans operate artificial robotic limbs.  The work will also lead to creation of a volition trials database that will be documented and shared with the broad community of brain scholars and brain-machine interface researches.  And the project will have additional broad impact by supporting students in the Robotic Musicianship group at Georgia Tech as it transitions from its previous focus on robotic musicianship into the fields of prosthetic and human augmentation.\r\n\r\nPrior studies of volition have shown that across multiple repetitions of (real or imagined) motor activity one can derive the Event-Related-Potential (ERP) associated with the intent to move the hand, up to a few seconds prior to the generation of the movement.  Additionally, studies of mirror neurons have shown that observing a motor activity can trigger sets of cells in the brain that replicate the activity depicted when a subject is engaged in the action itself.  In this project the PI will build on such findings to develop new pattern recognition algorithms for EEG signal analysis in an effort to identify volition and design new anticipatory algorithms for brain-machine interfaces that reduce latency and allow for synchronization at the millisecond level.  The work will be carried out in stages.  The PI will first collect EEG data from a large number of experimental trials where participants are engaged in a voluntary motor action.  The data will be studied to detect patterns indicative of volition activity from electrodes monitoring both the motor and pre-motor cortices (SMA and pre-SMA), and also to isolate the neural correlates of imagined vs. real movement.  A variety of general purpose machine learning classifiers, as well as music focused feature extraction techniques, will be used to distinguish between anticipatory patterns of activity preluding an action (volition) and patterns generated when the action is indeed manifested.  As part of the analysis the PI will attempt to acquire an understanding of the delta times between volition and action under different conditions, and he will develop a repeatability / reliability matrix to be utilized for synchronization in the next stage of the work, in which the PI will develop a \"latency compensation engine\" that generates robotic drum hits at the exact anticipated action time, compensating for mechanical latencies while taking into account the projected delta time between volition and action.  Multi-modal integration with data from other sensors (EMG, microphones, proximity, etc.) will be exploited to correct errors is detection and classification.  Finally, success of the new algorithms will be evaluated using both objective and subjective measures by having the amputee drummer perform a series of musical tasks with the robotic arm.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gil",
   "pi_last_name": "Weinberg",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gil Weinberg",
   "pi_email_addr": "gil.weinberg@coa.gatech.edu",
   "nsf_id": "000105700",
   "pi_start_date": "2015-08-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Ave",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 178761.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">We developed a robotic drumming prostheses that can anticipate and respond to human actions based on analysis of bio and environmental sensors, enabling unprecedented levels of fluency and synchronization in Human-Prosthesis Interaction. The semi-autonomous robotic arm allows drummers not only to obtain the musical skills of abled-bodied musicians, but also to push the boundaries of expressive and improvisatory music making. As part of the project, we embedded new sensors and developed new algorithms for a robotic drumming prosthesis as well as new general-purpose robotic prosthetic arm designed for a wide range of upper extremity amputation types as well as a third arm for able bodied musicians. To facilitate and evaluate the time sensitive operations of the prostheses we utilized the medium of music &ndash; one of the most time-demanding media where millisecond level accuracy is of importance and asynchronous operations of more than a few milliseconds are noticeable to listeners.</p>\n<p class=\"p1\">The project explored how a shared control paradigm between a human drummer and wearable robotic third arm can influence and potentially enhance performance. The wearable system allowed us to examine interaction beyond the visual and auditory that is explored in non-wearable robotic systems. The primary research challenges addressed focused on design and usability. This included developing a prototype that allows for comfort and robust functionality and designing functions that increase the autonomy of the robot and decrease cognitive load for the human.</p>\n<p class=\"p1\">The intellectual merit of the project focused on fundamental contributions to knowledge in Human-wearable Robotic Interaction (HRI), Brain-Machine Interface (BMI), Robotic Musical Expression (RME), and Robotic Improvisation (RI). &nbsp;By advancing and integrating research in these disciplines, the project helped shed light on the mostly uncharted territory of human interaction with robotic body augmentation. The project explored novel technical and design approaches for robotic prosthetics and studied the social and psychological effects of synchronization and fluency with semi-autonomous wearable robotics. The project also pushed the state-of-the-art of algorithmic robotic improvisation and robotic musical expression by creating new corpi of human generated rhythms, leading to the development of novel models for timbre control and rhythmic improvisation. These new capabilities can allow amputees and able-bodied musicians to push the boundaries of their expressive and creative musical skills.</p>\n<p class=\"p1\">The cognitive models and technical approaches that were developed for the robotic drumming prostheses can be useful for improving efficiency and fluency in a wide range of human-robot and human-prosthesis interaction scenarios: from joint construction tasks, where humans and robots collaborate to achieve common goals, to artificial limb control, where humans operate artificial robotic limbs in time-demanding tasks. Interaction design schemes that were developed and user studies that will be conducted as part of the project will be valuable to the general HRI and HCI research community. Our proposed work on EEG driven body augmentation will lead to a large trial database that will be shared with the large community of brain and BMI researchers. For music researchers, the analyzed corpi of transcribed improvisation and drumming expression techniques can serve as a reference tool for future research in human and artificial musicianship. Building on the engaging power of music, the project also helped bring HRI to the general public through workshops and high visibility concerts and media appearances, aimed at capturing the interest and imagination of students who are not regularly drawn to music, math, sciences, and engineering. And lastly, the project also served as a pivotal point for the new BS program in Music Technology at the Georgia Tech Center for Music Technology, allowing undergraduate students to engage in creative interdisciplinary research.</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/16/2017<br>\n\t\t\t\t\tModified by: Gil&nbsp;Weinberg</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1550397/1550397_10383780_1510868422674_robotarm--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1550397/1550397_10383780_1510868422674_robotarm--rgov-800width.jpg\" title=\"EEG controlled &quot;Third Arm&quot;\"><img src=\"/por/images/Reports/POR/2017/1550397/1550397_10383780_1510868422674_robotarm--rgov-66x44.jpg\" alt=\"EEG controlled &quot;Third Arm&quot;\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A drummer controls a wearable drumming arm with an EEG headband</div>\n<div class=\"imageCredit\">Georgia Tech</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Gil&nbsp;Weinberg</div>\n<div class=\"imageTitle\">EEG controlled \"Third Arm\"</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "We developed a robotic drumming prostheses that can anticipate and respond to human actions based on analysis of bio and environmental sensors, enabling unprecedented levels of fluency and synchronization in Human-Prosthesis Interaction. The semi-autonomous robotic arm allows drummers not only to obtain the musical skills of abled-bodied musicians, but also to push the boundaries of expressive and improvisatory music making. As part of the project, we embedded new sensors and developed new algorithms for a robotic drumming prosthesis as well as new general-purpose robotic prosthetic arm designed for a wide range of upper extremity amputation types as well as a third arm for able bodied musicians. To facilitate and evaluate the time sensitive operations of the prostheses we utilized the medium of music &ndash; one of the most time-demanding media where millisecond level accuracy is of importance and asynchronous operations of more than a few milliseconds are noticeable to listeners.\nThe project explored how a shared control paradigm between a human drummer and wearable robotic third arm can influence and potentially enhance performance. The wearable system allowed us to examine interaction beyond the visual and auditory that is explored in non-wearable robotic systems. The primary research challenges addressed focused on design and usability. This included developing a prototype that allows for comfort and robust functionality and designing functions that increase the autonomy of the robot and decrease cognitive load for the human.\nThe intellectual merit of the project focused on fundamental contributions to knowledge in Human-wearable Robotic Interaction (HRI), Brain-Machine Interface (BMI), Robotic Musical Expression (RME), and Robotic Improvisation (RI).  By advancing and integrating research in these disciplines, the project helped shed light on the mostly uncharted territory of human interaction with robotic body augmentation. The project explored novel technical and design approaches for robotic prosthetics and studied the social and psychological effects of synchronization and fluency with semi-autonomous wearable robotics. The project also pushed the state-of-the-art of algorithmic robotic improvisation and robotic musical expression by creating new corpi of human generated rhythms, leading to the development of novel models for timbre control and rhythmic improvisation. These new capabilities can allow amputees and able-bodied musicians to push the boundaries of their expressive and creative musical skills.\nThe cognitive models and technical approaches that were developed for the robotic drumming prostheses can be useful for improving efficiency and fluency in a wide range of human-robot and human-prosthesis interaction scenarios: from joint construction tasks, where humans and robots collaborate to achieve common goals, to artificial limb control, where humans operate artificial robotic limbs in time-demanding tasks. Interaction design schemes that were developed and user studies that will be conducted as part of the project will be valuable to the general HRI and HCI research community. Our proposed work on EEG driven body augmentation will lead to a large trial database that will be shared with the large community of brain and BMI researchers. For music researchers, the analyzed corpi of transcribed improvisation and drumming expression techniques can serve as a reference tool for future research in human and artificial musicianship. Building on the engaging power of music, the project also helped bring HRI to the general public through workshops and high visibility concerts and media appearances, aimed at capturing the interest and imagination of students who are not regularly drawn to music, math, sciences, and engineering. And lastly, the project also served as a pivotal point for the new BS program in Music Technology at the Georgia Tech Center for Music Technology, allowing undergraduate students to engage in creative interdisciplinary research.\n \n \n \n\n \n\n\t\t\t\t\tLast Modified: 11/16/2017\n\n\t\t\t\t\tSubmitted by: Gil Weinberg"
 }
}