{
 "awd_id": "1514437",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC: TTP Option: Medium: Scalable Web Transparency: New Scientific Building Blocks, Tools, and Measurements to Tame the Data-Driven Web",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rob Beverly",
 "awd_eff_date": "2015-08-01",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 1588998.0,
 "awd_amount": 1588998.0,
 "awd_min_amd_letter_date": "2015-07-23",
 "awd_max_amd_letter_date": "2015-07-23",
 "awd_abstract_narration": "With the advent of \"big data,\" the Web has become a highly potent and opaque place which, left unchecked, can breed data misuse and unfair practices toward individuals. Today's Web services accumulate staggering amounts of personal data, such as emails, searches, and activity logs. They are mined for business value, retained for extended periods of time, and at times shared with third parties -- all without individuals' knowledge or explicit consent. Are these uses good or bad for individuals? Do they match a service's privacy policy? How long is data used after deletion? Who shares data with whom?  Presently, there is little insight into these questions.  This project creates a set of building blocks to track different types of individual data (e.g., keywords used in searches, previous sites visited) and measure multiple types of use (e.g., targeted advertising).  These are used to develop robust and scalable tools for tracking data to uncover misuse.\r\n\r\nOur project seeks to increase the data-driven Web's transparency by developing both the tools and the scientific foundations for tracking the data's journey on the web. We make contributions on three fronts.  First, we design a set of building blocks, highly reusable and scalable components that facilitate the building of a new generation of auditing tools to lift the curtain on how personal data is being used.  Second, we build a set of robust and scalable transparency tools that instantiate those building blocks and enable users, journalists, and investigators to obtain visibility into Web services' data uses. We are actively seeking out deployments through collaborations with journalists and investigators.  Third, we leverage these tools to run extensive measurement studies of various data-driven platforms, such as targeted advertising ecosystems, data brokers, and online price discrimination. These studies increase awareness, and help uncover examples of data mistreatment, which we hope will provide the grounds for an informed societal argument on the need for increased voluntary transparency on the Web.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Roxana",
   "pi_last_name": "Geambasu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Roxana Geambasu",
   "pi_email_addr": "roxana@cs.columbia.edu",
   "nsf_id": "000602293",
   "pi_start_date": "2015-07-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Augustin",
   "pi_last_name": "Chaintreau",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Augustin Chaintreau",
   "pi_email_addr": "ac3318@columbia.edu",
   "nsf_id": "000575992",
   "pi_start_date": "2015-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "1214 Amsterdam Ave",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100277690",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 1588998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project involves efforts in three major inter-related directions: (1) fundamental research, (2) transition to practice, and (3) education and outreach activities.</p>\n<p><br />[Fundamental Research]<br />With the advent of \"big data,\" the Web has become a highly potent and opaque place which, left unchecked, can breed data misuse and unfair practices toward individuals. Today's Web services accumulate staggering amounts of personal data, such as emails, searches, and activity logs. They are mined for business value, retained for extended periods of time, and at times shared with third parties -- all without individuals' knowledge or explicit consent. Are these uses good or bad for individuals? Do they match a service's privacy policy? How long is data used after deletion? Who shares data with whom? Presently, there is little insight into these questions. This project creates a set of building blocks to track different types of individual data (e.g., keywords used in searches, previously visited sites) and measure multiple types of use (e.g., targeted advertising, personalized contents). These are used to develop robust and scalable tools for tracking data to uncover misuse.</p>\n<p><br />Our project makes scientific contributions on three fronts. First, we design a set of building blocks, highly reusable and scalable components that facilitate the building of a new generation of auditing tools to lift the curtain on how personal data is being used. Second, we build a set of robust and scalable transparency tools that instantiate those building blocks and enable users, journalists, investigators, and the developers themselves to obtain visibility into web services' data uses. We are actively seeking out deployments through collaborations with journalists and investigators. Third, we leverage these tools to run extensive measurement studies of various data-driven platforms, such as targeted advertising ecosystems, data brokers, and online price discrimination. These studies increase awareness, and help uncover examples of data mistreatment, which we hope will provide the grounds for an informed societal argument on the need for increased voluntary transparency on the Web.</p>\n<p><br />[Transition to Practice]<br />This project includes a transition to practice option. The goal is to place the transparency tools we develop into the hands of privacy watchdogs, consumer protection agencies, and investigative journalists. Additionally, we believe that it is important to not only empower privacy watchdogs with external auditing tools, but also to empower developers themselves with the ability to reason about their own data-driven applications and the implications of their use of personal data on their user population. This projects helped experts in other disciplines (psychology, journalism and communication) as well as practitioners (mental self-assessment app developer, fact checkers) with tools informing when and how bias from data-driven decision may affect their workflow.</p>\n<p><br />[Education and Diversity Outreach]<br />Our project seeks to develop a new educational agenda for \"responsible\" big-data (some call it ethics of big data). Our agenda entails teaching our students how to manage data carefully to limit its exposure to attack, and how to use it in ways that are transparent and fair to their users. Moreover, a central goal in our project is to increase diversity within the CS field. We develop hands-on coding workshops and discuss our experience to expose young women and under-priviledged students to the CS field and our privacy-related research. The project also supported the organization of a 3 week summer school allowing 20 high school students from STEM-under-represented groups (95% student of colors, 45% Black or African American, 30% Latino and 50% female). In addition to the young learners of that program, Ph.D student and undergraduate students from 3 universities, played the role of instructors had a unique opportunity to learn how to teach and lead student group.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/15/2020<br>\n\t\t\t\t\tModified by: Roxana&nbsp;Geambasu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project involves efforts in three major inter-related directions: (1) fundamental research, (2) transition to practice, and (3) education and outreach activities.\n\n\n[Fundamental Research]\nWith the advent of \"big data,\" the Web has become a highly potent and opaque place which, left unchecked, can breed data misuse and unfair practices toward individuals. Today's Web services accumulate staggering amounts of personal data, such as emails, searches, and activity logs. They are mined for business value, retained for extended periods of time, and at times shared with third parties -- all without individuals' knowledge or explicit consent. Are these uses good or bad for individuals? Do they match a service's privacy policy? How long is data used after deletion? Who shares data with whom? Presently, there is little insight into these questions. This project creates a set of building blocks to track different types of individual data (e.g., keywords used in searches, previously visited sites) and measure multiple types of use (e.g., targeted advertising, personalized contents). These are used to develop robust and scalable tools for tracking data to uncover misuse.\n\n\nOur project makes scientific contributions on three fronts. First, we design a set of building blocks, highly reusable and scalable components that facilitate the building of a new generation of auditing tools to lift the curtain on how personal data is being used. Second, we build a set of robust and scalable transparency tools that instantiate those building blocks and enable users, journalists, investigators, and the developers themselves to obtain visibility into web services' data uses. We are actively seeking out deployments through collaborations with journalists and investigators. Third, we leverage these tools to run extensive measurement studies of various data-driven platforms, such as targeted advertising ecosystems, data brokers, and online price discrimination. These studies increase awareness, and help uncover examples of data mistreatment, which we hope will provide the grounds for an informed societal argument on the need for increased voluntary transparency on the Web.\n\n\n[Transition to Practice]\nThis project includes a transition to practice option. The goal is to place the transparency tools we develop into the hands of privacy watchdogs, consumer protection agencies, and investigative journalists. Additionally, we believe that it is important to not only empower privacy watchdogs with external auditing tools, but also to empower developers themselves with the ability to reason about their own data-driven applications and the implications of their use of personal data on their user population. This projects helped experts in other disciplines (psychology, journalism and communication) as well as practitioners (mental self-assessment app developer, fact checkers) with tools informing when and how bias from data-driven decision may affect their workflow.\n\n\n[Education and Diversity Outreach]\nOur project seeks to develop a new educational agenda for \"responsible\" big-data (some call it ethics of big data). Our agenda entails teaching our students how to manage data carefully to limit its exposure to attack, and how to use it in ways that are transparent and fair to their users. Moreover, a central goal in our project is to increase diversity within the CS field. We develop hands-on coding workshops and discuss our experience to expose young women and under-priviledged students to the CS field and our privacy-related research. The project also supported the organization of a 3 week summer school allowing 20 high school students from STEM-under-represented groups (95% student of colors, 45% Black or African American, 30% Latino and 50% female). In addition to the young learners of that program, Ph.D student and undergraduate students from 3 universities, played the role of instructors had a unique opportunity to learn how to teach and lead student group. \n\n\t\t\t\t\tLast Modified: 11/15/2020\n\n\t\t\t\t\tSubmitted by: Roxana Geambasu"
 }
}