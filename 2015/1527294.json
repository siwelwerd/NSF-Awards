{
 "awd_id": "1527294",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Small: Learning to Eliminate Heuristics in Stereo Vision",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 432031.0,
 "awd_amount": 432031.0,
 "awd_min_amd_letter_date": "2015-08-24",
 "awd_max_amd_letter_date": "2016-05-16",
 "awd_abstract_narration": "This project develops technologies to improve stereo and multi-view stereo algorithms by removing heuristics and hand-tuning using machine learning techniques. Stereo matching is the process of estimating depth of points, or 3D coordinates in a scene, and is enabled by the estimation of correspondences between pixels or other primitives in two or more images. Even the most successful current stereo matching algorithms, however, use a large number of heuristics. The developed methods from this project eliminate the heuristics from binocular and multi-view stereo matching and deliver algorithms with higher accuracy, interpretability of the results and higher portability to different settings. Stereo vision plays an important role in many applications, such as 3D modeling, augmented reality, driver assistance, autonomous navigation and human computer interaction. The educational and outreach aspects of the project focus on involving K-12 and undergraduate students in STEM education and research. \r\n\r\nThis research addresses stereo vision by training classifiers that learn from pairs, or larger sets of images, with ground truth depth to make more accurate predictions about unobserved data than those obtained by hand-crafted rules. The approach is comprehensive and tackles all stages of the binocular stereo matching process, including the matching cost function, cost aggregation, optimization and refinement. Representations for multi-view stereo based on surface patches, depth maps or occupancy grids and the corresponding algorithms are also supported by the same framework. Random forest classifiers are well suited for use in inhomogeneous feature spaces and classifier calibration can ensure that their outputs are close to the true posterior probabilities of the classes under consideration. The resulting algorithms and findings can be transferred to other computer vision problems that require pixel correspondences, such as optical flow estimation, image stitching and template matching.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Philippos",
   "pi_last_name": "Mordohai",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Philippos Mordohai",
   "pi_email_addr": "Philippos.Mordohai@stevens.edu",
   "nsf_id": "000512790",
   "pi_start_date": "2015-08-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stevens Institute of Technology",
  "inst_street_address": "ONE CASTLE POINT ON HUDSON",
  "inst_street_address_2": "",
  "inst_city_name": "HOBOKEN",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "2012168762",
  "inst_zip_code": "070305906",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "NJ08",
  "org_lgl_bus_name": "THE TRUSTEES OF THE STEVENS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJ6CN5Y5A2R5"
 },
 "perf_inst": {
  "perf_inst_name": "Stevens Institute of Technology",
  "perf_str_addr": "Castle Point on Hudson",
  "perf_city_name": "Hoboken",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "070305991",
  "perf_ctry_code": "US",
  "perf_cong_dist": "08",
  "perf_st_cong_dist": "NJ08",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 232188.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 199843.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In the duration of this project, there was a paradigm shift in research on computational stereo vision with conventional, hand-crafted approaches being replaced by data-driven approached trained on large datasets with ground truth. The goal of computational stereo vision is 3D reconstruction from two or more 2D images acquired by cameras with known poses, and the key problem to be solved is the estimation of correspondences between pixels or other image primitives. This award supported research aiming to eliminate heuristics and hand-tuning from algorithms for binocular and multi-view stereo matching. Initial efforts were part of the transition to learning-based stereo vision, while subsequently the focus shifted towards effective ways to synthesize conventional and learning-based methods.</p>\n<p>Important findings include algorithms for estimating the confidence of detected pixel correspondences and for using confidence to improve depth estimation and to select among multiple hypotheses. A learning-based matching cost estimation algorithm, which can be used as a component of a conventional pipeline, as well as several end-to-end stereo matching networks were published. They all achieved exceptional generalization performance when tested on imagery not drawn from the training data, easily surpassing state-of-the-art learning-based stereo matching systems. This is attributed to designs that do not expose the learning system to RGB appearance. In parallel, research was carried out on global surface inference from multiple images employing a representation by a set of tetrahedra. This approach also combines the strengths of geometric and learning methods.</p>\n<p>Throughout the project, several pre-college and undergraduate students were either directly involved in aspects of the above research, or more broadly engaged in STEM research. Software created during the project has been released to the research community in five open-source repositories, while the findings were presented in three tutorials at major computer vision conferences.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/08/2020<br>\n\t\t\t\t\tModified by: Philippos&nbsp;Mordohai</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1527294/1527294_10390886_1607411714820_msnet-archi-02--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1527294/1527294_10390886_1607411714820_msnet-archi-02--rgov-800width.jpg\" title=\"Genelizable end-to-end stereo matching network\"><img src=\"/por/images/Reports/POR/2020/1527294/1527294_10390886_1607411714820_msnet-archi-02--rgov-66x44.jpg\" alt=\"Genelizable end-to-end stereo matching network\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Top: conventional 3D convolutional stereo matching network where the network is trained directly on RGB data. Bottom: proposed Matching Space Network where training takes place on outputs of matching and confidence functions, isolating the network from RGB data.</div>\n<div class=\"imageCredit\">[Changjiang Cai]</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Philippos&nbsp;Mordohai</div>\n<div class=\"imageTitle\">Genelizable end-to-end stereo matching network</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1527294/1527294_10390886_1607411618623_cbmv--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1527294/1527294_10390886_1607411618623_cbmv--rgov-800width.jpg\" title=\"Generalization using CBMV matching score.\"><img src=\"/por/images/Reports/POR/2020/1527294/1527294_10390886_1607411618623_cbmv--rgov-66x44.jpg\" alt=\"Generalization using CBMV matching score.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Disparity and error maps for a stereo pair from the Middlebury 2014 benchmark using CBMV trained on data from the Middlebury, KITTI 2012 and KITTI 2015 benchmarks (left to right). Error rates are stable regardless of the training set.</div>\n<div class=\"imageCredit\">[Konstantinos Batsos]</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Philippos&nbsp;Mordohai</div>\n<div class=\"imageTitle\">Generalization using CBMV matching score.</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1527294/1527294_10390886_1607411284781_ensemble--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1527294/1527294_10390886_1607411284781_ensemble--rgov-800width.jpg\" title=\"Stereo matcher selection\"><img src=\"/por/images/Reports/POR/2020/1527294/1527294_10390886_1607411284781_ensemble--rgov-66x44.jpg\" alt=\"Stereo matcher selection\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An input frame and a visualization showing pixels colored according to the matcher that was selected for them based on the estimated confidence.</div>\n<div class=\"imageCredit\">[Aristotle Spyropoulos]</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Philippos&nbsp;Mordohai</div>\n<div class=\"imageTitle\">Stereo matcher selection</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nIn the duration of this project, there was a paradigm shift in research on computational stereo vision with conventional, hand-crafted approaches being replaced by data-driven approached trained on large datasets with ground truth. The goal of computational stereo vision is 3D reconstruction from two or more 2D images acquired by cameras with known poses, and the key problem to be solved is the estimation of correspondences between pixels or other image primitives. This award supported research aiming to eliminate heuristics and hand-tuning from algorithms for binocular and multi-view stereo matching. Initial efforts were part of the transition to learning-based stereo vision, while subsequently the focus shifted towards effective ways to synthesize conventional and learning-based methods.\n\nImportant findings include algorithms for estimating the confidence of detected pixel correspondences and for using confidence to improve depth estimation and to select among multiple hypotheses. A learning-based matching cost estimation algorithm, which can be used as a component of a conventional pipeline, as well as several end-to-end stereo matching networks were published. They all achieved exceptional generalization performance when tested on imagery not drawn from the training data, easily surpassing state-of-the-art learning-based stereo matching systems. This is attributed to designs that do not expose the learning system to RGB appearance. In parallel, research was carried out on global surface inference from multiple images employing a representation by a set of tetrahedra. This approach also combines the strengths of geometric and learning methods.\n\nThroughout the project, several pre-college and undergraduate students were either directly involved in aspects of the above research, or more broadly engaged in STEM research. Software created during the project has been released to the research community in five open-source repositories, while the findings were presented in three tutorials at major computer vision conferences.\n\n \n\n\t\t\t\t\tLast Modified: 12/08/2020\n\n\t\t\t\t\tSubmitted by: Philippos Mordohai"
 }
}