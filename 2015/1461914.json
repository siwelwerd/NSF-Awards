{
 "awd_id": "1461914",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BDD: Efficient and Scalable Collection, Analytics and Processing of Big Data for Disaster Applications",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2015-04-01",
 "awd_exp_date": "2020-09-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 346632.0,
 "awd_min_amd_letter_date": "2015-03-25",
 "awd_max_amd_letter_date": "2020-03-18",
 "awd_abstract_narration": "The outcomes from this project is to assist human operators in their disaster management coordination and planning, such as directing a medical physician's team to their nearest cluster of affected people in a region to administer medications as necessary, or finding a safe route for evacuation of affected people. Sensor data integrated with microblogs such as Tweets help identifying some local events and people's sentiments, which are significantly useful in handling/understanding disaster situations. It will also benefit other applications such as real-time tracking of road/driving conditions in vehicular networks.\r\n\r\nThis research is conducted jointly with Osaka University in Japan, to benefit both the universities in enhancing not only their knowledge but also to learn global perspective in solving important problems. The research team is designing schemes for dynamic and collaborative data compression and multi-streams compression of multi-dimensional sensor data with error correction and recovery for addressing the energy efficiency and bandwidth limitation issues. Compression schemes exploit temporal locality and delta compression to provide better bandwidth utilization. Different methods for measuring error are designed and compared for the compressibility and actual error for variations in methods of utilizing the error tolerance. In addition, the team is developing algorithms for highly scalable indexing schemes for efficient data retrieval involving mainly range queries, top-k query, ranked-based searches and snapshot queries for multi-dimensional sensor data from different data sources to address the issue of timely dissemination. Hilbert Curve based linearization technique integrated with an overlay network is designed to (1) map multidimensional attributes onto a single dimension while preserving its data locality, and (2) to create a balanced network by associating only one node with each leaf of the virtual tree and then partition the multidimensional search space into subspaces and assign each node to a unique subspace. This allows an overlay network to start from a predefined prefix to handle data skewness. This research is also designing a scheme for using microblog messages as social sensors for efficient integration with other sensor data. We are using machine-learning techniques to match each message with its associate location based on the characteristics of the message. The results will be validated and evaluated using the sensor cloud test-bed available at Missouri S&T.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanjay",
   "pi_last_name": "Madria",
   "pi_mid_init": "k",
   "pi_sufx_name": "",
   "pi_full_name": "Sanjay k Madria",
   "pi_email_addr": "madrias@mst.edu",
   "nsf_id": "000289664",
   "pi_start_date": "2015-03-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Missouri University of Science and Technology",
  "inst_street_address": "300 W. 12TH STREET",
  "inst_street_address_2": "202 CENTENNIAL HALL",
  "inst_city_name": "ROLLA",
  "inst_state_code": "MO",
  "inst_state_name": "Missouri",
  "inst_phone_num": "5733414134",
  "inst_zip_code": "654091330",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "MO08",
  "org_lgl_bus_name": "UNIVERSITY OF MISSOURI SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "Y6MGH342N169"
 },
 "perf_inst": {
  "perf_inst_name": "Missouri University of Science and Technology",
  "perf_str_addr": "500 W. 15th St.",
  "perf_city_name": "Rolla",
  "perf_st_code": "MO",
  "perf_st_name": "Missouri",
  "perf_zip_code": "654096506",
  "perf_ctry_code": "US",
  "perf_cong_dist": "08",
  "perf_st_cong_dist": "MO08",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "022Z",
   "pgm_ref_txt": "International Partnerships"
  },
  {
   "pgm_ref_code": "5921",
   "pgm_ref_txt": "JAPAN"
  },
  {
   "pgm_ref_code": "7363",
   "pgm_ref_txt": "RES IN NETWORKING TECH & SYS"
  },
  {
   "pgm_ref_code": "8230",
   "pgm_ref_txt": "Big Data and Disasters"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 316000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 14632.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research is on the design of energy- and bandwidth-efficient schemes for &#65279;information acquisition and machine learning for situation awareness for disaster management and evacuation of people affected by the disaster. Every activity in disaster management demands accurate and up-to-date information to allow a quick, easy, and cost-effective response to reduce the possible loss of lives and properties.&nbsp;It is a challenging and complex task to acquire information from different regions of a disaster-affected area in a timely fashion.&nbsp;Thus, this research has resulted into several algorithms for (1) dynamic collaborative data compression and multi-streams compression of multi-dimensional sensor data for identifying the situation on ground such as chemical-leaks, (2) highly scalable indexing schemes for efficient data storage and processing for efficient query processing, (3) an efficient data collection scheme that only gathers the necessary data from IoT devices like wireless sensors along a trajectory for disaster management &nbsp;services based on geospatial constraints, and &#65279;(4) developing machine learning models using social media data such as tweets &#65279;for better situational awareness and classifying automatically these tweets into FEMA defined help-seeking categories of DECW (Disabled, Elderly, Child, Women), water needed, sick and injured for prioritized evacuation, and &#65279;designing a hybrid rescue scheduling algorithm by extracting and estimating the locations of classified tweets for stranded people for evacuation, and integrating the resources available for organizing rescue missions.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/29/2021<br>\n\t\t\t\t\tModified by: Sanjay&nbsp;K&nbsp;Madria</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis research is on the design of energy- and bandwidth-efficient schemes for &#65279;information acquisition and machine learning for situation awareness for disaster management and evacuation of people affected by the disaster. Every activity in disaster management demands accurate and up-to-date information to allow a quick, easy, and cost-effective response to reduce the possible loss of lives and properties. It is a challenging and complex task to acquire information from different regions of a disaster-affected area in a timely fashion. Thus, this research has resulted into several algorithms for (1) dynamic collaborative data compression and multi-streams compression of multi-dimensional sensor data for identifying the situation on ground such as chemical-leaks, (2) highly scalable indexing schemes for efficient data storage and processing for efficient query processing, (3) an efficient data collection scheme that only gathers the necessary data from IoT devices like wireless sensors along a trajectory for disaster management  services based on geospatial constraints, and &#65279;(4) developing machine learning models using social media data such as tweets &#65279;for better situational awareness and classifying automatically these tweets into FEMA defined help-seeking categories of DECW (Disabled, Elderly, Child, Women), water needed, sick and injured for prioritized evacuation, and &#65279;designing a hybrid rescue scheduling algorithm by extracting and estimating the locations of classified tweets for stranded people for evacuation, and integrating the resources available for organizing rescue missions.\n\n \n\n\t\t\t\t\tLast Modified: 01/29/2021\n\n\t\t\t\t\tSubmitted by: Sanjay K Madria"
 }
}