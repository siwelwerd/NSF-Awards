{
 "awd_id": "1535755",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AitF: EXPL: Data Management in Domain Wall Memory-based Scratchpad for High Performance Mobile Devices",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 399910.0,
 "awd_amount": 399910.0,
 "awd_min_amd_letter_date": "2015-08-18",
 "awd_max_amd_letter_date": "2021-04-26",
 "awd_abstract_narration": "To achieve scalable performance improvement in mobile devices such as smart phones, it is important to integrate a larger and faster memory. The major constraints on enlarging on-chip memory using traditional memory technologies are size and energy efficiency. Size is an issue because devices must inherently be small to be mobile. Energy efficiency is an issue because battery life is often the limiting factor in the usefulness of mobile devices, and the memory subsystem in mobile devices such as smart phones can consume about a third of the total energy. Because of these limitations, the amount of memory per processor in mobile devices such as smart phones has stayed relatively stable over the last few generations of technologies. The incorporation of the emerging technology of Domain Wall Memory in mobile devices is attractive as it can store more information in less volume than any competing technologies, while simultaneously using little energy, and being nearly as fast as traditional memory technologies.\r\n\r\nHowever, Domain Wall Memory has physical properties that are different than traditional memory technologies, and that can potentially impact performance. In particular, Domain Wall Memory is divided into tracks, which like a tape, may only be accessed sequentially. Thus accessing two data items stored far apart within the same track will be a costly, time-consuming operation. Thus obtaining the best possible performance of Domain Wall Memory will require algorithms/solutions that will smartly manage the placement of data items into memory so that the sequential access properties of Domain Wall Memory do not significantly degrade performance. The goal of the project is to design, analyze, test and deploy algorithms/solutions for data allocation problems that will arise with the adoption of Domain Wall Memory in mobile devices. As these data management problems have unique features, the development of algorithms for these problems will likely require the development of new algorithmic design and analysis techniques. Developing a good practical implementation of these algorithms, or implementations inspired by these algorithms, will require the development of a significant understanding of both implementation issues and common instance properties. The project will cross-train students in the area of computer architecture and algorithms. Transfer of technology to the industry will be\r\npursued through collaborations and visits.\r\n\r\nIt is promising to incorporate Domain Wall Memory as a software-controlled scratchpad memory, which has been widely adopted in embedded systems for achieving high performance and energy efficiency. For data items allocated in the same Domain Wall Memory track, accesses start with shifting the target domains below the head, which is similar to accesses to sequential access memory such as tape and hard drives. The overhead to access a data item includes both the read/write overhead and the shift overhead. While the former is constant, the latter depends heavily on how the data items are allocated within the track. Thus optimizing aggregate access time in DWM-SPM largely involves minimizing shifts. The performance of DWM-SPM will be significantly affected by the policies used for: (a) Track management: How the data items are organized/ordered within a track, (b) Data layout: How the data items are assigned to tracks, and (c) Data selection: How the data items that will be stored in DWM-SPM are selected.\r\n\r\nThe project will design and formally analyze algorithms for track management, data layout, and data selection in idealized models of Domain Wall Memory. The advantage of formal algorithmics is that the formal objective can drive the discovery of non-intuitive algorithms. Concurrent with this theoretical investigation, a simulation environment will be created to test proposed solutions to managing Domain Wall Memory. This includes the assembly of hardware modeling tools, software simulators, and a collection of benchmark programs. The project will develop and implement some simple policies to serve as a baseline to compare against, and obtain test instances representative of those that would arise in practice, and will transfer the theoretical insights into actual implementations. These implementations would then be compared to the baseline and greedy heuristic solutions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kirk",
   "pi_last_name": "Pruhs",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kirk Pruhs",
   "pi_email_addr": "kirk@cs.pitt.edu",
   "nsf_id": "000388694",
   "pi_start_date": "2015-08-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Youtao",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Youtao Zhang",
   "pi_email_addr": "zhangyt@cs.pitt.edu",
   "nsf_id": "000104863",
   "pi_start_date": "2015-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pittsburgh",
  "inst_street_address": "4200 FIFTH AVENUE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4126247400",
  "inst_zip_code": "152600001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "UNIVERSITY OF PITTSBURGH - OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "MKAGLD59JRL1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pittsburgh",
  "perf_str_addr": "123 University Club",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152132303",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723900",
   "pgm_ele_name": "Algorithms in the Field"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "013Z",
   "pgm_ref_txt": "AitF EXPL Projects"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 399910.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><br /><br /><br /><br />The goal of the project is to design, analyze, test and deploy algorithms/solutions for data allocation problems that will arise with the adoption of Domain Wall Memory in mobile devices. Conceptually Domain Wall Memory consists of several ``tapes'' with one read/write head per tape. So accessing items near the current location of the tape head is significantly more efficient in terms of the resources of energy and time.<br /><br />A convolutional neural network is a deep learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other.&nbsp; We developed an accelerator for convolutional neural networks in domain wall memory that exploits the natural shift property of domain wall memory. Our accelerator employs asymmetrical storage of weight and input data, to speed up the inference phase. Our accelerator supports flexible shift operations to enable fast processing with low performance and area overhead. Our experimental results showed that, on average, this accelerator&nbsp; achieves an order of magnitude performance improvement, and two orders of magnitude energy consumption reduction, over a state-of-the-art based designs.<br /><br /><br />We developed an efficient algorithm that given a sequence of accesses to virtual memory, produces a dynamic map from virtual memory to domain wall physical memory in such a way that guarantees that the number of read/write head movements for this embedding will not be too much more than optimal. Here dynamic means that the mapping from virtual memory to physical memory can change over time. This dynamism introduces significantly new challenges relative to computing a static mapping, and in particular the optimal solution is no longer subadditive. Thus we had to develop new algorithmic analysis techniques that did not rely on the subadditivity of the optimal solution.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/29/2021<br>\n\t\t\t\t\tModified by: Kirk&nbsp;Pruhs</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\n\n\nThe goal of the project is to design, analyze, test and deploy algorithms/solutions for data allocation problems that will arise with the adoption of Domain Wall Memory in mobile devices. Conceptually Domain Wall Memory consists of several ``tapes'' with one read/write head per tape. So accessing items near the current location of the tape head is significantly more efficient in terms of the resources of energy and time.\n\nA convolutional neural network is a deep learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other.  We developed an accelerator for convolutional neural networks in domain wall memory that exploits the natural shift property of domain wall memory. Our accelerator employs asymmetrical storage of weight and input data, to speed up the inference phase. Our accelerator supports flexible shift operations to enable fast processing with low performance and area overhead. Our experimental results showed that, on average, this accelerator  achieves an order of magnitude performance improvement, and two orders of magnitude energy consumption reduction, over a state-of-the-art based designs.\n\n\nWe developed an efficient algorithm that given a sequence of accesses to virtual memory, produces a dynamic map from virtual memory to domain wall physical memory in such a way that guarantees that the number of read/write head movements for this embedding will not be too much more than optimal. Here dynamic means that the mapping from virtual memory to physical memory can change over time. This dynamism introduces significantly new challenges relative to computing a static mapping, and in particular the optimal solution is no longer subadditive. Thus we had to develop new algorithmic analysis techniques that did not rely on the subadditivity of the optimal solution.\n\n\t\t\t\t\tLast Modified: 12/29/2021\n\n\t\t\t\t\tSubmitted by: Kirk Pruhs"
 }
}