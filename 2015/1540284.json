{
 "awd_id": "1540284",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Connections Between Algorithm Design and Complexity Theory",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2015-07-01",
 "awd_exp_date": "2016-06-30",
 "tot_intn_awd_amt": 25000.0,
 "awd_amount": 25000.0,
 "awd_min_amd_letter_date": "2015-04-15",
 "awd_max_amd_letter_date": "2015-04-15",
 "awd_abstract_narration": "Complexity theory, through such concepts as NP-completeness, distinguishes between computational problems that have relatively efficient solutions and those that are intractable. Complexity theory has the potential to become a real guide for algorithm design, identifying precisely what algorithmic performance is obtainable.  A fundamental model of computation is the Boolean circuit, composed of interconnected logic gates. Complexity theory studies the capabilities of Boolean circuits when limits are placed on circuit size and circuit depth.\u00a0 Recently, in what seems to be a paradox, breakthroughs on lower bounds in circuit\u00a0 complexity\u00a0 have been derived from the discovery of remarkably efficient algorithms.\u00a0 The precise time complexity of SATISFIABILITY and other NP-complete problems is now linked to progress on a variety of fundamental questions in the theory of computation, many in surprising and counter-intuitive ways. These connections involve the exact complexity of basic polynomial-time solvable problems such as matrix multiplication and triangle detection.\r\n\r\nThe workshop, which will be open to the public, \u00a0will gather researchers from computational complexity and algorithm design to discuss and extend these new developments.\u00a0 This workshop will foster discussions that could lead to new algorithmic ideas for basic problems (often utilizing techniques from lower bounds), as well as new circuit lower bounds (utilizing improved algorithms).   Students will be encouraged to participate in the workshop.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Karp",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Richard M Karp",
   "pi_email_addr": "karp@cs.berkeley.edu",
   "nsf_id": "000099536",
   "pi_start_date": "2015-04-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947045940",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "7927",
   "pgm_ref_txt": "COMPLEXITY & CRYPTOGRAPHY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 25000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The first workshop of the Simons Institute program on &ldquo;Fine-Grained Complexity and Algorithm Design&rdquo;, entitled &ldquo;Connections Between Algorithm Design and Complexity Theory&rdquo; was co-organized by Valentine Kabanets and Ryan Williams. The purpose of the workshop was to bring together different groups &ndash; algorithm designers and complexity theorists &ndash; to discuss the developments in their areas of interest, with a particular focus on interesting connections between the areas.&nbsp;</p>\n<p>The first day started with a lecture by Manuel Blum on &ldquo;Human Computation&rdquo;, in which a computational model for password management was described; the lecture included an enjoyable amount of audience participation, by persons implementing some of the models in their heads. This talk was especially interesting in that it was illustrating the connection of complexity theory with cognitive sciences (the issue raised also at the panel discussion on the third day of the workshop).&nbsp;</p>\n<p>The second lecture of the morning featured David Zuckerman&rsquo;s recent breakthrough in explicit extractor constructions. This has a direct application to the explicit construction of Ramsey graphs with significantly improved parameters. The beauty of this new result is that it brings together seemingly disparate technical tools: seeded extractors, resilient monotone Boolean functions, and simple pseudorandom generators for AC^0 circuits! Such &ldquo;breaking the boundaries between different areas of complexity research&rdquo; was one of the main recurring themes at the workshop, reflecting the main message of the workshop that various computational aspects (complexity-theoretic, algorithmic, algebraic, combinatorial, etc.) are closely interconnected and must be considered together as a unit.</p>\n<p>Then Parikshit Gopalan surveyed recent pseudorandom generator constructions in interesting situations. The afternoon featured short talks by Raghu Meka, Pascal Koiran, and Osamu Watanabe, who discussed polynomial approximations to Boolean functions, arithmetic complexity, and space complexity, respectively</p>\n<p>On the second day, the morning had two 45-minute talks and three 15-minute talks. Avi Wigderson began the day with a survey talk on noncommutative arithmetic circuits; Emanuele Viola discussed new NP-completeness reductions with extremely low complexity (this has been useful in recent lower bound results). Omer Reingold, Michael Forbes, and Eric Allender spoke about &ldquo;fine-grained cryptography&rdquo;, new polynomial identity testing algorithms, and solving the famous Graph Automorphism problem using an oracle for time-bounded Kolmogorov complexity, respectively.</p>\n<p>The afternoon was devoted to approximately 1.5 hours of &ldquo;Open Problems and Short Announcements&rdquo;, where researchers were given the opportunity to speak about whatever they liked for up to 10 minutes each. A variety of problems and new results were presented. &nbsp;Highlights include Amir Abboud&rsquo;s open problems regarding exponential-time hypotheses and connections to polynomial-time problems, Ben Rossman and Igor Oliveira discussing some of their recent depth lower bound results, and Sasha Kulikov&rsquo;s open problem regarding an explicit construction of &ldquo;quadratic dispersers&rdquo; (which would entail stronger circuit lower bounds!).</p>\n<p>&nbsp;The third day opened with a talk by Boaz Barak on how one may achieve such great understanding of algorithms that they become &ldquo;boring&rdquo;.&nbsp; Srikanth Srinivasan then showed how to get an efficient compression algorithm for constant-depth circuits with parity gates (using the techniques from the lower bound proofs for such circuits). Chris Umans spoke of challenges and new developments in the search of fast matrix multiplication algorithms.</p>\n<p>&nbsp;The afternoon featured a distinguished panel of researchers (Toni Pitassi, Avi Wigderson, Virginia Williams, Christos Papadimitriou, and Russell Impagliazzo) who spoke broadly about complexity theory&rsquo;s past, current issues in the fields, and the future of theory.&nbsp; Some of the questions raised were:&nbsp; Why prove lower bounds at all? Should we be doing something else? Is complexity research relevant to other areas of science? Is complexity theory part of mathematics? Should the complexity research be influenced by current technological developments, or should we be ahead of the current technology? How to bridge the gap between the big open questions in complexity and special cases currently studied? What are the good criteria for deciding if a problem is interesting to study? Do we need so many conjectures and hypotheses in complexity theory? Should we (as a community) be more critical of ourselves when judging our achievements? How do we engage the general public in the research we do?</p>\n<p>The last day had a schedule parallel to that of the first day. Rahul Santhanam gave a whiteboard talk on recent quantified Boolean formula algorithms with connections to circuit complexity, Suguru Tamaki announced several new results on SAT solving for difficult Boolean circuit classes, and Joshua Alman spoke on a new probabilistic polynomial construction for MAJORITY which leads to new nearest-neighbor algorithms. In the short talks, Alexander Kulikov, Igor Olivera, and Ruiwen Chen announced new circuit lower bounds slightly larger than 3n, an exponential separation between addition and counting in monotone circuits, and SAT algorithms via new analysis of old lower bounds.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/15/2016<br>\n\t\t\t\t\tModified by: Richard&nbsp;M&nbsp;Karp</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe first workshop of the Simons Institute program on \"Fine-Grained Complexity and Algorithm Design\", entitled \"Connections Between Algorithm Design and Complexity Theory\" was co-organized by Valentine Kabanets and Ryan Williams. The purpose of the workshop was to bring together different groups &ndash; algorithm designers and complexity theorists &ndash; to discuss the developments in their areas of interest, with a particular focus on interesting connections between the areas. \n\nThe first day started with a lecture by Manuel Blum on \"Human Computation\", in which a computational model for password management was described; the lecture included an enjoyable amount of audience participation, by persons implementing some of the models in their heads. This talk was especially interesting in that it was illustrating the connection of complexity theory with cognitive sciences (the issue raised also at the panel discussion on the third day of the workshop). \n\nThe second lecture of the morning featured David Zuckerman?s recent breakthrough in explicit extractor constructions. This has a direct application to the explicit construction of Ramsey graphs with significantly improved parameters. The beauty of this new result is that it brings together seemingly disparate technical tools: seeded extractors, resilient monotone Boolean functions, and simple pseudorandom generators for AC^0 circuits! Such \"breaking the boundaries between different areas of complexity research\" was one of the main recurring themes at the workshop, reflecting the main message of the workshop that various computational aspects (complexity-theoretic, algorithmic, algebraic, combinatorial, etc.) are closely interconnected and must be considered together as a unit.\n\nThen Parikshit Gopalan surveyed recent pseudorandom generator constructions in interesting situations. The afternoon featured short talks by Raghu Meka, Pascal Koiran, and Osamu Watanabe, who discussed polynomial approximations to Boolean functions, arithmetic complexity, and space complexity, respectively\n\nOn the second day, the morning had two 45-minute talks and three 15-minute talks. Avi Wigderson began the day with a survey talk on noncommutative arithmetic circuits; Emanuele Viola discussed new NP-completeness reductions with extremely low complexity (this has been useful in recent lower bound results). Omer Reingold, Michael Forbes, and Eric Allender spoke about \"fine-grained cryptography\", new polynomial identity testing algorithms, and solving the famous Graph Automorphism problem using an oracle for time-bounded Kolmogorov complexity, respectively.\n\nThe afternoon was devoted to approximately 1.5 hours of \"Open Problems and Short Announcements\", where researchers were given the opportunity to speak about whatever they liked for up to 10 minutes each. A variety of problems and new results were presented.  Highlights include Amir Abboud?s open problems regarding exponential-time hypotheses and connections to polynomial-time problems, Ben Rossman and Igor Oliveira discussing some of their recent depth lower bound results, and Sasha Kulikov?s open problem regarding an explicit construction of \"quadratic dispersers\" (which would entail stronger circuit lower bounds!).\n\n The third day opened with a talk by Boaz Barak on how one may achieve such great understanding of algorithms that they become \"boring\".  Srikanth Srinivasan then showed how to get an efficient compression algorithm for constant-depth circuits with parity gates (using the techniques from the lower bound proofs for such circuits). Chris Umans spoke of challenges and new developments in the search of fast matrix multiplication algorithms.\n\n The afternoon featured a distinguished panel of researchers (Toni Pitassi, Avi Wigderson, Virginia Williams, Christos Papadimitriou, and Russell Impagliazzo) who spoke broadly about complexity theory?s past, current issues in the fields, and the future of theory.  Some of the questions raised were:  Why prove lower bounds at all? Should we be doing something else? Is complexity research relevant to other areas of science? Is complexity theory part of mathematics? Should the complexity research be influenced by current technological developments, or should we be ahead of the current technology? How to bridge the gap between the big open questions in complexity and special cases currently studied? What are the good criteria for deciding if a problem is interesting to study? Do we need so many conjectures and hypotheses in complexity theory? Should we (as a community) be more critical of ourselves when judging our achievements? How do we engage the general public in the research we do?\n\nThe last day had a schedule parallel to that of the first day. Rahul Santhanam gave a whiteboard talk on recent quantified Boolean formula algorithms with connections to circuit complexity, Suguru Tamaki announced several new results on SAT solving for difficult Boolean circuit classes, and Joshua Alman spoke on a new probabilistic polynomial construction for MAJORITY which leads to new nearest-neighbor algorithms. In the short talks, Alexander Kulikov, Igor Olivera, and Ruiwen Chen announced new circuit lower bounds slightly larger than 3n, an exponential separation between addition and counting in monotone circuits, and SAT algorithms via new analysis of old lower bounds.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/15/2016\n\n\t\t\t\t\tSubmitted by: Richard M Karp"
 }
}