{
 "awd_id": "1527364",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC: Small: Statistical Models for Opinion Spam Detection Leveraging Linguistic and Behavioral Cues",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Shannon Beck",
 "awd_eff_date": "2015-08-01",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 499695.0,
 "awd_amount": 499695.0,
 "awd_min_amd_letter_date": "2015-07-29",
 "awd_max_amd_letter_date": "2015-07-29",
 "awd_abstract_narration": "Online opinions now play a pivotal role in decision making and influence a wide spectrum of our lives. Choices of restaurants at which to dine, places to stay, universities to attend, books to read, doctors to consult, and even political candidates to vote for, are largely influenced by crowdsourced opinions. However, it is estimated that up to 30% of reviews on websites are fake. As a larger part of the US economy is becoming driven by social opinions, it poses a serious risk to the general public (e.g., by getting mislead to invest on low quality products, services or doctors). The Federal Trade Commission Opinion may soon consider online fraud as unlawful and a legal offense. Detecting fake online opinions is an urgent research area. Otherwise, online social media might continue to progress undetected. This project aims to develop novel deception detection algorithms in order to identify fraudulent behavior. It synergistically integrates techniques from computational linguistics, behavioral modeling and statistical machine learning in order to advance knowledge in this area. \r\n\r\nThe project consists of a four-pronged research effort: 1) novel methods to learn deception classifiers from large-scale noisy crowd data and small-scale domain expert coded data, 2) unsupervised models that treat \"spamicity\" of reviewers as latent with observed behavioral footprints, 3) a relational architecture for jointly modeling reviews, reviewers, and their linguistic and behavioral patterns leveraging inherent reinforcement relations, and 4) an ensemble scoring mechanism blending cues from of all approaches, and an end-to-end validation framework. The techniques developed in the project can (1) reduce the marketing, consumer, and economic risk in e-commerce; (2) improve user profiling, detecting online harassment, bigotry, trolls, and other social media fraud that are of major relevance to national security; and (3) transition techniques developed to courses/tutorials and attract underrepresented students, including minorities and women. The result is a suite of novel, principled, and scalable techniques to filter opinion spam at large scale.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Arjun",
   "pi_last_name": "Mukherjee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Arjun Mukherjee",
   "pi_email_addr": "amukher6@Central.UH.EDU",
   "nsf_id": "000681755",
   "pi_start_date": "2015-07-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Houston",
  "inst_street_address": "4300 MARTIN LUTHER KING BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "HOUSTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7137435773",
  "inst_zip_code": "772043067",
  "inst_country_name": "United States",
  "cong_dist_code": "18",
  "st_cong_dist_code": "TX18",
  "org_lgl_bus_name": "UNIVERSITY OF HOUSTON SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "QKWEF8XLMTT3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Houston",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "770042610",
  "perf_ctry_code": "US",
  "perf_cong_dist": "18",
  "perf_st_cong_dist": "TX18",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 499695.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project aimed to develop novel deception detection models for filtering fake online reviews. The goal was to develop joint models that leverage linguistic and behavioral features that can improve deception detection effectiveness. Over the course of the project several dimensions were explored to improve deception detection of fake online reviews and online opinions such as 1) creating ground truth fake reviews to improve gold standard data for training deceptive opinion spam models, 2) developing temporal and behavioral dynamics analysis models, and popularity and competition analysis models that provide a prognostic insight as to &ldquo;how&rdquo;, &ldquo;why&rdquo; and &ldquo;when&rdquo; fake reviews are potentially injected, and 3) deep linguistic models of authorship verification , style change detection and transfer learning/domain adaptation models for authorship attribution and sockpuppet detection. We believe all the above results and models provide a foundation and the needed intellectual resource/capital which when leveraged to build products will be effective in&nbsp; combating deceptive opinions online, improve the trustworthiness of online opinions by filtering potentially bogus opinions and can improve user profiling, detecting online harassment, bigotry, trolls, and other social media fraud that are of major relevance to national security.</p>\n<p>Additional models were developed to encompass the growing trend of deception and linguistic models for combating deceptive opinion spam in news, social network, and analysis of deception techniques that involve email masquerade.&nbsp; Deceptive opinion spam in news (fake news) can unfortunately be used to game political elections and can cause a lot of social distrust hindering the Web to function as a trustworthy cyberspace. The project developed novel models for detecting deceptive news. These include models that employ a variety of linguistic features such as psycholinguistic, readability, stylistic and structural features in conjunction with a paragraph level attentive neural network, and an architecture that captures satirical deceptive spam in news at both the sentence level and the document level. The architecture incorporates pluggable generic neural networks (e.g., CNN, GRU, and LSTM) making it very extensible and a testbed for exploring other forms of deceptive opinion spam in news.</p>\n<p>Listed below are the summary of core results and outcomes that was accomplished by the project:</p>\n<p>(A) A suite of models that can characterize consumer reviewing behaviors and patterns and linguistic models for authorship verification that can allow us to detect deceptive opinion spam more accurately.</p>\n<p>(B) Dedicated linguistic neural models that can allow us to detect certain kinds of deceptive news (e.g., satirical news) online and have a generic architecture that can be used for extending to other forms of deceptive news. We also found key results (e.g., paragraph structures contain major hints in deception detection) that were previously unknown.</p>\n<p>(c) Focused models for detecting spam (w and w/o involving opinion spam) in social network.</p>\n<p>The above results appear in the following papers that were published during the course of the project.</p>\n<p>&nbsp;</p>\n<p>1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Santosh KC Arjun Mukherjee. On the Temporal Dynamics of Opinion Spamming: Case Studies on Yelp. WWW 16.</p>\n<p>2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Marjan Hosseinia and Arjun Mukherjee. Detecting Sockpuppets in Deceptive Opinion Spam. CICLING&rsquo;17.</p>\n<p>3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Shahryar Baki, Rakesh Verma, Arjun Mukherjee, Omprakash Gnawali. Scaling and Effectiveness of Email Masquerade Attacks: Exploiting Natural Language Generation. ASIACCS&rsquo;17.</p>\n<p>4.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Huayi Li, Geli Fei, Shuai Wang, Bing Liu, Weixiang Shao, Arjun Mukherjee and Jidong Shao. Bimodal Distribution and CoBursting in Review Spam Detection. WWW&rsquo;17.</p>\n<p>5.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Fan Yang, Arjun Mukherjee, Eduard Dragut. Satire News Detection and Analysis using Attention Mechanism and Linguistic Features. EMNLP&rsquo;17.</p>\n<p>6.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Santosh K C, Suman Kalyan Maity and Arjun Mukherjee. ENWalk: Learning Network Features for Spam Detection in Twitter. SBP&rsquo;17.</p>\n<p>7.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Marjan Hosseinia, Arjun Mukherjee. Experiments with Neural Networks for Small and Large Scale Authorship Verification. CICLING&rsquo;18.</p>\n<p>8.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Dainis Boumber, Yifan Zhang, Arjun Mukherjee. Experiments with Convolutional Neural Networks for Multi-Label Authorship Attribution. LREC&rsquo;18.</p>\n<p>9.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Suman Kalyan Maity, Santosh KC and Arjun Mukherjee. Spam2Vec: Learning Biased Embeddings for Spam Detection in Twitter. WWW&rsquo;18.</p>\n<p>10.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Fan Yang, Arjun Mukherjee, Eduard Dragut. Satire News Detection and Analysis using Attention Mechanism. EMNLP 2017</p>\n<p>11.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sohan De Sarkar, Fan Yang, Arjun Mukherjee. Attending Sentences to detect Satirical Fake News. COLING&rsquo;18.</p>\n<p>12.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Marjan Hosseinia and Arjun Mukherjee. Parallel Attention Recurrent Neural Network for Style Change Detection. CLEF 2018.</p>\n<p>13.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Santosh KC, Sohan De Sarkar, and Arjun Mukherjee. Product Popularity Modeling via Time Series Embedding. ASONAM &lsquo;18.</p>\n<p>14.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Dainis Boumber, Yifan Zhang, Marjan Hosseinia, Arjun Mukherjee, Ricardo Vilalta. Robust Authorship Verification using Transfer Learning. CICLING&rsquo;19.</p>\n<p>&nbsp;</p>\n<p>The research resulted in a total of 14 papers that were published in leading venues over a period of 4 years. The papers have acknowledged NSF support. Over the entire course of the project, it supported 3 PhD (of which 1 was female) students, 3 interns in their professional development apart from progress in science.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/14/2019<br>\n\t\t\t\t\tModified by: Arjun&nbsp;Mukherjee</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project aimed to develop novel deception detection models for filtering fake online reviews. The goal was to develop joint models that leverage linguistic and behavioral features that can improve deception detection effectiveness. Over the course of the project several dimensions were explored to improve deception detection of fake online reviews and online opinions such as 1) creating ground truth fake reviews to improve gold standard data for training deceptive opinion spam models, 2) developing temporal and behavioral dynamics analysis models, and popularity and competition analysis models that provide a prognostic insight as to \"how\", \"why\" and \"when\" fake reviews are potentially injected, and 3) deep linguistic models of authorship verification , style change detection and transfer learning/domain adaptation models for authorship attribution and sockpuppet detection. We believe all the above results and models provide a foundation and the needed intellectual resource/capital which when leveraged to build products will be effective in  combating deceptive opinions online, improve the trustworthiness of online opinions by filtering potentially bogus opinions and can improve user profiling, detecting online harassment, bigotry, trolls, and other social media fraud that are of major relevance to national security.\n\nAdditional models were developed to encompass the growing trend of deception and linguistic models for combating deceptive opinion spam in news, social network, and analysis of deception techniques that involve email masquerade.  Deceptive opinion spam in news (fake news) can unfortunately be used to game political elections and can cause a lot of social distrust hindering the Web to function as a trustworthy cyberspace. The project developed novel models for detecting deceptive news. These include models that employ a variety of linguistic features such as psycholinguistic, readability, stylistic and structural features in conjunction with a paragraph level attentive neural network, and an architecture that captures satirical deceptive spam in news at both the sentence level and the document level. The architecture incorporates pluggable generic neural networks (e.g., CNN, GRU, and LSTM) making it very extensible and a testbed for exploring other forms of deceptive opinion spam in news.\n\nListed below are the summary of core results and outcomes that was accomplished by the project:\n\n(A) A suite of models that can characterize consumer reviewing behaviors and patterns and linguistic models for authorship verification that can allow us to detect deceptive opinion spam more accurately.\n\n(B) Dedicated linguistic neural models that can allow us to detect certain kinds of deceptive news (e.g., satirical news) online and have a generic architecture that can be used for extending to other forms of deceptive news. We also found key results (e.g., paragraph structures contain major hints in deception detection) that were previously unknown.\n\n(c) Focused models for detecting spam (w and w/o involving opinion spam) in social network.\n\nThe above results appear in the following papers that were published during the course of the project.\n\n \n\n1.         Santosh KC Arjun Mukherjee. On the Temporal Dynamics of Opinion Spamming: Case Studies on Yelp. WWW 16.\n\n2.         Marjan Hosseinia and Arjun Mukherjee. Detecting Sockpuppets in Deceptive Opinion Spam. CICLING?17.\n\n3.         Shahryar Baki, Rakesh Verma, Arjun Mukherjee, Omprakash Gnawali. Scaling and Effectiveness of Email Masquerade Attacks: Exploiting Natural Language Generation. ASIACCS?17.\n\n4.         Huayi Li, Geli Fei, Shuai Wang, Bing Liu, Weixiang Shao, Arjun Mukherjee and Jidong Shao. Bimodal Distribution and CoBursting in Review Spam Detection. WWW?17.\n\n5.         Fan Yang, Arjun Mukherjee, Eduard Dragut. Satire News Detection and Analysis using Attention Mechanism and Linguistic Features. EMNLP?17.\n\n6.         Santosh K C, Suman Kalyan Maity and Arjun Mukherjee. ENWalk: Learning Network Features for Spam Detection in Twitter. SBP?17.\n\n7.         Marjan Hosseinia, Arjun Mukherjee. Experiments with Neural Networks for Small and Large Scale Authorship Verification. CICLING?18.\n\n8.         Dainis Boumber, Yifan Zhang, Arjun Mukherjee. Experiments with Convolutional Neural Networks for Multi-Label Authorship Attribution. LREC?18.\n\n9.         Suman Kalyan Maity, Santosh KC and Arjun Mukherjee. Spam2Vec: Learning Biased Embeddings for Spam Detection in Twitter. WWW?18.\n\n10.       Fan Yang, Arjun Mukherjee, Eduard Dragut. Satire News Detection and Analysis using Attention Mechanism. EMNLP 2017\n\n11.       Sohan De Sarkar, Fan Yang, Arjun Mukherjee. Attending Sentences to detect Satirical Fake News. COLING?18.\n\n12.       Marjan Hosseinia and Arjun Mukherjee. Parallel Attention Recurrent Neural Network for Style Change Detection. CLEF 2018.\n\n13.       Santosh KC, Sohan De Sarkar, and Arjun Mukherjee. Product Popularity Modeling via Time Series Embedding. ASONAM ?18.\n\n14.       Dainis Boumber, Yifan Zhang, Marjan Hosseinia, Arjun Mukherjee, Ricardo Vilalta. Robust Authorship Verification using Transfer Learning. CICLING?19.\n\n \n\nThe research resulted in a total of 14 papers that were published in leading venues over a period of 4 years. The papers have acknowledged NSF support. Over the entire course of the project, it supported 3 PhD (of which 1 was female) students, 3 interns in their professional development apart from progress in science.\n\n \n\n\t\t\t\t\tLast Modified: 10/14/2019\n\n\t\t\t\t\tSubmitted by: Arjun Mukherjee"
 }
}