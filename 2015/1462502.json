{
 "awd_id": "1462502",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER-DynamicData: Principled and Scalable Probabilistic Frameworks for Dynamic Multi-modal Data",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "akbar sayeed",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 100000.0,
 "awd_amount": 100000.0,
 "awd_min_amd_letter_date": "2015-09-04",
 "awd_max_amd_letter_date": "2015-09-04",
 "awd_abstract_narration": "Emergence of the Big Data phenomenon has given rise to data collections that are massive, highly heterogeneous and multi-modal, dynamically evolving, as well as incomplete, noisy and imprecise. These characteristics are becoming increasingly prevalent in data from a diverse range of domains, such as robotics, cognitive neuroscience, sensor generated data (e.g., in geoscience and remote sensing), and the dynamically evolving data on the web. The heterogeneity, complexity, dynamic evolution, and the often real-time processing requirements, call for methods that are both statistically rigorous as well as computationally scalable. Moreover, performing fast feature-extraction and/or predictions at *test time* is another key requirement, especially in problems involving dynamic data arriving at high speeds. This project will innovate on scalable statistical methods for learning from such massive dynamic multi-modal data, with a focus on designing novel probabilistic models for multi-layer latent feature extraction for such data. These multi-layer latent feature representations  of the data will help capture the underlying dynamics and allow reconciling the data heterogeneity arising due to diverse data types and widely differing spatial and temporal resolutions across the different modalities, while also being useful for a wide range of fundamental data analysis tasks, such as classification, clustering, and predicting missing data. At the same time, the focus will also be on developing methods that are efficient at test time, so that fast feature extraction and predictions can be made in real time, to make these methods readily applicable to dynamic streaming data.\r\n\r\nThis EArly Grant for Exploratory Research (EAGER) project endeavors to move beyond existing ad hoc approaches currently used for these problems, and develop a probabilistically grounded, statistically rigorous, and computationally scalable framework, based on Bayesian and nonparametric Bayesian modeling. Taking a Bayesian generative modeling approach will naturally enable modeling the dynamic behavior of the data and seamlessly integrate diverse types of data, while handling issues such as missingness, noise and the imprecise nature of the data. In addition, the nonparametric Bayesian treatment will provide the much-needed modeling flexibility and address many of the limitations of the existing Deep Learning models, e.g., by doing away with the need of extensive hand-tuning, incorporating rich prior knowledge about the model parameters, and allowing a natural sharing of statistical strength across the multiple data modalities. To handle the associated computational challenges, the framework will provide novel inference machinery in form of online Bayesian inference methods that will naturally handle dynamic, real-time data, and parallel and distributed Bayesian inference methods to handle massive multi-modal data that are too large for the capacity (storage and/or computational) of a single computing node. Furthermore, due to its inherent ability of quantifying model uncertainty, the proposed Bayesian framework will naturally facilitate a dynamic integration between model computation (inference) and data acquisition, and help design informed data acquisition (i.e., \"active\" sensing) methods in the context of dynamic multi-modal data. An overarching goal of this project is to also help synergize two important research directions in machine learning - nonparametric Bayesian methods and Deep Learning methods. By designing scalable nonparametric Bayesian solutions to the type of problems Deep Learning methods have been applied for, the project will convince the skeptics of Deep Learning methods to adopt these methods more openly. At the same time, the compelling range of problems and applications Deep Learning are being used for, will broaden the appeal of nonparametric Bayesian methods from a practical sense. We expect this synergy between these two areas will significantly advance the state-of-the-art in both areas.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lawrence",
   "pi_last_name": "Carin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lawrence Carin",
   "pi_email_addr": "lcarin@ee.duke.edu",
   "nsf_id": "000522425",
   "pi_start_date": "2015-09-04",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Piyush",
   "pi_last_name": "Rai",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Piyush Rai",
   "pi_email_addr": "piyush.rai@duke.edu",
   "nsf_id": "000678115",
   "pi_start_date": "2015-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "2200  W. Main St",
  "perf_city_name": "Durham",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277054040",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "153E",
   "pgm_ref_txt": "Wireless comm & sig processing"
  },
  {
   "pgm_ref_code": "5384",
   "pgm_ref_txt": "DATA AND DATA SYSTEMS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 100000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we developed novel deep learning models and inference algorithms for feature learning and latent structure discovery from dynamic and multimodal data. In particular, we developed novel deep generative models for various types of data such as image and video, text, and EEG data, most of which are inherently dynamic in nature. Our models are based on principled design framework, rooted in probabilistic and Bayesian modeling, and we have also developed scalable inference algorithms that enable these models to apply to large datasets.</p>\n<p>Some of our work in this project involves fundamental contributions in the area of generative models for sequence data such as text. In particular, we have developed novel approaches to learning generative adversarial networks and applied these successfully on real-world datasets. Our algorithms are able to generate realistic text and perform favorably on various machine learning tasks involving text data. Our generative frameworks can be easily extended to incorporate data from multiple modalities.</p>\n<p>Some of the key publications resulting from this work include:</p>\n<p>-&nbsp;<span>Z. Gan, C. Li, R. Henao, D.E. Carlson and L. Carin, Deep Temporal Sigmoid Belief Networks for Sequence Modeling, Neural and Information Processing Systems (NIPS), 2015</span><br /><span>- C. Hu, P. Rai, C. Chen, M. Harding, and L. Carin, Scalable Bayesian Non-Negative Tensor Factorization for Massive Count Data, European Conference on Machine Learning (ECML), 2015</span><br /><span>- Y. Zhang, Y. Zhao, L. David, R. Henao and L. Carin, Dynamic Poisson Factor Analysis, IEEE Int. Conf. Data Mining (ICDM), 2016</span><br /><span>- . Song, Z. Gan and L. Carin, Factored Temporal Sigmoid Belief Networks for Sequence Learning, Int. Conf. Machine Learning (ICML), 2016</span><br /><span>- Y. Pu, &nbsp;Z. Gan, &nbsp;R. Henao, X. Yuan, &nbsp;C. Li, &nbsp;A. Stevens and &nbsp;L. Carin, Variational Autoencoder for Deep Learning of Images, Labels and Captions, Neural and Information Processing Systems (NIPS), 2016</span><br /><span>- Z. Gan, C. Li, C. Chen, Y. Pu, Q. Su, and L. Carin, Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling, Association for Computational Linguistics (ACL), 2017</span><br /><span>- Y. Zhang, Z. Gan, K. Fan, Z. Chen, R. Henao, D. Shen and L. Carin, Adversarial Feature Matching for Text Generation,</span><br /><span>- Z. Gan, Y. Pu, R. Henao, C. Li, X. He and L. Carin, Learning Generic Sentence Representations Using Convolutional Neural Networks, Conf. on Empirical Methods in Natural Language Processing (EMNLP), 2017 Int. Conf. Machine Learning (ICML), 2017</span><br /><span>- Y. Li, M. Murias, S. Major, G. Dawson, K. Dzirasa, L. Carin and D.E. Carlson, Targeting EEG/LFP Synchrony with Neural Nets, Neural and Information Processing Systems (NIPS), 2017</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/05/2017<br>\n\t\t\t\t\tModified by: Piyush&nbsp;Rai</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this project, we developed novel deep learning models and inference algorithms for feature learning and latent structure discovery from dynamic and multimodal data. In particular, we developed novel deep generative models for various types of data such as image and video, text, and EEG data, most of which are inherently dynamic in nature. Our models are based on principled design framework, rooted in probabilistic and Bayesian modeling, and we have also developed scalable inference algorithms that enable these models to apply to large datasets.\n\nSome of our work in this project involves fundamental contributions in the area of generative models for sequence data such as text. In particular, we have developed novel approaches to learning generative adversarial networks and applied these successfully on real-world datasets. Our algorithms are able to generate realistic text and perform favorably on various machine learning tasks involving text data. Our generative frameworks can be easily extended to incorporate data from multiple modalities.\n\nSome of the key publications resulting from this work include:\n\n- Z. Gan, C. Li, R. Henao, D.E. Carlson and L. Carin, Deep Temporal Sigmoid Belief Networks for Sequence Modeling, Neural and Information Processing Systems (NIPS), 2015\n- C. Hu, P. Rai, C. Chen, M. Harding, and L. Carin, Scalable Bayesian Non-Negative Tensor Factorization for Massive Count Data, European Conference on Machine Learning (ECML), 2015\n- Y. Zhang, Y. Zhao, L. David, R. Henao and L. Carin, Dynamic Poisson Factor Analysis, IEEE Int. Conf. Data Mining (ICDM), 2016\n- . Song, Z. Gan and L. Carin, Factored Temporal Sigmoid Belief Networks for Sequence Learning, Int. Conf. Machine Learning (ICML), 2016\n- Y. Pu,  Z. Gan,  R. Henao, X. Yuan,  C. Li,  A. Stevens and  L. Carin, Variational Autoencoder for Deep Learning of Images, Labels and Captions, Neural and Information Processing Systems (NIPS), 2016\n- Z. Gan, C. Li, C. Chen, Y. Pu, Q. Su, and L. Carin, Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling, Association for Computational Linguistics (ACL), 2017\n- Y. Zhang, Z. Gan, K. Fan, Z. Chen, R. Henao, D. Shen and L. Carin, Adversarial Feature Matching for Text Generation,\n- Z. Gan, Y. Pu, R. Henao, C. Li, X. He and L. Carin, Learning Generic Sentence Representations Using Convolutional Neural Networks, Conf. on Empirical Methods in Natural Language Processing (EMNLP), 2017 Int. Conf. Machine Learning (ICML), 2017\n- Y. Li, M. Murias, S. Major, G. Dawson, K. Dzirasa, L. Carin and D.E. Carlson, Targeting EEG/LFP Synchrony with Neural Nets, Neural and Information Processing Systems (NIPS), 2017\n\n\t\t\t\t\tLast Modified: 10/05/2017\n\n\t\t\t\t\tSubmitted by: Piyush Rai"
 }
}