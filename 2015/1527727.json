{
 "awd_id": "1527727",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Predictable Real-Time Computing in GPU-enabled Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2015-10-01",
 "awd_exp_date": "2018-09-30",
 "tot_intn_awd_amt": 354076.0,
 "awd_amount": 354076.0,
 "awd_min_amd_letter_date": "2015-08-18",
 "awd_max_amd_letter_date": "2015-08-18",
 "awd_abstract_narration": "Given the need to achieve higher performance without driving up energy consumption, most chip manufacturers have shifted to multicore architectures, especially heterogeneous ones. Among heterogeneous processing elements, graphic processing units (GPUs) have seen wide-spread use. GPUs have the power to enable orders of magnitude faster execution of many applications. Thus, they are becoming increasingly applicable for general-purpose systems. Unfortunately, it is not straightforward to reliably adopt GPUs in many safety-critical systems that require predictable real-time correctness, one of the most important tenets in certification required for such systems. A key example is the advanced automotive system where timeliness of computations is an essential requirement of correctness due to the interaction with the physical world. \r\n\r\nThe goal of this project is to ensure predictable real-time correctness in current GPU-enabled systems, through (i) developing new real-time resource allocation methods that can be applied in GPU-enabled systems, where a number of difficult analysis issues due to the problem of co-scheduling CPU and GPU resources and several GPU-specific constraints will be addressed, and (ii) building an open-source ecosystem of predictably managing GPU resources in the operating system. These efforts will pave the way to utilizing GPUs in a predictable manner and benefit many applications and systems in which real-time constraints exist, such as automated automobiles and medical instrumentation. The successful completion of this work will enable powerful GPU computing capability. In safety-critical systems  which usually require certification, this work will help enable such systems equipped with GPUs to be certifiable.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cong",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cong Liu",
   "pi_email_addr": "cong@utdallas.edu",
   "nsf_id": "000662039",
   "pi_start_date": "2015-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Dallas",
  "inst_street_address": "800 WEST CAMPBELL RD.",
  "inst_street_address_2": "SP2.25",
  "inst_city_name": "RICHARDSON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9728832313",
  "inst_zip_code": "750803021",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "TX24",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT DALLAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "EJCVPNN1WFS5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Dallas",
  "perf_str_addr": "800 W. Compell Road",
  "perf_city_name": "Richardson",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "750803021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "TX24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 354076.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; line-height: 17.0px; font: 14.0px Verdana; color: #000000; -webkit-text-stroke: #000000; background-color: #ffffff} p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; line-height: 17.0px; font: 14.0px Verdana; color: #000000; -webkit-text-stroke: #000000; background-color: #ffffff; min-height: 17.0px} li.li3 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; line-height: 17.0px; font: 14.0px Verdana; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font-kerning: none; background-color: #ffffff} ul.ul1 {list-style-type: disc} -->\n<p class=\"p1\"><span class=\"s1\">Since GPUs have the power to enable orders of magnitude faster and more energy efficient execution of many applications, GPU-enabled multicore platforms have been pervasively seen in embedded systems domains such as transportation, avionics, and robotics. Unfortunately, it is not straightforward to reliably adopt GPUs in many safety-critical embedded systems that require predictable real-time correctness, one of the most important tenets in certification required for such systems. A key example is the autonomous automotive system where timeliness of computations is an essential requirement of correctness due to the interaction with the physical world. Achieving real-time correctness in GPU-enabled systems encounter new challenges at both algorithmic and systems level. Algorithmically, adding another type of resource (i.e., GPU) into the system brings hard resource management problems such as co-scheduling CPU and GPU resources and variable execution times of workloads executed on GPU. At the systems level, current system software support for GPUs is tailored to accelerate particular dedicated applications, but not well-designed to enable efficient and predictable utilization of GPUs in a real-time multi-tasking environment.<span>&nbsp;</span></span>&nbsp;</p>\n<p class=\"p1\"><span class=\"s1\">This project aimed to ensure predictable real-time correctness in GPU-enabled systems. For resolving the algorithmic challenges, a set of new real-time resource allocation methods that can be applied in GPU-enabled systems have been developed, where a number of difficult analysis issues due to the problem of co-scheduling CPU and GPU resources and several GPU-specific constraints have been addressed. Moreover, at the system-level, a comprehensive open-source ecosystem of predictably managing GPU resources in the operating system has been built.</span></p>\n<p class=\"p1\"><span class=\"s1\">The project results in many new discoveries and techniques, including:<span>&nbsp;</span></span>&nbsp;</p>\n<ul class=\"ul1\">\n<li class=\"li3\"><span class=\"s2\">The suspension-based methodology proposed in the project, which treats the latency experienced by any task due to accessing GPUs as self-suspensions, has been shown to be very effective in solving the CPU/GPU co-scheduling problem. This methodology is powerful in making judicious coordinated decisions on allocating CPU and GPU resources to satisfy applications' timing requirements.</span></li>\n<li class=\"li3\"><span class=\"s2\">A set of new runtime scheduling and timing validation techniques, for maximizing the utilization of CPUs and GPUs in supporting workloads with self-suspension behaviors with analytically guaranteed real-time correctness.</span></li>\n<li class=\"li3\"><span class=\"s2\">A stochastic scheduling framework for GPU-enabled systems with probabilistic timing guarantees, which can handle the variable execution time experienced by workloads that are executed on GPU.</span></li>\n<li class=\"li3\"><span class=\"s2\">An analysis technique that handles the parallelism characteristic seen in many GPU-accelerated workloads.</span></li>\n<li class=\"li3\"><span class=\"s2\">A system-level solution that enable efficient preemptive execution on GPU.</span></li>\n<li class=\"li3\"><span class=\"s2\">A new technique to support GPU computing result reuse through exploring potential data/computation redundancy, which improves throughput, latency, and energy efficiency of GPGPU computing.</span></li>\n<li class=\"li3\"><span class=\"s2\">A systemic framework for accelerating DNN (deep neural networks) based workloads in autonomous driving systems with guaranteed timing predictability and improved overall concurrency and throughput performance.</span></li>\n<li class=\"li3\"><span class=\"s2\">A timing-predictable energy optimization framework for DNN-driven autonomous driving system, which guarantees timing correctness with significantly improved energy efficiency.</span></li>\n</ul>\n<p class=\"p1\"><span class=\"s1\">In the end, this project trained and educated 4 graduates and 2 high school students, and produced 2 Ph.D. dissertations (one in Summer 2018 and another in Fall 2018) and 2 Masters Thesis. Our findings produced more than 20 papers at top venues. These findings have gotten recognized by the research community, including<span>&nbsp; </span>an \"Outstanding Paper Award\" at RTSS'17, a \"Best Paper Award\" at RTAS'18, and a \"Top-10 Papers\" at INFOCOM'17 (these three conferences are top-tier conferences in the areas of embedded &amp; real-time systems and networking). We have also received a Best Paper Nomination at the&nbsp;RTCSA'17 conference. All&nbsp;students who contributed to these research are being&nbsp;supported by this project. Moreover, the project also resulted in new courses and lecture materials to students, including a new graduate-level course CS 6308 &ldquo;Predictable GPGPU Computing&rdquo; and a well-defined project focusing on using GPUs in a predictable manner to control an autonomous toy train. We have also delivered more than 20 presentations at conferences and industrial meetings during this project period, to disseminate the results of the project and educate students, researchers, and practitioners.<span>&nbsp;</span></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/09/2018<br>\n\t\t\t\t\tModified by: Cong&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSince GPUs have the power to enable orders of magnitude faster and more energy efficient execution of many applications, GPU-enabled multicore platforms have been pervasively seen in embedded systems domains such as transportation, avionics, and robotics. Unfortunately, it is not straightforward to reliably adopt GPUs in many safety-critical embedded systems that require predictable real-time correctness, one of the most important tenets in certification required for such systems. A key example is the autonomous automotive system where timeliness of computations is an essential requirement of correctness due to the interaction with the physical world. Achieving real-time correctness in GPU-enabled systems encounter new challenges at both algorithmic and systems level. Algorithmically, adding another type of resource (i.e., GPU) into the system brings hard resource management problems such as co-scheduling CPU and GPU resources and variable execution times of workloads executed on GPU. At the systems level, current system software support for GPUs is tailored to accelerate particular dedicated applications, but not well-designed to enable efficient and predictable utilization of GPUs in a real-time multi-tasking environment.  \nThis project aimed to ensure predictable real-time correctness in GPU-enabled systems. For resolving the algorithmic challenges, a set of new real-time resource allocation methods that can be applied in GPU-enabled systems have been developed, where a number of difficult analysis issues due to the problem of co-scheduling CPU and GPU resources and several GPU-specific constraints have been addressed. Moreover, at the system-level, a comprehensive open-source ecosystem of predictably managing GPU resources in the operating system has been built.\nThe project results in many new discoveries and techniques, including:  \n\nThe suspension-based methodology proposed in the project, which treats the latency experienced by any task due to accessing GPUs as self-suspensions, has been shown to be very effective in solving the CPU/GPU co-scheduling problem. This methodology is powerful in making judicious coordinated decisions on allocating CPU and GPU resources to satisfy applications' timing requirements.\nA set of new runtime scheduling and timing validation techniques, for maximizing the utilization of CPUs and GPUs in supporting workloads with self-suspension behaviors with analytically guaranteed real-time correctness.\nA stochastic scheduling framework for GPU-enabled systems with probabilistic timing guarantees, which can handle the variable execution time experienced by workloads that are executed on GPU.\nAn analysis technique that handles the parallelism characteristic seen in many GPU-accelerated workloads.\nA system-level solution that enable efficient preemptive execution on GPU.\nA new technique to support GPU computing result reuse through exploring potential data/computation redundancy, which improves throughput, latency, and energy efficiency of GPGPU computing.\nA systemic framework for accelerating DNN (deep neural networks) based workloads in autonomous driving systems with guaranteed timing predictability and improved overall concurrency and throughput performance.\nA timing-predictable energy optimization framework for DNN-driven autonomous driving system, which guarantees timing correctness with significantly improved energy efficiency.\n\nIn the end, this project trained and educated 4 graduates and 2 high school students, and produced 2 Ph.D. dissertations (one in Summer 2018 and another in Fall 2018) and 2 Masters Thesis. Our findings produced more than 20 papers at top venues. These findings have gotten recognized by the research community, including  an \"Outstanding Paper Award\" at RTSS'17, a \"Best Paper Award\" at RTAS'18, and a \"Top-10 Papers\" at INFOCOM'17 (these three conferences are top-tier conferences in the areas of embedded &amp; real-time systems and networking). We have also received a Best Paper Nomination at the RTCSA'17 conference. All students who contributed to these research are being supported by this project. Moreover, the project also resulted in new courses and lecture materials to students, including a new graduate-level course CS 6308 \"Predictable GPGPU Computing\" and a well-defined project focusing on using GPUs in a predictable manner to control an autonomous toy train. We have also delivered more than 20 presentations at conferences and industrial meetings during this project period, to disseminate the results of the project and educate students, researchers, and practitioners. \n\n\t\t\t\t\tLast Modified: 10/09/2018\n\n\t\t\t\t\tSubmitted by: Cong Liu"
 }
}