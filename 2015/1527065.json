{
 "awd_id": "1527065",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Closing the Productivity/Performance Gap with Just-in-Time Configuration of Meta-Trace Accelerators",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2015-08-01",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2015-07-20",
 "awd_max_amd_letter_date": "2015-07-20",
 "awd_abstract_narration": "Title: SHF: Small: Closing the Productivity/Performance Gap with Just-in-Time Configuration of Meta-Trace Accelerators\r\n\r\nDynamic programming languages are growing in popularity across the computing spectrum from smartphones, to servers, to supercomputers. Dynamic programming languages such as Python, JavaScript, and MATLAB are all now among the top-ten most popular programming languages. These \"productivity-level\" languages make it easy to quickly develop, verify, and maintain applications, but unfortunately, the performance of such applications is usually quite low. This project is exploring a new hardware/software co-design approach for closing this productivity-performance gap. The intellectual merits of this project are the potential for fundamental advances in new hardware accelerators specifically designed for dynamic programming languages, and new software techniques to let applications take advantage of these accelerators. The project's broader significance and importance are rooted in the popularity of dynamic programming languages, and the potential to significantly improve the performance of these highly productive languages.\r\n\r\nThere has been great interest in software and hardware techniques to close the \"productivity-performance gap\". On the software side, high-performance interpreters are increasingly leveraging just-in-time (JIT) method- or trace-based compilation techniques. On the hardware-side, there is a long history of directly supporting high-level languages in hardware. Unfortunately, direct execution of high-level languages precludes the kinds of aggressive optimizations possible with JIT compilation and can prevent efficient execution of alternative high-level languages. A key insight is that future hardware acceleration for dynamic programming languages should not replace JIT compilation, but should instead elegantly complement JIT compilation for a variety of different dynamic programming languages. This project is investigating a new approach using just-in-time configuration of meta-trace accelerators. The project is using a vertically integrated research methodology to explore the following four research thrusts: (1) developing and optimizing a new Scheme interpreter (called RLisPy) to create a state-of-the-art software baseline; (2) exploring various novel hardware meta-trace accelerators for RLisPy; (3) exploring JIT configuration to accelerate RLisPy using these meta-trace accelerators; and (4) applying these techniques to the more popular Python dynamic programming language.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Batten",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher Batten",
   "pi_email_addr": "cbatten@cornell.edu",
   "nsf_id": "000539036",
   "pi_start_date": "2015-07-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "323 Rhodes Hall",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148533801",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Dynamic programming languages are growing in popularity across the computing spectrum from smartphones, to servers, to supercomputers. Dynamic programming languages such as Python, JavaScript, and MATLAB are all now among the top-ten most popular programming languages. These \"productivity-level\" languages make it easy to quickly develop, verify, and maintain applications, but unfortunately, the performance of such applications is usually quite low. There has been great interest in software and hardware techniques to close the \"productivity-performance gap\". On the software side, high-performance interpreters are increasingly leveraging just-in-time (JIT) method- or trace-based compilation techniques. On the hardware-side, there is a long history of directly supporting high-level languages in hardware. Unfortunately, direct execution of high-level languages precludes the kinds of aggressive optimizations possible with JIT compilation and can prevent efficient execution of alternative high-level languages. A key insight is that future hardware acceleration for dynamic programming languages should not replace JIT compilation, but should instead elegantly complement JIT compilation for a variety of different dynamic programming languages.</p>\n<p><br />This project explored new hardware/software co-design approaches for closing this productivity-performance gap within the context of JIT compilation. The number and complexity of abstraction layers within a JIT compilation framework is one of the key obstacles in pursuing research in this area. To address this challenge, the project developed a new cross-layer workload characterization methodology to understand the subtle interaction of these various layers. The project then leveraged this methodology to explore two new techniques for accelerating general-purpose Python programs and new techniques for accelerating domain-specific Python programs in three different domains including hardware simulation and machine learning. Taken holistically, this project has made important fundamental advances in accelerating dynamic programming languages.</p>\n<p><br />As part of this project's educational outreach plan, the PI integrated domain-specific JIT compilation optimizations for hardware simulation into a recently developed course on chip design. This course targets advanced undergraduates and first-year graduate students and teaches students the principles and practices involved in transforming hardware descriptions into actual chip layout using state-of-the art design tools. As part of the laboratory assignments and design projects, student use an open-source Python-based hardware modeling framework that includes the JIT compilation optimizations developed in this research project. This experience provided valuable real-world usage feedback and has enabled the PI to incorporate research ideas into broadly used open-source tools. The PI also organized a dynamic and engaging 90-minute hands-on activity for 20 freshmen to help increase participation of diversity students in computer engineering. Students incrementally developed a simple Internet-of-Things (IoT) system capable of monitoring an input sensor and triggering a remote output actuator through the cloud.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/02/2021<br>\n\t\t\t\t\tModified by: Christopher&nbsp;Batten</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDynamic programming languages are growing in popularity across the computing spectrum from smartphones, to servers, to supercomputers. Dynamic programming languages such as Python, JavaScript, and MATLAB are all now among the top-ten most popular programming languages. These \"productivity-level\" languages make it easy to quickly develop, verify, and maintain applications, but unfortunately, the performance of such applications is usually quite low. There has been great interest in software and hardware techniques to close the \"productivity-performance gap\". On the software side, high-performance interpreters are increasingly leveraging just-in-time (JIT) method- or trace-based compilation techniques. On the hardware-side, there is a long history of directly supporting high-level languages in hardware. Unfortunately, direct execution of high-level languages precludes the kinds of aggressive optimizations possible with JIT compilation and can prevent efficient execution of alternative high-level languages. A key insight is that future hardware acceleration for dynamic programming languages should not replace JIT compilation, but should instead elegantly complement JIT compilation for a variety of different dynamic programming languages.\n\n\nThis project explored new hardware/software co-design approaches for closing this productivity-performance gap within the context of JIT compilation. The number and complexity of abstraction layers within a JIT compilation framework is one of the key obstacles in pursuing research in this area. To address this challenge, the project developed a new cross-layer workload characterization methodology to understand the subtle interaction of these various layers. The project then leveraged this methodology to explore two new techniques for accelerating general-purpose Python programs and new techniques for accelerating domain-specific Python programs in three different domains including hardware simulation and machine learning. Taken holistically, this project has made important fundamental advances in accelerating dynamic programming languages.\n\n\nAs part of this project's educational outreach plan, the PI integrated domain-specific JIT compilation optimizations for hardware simulation into a recently developed course on chip design. This course targets advanced undergraduates and first-year graduate students and teaches students the principles and practices involved in transforming hardware descriptions into actual chip layout using state-of-the art design tools. As part of the laboratory assignments and design projects, student use an open-source Python-based hardware modeling framework that includes the JIT compilation optimizations developed in this research project. This experience provided valuable real-world usage feedback and has enabled the PI to incorporate research ideas into broadly used open-source tools. The PI also organized a dynamic and engaging 90-minute hands-on activity for 20 freshmen to help increase participation of diversity students in computer engineering. Students incrementally developed a simple Internet-of-Things (IoT) system capable of monitoring an input sensor and triggering a remote output actuator through the cloud.\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 05/02/2021\n\n\t\t\t\t\tSubmitted by: Christopher Batten"
 }
}