{
 "awd_id": "1536795",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF:  Large:  Collaborative Research:  Designing the Programmable Many-Core for Extreme Scale Computing",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tao Li",
 "awd_eff_date": "2014-09-01",
 "awd_exp_date": "2016-12-31",
 "tot_intn_awd_amt": 274973.0,
 "awd_amount": 274973.0,
 "awd_min_amd_letter_date": "2015-04-24",
 "awd_max_amd_letter_date": "2015-10-28",
 "awd_abstract_narration": "This work proposes to design a programmable many-core for Extreme-Scale Computing in mobile platforms (netbooks and smart-phones) of year 2020. This work cuts across the architecture, compiler, operating system, and correctness/performance tools areas. A key technology explored is that of cores and all of the software continuously operating in Chunks (i.e., atomic blocks) of instructions at a time --- eliminating the need for in-order, single-instruction-at-a-time commit. The PIs will develop a novel chunk-based architecture that supports the high levels of performance, power/energy efficiency, concurrency, and locality required. They will develop advanced compiler support for chunk generation that delivers high performance at low power, and leverages all the programmability features of the architecture. They will also design an OS that supports and takes advantage of chunks. Finally, they will design a set of novel correctness and performance tools that exploit chunks, signatures, hashes, and all the other features of this architecture.\r\n\r\nThe broader impacts of this work involve the creation of a multidisciplinary research and education center at University of Illinois and Purdue on Programmable Extreme Scale Computing. Faculty of diverse expertise will be devoted to solving the problem of programmable, very-high performance, very power/energy-efficient many-cores for mobile platforms of year 2020 and beyond. The PIs will broaden the course offerings at University of Illinois and Purdue in the four areas, with multidisciplinary courses at different depth levels. Graduate and undergraduate researchers in ECE and CS will be involved in the research. Overall, the PIs hope to prove that programmable, high-performance, and highly power/energy-efficient many-cores based on continuous atomic-block operation are attractive.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Josep",
   "pi_last_name": "Torrellas",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Josep Torrellas",
   "pi_email_addr": "torrellas@cs.uiuc.edu",
   "nsf_id": "000488177",
   "pi_start_date": "2015-10-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Samuel",
   "pi_last_name": "Midkiff",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Samuel P Midkiff",
   "pi_email_addr": "smidkiff@purdue.edu",
   "nsf_id": "000344348",
   "pi_start_date": "2015-04-24",
   "pi_end_date": "2015-10-28"
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618207473",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6863",
   "pgm_ref_txt": "SEBML-MOORE'S LAW"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 274973.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Most of the programming in websites is done in JavaScript, which is<br />called \"the language of the internet\". Many people write in this language<br />and find that the performance is 10-100x lower than in conventional<br />languages such as C and C++.<br /><br />To understand the problem, we took over a year to analyze the best compiler<br />that currently exists for JavaScript, which is written by Google and it is<br />called V8. We compiled and ran popular websites, such as Amazon and CBS News.<br /><br />The results we found were very surprising. JavaScript creates many<br />software data strcutures as it generates the code, and as the code<br />runs, it has to check these data structures to find the correct operations<br />to perform. What we did is to streamline these data structures, so that<br />at the cost of a little more memory space, we did not have to follow<br />up so many links and so many pointers to find the right information,.<br />The result is that the programs ran about 33% faster.<br /><br />We have passed the compiler changes that we have made to Google.<br />Google is the original creator of the open-source V8 compiler.<br />They are considering the changes that we made. Hopefully, this will<br />help them improve their compiler and, therefore, speed-up the user's codes.<br /><br />Our work for published in an award-winning paper at a top conference.</p>\n<p>&nbsp;</p>\n<p>This work aimed at making fundamental advances toward designing a compiler for the programmable many-core for the year 2020. These many-cores are referred to as Extreme Scale because of their high integration. In particular, the main goal was to develop compiler support to drive an unconventional cache coherence protocol that relies on software directives.<br /><br />The Principal Investigator (PI) has developed a compiler that drives the support for software cache coherence in the proposed machine. The PI developed algorithms to automatically insert software cache coherence instructions into parallel applications. The instructions proposed were two: 1) invalidate an address, which invalidates a cache line that contains the address; and 2) write back an address, which writes back to a shared cache the cache line with that address. <br /><br />The work took a multi-pronged approach using several strategies:<br /><br />1) For memory accesses with affine index expressions, the PI developed compile-time analyses to precisely mark for invalidation only those variables that could become stale in the private cache due to other writes from other cores. Similarly, the PI developed analyses to precisely identify the data to be written back from the private caches to shared caches because other cores might need to access the data in future epochs. <br /><br />2) For repetitive irregular (non-affine) accesses, the PI introduced inspector-based schemes that exactly demarcate data for coherence management. Many scientific applications use sparse and irregular computations and are often iterative in nature and furthermore, the data access pattern remains the same across iterations.&nbsp; For such code, the PI proposed the use of inspectors to gather information on irregular data accesses so that coherence operations are applied only where necessary. The inspectors that are inserted in the parallel code are themselves parallel and are lock-free. <br /><br />3) Other irregular parallel applications were handled via methods that write back and invalidate all the non-read-only data in the caches across synchronization points. Specifically, at the beginning of an epoch, the entire private cache is invalidated and at the end of the epoch, all data that were written in the current epoch (dirty words) are written to the shared cache.<br /><br />Experimental evaluation over a number of benchmarks demonstrated that effective compiler techniques can make software cache coherence competitive with hardware coherence schemes both in terms of energy and performance.<br /><br />The PI also built upon his work on speeding-up JavaScript, which received a Distinguished Paper Award at PLDI in June 2014. Following-up on that work, the PI proposed to create chunks or transactions on the JavaScript codes using a runtime layer that supports speculation. The PI speculated on the most likely execution and optimized heavily. <br /><br />This work has also trained several students. Among them, Dr. Wooil Kim took a position at Samsung Electronics. In addition, the PI has given several talks on this topic at Intel.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/30/2014<br>\n\t\t\t\t\tModified by: Josep&nbsp;Torrellas</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMost of the programming in websites is done in JavaScript, which is\ncalled \"the language of the internet\". Many people write in this language\nand find that the performance is 10-100x lower than in conventional\nlanguages such as C and C++.\n\nTo understand the problem, we took over a year to analyze the best compiler\nthat currently exists for JavaScript, which is written by Google and it is\ncalled V8. We compiled and ran popular websites, such as Amazon and CBS News.\n\nThe results we found were very surprising. JavaScript creates many\nsoftware data strcutures as it generates the code, and as the code\nruns, it has to check these data structures to find the correct operations\nto perform. What we did is to streamline these data structures, so that\nat the cost of a little more memory space, we did not have to follow\nup so many links and so many pointers to find the right information,.\nThe result is that the programs ran about 33% faster.\n\nWe have passed the compiler changes that we have made to Google.\nGoogle is the original creator of the open-source V8 compiler.\nThey are considering the changes that we made. Hopefully, this will\nhelp them improve their compiler and, therefore, speed-up the user's codes.\n\nOur work for published in an award-winning paper at a top conference.\n\n \n\nThis work aimed at making fundamental advances toward designing a compiler for the programmable many-core for the year 2020. These many-cores are referred to as Extreme Scale because of their high integration. In particular, the main goal was to develop compiler support to drive an unconventional cache coherence protocol that relies on software directives.\n\nThe Principal Investigator (PI) has developed a compiler that drives the support for software cache coherence in the proposed machine. The PI developed algorithms to automatically insert software cache coherence instructions into parallel applications. The instructions proposed were two: 1) invalidate an address, which invalidates a cache line that contains the address; and 2) write back an address, which writes back to a shared cache the cache line with that address. \n\nThe work took a multi-pronged approach using several strategies:\n\n1) For memory accesses with affine index expressions, the PI developed compile-time analyses to precisely mark for invalidation only those variables that could become stale in the private cache due to other writes from other cores. Similarly, the PI developed analyses to precisely identify the data to be written back from the private caches to shared caches because other cores might need to access the data in future epochs. \n\n2) For repetitive irregular (non-affine) accesses, the PI introduced inspector-based schemes that exactly demarcate data for coherence management. Many scientific applications use sparse and irregular computations and are often iterative in nature and furthermore, the data access pattern remains the same across iterations.  For such code, the PI proposed the use of inspectors to gather information on irregular data accesses so that coherence operations are applied only where necessary. The inspectors that are inserted in the parallel code are themselves parallel and are lock-free. \n\n3) Other irregular parallel applications were handled via methods that write back and invalidate all the non-read-only data in the caches across synchronization points. Specifically, at the beginning of an epoch, the entire private cache is invalidated and at the end of the epoch, all data that were written in the current epoch (dirty words) are written to the shared cache.\n\nExperimental evaluation over a number of benchmarks demonstrated that effective compiler techniques can make software cache coherence competitive with hardware coherence schemes both in terms of energy and performance.\n\nThe PI also built upon his work on speeding-up JavaScript, which received a Distinguished Paper Award at PLDI in June 2014. Following-up on that work, the PI proposed to create chunks or transactions on the JavaScript codes using a runtime layer that supports speculation. The PI speculated on the most likely execution and optimized heavily. \n\nThis work has also trained several students. Among them, Dr. Wooil Kim took a position at Samsung Electronics. In addition, the PI has given several talks on this topic at Intel.\n\n\t\t\t\t\tLast Modified: 12/30/2014\n\n\t\t\t\t\tSubmitted by: Josep Torrellas"
 }
}