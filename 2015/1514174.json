{
 "awd_id": "1514174",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Medium: Collaborative Research: Computational Tools for Extracting Individual, Dyadic, and Network Behavior from Remotely Sensed Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 401937.0,
 "awd_amount": 409937.0,
 "awd_min_amd_letter_date": "2015-08-25",
 "awd_max_amd_letter_date": "2016-07-05",
 "awd_abstract_narration": "Recent technological advances in location tracking, video and photo capture, accelerometers, and other mobile sensors provide massive amounts of low-level data on the behavior of animals and humans.  Analysis of this data can teach us much about individual and group behavior, but analytical techniques that lead to insight about that behavior are still in their infancy.  In particular, these new data can provide an unprecedented window into the lives of wild animals, augmenting the traditional time-consuming first-hand observations from field biologists.  Unfortunately, the interpretation of low-level (i.e., unprocessed) data from animal-borne electronic sensors still poses a significant bottleneck in leveraging all of the available data to better understand the individual, pairwise, and group behavior of animal populations.  This project will develop tools for scaling the expert knowledge needed to interpret high-level behaviors from low-level sensor data using tools from statistical machine learning and network analysis.  These data and analytical tools promise to fundamentally change our understanding why animals do what they do, at high resolution and across multiple scales, from individuals to entire populations.  The results of the project will be applicable in many settings where massive sensor data is overwhelming traditional insight derived from observational approaches.  As part of the project, unique data on primate behavior that will bridge the low-level data and expert knowledge will be collected at Mpala Research Centre, Kenya. Undergraduate, graduate, and postdoctoral students from computer science and animal behavior will collaborate across continental and disciplinary boundaries. \r\n\r\nThe technical aims of this project include developing structured prediction methods that improve behavior recognition at multiple levels (individual, pair-wise, and group), using network properties to improve the identification of group activities, and advancing active learning in the structured prediction setting so that \"expensive\" expert knowledge and supplemental data collection will be judiciously utilized for maximum benefit in learning behavior recognition models.  Recognizing animal behavior from low-level sensor data is hierarchical in this approach, with individual activities recognized directly from data and the context of these data, the inferred individual activities informing pair-wise behavior recognition, and inferred pair-wise behavior informing group-level activity recognition. The benefits of improving the accuracy of individual and pair-wise behavior for recognizing group-level behavior will enable expert annotations to be requested that improve behavior recognition the most across all levels.  These advances will enable field-biologists to investigate new hypotheses about fundamental evolutionary, ecological, and population processes at scale without the burdens of complete manual annotation of collected data.  The methods will be applicable beyond field biology to understanding the hierarchy of behavior from individual entities to groups, from humans to cells, in scientific, educational, and business contexts. The team will leverage the interdisciplinary and international nature of the project to continue its ongoing work to increase participation of women and minorities in STEM research at undergraduate and graduate levels.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Margaret",
   "pi_last_name": "Crofoot",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Margaret Crofoot",
   "pi_email_addr": "mccrofoot@ucdavis.edu",
   "nsf_id": "000649222",
   "pi_start_date": "2015-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "Mpala Research Center",
  "perf_str_addr": "",
  "perf_city_name": "Nanyuki",
  "perf_st_code": "",
  "perf_st_name": "RI REQUIRED",
  "perf_zip_code": "",
  "perf_ctry_code": "KE",
  "perf_cong_dist": "",
  "perf_st_cong_dist": "",
  "perf_ctry_name": "Kenya",
  "perf_ctry_flag": "0"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 401937.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In gregarious organisms from protists to primates, the actions and interactions of group-mates combine to create emergent patterns of behavior that transform animals' environments and generate novel selection pressures that can drive the evolution of social complexity. How the group-level behaviors and traits that define complex animal societies emerge and are elaborated and maintained are questions of widespread, interdisciplinary interest because we ourselves are a hyper-social species with an unusual capacity for and reliance on coordinated group behavior. Long-term, observational research of individually recognized, habituated wild animals has proven a tremendously powerful approach for studying complex social systems. However, these methods have limitations that have made key questions about group-level behavior intractable. Advances in remote sensing may allow us overcome many of these limitations, as technologies like GPS tracking, proximity loggers and drone-based video tracking all generate vast quantities of detailed, noisy data about individual behavior in social contexts. However, our ability to collect remotely sensed data is rapidly outstripping our ability to make sense of it.</p>\n<p>In this project we developed an integrated, multi-sensor array that could be fit on wild primates to remotely track their behavior. The array consists of a collar and wristband that collect complementary data; integrated into the collar are high resolution GPS, 3-axis accelerometer and magnetometer sensors, as well as a microphone, while the wrist-band incorporates a 3-axis accelerometer, magnetometer and PIT-tag. Together, these sensors record the position, orientation and movement of the animal's body and hand, making it possible to infer a wide range of behavioral states. We fit our multi-sensor arrays to 31 baboons living Kenya, and collected ground-truthed data on the behaviors and activities of these individuals over a 1- month period. In collaboration with our co-PIs (Tanya Berger-Wolf and Brian Ziebart, Department of Computer Science, University of Illinois, Chicago), we used the data collected in the field to develop comprehensive and robust computational tools for extracting individual behaviors, dyadic interactions, and collective, group-level behaviors from the remotely sensed data traces that our multi-sensor arrays produced. These tools provide the foundation for a common framework for monitoring and analyzing the interactions--from dyad to group to population--that comprise the 'sociome'.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/19/2020<br>\n\t\t\t\t\tModified by: Margaret&nbsp;Crofoot</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1514174/1514174_10391947_1584613880262_Figure1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1514174/1514174_10391947_1584613880262_Figure1--rgov-800width.jpg\" title=\"Multi-sensor array for remotely tracking behavior\"><img src=\"/por/images/Reports/POR/2020/1514174/1514174_10391947_1584613880262_Figure1--rgov-66x44.jpg\" alt=\"Multi-sensor array for remotely tracking behavior\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Baboon wearing our multi-sensor array for remote behavior tracking, with examples of the data collected by the integrated sensors.</div>\n<div class=\"imageCredit\">Roi Harel</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Margaret&nbsp;Crofoot</div>\n<div class=\"imageTitle\">Multi-sensor array for remotely tracking behavior</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nIn gregarious organisms from protists to primates, the actions and interactions of group-mates combine to create emergent patterns of behavior that transform animals' environments and generate novel selection pressures that can drive the evolution of social complexity. How the group-level behaviors and traits that define complex animal societies emerge and are elaborated and maintained are questions of widespread, interdisciplinary interest because we ourselves are a hyper-social species with an unusual capacity for and reliance on coordinated group behavior. Long-term, observational research of individually recognized, habituated wild animals has proven a tremendously powerful approach for studying complex social systems. However, these methods have limitations that have made key questions about group-level behavior intractable. Advances in remote sensing may allow us overcome many of these limitations, as technologies like GPS tracking, proximity loggers and drone-based video tracking all generate vast quantities of detailed, noisy data about individual behavior in social contexts. However, our ability to collect remotely sensed data is rapidly outstripping our ability to make sense of it.\n\nIn this project we developed an integrated, multi-sensor array that could be fit on wild primates to remotely track their behavior. The array consists of a collar and wristband that collect complementary data; integrated into the collar are high resolution GPS, 3-axis accelerometer and magnetometer sensors, as well as a microphone, while the wrist-band incorporates a 3-axis accelerometer, magnetometer and PIT-tag. Together, these sensors record the position, orientation and movement of the animal's body and hand, making it possible to infer a wide range of behavioral states. We fit our multi-sensor arrays to 31 baboons living Kenya, and collected ground-truthed data on the behaviors and activities of these individuals over a 1- month period. In collaboration with our co-PIs (Tanya Berger-Wolf and Brian Ziebart, Department of Computer Science, University of Illinois, Chicago), we used the data collected in the field to develop comprehensive and robust computational tools for extracting individual behaviors, dyadic interactions, and collective, group-level behaviors from the remotely sensed data traces that our multi-sensor arrays produced. These tools provide the foundation for a common framework for monitoring and analyzing the interactions--from dyad to group to population--that comprise the 'sociome'.\n\n \n\n\t\t\t\t\tLast Modified: 03/19/2020\n\n\t\t\t\t\tSubmitted by: Margaret Crofoot"
 }
}