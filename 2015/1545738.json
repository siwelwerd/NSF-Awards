{
 "awd_id": "1545738",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Monte Carlo Methods for Analysis of Large Spatial Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2015-03-02",
 "awd_exp_date": "2015-07-31",
 "tot_intn_awd_amt": 38829.0,
 "awd_amount": 38829.0,
 "awd_min_amd_letter_date": "2015-05-26",
 "awd_max_amd_letter_date": "2015-05-26",
 "awd_abstract_narration": "Spatial data sets are analyzed in many scientific disciplines, such as ecology, geology, and environmental sciences.  However, the classical approaches, such as Kriging and Bayesian hierarchical Gaussian modeling, often break down for large data sets due to expensive matrix inverse operations, whose computational complexity increases in cubic order with the number of spatial locations. To alleviate this difficulty, various approximation approaches, such as covariance tapering,  lower-dimensional space spatial process approximation, likelihood approximation and Markov random field approximations, have been proposed under the general idea of approximating the original spatial model with a computationally convenient model. A general concern on these approaches is the adequacy of approximation. In this proposal, the investigators propose three new approaches, Bayesian auxiliary lattice approach, Bayesian site selection approach and marginal inference approach. The Bayesian auxiliary lattice approach introduces an auxiliary lattice to the space of observations and defines a hidden Gaussian Markov random field on the auxiliary lattice.  By using some analytical results of Gaussian Markov random fields,  the Bayesian auxiliary lattice approach completely avoids the problem of matrix inversion in likelihood evaluation. The Bayesian site selection approach reformulates the problem of spatial model estimation as a problem of Bayesian variable selection. It works with only a small proportion of the data at each iteration and thus significantly reduces the dimension of the data. The marginal inference approach is proposed based on the idea of bootstrap resampling. Like the Bayesian site selection approach, it works with only a small proportion of the data at each iteration and thus significantly reduces the dimension of the data. It is worth noting that the Bayesian site selection and marginal inference approaches are conceptually very different from the approximation approaches existing in the literature. The existing approximation approaches are to approximate the original model using a computationally convenient model. Instead, the Bayesian site selection and marginal inference approaches seek to reduce the dimension of the data,  while not sacrificing the complexity of the original model. In this proposal, the investigators also extend the proposed approaches to spatio-temporal models with applications to satellite climate data. How to deal with missing data for spatio-temporal models are addressed.\r\n\r\nThe intellectual merit of this project is to provide some computationally efficient or data dimension reduction approaches for statistical analysis of large spatial data. The new approaches address some core problems in spatial data analysis, such as large matrix inversion and missing data imputation. The new approaches are expected to play a major role in statistical analysis of geostatistical data, satellite climate data and other large spatial data. This project will have broader impacts in both communities of spatial statistics and computational atmospheric sciences. The research results will be disseminated to the communities via direct collaboration with researchers in other disciplines, conference presentations, books, and papers to be published in academic journals.  The project will have also significant impacts on education through direct \r\ninvolvement of graduate students in the project and incorporation of results into undergraduate and graduate courses.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Faming",
   "pi_last_name": "Liang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Faming Liang",
   "pi_email_addr": "fmliang@purdue.edu",
   "nsf_id": "000490214",
   "pi_start_date": "2015-05-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1 UNIVERSITY OF FLORIDA",
  "perf_city_name": "GAINESVILLE",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326112002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 38829.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Spatial data sets are analyzed in many scientific disciplines, such as ecology, geology, and environmental sciences. However, the classical approaches, such as kriging and Bayesian hierarchical Gaussian<br />modeling, often break down for large data sets due to expensive matrix inverse operations, whose computational complexity increases in cubic order with the number of spatial locations. To alleviate this difficulty, various approaches, such as covariance tapering, lower-dimensional space spatial process approximation, likelihood approximation and Markov random field approximations, have been proposed under the idea of approximating the original spatial model with a computationally convenient model. A general concern on these approaches is the adequacy of approximation.</p>\n<p>Under this project, the investigators and their coauthors mainly developed three new approaches, including Bayesian auxiliary lattice approach, Bayesian site selection approach, and the resampling-based stochastic approximation approach, to address the above difficulty and concern. The Bayesian auxiliary lattice approach, which was developed in Park and Liang (2012,Journal of Computational and Graphical Statistics,&nbsp; 21, 453-475 ),&nbsp; introduces an auxiliary lattice to the space of observations and defines a hidden Gaussian Markov random field on the auxiliary lattice. By using some analytical results of Gaussian Markov random fields, the Bayesian auxiliary lattice approach completely avoids the problem of matrix inversion in likelihood evaluation and is thus computationally efficient. This approach has been extended to the spatio-temporal data by Xu, Liang and Genton (2015, Statistica Sinica, in press) with applications to real climate data analysis.</p>\n<p>The Bayesian site selection approach, developed in Park and Liang (2013, Journal of Statistical Research, 47, 11-30), reformulates the problem of spatial model estimation as a problem of Bayesian variable selection. It &nbsp;works with a small proportion of the data, which are selected under a Bayesian framework, at each iteration and thus significantly reduces the dimension of the data. This approach has been successfully extended to Gaussian process regression by Pourhabib, Liang and Ding (2014, IIE Transactions, 46, 543-555).</p>\n<p>The resampling-based stochastic approximation approach, developed in Liang, Chwen, Song, Park and Yang (2013, Journal of the American Statistical Association, 108, 325-339), works with the techniques of subsampling and stochastic approximation. &nbsp;A<span>t each iteration of this approach, a small subsample is drawn from the full dataset, and then the current estimate of the parameters is updated accordingly under the frameworkof stochastic approximation. Since it makes use of only a small proportion of the data at each iteration, it avoids inverting large covariance matrices and thus is scalable to large datasets. The resampling-based stochastic approximation approach has led to a general parameter estimation approach,maximum mean log-likelihood estimation, which includes the popular maximum (log)-likelihood estimation (MLE) approach as a special case and is expected to play an important role in parameter estimation for big data problems. </span>&nbsp;Therefore, it &nbsp;potentially impacts on many other scientific disciplines where big data are involved,such as social science and biomedical science.&nbsp;</p>\n<p>It is worth noting that the Bayesian site selection and resampling-based stochastic approximation approaches are conceptually very different from the approximation approaches existing in the literature. The existing approximation approaches are to approximate the original model using a computationally convenient model. Instead, the Bayesian site selection and resampling-based stochastic approximation approaches seek to reduce the dimension of the data, while not sacrificing the complexi...",
  "por_txt_cntn": "\nSpatial data sets are analyzed in many scientific disciplines, such as ecology, geology, and environmental sciences. However, the classical approaches, such as kriging and Bayesian hierarchical Gaussian\nmodeling, often break down for large data sets due to expensive matrix inverse operations, whose computational complexity increases in cubic order with the number of spatial locations. To alleviate this difficulty, various approaches, such as covariance tapering, lower-dimensional space spatial process approximation, likelihood approximation and Markov random field approximations, have been proposed under the idea of approximating the original spatial model with a computationally convenient model. A general concern on these approaches is the adequacy of approximation.\n\nUnder this project, the investigators and their coauthors mainly developed three new approaches, including Bayesian auxiliary lattice approach, Bayesian site selection approach, and the resampling-based stochastic approximation approach, to address the above difficulty and concern. The Bayesian auxiliary lattice approach, which was developed in Park and Liang (2012,Journal of Computational and Graphical Statistics,  21, 453-475 ),  introduces an auxiliary lattice to the space of observations and defines a hidden Gaussian Markov random field on the auxiliary lattice. By using some analytical results of Gaussian Markov random fields, the Bayesian auxiliary lattice approach completely avoids the problem of matrix inversion in likelihood evaluation and is thus computationally efficient. This approach has been extended to the spatio-temporal data by Xu, Liang and Genton (2015, Statistica Sinica, in press) with applications to real climate data analysis.\n\nThe Bayesian site selection approach, developed in Park and Liang (2013, Journal of Statistical Research, 47, 11-30), reformulates the problem of spatial model estimation as a problem of Bayesian variable selection. It  works with a small proportion of the data, which are selected under a Bayesian framework, at each iteration and thus significantly reduces the dimension of the data. This approach has been successfully extended to Gaussian process regression by Pourhabib, Liang and Ding (2014, IIE Transactions, 46, 543-555).\n\nThe resampling-based stochastic approximation approach, developed in Liang, Chwen, Song, Park and Yang (2013, Journal of the American Statistical Association, 108, 325-339), works with the techniques of subsampling and stochastic approximation.  At each iteration of this approach, a small subsample is drawn from the full dataset, and then the current estimate of the parameters is updated accordingly under the frameworkof stochastic approximation. Since it makes use of only a small proportion of the data at each iteration, it avoids inverting large covariance matrices and thus is scalable to large datasets. The resampling-based stochastic approximation approach has led to a general parameter estimation approach,maximum mean log-likelihood estimation, which includes the popular maximum (log)-likelihood estimation (MLE) approach as a special case and is expected to play an important role in parameter estimation for big data problems.  Therefore, it  potentially impacts on many other scientific disciplines where big data are involved,such as social science and biomedical science. \n\nIt is worth noting that the Bayesian site selection and resampling-based stochastic approximation approaches are conceptually very different from the approximation approaches existing in the literature. The existing approximation approaches are to approximate the original model using a computationally convenient model. Instead, the Bayesian site selection and resampling-based stochastic approximation approaches seek to reduce the dimension of the data, while not sacrificing the complexity of the original model.\n\nThe proposed approaches have been successfully applied to analysis of various spatial and spatio-temporal datase..."
 }
}