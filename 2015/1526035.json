{
 "awd_id": "1526035",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Collaborative Research: Modeling Social Context to Improve Human-Robot Interaction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2015-08-20",
 "awd_max_amd_letter_date": "2015-08-20",
 "awd_abstract_narration": "For robots to be truly useful to people, it is critical that they be able to understand and operate independently in human social environments (HSEs).  Decades of research into this problem by many investigators have to date failed to yield a solution.  The PIs on this collaborative project that spans two partner institutions argue that a fundamental paradigm shift is necessary to enable progress, and that this shift can be ignited through a contextually driven approach to mobile robotics.  Thus, the goal of this proposal is to create and evaluate new models of social context in order to enable mobile robots to interact appropriately with people in HSEs.  Project outcomes will help give all \"things that think\", from social robots to smart homes, a better understanding of human social context and a greater capability to operate effectively in real-world human spaces.  By contributing new theoretical models, techniques, and open source implementations that will accelerate the development and adoption of machines that operate in HSEs, the PIs anticipate this work will have a transformative impact on many fields within computer and information science, including robotics, human-machine interaction, and ubiquitous computing.  The PIs also will make their context models available to other researchers.  \r\n\r\nThe PIs' approach to context is unique in that, rather than being techno-centric and entirely representational, it fully adopts Dourish's approach to an interactional model of context inspired by the social sciences - relational, dynamic, occasioned, and arising from activity - i.e., fluid.  The key contribution of the approach is that it ties real-time sensor data to models of situational context, which then inform a robot of the social affordances of the environment.  The PIs will engage in two primary research activities.  First, they will create a situational context processing capability that can accept a multimodal, social scene snapshot from a robot and return back a situational context frame (SCF) that contains an estimate of the scene's salient objects, social activities, and situational context.  Then, they will contribute algorithmic techniques that enable a robot to leverage the SCF to perform guided exploration to refine its model, and ultimately, goal-driven task execution adapted to conform to social norms.  The PIs' research emphasis on using solely naturalistic, real-world, multimodal data, will enable them to make unique contributions for increasing robustness in multimodal processing.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ross",
   "pi_last_name": "Knepper",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Ross A Knepper",
   "pi_email_addr": "rak@cs.cornell.edu",
   "nsf_id": "000662752",
   "pi_start_date": "2015-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "Gates Hall",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148537501",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project investigated socially-competent robot navigation in human settings.&nbsp; Many state-of-the-art robot navigation planners operate based on randomized algorithms, which can produce unpredictable motions that are hard for humans to understand or react to.&nbsp; In contrast, this project examined models and methods for producing robot behavior that is natural to human observers and appears easy to predict and adapt to.</p>\n<p>The fundamental method is based on the idea that humans navigate through space relative to each other as well as obstacles in their environment.&nbsp; If one person needs to shift to the side while passing, other people will fluidly shift as well to make room.&nbsp; Thus, the paths followed by people are able to grow and stretch like elastic.&nbsp; Traditional robot path planners attempt to follow paths rigidly.&nbsp; In this project, all robot paths are elastic and can flex in response to the movement of others.</p>\n<p>In addition, it is important for robots to reason about the intentions of human navigators.&nbsp; If a person wants to pass on the right, the robot should comply with that intention unless there is a good reason to do the opposite.&nbsp; Similarly, the robot ought to express its intended passing side.&nbsp; This kind of intent expression can be accomplished by modifying the shape of the path to suggest moving to one side over the other.&nbsp; People are able to reason about the behavior of several other navigating people simultaneously, and so we have provided our robots with a representation of the moving people in their environment that can handle multiple passings occurring in different orders quite flexibly.</p>\n<p>The robot is able to track the motions of multiple people, prediction their future behavior, form an intention about its own motion, find a plan that complies with the predicted intentions of the humans, and then move in such a way to comply with those motions while simultaneously expressing its own intentions.</p>\n<p>The project produced mathematical models, software for predictve models and planners, training data for machine learning models, simulation studies,&nbsp;a real robot implementation on a BeamPro telepresence robot platform,&nbsp;and a live human user study.&nbsp; The final study examined how the robot performs when navigating among several humans in close quarters while performing a task.&nbsp; The algorithms produced by this project were compared against other state-of-the-art approaches according to multiple quantitative and qualitative metics.&nbsp; The research results from this project were published in top, peer-reviewed venues appropriate for human-robot interaction research, including a journal and conferences.</p>\n<p>Two graduate students completed their theses based on the work performed on this project.&nbsp; Four undergraduates also worked on the project and learned important skills about robotic technologies as well as good research conduct.</p>\n<p>As a result of this project, robots are able to move in a manner that is intuitive and intent-expressive to human observers.&nbsp; In the future, many more robots are expected to operate and move within human spaces, and so this technology will become increasingly necessary.&nbsp; As a result of this project, other researchers as well as companies and individuals will be able to download code and use the project's results to develop their own socially-competent robot navigators.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/04/2019<br>\n\t\t\t\t\tModified by: Ross&nbsp;A&nbsp;Knepper</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project investigated socially-competent robot navigation in human settings.  Many state-of-the-art robot navigation planners operate based on randomized algorithms, which can produce unpredictable motions that are hard for humans to understand or react to.  In contrast, this project examined models and methods for producing robot behavior that is natural to human observers and appears easy to predict and adapt to.\n\nThe fundamental method is based on the idea that humans navigate through space relative to each other as well as obstacles in their environment.  If one person needs to shift to the side while passing, other people will fluidly shift as well to make room.  Thus, the paths followed by people are able to grow and stretch like elastic.  Traditional robot path planners attempt to follow paths rigidly.  In this project, all robot paths are elastic and can flex in response to the movement of others.\n\nIn addition, it is important for robots to reason about the intentions of human navigators.  If a person wants to pass on the right, the robot should comply with that intention unless there is a good reason to do the opposite.  Similarly, the robot ought to express its intended passing side.  This kind of intent expression can be accomplished by modifying the shape of the path to suggest moving to one side over the other.  People are able to reason about the behavior of several other navigating people simultaneously, and so we have provided our robots with a representation of the moving people in their environment that can handle multiple passings occurring in different orders quite flexibly.\n\nThe robot is able to track the motions of multiple people, prediction their future behavior, form an intention about its own motion, find a plan that complies with the predicted intentions of the humans, and then move in such a way to comply with those motions while simultaneously expressing its own intentions.\n\nThe project produced mathematical models, software for predictve models and planners, training data for machine learning models, simulation studies, a real robot implementation on a BeamPro telepresence robot platform, and a live human user study.  The final study examined how the robot performs when navigating among several humans in close quarters while performing a task.  The algorithms produced by this project were compared against other state-of-the-art approaches according to multiple quantitative and qualitative metics.  The research results from this project were published in top, peer-reviewed venues appropriate for human-robot interaction research, including a journal and conferences.\n\nTwo graduate students completed their theses based on the work performed on this project.  Four undergraduates also worked on the project and learned important skills about robotic technologies as well as good research conduct.\n\nAs a result of this project, robots are able to move in a manner that is intuitive and intent-expressive to human observers.  In the future, many more robots are expected to operate and move within human spaces, and so this technology will become increasingly necessary.  As a result of this project, other researchers as well as companies and individuals will be able to download code and use the project's results to develop their own socially-competent robot navigators.\n\n\t\t\t\t\tLast Modified: 01/04/2019\n\n\t\t\t\t\tSubmitted by: Ross A Knepper"
 }
}