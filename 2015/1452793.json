{
 "awd_id": "1452793",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER: Real-Time 3D Reconstruction and Manipulation for Underwater Intervention - A Career Development Plan",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2015-02-01",
 "awd_exp_date": "2020-01-31",
 "tot_intn_awd_amt": 531916.0,
 "awd_amount": 531916.0,
 "awd_min_amd_letter_date": "2015-01-23",
 "awd_max_amd_letter_date": "2015-01-23",
 "awd_abstract_narration": "Underwater robotic vehicles like AUVs (Autonomous Underwater Vehicles) and ROVs (Remotely Operated Vehicles) have occasion to interact with the environment in many tasks including deep-water science, resource extraction, and sub-sea construction, and maintenance. Crucial to these tasks is the ability to interpret the operating environment to ensure safety and effectiveness. This project proposes the development of algorithms for quickly constructing 3D models of the environment from pictures and video obtained with an underwater camera.  In the short term, this means augmenting how humans control AUVs and ROVs.  In the long term, the PI's career plan aims to produce systems that can safely interact with the environment without direct human control. Beyond the technical goals, this proposal lays out a plan for education and outreach to encourage, foster, and promote both engineering science and marine exploration to a broad audience.\r\n\r\nReal-time underwater 3D reconstruction is an enabling technology for many other research areas, including manipulation, navigation, obstacle avoidance, intelligent sampling, and adaptive surveying. This career development plan approaches the general vision problem by analyzing the constraints imposed by the underwater domain. The PI proposes a principled approach for online 3D reconstruction that handles both the propagation of light in water and a formulation that includes prior shape knowledge. Additionally, scene understanding is framed to allow for the segmentation and classification of underwater optical data based upon a joint model of the 3D structure and the photometric properties of the scene using a state-of-the-art dimensionality reduction approach.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Johnson-Roberson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew Johnson-Roberson",
   "pi_email_addr": "mkj@andrew.cmu.edu",
   "nsf_id": "000649944",
   "pi_start_date": "2015-01-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "3003 South State St. Room 1062",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091274",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 531916.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>There have been huge advances in machine learning that have touched many aspects of terrestrial, business, robotics, entertainment and beyond.&nbsp; However, machine learning as applied to the underwater domain has been much more limited. This CAREER grant has enabled us to produce tangible results for the application of neural networks to understand the underwater environment. Specifically, we&rsquo;ve produced techniques that take camera imagery and remove the distortion and color effects of water and restore the images for human viewing and machine use. Furthermore, we have produced approaches that estimate the depth of objects in a scene which gives robots a 3D understanding of the underwater world.</p>\n<p>Several field expeditions were mounted during this time, notably data was gathered in Bermuda and Jamaica looking at environmental monitoring of coral reefs and archaeological excavation of a sunken city. The fundamental science developed through this grant has gone to enhance and process the data used in these science applications. From an outreach perspective this grant enabled us to collaborate with GoGirl in Detroit and run a successful experiential learning program for middle and high school girls to give hands on experience in STEM research. The graduate students supported on this grant worked directly with the students to develop, build and experiment with their own underwater robotics vehicle, deploy the vehicle locally to help understand the local marine environment.</p>\n<p>&nbsp;</p>\n<p>The perception techniques developed go directly towards furthering the broader impacts of the grant in enabling more autonomous ROV intervention.&nbsp; Several of them will deployed on an ROV in Greece in the coming year showing the direct utility of the proposed work.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/10/2020<br>\n\t\t\t\t\tModified by: Matthew&nbsp;Johnson-Roberson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThere have been huge advances in machine learning that have touched many aspects of terrestrial, business, robotics, entertainment and beyond.  However, machine learning as applied to the underwater domain has been much more limited. This CAREER grant has enabled us to produce tangible results for the application of neural networks to understand the underwater environment. Specifically, we\u2019ve produced techniques that take camera imagery and remove the distortion and color effects of water and restore the images for human viewing and machine use. Furthermore, we have produced approaches that estimate the depth of objects in a scene which gives robots a 3D understanding of the underwater world.\n\nSeveral field expeditions were mounted during this time, notably data was gathered in Bermuda and Jamaica looking at environmental monitoring of coral reefs and archaeological excavation of a sunken city. The fundamental science developed through this grant has gone to enhance and process the data used in these science applications. From an outreach perspective this grant enabled us to collaborate with GoGirl in Detroit and run a successful experiential learning program for middle and high school girls to give hands on experience in STEM research. The graduate students supported on this grant worked directly with the students to develop, build and experiment with their own underwater robotics vehicle, deploy the vehicle locally to help understand the local marine environment.\n\n \n\nThe perception techniques developed go directly towards furthering the broader impacts of the grant in enabling more autonomous ROV intervention.  Several of them will deployed on an ROV in Greece in the coming year showing the direct utility of the proposed work.\n\n \n\n\t\t\t\t\tLast Modified: 06/10/2020\n\n\t\t\t\t\tSubmitted by: Matthew Johnson-Roberson"
 }
}