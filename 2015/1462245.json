{
 "awd_id": "1462245",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER-DynamicData: Real-time Discovery and Timely Event Detection from Dynamic and Multi-Modal Data Streams",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Lawrence Goldberg",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 266773.0,
 "awd_amount": 266773.0,
 "awd_min_amd_letter_date": "2015-09-04",
 "awd_max_amd_letter_date": "2015-09-04",
 "awd_abstract_narration": "Emergency responders (police, fire, ambulance services) have more and more access to more and more data stream: sensor readings, security cameras, personal reports (via cellphone, texts, tweets), GPS data etc. The availability of these data streams presents enormous opportunities - but also poses fundamental challenges:\r\n* Data streams arrive from a wide variety of sources and contain many diverse features; this makes it difficult to extract information from the streams, and especially, to integrate information from different streams.   \r\n* Knowledge learned from past events must be transferred to knowledge about present (and future) events.  Because no two events are ever identical, the knowledge learned from past events must be transferred to knowledge about present events that are not identical but only \"similar\" - and in ways that may not be known in advance and so must be discovered. \r\n* Learning and detection - and the actions that follow learning and detection ? must take place in a timely fashion: it is of little use to learn how to respond to an emergency only long after the emergency has passed.  \r\nTo accomplish this, the proposed work relies on new methods to discover what is relevant both in each individual data stream and across data streams, and to learn and exploit the similarities between the past and the present.  This work is transformative and success in this project has the potential to lead to enormously enhanced, even life-saving, responses to emergencies of many sorts. \r\n\r\nExisting approaches treat individual data streams by exploiting particular physical characteristics of the signal, and treat multiple data streams in an ad-hoc fashion.  These approaches miss the fact that it is not the physical characteristics of the signal that are important but rather the (semantic) information in the signal, and that there are connections between the information in different data streams. This project transforms the problem of learning from multiple (multi-modal) data streams by focusing on the relevance of information in each data stream, across data streams, and through time.  The relevant information will generally be different for different events and different purposes and will not be known in advance, so relevance must be learned.  To do this, this project organizes the information available at each moment in time in terms of contexts which encode exogenous metadata (e.g., when, where and by whom data was gathered) and endogenous metadata (e.g., features and statistics extracted from the data). In general, there are an enormous number and variety of contexts, but the most relevant information is embedded in only a few contexts. Because these most relevant contexts will not generally be known in advance and will be different in different scenarios, this project will develop a new class of methods and algorithms to discover the relevant contexts from multiple dynamic, multi-modal and high-dimensional data streams, and to use what is discovered to learn, detect and respond in a timely fashion.  Because no two events are exactly the same, this project will develop of a new class of methods and algorithms for the discovery of relevant semantic similarities and their application, making it possible to transfer knowledge learned from past events to knowledge about present events. This work requires the development of highly innovative methodology and techniques that go far beyond existing work (high risk) and are potentially transformative for a wide variety of applications ranging from event detection to actionable intelligence.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mihaela",
   "pi_last_name": "van der Schaar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mihaela van der Schaar",
   "pi_email_addr": "mihaela@ee.ucla.edu",
   "nsf_id": "000152646",
   "pi_start_date": "2015-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900951594",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "153E",
   "pgm_ref_txt": "Wireless comm & sig processing"
  },
  {
   "pgm_ref_code": "5384",
   "pgm_ref_txt": "DATA AND DATA SYSTEMS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 266773.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Emergency responders (e.g. in healthcare settings) have ever more access to more and more dynamic data streams. This presents an enormous opportunity for enhanced response to emergencies of many kinds but exploiting these opportunities presents significant and unique challenges: 1) the available information often arrives from a variety of dynamic, multi-modal and high-dimensional sources and has diverse features so that learning from all the sources is extremely difficult; 2) no two events are ever exactly the same so the knowledge gained from past events must be transferred to knowledge about present/future events, even though the past events and the present/future events are not identical, but only &ldquo;similar&rdquo;; 3) detection and response need to be performed in a timely fashion.</p>\n<p>To address these unique challenges, this NSF funded project developed and successfully exploited two key ideas: the first is <em>discovering relevance</em> to extract knowledge from the various dynamic data streams and the second is <em>exploiting similarities</em> to transfer knowledge. Much existing work deals with high-dimensional data streams by assuming and then exploiting particular characteristics of the signal (e.g. sparsity). Moreover, existing work treats mixed data stream modalities either separately or in an ad-hoc fashion, thereby missing the connection between the information in different data streams. The key to our success in this NSF project was the recognition that what is important is not the characteristics of the signal (e.g. sparsity) but rather the understanding of the <em>relevance of information</em> in the signal within a single data stream, across multiple data streams and modalities, and through time. The relevant information may be different for different events and different purposes (learning, detection, response) and will not be known in advance &ndash; so our methods learn this. &nbsp;To do this, we organized the information available at each moment in time&nbsp;such as when, where and by whom data was gathered, and endogenous metadata such as features and statistics extracted from the data etc. In general, there are an enormous number and variety of contexts, but the most relevant information is embedded in only a few contexts. If these most relevant contexts were known in advance, learning, detection and response would be relatively simple &ndash; but they are not. Moreover, the relevant contexts are different in different scenarios. We developed in this NSF project a new class of methods and algorithms aimed at <em>discovering the relevant contexts</em> from multiple dynamic, multi-modal and high-dimensional data streams &ndash; and using what is discovered to learn, detect and respond in a timely fashion. We have applied our methods to various real-life scenarios, including early warning systems for patient deterioration in the hospital.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/11/2019<br>\n\t\t\t\t\tModified by: Mihaela&nbsp;Van Der Schaar</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nEmergency responders (e.g. in healthcare settings) have ever more access to more and more dynamic data streams. This presents an enormous opportunity for enhanced response to emergencies of many kinds but exploiting these opportunities presents significant and unique challenges: 1) the available information often arrives from a variety of dynamic, multi-modal and high-dimensional sources and has diverse features so that learning from all the sources is extremely difficult; 2) no two events are ever exactly the same so the knowledge gained from past events must be transferred to knowledge about present/future events, even though the past events and the present/future events are not identical, but only \"similar\"; 3) detection and response need to be performed in a timely fashion.\n\nTo address these unique challenges, this NSF funded project developed and successfully exploited two key ideas: the first is discovering relevance to extract knowledge from the various dynamic data streams and the second is exploiting similarities to transfer knowledge. Much existing work deals with high-dimensional data streams by assuming and then exploiting particular characteristics of the signal (e.g. sparsity). Moreover, existing work treats mixed data stream modalities either separately or in an ad-hoc fashion, thereby missing the connection between the information in different data streams. The key to our success in this NSF project was the recognition that what is important is not the characteristics of the signal (e.g. sparsity) but rather the understanding of the relevance of information in the signal within a single data stream, across multiple data streams and modalities, and through time. The relevant information may be different for different events and different purposes (learning, detection, response) and will not be known in advance &ndash; so our methods learn this.  To do this, we organized the information available at each moment in time such as when, where and by whom data was gathered, and endogenous metadata such as features and statistics extracted from the data etc. In general, there are an enormous number and variety of contexts, but the most relevant information is embedded in only a few contexts. If these most relevant contexts were known in advance, learning, detection and response would be relatively simple &ndash; but they are not. Moreover, the relevant contexts are different in different scenarios. We developed in this NSF project a new class of methods and algorithms aimed at discovering the relevant contexts from multiple dynamic, multi-modal and high-dimensional data streams &ndash; and using what is discovered to learn, detect and respond in a timely fashion. We have applied our methods to various real-life scenarios, including early warning systems for patient deterioration in the hospital.\n\n\t\t\t\t\tLast Modified: 10/11/2019\n\n\t\t\t\t\tSubmitted by: Mihaela Van Der Schaar"
 }
}