{
 "awd_id": "1533644",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS: FULL: FP: A profile-centric IDE for science-based performance engineering in the cloud",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2015-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 750000.0,
 "awd_amount": 2195770.0,
 "awd_min_amd_letter_date": "2015-08-26",
 "awd_max_amd_letter_date": "2020-10-15",
 "awd_abstract_narration": "Scientists developing compute-intensive multicore applications find it difficult to parallelize their code, a problem that is exacerbated if they wish to take maximum advantage of the potential provided by cloud computing.  Part of the problem is that bad codes cause the generation of incorrect hypotheses while reading, writing, and debugging code, wasting time, energy, and resources.   \r\n\r\nThis research plans to meld advanced profiling methods for multithreaded programming with modern user-interface technology to produce a highly usable open-source integrated development environment (IDE) for the performance-engineering of multicore software applications in the cloud.  The goal is to provide programmers with continuous profile data for scalability and other performance profiling relevant to parallel programming.  They plan to embed an IDE into a profiling framework to produce a profile-centric IDE, continuously providing performance feedback so that developers can see and compare the results of recent runs of their program as they edit their code.\r\n\r\nThe project has the potential to enable science-based performance engineering of multicore applications in the cloud.  The vast majority of computer users, not just expert computer scientists, will be able to develop highly efficient parallel software applications, broadly impacting every computing application in every walk of life.  The software produced by this project will be made freely available to anyone on the World Wide Web using a liberal open-source license.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Charles",
   "pi_last_name": "Leiserson",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Charles E Leiserson",
   "pi_email_addr": "cel@csail.mit.edu",
   "nsf_id": "000114754",
   "pi_start_date": "2015-08-26",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Miller",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Robert C Miller",
   "pi_email_addr": "rcm@mit.edu",
   "nsf_id": "000222423",
   "pi_start_date": "2015-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachussetts Avenue",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8237",
   "pgm_ref_txt": "CISE Interagency Agreements"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 750000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 420615.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 605215.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 419940.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-e60b1f08-7fff-d621-f8d5-09f452f7a8e8\"> </span></p>\n<p dir=\"ltr\"><span>This award supported a wide variety of advancements in computer science, especially in the areas of parallel computing and software performance engineering.&nbsp; These advancements span multiple areas, including tools for analyzing parallel programs; novel parallel algorithms; software systems for parallel computing and program analysis; and theoretical foundations of computer science.&nbsp; The award supported over 70 publications, including 5 award-winning publications, 3 PhD theses, and 1 Masters of Engineering thesis.</span></p>\n<p dir=\"ltr\"><span>We highlight several key advancements supported by this award.</span></p>\n<p dir=\"ltr\"><span>We designed and implemented an initial version of the Cilkpride integrated development environment (IDE), building on top of the Atom programming editor.&nbsp; Cilkpride incorporates automatic background execution of the Cilksan determinacy-race detector.&nbsp; As the programmer edits, the IDE automatically schedules test runs with Cilksan in the background and puts error markers next to source code lines that exhibit races.&nbsp; This work is a first step towards always-on parallel program analysis. The IDE has been used by students in the 6.172/6.871 Performance Engineering of Software Systems course at MIT.</span></p>\n<p dir=\"ltr\"><span>Since flexibility in supporting parallelism is an important requirement of the Cilkpride environment, we studied compiler intermediate representations (IRs) of task parallelism that support the development of efficient program-analysis tools, such as memory checkers, race detectors, and performance profilers.&nbsp; We developed Tapir, a compiler IR that embeds task parallelism into a mainstream compiler IR.&nbsp; Mainstream compilers typically treat parallel language constructs as syntactic sugar for function calls into a parallel runtime.&nbsp; These calls prevent the compiler from effectively analyzing and optimizing software across parallel control constructs.&nbsp; Tapir leverages the ?serial-projecting property,? which is commonly satisfied by task-parallel programs, to handle task-parallel semantics without an extensive rework of the compiler internals.&nbsp; By embedding task parallelism into the compiler IR, Tapir enables the compiler to effectively analyze and optimize task-parallel programs.&nbsp; In addition, Tapir provides a simple representation of task-parallelism that is easy for dynamic-analysis tools to use to understand parallelism.&nbsp; Tapir was published in ACM PPoPP 2017, where it won the Best Paper Award.</span></p>\n<p dir=\"ltr\"><span>To make building dynamic analysis tools for Cilkpride easier, we created the CSI framework for compiler-inserted program instrumentation.&nbsp; CSI provides comprehensive static instrumentation that a compiler can insert into a program-under-test so that dynamic-analysis tools can observe and investigate runtime behavior.&nbsp; Traditionally, tools based on compiler instrumentation would each separately modify the compiler to insert their own instrumentation.&nbsp; In contrast, CSI inserts a standard collection of instrumentation hooks into the program-under-test. Each CSI-tool is implemented as a library that defines relevant hooks, and unused hooks are ?nulled? out and elided during either compile-time or link-time optimization, resulting in instrumented runtimes on par with custom instrumentation.&nbsp; We used CSI to implement a variety of tools that use compiler instrumentation, including performance profilers, code-coverage analyzers, and a port of Google?s ThreadSanitizer.&nbsp; We observed that these CSI tools exhibit minimal overheads due to program instrumentation.&nbsp; CSI was published at ACM SIGMETRICS 2018.</span></p>\n<p dir=\"ltr\"><span>Using the CSI framework, we developed a new dynamic-analysis tool, called Cilkmem, that can be incorporated into Cilkpride.&nbsp; Software engineers designing parallel programs destined to run on massively parallel computing systems must be cognizant of how their program's memory requirements scale in a many-processor execution. Although tools exist for measuring memory usage during one particular execution of a parallel program, such tools cannot bound the worst-case memory usage over all possible parallel executions.&nbsp; Cilkmem analyzes the execution of a deterministic Cilk program to determine its parallel memory high-water mark, which is the worst-case memory usage of the program over all possible parallel executions.&nbsp; Cilkmem employs two new memory-efficient algorithms to measure the memory high-water mark either exactly, though more slowly, or approximately and more quickly.&nbsp; We used Cilkmem to reveal and diagnose a previously unknown memory issue in a large image-alignment program that contributed to unexpectedly high memory usage under parallel executions.&nbsp; Cilkmem was published at SIAM APOCS 2020, where it was a Best Paper Finalist.</span></p>\n<p dir=\"ltr\"><span>To consolidate these developments, we have started to develop OpenCilk, a new open-source platform to support Cilk task-parallel programming, especially for researchers and teachers.&nbsp; OpenCilk aims to provide a full-featured implementation of Cilk that is easy to modify and extend.&nbsp; Based on the Tapir/LLVM compiler, OpenCilk will provide a streamlined runtime system and incorporate our work on CSI to support dynamic-analysis tools.&nbsp; As a community-infrastructure project, OpenCilk encourages contributions from researchers in areas of languages, compilers, runtime systems, tools, libraries, and benchmarks.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/25/2022<br>\n\t\t\t\t\tModified by: Charles&nbsp;E&nbsp;Leiserson</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1533644/1533644_10392092_1644500298801_Cilkpride-screenshots_Page_3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1533644/1533644_10392092_1644500298801_Cilkpride-screenshots_Page_3--rgov-800width.jpg\" title=\"Screenshot of the prototype Cilkpride IDE\"><img src=\"/por/images/Reports/POR/2022/1533644/1533644_10392092_1644500298801_Cilkpride-screenshots_Page_3--rgov-66x44.jpg\" alt=\"Screenshot of the prototype Cilkpride IDE\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Screenshot of the prototype Cilkpride IDE, showing how Cilksan is integrated into Cilkpride to give users additional views of the code that indicate race conditions.</div>\n<div class=\"imageCredit\">Robert Miller</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Charles&nbsp;E&nbsp;Leiserson</div>\n<div class=\"imageTitle\">Screenshot of the prototype Cilkpride IDE</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nThis award supported a wide variety of advancements in computer science, especially in the areas of parallel computing and software performance engineering.  These advancements span multiple areas, including tools for analyzing parallel programs; novel parallel algorithms; software systems for parallel computing and program analysis; and theoretical foundations of computer science.  The award supported over 70 publications, including 5 award-winning publications, 3 PhD theses, and 1 Masters of Engineering thesis.\nWe highlight several key advancements supported by this award.\nWe designed and implemented an initial version of the Cilkpride integrated development environment (IDE), building on top of the Atom programming editor.  Cilkpride incorporates automatic background execution of the Cilksan determinacy-race detector.  As the programmer edits, the IDE automatically schedules test runs with Cilksan in the background and puts error markers next to source code lines that exhibit races.  This work is a first step towards always-on parallel program analysis. The IDE has been used by students in the 6.172/6.871 Performance Engineering of Software Systems course at MIT.\nSince flexibility in supporting parallelism is an important requirement of the Cilkpride environment, we studied compiler intermediate representations (IRs) of task parallelism that support the development of efficient program-analysis tools, such as memory checkers, race detectors, and performance profilers.  We developed Tapir, a compiler IR that embeds task parallelism into a mainstream compiler IR.  Mainstream compilers typically treat parallel language constructs as syntactic sugar for function calls into a parallel runtime.  These calls prevent the compiler from effectively analyzing and optimizing software across parallel control constructs.  Tapir leverages the ?serial-projecting property,? which is commonly satisfied by task-parallel programs, to handle task-parallel semantics without an extensive rework of the compiler internals.  By embedding task parallelism into the compiler IR, Tapir enables the compiler to effectively analyze and optimize task-parallel programs.  In addition, Tapir provides a simple representation of task-parallelism that is easy for dynamic-analysis tools to use to understand parallelism.  Tapir was published in ACM PPoPP 2017, where it won the Best Paper Award.\nTo make building dynamic analysis tools for Cilkpride easier, we created the CSI framework for compiler-inserted program instrumentation.  CSI provides comprehensive static instrumentation that a compiler can insert into a program-under-test so that dynamic-analysis tools can observe and investigate runtime behavior.  Traditionally, tools based on compiler instrumentation would each separately modify the compiler to insert their own instrumentation.  In contrast, CSI inserts a standard collection of instrumentation hooks into the program-under-test. Each CSI-tool is implemented as a library that defines relevant hooks, and unused hooks are ?nulled? out and elided during either compile-time or link-time optimization, resulting in instrumented runtimes on par with custom instrumentation.  We used CSI to implement a variety of tools that use compiler instrumentation, including performance profilers, code-coverage analyzers, and a port of Google?s ThreadSanitizer.  We observed that these CSI tools exhibit minimal overheads due to program instrumentation.  CSI was published at ACM SIGMETRICS 2018.\nUsing the CSI framework, we developed a new dynamic-analysis tool, called Cilkmem, that can be incorporated into Cilkpride.  Software engineers designing parallel programs destined to run on massively parallel computing systems must be cognizant of how their program's memory requirements scale in a many-processor execution. Although tools exist for measuring memory usage during one particular execution of a parallel program, such tools cannot bound the worst-case memory usage over all possible parallel executions.  Cilkmem analyzes the execution of a deterministic Cilk program to determine its parallel memory high-water mark, which is the worst-case memory usage of the program over all possible parallel executions.  Cilkmem employs two new memory-efficient algorithms to measure the memory high-water mark either exactly, though more slowly, or approximately and more quickly.  We used Cilkmem to reveal and diagnose a previously unknown memory issue in a large image-alignment program that contributed to unexpectedly high memory usage under parallel executions.  Cilkmem was published at SIAM APOCS 2020, where it was a Best Paper Finalist.\nTo consolidate these developments, we have started to develop OpenCilk, a new open-source platform to support Cilk task-parallel programming, especially for researchers and teachers.  OpenCilk aims to provide a full-featured implementation of Cilk that is easy to modify and extend.  Based on the Tapir/LLVM compiler, OpenCilk will provide a streamlined runtime system and incorporate our work on CSI to support dynamic-analysis tools.  As a community-infrastructure project, OpenCilk encourages contributions from researchers in areas of languages, compilers, runtime systems, tools, libraries, and benchmarks.\n\n \n\n\t\t\t\t\tLast Modified: 02/25/2022\n\n\t\t\t\t\tSubmitted by: Charles E Leiserson"
 }
}