{
 "awd_id": "1464317",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: CI: Exploring Advanced Cyber-Infrastructure Co-Design for Big Data Analytics",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Sushil K Prasad",
 "awd_eff_date": "2015-07-01",
 "awd_exp_date": "2018-06-30",
 "tot_intn_awd_amt": 171257.0,
 "awd_amount": 171257.0,
 "awd_min_amd_letter_date": "2015-03-23",
 "awd_max_amd_letter_date": "2015-03-23",
 "awd_abstract_narration": "The proliferation of digital data provides new opportunities in all areas of science, engineering and industry. However, the increasing data volumes and rates, and the associated costs in terms of latencies and energy, quickly dominate and limit data analytics applications' ability to leverage this data in an effective and timely manner. The co-design process enables scientists to reason about the rich design spaces available in software and hardware, and is expected to help in constructing a new class of cyber-infrastructure. Nevertheless, current solutions for big data analytics have important limitations that make these solutions infeasible for the next generation of cyber-infrastructure. As a result, exploring key co-design issues in the scope of big data analytics has become critical.\r\n\r\nThe overarching goals of this research are to understand the performance and power behaviors and tradeoffs related to data placement, movement, and processing of big data analytics on systems with emerging architectures, and to develop models that can fundamentally enable big data analytics on ongoing cyber-infrastructure. In contrast to existing work, this research effort focuses on the co-design process that has been exploited in the context of large-scale scientific applications. Key research activities include building a framework to evaluate different classes of big data analytics, characterizing data analytics applications in terms of performance and power, and developing a methodology to construct models to understand and explore the design space.\r\n\r\nAs data analytics applications become increasingly important in a wide range of domains, the ability to develop large-scale and sustainable platforms and software infrastructure to support these applications has significant potential to drive research and innovation in science and business domains. This project provides an understanding of hardware/software characteristics and requirements for big data analytics and future cyber-infrastructure design. These research activities are integrated with graduate and undergraduate student research, and leverage minority student outreach networks at Rutgers.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ivan",
   "pi_last_name": "Rodero",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ivan Rodero",
   "pi_email_addr": "ivan.rodero@utah.edu",
   "nsf_id": "000631333",
   "pi_start_date": "2015-03-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers Discovery Informatics Institute",
  "perf_str_addr": "96 Frelinghuysen Road",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548058",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7231",
   "pgm_ref_txt": "CYBERINFRASTRUCTURE"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 171257.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The overarching goals of this project were goals of this research were understanding the performance and power behaviors and tradeoffs related to data placement, movement, and processing of data analysis systems with emerging architectures, and to develop models that can fundamentally enable big data analytics on ongoing cyber-infrastructure.</p>\n<p>First, we studied different architectural designs and processing frameworks for different classes of relevant applications under different constrains. We aimed at providing the foundations to develop models that can enable Big Data analytics on next generation cyber-infrastructure based on software-defined infrastructure. We specifically targeted two of the main distributed processing systems for Big Data analytics: Apache Hadoop and Spark, using different storage technologies (i.e., from hard disk to current non-volatile memory solutions). The experimental evaluation delivered a comprehensive characterization of performance and energy/power behaviors and tradeoffs of Hadoop and Spark; provided insights on using power capping techniques in Spark deployments for operating under power constraints while meeting performance goals; identified a number of factors that play an important role in Hadoop and Spark&rsquo;s performance, power, and energy efficiency; and explored for first time the potential of software-defined infrastructure for Big Data processing frameworks in terms of execution time, energy and cost. This effort not only characterized different big data processing system but also took into account the impact of the operating system, different flavors of virtualization and the programming language to performance and energy/power related metrics. It provided a better understanding of virtualization mechanisms to improve resource utilization and quantified overheads that are useful to the targeted models for optimizing design choices and policies that can optimize energy consumption and meeting power budgets.</p>\n<p>Further, we investigated behaviors and limitations of current in-memory frameworks, thus leading to insights regarding design choices toward next-generation software-defined in-memory frameworks. Our empirical experimental evaluation focused on persistence methods for Spark and the use of Alluxio. It provided meaningful data points to better understand requirements and design choices for next-generation software-defined infrastructure and explored the use of disaggregated off-rack memory and NVMe via simulation. The obtained results indicated that software-defined infrastructure can be a viable solution for provisioning bare metal disaggregated datacenter resources and provided meaningful data points to illuminate the requirements of in-memory systems to efficiently scale next-generation software-defined infrastructure implementations. While this work represents the foundation or a segment in the most ambitious path towards software-defined in-memory frameworks, the insights obtained from this work were critical for future efforts on caching systems for combining Spark and Alluxio efficiently. We complemented these efforts investigating in-memory analytics and tradeoffs in the context of data intensive scientific workflows using RDMA-based abstractions, cyber-security, and data streaming for IoT environments and scientific cyber-infrastructure.</p>\n<p>Finally, we investigated tradeoffs between power, performance, and quality in the context of high performance computing for building a new task scheduling model considering AMR properties for managing power budgets at scale. To understand the applicability of the proposed approach, we studied the mechanisms and policies that control AMR properties and then characterized AMR properties in terms of performance, power consumption, and system impact for a representative set of AMR-based applications. We also studied the potential of power capping techniques for re-distributing the power budget to other components of a workflow by trading-off power and quality metrics. The experiments revealed that tradeoff strategies can create an available power budget to enhance system reliability with minimum resolution degradation.</p>\n<p>Eleven (11) scientific publications resulting from this effort have been published in major international workshops, conferences, and journals. This project has provided research and educational opportunities for students and researchers and has contributed to their academic work. It has also provided them the opportunity to collaborate with other researchers in academia and industry, to present their work at conferences and other meetings, to work with state of the art technologies, and to participate in software development and acquire related skills.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/30/2018<br>\n\t\t\t\t\tModified by: Ivan&nbsp;Rodero</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe overarching goals of this project were goals of this research were understanding the performance and power behaviors and tradeoffs related to data placement, movement, and processing of data analysis systems with emerging architectures, and to develop models that can fundamentally enable big data analytics on ongoing cyber-infrastructure.\n\nFirst, we studied different architectural designs and processing frameworks for different classes of relevant applications under different constrains. We aimed at providing the foundations to develop models that can enable Big Data analytics on next generation cyber-infrastructure based on software-defined infrastructure. We specifically targeted two of the main distributed processing systems for Big Data analytics: Apache Hadoop and Spark, using different storage technologies (i.e., from hard disk to current non-volatile memory solutions). The experimental evaluation delivered a comprehensive characterization of performance and energy/power behaviors and tradeoffs of Hadoop and Spark; provided insights on using power capping techniques in Spark deployments for operating under power constraints while meeting performance goals; identified a number of factors that play an important role in Hadoop and Spark?s performance, power, and energy efficiency; and explored for first time the potential of software-defined infrastructure for Big Data processing frameworks in terms of execution time, energy and cost. This effort not only characterized different big data processing system but also took into account the impact of the operating system, different flavors of virtualization and the programming language to performance and energy/power related metrics. It provided a better understanding of virtualization mechanisms to improve resource utilization and quantified overheads that are useful to the targeted models for optimizing design choices and policies that can optimize energy consumption and meeting power budgets.\n\nFurther, we investigated behaviors and limitations of current in-memory frameworks, thus leading to insights regarding design choices toward next-generation software-defined in-memory frameworks. Our empirical experimental evaluation focused on persistence methods for Spark and the use of Alluxio. It provided meaningful data points to better understand requirements and design choices for next-generation software-defined infrastructure and explored the use of disaggregated off-rack memory and NVMe via simulation. The obtained results indicated that software-defined infrastructure can be a viable solution for provisioning bare metal disaggregated datacenter resources and provided meaningful data points to illuminate the requirements of in-memory systems to efficiently scale next-generation software-defined infrastructure implementations. While this work represents the foundation or a segment in the most ambitious path towards software-defined in-memory frameworks, the insights obtained from this work were critical for future efforts on caching systems for combining Spark and Alluxio efficiently. We complemented these efforts investigating in-memory analytics and tradeoffs in the context of data intensive scientific workflows using RDMA-based abstractions, cyber-security, and data streaming for IoT environments and scientific cyber-infrastructure.\n\nFinally, we investigated tradeoffs between power, performance, and quality in the context of high performance computing for building a new task scheduling model considering AMR properties for managing power budgets at scale. To understand the applicability of the proposed approach, we studied the mechanisms and policies that control AMR properties and then characterized AMR properties in terms of performance, power consumption, and system impact for a representative set of AMR-based applications. We also studied the potential of power capping techniques for re-distributing the power budget to other components of a workflow by trading-off power and quality metrics. The experiments revealed that tradeoff strategies can create an available power budget to enhance system reliability with minimum resolution degradation.\n\nEleven (11) scientific publications resulting from this effort have been published in major international workshops, conferences, and journals. This project has provided research and educational opportunities for students and researchers and has contributed to their academic work. It has also provided them the opportunity to collaborate with other researchers in academia and industry, to present their work at conferences and other meetings, to work with state of the art technologies, and to participate in software development and acquire related skills.\n\n\t\t\t\t\tLast Modified: 09/30/2018\n\n\t\t\t\t\tSubmitted by: Ivan Rodero"
 }
}