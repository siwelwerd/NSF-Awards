{
 "awd_id": "1533771",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS: FULL: DSD: Collaborative Research: FPGA Cloud Platform for Deep Learning, Applications in Computer Vision",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yuanyuan Yang",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 300955.0,
 "awd_amount": 300955.0,
 "awd_min_amd_letter_date": "2015-08-13",
 "awd_max_amd_letter_date": "2015-08-13",
 "awd_abstract_narration": "We stand on the verge of dramatic advances in deep learning applications, which will soon enable practicality and widespread adoption of computer vision based recognition in scientific inquiry, commercial applications, and everyday life.  Grand challenge problems are within our reach; we will soon be able to build automated systems that recognize nearly everything we see, systems that can recognize the tens of thousands of basic-level categories that psychologists posit humans can recognize, systems that continuously learn from photos, video, and web content in order to create more complete and accurate visual models of the world.  However, while it is clear that the computational capabilities for deep learning are within reach, it is equally clear that the required computational power cannot come from general-purpose processors.  To succeed, we will need to build specialized domain-specific computing systems based on hardware accelerators that are capable of exploiting the extreme fine-grained parallelism inherent in deep-learning workloads.  This project leverages parallelization and reconfigurable hardware to create an automated system that distributes computer vision algorithms onto a large number of field-programmable gate arrays (FPGA Cloud). \r\n\r\nThis project builds on recent advances in domain-specific hardware generation tools in order to bring the potential parallelism and performance per watt advantages of FPGAs to large-scale computer vision problems.   By developing a platform to run deep learning algorithms on large clouds of FPGAs, this proposal explicitly addresses scaling algorithms beyond what a single chip can process.  This involves addressing a wide range of challenging problems in algorithm analysis, building domain-specific hardware generators, communication for scaling algorithms across multiple FPGAs, and extensive validation of generating hardware for state-of-the-art deep learning approaches applied to computer vision problems.  This project advances tools for designing domain-specific FPGA implementations of algorithms, taking a step toward making more efficient computing with greater parallelism more widely available.  In particular, for computer vision, there will be significant benefits from a product of multiple improvements: higher parallelism, lower gate requirement by moving to fixed point when possible, and better performance per watt leading to higher computation density in servers.  Together, these have the potential to significantly increase the extent to which computer vision can be a part of our daily lives, making computers better able to understand the context of our world.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alexander",
   "pi_last_name": "Berg",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Alexander C Berg",
   "pi_email_addr": "bergac@uci.edu",
   "nsf_id": "000569050",
   "pi_start_date": "2015-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "104 AIRPORT DR STE 2200",
  "perf_city_name": "Chapel hill",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275991350",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 300955.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>While it is clear that the computational capabilities for deep learning are within reach, it is equally clear that the required computational power cannot come from general-purpose processors. To succeed, we will need to build specialized domain-specific computing systems based on hardware accelerators that are capable of exploiting the extreme fine-grained parallelism inherent in deep-learning workloads. This project leverages parallelization and reconfigurable hardware to create an automated system that distributes computer vision algorithms onto a large number of field-programmable gate arrays (FPGA Cloud).</p>\n<p><br />A major goal of this project is to build on recent advances in domain-specific hardware generation tools in order to bring the potential parallelism and performance per watt advantages of FPGAs to large-scale computer vision problems.&nbsp; Part of achieving this goal is exploring and developing state of the art deep-learning based approaches to object detection.&nbsp; Toward this goal we explored single-shot detection strategies.&nbsp; These work by running a detector at a sparse grid of locations and then predicting how to offset the detections to the actual object positions.&nbsp; Highlights of our work on this project include adapting the original single shot detector algorithm to increase accuracy for small objects in our work on \"deconvolutional single-shot detection\".&nbsp; Going further we showed that by adding an auxiliary training objective---predicting segmentation masks on objects---we could train a significantly more accurate single-shot detector without increasing computational cost (in \"Retina-Mask\").&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/16/2021<br>\n\t\t\t\t\tModified by: Alexander&nbsp;C&nbsp;Berg</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhile it is clear that the computational capabilities for deep learning are within reach, it is equally clear that the required computational power cannot come from general-purpose processors. To succeed, we will need to build specialized domain-specific computing systems based on hardware accelerators that are capable of exploiting the extreme fine-grained parallelism inherent in deep-learning workloads. This project leverages parallelization and reconfigurable hardware to create an automated system that distributes computer vision algorithms onto a large number of field-programmable gate arrays (FPGA Cloud).\n\n\nA major goal of this project is to build on recent advances in domain-specific hardware generation tools in order to bring the potential parallelism and performance per watt advantages of FPGAs to large-scale computer vision problems.  Part of achieving this goal is exploring and developing state of the art deep-learning based approaches to object detection.  Toward this goal we explored single-shot detection strategies.  These work by running a detector at a sparse grid of locations and then predicting how to offset the detections to the actual object positions.  Highlights of our work on this project include adapting the original single shot detector algorithm to increase accuracy for small objects in our work on \"deconvolutional single-shot detection\".  Going further we showed that by adding an auxiliary training objective---predicting segmentation masks on objects---we could train a significantly more accurate single-shot detector without increasing computational cost (in \"Retina-Mask\"). \n\n \n\n\t\t\t\t\tLast Modified: 04/16/2021\n\n\t\t\t\t\tSubmitted by: Alexander C Berg"
 }
}