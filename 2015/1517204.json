{
 "awd_id": "1517204",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Sampling and quantization theorems for modern data acquisition",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Victor Roytburd",
 "awd_eff_date": "2015-08-01",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 160404.0,
 "awd_amount": 160404.0,
 "awd_min_amd_letter_date": "2015-08-04",
 "awd_max_amd_letter_date": "2015-08-04",
 "awd_abstract_narration": "This award supports the research program of the Principal Investigator in the general area of signal processing, which concerns itself, for example, with the electronic transmission of information: digitization, compression, encoding, decoding, and the like.  Modern sensors are ubiquitous.  They measure signals of interest and digitally store or transmit large amounts of data.  Sophisticated computer algorithms then process the data, to recover the signals or to perform other tasks.  To allow accurate\u00a0signal recovery and optimize subsequent use, it is critical that the measurement and digitization processes be well designed.  It is also important that\u00a0their theoretical properties, performance guarantees, and limitations be understood.\u00a0\u00a0Under practical constraints, we\u00a0theoretically investigate not only how measurements should be made, but also how they should be digitized (i.e., how they should be converted into bit-streams and subsequently compressed).  The Principal Investigator will focus on\u00a0nonclassical signal models (including sparse vectors and low-rank matrices) whose\u00a0importance\u00a0has been increasing in recent years due to their relevance to modern applications.\r\n\r\nThis project aims to understand the interplay between sampling of structured signals, digitization, and compression---all in the modern setting of signal reconstruction by non-linear algorithms. \u00a0For example, it focuses on approximately sparse signals measured using compressed sensing techniques, low-rank matrices measured by randomly sampling their entries, and vectors whose phase-less measurements consist of the magnitudes of inner products with other vectors. \u00a0In short, the Principal Investigator seeks sampling and quantization theorems for the digital world.  This requires developing and using tools from various areas of mathematics.  As the measurement models related to this research rely heavily on randomness, the project must develop and use methods from geometric functional analysis and nonasymptotic random matrix theory.  In the formulation of quantization methods for redundant measurements, connections with frame theory and the mathematical literature on noise-shaping quantization will be established and used.  The encoding (compression) algorithms proposed in this research use randomness extensively, and here the Principal Investigator anticipates connections with the randomized numerical linear algebra literature.  In analyzing new reconstruction algorithms, he will employ and develop methods from convex optimization and numerical analysis.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rayan",
   "pi_last_name": "Saab",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rayan Saab",
   "pi_email_addr": "rsaab@ucsd.edu",
   "nsf_id": "000653192",
   "pi_start_date": "2015-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 Gilman Drive",
  "perf_city_name": "La Jolla",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930934",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126600",
   "pgm_ele_name": "APPLIED MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 160404.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Recent years have witnessed a revolution in our ability to acquire, or sense, unprecedented amounts of data. This revolution has permeated across multiple disciplines and is seen in areas as diverse as digital photography, astronomy, medical imaging, and seismic data acquisition. Spurring this progress are advances in sensor technologies, computer technologies, computer science, and -- importantly -- mathematics. Our work, funded by this award, focused on the algorithms and associated mathematical theory of two critical components of high-dimensional data acquisition, namely, its sampling and its quantization.</p>\n<p>Sampling algorithms are methods for collecting a reduced number of samples of a signal of interest in such a way that the entire original signal can be computationally reconstructed. The accompanying sampling theory reveals the conditions under which this can be successfully done and quantifies the tradeoffs in the presence of noise and modelling errors. On the other hand, it is via the quantization process that continuously valued sensor samples are mapped to a finite set of values (equivalently, to bits) so that they may be stored, transmitted, and processed using digital devices. As we live in a digital age of computing, every sampling algorithm/theory must be accompanied by an associated quantization algorithm/theory.</p>\n<p>Modern examples of data acquisition -- which we studied -- include compressed sensing, whereby linear measurements (rather than point samples) of the underlying signal are acquired. Then, to reconstruct the signal, sophisticated non-linear algorithms are used. To reduce the number of measurements, these algorithms employ knowledge of the class of signals to which our underlying one belongs. Applications for this paradigm range from speedier MRI imaging, to channel identification in wireless communication, among many others.</p>\n<p>Our work resulted in establishing and analyzing algorithms for reconstructing signals under the compressed sensing paradigm. We studied various scenarios, including those where the location of the non-zero entries of the signals is known, albeit not with full confidence. Importantly, we also devised and analyzed quantization algorithms (a previously under-studied aspect of compressed sensing) and their associated reconstruction algorithms. We showed that our computationally efficient methods vastly outperform their competitors under a wide range of scenarios, in terms of the tradeoffs between the number of measurements, number of bits per measurement, and the resulting reconstruction errors. Our results applied to a wide range of signal and measurement models arising, for example, in MRI imaging and wireless communication. In another direction, we devised efficient algorithms and measurement designs along with their reconstruction error guarantees for a type of non-linear imaging modality known as ptychography, which arises for example, in nano-scale imaging. &nbsp;&nbsp;&nbsp;&nbsp;</p>\n<p>The research we conducted involved 4 of my PhD students (two of whom have already graduated) and a postdoctoral researcher. Our results were published and presented in over 15 national and international venues. Additionally, some of the mathematical tools and methods we used were taught in graduate courses that the PI developed.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/26/2019<br>\n\t\t\t\t\tModified by: Rayan&nbsp;Saab</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nRecent years have witnessed a revolution in our ability to acquire, or sense, unprecedented amounts of data. This revolution has permeated across multiple disciplines and is seen in areas as diverse as digital photography, astronomy, medical imaging, and seismic data acquisition. Spurring this progress are advances in sensor technologies, computer technologies, computer science, and -- importantly -- mathematics. Our work, funded by this award, focused on the algorithms and associated mathematical theory of two critical components of high-dimensional data acquisition, namely, its sampling and its quantization.\n\nSampling algorithms are methods for collecting a reduced number of samples of a signal of interest in such a way that the entire original signal can be computationally reconstructed. The accompanying sampling theory reveals the conditions under which this can be successfully done and quantifies the tradeoffs in the presence of noise and modelling errors. On the other hand, it is via the quantization process that continuously valued sensor samples are mapped to a finite set of values (equivalently, to bits) so that they may be stored, transmitted, and processed using digital devices. As we live in a digital age of computing, every sampling algorithm/theory must be accompanied by an associated quantization algorithm/theory.\n\nModern examples of data acquisition -- which we studied -- include compressed sensing, whereby linear measurements (rather than point samples) of the underlying signal are acquired. Then, to reconstruct the signal, sophisticated non-linear algorithms are used. To reduce the number of measurements, these algorithms employ knowledge of the class of signals to which our underlying one belongs. Applications for this paradigm range from speedier MRI imaging, to channel identification in wireless communication, among many others.\n\nOur work resulted in establishing and analyzing algorithms for reconstructing signals under the compressed sensing paradigm. We studied various scenarios, including those where the location of the non-zero entries of the signals is known, albeit not with full confidence. Importantly, we also devised and analyzed quantization algorithms (a previously under-studied aspect of compressed sensing) and their associated reconstruction algorithms. We showed that our computationally efficient methods vastly outperform their competitors under a wide range of scenarios, in terms of the tradeoffs between the number of measurements, number of bits per measurement, and the resulting reconstruction errors. Our results applied to a wide range of signal and measurement models arising, for example, in MRI imaging and wireless communication. In another direction, we devised efficient algorithms and measurement designs along with their reconstruction error guarantees for a type of non-linear imaging modality known as ptychography, which arises for example, in nano-scale imaging.     \n\nThe research we conducted involved 4 of my PhD students (two of whom have already graduated) and a postdoctoral researcher. Our results were published and presented in over 15 national and international venues. Additionally, some of the mathematical tools and methods we used were taught in graduate courses that the PI developed.\n\n \n\n\t\t\t\t\tLast Modified: 12/26/2019\n\n\t\t\t\t\tSubmitted by: Rayan Saab"
 }
}