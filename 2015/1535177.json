{
 "awd_id": "1535177",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research:  Personalized Benchmarks for High Performance Computing Applications",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924863",
 "po_email": "edwalker@nsf.gov",
 "po_sign_block_name": "Edward Walker",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 309000.0,
 "awd_amount": 330000.0,
 "awd_min_amd_letter_date": "2015-08-14",
 "awd_max_amd_letter_date": "2015-11-06",
 "awd_abstract_narration": "As high-performance computing applications target ever-larger problems, data input and output (I/O) takes up more and more run time. Users, software developers, and platform administrators often find it difficult to understand what an application's I/O code is doing, why it is slow, how it might be improved, or how well it would perform on a different platform. I/O benchmarks help address this problem, but they are expensive to produce and thus are not available for most applications. This project is providing user-friendly personalized I/O benchmarks for all applications, by leveraging existing lightweight I/O profilers that already monitor the behavior of applications on high-performance computing platforms. The resulting personalized benchmarks will help researchers, developers, and purchasers in evaluating potential new storage system architectures, evaluating existing or new versions of storage systems and I/O libraries, planning for purchases, comparing performance of application clusters or workloads across platforms, and improving the performance of parallel I/O libraries and applications. The analytics and benchmark generation software, and example benchmarks, will be publicly released.\r\n \r\nThis project uses two methods to construct personalized I/O benchmarks. First, the project is making existing applications self-benchmarking across all of their runs, by providing analytics and visualization facilities to convey to stakeholders the information already automatically captured by lightweight I/O profilers such as Darshan during each run. Second, the project is creating platform-customized benchmark suites that represent the mix of application-level workloads observed on a given platform. To accomplish this, the project is clustering observed production jobs based on their I/O behavior and using both new and existing I/O kernel generation techniques to generate a compact benchmark for each cluster. The resulting benchmark suite will advance the state of the art by serving as a proxy for real-world, platform-specific production I/O workloads, and by providing previously unavailable insight into how prevalent those workloads are at a given facility.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Marianne",
   "pi_last_name": "Winslett",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Marianne Winslett",
   "pi_email_addr": "winslett@illinois.edu",
   "nsf_id": "000443748",
   "pi_start_date": "2015-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618207473",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "768400",
   "pgm_ele_name": "CESER-Cyberinfrastructure for"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7684",
   "pgm_ref_txt": "STRATEGIC TECHNOLOGIES FOR CI"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 309000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 21000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Parallel I/O is a common performance bottleneck for applications that  run on supercomputers.&nbsp; To help in understanding parallel I/O behavior,  the lightweight Darshan profiler captures both a coarse-grained and  fine-grained picture of the I/O behavior of jobs.&nbsp; Darshan profiling is  enabled by default on many major US supercomputers, and has proved to be  very helpful for providing platform-level situational awareness and  application-level data to help identify and resolve performance  bottlenecks.&nbsp; However, due to its volume and complexity, Darshan data is  not always easy to use in parallel I/O research.</p>\n<p>This project addressed that problem by building an easily queryable  SQL database that contains the data from profiling all Darshan-enabled  jobs on the Blue Waters supercomputer from 2014 to 2019.&nbsp; The tens of  millions of jobs in the database are a valuable resource for researchers  studying benchmarking issues or any other aspect of parallel I/O.</p>\n<p>The project also used profiling to evaluate the overhead of  collective I/O operations, and designed and evaluated ways to greatly  reduce the communication overhead of the most common types of collective  I/O calls, including write calls for 2D arrays made of non-overlapping  2D tiles.&nbsp; The project also proposed new ways of using machine learning  to select representative jobs and applications, to serve as parallel I/O  benchmarks.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/11/2020<br>\n\t\t\t\t\tModified by: Marianne&nbsp;Winslett</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nParallel I/O is a common performance bottleneck for applications that  run on supercomputers.  To help in understanding parallel I/O behavior,  the lightweight Darshan profiler captures both a coarse-grained and  fine-grained picture of the I/O behavior of jobs.  Darshan profiling is  enabled by default on many major US supercomputers, and has proved to be  very helpful for providing platform-level situational awareness and  application-level data to help identify and resolve performance  bottlenecks.  However, due to its volume and complexity, Darshan data is  not always easy to use in parallel I/O research.\n\nThis project addressed that problem by building an easily queryable  SQL database that contains the data from profiling all Darshan-enabled  jobs on the Blue Waters supercomputer from 2014 to 2019.  The tens of  millions of jobs in the database are a valuable resource for researchers  studying benchmarking issues or any other aspect of parallel I/O.\n\nThe project also used profiling to evaluate the overhead of  collective I/O operations, and designed and evaluated ways to greatly  reduce the communication overhead of the most common types of collective  I/O calls, including write calls for 2D arrays made of non-overlapping  2D tiles.  The project also proposed new ways of using machine learning  to select representative jobs and applications, to serve as parallel I/O  benchmarks.\n\n\t\t\t\t\tLast Modified: 07/11/2020\n\n\t\t\t\t\tSubmitted by: Marianne Winslett"
 }
}