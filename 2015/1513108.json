{
 "awd_id": "1513108",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CI-NEW: Collaborative Research: A Modular Platform for Enabling Computing Research in Intelligent Human-Robot Interaction",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2015-06-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 675000.0,
 "awd_amount": 736866.0,
 "awd_min_amd_letter_date": "2015-06-05",
 "awd_max_amd_letter_date": "2021-05-18",
 "awd_abstract_narration": "This project is to design, develop, and freely distribute novel, affordable, modular hardware and accompanying software platforms for enabling non-contact human-robot interaction (HRI) research. Such research is a significant portion of HRI today, and encompasses a broad spectrum of computing challenges and compelling application domains, including education, training, rehabilitation, and health. The goal of this project is to significantly increase access to hardware to a large body of researchers, so that computing advances can be applied to physical systems and evaluated in real-world environments, in order to drive progress in the computing community.\r\n\r\nAdvances in sensor and communication technologies have facilitated progress in computing research on physical platforms. The field of human-robot interaction in particular has grown significantly and actively brings together an interdisciplinary community of researchers across computing, robotics, and social science. However, progress has been limited by the lack of affordable, general-purpose, modular hardware platforms with available low-level software that would enable large numbers of computing researchers to enter the field and develop and test algorithms, as well as conduct statistically significant user studies by deploying systems in the real world and collecting user data to inform further computational research in HRI.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Yim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mark Yim",
   "pi_email_addr": "yim@seas.upenn.edu",
   "nsf_id": "000230349",
   "pi_start_date": "2015-06-05",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Simon",
   "pi_last_name": "Kim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Simon Kim",
   "pi_email_addr": "simonkim@design.upenn.edu",
   "nsf_id": "000607673",
   "pi_start_date": "2015-06-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "220 S. 33rd Street",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046315",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735900",
   "pgm_ele_name": "CCRI-CISE Cmnty Rsrch Infrstrc"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7359",
   "pgm_ref_txt": "COMPUTING RES INFRASTRUCTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 675000.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 61866.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\"><span class=\"s1\">This NSF Computing Research Infrastructure (CRI) project involved the design, development, and deployment of an affordable, general-purpose, and modular face-to-face human-robot interaction (HRI) robot platform called Quori, as well as open-source social behavior application programming interfaces (APIs) and developer tools for computing researchers to develop and test algorithms and conduct user studies in the real world, using Quori or other suitable HRI platforms.&nbsp; This CRI project involved a collaboration with an industry partner, Semio (<a href=\"https://semio.ai/\"><span class=\"s2\">https://semio.ai</span></a>). The project team used an iterative, community-driven design process for determining the design of the hardware, software, physical appearance, and cost of the robot. By continually engaging communities of interest through surveys, symposia, and workshops, this CRI project addressed the needs and desires of potential platform users.&nbsp; The developed robot has multiple novel design features, including a projected face and a waist joint, allowing for new directions of HRI research.&nbsp; The developed software, in particular the social behavior APIs and developer tools are general and platform-agnostic, helping researchers to explore topics in HRI without having to write and maintain basic software in each individual lab and institution.&nbsp; The project included a phase that solicited applications from interested institutions to be awarded a Quori platform for research; eight research institutions across the US were awarded Quori robots, along with the two partnered leading institutions on the project (U Penn and USC), and the industry partner (Semio).</span></p>\n<p class=\"p1\"><span class=\"s1\">The rest of this summary summarizes the Quori robot hardware.&nbsp; (Partner USC summary describes the robot software.)<span>&nbsp; </span>The Quori robot is cost-effective (bill of materials around USD 6,300) while enabling a human scale robot that can interact with humans and provide a rich platform for HRI research.<span>&nbsp; </span>Note that while most robots include applications for manipulation, Quori is not made to manipulate other objects and thus large cost savings were found in reducing arm strength, dexterity and removing the need for actuated grippers.<span>&nbsp; </span>A consequence of this is that Quori is also lighter, slower and more inherently safe for interaction.</span></p>\n<p class=\"p1\"><span class=\"s1\">The module features of the hardware include;</span>&nbsp;</p>\n<ul>\n<li><span class=\"s1\">A rear projection head. Instead of a fixed facial appearance with articulations, a projector allows millions of possible faces expressions and animations. By making the head spherical, nodding or turning of the head could also be projected without requiring extra actuation again saving costs.</span></li>\n<li><span class=\"s1\">Two arms have shoulders that can articulate with two degrees of freedom like human shoulders. The range of motion is similar to that of humans except that it can twist the arms beyond what humans can do. The software merely needs to limit its motion.</span>&nbsp;</li>\n<li><span class=\"s1\">The mobile base is wheeled but hidden under a skirt/kilt that provides full holonomic motion (the robot can simultaneously spin or translate or pirouette). The gender of the robot is made intentionally ambiguous so the researchers may imbue gender however they wish by adding features or behaviors that may or may not indicate gender.</span></li>\n<li><span class=\"s1\">Uniquely, Quori also has an articulated waste in which the robot may bow forwards or backwards to a limited extent. The upper torso is counter balanced in such a manner so that unwanted vibrations are never seen when the robot suddenly starts or stops.</span></li>\n<li><span class=\"s1\">The sensor and computation suite on the robot includes 3D vision, stereoscopic audio listening and speaking as well as the computational power to process in realtime.</span></li>\n</ul><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/28/2022<br>\n\t\t\t\t\tModified by: Mark&nbsp;Yim</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1513108/1513108_10367533_1643429017016_Quori_physical--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1513108/1513108_10367533_1643429017016_Quori_physical--rgov-800width.jpg\" title=\"Quori Robot\"><img src=\"/por/images/Reports/POR/2022/1513108/1513108_10367533_1643429017016_Quori_physical--rgov-66x44.jpg\" alt=\"Quori Robot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Quori is a cost-effective humanoid robot to study human-robot-interaction.</div>\n<div class=\"imageCredit\">Simon Kim</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Mark&nbsp;Yim</div>\n<div class=\"imageTitle\">Quori Robot</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "This NSF Computing Research Infrastructure (CRI) project involved the design, development, and deployment of an affordable, general-purpose, and modular face-to-face human-robot interaction (HRI) robot platform called Quori, as well as open-source social behavior application programming interfaces (APIs) and developer tools for computing researchers to develop and test algorithms and conduct user studies in the real world, using Quori or other suitable HRI platforms.  This CRI project involved a collaboration with an industry partner, Semio (https://semio.ai). The project team used an iterative, community-driven design process for determining the design of the hardware, software, physical appearance, and cost of the robot. By continually engaging communities of interest through surveys, symposia, and workshops, this CRI project addressed the needs and desires of potential platform users.  The developed robot has multiple novel design features, including a projected face and a waist joint, allowing for new directions of HRI research.  The developed software, in particular the social behavior APIs and developer tools are general and platform-agnostic, helping researchers to explore topics in HRI without having to write and maintain basic software in each individual lab and institution.  The project included a phase that solicited applications from interested institutions to be awarded a Quori platform for research; eight research institutions across the US were awarded Quori robots, along with the two partnered leading institutions on the project (U Penn and USC), and the industry partner (Semio).\nThe rest of this summary summarizes the Quori robot hardware.  (Partner USC summary describes the robot software.)  The Quori robot is cost-effective (bill of materials around USD 6,300) while enabling a human scale robot that can interact with humans and provide a rich platform for HRI research.  Note that while most robots include applications for manipulation, Quori is not made to manipulate other objects and thus large cost savings were found in reducing arm strength, dexterity and removing the need for actuated grippers.  A consequence of this is that Quori is also lighter, slower and more inherently safe for interaction.\nThe module features of the hardware include; \n\nA rear projection head. Instead of a fixed facial appearance with articulations, a projector allows millions of possible faces expressions and animations. By making the head spherical, nodding or turning of the head could also be projected without requiring extra actuation again saving costs.\nTwo arms have shoulders that can articulate with two degrees of freedom like human shoulders. The range of motion is similar to that of humans except that it can twist the arms beyond what humans can do. The software merely needs to limit its motion. \nThe mobile base is wheeled but hidden under a skirt/kilt that provides full holonomic motion (the robot can simultaneously spin or translate or pirouette). The gender of the robot is made intentionally ambiguous so the researchers may imbue gender however they wish by adding features or behaviors that may or may not indicate gender.\nUniquely, Quori also has an articulated waste in which the robot may bow forwards or backwards to a limited extent. The upper torso is counter balanced in such a manner so that unwanted vibrations are never seen when the robot suddenly starts or stops.\nThe sensor and computation suite on the robot includes 3D vision, stereoscopic audio listening and speaking as well as the computational power to process in realtime.\n\n\n\t\t\t\t\tLast Modified: 01/28/2022\n\n\t\t\t\t\tSubmitted by: Mark Yim"
 }
}