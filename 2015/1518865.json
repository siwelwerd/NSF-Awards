{
 "awd_id": "1518865",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CSR: CHS: Large: Wearable Cognitive Assistance",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2015-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 2807787.0,
 "awd_amount": 2847787.0,
 "awd_min_amd_letter_date": "2015-08-06",
 "awd_max_amd_letter_date": "2019-04-22",
 "awd_abstract_narration": "This research explores the deep technical challenges of a new class of computing systems that integrate a wearable device (such as Google Glass) with cloud-based processing to guide a user step by step through a complex task. Although easy to describe, many challenges in computer systems, computer vision and human-computer interaction must be overcome for this concept to become reality. Human cognition is a remarkable feat of real-time processing. It involves the synthesis of outputs from real-time analytics on multiple sensor stream inputs. An assistive system amplifies human cognition with compute-intensive processing that is so responsive that it fits into the inner loop of the human cognitive workflow. In its most general form, cognitive assistance is a very broad and ambitious concept that could be applied to virtually all facets of everyday life.   As a pioneering effort, this research is more narrowly focused on user assistance for well-defined tasks that require specialized knowledge and/or skills, and for which task state and task-relevant actions are fully accessible to computer vision algorithms.   \r\n\r\nThe research is organized into four broad thrusts. The first thrust decouples and cleanly separates low-level mobile computing and cloud computing issues such as resource management, network latency, placement, provisioning, scalability, and load balancing from the task-centric foci of the other tasks. The second thrust focuses on the computer vision research necessary to address the challenges of wearable cognitive assistance. Vision is the dominant sensing modality for the kinds of tasks addressed in this research, but the validation experiments will include proof-of-concept use of other sensing modalities such as audio and location. The third thrust focuses on task description, tracking, sequencing and user guidance. Its goal is to create a set of generalizable principles and tools that can be applied to a wide range of tasks. Matching task assistance to task demands and user capabilities will be integral to this thrust. The fourth thrust involves continuous integration of research from the first three thrusts and applies it towards end-to-end validation on a series of tasks of increasing sophistication and difficulty. This thrust involves close collaboration with industry partners. \r\n\r\nThis research will advance computer science by producing scientific insights, algorithms, system designs, implementation techniques, and experimental validations at the intersection of computer systems (including mobile computing, cloud computing, virtual machines, operating systems, wireless networking, and sensor networks), vision technologies (including computer vision and machine learning), and human-computer interaction.  More broadly, society will benefit from wearable cognitive application in areas such as health care training, industrial troubleshooting and consumer product assembly. From an educational viewpoint, this research offers many unique opportunities to train graduate and undergraduate students on how to approach problems from a broad cross-disciplinary viewpoint.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mahadev",
   "pi_last_name": "Satyanarayanan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mahadev Satyanarayanan",
   "pi_email_addr": "satya@cs.cmu.edu",
   "nsf_id": "000217675",
   "pi_start_date": "2015-08-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Siewiorek",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel P Siewiorek",
   "pi_email_addr": "dps@cs.cmu.edu",
   "nsf_id": "000278815",
   "pi_start_date": "2015-08-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Roberta",
   "pi_last_name": "Klatzky",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Roberta L Klatzky",
   "pi_email_addr": "klatzky@cmu.edu",
   "nsf_id": "000330465",
   "pi_start_date": "2015-08-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Martial",
   "pi_last_name": "Hebert",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Martial Hebert",
   "pi_email_addr": "martial.Hebert@cs.cmu.edu",
   "nsf_id": "000225106",
   "pi_start_date": "2015-08-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 Forbes Ave",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1714",
   "pgm_ref_txt": "SPECIAL PROJECTS - CISE"
  },
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 1362414.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 712004.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 733369.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 24000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our research was inspired by the impact that GPS navigation on our smartphones and vehicles has had over the last decade.&nbsp; They have completely transformed the complex task of driving in an unfamiliar city.&nbsp; Instead of using paper maps, we now listen to a voice that guides us step by step and corrects our errors.&nbsp; What used to be difficult has now been made almost trivial.</p>\n<p>Our research expands this metaphor to a much broader range of tasks.&nbsp; Its goal is to create assistive systems that amplify human cognition with compute-intensive processing that is so responsive that it fits into the inner loop of the human cognitive workflow. Enormous computing resources are applied in real time to the same video and audio sensor streams available to the human. The results are available so fast that it shapes the human's response.&nbsp; Through task-specific integration of wearable devices, high-bandwidth and low-latency wireless communication, and edge computing, we effectively create an \"angel on your shoulder\" that is aware of your task and helps you to complete it successfully.</p>\n<p>Our research was organized into four broad thrusts. The first thrust decoupled and cleanly separated out low-level mobile computing and cloud computing issues such as resource management, network latency ,placement, provisioning, scalability, and load balancing.&nbsp; The second thrust focused on the computer vision research necessary to address the challenges of wearable cognitive assistance.&nbsp; The third thrust focused on task description, tracking, sequencing and userguidance. Its goal was to create a set of generalizable principles and tools that could be applied to a wide range of tasks. The fourth thrust involved continuous integration of results from the first three thrusts, and applied it towards end-to-end validation on a series of tasks of increasing sophistication and difficulty.</p>\n<p>In terms of intellectual merit, this research has advanced the boundaries of our knowledge at the intersection of mobile computing, computer vision and human-computer interaction.&nbsp; This learning has taken many forms: scientific insights, new algorithms, novel system designs, implementation techniques, and experimental validations.These learnings have resulted in nearly 30 peer-reviewed scholarly papers in conferences, journals and workshops.</p>\n<p>This research has also had considerable broader impact.&nbsp; Four PhD students and five Masters students whose dissertations were based on this research have already graduated.&nbsp; Two more PhD students are nearing graduaton.&nbsp; This project has also helped seven undergraduates (all US citizens) to gain initial exposure to research.&nbsp; Inspired by this experience, one of the undergraduates is already enrolled in a PhD program and others are planning to go on to grad school..&nbsp; Class projects inspired by this research have given roughly 15 students each year, for five years, hands-on experience in edge computing, wearable devices, machine learning, computer vision, and other related areas that are integral to this research.&nbsp; The Gabriel infrastructure that has been created in this project represents a \"Platform as a Service\"(PaaS) infrastructure for the emerging class of wearable cognitive assistance applications.&nbsp; We have created the Open Edge Computing Initiative (https://www.openedgecomputing.org/) with over a dozen industry members who are working closely with us on this research. Through our close partnership with industry, the core developments stemming from this research have already had significant impact on edge computing.&nbsp; Nearly 20 proof-of-concept wearable cognitive assistance applications based on this research research have been created and released open source.&nbsp; A sample of these can be found n the attached image.</p>\n<p><br /><br /><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/30/2021<br>\n\t\t\t\t\tModified by: Mahadev&nbsp;Satyanarayanan</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1518865/1518865_10384201_1633034555352_fig-backend-structure-simple-crop10241024_1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1518865/1518865_10384201_1633034555352_fig-backend-structure-simple-crop10241024_1--rgov-800width.jpg\" title=\"Gabriel Platform for Wearable Cognitive Assistance\"><img src=\"/por/images/Reports/POR/2021/1518865/1518865_10384201_1633034555352_fig-backend-structure-simple-crop10241024_1--rgov-66x44.jpg\" alt=\"Gabriel Platform for Wearable Cognitive Assistance\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Gabriel is an extensible platform-as-a-service layer.   The front end  performs preprocessing of sensor data and streams it over a wireless network to a cloudlet.  The back end on the cloudlet is organized as a collection of cognittive modules.</div>\n<div class=\"imageCredit\">Mahadev Satyanarayanan</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Mahadev&nbsp;Satyanarayanan</div>\n<div class=\"imageTitle\">Gabriel Platform for Wearable Cognitive Assistance</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1518865/1518865_10384201_1633036571448_bigtable10241024_1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1518865/1518865_10384201_1633036571448_bigtable10241024_1--rgov-800width.jpg\" title=\"Examples of Wearable Cognitive Assistance Applications\"><img src=\"/por/images/Reports/POR/2021/1518865/1518865_10384201_1633036571448_bigtable10241024_1--rgov-66x44.jpg\" alt=\"Examples of Wearable Cognitive Assistance Applications\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This is a small sample from nearly 20 applications that we have created.</div>\n<div class=\"imageCredit\">Mahadev Satyanarayanan</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Mahadev&nbsp;Satyanarayanan</div>\n<div class=\"imageTitle\">Examples of Wearable Cognitive Assistance Applications</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nOur research was inspired by the impact that GPS navigation on our smartphones and vehicles has had over the last decade.  They have completely transformed the complex task of driving in an unfamiliar city.  Instead of using paper maps, we now listen to a voice that guides us step by step and corrects our errors.  What used to be difficult has now been made almost trivial.\n\nOur research expands this metaphor to a much broader range of tasks.  Its goal is to create assistive systems that amplify human cognition with compute-intensive processing that is so responsive that it fits into the inner loop of the human cognitive workflow. Enormous computing resources are applied in real time to the same video and audio sensor streams available to the human. The results are available so fast that it shapes the human's response.  Through task-specific integration of wearable devices, high-bandwidth and low-latency wireless communication, and edge computing, we effectively create an \"angel on your shoulder\" that is aware of your task and helps you to complete it successfully.\n\nOur research was organized into four broad thrusts. The first thrust decoupled and cleanly separated out low-level mobile computing and cloud computing issues such as resource management, network latency ,placement, provisioning, scalability, and load balancing.  The second thrust focused on the computer vision research necessary to address the challenges of wearable cognitive assistance.  The third thrust focused on task description, tracking, sequencing and userguidance. Its goal was to create a set of generalizable principles and tools that could be applied to a wide range of tasks. The fourth thrust involved continuous integration of results from the first three thrusts, and applied it towards end-to-end validation on a series of tasks of increasing sophistication and difficulty.\n\nIn terms of intellectual merit, this research has advanced the boundaries of our knowledge at the intersection of mobile computing, computer vision and human-computer interaction.  This learning has taken many forms: scientific insights, new algorithms, novel system designs, implementation techniques, and experimental validations.These learnings have resulted in nearly 30 peer-reviewed scholarly papers in conferences, journals and workshops.\n\nThis research has also had considerable broader impact.  Four PhD students and five Masters students whose dissertations were based on this research have already graduated.  Two more PhD students are nearing graduaton.  This project has also helped seven undergraduates (all US citizens) to gain initial exposure to research.  Inspired by this experience, one of the undergraduates is already enrolled in a PhD program and others are planning to go on to grad school..  Class projects inspired by this research have given roughly 15 students each year, for five years, hands-on experience in edge computing, wearable devices, machine learning, computer vision, and other related areas that are integral to this research.  The Gabriel infrastructure that has been created in this project represents a \"Platform as a Service\"(PaaS) infrastructure for the emerging class of wearable cognitive assistance applications.  We have created the Open Edge Computing Initiative (https://www.openedgecomputing.org/) with over a dozen industry members who are working closely with us on this research. Through our close partnership with industry, the core developments stemming from this research have already had significant impact on edge computing.  Nearly 20 proof-of-concept wearable cognitive assistance applications based on this research research have been created and released open source.  A sample of these can be found n the attached image.\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 09/30/2021\n\n\t\t\t\t\tSubmitted by: Mahadev Satyanarayanan"
 }
}