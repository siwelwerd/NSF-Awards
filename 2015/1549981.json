{
 "awd_id": "1549981",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "INSPIRE: Not Unbiased: The Implications of Human-Algorithm Interaction on Training Data and Algorithm Performance",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Wei Ding",
 "awd_eff_date": "2015-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 813222.0,
 "awd_amount": 829222.0,
 "awd_min_amd_letter_date": "2015-09-14",
 "awd_max_amd_letter_date": "2020-09-03",
 "awd_abstract_narration": "This INSPIRE award is partially funded by the Information Integration and Informatics program in the Division of Information and Intelligent Systems in the Directorate for Computer & Information Science & Engineering, the Perception, Action & Cognition program in the Division of Behavioral and Cognitive Sciences in the Directorate for Social, Behavioral & Economic Sciences, and the Office of Integrative Activities in the Office of the Director.\r\n\r\nOne of the most common uses of machine learning is to learn to replicate human decisions, a common example is recommender systems. In these systems, computers are trained to replicate the recommendation a collaboration of hundreds or thousands of humans would give, if that were possible.  Most of the data used to train these systems are not from a controlled random sample, but are obtained from users based on outputs of algorithms (e.g., which search engine results do users click on?), which introduces bias into the process and ultimately impacts the quality of the results.  This project addresses this problem by examining how the human decision process that creates these data in the first place is affected by the data coming from machine algorithms, how this in turn impacts the algorithms themselves, and how to ultimately adjust for human bias in the machine learning process.  Specific areas tackled are filtering (e.g., web search) and recommender systems.  The deep research into how the human decision process affects machine learning, and how machine learning impacts the human decision process, can provide significant advances in the accuracy and utility of systems using machine learning.\r\n\r\nThe project builds on analysis of machine learning algorithms based on Hidden Markov Models (HMMs).  The formal analysis initially looks at \"blind spots\" - the impact of bias from users not getting complete (or a random sample) of data.  Further analysis will be based on the outcome of two human experiments:  Two category recommendation (labeling items, with items to be labelled chosen by random, active learning, and filter-based algorithms), and movie recommendation.  The results will be used to develop improved machine learning approaches based on antidotes (altering learned models to reduce bias) and reactive learning (active learning that takes into account the human and machine biases).  The PIs also have plans to capitalize on the lessons learned by providing examples of the use of cognitive science in a Web Mining course, and of the impact of machine learning in Data Science for Psychologists courses.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Olfa",
   "pi_last_name": "Nasraoui",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Olfa Nasraoui",
   "pi_email_addr": "olfa.nasraoui@louisville.edu",
   "nsf_id": "000367596",
   "pi_start_date": "2015-09-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Patrick",
   "pi_last_name": "Shafto",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Patrick Shafto",
   "pi_email_addr": "patrick.shafto@gmail.com",
   "nsf_id": "000504025",
   "pi_start_date": "2015-09-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Louisville Research Foundation Inc",
  "inst_street_address": "2301 S 3RD ST",
  "inst_street_address_2": "",
  "inst_city_name": "LOUISVILLE",
  "inst_state_code": "KY",
  "inst_state_name": "Kentucky",
  "inst_phone_num": "5028523788",
  "inst_zip_code": "402081838",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "KY03",
  "org_lgl_bus_name": "UNIVERSITY OF LOUISVILLE",
  "org_prnt_uei_num": "",
  "org_uei_num": "E1KJM4T54MK6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Louisville",
  "perf_str_addr": "2301 South Third Street",
  "perf_city_name": "Louisville",
  "perf_st_code": "KY",
  "perf_st_name": "Kentucky",
  "perf_zip_code": "402920001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "KY03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  },
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  },
  {
   "pgm_ele_code": "807800",
   "pgm_ele_name": "INSPIRE"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "8653",
   "pgm_ref_txt": "INSPIRE Track-1 Creative"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 813222.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-11d50ce5-7fff-7035-24ac-27a8caaf0a29\"> </span></p>\n<p dir=\"ltr\"><span>Recommender systems and information filters allow one to search through the voluminous possible products when shopping and webpages when searching the internet. Necessarily, these tools work by surfacing certain possibilities and obscuring the vast majority. Typically, the results of recommender systems and information filters are then improved by providing more of what people purchased or read, and less of that which they did not. While this filtering is essential to help users against information overload, it raises the concern of feedback loops (Figure 1) in which people are shown more and more of the products and webpages that the system initially favored, and never see alternative products and information that would be preferred, if presented. This bias in exposure and diversity of recommendations leads to under-exposure which in turn can have profound impacts on humans as it may limit the user's discovery and harm a product's exposure. Potential impacts can be unfairness, polarization and filter bubbles.</span></p>\n<p dir=\"ltr\"><span>We proposed a theory for investigating the implications of interactions between humans and recommendation algorithms. The theory drew on diverse literature to provide algorithmic, mathematical, computational, and behavioral tools for investigating human-algorithm interaction. We specifically investigated and provided results regarding three key questions. How does biased selection in recommendation and filtering affect algorithm performance over time? How do people's actions and reasoning affect performance over time? How can we formalize the interaction between people and algorithms and predict whether changes to algorithms will \"undo\" the effects of bias and ensure \"good\" performance? Our results show that feedback loops that skew results and amplify bias (Figure 2) are possible and result in bad and biased recommendation and web search results. In doing so, we developed theoretical and experimental tools for studying how technology affects humans and vice versa. Our new methods include algorithms to detect, measure, and mitigate polarization, as well as to debias and add explainability to state of the art recommendation modeling techniques. The results show an ability to compute debiased and diversified recommendations without sacrificing their accuracy or relevance. Examples of our Intellectual Merit research outcomes are summarized in Figure 3.</span></p>\n<p dir=\"ltr\"><span>Our project has contributed to diverse broader impacts. Our project has profound societal impact, in particular on Fairness in AI, because&nbsp;our research contributes to recommender system algorithms that reduce the undesirable effects of bias, including filter bubbles, polarization and underexposure. In addition, our project contributed&nbsp;new&nbsp;open source data and software; outreach through open lab demos to the public, presentations at girl camps, and invited talks in industry. Our education and training impacts include&nbsp;a workshop, new course modules, and training PhD, Masters, and undergraduate students; as well as high school and middle school teachers through embedded authentic research experiences and related curriculum development in their classrooms. Examples of our Broader Impacts are summarized in Figure 4.</span></p>\n<p><span id=\"docs-internal-guid-d2285c4b-7fff-9550-d910-1d609cf5234a\"> </span></p>\n<p dir=\"ltr\"><span>The project has a web presence, including:</span></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>A dedicated website: </span><a href=\"http://webmining.spd.louisville.edu/?page_id=608\"><span>http://webmining.spd.louisville.edu/?page_id=608</span></a><span>&nbsp;</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>An open space on ResearchGate for all the papers resulting from our project, under the project named&nbsp;<em>Fair Machine Learning and Algorithmic Bias</em>: </span><a href=\"https://www.researchgate.net/project/Fair-Machine-Learning-and-Algorithmic-Bias\"><span>https://www.researchgate.net/project/Fair-Machine-Learning-and-Algorithmic-Bias</span></a></p>\n</li>\n</ul>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><span>Below, is additional information that summarizes two of our research outcomes for a general audience:</span></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Brief Teaser Video, using Simba the puppy as the main star,&nbsp;of our ACM Recsys 2020 paper about feedback loop theory:</span></p>\n</li>\n</ul>\n<p style=\"padding-left: 90px;\" dir=\"ltr\"><span>S. Khenissi, M. Boujelbene, O. Nasraoui. Theoretical Modeling of the Iterative Properties of User Discovery in a Collaborative Filtering Recommender System, In Proceedings of the ACM Conference on Recommender Systems (ACM RecSys), 2020:&nbsp;</span><a href=\"https://www.youtube.com/watch?v=QO-anl8sC-Q\">https://www.youtube.com/watch?v=QO-anl8sC-Q</a></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>A brief Explainer of our ACM RecSys2021 paper proposing new recommender system algorithms that provide both debiasing and explainability for the state of the art Bayesian Pairwise Ranking model:</span></p>\n</li>\n</ul>\n<p style=\"padding-left: 90px;\">Damak, Khalil; Khenissi, Sami; and Nasraoui, Olfa. Promoting explainability and unbiasedness in ranking-based recommendation in Kudos, Association for Computing Machinery (ACM), Sep. 2021: <a href=\"https://www.growkudos.com/publications/10.1145%252F3460231.3474274/reader\">https://www.growkudos.com/publications/10.1145%252F3460231.3474274/reader</a></p>\n<p><span><br /></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/27/2022<br>\n\t\t\t\t\tModified by: Olfa&nbsp;Nasraoui</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648339045148_Figure1-BiasAmplificationinLoop--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648339045148_Figure1-BiasAmplificationinLoop--rgov-800width.jpg\" title=\"A recommendation system feedback loop\"><img src=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648339045148_Figure1-BiasAmplificationinLoop--rgov-66x44.jpg\" alt=\"A recommendation system feedback loop\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 1: Users interact with items by rating, buying, clicking, etc, items recommended by a machine learning model. The interactions generate data used to train the model to predict the user interests. The predictions are used to recommend new items. The process is iterated to form a feedback loop.</div>\n<div class=\"imageCredit\">Project team</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Olfa&nbsp;Nasraoui</div>\n<div class=\"imageTitle\">A recommendation system feedback loop</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648339109071_Figure2-IteratedLearninginFeedbackLoop--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648339109071_Figure2-IteratedLearninginFeedbackLoop--rgov-800width.jpg\" title=\"The different steps in iterated learning in a recommendation feedback loop\"><img src=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648339109071_Figure2-IteratedLearninginFeedbackLoop--rgov-66x44.jpg\" alt=\"The different steps in iterated learning in a recommendation feedback loop\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 2: The different steps in iterated learning in a recommendation feedback loop, showing the step numbers (1-4) inside the gray ovals. The steps continue indefinitely, as long as the human interacts with the recommendation algorithm.</div>\n<div class=\"imageCredit\">Project team</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Olfa&nbsp;Nasraoui</div>\n<div class=\"imageTitle\">The different steps in iterated learning in a recommendation feedback loop</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648413625233_Figure3-IntellectualMeritResearchOutcomes--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648413625233_Figure3-IntellectualMeritResearchOutcomes--rgov-800width.jpg\" title=\"A Sample of Intellectual Merit Research Outcomes\"><img src=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648413625233_Figure3-IntellectualMeritResearchOutcomes--rgov-66x44.jpg\" alt=\"A Sample of Intellectual Merit Research Outcomes\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 3: Clockwise from top left: (a) We prove that the user\ufffds blind spot eventually stops decreasing. (b) Our empirical validation verifies our theory. (c) State-of-the-art algorithms with debiasing and explainability. (d) Cognitive experiments. (e) New algorithms for counter-polarization.</div>\n<div class=\"imageCredit\">Project team</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Olfa&nbsp;Nasraoui</div>\n<div class=\"imageTitle\">A Sample of Intellectual Merit Research Outcomes</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648416008139_Figure4-BroaderImpacts--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648416008139_Figure4-BroaderImpacts--rgov-800width.jpg\" title=\"Broader Impacts\"><img src=\"/por/images/Reports/POR/2022/1549981/1549981_10399123_1648416008139_Figure4-BroaderImpacts--rgov-66x44.jpg\" alt=\"Broader Impacts\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 4: Broader Impacts benefited the following (clockwise from top left): (a) Undergraduate students. (b) Teachers (and indirectly their students). (c) The general public. (d) Industry. (e) Other disciplines. (f) Social welfare. (g) Graduate students.</div>\n<div class=\"imageCredit\">Project team</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Olfa&nbsp;Nasraoui</div>\n<div class=\"imageTitle\">Broader Impacts</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nRecommender systems and information filters allow one to search through the voluminous possible products when shopping and webpages when searching the internet. Necessarily, these tools work by surfacing certain possibilities and obscuring the vast majority. Typically, the results of recommender systems and information filters are then improved by providing more of what people purchased or read, and less of that which they did not. While this filtering is essential to help users against information overload, it raises the concern of feedback loops (Figure 1) in which people are shown more and more of the products and webpages that the system initially favored, and never see alternative products and information that would be preferred, if presented. This bias in exposure and diversity of recommendations leads to under-exposure which in turn can have profound impacts on humans as it may limit the user's discovery and harm a product's exposure. Potential impacts can be unfairness, polarization and filter bubbles.\nWe proposed a theory for investigating the implications of interactions between humans and recommendation algorithms. The theory drew on diverse literature to provide algorithmic, mathematical, computational, and behavioral tools for investigating human-algorithm interaction. We specifically investigated and provided results regarding three key questions. How does biased selection in recommendation and filtering affect algorithm performance over time? How do people's actions and reasoning affect performance over time? How can we formalize the interaction between people and algorithms and predict whether changes to algorithms will \"undo\" the effects of bias and ensure \"good\" performance? Our results show that feedback loops that skew results and amplify bias (Figure 2) are possible and result in bad and biased recommendation and web search results. In doing so, we developed theoretical and experimental tools for studying how technology affects humans and vice versa. Our new methods include algorithms to detect, measure, and mitigate polarization, as well as to debias and add explainability to state of the art recommendation modeling techniques. The results show an ability to compute debiased and diversified recommendations without sacrificing their accuracy or relevance. Examples of our Intellectual Merit research outcomes are summarized in Figure 3.\nOur project has contributed to diverse broader impacts. Our project has profound societal impact, in particular on Fairness in AI, because our research contributes to recommender system algorithms that reduce the undesirable effects of bias, including filter bubbles, polarization and underexposure. In addition, our project contributed new open source data and software; outreach through open lab demos to the public, presentations at girl camps, and invited talks in industry. Our education and training impacts include a workshop, new course modules, and training PhD, Masters, and undergraduate students; as well as high school and middle school teachers through embedded authentic research experiences and related curriculum development in their classrooms. Examples of our Broader Impacts are summarized in Figure 4.\n\n \nThe project has a web presence, including:\n\n\nA dedicated website: http://webmining.spd.louisville.edu/?page_id=608 \n\n\nAn open space on ResearchGate for all the papers resulting from our project, under the project named Fair Machine Learning and Algorithmic Bias: https://www.researchgate.net/project/Fair-Machine-Learning-and-Algorithmic-Bias\n\n\n\n \nBelow, is additional information that summarizes two of our research outcomes for a general audience:\n\n\nBrief Teaser Video, using Simba the puppy as the main star, of our ACM Recsys 2020 paper about feedback loop theory:\n\n\nS. Khenissi, M. Boujelbene, O. Nasraoui. Theoretical Modeling of the Iterative Properties of User Discovery in a Collaborative Filtering Recommender System, In Proceedings of the ACM Conference on Recommender Systems (ACM RecSys), 2020: https://www.youtube.com/watch?v=QO-anl8sC-Q\n\n\nA brief Explainer of our ACM RecSys2021 paper proposing new recommender system algorithms that provide both debiasing and explainability for the state of the art Bayesian Pairwise Ranking model:\n\n\nDamak, Khalil; Khenissi, Sami; and Nasraoui, Olfa. Promoting explainability and unbiasedness in ranking-based recommendation in Kudos, Association for Computing Machinery (ACM), Sep. 2021: https://www.growkudos.com/publications/10.1145%252F3460231.3474274/reader\n\n\n\n\n\t\t\t\t\tLast Modified: 03/27/2022\n\n\t\t\t\t\tSubmitted by: Olfa Nasraoui"
 }
}