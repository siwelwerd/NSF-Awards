{
 "awd_id": "1452831",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Identifying Neurosensory Solutions to the Binding Problem in Animal Behavior",
 "cfda_num": "47.074",
 "org_code": "08090200",
 "po_phone": "7032924845",
 "po_email": "sraghava@nsf.gov",
 "po_sign_block_name": "Sridhar Raghavachari",
 "awd_eff_date": "2015-05-15",
 "awd_exp_date": "2021-12-31",
 "tot_intn_awd_amt": 680000.0,
 "awd_amount": 680000.0,
 "awd_min_amd_letter_date": "2015-05-14",
 "awd_max_amd_letter_date": "2021-01-29",
 "awd_abstract_narration": "Human and animal behavior is guided by continuous and often complex sensory input. Nervous systems must parse this input stream and bind together those pieces corresponding to actual objects in the environment. As an illustration, consider the command to STOP. The human visual system effortlessly binds an octagonal shape with red coloration into a unified visual percept that elicits stopping behavior. Likewise, different sounds in the spoken word \"stop\" become bound into an auditory percept that also elicits stopping behavior. Efforts to understand how nervous systems solve these so-called \"binding problems\" have advanced the fields of cognitive and computational neuroscience. By comparison, much less is known about how nonhuman animals create bound percepts that correspond to the variety of things of interest to animals (e.g. prey, predators, mates, communication signals). Hence, important knowledge gaps remain concerning the brain mechanisms that allow animals to solve binding problems. This project integrates behavioral and electrophysiological experiments to uncover general mechanisms of auditory perceptual binding in an animal model for which vocal communication in noisy social environments is key to successful reproduction. This research is important because basic knowledge of neurosensory mechanisms that enable animals to solve auditory binding problems could benefit society by helping to improve hearing prosthetics and speech recognition systems, which perform poorly in noisy acoustic scenes. This research will also lead to answering new questions about how neural systems shape the evolution of communication behaviors. In addition, the project will create research experiences for a minimum of 15 undergraduates, advance the training of a postdoctoral scholar, and integrate research and teaching with public outreach aimed at elementary school kids in a large metropolitan area. \r\n\r\nThe project investigates auditory binding in green treefrogs (Hyla cinerea), a well-known animal model in studies of hearing and sound communication. Aim 1 uses behavioral experiments to identify cues that promote auditory binding. Two experiments will test the hypothesis that synchronous onsets/offsets, common spatial origin, and harmonic relatedness function to bind together separate parts of the frequency spectrum of vocalizations analogous to formants in human vowel sounds. Aim 2 involves electrophysiological recordings from single neurons in the auditory midbrain to identify neural correlates of auditory binding. Three experiments will test the hypothesis that changes in the responses of neurons sensitive to spectral combinations correlate with changes in the behavioral decisions made in response to manipulations of the auditory binding cues from Aim 1.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "BIO",
 "org_dir_long_name": "Directorate for Biological Sciences",
 "div_abbr": "IOS",
 "org_div_long_name": "Division Of Integrative Organismal Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Bee",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Mark A Bee",
   "pi_email_addr": "mbee@umn.edu",
   "nsf_id": "000292566",
   "pi_start_date": "2015-05-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "University of Minnesota-Twin Cities",
  "perf_str_addr": "1479 Gortner Ave",
  "perf_city_name": "St. Paul",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "551081041",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "771300",
   "pgm_ele_name": "Activation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 170000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 170000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 170000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 170000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Most people have experienced the difficulty of trying to follow a conversation in a noisy social environment, such as a cocktail party or cafeteria. Compared with quiet settings, the noise of competing voices and other background sounds makes it harder to comprehend speech. Scientists refer to this added difficulty in speech perception as the <em><strong>cocktail party problem</strong></em>, and it is of interest to society for several reasons.&nbsp;</p>\n<p>From a biomedical perspective, it is important to study the cocktail party problem because hearing impaired people have trouble solving it, even when using the most advanced hearing aids and cochlear implants. From an engineering perspective, other human technologies - from smartphones to cars, computers, and robots - are capable of automated speech recognition but perform poorly when there are competing voices and other background noise. From an evolutionary perspective, it is now apparent that many nonhuman animals have independently evolved social behaviors and communication systems in which they routinely encounter and solve biological analogs of the cocktail party problem. Therefore, by studying a diversity of nonhuman animals, we can learn how biological systems have evolved to solve a difficult problem of interest in medicine, computer science, and engineering.&nbsp;</p>\n<p>This project investigated how frogs - famous for calling loudly in noisy breeding choruses - overcome their own cocktail-party-like problem. What makes hearing in noisy social environments so difficult? It is because, unlike in <em>visual scenes</em>&nbsp;where objects in the foreground occlude those in the background, the sound pressure waves generated by multiple sound sources in an <em>acoustic scene</em>&nbsp;add together. The result is a complex sound mixture that the auditory system must decompose in order to hear and identify distinct sound sources. This project investigated how female treefrogs go about decomposing the complex sound mixtures created in noisy breeding choruses, where dozens or even hundreds of males from multiple species may be heard calling at the same time to attract a mate.&nbsp;</p>\n<p>The investigators discovered that the frog auditory system exploits cues related to the physics of sound production to assign different parts of the complex sound mixture to the source that produced them. Among these cues is one called <em>temporal coherence</em>, which describes how different parts of a sound mixture that start and stop at the same time are likely produced by the same sound source. Experimental results showed that frogs take advantage of temporal coherence in two contexts. First, vocalizations in frogs (and humans and other animals) contain simultaneous acoustic energy at different frequencies (e.g., harmonics or speech formants) that starts and stops together. Female treefrogs were found to assign different frequencies that start and stop together to the same vocal sound source; but when these frequencies started and stopped at different times, they were assigned to different vocal sources. Second, the researchers discovered that the noise generated in frog choruses undergoes coherent fluctuations in volume across different frequencies. They discovered that female frogs exploit these temporally coherent fluctuations to improve the detection of mating calls in noise.&nbsp;</p>\n<p>The use of additional cues, such as <em>harmonicity</em>&nbsp;and <em>spatial coherence</em> were also investigated. Harmonicity is a feature of vocalizations in humans and other animals (and of the sounds of musical instruments). It refers to fixed numerical relationships between different parts of the frequency spectrum. The researchers showed that treefrogs also exploit these harmonic relationships to assign different simultaneous frequency components to the same source. Spatial coherence is another byproduct of sound production that stems from the fact that the sounds produced by a source originate from the same location in space. However, the researchers found that, as in humans, spatial coherence was a less potent cue in frogs for assigning simultaneous sounds to the same source compared with other cues.&nbsp;</p>\n<p>An additional and unexpected discovery from this work was the function of a unique lung-to-ear sound transmission pathway in frogs. Historically, this pathway was hypothesized to function in sound localization. The researchers were able to reject this hypothesis and showed instead that the lung input functions to reduce unwanted noise in a specific frequency range that would otherwise impair their ability to hear calls of interest. The mechanism behind the phenomenon is believed to function in much the same way as noise-cancellation headphones.</p>\n<p>Collectively, the outcomes from this project created new knowledge about how a vertebrate auditory system has evolved to hear and interpret vocalizations in noisy social settings. Along the way, this project provided training and professional development opportunities for several undergraduate students, PhD and MS students, and postdocs, several of whom were members of underrepresented minorities in STEM fields. In addition, this project supported several outreach efforts designed to enhance public awareness and understanding of hearing and vocal communication in humans and other animals.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/14/2022<br>\n\t\t\t\t\tModified by: Mark&nbsp;A&nbsp;Bee</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMost people have experienced the difficulty of trying to follow a conversation in a noisy social environment, such as a cocktail party or cafeteria. Compared with quiet settings, the noise of competing voices and other background sounds makes it harder to comprehend speech. Scientists refer to this added difficulty in speech perception as the cocktail party problem, and it is of interest to society for several reasons. \n\nFrom a biomedical perspective, it is important to study the cocktail party problem because hearing impaired people have trouble solving it, even when using the most advanced hearing aids and cochlear implants. From an engineering perspective, other human technologies - from smartphones to cars, computers, and robots - are capable of automated speech recognition but perform poorly when there are competing voices and other background noise. From an evolutionary perspective, it is now apparent that many nonhuman animals have independently evolved social behaviors and communication systems in which they routinely encounter and solve biological analogs of the cocktail party problem. Therefore, by studying a diversity of nonhuman animals, we can learn how biological systems have evolved to solve a difficult problem of interest in medicine, computer science, and engineering. \n\nThis project investigated how frogs - famous for calling loudly in noisy breeding choruses - overcome their own cocktail-party-like problem. What makes hearing in noisy social environments so difficult? It is because, unlike in visual scenes where objects in the foreground occlude those in the background, the sound pressure waves generated by multiple sound sources in an acoustic scene add together. The result is a complex sound mixture that the auditory system must decompose in order to hear and identify distinct sound sources. This project investigated how female treefrogs go about decomposing the complex sound mixtures created in noisy breeding choruses, where dozens or even hundreds of males from multiple species may be heard calling at the same time to attract a mate. \n\nThe investigators discovered that the frog auditory system exploits cues related to the physics of sound production to assign different parts of the complex sound mixture to the source that produced them. Among these cues is one called temporal coherence, which describes how different parts of a sound mixture that start and stop at the same time are likely produced by the same sound source. Experimental results showed that frogs take advantage of temporal coherence in two contexts. First, vocalizations in frogs (and humans and other animals) contain simultaneous acoustic energy at different frequencies (e.g., harmonics or speech formants) that starts and stops together. Female treefrogs were found to assign different frequencies that start and stop together to the same vocal sound source; but when these frequencies started and stopped at different times, they were assigned to different vocal sources. Second, the researchers discovered that the noise generated in frog choruses undergoes coherent fluctuations in volume across different frequencies. They discovered that female frogs exploit these temporally coherent fluctuations to improve the detection of mating calls in noise. \n\nThe use of additional cues, such as harmonicity and spatial coherence were also investigated. Harmonicity is a feature of vocalizations in humans and other animals (and of the sounds of musical instruments). It refers to fixed numerical relationships between different parts of the frequency spectrum. The researchers showed that treefrogs also exploit these harmonic relationships to assign different simultaneous frequency components to the same source. Spatial coherence is another byproduct of sound production that stems from the fact that the sounds produced by a source originate from the same location in space. However, the researchers found that, as in humans, spatial coherence was a less potent cue in frogs for assigning simultaneous sounds to the same source compared with other cues. \n\nAn additional and unexpected discovery from this work was the function of a unique lung-to-ear sound transmission pathway in frogs. Historically, this pathway was hypothesized to function in sound localization. The researchers were able to reject this hypothesis and showed instead that the lung input functions to reduce unwanted noise in a specific frequency range that would otherwise impair their ability to hear calls of interest. The mechanism behind the phenomenon is believed to function in much the same way as noise-cancellation headphones.\n\nCollectively, the outcomes from this project created new knowledge about how a vertebrate auditory system has evolved to hear and interpret vocalizations in noisy social settings. Along the way, this project provided training and professional development opportunities for several undergraduate students, PhD and MS students, and postdocs, several of whom were members of underrepresented minorities in STEM fields. In addition, this project supported several outreach efforts designed to enhance public awareness and understanding of hearing and vocal communication in humans and other animals.\n\n \n\n\t\t\t\t\tLast Modified: 03/14/2022\n\n\t\t\t\t\tSubmitted by: Mark A Bee"
 }
}